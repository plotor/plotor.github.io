[{"title":"Ray Serve 集成 Triton Inference Server 构建模型在线推理服务","url":"/2025/03/31/ray/triton-inference-server/","content":"\nTriton Inference Server（下文简称 Triton）是 Nvidia 推出的高性能推理服务器，支持多种模型框架和硬件平台，关于 Triton 的更多内容可以参考 [官方文档](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/introduction/index.html)。Triton 与 Ray Serve 在功能定位方面存在相同之处，不过二者也各有优势：\n\n- Ray Serve 原生支持以分布式模式运行，可在单一应用中编排并部署多个模型，以满足复杂推理场景的需求。同时，其内置的弹性伸缩特性能够有效平衡用户请求与资源开销。\n\n- Triton 主要专注于单机推理场景，兼容多种硬件平台。通过引入动态批处理、多 GPU 并行推理等技术以提升模型推理性能，同时支持以 Backend 插件形式集成多种模型框架，并对外提供统一的接入 API。<!-- more -->\n\n如下图所示，通过将 Ray Serve 与 Triton 集成能够让二者的优势形成互补：\n\n![image](/images/2025/ray-serve-triton-infer-server.png)\n\n在集成模式下，Ray Serve 主要承担流量承接、负载均衡、模型编排以及弹性伸缩等职责；而 Triton 则作为单机版的模型推理服务，具备模型加载、推理及加速等功能。本文首先介绍如何基于 Triton 部署大语言模型，然后介绍如何将 Ray Serve 与 Triton 集成，使用的环境信息如下：\n\n> - 镜像：nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3\n> - 模型：Llama-3.2-1B-Instruct\n> - 显卡：Nvidia A10 (24GB), CUDA 12.2\n\n## 基于 Triton 部署单机版在线推理服务\n\nTriton 支持多种类型的 Backend，这里我们以 TensorRT-LLM Backend 为例。要让 Triton 能够部署 Llama 模型，主要包含如下两步操作：\n\n1. 编译模型文件生成 TensorRT 引擎，利用 TensorRT-LLM Backend 实现与 Triton 集成。\n\n2. 通过 TensorRT-LLM Backend 内置的模型集成配置模板对 Triton 模型仓库进行配置，以便 Triton 能够识别并部署该模型。\n\n简单起见，这里我们基于 Nvidia 提供的镜像创建 Docker 容器进行操作，以避免复杂的 CUDA 驱动安装，以及一系列环境配置等。为了让 Docker 容器能够访问宿主机 GPU 资源，你需要参考 [官方文档](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) 安装配置 NVIDIA Container Toolkit，然后基于 `nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3` 镜像创建并进入 Docker 容器：\n\n```bash\n$ docker run -it \\\n  --name triton-infer-server \\\n  --gpus all \\\n  --ipc=host \\\n  -p8000:8000 -p8001:8001 -p8002:8002 -p:8080:8080 -p8265:8265 \\\n  -v /opt/workspace:/opt/workspace \\\n  -w /opt/workspace \\\n  -d nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3 \\\n  /bin/bash\n\n$ docker exec -it 859b7c7d53dd /bin/bash\n```\n\n### 编译模型\n\n以 `Llama-3.2-1B-Instruct` 模型为例，参考 [官方文档](https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/llama) 将其转换成 TensorRT 引擎格式：\n\n- 脚本 `convert_checkpoint.py` 用于将 HF 权重转换为 TensorRT-LLM 检查点。\n\n- 命令 `trtllm-build` 用于从 TensorRT-LLM 检查点构建 TensorRT-LLM 引擎。\n\n操作示例：\n\n```bash\ncd /opt/workspace/nvidia && git clone https://github.com/NVIDIA/TensorRT-LLM.git\n\ncd ./TensorRT-LLM && pip install --upgrade -r requirements.txt\n\ncd ./examples/llama\n\npython convert_checkpoint.py \\\n  --model_dir /opt/workspace/models/llama/Llama-3.2-1B-Instruct \\\n  --output_dir /opt/workspace/models/llama/tllm_checkpoint_1gpu_tp1 \\\n  --dtype float16 \\\n  --tp_size 1\n\ntrtllm-build \\\n  --checkpoint_dir /opt/workspace/models/llama/tllm_checkpoint_1gpu_tp1 \\\n  --output_dir /opt/workspace/models/llama/trt_engines \\\n  --gemm_plugin auto\n```\n\n这一步完成后将在 `trt_engines` 目录下生成如下 2 个文件：\n\n- `rank0.engine`：该文件包含嵌入模型权重的可执行操作图。\n\n- `config.json`：该文件包含模型的详细信息，例如结构、精度，以及引擎中集成的插件列表等。\n\n此时，我们可以通过 TensorRT-LLM 提供的脚本进行推理验证：\n\n```bash\ncd /opt/workspace/nvidia/TensorRT-LLM/examples/llama\n\npython ../run.py \\\n  --input_text \"What is Nvidia Triton Inference Server\" \\\n  --max_output_len=1024 \\\n  --tokenizer_dir /opt/workspace/models/llama/Llama-3.2-1B-Instruct \\\n  --engine_dir=/opt/workspace/models/llama/trt_engines\n```\n\n没有问题的话，上述请求会返回模型的推理结果。\n\n### 部署模型\n\nTensorRT-LLM Backend 内置了模型集成配置模板以简化模型的集成操作（位于 `all_models/inflight_batcher_llm` 目录，内容如下），模板主要包含 4 个模块，分别对应模型执行过程的不同阶段。\n\n```text\n.\n|-- ensemble\n|   |-- 1\n|   `-- config.pbtxt\n|-- postprocessing\n|   |-- 1\n|   |   `-- model.py\n|   `-- config.pbtxt\n|-- preprocessing\n|   |-- 1\n|   |   `-- model.py\n|   `-- config.pbtxt\n`-- tensorrt_llm\n    |-- 1\n    |   |-- config.json\n    |   |-- model.py\n    |   `-- rank0.engine\n    `-- config.pbtxt\n```\n\n说明：\n\n- 模块 preprocessing 包含用于对输入进行 tokenizing 的脚本，支持将用户输入的 prompt 字符串转换成 input_id 列表。\n\n- 模块 postprocessing 包含用于对输出进行 de-tokenizing 的脚本，支持将模型输出的 output_id 列表转换成用户能够理解的字符串。\n\n- 模块 tensorrt_llm 包含用户编译生成的模型文件，负载加载并调用用户自定义模型完成推理操作。\n\n- 模块 ensemble  用于将 preprocessing、tensorrt_llm 和 postprocessing 模块串联在一起，指导 Triton 如何在这些模块之间传输数据以构建一个完整的推理流程。\n\n你可以从 Github 下载模型仓库配置模板，并将前面编译得到的模型文件拷贝到模型仓库中：\n\n```bash\ncd /opt/workspace/nvidia && git clone https://github.com/triton-inference-server/tensorrtllm_backend.git\n\ncp -r ./tensorrtllm_backend/all_models/inflight_batcher_llm/* /opt/workspace/models/llama/triton\n\ncp /opt/workspace/models/llama/trt_engines/* /opt/workspace/models/llama/triton/tensorrt_llm/1\n```\n\n然后执行如下命令修改相关配置：\n\n```bash\nTOKENIZER_DIR=/opt/workspace/models/llama/Llama-3.2-1B-Instruct\nTOKENIZER_TYPE=auto\nENGINE_DIR=/opt/workspace/models/llama/triton/tensorrt_llm/1\nDECOUPLED_MODE=false\nMODEL_FOLDER=/opt/workspace/models/llama/triton\nMAX_BATCH_SIZE=4\nINSTANCE_COUNT=1\nMAX_QUEUE_DELAY_MS=10000\nTRITON_BACKEND=tensorrtllm\nLOGITS_DATATYPE=\"TYPE_FP32\"\nFILL_TEMPLATE_SCRIPT=/opt/workspace/nvidia/tensorrtllm_backend/tools/fill_template.py\npython3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_FOLDER}/preprocessing/config.pbtxt tokenizer_dir:${TOKENIZER_DIR},tokenizer_type:${TOKENIZER_TYPE},triton_max_batch_size:${MAX_BATCH_SIZE},preprocessing_instance_count:${INSTANCE_COUNT}\npython3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_FOLDER}/postprocessing/config.pbtxt tokenizer_dir:${TOKENIZER_DIR},tokenizer_type:${TOKENIZER_TYPE},triton_max_batch_size:${MAX_BATCH_SIZE},postprocessing_instance_count:${INSTANCE_COUNT}\npython3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_FOLDER}/tensorrt_llm_bls/config.pbtxt triton_max_batch_size:${MAX_BATCH_SIZE},decoupled_mode:${DECOUPLED_MODE},bls_instance_count:${INSTANCE_COUNT},logits_datatype:${LOGITS_DATATYPE}\npython3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_FOLDER}/ensemble/config.pbtxt triton_max_batch_size:${MAX_BATCH_SIZE},logits_datatype:${LOGITS_DATATYPE}\npython3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_FOLDER}/tensorrt_llm/config.pbtxt triton_backend:${TRITON_BACKEND},triton_max_batch_size:${MAX_BATCH_SIZE},decoupled_mode:${DECOUPLED_MODE},engine_dir:${ENGINE_DIR},max_queue_delay_microseconds:${MAX_QUEUE_DELAY_MS},batching_strategy:inflight_fused_batching,encoder_input_features_data_type:TYPE_FP16,logits_datatype:${LOGITS_DATATYPE}\n```\n\n如果需要手动编辑 CPU 核数可以修改 `config.pbtxt` 配置：\n\n```text\ninstance_group [\n  {\n    count: 8\n    kind : KIND_CPU\n  }\n]\n```\n\n需要注意的是这个参数不宜设置过大，否则可能导致服务拉不起来报 OOM 错误：\n\n```text\n[TensorRT-LLM][ERROR] [engine.cpp::readEngineFromArchive::1093] Error Code 2: OutOfMemory (Requested size was 996311552 bytes.)\n```\n\n启动 Triton Inference Server：\n\n```bash\ncd /opt/workspace/nvidia/tensorrtllm_backend\n\npython scripts/launch_triton_server.py \\\n  --model_repo /opt/workspace/models/llama/triton \\\n  --world_size 1\n```\n\n启动成功将会在最后打印：\n\n```text\nI0314 12:05:57.080618 17817 grpc_server.cc:2558] \"Started GRPCInferenceService at 0.0.0.0:8001\"\nI0314 12:05:57.080826 17817 http_server.cc:4725] \"Started HTTPService at 0.0.0.0:8000\"\nI0314 12:05:57.122329 17817 http_server.cc:358] \"Started Metrics Service at 0.0.0.0:8002\"\n```\n\n此时可以通过 POST 请求验证：\n\n```bash\ncurl --location 'http://127.0.0.1:8000/v2/models/ensemble/generate' \\\n--header 'Content-Type: application/json' \\\n--data '{\n  \"text_input\": \"介绍一下 Triton Inference Server\",\n  \"parameters\": {\n    \"max_tokens\": 256,\n    \"bad_words\": [\n      \"\"\n    ],\n    \"stop_words\": [\n      \"\"\n    ]\n  }\n}'\n```\n\n## 引入 Ray Serve 构建分布式在线推理服务\n\nRay Serve 是依托于 Ray 分布式计算框架之上构建的模型在线服务库，提供基于给定模型构建高性能、低延迟在线推理服务的能力。基于 Ray Serve 构建在线推理服务具有如下优势：\n\n- __异构计算__：支持根据模型对资源的需求，灵活地将模型部署并运行于 CPU 或 GPU 类型的节点上。\n\n- __弹性伸缩__：支持依据请求负载，在预设范围内自动调整集群规模，以平衡推理性能与资源开销。火山 EMR Ray 在社区 Autoscale 能力的基础上进一步优化，支持自定义扩缩容指标和策略。\n\n- __失败容错__：支持多副本部署以抵御单副本故障，同时提供针对系统级、应用级的故障恢复能力，当副本或节点出现故障时，可通过重试、重调度等方式确保服务持续运行。\n\n- __多模型融合__：支持在单个 Ray Serve 应用中编排部署多个模型，这些模型可以独立或组合对外提供服务，同时针对各个模型可以独立配置资源调度、弹性伸缩等。\n\n- __动态批处理__：支持按照请求数量和时间跨度对多个请求进行合并，然后批量发送给模型进行处理，通过借助硬件（如 GPU）的并行计算能力，能够在显著提升吞吐量的同时，尽量维持低延迟。\n\n- __模型多路复用__：针对需加载大量模型的应用场景（例如个性化推荐），允许单个应用加载多个模型并向外部提供服务，然而出于资源考量，也会对应用内单副本可加载的模型在数量上加以限制。同时，Ray Serve 会尽可能将请求路由至已完成模型加载的副本进行处理，以平衡推理性能与资源消耗。\n\n- __支持原生集成 vLLM 实现推理加速__：提供与 vLLM 引擎的原生集成能力，通过简单配置即可复用 vLLM 在推理场景中引入的 PagedAttention、动态批处理等多项优化技术，以提升模型推理性能和资源利用率。\n\n- __支持集成 Nvidia Triton Inference Server 实现优势互补__：Triton 针对单机推理场景进行了大量的优化以提升性能，但生产化部署还需要具备负载均衡、弹性伸缩、失败容错，以及模型编排等多方面的能力，通过集成 Triton，能够实现双方优势的有效互补。在集成形态下，Triton 作为单机版的模型推理服务，而 Ray Serve 则承担上层路由与管理职责，提供整体的请求路由、负载均衡、多模型编排，以及弹性伸缩等能力。\n\n- 简洁的编程模型便于进行本地开发与调试，仅需进行简单修改便可进行线上部署。\n\n- Python Native。\n\n在分布式在线推理场景下，通过将 Ray Serve 与 Triton 进行集成，能够在发挥 Triton 在单机场景固有优势的同时，为其补齐在分布式场景下的不足。Triton 提供了 [In-Process Python API](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/client_guide/python.html) 用于支持 Python 生态与 Triton 进行集成，相较于发送 HTTP 请求的方式更为便捷。下面的示例通过 Triton In-Process Python API 实现了 Ray Serve 与 Triton 的集成：\n\n```python\nimport ctypes\nfrom typing import Iterable\n\nimport numpy as np\nimport tritonserver\nfrom fastapi import FastAPI\nfrom ray import serve\n\napi = FastAPI()\n\n\n@serve.deployment(\n    ray_actor_options=dict(\n        num_gpus=1\n    )\n)\n@serve.ingress(api)\nclass Generator:\n\n    def __init__(self, model_path: str):\n        import torch\n        assert torch.cuda.is_available(), RuntimeError(\"CUDA is not available\")\n\n        self._server = tritonserver.Server(\n            tritonserver.Options(\n                model_repository=model_path,\n                log_info=True,\n                log_warn=True,\n                log_error=True\n            )\n        )\n        self._server.start(wait_until_ready=True)\n        self._model = self._server.model(\"ensemble\")\n\n    @api.get(\"/generate\")\n    def generate(self, query: str):\n        if not self._model.ready():\n            raise RuntimeError(\"Model is not ready, Please try again later.\")\n\n        resp = list(self._model.infer(inputs={\n            \"text_input\": [[query]],\n            \"max_tokens\": np.array([[1024]], dtype=np.int32)\n        }))[0]\n\n        return self._to_string(resp.outputs[\"text_output\"])\n\n    def _to_string(self, tensor: tritonserver.Tensor) -> str:\n        \"\"\"\n        This method is copied from https://github.com/triton-inference-server/server\n        \"\"\"\n        ...\n\n\napp = Generator.bind(\"/opt/workspace/models/llama/triton\")\n```\n\n注意：\n\n1. 由于 ensemble 模块是整个推理模型流程对外接口，因此加载的模型名称应该是 ensemble，而不是 tensorrt_llm。\n\n2. 对于需要 GPU 资源的模型，必须配置 `num_gpus` 参数，否则 Ray Serve 并不会将 Deployment 调度部署到 GPU 节点上，从而导致 Triton 加载失败。\n\n通过执行 `serve deploy` 命令，可将上述 Ray Serve 应用部署至目标 Ray Cluster 集群。应用成功启动后，可通过以下 POST 请求向模型发送推理请求：\n\n```bash\ncurl --location 'http://127.0.0.1:8000/v1/chat/completions' \\\n--header 'Content-Type: application/json' \\\n--data '{\n  \"model\": \"meta-llama/Llama-3.2-1B-Instruct\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"介绍一下 Ray Serve 集成 Triton Inference Server 的优势\"\n    }\n  ]\n}'\n```\n\n## 参考\n\n- [NVIDIA Triton Inference Server](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/introduction/index.html)\n- [Turbocharging Meta Llama 3 Performance with NVIDIA TensorRT-LLM and NVIDIA Triton Inference Server](https://developer.nvidia.com/blog/turbocharging-meta-llama-3-performance-with-nvidia-tensorrt-llm-and-nvidia-triton-inference-server/)\n","tags":["Ray","LLM"],"categories":["ray"]},{"title":"SOFA-JRaft 源码解析：线性一致性读","url":"/2020/06/29/sofa/sofa-jraft-linearizable-read/","content":"\n关于线性一致性读的定义，简单而言就是在 T 时刻执行写入操作，那么在 T 时刻之后一定能够读取到之前写入的值。Raft 算法能够至少保证集群节点数据的最终一致性，也就说就某一特定时刻而言各个节点之间的数据状态允许存在滞后。在分布式场景下如果允许各个节点随机响应用户的读请求，则可能会读取到脏数据。如果希望基于 Raft 算法实现线性一致性读语义，最简单的方式就是将读操作作为一个指令提交给 Raft 集群，由于 Raft 算法能够保证指令执行的顺序性，所以该读操作指令一定能够读取到在此之前写入的值（本文将此类线性一致性读策略命名为 RaftLog Read）。然而，RaftLog Read 的缺点也是显而易见的，每次读操作都需要走一遍完整的 Raft 算法流程势必效率低下，并且大部分的应用场景都具备读多写少的特征，所以该策略势必会让 Raft 集群产生大量的日志文件，增加磁盘和网络的开销。\n\n换一个角度思考，在 Raft 算法中更新操作都由 Leader 节点负责响应，那么极端一点每次都从 Leader 节点读数据是不是就万事大吉了呢？先不说这种方式将一个分布式系统退化成了单机系统，我们还需要考虑下面两个问题：\n\n- 日志数据从提交到被业务状态机所应用这中间存在一定的时间滞后性，所以直接执行读操作不一定能够读取到最新的数据。\n- 当前 Leader 节点不一定是有效的，因为 Leader 节点的变更通常有一个时间差，而这中间存在导致脏读的可能性。\n\n<!-- more -->\n\n对于一个分布式系统而言，只能从 Leader 节点读这显然是不能接受的，所以我们的真正需求是能够从各个节点发起读请求，同时还需要保证读写的线性一致性。为此，Raft 算法的最终实现思路可以概括如下：\n\n1. 确定当前 Leader 节点的有效性；\n2. 从 Leader 节点拉取最新的 comittedIndex 值，即 lastComittedIndex 值；\n3. 等待本地已被业务状态应用的 LogEntry 对应的 logIndex 值超过该 lastComittedIndex 位置。\n\n如果目标 Leader 节点是有效的，那么由于写操作在前（令时刻为 `T1`），在发起读操作的那一刻（令时刻为 `T2(T2 > T1)`）开始，该 Leader 节点已提交的日志中必定包含 `T1` 时刻的写操作指令，也就是说该写操作对应 LogEntry 的 logIndex 必定小于等于 lastComittedIndex 值。所以，如果我们在本地等待业务状态机完成对于 lastComittedIndex 位置之前日志的应用，一定能够保证 `T2` 时刻的读操作能够从本地看到 `T2` 时刻 Leader 节点的数据状态，又 `T2 > T1`，所以 `T2` 时刻的读操作至少能够看到 `T1` 时刻的写结果。\n\n既然证明了上述思路能够让 Raft 算法实现线性一致性读语义，那么接下去问题就演变成如何确定当前 Leader 节点是否有效。Raft 算法为此提出了两种思路，即：ReadIndex Read 和 Lease Read。\n\n- __ReadIndex Read__\n\n我们的目标是确定当前 Leader 节点是否有效，直观的思路就是让该 Leader 节点向所有的 Follower 节点发送一次心跳请求，如果过半数的 Follower 节点都能正常响应该心跳请求，则视为当前 Leader 节点仍然有效，这要是 ReadIndex Read 的核心思想。相对于 RaftLog Read，ReadIndex Read 策略虽然也需要与各个 Follower 节点进行一次 RPC 交互（心跳请求交互的开销极小），但是省去了日志流程，在磁盘和网络开销层面都更加友好，整体性能也完胜 RaftLog Read。\n\n- __Lease Read__\n\nReadIndex Read 相对于 RaftLog Read 策略，在保证线性一致性读语义的前提下在磁盘占用、网络开销，以及读性能等方面都有明显的改善，但是不足之处在于仍然会与各个 Follower 节点进行一次 RPC 交互，能不能消除这一次 RPC 交互呢？为此，Raft 算法基于 `clock + heartbeat` 的思想提出了 Lease Read 策略。\n\nLease Read 策略下 Leader 节点会记录一轮成功心跳请求的开始时间（即向各个 Follower 节点成功发送心跳 RPC 请求的最早时间戳），令其为 startTime。由于 Raft 的选举由超时策略触发（令超时时长为 electionTimeout），所以我们可以认为所有的 Follower 节点在 `startTime + electionTimeout` 时间之前都不会发起新一轮的选举请求（因为心跳请求会重置 Follower 节点的选举计时器），即对应的 Leader 节点在此时间之前一定是有效的，从而避免了向各个 Follower 节点发送心跳请求的操作。\n\n然而，Lease Read 策略的应用有一个前提，即所有节点宿主机的时钟频率是一致的，如果某个节点的时钟频率相对较快则会导致该节点在 `startTime + electionTimeout` 之前出现超时的情况。为了解决此类时钟漂移的问题，我们可以将 `startTime + electionTimeout` 修改为 `startTime + electionTimeout / clockDriftBound`，即容忍一定的时间漂移，不过这只是降低了问题出现的可能性，并没有完全解决问题。好在大多数情况下 CPU 的时钟频率都是准确的，并且 Lease Read 策略相对于 ReadIndex Read 策略在性能层面表现更优（JRaft 给出的统计提升在 15% 左右），所以业务可以基于自己的应用场景决策使用哪种线性一致性读策略。\n\n### 实现内幕\n\n上面介绍了线性一致性读的定义，以及在 Raft 算法中提供线性一致性读语义的 3 种策略及其优缺点，本小节我们开始从 JRaft 算法库的实现层面去分析如何实现这些策略。\n\nJRaft 节点定义了 `Node#readIndex` 方法用于实现向 JRaft 集群发送一个线性一致性读请求，并感知当前节点是否完成与 Leader 节点就当前时刻 Leader 节点已经提交的数据的同步状态。该方法接收两个参数，其中 requestContext 参数用于封装一些请求上下文信息，而 done 参数则会在节点完成线性一致性读处理时被回调，具体实现如下：\n\n```java\npublic void readIndex(final byte[] requestContext, final ReadIndexClosure done) {\n    // 当前节点正在被关闭\n    if (this.shutdownLatch != null) {\n        Utils.runClosureInThread(done,\n                new Status(RaftError.ENODESHUTDOWN, \"Node is shutting down.\"));\n        throw new IllegalStateException(\"Node is shutting down\");\n    }\n    Requires.requireNonNull(done, \"Null closure\");\n    // 向 ReadOnlyService 提交一个 ReadIndex 请求，\n    // 当本地数据与 Leader 节点数据在特定的位置（lastCommittedIndex）同步时，响应回调\n    this.readOnlyService.addRequest(requestContext, done);\n}\n```\n\n如果当前节点处于正常运行状态，则上述方法会调用 `ReadOnlyService#addRequest` 方法以 Disruptor 消息的形式向集群提交一个线性一致性读请求事件，而处理这一类型事件的逻辑则由 `ReadOnlyServiceImpl#executeReadIndexEvents` 方法实现：\n\n```java\nprivate void executeReadIndexEvents(final List<ReadIndexEvent> events) {\n    if (events.isEmpty()) {\n        return;\n    }\n\n    // 构造 ReadIndex 请求\n    final ReadIndexRequest.Builder rb = ReadIndexRequest.newBuilder() //\n            .setGroupId(this.node.getGroupId()) //\n            .setServerId(this.node.getServerId().toString());\n\n    final List<ReadIndexState> states = new ArrayList<>(events.size());\n\n    for (final ReadIndexEvent event : events) {\n        rb.addEntries(ZeroByteStringHelper.wrap(event.requestContext.get()));\n        states.add(new ReadIndexState(event.requestContext, event.done, event.startTime));\n    }\n    final ReadIndexRequest request = rb.build();\n\n    // 处理 ReadIndex 请求\n    this.node.handleReadIndexRequest(request, new ReadIndexResponseClosure(states, request));\n}\n```\n\n上述实现的主要逻辑在于构造 ReadIndex 请求，然后调用 `NodeImpl#handleReadIndexRequest` 方法处理该请求。发起线性一致性读请求的节点可以是 Leader 节点，也可以是 Follower 或 Learner 节点：\n\n- 对于 Follower 或 Learner 节点而言，需要将请求转发给 Leader 节点，以获取当前 Leader 节点的 lastCommittedIndex 位置。\n- 对于 Leader 节点而言，其目的是读取本地的 lastCommittedIndex 值返回给请求节点，但是在返回之前需要验证当前 Leader 节点的有效性。\n\n方法 `NodeImpl#handleReadIndexRequest` 实现如下：\n\n```java\npublic void handleReadIndexRequest(final ReadIndexRequest request, final RpcResponseClosure<ReadIndexResponse> done) {\n    final long startMs = Utils.monotonicMs();\n    this.readLock.lock();\n    try {\n        switch (this.state) {\n            // 当前节点是 LEADER 角色\n            case STATE_LEADER:\n                // 基于 ReadIndexRead 或 LeaseRead 策略验证当前 Leader 节点是否仍然有效\n                readLeader(request, ReadIndexResponse.newBuilder(), done);\n                break;\n            // 当前节点是 FOLLOWER 角色\n            case STATE_FOLLOWER:\n                // 向 Leader 节点发送 ReadIndex 请求\n                readFollower(request, done);\n                break;\n            // 当前正在执行 LEADER 节点切换\n            case STATE_TRANSFERRING:\n                done.run(new Status(RaftError.EBUSY, \"Is transferring leadership.\"));\n                break;\n            default:\n                done.run(new Status(RaftError.EPERM, \"Invalid state for readIndex: %s.\", this.state));\n                break;\n        }\n    } finally {\n        // ... metrics\n    }\n}\n```\n\n上述方法依据当前节点的角色分而治之，对于 Follower 或 Learner 节点而言只是简单的将 ReadIndex 请求转发给 Leader 节点进行处理，实现比较简单。下面重点来看一下 `NodeImpl#readLeader` 方法的实现，不管当前 ReadIndex 请求是来自 Leader 节点还是 Follower 节点，最终都需要转发给 Leader 节点执行。方法 `NodeImpl#readLeader` 实现如下：\n\n```java\nprivate void readLeader(final ReadIndexRequest request,\n                        final ReadIndexResponse.Builder respBuilder,\n                        final RpcResponseClosure<ReadIndexResponse> closure) {\n    // 获取仲裁值，即集群节点的半数加 1\n    final int quorum = getQuorum();\n\n    // 当前集群只有一个节点，直接返回 lastCommittedIndex 值\n    if (quorum <= 1) {\n        // Only one peer, fast path.\n        respBuilder.setSuccess(true) //\n                .setIndex(this.ballotBox.getLastCommittedIndex());\n        closure.setResponse(respBuilder.build());\n        closure.run(Status.OK());\n        return;\n    }\n\n    // 获取本地记录的 lastCommittedIndex 值\n    final long lastCommittedIndex = this.ballotBox.getLastCommittedIndex();\n    // 校验 term 值是否发生变化，以保证对应的 lastCommittedIndex 值是有效的\n    if (this.logManager.getTerm(lastCommittedIndex) != this.currTerm) {\n        // Reject read only request when this leader has not committed any log entry at its term\n        closure.run(new Status(\n                RaftError.EAGAIN,\n                \"ReadIndex request rejected because leader has not committed any log entry at its term, logIndex=%d, currTerm=%d.\",\n                lastCommittedIndex, this.currTerm));\n        return;\n    }\n    // 记录 lastCommittedIndex 到请求响应对象中\n    respBuilder.setIndex(lastCommittedIndex);\n\n    // 对于来自 Follower 节点或 Learner 节点的请求，peerId 字段会记录这些节点已知的 leaderId 值，所以不为 null\n    if (request.getPeerId() != null) {\n        // request from follower or learner, check if the follower/learner is in current conf.\n        final PeerId peer = new PeerId();\n        peer.parse(request.getServerId());\n        // 请求来源节点并不是当前 Leader 节点管理范围内的节点\n        if (!this.conf.contains(peer) && !this.conf.containsLearner(peer)) {\n            closure.run(new Status(RaftError.EPERM,\n                    \"Peer %s is not in current configuration: %s.\", peer, this.conf));\n            return;\n        }\n    }\n\n    // 基于参数决策是走 ReadIndexRead 还是 LeaseRead 策略，默认走 ReadIndexRead 策略，\n    // 如果是 LeaseRead，则基于时间戳检查集群中是否有过半数的节点仍然认可当前 Leader 节点，\n    ReadOnlyOption readOnlyOpt = this.raftOptions.getReadOnlyOptions();\n    if (readOnlyOpt == ReadOnlyOption.ReadOnlyLeaseBased && !isLeaderLeaseValid()) {\n        // If leader lease timeout, we must change option to ReadOnlySafe\n        readOnlyOpt = ReadOnlyOption.ReadOnlySafe;\n    }\n\n    switch (readOnlyOpt) {\n        // ReadIndexRead 策略\n        case ReadOnlySafe:\n            final List<PeerId> peers = this.conf.getConf().getPeers();\n            Requires.requireTrue(peers != null && !peers.isEmpty(), \"Empty peers\");\n            // 向所有的 Follower 节点发送心跳请求，以检查当前 Leader 节点是否仍然有效\n            final ReadIndexHeartbeatResponseClosure heartbeatDone =\n                    new ReadIndexHeartbeatResponseClosure(closure, respBuilder, quorum, peers.size());\n            // Send heartbeat requests to followers\n            for (final PeerId peer : peers) {\n                if (peer.equals(this.serverId)) {\n                    continue;\n                }\n                this.replicatorGroup.sendHeartbeat(peer, heartbeatDone);\n            }\n            break;\n        // LeaseRead 策略，能够走到这里，说明集群中有超过半数的节点仍然认可当前 Leader 节点\n        case ReadOnlyLeaseBased:\n            // Responses to followers and local node.\n            respBuilder.setSuccess(true);\n            closure.setResponse(respBuilder.build());\n            closure.run(Status.OK());\n            break;\n    }\n}\n```\n\nLeader 节点处理线性一致性读请求的整体执行流程可以概括为：\n\n1. 如果当前集群只有一个节点，则立即响应成功；\n2. 否则，校验当前节点本地 lastCommittedIndex 值是否有效，如果无效则响应异常；\n3. 否则，对于来自 Follower 或 Learner 节点的请求，需要校验请求来源节点是否是有效节点，即这些节点位于当前 Leader 节点的主权范围内，如果不是则响应异常；\n4. 否则，基于 ReadIndex Read 或 Lease Read 策略判断当前节点 LEADER 角色的有效性，如果有效则响应成功，否则响应失败。\n\n当一个节点刚刚竞选成为 LEADER 角色时，此时该节点本地的 lastCommittedIndex 值并不一定是当前整个系统最新的 lastCommittedIndex 值，所以上述步骤二需要校验本地 lastCommittedIndex 值的有效性，如果对应的 term 值不匹配则一定是无效的。此外，前面在分析主节点选举机制时曾介绍过当一个节点竞选成功后会将当前集群的节点配置信息作为任期内第一条 LogEntry 进行提交，这一操作能够保证 Leader 节点的 lastCommittedIndex 值是集群范围内最新的。\n\n在获取到最新的 lastCommittedIndex 位置之后，只要能够确定当前 Leader 节点是有效的即能返回该 lastCommittedIndex 值。Raft 算法提出了两种策略以验证当前 Leader 节点的有效性，即 ReadIndex Read 和 Lease Read。JRaft 算法库在实现上允许我们在节点启动时通过参数指定具体的策略，默认则采用 ReadIndex Read 策略。\n\n对于 ReadIndex Read 策略而言，Leader 节点会调用 `ReplicatorGroup#sendHeartbeat` 方法向集群中除自己以外的所有节点发送一次心跳请求，如果集群中过半数的节点能够成功响应该请求，则视为当前 Leader 节点仍然有效。关于心跳机制已在前面分析日志复制机制时介绍过，这里不再重复说明。\n\n对于 Lease Read 策略而言，Leader 节点会基于租约机制判断当前 LEADER 角色是否仍然有效，即判断最近一轮向所有 Follower 节点成功发送 RPC 请求的最早时间距离当前时间是否在租约范围内。判断的过程由 `NodeImpl#isLeaderLeaseValid` 方法实现：\n\n```java\nprivate boolean isLeaderLeaseValid() {\n    final long monotonicNowMs = Utils.monotonicMs();\n    // 检查距离最近校验当前 Leader 节点有效性的时间是否在租约范围内\n    if (checkLeaderLease(monotonicNowMs)) {\n        return true;\n    }\n    // 检查管理的所有 Follower 节点是否有超过半数仍然认为当前 Leader 节点有效\n    checkDeadNodes0(this.conf.getConf().getPeers(), monotonicNowMs, false, null);\n    return checkLeaderLease(monotonicNowMs);\n}\n\nprivate boolean checkLeaderLease(final long monotonicNowMs) {\n    // 最近一次向所有活跃 Follower 节点成功发送 RPC 请求的最早时间距离指定时间是否在有效租约范围内\n    return monotonicNowMs - this.lastLeaderTimestamp < this.options.getLeaderLeaseTimeoutMs();\n}\n```\n\n关于 `NodeImpl#checkDeadNodes0` 方法的实现已在前面介绍主节点选举机制时分析过，这里不再展开。\n\n最后来看一下针对线性一致性读响应 ReadIndexResponseClosure 的处理过程，实现如下：\n\n```java\npublic void run(final Status status) {\n    // 响应异常，说明 Leader 节点本地的 lastCommittedIndex 值无效，\n    // 或者当前请求节点不是一个有效节点，或者节点状态不能够响应当前请求\n    if (!status.isOk()) {\n        // 快速失败\n        notifyFail(status);\n        return;\n    }\n    final ReadIndexResponse readIndexResponse = getResponse();\n    // 响应失败，说明 Leader 节点的 LEADER 角色无效\n    if (!readIndexResponse.getSuccess()) {\n        notifyFail(new Status(-1, \"Fail to run ReadIndex task, maybe the leader stepped down.\"));\n        return;\n    }\n\n    // Success\n    final ReadIndexStatus readIndexStatus = new ReadIndexStatus(\n            this.states, this.request, readIndexResponse.getIndex());\n    // 为各个 ReadIndex 请求填充从 Leader 节点读取到的 lastCommittedIndex 值\n    for (final ReadIndexState state : this.states) {\n        // Records current commit log index.\n        state.setIndex(readIndexResponse.getIndex());\n    }\n\n    boolean doUnlock = true;\n    ReadOnlyServiceImpl.this.lock.lock();\n    try {\n        // 本地已经应用的 LogEntry 的 logIndex 已经超过 lastCommittedIndex 位置，\n        // 说明就 lastCommittedIndex 位置而言，此位置之前的数据已经能够保证与 Leader 节点同步\n        if (readIndexStatus.isApplied(ReadOnlyServiceImpl.this.fsmCaller.getLastAppliedIndex())) {\n            // Already applied, notify readIndex request.\n            ReadOnlyServiceImpl.this.lock.unlock();\n            doUnlock = false;\n            // 回调响应各个 ReadIndex 请求\n            notifySuccess(readIndexStatus);\n        }\n        // 本地已经应用的 LogEntry 的 logIndex 还未到达 lastCommittedIndex 位置，\n        // 缓存当前请求，等待对应的 LogEntry 在本地被应用时回调响应\n        else {\n            // Not applied, add it to pending-notify cache.\n            ReadOnlyServiceImpl.this.pendingNotifyStatus\n                    .computeIfAbsent(readIndexStatus.getIndex(), k -> new ArrayList<>(10)) //\n                    .add(readIndexStatus);\n        }\n    } finally {\n        if (doUnlock) {\n            ReadOnlyServiceImpl.this.lock.unlock();\n        }\n    }\n}\n```\n\n如果目标 Leader 节点的 LEADER 角色仍然有效，则当前节点会等待本地被应用到状态机的 LogEntry 的 logIndex 位置不小于从该 Leader 节点获取到的 lastComittedIndex 值。这样可以保证就 lastComittedIndex 这个位置而言，本地与 Leader 的数据是同步的，否则就需要等待本地的数据与 Leader 节点的数据进行同步。ReadOnlyServiceImpl 实现了 LastAppliedLogIndexListener 接口，所以当完成应用一批日志数据到状态机中时，相应的 `ReadOnlyServiceImpl#onApplied` 方法也会被回调，从而尝试触发执行那些等待数据同步的回调。\n\n### 总结\n\n本文对线性一致性读的定义进行了介绍，并对 Raft 算法提供线性一致性读语义的 3 种策略进行了说明，同时比对了这些策略的优缺点，最后从 JRaft 的源码层面分析了如何实现线性一致性读。JRaft 支持 ReadIndex Read 和 Lease Read 两种线性一致性读策略，并且默认采用 ReadIndex Read 策略。前面我们曾分析了这两种策略各自的优缺点，业务可以结合自己的应用场景进行决策。不过需要注意的一点是，无论采用哪种策略，线性一致性读都需要与 Leader 节点进行交互，当 QPS 较高时需要考量 Leader 节点的负载能力。\n\n### 参考\n\n1. [Raft Consensus Algorithm](https://raft.github.io/)\n2. [SOFA-JRaft 官网](https://www.sofastack.tech/projects/sofa-jraft/overview/)\n3. [SOFA-JRaft：线性一致读实现剖析](https://www.sofastack.tech/blog/sofa-jraft-linear-consistent-read-implementation/)\n4. [TiKV 功能介绍 - Lease Read](https://pingcap.com/blog-cn/lease-read/)\n","tags":["Raft","SOFA-JRaft"],"categories":["sofa"]},{"title":"SOFA-JRaft 源码解析：快照机制","url":"/2020/06/22/sofa/sofa-jraft-snapshot/","content":"\n上一篇我们介绍了 JRaft 关于日志复制机制的设计与实现，其中提到了快照机制本质上也是一种对日志数据复制的优化手段，本文我们就对 JRaft 关于快照机制的设计与实现展开分析。在开始之前我们先聊聊为什么需要引入快照机制，思考以下两个问题：\n\n1. 因为日志数据需要落盘存储，当日志数据量大到磁盘空间无法容纳时，除了扩容是否还有其它的优化手段？\n2. 当一个新的节点加入 Raft 集群时需要重放集群之前接收到的所有指令以追赶上集群的数据状态，这一过程往往比较耗时和消费带宽，如何进行优化？\n\n对于一个生产级别的 Raft 算法库而言必须能够解决好上述问题，而 Raft 算法也为解决上述问题提供了思路，即快照机制。该机制通过定期为本地的数据状态生成对应的快照文件，并删除对应的日志文件，从而降低对于磁盘空间的容量消耗。当一个新的节点加入集群时，不同于从 Leader 节点复制集群在此之前的所有日志文件，基于快照机制该节点只需要从 Leader 节点下载安装最新的快照文件即可。由于快照文件是对某一时刻数据状态的备份，相对于原生日志数据而言在容量上要小很多，所以既降低了本地磁盘空间占用，也降低了新加入节点从 Leader 节点同步历史数据的时间和网络开销，很好的解决了上面抛出的两个问题。<!-- more -->\n\n本文将对快照文件的生成和安装过程展开分析。在 Raft 集群中由于各个节点都需要在本地对日志文件进行存储，所以都有生成快照文件的诉求，而安装快照文件则面向于新加入集群的节点，这些节点需要通过从 Leader 节点下载安装快照文件以快速追赶上集群的数据状态。\n\n### 生成快照\n\n快照机制对于 JRaft 算法库而言是一个可选的功能，如果在启动 JRaft 节点时指定了快照路径 snapshotUri，则表明业务希望启用快照机制。JRaft 节点会在初始化期间（即执行 `Node#init` 方法）启动快照计时器 snapshotTimer，用于周期性生成快照（默认周期为 1 小时）。该计时器的具体执行逻辑由 `NodeImpl#handleSnapshotTimeout` 方法实现，该方法会判断当前节点是否处于活跃状态，如果是则会异步调用 `NodeImpl#doSnapshot` 方法执行生成快照的操作，实现如下：\n\n```java\nprivate void doSnapshot(final Closure done) {\n    if (this.snapshotExecutor != null) {\n        // 调用 SnapshotExecutor 生成快照\n        this.snapshotExecutor.doSnapshot(done);\n    } else {\n        if (done != null) {\n            final Status status = new Status(RaftError.EINVAL, \"Snapshot is not supported\");\n            Utils.runClosureInThread(done, status);\n        }\n    }\n}\n```\n\n该方法除了被快照计时器定时触发执行外，还可以被 Cli 服务手动触发执行。由上述实现可以看到，该方法只是简单的将请求委托给快照执行器 SnapshotExecutor 执行，方法 `SnapshotExecutorImpl#doSnapshot` 实现如下：\n\n```java\npublic void doSnapshot(final Closure done) {\n    boolean doUnlock = true;\n    this.lock.lock();\n    try {\n        // SnapshotExecutor 已被停止\n        if (this.stopped) {\n            Utils.runClosureInThread(done, new Status(RaftError.EPERM, \"Is stopped.\"));\n            return;\n        }\n\n        // 正在安装快照\n        if (this.downloadingSnapshot.get() != null) {\n            Utils.runClosureInThread(done, new Status(RaftError.EBUSY, \"Is loading another snapshot.\"));\n            return;\n        }\n\n        // 正在生成快照，不允许重复执行\n        if (this.savingSnapshot) {\n            Utils.runClosureInThread(done, new Status(RaftError.EBUSY, \"Is saving another snapshot.\"));\n            return;\n        }\n\n        // 状态机调度器最后应用的 LogEntry 已经被快照，说明没有新的数据可以被快照\n        if (this.fsmCaller.getLastAppliedIndex() == this.lastSnapshotIndex) {\n            // There might be false positive as the getLastAppliedIndex() is being updated.\n            // But it's fine since we will do next snapshot saving in a predictable time.\n            doUnlock = false;\n            this.lock.unlock();\n            this.logManager.clearBufferedLogs();\n            Utils.runClosureInThread(done);\n            return;\n        }\n\n        // 可以被快照的数据量小于阈值，暂不生成快照\n        final long distance = this.fsmCaller.getLastAppliedIndex() - this.lastSnapshotIndex;\n        if (distance < this.node.getOptions().getSnapshotLogIndexMargin()) {\n            // If state machine's lastAppliedIndex value minus lastSnapshotIndex value is\n            // less than snapshotLogIndexMargin value, then directly return.\n            if (this.node != null) {\n                LOG.debug(\"Node {} snapshotLogIndexMargin={}, distance={}, so ignore this time of snapshot by snapshotLogIndexMargin setting.\",\n                        this.node.getNodeId(), distance, this.node.getOptions().getSnapshotLogIndexMargin());\n            }\n            doUnlock = false;\n            this.lock.unlock();\n            Utils.runClosureInThread(done);\n            return;\n        }\n\n        // 创建并初始化快照写入器，默认使用 LocalSnapshotWriter 实现类\n        final SnapshotWriter writer = this.snapshotStorage.create();\n        if (writer == null) {\n            Utils.runClosureInThread(done, new Status(RaftError.EIO, \"Fail to create writer.\"));\n            reportError(RaftError.EIO.getNumber(), \"Fail to create snapshot writer.\");\n            return;\n        }\n\n        // 标记当前正在安装快照\n        this.savingSnapshot = true;\n        // 创建一个回调，用于感知异步快照生成状态\n        final SaveSnapshotDone saveSnapshotDone = new SaveSnapshotDone(writer, done, null);\n        if (!this.fsmCaller.onSnapshotSave(saveSnapshotDone)) {\n            // 往 Disruptor 队列投递事件失败\n            Utils.runClosureInThread(done, new Status(RaftError.EHOSTDOWN, \"The raft node is down.\"));\n            return;\n        }\n        this.runningJobs.incrementAndGet();\n    } finally {\n        if (doUnlock) {\n            this.lock.unlock();\n        }\n    }\n\n}\n```\n\n上述实现在开始生成快照之前会经过一系列的校验，如果校验通过则会创建并初始化快照写入器 SnapshotWriter 实例，并向状态机调度器发布一个 `SNAPSHOT_SAVE` 事件用于异步生成快照文件，同时会绑定一个 SaveSnapshotDone 回调以感知异步快照生成的状态。\n\n方法 `FSMCallerImpl#doSnapshotSave` 实现了对于该事件的处理逻辑，如下：\n\n```java\nprivate void doSnapshotSave(final SaveSnapshotClosure done) {\n    Requires.requireNonNull(done, \"SaveSnapshotClosure is null\");\n    final long lastAppliedIndex = this.lastAppliedIndex.get();\n    // 构造快照元数据信息，封装当前被状态机应用的 LogEntry 的 logIndex 和 term 值，以及对应的集群节点配置信息\n    final RaftOutter.SnapshotMeta.Builder metaBuilder = RaftOutter.SnapshotMeta.newBuilder() //\n            .setLastIncludedIndex(lastAppliedIndex) //\n            .setLastIncludedTerm(this.lastAppliedTerm);\n    final ConfigurationEntry confEntry = this.logManager.getConfiguration(lastAppliedIndex);\n    if (confEntry == null || confEntry.isEmpty()) {\n        LOG.error(\"Empty conf entry for lastAppliedIndex={}\", lastAppliedIndex);\n        Utils.runClosureInThread(done, new Status(RaftError.EINVAL,\n                \"Empty conf entry for lastAppliedIndex=%s\", lastAppliedIndex));\n        return;\n    }\n    for (final PeerId peer : confEntry.getConf()) {\n        metaBuilder.addPeers(peer.toString());\n    }\n    for (final PeerId peer : confEntry.getConf().getLearners()) {\n        metaBuilder.addLearners(peer.toString());\n    }\n    if (confEntry.getOldConf() != null) {\n        for (final PeerId peer : confEntry.getOldConf()) {\n            metaBuilder.addOldPeers(peer.toString());\n        }\n        for (final PeerId peer : confEntry.getOldConf().getLearners()) {\n            metaBuilder.addOldLearners(peer.toString());\n        }\n    }\n    // 记录快照元数据\n    final SnapshotWriter writer = done.start(metaBuilder.build());\n    if (writer == null) {\n        done.run(new Status(RaftError.EINVAL, \"snapshot_storage create SnapshotWriter failed\"));\n        return;\n    }\n    // 调用状态机 StateMachine#onSnapshotSave 方法生成快照\n    this.fsm.onSnapshotSave(writer, done);\n}\n```\n\n上述方法会以当前已被状态机应用的最新 LogEntry 的 logIndex 和 term 值，以及当前集群的节点配置信息，构造快照元数据信息，并记录到 SaveSnapshotDone 回调中，最后调用状态机 `StateMachine#onSnapshotSave` 方法由业务负责生成快照数据。\n\n这里我们以 CounterStateMachine 为例了解一下业务是如何生成快照文件的，实现如下：\n\n```java\npublic void onSnapshotSave(final SnapshotWriter writer, final Closure done) {\n    final long currVal = this.value.get();\n    // 异步将数据落盘\n    Utils.runInThread(() -> {\n        final CounterSnapshotFile snapshot = new CounterSnapshotFile(writer.getPath() + File.separator + \"data\");\n        if (snapshot.save(currVal)) {\n            // 记录快照文件名，及其元数据信息\n            if (writer.addFile(\"data\")) {\n                done.run(Status.OK());\n            } else {\n                done.run(new Status(RaftError.EIO, \"Fail to add file to writer\"));\n            }\n        } else {\n            done.run(new Status(RaftError.EIO, \"Fail to save counter snapshot %s\", snapshot.getPath()));\n        }\n    });\n}\n```\n\n生成快照由于涉及到文件 IO，所以相对而言是一个重量级的操作，JRaft 针对是否将相关逻辑实现为异步给到的建议为：\n\n> 通常情况下，每次 `onSnapshotSave` 被调用都应该阻塞状态机（同步调用）以保证用户可以捕获当前状态机的状态，如果想通过异步 snapshot 来提升性能，那么需要用户状态机支持快照读，并先同步读快照，再异步保存快照数据。\n\n如果生成快照成功，我们需要调用 `SnapshotWriter#addFile` 方法将快照文件名和对应的元数据信息记录到快照元数据信息表中。这么做的目的除了能够让 JRaft 识别该快照文件，业务也可以在后续安装快照文件时读取到快照的元数据信息。\n\n下面继续来看一下完成生成快照文件之后的逻辑，即回调 `SaveSnapshotDone#run` 方法，该方法以异步的方式将请求委托给 `SaveSnapshotDone#continueRun` 方法执行，实现如下：\n\n```java\nvoid continueRun(final Status st) {\n    // 更新已经被快照的 logIndex 和 term 状态值，更新 LogManager 状态\n    final int ret = onSnapshotSaveDone(st, this.meta, this.writer);\n    if (ret != 0 && st.isOk()) {\n        st.setError(ret, \"node call onSnapshotSaveDone failed\");\n    }\n    if (this.done != null) {\n        Utils.runClosureInThread(this.done, st);\n    }\n}\n\n// com.alipay.sofa.jraft.storage.snapshot.SnapshotExecutorImpl#onSnapshotSaveDone\nint onSnapshotSaveDone(final Status st, final SnapshotMeta meta, final SnapshotWriter writer) {\n    int ret;\n    this.lock.lock();\n    try {\n        ret = st.getCode();\n        // InstallSnapshot can break SaveSnapshot, check InstallSnapshot when SaveSnapshot\n        // because upstream Snapshot maybe newer than local Snapshot.\n        if (st.isOk()) {\n            // 已安装的快照相对于本次生成的快照数据要新\n            if (meta.getLastIncludedIndex() <= this.lastSnapshotIndex) {\n                ret = RaftError.ESTALE.getNumber();\n                if (this.node != null) {\n                    LOG.warn(\"Node {} discards an stale snapshot lastIncludedIndex={}, lastSnapshotIndex={}.\",\n                            this.node.getNodeId(), meta.getLastIncludedIndex(), this.lastSnapshotIndex);\n                }\n                writer.setError(RaftError.ESTALE, \"Installing snapshot is older than local snapshot\");\n            }\n        }\n    } finally {\n        this.lock.unlock();\n    }\n\n    // 生成快照成功\n    if (ret == 0) {\n        // 记录快照元数据信息\n        if (!writer.saveMeta(meta)) {\n            LOG.warn(\"Fail to save snapshot {}.\", writer.getPath());\n            ret = RaftError.EIO.getNumber();\n        }\n    }\n    // 生成快照失败\n    else {\n        if (writer.isOk()) {\n            writer.setError(ret, \"Fail to do snapshot.\");\n        }\n    }\n    // 关闭快照写入器\n    try {\n        writer.close();\n    } catch (final IOException e) {\n        LOG.error(\"Fail to close writer\", e);\n        ret = RaftError.EIO.getNumber();\n    }\n    boolean doUnlock = true;\n    this.lock.lock();\n    try {\n        // 生成快照成功\n        if (ret == 0) {\n            // 更新最新快照对应的 logIndex 和 term 值\n            this.lastSnapshotIndex = meta.getLastIncludedIndex();\n            this.lastSnapshotTerm = meta.getLastIncludedTerm();\n            doUnlock = false;\n            this.lock.unlock();\n            // 更新 LogManager 状态，并将本地已快照的日志剔除\n            this.logManager.setSnapshot(meta); // should be out of lock\n            doUnlock = true;\n            this.lock.lock();\n        }\n        if (ret == RaftError.EIO.getNumber()) {\n            reportError(RaftError.EIO.getNumber(), \"Fail to save snapshot.\");\n        }\n        // 清除正在生成快照的标记\n        this.savingSnapshot = false;\n        this.runningJobs.countDown();\n        return ret;\n\n    } finally {\n        if (doUnlock) {\n            this.lock.unlock();\n        }\n    }\n}\n```\n\n快照数据除了可以由本地生成，也可以是从 Leader 节点复制而来，如果从远端复制过来的快照数据相对于本地更新，则应该忽略本地生成快照文件的结果。SnapshotExecutor 定义了 `SnapshotExecutorImpl#lastSnapshotIndex` 和 `SnapshotExecutorImpl#lastSnapshotTerm` 两个字段用于记录最近一次快照对应的 logIndex 和 term 值，所以当生成快照成功之后需要更新这两个状态值。此外，既然相应的数据已经被快照，则表示对应的原生日志文件可以从本地存储系统中删除，从而节省存储空间。这一过程由 `LogManager#setSnapshot` 方法实现，该方法会对本地的日志数据执行截断处理。\n\n### 安装快照\n\n通过上一篇对于日志复制机制的介绍可知，Leader 节点会给每个 Follower 或 Learner 节点创建一个复制器 Replicator 实例。实际上，Replicator 除了肩负向目标 Follower 或 Learner 节点复制日志数据外，还负责给目标节点安装快照文件。Replicator 定义了 `Replicator#installSnapshot` 方法，前面在分析日志复制实现时我们曾几次遇到过对于该方法的调用，对应的调用原因可以简单概括为：\n\n> Replicator 期望给目标 Follower 节点复制日志数据时发现对应 logIndex 的数据已经变为快照文件，所以需要先给目标 Follower 节点安装快照。\n\n方法 `Replicator#installSnapshot` 的实现如下：\n\n```java\nvoid installSnapshot() {\n    // 正在给目标 Follower 节点安装快照，无需重复执行\n    if (this.state == State.Snapshot) {\n        LOG.warn(\"Replicator {} is installing snapshot, ignore the new request.\", this.options.getPeerId());\n        this.id.unlock();\n        return;\n    }\n    boolean doUnlock = true;\n    try {\n        Requires.requireTrue(this.reader == null,\n                \"Replicator %s already has a snapshot reader, current state is %s\", this.options.getPeerId(), this.state);\n        // 创建并初始化快照读取器，具体实现为 LocalSnapshotReader 类\n        this.reader = this.options.getSnapshotStorage().open();\n        if (this.reader == null) {\n            final NodeImpl node = this.options.getNode();\n            final RaftException error = new RaftException(EnumOutter.ErrorType.ERROR_TYPE_SNAPSHOT);\n            error.setStatus(new Status(RaftError.EIO, \"Fail to open snapshot\"));\n            this.id.unlock();\n            doUnlock = false;\n            node.onError(error);\n            return;\n        }\n        // 生一个快照访问地址\n        final String uri = this.reader.generateURIForCopy();\n        if (uri == null) {\n            final NodeImpl node = this.options.getNode();\n            final RaftException error = new RaftException(EnumOutter.ErrorType.ERROR_TYPE_SNAPSHOT);\n            error.setStatus(new Status(RaftError.EIO, \"Fail to generate uri for snapshot reader\"));\n            releaseReader();\n            this.id.unlock();\n            doUnlock = false;\n            node.onError(error);\n            return;\n        }\n        // 加载快照元数据信息\n        final RaftOutter.SnapshotMeta meta = this.reader.load();\n        if (meta == null) {\n            final String snapshotPath = this.reader.getPath();\n            final NodeImpl node = this.options.getNode();\n            final RaftException error = new RaftException(EnumOutter.ErrorType.ERROR_TYPE_SNAPSHOT);\n            error.setStatus(new Status(RaftError.EIO, \"Fail to load meta from %s\", snapshotPath));\n            releaseReader();\n            this.id.unlock();\n            doUnlock = false;\n            node.onError(error);\n            return;\n        }\n        // 构造安装快照请求\n        final InstallSnapshotRequest.Builder rb = InstallSnapshotRequest.newBuilder();\n        rb.setTerm(this.options.getTerm());\n        rb.setGroupId(this.options.getGroupId());\n        rb.setServerId(this.options.getServerId().toString());\n        rb.setPeerId(this.options.getPeerId().toString());\n        rb.setMeta(meta);\n        rb.setUri(uri);\n\n        this.statInfo.runningState = RunningState.INSTALLING_SNAPSHOT;\n        this.statInfo.lastLogIncluded = meta.getLastIncludedIndex();\n        this.statInfo.lastTermIncluded = meta.getLastIncludedTerm();\n\n        final InstallSnapshotRequest request = rb.build();\n        // 标记当前运行状态为正在给目标节点安装快照\n        this.state = State.Snapshot;\n        // noinspection NonAtomicOperationOnVolatileField\n        this.installSnapshotCounter++;\n        final long monotonicSendTimeMs = Utils.monotonicMs();\n        final int stateVersion = this.version;\n        // 递增请求序列\n        final int seq = getAndIncrementReqSeq();\n        // 向目标节点发送安装快照请求\n        final Future<Message> rpcFuture = this.rpcService.installSnapshot(\n                this.options.getPeerId().getEndpoint(),\n                request,\n                new RpcResponseClosureAdapter<InstallSnapshotResponse>() {\n\n                    @Override\n                    public void run(final Status status) {\n                        onRpcReturned(Replicator.this.id, RequestType.Snapshot, status, request, getResponse(), seq, stateVersion, monotonicSendTimeMs);\n                    }\n                });\n        // 标记当前请求为 in-flight\n        addInflight(RequestType.Snapshot, this.nextIndex, 0, 0, seq, rpcFuture);\n    } finally {\n        if (doUnlock) {\n            this.id.unlock();\n        }\n    }\n}\n```\n\n上述方法的整体执行流程可以概括为：\n\n1. 如果当前正在给目标 Follower 或 Learner 节点安装快照文件，则直接返回；\n2. 否则，构造安装快照 InstallSnapshot RPC 请求对象，除了填充基本的状态数据外，其中还包含快照的远程访问地址，以及快照的元数据信息；\n3. 向目标节点发送安装快照的请求。\n\n关于 Replicator 请求的 pipeline 机制已在上一篇介绍过，这里不再重复介绍。下面来看一下 Follower 节点对于 InstallSnapshot 请求的处理过程，由 `NodeImpl#handleInstallSnapshot` 方法实现。该方法首先会完成一些基本的状态校验（具体实现与处理 AppendEntries 请求基本相同，不再展开），如果校验通过则调用 `SnapshotExecutor#installSnapshot` 方法执行安装快照文件逻辑，如下：\n\n```java\npublic void installSnapshot(final InstallSnapshotRequest request,\n                            final InstallSnapshotResponse.Builder response,\n                            final RpcRequestClosure done) {\n    // 从请求中获取快照元数据信息\n    final SnapshotMeta meta = request.getMeta();\n    // 新建一个下载快照的任务\n    final DownloadingSnapshot ds = new DownloadingSnapshot(request, response, done);\n    // DON'T access request, response, and done after this point\n    // as the retry snapshot will replace this one.\n    // 尝试注册当前任务，可能存在有其它任务正在运行的情况\n    if (!registerDownloadingSnapshot(ds)) {\n        LOG.warn(\"Fail to register downloading snapshot.\");\n        // This RPC will be responded by the previous session\n        return;\n    }\n    Requires.requireNonNull(this.curCopier, \"curCopier\");\n    try {\n        // 等待从 Leader 复制快照数据完成\n        this.curCopier.join();\n    } catch (final InterruptedException e) {\n        Thread.currentThread().interrupt();\n        LOG.warn(\"Install snapshot copy job was canceled.\");\n        return;\n    }\n\n    // 加载刚刚从 Leader 复制过来的快照数据\n    loadDownloadingSnapshot(ds, meta);\n}\n```\n\n安装快照文件的执行过程整体可以分为三个步骤：\n\n1. 尝试注册一个下载快照数据的 DownloadingSnapshot 任务；\n2. 从 Leader 节点下载快照文件到本地，并阻塞等待文件下载完成；\n3. 从本地加载下载回来的快照文件。\n\n下面首先来看 __步骤 1__ ，注册一个新的下载快照文件任务时需要考虑可能会与一个正在执行的下载任务相互冲突，具体实现如下：\n\n```java\nboolean registerDownloadingSnapshot(final DownloadingSnapshot ds) {\n    DownloadingSnapshot saved = null;\n    boolean result = true;\n\n    this.lock.lock();\n    try {\n        // SnapshotExecutor 已被停止\n        if (this.stopped) {\n            LOG.warn(\"Register DownloadingSnapshot failed: node is stopped.\");\n            ds.done.sendResponse(RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(InstallSnapshotResponse.getDefaultInstance(), RaftError.EHOSTDOWN, \"Node is stopped.\"));\n            return false;\n        }\n        // 正在生成快照\n        if (this.savingSnapshot) {\n            LOG.warn(\"Register DownloadingSnapshot failed: is saving snapshot.\");\n            ds.done.sendResponse(RpcFactoryHelper //\n                    .responseFactory().newResponse(InstallSnapshotResponse.getDefaultInstance(), RaftError.EBUSY, \"Node is saving snapshot.\"));\n            return false;\n        }\n\n        ds.responseBuilder.setTerm(this.term);\n        // 安装快照请求中的 term 值与当前节点的 term 值不匹配\n        if (ds.request.getTerm() != this.term) {\n            LOG.warn(\"Register DownloadingSnapshot failed: term mismatch, expect {} but {}.\", this.term, ds.request.getTerm());\n            ds.responseBuilder.setSuccess(false);\n            ds.done.sendResponse(ds.responseBuilder.build());\n            return false;\n        }\n        // 需要安装的快照数据已经被快照\n        if (ds.request.getMeta().getLastIncludedIndex() <= this.lastSnapshotIndex) {\n            LOG.warn(\n                    \"Register DownloadingSnapshot failed: snapshot is not newer, request lastIncludedIndex={}, lastSnapshotIndex={}.\",\n                    ds.request.getMeta().getLastIncludedIndex(), this.lastSnapshotIndex);\n            ds.responseBuilder.setSuccess(true);\n            ds.done.sendResponse(ds.responseBuilder.build());\n            return false;\n        }\n        final DownloadingSnapshot m = this.downloadingSnapshot.get();\n        // null 表示当前没有正在进行中的安装快照操作\n        if (m == null) {\n            this.downloadingSnapshot.set(ds);\n            Requires.requireTrue(this.curCopier == null, \"Current copier is not null\");\n            // 从指定的 URI 下载快照数据\n            this.curCopier = this.snapshotStorage.startToCopyFrom(ds.request.getUri(), newCopierOpts());\n            if (this.curCopier == null) {\n                this.downloadingSnapshot.set(null);\n                LOG.warn(\"Register DownloadingSnapshot failed: fail to copy file from {}.\", ds.request.getUri());\n                ds.done.sendResponse(RpcFactoryHelper //\n                        .responseFactory() //\n                        .newResponse(InstallSnapshotResponse.getDefaultInstance(),\n                                RaftError.EINVAL, \"Fail to copy from: %s\", ds.request.getUri()));\n                return false;\n            }\n            this.runningJobs.incrementAndGet();\n            return true;\n        }\n\n        // A previous snapshot is under installing, check if this is the same snapshot and resume it,\n        // otherwise drop previous snapshot as this one is newer\n\n        // m 为正在安装快照的任务，ds 为当前任务\n\n        // 当前新注册的任务与正在执行的任务安装的是同一份快照数据\n        if (m.request.getMeta().getLastIncludedIndex() == ds.request.getMeta().getLastIncludedIndex()) {\n            // m is a retry\n            // Copy |*ds| to |*m| so that the former session would respond this RPC.\n            saved = m;\n            this.downloadingSnapshot.set(ds);\n            result = false;\n        }\n        // 正在执行的安装快照任务操作的数据更新，忽略当前任务\n        else if (m.request.getMeta().getLastIncludedIndex() > ds.request.getMeta().getLastIncludedIndex()) {\n            // |is| is older\n            LOG.warn(\"Register DownloadingSnapshot failed: is installing a newer one, lastIncludeIndex={}.\",\n                    m.request.getMeta().getLastIncludedIndex());\n            ds.done.sendResponse(RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(InstallSnapshotResponse.getDefaultInstance(), RaftError.EINVAL,\n                            \"A newer snapshot is under installing\"));\n            return false;\n        }\n        // 当前安装快照任务操作的数据相对于正在执行的任务更新\n        else {\n            // 正在执行的任务已经进入了 loading 阶段\n            if (this.loadingSnapshot) {\n                LOG.warn(\"Register DownloadingSnapshot failed: is loading an older snapshot, lastIncludeIndex={}.\",\n                        m.request.getMeta().getLastIncludedIndex());\n                ds.done.sendResponse(RpcFactoryHelper //\n                        .responseFactory() //\n                        .newResponse(InstallSnapshotResponse.getDefaultInstance(),\n                                RaftError.EBUSY, \"A former snapshot is under loading\"));\n                return false;\n            }\n            Requires.requireNonNull(this.curCopier, \"curCopier\");\n            // 停止当前正在执行的任务\n            this.curCopier.cancel();\n            LOG.warn(\n                    \"Register DownloadingSnapshot failed: an older snapshot is under installing, cancel downloading, lastIncludeIndex={}.\",\n                    m.request.getMeta().getLastIncludedIndex());\n            ds.done.sendResponse(RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(InstallSnapshotResponse.getDefaultInstance(),\n                            RaftError.EBUSY, \"A former snapshot is under installing, trying to cancel\"));\n            return false;\n        }\n    } finally {\n        this.lock.unlock();\n    }\n    if (saved != null) {\n        // Respond replaced session\n        LOG.warn(\"Register DownloadingSnapshot failed: interrupted by retry installling request.\");\n        saved.done.sendResponse(RpcFactoryHelper //\n                .responseFactory() //\n                .newResponse(InstallSnapshotResponse.getDefaultInstance(),\n                        RaftError.EINTR, \"Interrupted by the retry InstallSnapshotRequest\"));\n    }\n    return result;\n}\n```\n\n注册新的快照文件下载任务的整体执行流程可以概括为：\n\n1. 如果当前 SnapshotExecutor 已被停止，则放弃注册新的任务；\n2. 否则，如果当前正在生成快照文件，则放弃注册新的任务；\n3. 否则，校验安装快照请求中指定的 term 值是否与当前节点的 term 值相匹配，如果不匹配则说明请求来源节点已经不再是 LEADER 角色，放弃为本次安装快照请求注册新的任务；\n4. 否则，校验本次需要安装的快照数据是否已在本地被快照，如果是则放弃注册新的任务；\n5. 否则，尝试为本次安装快照请求注册新的下载快照文件任务，并开始下载快照文件。\n\n其中最后一步可能会遇到当前已有一个正在安装快照的任务在执行的情况，需要决策是让该任务继续执行，还是中断该任务并注册新的任务，具体决策过程如下：\n\n1. 如果当前待注册的任务与正在执行的任务安装的是同一份快照数据，则让正在执行的任务先响应，并标记待注册的任务为正在执行；\n2. 否则，如果正在执行的任务安装的快照文件相对于待注册的任务更新，则放弃注册；\n3. 否则，说明待注册的任务需要安装的快照文件更新，如果正在执行的任务已经进入了第三阶段（即已经从远程下载快照文件完成，并开始加载这些快照数据），则放弃注册，否则需要取消正在执行的任务。\n\n一旦完成了下载快照文件任务的注册过程，则进入 __步骤 2__ ，开始从 Leader 节点下载快照文件，并阻塞等待下载过程的完成，这一步由 `SnapshotStorage#startToCopyFrom` 方法实现：\n\n```java\npublic SnapshotCopier startToCopyFrom(final String uri, final SnapshotCopierOptions opts) {\n    // 新建快照数据拷贝器，用于从 Leader 节点往本地拷贝快照数据\n    final LocalSnapshotCopier copier = new LocalSnapshotCopier();\n    copier.setStorage(this);\n    copier.setSnapshotThrottle(this.snapshotThrottle);\n    copier.setFilterBeforeCopyRemote(this.filterBeforeCopyRemote);\n    // 初始化\n    if (!copier.init(uri, opts)) {\n        LOG.error(\"Fail to init copier to {}.\", uri);\n        return null;\n    }\n    // 开始异步拷贝数据\n    copier.start();\n    return copier;\n}\n```\n\n下载快照文件的操作由拷贝器 LocalSnapshotCopier 完成，本质上是一个 RPC 交互的过程，这里不再展开。\n\n完成了将快照文件从 Leader 节点下载到本地之后， __步骤 3__ 会尝试在本地加载并应用这些数据，这一步由 `SnapshotExecutorImpl#loadDownloadingSnapshot` 方法实现：\n\n```java\nvoid loadDownloadingSnapshot(final DownloadingSnapshot ds, final SnapshotMeta meta) {\n    SnapshotReader reader;\n    this.lock.lock();\n    try {\n        // 当前任务已经失效，说明有新的任务被注册\n        if (ds != this.downloadingSnapshot.get()) {\n            // It is interrupted and response by other request, just return\n            return;\n        }\n        Requires.requireNonNull(this.curCopier, \"curCopier\");\n        reader = this.curCopier.getReader();\n        // 从 leader 节点复制快照数据异常\n        if (!this.curCopier.isOk()) {\n            if (this.curCopier.getCode() == RaftError.EIO.getNumber()) {\n                reportError(this.curCopier.getCode(), this.curCopier.getErrorMsg());\n            }\n            Utils.closeQuietly(reader);\n            ds.done.run(this.curCopier);\n            Utils.closeQuietly(this.curCopier);\n            this.curCopier = null;\n            this.downloadingSnapshot.set(null);\n            this.runningJobs.countDown();\n            return;\n        }\n        Utils.closeQuietly(this.curCopier);\n        this.curCopier = null;\n        // 快照读取器状态异常\n        if (reader == null || !reader.isOk()) {\n            Utils.closeQuietly(reader);\n            this.downloadingSnapshot.set(null);\n            ds.done.sendResponse(RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(InstallSnapshotResponse.getDefaultInstance(),\n                            RaftError.EINTERNAL, \"Fail to copy snapshot from %s\", ds.request.getUri()));\n            this.runningJobs.countDown();\n            return;\n        }\n\n        // 标记正在加载快照数据\n        this.loadingSnapshot = true;\n        this.loadingSnapshotMeta = meta;\n    } finally {\n        this.lock.unlock();\n    }\n\n    // 创建一个回调，用于感知异步快照加载状态\n    final InstallSnapshotDone installSnapshotDone = new InstallSnapshotDone(reader);\n    if (!this.fsmCaller.onSnapshotLoad(installSnapshotDone)) {\n        // 往 Disruptor 队列投递事件失败\n        LOG.warn(\"Fail to call fsm onSnapshotLoad.\");\n        installSnapshotDone.run(new Status(RaftError.EHOSTDOWN, \"This raft node is down\"));\n    }\n}\n```\n\n前面在分析快照文件的生成过程时已知具体生成快照数据的过程由业务负责完成，而此处加载快照数据的过程同样也需要业务实现，因为这些快照数据都是执行业务指令所生成的特定时刻的数据状态备份。JRaft 同样会向状态机调度器 FSMCaller 发布一个 `SNAPSHOT_LOAD` 类型的事件，并由 `FSMCallerImpl#doSnapshotLoad` 方法负责处理此类事件：\n\n```java\nprivate void doSnapshotLoad(final LoadSnapshotClosure done) {\n    Requires.requireNonNull(done, \"LoadSnapshotClosure is null\");\n    // 获取快照数据读取器\n    final SnapshotReader reader = done.start();\n    if (reader == null) {\n        done.run(new Status(RaftError.EINVAL, \"open SnapshotReader failed\"));\n        return;\n    }\n    // 获取快照元数据信息\n    final RaftOutter.SnapshotMeta meta = reader.load();\n    if (meta == null) {\n        done.run(new Status(RaftError.EINVAL, \"SnapshotReader load meta failed\"));\n        if (reader.getRaftError() == RaftError.EIO) {\n            final RaftException err = new RaftException(EnumOutter.ErrorType.ERROR_TYPE_SNAPSHOT,\n                    RaftError.EIO, \"Fail to load snapshot meta\");\n            setError(err);\n        }\n        return;\n    }\n    final LogId lastAppliedId = new LogId(this.lastAppliedIndex.get(), this.lastAppliedTerm);\n    final LogId snapshotId = new LogId(meta.getLastIncludedIndex(), meta.getLastIncludedTerm());\n    // 本地已经应用的日志 logIndex 和 term 值相对于当前正在安装的快照更新，说明待加载的快照数据已经过期\n    if (lastAppliedId.compareTo(snapshotId) > 0) {\n        done.run(new Status(\n                RaftError.ESTALE,\n                \"Loading a stale snapshot last_applied_index=%d last_applied_term=%d snapshot_index=%d snapshot_term=%d\",\n                lastAppliedId.getIndex(), lastAppliedId.getTerm(), snapshotId.getIndex(), snapshotId.getTerm()));\n        return;\n    }\n    // 调用状态机 StateMachine#onSnapshotLoad 方法加载快照\n    if (!this.fsm.onSnapshotLoad(reader)) {\n        done.run(new Status(-1, \"StateMachine onSnapshotLoad failed\"));\n        final RaftException e = new RaftException(EnumOutter.ErrorType.ERROR_TYPE_STATE_MACHINE,\n                RaftError.ESTATEMACHINE, \"StateMachine onSnapshotLoad failed\");\n        setError(e);\n        return;\n    }\n    if (meta.getOldPeersCount() == 0) {\n        // Joint stage is not supposed to be noticeable by end users.\n        final Configuration conf = new Configuration();\n        for (int i = 0, size = meta.getPeersCount(); i < size; i++) {\n            final PeerId peer = new PeerId();\n            Requires.requireTrue(peer.parse(meta.getPeers(i)), \"Parse peer failed\");\n            conf.addPeer(peer);\n        }\n        this.fsm.onConfigurationCommitted(conf);\n    }\n    // 更新状态数据\n    this.lastAppliedIndex.set(meta.getLastIncludedIndex());\n    this.lastAppliedTerm = meta.getLastIncludedTerm();\n    done.run(Status.OK());\n}\n```\n\nFSMCaller 通过调用状态机 `StateMachine#onSnapshotLoad` 方法将快照数据透传给业务，并由业务决定如何在本地恢复快照所蕴含的状态数据。下面同样以 CounterStateMachine 状态机实现为例来了解下业务加载快照数据的实现：\n\n```java\npublic boolean onSnapshotLoad(final SnapshotReader reader) {\n    // Leader 节点不应该执行安装快照的操作\n    if (isLeader()) {\n        LOG.warn(\"Leader is not supposed to load snapshot\");\n        return false;\n    }\n    // 获取快照文件对应的元数据信息\n    if (reader.getFileMeta(\"data\") == null) {\n        LOG.error(\"Fail to find data file in {}\", reader.getPath());\n        return false;\n    }\n    final CounterSnapshotFile snapshot = new CounterSnapshotFile(reader.getPath() + File.separator + \"data\");\n    try {\n        // 加载快照数据，并更新数据值\n        this.value.set(snapshot.load());\n        return true;\n    } catch (final IOException e) {\n        LOG.error(\"Fail to load snapshot from {}\", snapshot.getPath());\n        return false;\n    }\n}\n```\n\nSnapshotExecutor 在向 FSMCaller 发布 `SNAPSHOT_LOAD` 事件时会设置一个 InstallSnapshotDone 回调，用于感知加载快照数据的状态，如果操作正常则该回调会更新 SnapshotExecutor 本地的状态数据，包括最新被快照的 LogEntry 对应的 logIndex 和 term 值等。此外，还会调用 `LogManager#setSnapshot` 方法对本地已被快照的日志文件执行截断处理，以节省存储空间。\n\n最后来看一下复制器 Replicator 对于安装快照请求 InstallSnapshot 的响应处理过程，由 `Replicator#onInstallSnapshotReturned` 方法实现：\n\n```java\nstatic boolean onInstallSnapshotReturned(final ThreadId id,\n                                         final Replicator r,\n                                         final Status status,\n                                         final InstallSnapshotRequest request,\n                                         final InstallSnapshotResponse response) {\n    boolean success = true;\n    // 关闭快照数据读取器\n    r.releaseReader();\n    // noinspection ConstantConditions\n    do {\n        final StringBuilder sb = new StringBuilder(\"Node \"). //\n                append(r.options.getGroupId()).append(\":\").append(r.options.getServerId()). //\n                append(\" received InstallSnapshotResponse from \").append(r.options.getPeerId()). //\n                append(\" lastIncludedIndex=\").append(request.getMeta().getLastIncludedIndex()). //\n                append(\" lastIncludedTerm=\").append(request.getMeta().getLastIncludedTerm());\n        // 目标 Follower 节点运行异常\n        if (!status.isOk()) {\n            sb.append(\" error:\").append(status);\n            LOG.info(sb.toString());\n            notifyReplicatorStatusListener(r, ReplicatorEvent.ERROR, status);\n            if (++r.consecutiveErrorTimes % 10 == 0) {\n                LOG.warn(\"Fail to install snapshot at peer={}, error={}\", r.options.getPeerId(), status);\n            }\n            success = false;\n            break;\n        }\n        // 目标 Follower 节点拒绝本次安装快照的请求\n        if (!response.getSuccess()) {\n            sb.append(\" success=false\");\n            LOG.info(sb.toString());\n            success = false;\n            break;\n        }\n        // 目标 Follower 节点成功处理本次安装快照的请求，更新 nextIndex\n        r.nextIndex = request.getMeta().getLastIncludedIndex() + 1;\n        sb.append(\" success=true\");\n        LOG.info(sb.toString());\n    } while (false);\n    // We don't retry installing the snapshot explicitly.\n    // id is unlock in sendEntries\n    // 给目标节点安装快照失败，清空 inflight 请求，重新发送探针请求\n    if (!success) {\n        //should reset states\n        r.resetInflights();\n        r.state = State.Probe;\n        r.block(Utils.nowMs(), status.getCode());\n        return false;\n    }\n    r.hasSucceeded = true;\n    // 回调 CatchUpClosure\n    r.notifyOnCaughtUp(RaftError.SUCCESS.getNumber(), false);\n    if (r.timeoutNowIndex > 0 && r.timeoutNowIndex < r.nextIndex) {\n        r.sendTimeoutNow(false, false);\n    }\n    // id is unlock in _send_entriesheartbeatCounter\n    r.state = State.Replicate;\n    return true;\n}\n```\n\n如果给目标 Follower 或 Learner 节点安装快照成功，则对应的复制器 Replicator 会更新下一个待发送的 LogEntry 索引值 `Replicator#nextIndex` 字段，并切换运行状态为 `Replicate`，接下去转为向目标 Follower 或 Learner 节点复制日志数据。\n\n### 总结\n\n本文介绍了 Raft 算法引入快照机制所要解决的问题，并分析了 JRaft 对于生成和安装快照文件的设计与实现。快照机制虽然在 JRaft 算法库中被定义为一个可选的功能，但是对于线上业务而言还是尽量建议启动快照机制，对于降低本地磁盘空间占用和网络开销，缩短新节点上线的初始化时间都能够起到积极的作用。\n\n### 参考\n\n1. [Raft Consensus Algorithm](https://raft.github.io/)\n2. [SOFA-JRaft 官网](https://www.sofastack.tech/projects/sofa-jraft/overview/)\n3. [SOFA-JRaft：Snapshot 原理剖析](https://www.sofastack.tech/blog/sofa-jraft-snapshot-principle-analysis/)\n","tags":["Raft","SOFA-JRaft"],"categories":["sofa"]},{"title":"SOFA-JRaft 源码解析：日志复制机制","url":"/2020/06/15/sofa/sofa-jraft-log-replication/","content":"\n与上一篇介绍的主节点选举一样，日志复制（Log Replication）同样是 Raft 算法的核心组成部分，是支撑 Raft 节点达成共识的基础。Raft 中的日志主要可以分为两类：一类是协议自身运行所生成的日志，例如集群节点配置变更信息；另外一类就是用户向集群提交的指令所生成的日志。为了让集群中的各个节点达成共识，Leader 节点需要将日志数据复制给集群中的各个节点，并采用投票机制让这些节点决定是否许可日志对应的操作。对于被许可的操作日志，各个节点会严格按照相同的顺序在本地进行存储，并重放日志对应的操作，以此实现节点之间的共识。\n\nJRaft 在设计和实现层面为每个 Follower 和 Learner 节点都绑定了一个复制器 Replicator 实例，由 Replicator 负责向目标节点复制日志数据，Replicator 实例之间彼此相互隔离，互不影响，并由 ReplicatorGroup 进行统一管理。日志复制需要涉及到集群中节点之间的频繁通信和数据传输，所以需要保证复制操作的高性能，并且不允许出现乱序和断层。为此，JRaft 引入了多种优化策略，包括：Follower 节点之间并发复制、批量发送，以及 Pipeline 机制等。<!-- more -->\n\n日志复制从广义层面而言除了复制单条的 LogEntry 外，还包含向目标节点复制快照数据。本文我们重点关注对于 LogEntry 的复制，而对于快照数据的复制则留到下一篇介绍快照机制时再展开分析。\n\n### 日志生成\n\n在开始分析日志复制的运行机制之前，我打算先用一小节的篇幅介绍一下 JRaft 生成日志的过程。毕竟日志生成和复制是紧密关联的，了解 JRaft 如何生成一条日志有利于更好的理解后续复制日志的过程。前面曾介绍过，JRaft 中的日志主要可以分为两大类：一类是系统内部运行产生的日志；另外一类是用户主动往 JRaft 集群提交指令所产生的日志。本小节我们以后者为例，介绍 JRaft 日志从生成到写入本地存储系统的过程。\n\nJRaft 提供了 `Node#apply` 交互接口以让业务向 JRaft 集群提交操作指令，这些指令以 Task 的形式在集群中流转，并以日志的形式记录到 Leader 节点中，同时同步给集群中所有的 Follower 节点，并最终透传给所有成功完成日志复制的集群节点状态机。\n\n方法 `Node#apply` 的实现如下：\n\n```java\npublic void apply(final Task task) {\n    // 当前节点被关闭\n    if (this.shutdownLatch != null) {\n        Utils.runClosureInThread(task.getDone(), new Status(RaftError.ENODESHUTDOWN, \"Node is shutting down.\"));\n        throw new IllegalStateException(\"Node is shutting down\");\n    }\n    Requires.requireNonNull(task, \"Null task\");\n\n    // 创建一个 LogEntry 对象，用于封装 Task 中的数据\n    final LogEntry entry = new LogEntry();\n    entry.setData(task.getData());\n    int retryTimes = 0;\n    try {\n        // 将 Task 及其对应的 LogEntry 对象以事件的形式投递给 Disruptor 队列\n        final EventTranslator<LogEntryAndClosure> translator = (event, sequence) -> {\n            event.reset();\n            event.done = task.getDone();\n            event.entry = entry;\n            event.expectedTerm = task.getExpectedTerm();\n        };\n        while (true) {\n            if (this.applyQueue.tryPublishEvent(translator)) {\n                break;\n            } else {\n                // 重试 3 次\n                retryTimes++;\n                if (retryTimes > MAX_APPLY_RETRY_TIMES) {\n                    Utils.runClosureInThread(task.getDone(),\n                            new Status(RaftError.EBUSY, \"Node is busy, has too many tasks.\"));\n                    LOG.warn(\"Node {} applyQueue is overload.\", getNodeId());\n                    this.metrics.recordTimes(\"apply-task-overload-times\", 1);\n                    return;\n                }\n                ThreadHelper.onSpinWait();\n            }\n        }\n\n    } catch (final Exception e) {\n        LOG.error(\"Fail to apply task.\", e);\n        Utils.runClosureInThread(task.getDone(), new Status(RaftError.EPERM, \"Node is down.\"));\n    }\n}\n```\n\n上述实现只是简单的将承载用户操作指令的 Task 封装成 LogEntry 对象，并以事件的形式投递给 Disruptor 队列进行异步处理，用户可以通过 Task 的 `Task#done` 字段感知任务被状态机处理的响应状态。LogEntryAndClosureHandler 实现了 EventHandler 接口，用于消费 Disruptor 队列中的事件，具体的处理逻辑由 `NodeImpl#executeApplyingTasks` 方法完成：\n\n```java\nprivate void executeApplyingTasks(final List<LogEntryAndClosure> tasks) {\n    this.writeLock.lock();\n    try {\n        final int size = tasks.size();\n        // 只有 Leader 节点允许处理 Task\n        if (this.state != State.STATE_LEADER) {\n            final Status st = new Status();\n            if (this.state != State.STATE_TRANSFERRING) {\n                st.setError(RaftError.EPERM, \"Is not leader.\");\n            } else {\n                st.setError(RaftError.EBUSY, \"Is transferring leadership.\");\n            }\n            LOG.debug(\"Node {} can't apply, status={}.\", getNodeId(), st);\n            final List<LogEntryAndClosure> savedTasks = new ArrayList<>(tasks);\n            // 快速失败\n            Utils.runInThread(() -> {\n                for (int i = 0; i < size; i++) {\n                    savedTasks.get(i).done.run(st);\n                }\n            });\n            return;\n        }\n        final List<LogEntry> entries = new ArrayList<>(size);\n        // 遍历处理 Task 集合\n        for (int i = 0; i < size; i++) {\n            final LogEntryAndClosure task = tasks.get(i);\n            // 如果 Task 期望校验 term 值，则校验当前节点的 term 值是否是期望的 term 值\n            if (task.expectedTerm != -1 && task.expectedTerm != this.currTerm) {\n                LOG.debug(\"Node {} can't apply task whose expectedTerm={} doesn't match currTerm={}.\",\n                        getNodeId(), task.expectedTerm, this.currTerm);\n                if (task.done != null) {\n                    final Status st = new Status(RaftError.EPERM,\n                            \"expected_term=%d doesn't match current_term=%d\", task.expectedTerm, this.currTerm);\n                    Utils.runClosureInThread(task.done, st);\n                }\n                continue;\n            }\n            // 为每个 task 创建并初始化对应的选票，用于决策对应的 LogEntry 是否允许被提交\n            if (!this.ballotBox.appendPendingTask(this.conf.getConf(),\n                    this.conf.isStable() ? null : this.conf.getOldConf(), task.done)) {\n                Utils.runClosureInThread(task.done, new Status(RaftError.EINTERNAL, \"Fail to append task.\"));\n                continue;\n            }\n            // set task entry info before adding to list.\n            task.entry.getId().setTerm(this.currTerm);\n            task.entry.setType(EnumOutter.EntryType.ENTRY_TYPE_DATA);\n            entries.add(task.entry);\n        }\n        // 追加日志数据到本地文件系统，完成之后回调 LeaderStableClosure\n        this.logManager.appendEntries(entries, new LeaderStableClosure(entries));\n        // update conf.first\n        checkAndSetConfiguration(true);\n    } finally {\n        this.writeLock.unlock();\n    }\n}\n```\n\n对于往 Raft 集群提交的指令只允许由 Leader 节点进行处理，这点无可厚非。上述实现会对 Task 进行简单的校验，主要是验证当前节点的 term 值是否是 Task 期望的 term 值，对于通过校验的 Task 则会为其创建并初始化对应的选票，并转化为 LogEntry 对象写入本地存储系统。因为每个 Task 最终都会被转换为对应的日志复制给集群中的所有节点，所以需要创建对应的选票，以实现当集群中的大部分节点都成功完成对该日志的复制操作之后，将对应的日志标记为 committed。创建并初始化选票的过程由 `BallotBox#appendPendingTask` 方法实现，后续我们会再次提及该方法，这里暂且跳过。\n\n将日志数据写入本地存储系统的过程则由 `LogManager#appendEntries` 方法实现，该方法接收一个 LeaderStableClosure 类型的回调，当数据被处理完成之后会触发执行该回调。下面来看一下 `LogManager#appendEntries` 方法的执行流程，实现如下：\n\n```java\npublic void appendEntries(final List<LogEntry> entries, final StableClosure done) {\n    Requires.requireNonNull(done, \"done\");\n    // 运行发生错误\n    if (this.hasError) {\n        entries.clear();\n        Utils.runClosureInThread(done, new Status(RaftError.EIO, \"Corrupted LogStorage\"));\n        return;\n    }\n    boolean doUnlock = true;\n    this.writeLock.lock();\n    try {\n        // 对于 Leader 节点而言，基于本地 lastLogIndex 值设置各个 LogEntry 的 logIndex\n        // 对于 Follower 节点而言，检查待复制的日志与本地已有的日志是否存在冲突，如果存在冲突则强行覆盖本地日志\n        if (!entries.isEmpty() && !checkAndResolveConflict(entries, done)) {\n            // If checkAndResolveConflict returns false, the done will be called in it.\n            entries.clear();\n            return;\n        }\n        for (int i = 0; i < entries.size(); i++) {\n            final LogEntry entry = entries.get(i);\n            // Set checksum after checkAndResolveConflict\n            if (this.raftOptions.isEnableLogEntryChecksum()) {\n                // 设置 checksum 值\n                entry.setChecksum(entry.checksum());\n            }\n\n            // 对于 ENTRY_TYPE_CONFIGURATION 类型的 LogEntry，记录集群配置信息\n            if (entry.getType() == EntryType.ENTRY_TYPE_CONFIGURATION) {\n                Configuration oldConf = new Configuration();\n                if (entry.getOldPeers() != null) {\n                    oldConf = new Configuration(entry.getOldPeers(), entry.getOldLearners());\n                }\n                final ConfigurationEntry conf = new ConfigurationEntry(entry.getId(),\n                        new Configuration(entry.getPeers(), entry.getLearners()), oldConf);\n                this.configManager.add(conf);\n            }\n        }\n\n        // 更新内存数据\n        if (!entries.isEmpty()) {\n            done.setFirstLogIndex(entries.get(0).getId().getIndex());\n            this.logsInMemory.addAll(entries);\n        }\n        done.setEntries(entries);\n\n        // 将修正后的 LogEntry 数据封装成事件投递给 Disruptor 队列，事件类型为 OTHER\n        int retryTimes = 0;\n        final EventTranslator<StableClosureEvent> translator = (event, sequence) -> {\n            event.reset();\n            event.type = EventType.OTHER;\n            event.done = done;\n        };\n        while (true) {\n            if (tryOfferEvent(done, translator)) {\n                break;\n            } else {\n                retryTimes++;\n                // 最大重试 50 次\n                if (retryTimes > APPEND_LOG_RETRY_TIMES) {\n                    reportError(RaftError.EBUSY.getNumber(), \"LogManager is busy, disk queue overload.\");\n                    return;\n                }\n                ThreadHelper.onSpinWait();\n            }\n        }\n        doUnlock = false;\n        // 尝试触发等待新的可复制数据的回调，以继续向目标 Follower 节点发送数据\n        if (!wakeupAllWaiter(this.writeLock)) {\n            notifyLastLogIndexListeners();\n        }\n    } finally {\n        if (doUnlock) {\n            this.writeLock.unlock();\n        }\n    }\n}\n```\n\n往本地追加日志数据的操作除了会被 Leader 节点执行，也会被 Follower 或 Learner 节点所执行，所以上述方法会在各个节点上被调用。因为 Leader 节点的更替，这其中免不了会存在日志数据的冲突，而解决冲突的 `LogManagerImpl#checkAndResolveConflict` 方法实现如下：\n\n```java\nprivate boolean checkAndResolveConflict(final List<LogEntry> entries, final StableClosure done) {\n    final LogEntry firstLogEntry = ArrayDeque.peekFirst(entries);\n    // Leader 节点，基于 lastLogIndex 设置 logIndex 值\n    if (firstLogEntry.getId().getIndex() == 0) {\n        // Node is currently the leader and |entries| are from the user who\n        // don't know the correct indexes the logs should assign to.\n        // So we have to assign indexes to the appending entries\n        for (int i = 0; i < entries.size(); i++) {\n            entries.get(i).getId().setIndex(++this.lastLogIndex);\n        }\n        return true;\n    }\n    // Follower 节点\n    else {\n        // Node is currently a follower and |entries| are from the leader.\n        // We should check and resolve the conflicts between the local logs and |entries|\n        if (firstLogEntry.getId().getIndex() > this.lastLogIndex + 1) {\n            // 待写入的日志与本地已有的日志之间存在断层\n            Utils.runClosureInThread(done, new Status(RaftError.EINVAL,\n                    \"There's gap between first_index=%d and last_log_index=%d\",\n                    firstLogEntry.getId().getIndex(), this.lastLogIndex));\n            return false;\n        }\n\n        // 待写入的所有日志的 logIndex 都小于已经应用的日志的最大 logIndex，直接返回\n        final long appliedIndex = this.appliedId.getIndex();\n        final LogEntry lastLogEntry = ArrayDeque.peekLast(entries);\n        if (lastLogEntry.getId().getIndex() <= appliedIndex) {\n            LOG.warn(\n                    \"Received entries of which the lastLog={} is not greater than appliedIndex={}, return immediately with nothing changed.\",\n                    lastLogEntry.getId().getIndex(), appliedIndex);\n            // Replicate old logs before appliedIndex should be considered successfully, response OK.\n            Utils.runClosureInThread(done);\n            return false;\n        }\n\n        // 待追加的日志与本地已有的日志之前正好衔接上，直接更新 lastLogIndex\n        if (firstLogEntry.getId().getIndex() == this.lastLogIndex + 1) {\n            // fast path\n            this.lastLogIndex = lastLogEntry.getId().getIndex();\n        }\n        // 说明待追加的日志与本地已有的日志之间存在交叉\n        else {\n            // Appending entries overlap the local ones. We should find if there\n            // is a conflicting index from which we should truncate the local ones.\n            int conflictingIndex = 0;\n            // 从头开始遍历寻找第一个 term 值不匹配的 logIndex\n            for (; conflictingIndex < entries.size(); conflictingIndex++) {\n                if (unsafeGetTerm(entries.get(conflictingIndex).getId().getIndex())\n                        != entries.get(conflictingIndex).getId().getTerm()) {\n                    break;\n                }\n            }\n            // 日志数据存在冲突，将本地冲突之后的日志数据阶段\n            if (conflictingIndex != entries.size()) {\n                if (entries.get(conflictingIndex).getId().getIndex() <= this.lastLogIndex) {\n                    // Truncate all the conflicting entries to make local logs consensus with the leader.\n                    unsafeTruncateSuffix(entries.get(conflictingIndex).getId().getIndex() - 1);\n                }\n                this.lastLogIndex = lastLogEntry.getId().getIndex();\n            }\n            // else this is a duplicated AppendEntriesRequest, we have nothing to do besides releasing all the entries\n            // 将已经写入本地的日志数据从请求中剔除\n            if (conflictingIndex > 0) {\n                // Remove duplication\n                entries.subList(0, conflictingIndex).clear();\n            }\n        }\n        return true;\n    }\n}\n```\n\n对于 Leader 节点而言，因为 Raft 算法的强 Leader 设计，所以 Leader 的日志数据是整个集群日志数据的标杆，不存在冲突一说。因此，对于 Leader 节点而言，上述实现只是简单的为当前 LogEntry 对象修正对应的 logIndex 值，但是对于 Follower 和 Learner 节点而言则免不了出现日志数据冲突，分为以下几种情况：\n\n- 待写入的日志数据与本地已有的日志数据存在断层，此时只能返回错误。\n- 待写入的日志数据相对于本地已有的日志数据更老，即最大的 logIndex 小于等于本地已经写入的日志数据的 logIndex，直接忽略。\n- 待写入的日志数据与本地已有的日志数据正好衔接上，直接递增 lastLogIndex 即可。\n- 待写入的日志数据与本地已有的日志数据存在重叠，此时需要判断是否存在冲突，并强行覆盖本地存在冲突的数据。\n\n完成对于冲突数据的处理，LogManager 会先将日志数据写入内存，并将日志数据以 `OTHER` 类型事件的形式提交给 Disruptor 队列，用于实现异步刷盘。方法 `LogManagerImpl#wakeupAllWaiter` 用于通知那些等待新数据到达的复制器 Replicator 实例，这些 Replicator 在向目标 Follower 或 Learner 节点复制日志数据时可能出现没有数据可以复制的情况，此时这些复制器 Replicator 会注册一个回调监听新的数据到来，而通知这些监听器的时机则位于此，关于这一部分的具体流程留到下一小节再展开介绍。\n\n下面来看一下对于 Disruptor 队列中 `OTHER` 类型事件的处理过程，即异步刷盘的过程，由 StableClosureEventHandler 实现。StableClosureEventHandler 定义了一个 AppendBatcher 类型的字段，用于缓存待写入的数据。方法 `AppendBatcher#flush` 用于执行将缓存的数据写入存储系统，实现如下：\n\n```java\nLogId flush() {\n    if (this.size > 0) {\n        // 将数据落盘，并返回最新的 LogId\n        this.lastId = appendToStorage(this.toAppend);\n        for (int i = 0; i < this.size; i++) {\n            // 清空缓存的 LogEntry 数据\n            this.storage.get(i).getEntries().clear();\n            Status st = null;\n            try {\n                if (LogManagerImpl.this.hasError) {\n                    // LogManager 运行异常\n                    st = new Status(RaftError.EIO, \"Corrupted LogStorage\");\n                } else {\n                    st = Status.OK();\n                }\n                // 应用回调\n                this.storage.get(i).run(st);\n            } catch (Throwable t) {\n                LOG.error(\"Fail to run closure with status: {}.\", st, t);\n            }\n        }\n        this.toAppend.clear();\n        this.storage.clear();\n\n    }\n    this.size = 0;\n    this.bufferSize = 0;\n    return this.lastId;\n}\n```\n\n具体执行过程如上述代码注释，其中方法 `LogManagerImpl#appendToStorage` 实现了将数据写入存储系统的逻辑，默认也就是写入 RocksDB 存储引擎，实现比较直观，不再展开。\n\n在完成对一个批次日志数据的处理之后，下面来看一下针对回调 LeaderStableClosure 的处理逻辑，实现如下：\n\n```java\npublic void run(final Status status) {\n    if (status.isOk()) {\n        NodeImpl.this.ballotBox.commitAt(\n                this.firstLogIndex, this.firstLogIndex + this.nEntries - 1, NodeImpl.this.serverId);\n    } else {\n        LOG.error(\"Node {} append [{}, {}] failed, status={}.\",\n                getNodeId(), this.firstLogIndex, this.firstLogIndex + this.nEntries - 1, status);\n    }\n}\n```\n\n如果响应状态是 OK，则上述回调会执行 `BallotBox#commitAt` 方法检查该批次中的日志数据是否被过半数的节点所成功复制，如果存在复制成功的日志数据，则递增 lastCommittedIndex 值，并向状态机发布 `COMMITTED` 事件。方法 `BallotBox#commitAt` 实现如下：\n\n```java\npublic boolean commitAt(final long firstLogIndex, final long lastLogIndex, final PeerId peer) {\n    // TODO  use lock-free algorithm here?\n    final long stamp = this.stampedLock.writeLock();\n    long lastCommittedIndex = 0;\n    try {\n        if (this.pendingIndex == 0) {\n            return false;\n        }\n        if (lastLogIndex < this.pendingIndex) {\n            return true;\n        }\n\n        if (lastLogIndex >= this.pendingIndex + this.pendingMetaQueue.size()) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n\n        final long startAt = Math.max(this.pendingIndex, firstLogIndex);\n        Ballot.PosHint hint = new Ballot.PosHint();\n        // 遍历检查当前批次中的 LogEntry 是否有成功被过半数节点复制的\n        for (long logIndex = startAt; logIndex <= lastLogIndex; logIndex++) {\n            final Ballot bl = this.pendingMetaQueue.get((int) (logIndex - this.pendingIndex));\n            hint = bl.grant(peer, hint);\n            // 当前 LogEntry 被过半数节点成功复制，记录 lastCommittedIndex\n            if (bl.isGranted()) {\n                lastCommittedIndex = logIndex;\n            }\n        }\n        // 没有一条日志被过半数节点所成功复制，先返回\n        if (lastCommittedIndex == 0) {\n            return true;\n        }\n        // When removing a peer off the raft group which contains even number of peers,\n        // the quorum would decrease by 1, e.g. 3 of 4 changes to 2 of 3. In this case,\n        // the log after removal may be committed before some previous logs,\n        // since we use the new configuration to deal the quorum of the removal request,\n        // we think it's safe to commit all the uncommitted previous logs, which is not well proved right now\n        // 剔除已经被过半数节点复制的 LogIndex 对应的选票，\n        // Raft 保证一个 LogEntry 被提交之后，在此之前的 LogEntry 一定是 committed 状态\n        this.pendingMetaQueue.removeFromFirst((int) (lastCommittedIndex - this.pendingIndex) + 1);\n        LOG.debug(\"Committed log fromIndex={}, toIndex={}.\", this.pendingIndex, lastCommittedIndex);\n        this.pendingIndex = lastCommittedIndex + 1;\n        // 更新集群的 lastCommittedIndex 值\n        this.lastCommittedIndex = lastCommittedIndex;\n    } finally {\n        this.stampedLock.unlockWrite(stamp);\n    }\n\n    // 向状态机发布 COMMITTED 事件\n    this.waiter.onCommitted(lastCommittedIndex);\n    return true;\n}\n```\n\n可能读者会疑惑这里只有 Leader 节点执行了写入日志操作，当前日志怎么可能会被 granted 呢？读者需要明白的一点是，Leader 节点在将数据写入内存之后，即通知对应的复制器 Replicator 开始往目标 Follower 节点复制数据（Replicator 优先从内存中读取待复制的日志数据）。到日志数据在 Leader 节点被落盘之后回调上述 `BallotBox#commitAt` 方法这中间是有一个时间差的，所以此时 Leader 节点执行 `BallotBox#commitAt` 操作有可能对应的日志数据已被过半数节点所复制。此外，方法 `BallotBox#commitAt` 除了会被 Leader 节点调用，也会在 Follower 节点完成日志数据复制的 AppendEntries 请求响应处理期间被调用，此时也会触发检查 granted 操作，具体在下一小节介绍日志复制机制时会展开说明。\n\n关于日志生成的过程到这里也就基本介绍完了，本小节的最后我们来看一下 `FSMCaller#onCommitted` 方法到底做了哪些事情。该方法接收一个 committedIndex 参数，在 LogEntry 被提交时触发，会向对应的 Disruptor 队列中发布一个 `COMMITTED` 类型的事件，关于该事件的处理由 `FSMCallerImpl#doCommitted` 方法实现：\n\n```java\nprivate void doCommitted(final long committedIndex) {\n    // 状态机调度器运行异常\n    if (!this.error.getStatus().isOk()) {\n        return;\n    }\n    // 获取最新被状态机应用的 LogEntry 对应的 logIndex 值\n    final long lastAppliedIndex = this.lastAppliedIndex.get();\n    // We can tolerate the disorder of committed_index\n    if (lastAppliedIndex >= committedIndex) {\n        // 当前 committedIndex 对应的 LogEntry 已经被处理过，无需重复处理\n        return;\n    }\n    final long startMs = Utils.monotonicMs();\n    try {\n        final List<Closure> closures = new ArrayList<>();\n        final List<TaskClosure> taskClosures = new ArrayList<>();\n        // 获取 committedIndex 之前的 Task 的回调列表，填充到 closures 集合中，\n        // 如果是 TaskClosure 类型，则顺便记录到 taskClosures 中，主要是为了回调 TaskClosure#onCommitted 方法\n        final long firstClosureIndex = this.closureQueue.popClosureUntil(committedIndex, closures, taskClosures);\n\n        // 对于 TaskClosure 类型的 Task 回调，应用 TaskClosure#onCommitted 方法\n        onTaskCommitted(taskClosures);\n\n        Requires.requireTrue(firstClosureIndex >= 0, \"Invalid firstClosureIndex\");\n        // 迭代器，用于迭代 LogEntry\n        final IteratorImpl iterImpl = new IteratorImpl(\n                this.fsm, this.logManager, closures, firstClosureIndex, lastAppliedIndex, committedIndex, this.applyingIndex);\n\n        // 如果是 good，则说明还有可以继续处理的日志\n        while (iterImpl.isGood()) {\n            // 获取当前待处理的 LogEntry 对象\n            final LogEntry logEntry = iterImpl.entry();\n            // 系统内部的 LogEntry 对象\n            if (logEntry.getType() != EnumOutter.EntryType.ENTRY_TYPE_DATA) {\n                if (logEntry.getType() == EnumOutter.EntryType.ENTRY_TYPE_CONFIGURATION) {\n                    if (logEntry.getOldPeers() != null && !logEntry.getOldPeers().isEmpty()) {\n                        // Joint stage is not supposed to be noticeable by end users.\n                        this.fsm.onConfigurationCommitted(new Configuration(iterImpl.entry().getPeers()));\n                    }\n                }\n                if (iterImpl.done() != null) {\n                    // For other entries, we have nothing to do besides flush the\n                    // pending tasks and run this closure to notify the caller that the\n                    // entries before this one were successfully committed and applied.\n                    iterImpl.done().run(Status.OK());\n                }\n                iterImpl.next();\n                continue;\n            }\n\n            // 连续处理一批业务操作产生的日志，应用 StateMachine#onApply 方法\n            doApplyTasks(iterImpl);\n        }\n\n        // 发生错误，将错误透传给业务和当前节点\n        if (iterImpl.hasError()) {\n            setError(iterImpl.getError());\n            iterImpl.runTheRestClosureWithError();\n        }\n        final long lastIndex = iterImpl.getIndex() - 1;\n        final long lastTerm = this.logManager.getTerm(lastIndex);\n        final LogId lastAppliedId = new LogId(lastIndex, lastTerm);\n        // 更新最新应用的日志对应的 logIndex 和 term 值\n        this.lastAppliedIndex.set(lastIndex);\n        this.lastAppliedTerm = lastTerm;\n        // 通知 LogManager，这些已经被应用的 LogEntry 可以从内存中移除了\n        this.logManager.setAppliedId(lastAppliedId);\n        notifyLastAppliedIndexUpdated(lastIndex);\n    } finally {\n        this.nodeMetrics.recordLatency(\"fsm-commit\", Utils.monotonicMs() - startMs);\n    }\n}\n```\n\n业务向 JRaft 集群提交的 Task 在被转换成日志并成功复制给集群中的过半数以上节点（即对应的日志被提交）之后，接下去就需要将这些日志中存储的指令透传给业务状态机，相应的实现由上述方法完成。\n\nFSMCaller 本地维护了一个 lastAppliedIndex 字段，用于记录已经被应用（即已将日志中的指令透传给业务状态机）的 LogEntry 对应的 logIndex 值。因为 Raft 算法能够保证某个 committedIndex 之前的所有 LogEntry 都是被提交的，所以即使 committedIndex 的到达顺序出现乱序也不会影响正常的运行逻辑。\n\n我们在调用 `Node#apply` 方法向 JRaft 集群提交 Task 时，一般都会给 Task 设置一个回调，即给 `Task#done` 字段赋值。所以，FSMCaller 对于给定的 committedIndex，首先会调用 `ClosureQueueImpl#popClosureUntil` 方法获取到这些已经被提交的 LogEntry 对应的 Task 的回调。这些回调最终会透传给业务状态机，由业务决定是响应成功还是失败。那么这些回调是什么时候被记录的呢？\n\n还记得我们在介绍 JRaft 节点初始化过程时曾提及过 FSMCaller 和 BallotBox 所持有的 ClosureQueue 实例是同一个吗？这些 Task 回调正是在前面调用 `BallotBox#appendPendingTask` 方法时记录的，实现如下：\n\n```java\npublic boolean appendPendingTask(final Configuration conf, final Configuration oldConf, final Closure done) {\n    // 创建并初始化选票\n    final Ballot bl = new Ballot();\n    if (!bl.init(conf, oldConf)) {\n        LOG.error(\"Fail to init ballot.\");\n        return false;\n    }\n    final long stamp = this.stampedLock.writeLock();\n    try {\n        // 节点成功 Leader 之后必须调用 BallotBox#resetPendingIndex 方法重置 pendingIndex 值\n        if (this.pendingIndex <= 0) {\n            LOG.error(\"Fail to appendingTask, pendingIndex={}.\", this.pendingIndex);\n            return false;\n        }\n        // 记录选票，用于检查是否赢得过半数选票\n        this.pendingMetaQueue.add(bl);\n        // 记录 Task 的回调 done 对象，当对应的日志被 committed 时触发执行\n        this.closureQueue.appendPendingClosure(done);\n        return true;\n    } finally {\n        this.stampedLock.unlockWrite(stamp);\n    }\n}\n```\n\n接下来，FSMCaller 采用了迭代器模式将需要处理的日志封装成迭代器对象，并对于业务操作产生的日志调用 `FSMCallerImpl#doApplyTasks` 方法将一批连续的 `ENTRY_TYPE_DATA` 类型日志透传给状态机：\n\n```java\nprivate void doApplyTasks(final IteratorImpl iterImpl) {\n    final IteratorWrapper iter = new IteratorWrapper(iterImpl);\n    final long startApplyMs = Utils.monotonicMs();\n    final long startIndex = iter.getIndex();\n    try {\n        // 应用 StateMachine#onApply 方法\n        this.fsm.onApply(iter);\n    } finally {\n        this.nodeMetrics.recordLatency(\"fsm-apply-tasks\", Utils.monotonicMs() - startApplyMs);\n        this.nodeMetrics.recordSize(\"fsm-apply-tasks-count\", iter.getIndex() - startIndex);\n    }\n    // 迭代器中的日志还没有被处理完，但是业务已经退出了 onApply 方法\n    if (iter.hasNext()) {\n        LOG.error(\"Iterator is still valid, did you return before iterator reached the end?\");\n    }\n    // Try move to next in case that we pass the same log twice.\n    iter.next();\n}\n```\n\n而状态机 StateMachine 的核心方法 `StateMachine#onApply` 也正是在此处被调用。\n\n### 日志复制\n\n上一小节我们以业务操作日志为例，从 Leader 节点视角分析了 JRaft 是如何产生和处理一条日志的。在将用户操作指令封装成 LogEntry 写入内存之后，日志复制的进程即开始了，与此同时，Leader 节点会以异步的方式将数据落盘。日志复制仍然采用投票机制，当一条日志被集群中过半数以上的节点成功复制之后，这条日志会被打上 committed 标签。此类日志中承载的操作指令最后会被透传给状态机，由业务负责执行。\n\n本小节侧重于分析 Leader 节点将日志数据复制给集群中的 Follower 节点的运行机制。Leader 节点针对每个 Follower 节点都会在本地为其创建并启动一个复制器 Replicator 实例，而日志复制的过程则全权由 Replicator 负责，各 Replicator 之间相互独立，彼此互不影响。\n\nJRaft 还设计了 ReplicatorGroup 类，由名称我们可以推断出该类用于实现对于同一个 group 下的所有 Replicator 实例进行管理，例如启停到目标 Follower 或 Learner 节点的 Replicator 实例、检查到目标 Follower 或 Learner 节点的复制关系，以及主动向目标节点发送心跳请求等。\n\n#### Pipeline 机制\n\nLeader 节点将日志数据复制给 Follower 节点的过程必须保证日志数据的顺序性和连续性，这一点是毋庸置疑的。为了达到此目的，最简单的交互模式就是“request -> response -> request”，即每次发送出去一个请求之后必须等待接收并处理完对应的响应之后再发送下一个请求，从交互上保证日志复制的严格串行化。这一设计的优点在于实现简单，但是性能上却不尽如人意。\n\n日志数据复制在 Raft 算法的运行过程中是一项频繁的操作，为了在保证日志复制顺序和连续的前提下尽量提升复制的性能，除了并发的向各个 Follower 或 Learner 节点批量发送数据之外，JRaft 在实现上还引入了 pipeline 机制。这一机制简单而言就是将请求和响应从串行改为并行，请求和响应彼此之间互不阻塞。Leader 节点可以连续的向 Follower 节点发送请求，对于那些已经发送出去还未收到响应的请求，或者已经收到但是还没来得及处理的响应对应的请求将其标记为 inflight，并在成功处理完对应的响应之后去除请求的 inflight 标记。如果期间发生错误或者 Leader 节点宕机，对于这些 inflight 请求会尝试重新发送，以此保证日志数据在复制期间不会漏传给 Follower 节点。Pipeline 机制与 TCP 协议中的滑动窗口算法思想相通，是分布式系统中提升吞吐量的惯用策略，例如 Kafka 生产者在往服务端发送消息时同样采用了类似的机制。\n\n然而，我们也看到这一机制可能会导致同一个 LogEntry 被多次复制给 Follower 节点，好在 Raft 算法要求日志中的指令必须是幂等的，同时 Raft 算法针对日志数据的冲突解决机制能够保证重复复制的 LogEntry 能够被最后一次复制的 LogEntry 所覆盖。\n\n![image](/images/2020/jraft-log-replication-pipeline.png)\n\n上图描绘了 JRaft Pipeline 机制的设计，其中 inflight request queue 中的青色实心圆点表示已经发送出去还未接收到响应的请求（即 inflight 请求），而 pending response queue 中的黄色实心圆点表示已经收到的响应，黄色空心圆点表示还未收到的响应。对于响应而言，由于网络原因到达顺序不一定与请求顺序相吻合，JRaft 对于提前到达的响应会先将其缓存起来，并按照请求的顺序对响应按顺序进行处理。如果因为等待的某个响应迟迟不能到达导致 inflight 请求越积越多，或者某个响应异常，则 Leader 节点会清空 inflight request queue 中的请求，并重新发送这些请求。这一机制能够实现将发送请求和处理响应并行化，并且由于 Raft 算法要求日志承载的指令必须是幂等的，所以重试策略不会破坏数据的最终状态。\n\n下面来看一下 JRaft 对于 pipeline 机制的实现。首先来了解几个相关的字段定义，如下：\n\n```java\n/** 记录最近的 inflight RPC 请求 */\nprivate Inflight rpcInFly;\n/** FIFO 队列，记录 inflight RPC 请求列表 */\nprivate final ArrayDeque<Inflight> inflights = new ArrayDeque<>();\n/** 请求序列 */\nprivate int reqSeq = 0;\n/** 期望的响应序列 */\nprivate int requiredNextSeq = 0;\n/** 状态版本，当重置 inflight 请求队列时会递增，以实现忽略版本不匹配的 inflight 请求响应 */\nprivate int version = 0;\n/**\n * 记录已经收到但是还没有被处理的响应，按照请求序列从小到大排序，\n * 响应的顺序是未知的，但是需要保证处理的顺序\n */\nprivate final PriorityQueue<RpcResponse> pendingResponses = new PriorityQueue<>(50);\n```\n\n各字段的作用如代码注释，其中 Inflight 类用于描述一个 inflight 请求，定义如下：\n\n```java\nstatic class Inflight {\n    /** 请求中的 LogEntry 数目 */\n    final int count;\n    /** 请求对应的起始 nextIndex 值 */\n    final long startIndex;\n    /** LogEntry 的总字节长度 */\n    final int size;\n    /** RPC future */\n    final Future<Message> rpcFuture;\n    /** 请求类型：复制日志 or 安装快照 */\n    final RequestType requestType;\n    /** 请求序列，用于匹配请求和响应，保证按照请求的顺序处理响应 */\n    final int seq;\n\n    // ... 省略构造函数和 toString 方法\n\n    boolean isSendingLogEntries() {\n        return this.requestType == RequestType.AppendEntries && this.count > 0;\n    }\n}\n```\n\nReplicator 在成功发送一个 RPC 请求之后会调用 `Replicator#addInflight` 方法将请求相关的信息封装成 Inflight 对象记录到 inflight 队列中：\n\n```java\nprivate void addInflight(final RequestType reqType,\n                         final long startIndex,\n                         final int count,\n                         final int size,\n                         final int seq,\n                         final Future<Message> rpcInfly) {\n    // 更新本地记录的最近一次发送的 inflight RPC 请求\n    this.rpcInFly = new Inflight(reqType, startIndex, count, size, seq, rpcInfly);\n    // 标记当前请求为 inflight\n    this.inflights.add(this.rpcInFly);\n    this.nodeMetrics.recordSize(\"replicate-inflights-count\", this.inflights.size());\n}\n```\n\n当接收到请求对应的响应时，Replicator 会执行 `Replicator#onRpcReturned` 方法处理响应，实现如下：\n\n```java\nstatic void onRpcReturned(final ThreadId id,\n                          final RequestType reqType,\n                          final Status status,\n                          final Message request,\n                          final Message response,\n                          final int seq,\n                          final int stateVersion,\n                          final long rpcSendTime) {\n    if (id == null) {\n        return;\n    }\n    final long startTimeMs = Utils.nowMs();\n    Replicator r;\n    // 获取当前 Replicator 对应的不可重入锁\n    if ((r = (Replicator) id.lock()) == null) {\n        return;\n    }\n\n    // 状态版本发生变化，说明 inflight 队列被重置过，忽略重置之前请求对应的响应\n    if (stateVersion != r.version) {\n        LOG.debug(\"Replicator {} ignored old version response {}, current version is {}, request is {}\\n, and response is {}\\n, status is {}.\",\n                r, stateVersion, r.version, request, response, status);\n        id.unlock();\n        return;\n    }\n\n    // 获取等待处理的响应优先级队列，按照请求序列从小到大排序\n    final PriorityQueue<RpcResponse> holdingQueue = r.pendingResponses;\n    holdingQueue.add(new RpcResponse(reqType, seq, status, request, response, rpcSendTime));\n\n    // 太多等待处理的响应（默认为 256 个），而期望请求序列对应的响应迟迟不来，重置请求 inflight 队列，重新发送探针请求\n    if (holdingQueue.size() > r.raftOptions.getMaxReplicatorInflightMsgs()) {\n        LOG.warn(\"Too many pending responses {} for replicator {}, maxReplicatorInflightMsgs={}\",\n                holdingQueue.size(), r.options.getPeerId(), r.raftOptions.getMaxReplicatorInflightMsgs());\n        r.resetInflights();\n        r.state = State.Probe;\n        r.sendEmptyEntries(false);\n        return;\n    }\n\n    // 标识是否继续发送 AppendEntries 请求\n    boolean continueSendEntries = false;\n\n    final boolean isLogDebugEnabled = LOG.isDebugEnabled();\n    StringBuilder sb = null;\n    if (isLogDebugEnabled) {\n        sb = new StringBuilder(\"Replicator \").append(r).append(\" is processing RPC responses, \");\n    }\n    try {\n        // 记录已经处理的响应数\n        int processed = 0;\n        // 遍历处理响应\n        while (!holdingQueue.isEmpty()) {\n            // 获取收到的请求序列最小的响应\n            final RpcResponse queuedPipelinedResponse = holdingQueue.peek();\n\n            // Sequence mismatch, waiting for next response.\n            // 响应乱序，继续等待期望序列的响应\n            if (queuedPipelinedResponse.seq != r.requiredNextSeq) {\n                if (processed > 0) {\n                    if (isLogDebugEnabled) {\n                        sb.append(\"has processed \").append(processed).append(\" responses, \");\n                    }\n                    break;\n                } else {\n                    // Do not processed any responses, UNLOCK id and return.\n                    continueSendEntries = false;\n                    id.unlock();\n                    return;\n                }\n            }\n\n            /* 开始处理请求对应的响应 */\n\n            holdingQueue.remove();\n            processed++;\n            // 获取 inflight 请求\n            final Inflight inflight = r.pollInflight();\n            if (inflight == null) {\n                // 响应对应的请求已经被清除，忽略当前响应\n                if (isLogDebugEnabled) {\n                    sb.append(\"ignore response because request not found: \").append(queuedPipelinedResponse).append(\",\\n\");\n                }\n                continue;\n            }\n            // 请求序列与响应中记录的请求序列匹配不上，重置请求 inflight 队列，阻塞一会后重新发送探针请求\n            if (inflight.seq != queuedPipelinedResponse.seq) {\n                // reset state\n                LOG.warn(\"Replicator {} response sequence out of order, expect {}, but it is {}, reset state to try again.\",\n                        r, inflight.seq, queuedPipelinedResponse.seq);\n                r.resetInflights();\n                r.state = State.Probe;\n                continueSendEntries = false;\n                r.block(Utils.nowMs(), RaftError.EREQUEST.getNumber());\n                return;\n            }\n\n            // 依据响应类型分别处理\n            try {\n                switch (queuedPipelinedResponse.requestType) {\n                    // 处理 AppendEntries 请求\n                    case AppendEntries:\n                        continueSendEntries = onAppendEntriesReturned(\n                                id,\n                                inflight,\n                                queuedPipelinedResponse.status,\n                                (AppendEntriesRequest) queuedPipelinedResponse.request,\n                                (AppendEntriesResponse) queuedPipelinedResponse.response,\n                                rpcSendTime,\n                                startTimeMs,\n                                r);\n                        break;\n                    // 处理 InstallSnapshot 请求\n                    case Snapshot:\n                        continueSendEntries = onInstallSnapshotReturned(\n                                id,\n                                r,\n                                queuedPipelinedResponse.status,\n                                (InstallSnapshotRequest) queuedPipelinedResponse.request,\n                                (InstallSnapshotResponse) queuedPipelinedResponse.response);\n                        break;\n                }\n            } finally {\n                if (continueSendEntries) {\n                    // Success, increase the response sequence.\n                    r.getAndIncrementRequiredNextSeq();\n                } else {\n                    // The id is already unlocked in onAppendEntriesReturned/onInstallSnapshotReturned, we SHOULD break out.\n                    break;\n                }\n            }\n        }\n    } finally {\n        if (isLogDebugEnabled) {\n            sb.append(\"after processed, continue to send entries: \").append(continueSendEntries);\n            LOG.debug(sb.toString());\n        }\n        // 继续发送 AppendEntries 请求\n        if (continueSendEntries) {\n            // unlock in sendEntries.\n            r.sendEntries();\n        }\n    }\n}\n```\n\n由上述实现我们可以总结 pipeline 机制在处理响应时需要考虑以下几点：\n\n- 因为 inflight 请求本质上是一种未完成的请求，有重试的可能，所以当重新发送请求时，之前请求对应的响应即使收到了也应该被忽略。\n- 响应的顺序是未知的，但是需要保证处理的顺序，所以对于提前收到的响应需要先缓存起来，必须按照请求发送的顺序而非响应到达的顺序进行处理。\n- 需要保证请求序列和响应序列相匹配。\n\n针对上述中的第一点，JRaft 在实现上通过版本策略予以实现。Replicator 定义了一个 `Replicator#version` 字段，用于标识当前 inflight 队列的版本。当重置 inflight 队列时会自增该版本号，并清空 inflight 队列和响应队列等。Replicator 执行此操作的目的在于丢弃那些 inflight 请求以重新发送，但是这些已经发送出去的 inflight 请求对应的响应可能正在赶来的路上，当节点收到这些响应时需要予以忽略，而忽略的依据就是版本不匹配。\n\n#### 发送探针\n\n完成了对于 Pipeline 机制的介绍，下面开始分析 JRaft 复制日志数据的过程。上一篇曾介绍过，当一个节点竞选 Leader 成功之后会调用 `ReplicatorGroup#addReplicator` 方法建立到各个 Follower 节点之间的复制关系，本文我们将从这里切入分析 JRaft 的日志复制机制。\n\n方法 `ReplicatorGroup#addReplicator` 接收两个参数，用于指定目标 Follower 或 Learner 节点，以及节点类型，具体实现如下：\n\n```java\npublic boolean addReplicator(final PeerId peer, // 目标 Follower 或 Learner 节点\n                             final ReplicatorType replicatorType // 节点类型\n) {\n    // 在此之前应该先调用 ReplicatorGroup#resetTerm 方法\n    Requires.requireTrue(this.commonOptions.getTerm() != 0);\n    this.failureReplicators.remove(peer);\n    // 已建立复制关系，避免重复\n    if (this.replicatorMap.containsKey(peer)) {\n        return true;\n    }\n    final ReplicatorOptions opts = this.commonOptions == null ? new ReplicatorOptions() : this.commonOptions.copy();\n    opts.setReplicatorType(replicatorType);\n    opts.setPeerId(peer);\n    // 创建并启动到目标节点的复制器\n    final ThreadId rid = Replicator.start(opts, this.raftOptions);\n    if (rid == null) {\n        LOG.error(\"Fail to start replicator to peer={}, replicatorType={}.\", peer, replicatorType);\n        this.failureReplicators.put(peer, replicatorType);\n        return false;\n    }\n    return this.replicatorMap.put(peer, rid) == null;\n}\n```\n\n上述实现的核心在于调用 `Replicator#start` 方法创建并启动到目标节点的复制器 Replicator 实例。该方法返回一个 ThreadId 对象，用于为对应的 Replicator 对象提供不可重入锁支持，其中不可重入锁基于 [AQS](http://www.zhenchao.org/2018/08/24/java/juc-aqs/) 实现。\n\n方法 `Replicator#start` 实现如下：\n\n```java\npublic static ThreadId start(final ReplicatorOptions opts, final RaftOptions raftOptions) {\n    if (opts.getLogManager() == null || opts.getBallotBox() == null || opts.getNode() == null) {\n        throw new IllegalArgumentException(\"Invalid ReplicatorOptions.\");\n    }\n    // 创建复制器 Replicator 对象\n    final Replicator r = new Replicator(opts, raftOptions);\n    // 检查到目标节点的连通性\n    if (!r.rpcService.connect(opts.getPeerId().getEndpoint())) {\n        LOG.error(\"Fail to init sending channel to {}.\", opts.getPeerId());\n        // Return and it will be retried later.\n        return null;\n    }\n\n    // ... register replicator metric set\n\n    // Start replication\n    r.id = new ThreadId(r, r);\n    // 获取与当前 Replicator 绑定的不可重入锁\n    r.id.lock();\n    // 发布 CREATED 事件\n    notifyReplicatorStatusListener(r, ReplicatorEvent.CREATED);\n    LOG.info(\"Replicator={}@{} is started\", r.id, r.options.getPeerId());\n    r.catchUpClosure = null;\n    // 更新最近一次发送 RPC 请求的时间戳\n    r.lastRpcSendTimestamp = Utils.monotonicMs();\n    // 启动心跳超时计时器\n    r.startHeartbeatTimer(Utils.nowMs());\n    // 发送探针请求，以获取接下去发往目标节点的正确 logIndex 位置，并启动日志复制进程\n    // id.unlock in sendEmptyEntries\n    r.sendEmptyEntries(false);\n    return r.id;\n}\n```\n\n其中方法 `Replicator#sendEmptyEntries` 用于向目标节点发送一个空的 AppendEntries 请求，此类请求可以是一个探针（probe）请求，也可以是一个心跳请求。关于心跳请求的发送和响应过程，我们将在后面的小节专门介绍，下面来看一下探针请求的发送和响应过程。Leader 节点在通过复制器 Replicator 与目标 Follower 节点建立连接后，需要发送一个探针请求，目的是获取 Follower 节点已经拥有的日志位置，以便于接下去向 Follower 节点发送后续的日志数据。\n\n方法 `Replicator#sendEmptyEntries` 接收两个参数，当发送探针请求时会设置参数 `isHeartbeat = false`，同时设置参数 `heartBeatClosure = null`，实现如下：\n\n```java\nprivate void sendEmptyEntries(final boolean isHeartbeat,\n                              final RpcResponseClosure<AppendEntriesResponse> heartBeatClosure) {\n    // 构建 AppendEntries 请求\n    final AppendEntriesRequest.Builder rb = AppendEntriesRequest.newBuilder();\n    // 为 AppendEntries 请求填充基础参数，包括当前节点的 term 值、groupId、节点 ID，以及 committedLogIndex 等等\n    // 如果返回 false 说明待发送的部分日志已经变为快照，需要先给目标节点安装快照\n    if (!fillCommonFields(rb, this.nextIndex - 1, isHeartbeat)) {\n        // id is unlock in installSnapshot\n        installSnapshot();\n        if (isHeartbeat && heartBeatClosure != null) {\n            RpcUtils.runClosureInThread(heartBeatClosure,\n                    new Status(RaftError.EAGAIN, \"Fail to send heartbeat to peer %s\", this.options.getPeerId()));\n        }\n        return;\n    }\n    try {\n        final long monotonicSendTimeMs = Utils.monotonicMs();\n        final AppendEntriesRequest request = rb.build();\n\n        // 心跳请求\n        if (isHeartbeat) {\n            // ... 省略心跳请求相关实现\n        }\n        // 探针请求\n        else {\n            // Sending a probe request.\n            this.statInfo.runningState = RunningState.APPENDING_ENTRIES;\n            this.statInfo.firstLogIndex = this.nextIndex;\n            this.statInfo.lastLogIndex = this.nextIndex - 1;\n            this.appendEntriesCounter++;\n            this.state = State.Probe;\n            final int stateVersion = this.version;\n            // 递增请求序列\n            final int seq = getAndIncrementReqSeq();\n            // 向目标节点发送 AppendEntries 请求\n            final Future<Message> rpcFuture = this.rpcService.appendEntries(\n                    this.options.getPeerId().getEndpoint(),\n                    request,\n                    -1,\n                    new RpcResponseClosureAdapter<AppendEntriesResponse>() {\n\n                        @Override\n                        public void run(final Status status) {\n                            // 处理响应\n                            onRpcReturned(Replicator.this.id,\n                                    RequestType.AppendEntries,\n                                    status,\n                                    request,\n                                    getResponse(),\n                                    seq,\n                                    stateVersion,\n                                    monotonicSendTimeMs);\n                        }\n\n                    });\n\n            // 将当前请求标记为 inflight，并记录到 inflight 队列中\n            addInflight(RequestType.AppendEntries, this.nextIndex, 0, 0, seq, rpcFuture);\n        }\n        LOG.debug(\"Node {} send HeartbeatRequest to {} term {} lastCommittedIndex {}\",\n                this.options.getNode().getNodeId(), this.options.getPeerId(), this.options.getTerm(), request.getCommittedIndex());\n    } finally {\n        this.id.unlock();\n    }\n}\n```\n\n上述方法的核心逻辑在于构造并向目标节点发送 AppendEntries 请求，方法 `Replicator#fillCommonFields` 会往 AppendEntries 请求对象中填充一些基础数据，包括当前节点的 term 值、groupId、节点 ID、最近一次复制成功的日志对应的 logIndex 和 term 值、目标节点 ID，以及当前节点最新的 committedIndex 值。如果该方法返回 false，则说明需要发送给目标节点的日志已经变为快照形式存储，需要转为走快照机制为目标节点安装快照，关于快照相关的实现我们将在后面用专门的文章进行介绍，这里暂且跳过。\n\n在将 AppendEntries 请求发送出去之后，JRaft 会将请求标记为 inflight 并记录到 inflight 队列中，然后等待目标节点响应，关于请求的 pipeline 机制在前面已经专门介绍过。下面来看一下目标节点对于 AppendEntries 探针请求的处理过程，由 `NodeImpl#handleAppendEntriesRequest` 方法实现：\n\n```java\npublic Message handleAppendEntriesRequest(final AppendEntriesRequest request, final RpcRequestClosure done) {\n    boolean doUnlock = true;\n    final long startMs = Utils.monotonicMs();\n    this.writeLock.lock();\n    final int entriesCount = request.getEntriesCount();\n    try {\n        // 当前节点处于非活跃状态，响应错误\n        if (!this.state.isActive()) {\n            LOG.warn(\"Node {} is not in active state, currTerm={}.\", getNodeId(), this.currTerm);\n            return RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(AppendEntriesResponse.getDefaultInstance(), RaftError.EINVAL,\n                            \"Node %s is not in active state, state %s.\", getNodeId(), this.state.name());\n        }\n\n        // 解析请求来源节点 ID\n        final PeerId serverId = new PeerId();\n        if (!serverId.parse(request.getServerId())) {\n            // 解析失败，响应错误\n            LOG.warn(\"Node {} received AppendEntriesRequest from {} serverId bad format.\", getNodeId(), request.getServerId());\n            return RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(AppendEntriesResponse.getDefaultInstance(),\n                            RaftError.EINVAL, \"Parse serverId failed: %s.\", request.getServerId());\n        }\n\n        // 校验请求中的 term 值，如果小于当前节点，则拒绝请求并返回自己当前的 term 值\n        if (request.getTerm() < this.currTerm) {\n            LOG.warn(\"Node {} ignore stale AppendEntriesRequest from {}, term={}, currTerm={}.\",\n                    getNodeId(), request.getServerId(), request.getTerm(), this.currTerm);\n            return AppendEntriesResponse.newBuilder() //\n                    .setSuccess(false) //\n                    .setTerm(this.currTerm) //\n                    .build();\n        }\n\n        // 基于请求和节点本地状态判断是否需要执行 stepdown\n        checkStepDown(request.getTerm(), serverId);\n\n        // 请求来源节点并不是当前节点所知道的 Leader 节点，\n        // 可能出现网络分区，尝试将 term 值加 1，以触发 Leader 节点 stepdown\n        if (!serverId.equals(this.leaderId)) {\n            LOG.error(\"Another peer {} declares that it is the leader at term {} which was occupied by leader {}.\",\n                    serverId, this.currTerm, this.leaderId);\n            // Increase the term by 1 and make both leaders step down to minimize the loss of split brain\n            stepDown(request.getTerm() + 1, false,\n                    new Status(RaftError.ELEADERCONFLICT, \"More than one leader in the same term.\"));\n            return AppendEntriesResponse.newBuilder() //\n                    .setSuccess(false) //\n                    .setTerm(request.getTerm() + 1) //\n                    .build();\n        }\n\n        // 更新本地记录的最近一次收到来自 Leader 节点请求的时间戳\n        updateLastLeaderTimestamp(Utils.monotonicMs());\n\n        // 当前是复制日志的 AppendEntries 请求，但是本地正在安装快照，响应错误\n        if (entriesCount > 0 && this.snapshotExecutor != null && this.snapshotExecutor.isInstallingSnapshot()) {\n            LOG.warn(\"Node {} received AppendEntriesRequest while installing snapshot.\", getNodeId());\n            return RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(AppendEntriesResponse.getDefaultInstance(), RaftError.EBUSY,\n                            \"Node %s:%s is installing snapshot.\", this.groupId, this.serverId);\n        }\n\n        final long prevLogIndex = request.getPrevLogIndex();\n        final long prevLogTerm = request.getPrevLogTerm();\n        final long localPrevLogTerm = this.logManager.getTerm(prevLogIndex);\n        // 请求中 logIndex 对应的 term 值与本地不匹配\n        if (localPrevLogTerm != prevLogTerm) {\n            final long lastLogIndex = this.logManager.getLastLogIndex();\n            LOG.warn(\"Node {} reject term_unmatched AppendEntriesRequest from {}, \" +\n                            \"term={}, prevLogIndex={}, prevLogTerm={}, localPrevLogTerm={}, lastLogIndex={}, entriesSize={}.\",\n                    getNodeId(), request.getServerId(), request.getTerm(), prevLogIndex, prevLogTerm, localPrevLogTerm, lastLogIndex, entriesCount);\n\n            return AppendEntriesResponse.newBuilder() //\n                    .setSuccess(false) //\n                    .setTerm(this.currTerm) //\n                    .setLastLogIndex(lastLogIndex) //\n                    .build();\n        }\n\n        // 心跳或者探针请求\n        if (entriesCount == 0) {\n            // 返回本地当前的 term 值以及对应的 logIndex\n            final AppendEntriesResponse.Builder respBuilder = AppendEntriesResponse.newBuilder() //\n                    .setSuccess(true) //\n                    .setTerm(this.currTerm) //\n                    .setLastLogIndex(this.logManager.getLastLogIndex());\n            doUnlock = false;\n            this.writeLock.unlock();\n            // see the comments at FollowerStableClosure#run()\n            // 基于 Leader 的 committedIndex 更新本地的 lastCommittedIndex 值\n            this.ballotBox.setLastCommittedIndex(Math.min(request.getCommittedIndex(), prevLogIndex));\n            return respBuilder.build();\n        }\n\n        // ... 省略复制日志数据请求的处理逻辑\n\n    } finally {\n        if (doUnlock) {\n            this.writeLock.unlock();\n        }\n        // ... metrics\n    }\n}\n```\n\nFollower 节点对于探针请求的整体响应流程可以概括为：\n\n1. 如果当前节点处于非活跃状态，则响应错误；\n2. 否则，解析请求来源节点的节点 ID，如果解析失败则响应错误；\n3. 否则，校验请求中的 term 值是否小于当前节点，如果是则拒绝请求；\n4. 否则，基于请求和当前节点本地状态判断是否需要执行 stepdown 操作；\n5. 判断请求来源节点是否是当前节点所认可的 Leader 节点，如果不是则说明可能出现网络分区，尝试将响应中的 term 值加 1，以触发请求节点执行 stepdown 操作；\n6. 否则，更新本地记录的最近一次收到来自 Leader 节点的时间戳；\n7. 校验最近一次完成复制的 LogEntry 对应的 term 值是否与本地相匹配，如果不匹配则拒绝请求，并返回本地已知的最新 logIndex 值；\n8. 否则，依据请求中的 committedIndex 值更新本地的 committedIndex 值，同时响应请求，返回本地已知的最新 logIndex 和 term 值。\n\n通过这一系列的校验过程，Follower 节点会在针对当前探针请求的响应中附上本地已知的最新 logIndex 和 term 值，而 Leader 节点会依据响应选择正确位置的 LogEntry 发送给当前 Follower 节点。\n\n下面来看一下 Leader 节点对于上述 Follower 节点响应的处理过程，因为探针请求本质上是一类 AppendEntries 请求，所以由 `Replicator#onAppendEntriesReturned` 方法实现（省略了部分 DEBUG 日志打印）：\n\n```java\nprivate static boolean onAppendEntriesReturned(final ThreadId id,\n                                               final Inflight inflight,\n                                               final Status status,\n                                               final AppendEntriesRequest request,\n                                               final AppendEntriesResponse response,\n                                               final long rpcSendTime,\n                                               final long startTimeMs,\n                                               final Replicator r) {\n    // inflight 请求与响应中记录的请求对应的 logIndex 不匹配，重置请求 inflight 队列，重新发送探针请求\n    if (inflight.startIndex != request.getPrevLogIndex() + 1) {\n        LOG.warn(\"Replicator {} received invalid AppendEntriesResponse, in-flight startIndex={}, request prevLogIndex={}, reset the replicator state and probe again.\",\n                r, inflight.startIndex, request.getPrevLogIndex());\n        r.resetInflights();\n        r.state = State.Probe;\n        // unlock id in sendEmptyEntries\n        r.sendEmptyEntries(false);\n        return false;\n    }\n\n    // ... metrics\n\n    // 目标 Follower 发生错误，重置请求 inflight 队列，重新发送探针请求\n    if (!status.isOk()) {\n        // If the follower crashes, any RPC to the follower fails immediately,\n        // so we need to block the follower for a while instead of looping until it comes back or be removed\n        // dummy_id is unlock in block\n        notifyReplicatorStatusListener(r, ReplicatorEvent.ERROR, status);\n        if (++r.consecutiveErrorTimes % 10 == 0) {\n            LOG.warn(\"Fail to issue RPC to {}, consecutiveErrorTimes={}, error={}\",\n                    r.options.getPeerId(), r.consecutiveErrorTimes, status);\n        }\n        // 重置 inflight 队列，阻塞一会儿重新发送探针请求\n        r.resetInflights();\n        r.state = State.Probe;\n        // unlock in in block\n        r.block(startTimeMs, status.getCode());\n        return false;\n    }\n\n    /* 目标 Follower 节点运行正常 */\n\n    r.consecutiveErrorTimes = 0;\n    // 目标 Follower 节点拒绝响应\n    if (!response.getSuccess()) {\n        // Follower 节点的 term 值更大\n        if (response.getTerm() > r.options.getTerm()) {\n            final NodeImpl node = r.options.getNode();\n            r.notifyOnCaughtUp(RaftError.EPERM.getNumber(), true);\n            // 销毁当前复制器 Replicator\n            r.destroy();\n            // 提升当前节点的 term 值，并执行 stepdown\n            node.increaseTermTo(response.getTerm(), new Status(RaftError.EHIGHERTERMRESPONSE,\n                    \"Leader receives higher term heartbeat_response from peer:%s\", r.options.getPeerId()));\n            return false;\n        }\n        // 更新最近一次向目标节点发送 RPC 请求的时间戳\n        if (rpcSendTime > r.lastRpcSendTimestamp) {\n            r.lastRpcSendTimestamp = rpcSendTime;\n        }\n        // 重置 inflight 队列，调整 nextIndex 之后重新发送探针请求\n        r.resetInflights();\n        // prev_log_index and prev_log_term doesn't match\n        if (response.getLastLogIndex() + 1 < r.nextIndex) {\n            LOG.debug(\"LastLogIndex at peer={} is {}\", r.options.getPeerId(), response.getLastLogIndex());\n            // The peer contains less logs than leader\n            r.nextIndex = response.getLastLogIndex() + 1;\n        }\n        // Follower 节点本地的 logIndex 更大，可能包含老的 Leader 节点复制的日志，\n        // 递减 nextIndex 之后重试，直到找到两个节点相同日志的交叉点为止\n        else {\n            // The peer contains logs from old term which should be truncated,\n            // decrease _last_log_at_peer by one to test the right index to keep\n            if (r.nextIndex > 1) {\n                LOG.debug(\"logIndex={} dismatch\", r.nextIndex);\n                r.nextIndex--;\n            } else {\n                LOG.error(\"Peer={} declares that log at index=0 doesn't match, which is not supposed to happen\", r.options.getPeerId());\n            }\n        }\n        // dummy_id is unlock in _send_heartbeat\n        // 重新发送探针请求\n        r.sendEmptyEntries(false);\n        return false;\n    }\n\n    /* 目标 Follower 节点响应成功 */\n\n    // 请求期间 term 值已经发生变化，当前节点可能已经不是 Leader 节点，清空 inflight 队列\n    if (response.getTerm() != r.options.getTerm()) {\n        r.resetInflights();\n        r.state = State.Probe;\n        LOG.error(\"Fail, response term {} dismatch, expect term {}\", response.getTerm(), r.options.getTerm());\n        id.unlock();\n        return false;\n    }\n    // 更新最近一次向目标节点发送 RPC 请求的时间戳\n    if (rpcSendTime > r.lastRpcSendTimestamp) {\n        r.lastRpcSendTimestamp = rpcSendTime;\n    }\n    final int entriesSize = request.getEntriesCount();\n    // 如果是复制日志请求，当 Follower 节点复制成功之后需要尝试执行 BallotBox#commitAt 以检测当前日志是否被过半数的节点成功复制\n    if (entriesSize > 0) {\n        if (r.options.getReplicatorType().isFollower()) {\n            // Only commit index when the response is from follower.\n            r.options.getBallotBox().commitAt(r.nextIndex, r.nextIndex + entriesSize - 1, r.options.getPeerId());\n        }\n    }\n\n    r.state = State.Replicate;\n    r.blockTimer = null;\n    // 更新待发送的下一个 logIndex 位置\n    r.nextIndex += entriesSize;\n    r.hasSucceeded = true;\n    r.notifyOnCaughtUp(RaftError.SUCCESS.getNumber(), false);\n    // dummy_id is unlock in _send_entries\n    if (r.timeoutNowIndex > 0 && r.timeoutNowIndex < r.nextIndex) {\n        r.sendTimeoutNow(false, false);\n    }\n    return true;\n}\n```\n\nLeader 节点对于 Follower 节点的探针请求响应处理流程可以概括如下：\n\n1. 校验 inflight 请求与响应中记录的请求对应的已经完成复制的 logIndex 是否一致，如果不是则需要重置 inflight 队列，并重新发送探针请求；\n2. 否则，如果目标 Follower 节点运行异常，则同样需要重置 inflight 队列，并重新发送探针请求；\n3. 否则，说明目标 Follower 节点运行正常，但是目标节点可以同意当前请求，也可以拒绝当前请求，需要分别处理。\n\n__如果目标 Follower 节点拒绝当前请求__ ，按照之前对于 Follower 节点处理 AppendEntries 探针请求过程的分析可知可能包含以下原因：\n\n1. Follower 节点本地的 term 值相对于当前 Leader 节点更大。\n2. Follower 节点本地记录的 Leader 节点 ID 并不是当前 Leader 节点，即可能出现网络分区。\n3. Follower 节点与当前 Leader 节点的日志数据存在冲突。\n\n针对原因 1 和 2，说明集群中已经有更新的 Leader 节点，此时当前节点需要销毁对应的复制器 Replicator 实例，并执行 stepdown 操作。\n\n针对原因 3 需要分为两类情况：\n\n1. 如果目标 Follower 节点本地最新的 logIndex 相对于当前复制器 Replicator 记录的 nextIndex 要小，则需要修正 nextIndex 之后重新发送探针请求。\n2. 如果目标 Follower 节点本地最新的 logIndex 相对于当前复制器 Replicator 记录的 nextIndex 相等或更大，说明目标 Follower 节点包含老的 Leader 节点复制的日志，此时需要递减 nextIndex 值并重新发送探针请求，以解决日志冲突问题。\n\n__如果目标 Follower 节点同意当前请求__ ，则说明 Follower 节点确认当前复制器 Replicator 实例记录的 nextIndex 值是正确的，无需修正 nextIndex 值，接下去可以继续执行往目标 Follower 节点复制日志的操作。\n\n#### 复制日志\n\n上一小节介绍了复制器 Replicator 在启动时会向目标 Follower 节点发送探针请求，以获取目标 Follower 节点已经拥有的日志位置，以便于接下去向 Follower 节点发送后续的日志数据。如果刚刚分析的 `Replicator#onAppendEntriesReturned` 方法处理探针请求对应的响应正常，即返回 true，那么接下去就会触发日志复制的进程，即调用 `Replicator#sendEntries` 方法开始往目标 Follower 节点复制日志数据。\n\n方法 `Replicator#sendEntries` 会尝试计算接下去待发送的 LogEntry 对应的 logIndex 值，如果当前复制器 Replicator 负载较高，则会尝试暂停发送。方法实现如下：\n\n```java\nvoid sendEntries() {\n    boolean doUnlock = true;\n    try {\n        long prevSendIndex = -1;\n        while (true) {\n            // 获取下一个待发送的 LogEntry 对应的 logIndex 值，如果返回 -1 表示暂停复制\n            final long nextSendingIndex = getNextSendIndex();\n            if (nextSendingIndex > prevSendIndex) {\n                // 向目标节点复制 nextSendingIndex 位置之后的 LogEntry 数据\n                if (sendEntries(nextSendingIndex)) {\n                    prevSendIndex = nextSendingIndex;\n                } else {\n                    doUnlock = false;\n                    // id already unlock in sendEntries when it returns false.\n                    break;\n                }\n            } else {\n                break;\n            }\n        }\n    } finally {\n        if (doUnlock) {\n            this.id.unlock();\n        }\n    }\n}\n\nlong getNextSendIndex() {\n    // 没有 inflight 请求，从 nextIndex 开始发送\n    if (this.inflights.isEmpty()) {\n        return this.nextIndex;\n    }\n    // 太多 inflight 请求，暂停发送新的 AppendEntries 请求\n    if (this.inflights.size() > this.raftOptions.getMaxReplicatorInflightMsgs()) {\n        return -1L;\n    }\n    // Last request should be a AppendEntries request and has some entries.\n    // 最近一次发送的 RPC 请求是携带 LogEntry 的 AppendEntries 请求\n    if (this.rpcInFly != null && this.rpcInFly.isSendingLogEntries()) {\n        // 计算并返回接下去待发送的 LogEntry 对应的 logIndex 值\n        return this.rpcInFly.startIndex + this.rpcInFly.count;\n    }\n    return -1L;\n}\n```\n\n方法 `Replicator#sendEntries` 的重载版本 `Replicator#sendEntries(long)` 用于从指定 logIndex 位置开始从本地获取对应的 LogEntry 数据并复制给目标 Follower 节点，整体过程与前面介绍的发送探针请求 `Replicator#sendEmptyEntries` 方法基本类似。这里重点关注一下从本地加载日志数据并填充到 AppendEntries 请求对象中的过程，实现如下：\n\n```java\nByteBufferCollector dataBuf = null;\n// 获取单次批量发送 LogEntry 的数目上线\nfinal int maxEntriesSize = this.raftOptions.getMaxEntriesSize();\nfinal RecyclableByteBufferList byteBufList = RecyclableByteBufferList.newInstance();\ntry {\n    for (int i = 0; i < maxEntriesSize; i++) {\n        final RaftOutter.EntryMeta.Builder emb = RaftOutter.EntryMeta.newBuilder();\n        // 获取指定 logIndex 的 LogEntry 数据，填充到 emb 和 byteBufList 中，\n        // 如果返回 false 说明容量已满\n        if (!prepareEntry(nextSendingIndex, i, emb, byteBufList)) {\n            break;\n        }\n        rb.addEntries(emb.build());\n    }\n\n    // 未获取到任何 LogEntry 数据，可能目标数据已经变为快照了，也可能是真的没有数据可以复制\n    if (rb.getEntriesCount() == 0) {\n        // nextSendingIndex < firstLogIndex，说明对应区间的数据已变为快照，需要先给目标节点安装快照\n        if (nextSendingIndex < this.options.getLogManager().getFirstLogIndex()) {\n            installSnapshot();\n            return false;\n        }\n        // 说明没有新的数据可以复制，设置一个回调等待新的数据到来之后重新触发 sendEntries 操作\n        waitMoreEntries(nextSendingIndex);\n        return false;\n    }\n\n    // 将日志数据填充到 AppendEntries 请求中\n    if (byteBufList.getCapacity() > 0) {\n        dataBuf = ByteBufferCollector.allocateByRecyclers(byteBufList.getCapacity());\n        for (final ByteBuffer b : byteBufList) {\n            dataBuf.put(b);\n        }\n        final ByteBuffer buf = dataBuf.getBuffer();\n        buf.flip();\n        rb.setData(ZeroByteStringHelper.wrap(buf));\n    }\n} finally {\n    RecycleUtil.recycle(byteBufList);\n}\n```\n\nJRaft 在 AppendEntries 请求的设计上采用了将 LogEntry 的元数据和数据体相分离的策略，所以上述从本地加载日志数据的过程会先填充元数据，再填充数据体。实现上使用 RecyclableByteBufferList 作为数据体的载体，RecyclableByteBufferList 可以看做是一个可回收利用的 ByteBuffer 链表，实现层面借鉴了 Netty 的轻量级对象池的设计思想。\n\n下面来看一下从本地加载日志数据并填充 AppendEntries 请求的过程，由 `Replicator#prepareEntry` 方法实现：\n\n```java\nboolean prepareEntry(final long nextSendingIndex,\n                     final int offset,\n                     final RaftOutter.EntryMeta.Builder emb,\n                     final RecyclableByteBufferList dataBuffer) {\n    // 数据量已经超过阈值\n    if (dataBuffer.getCapacity() >= this.raftOptions.getMaxBodySize()) {\n        return false;\n    }\n    // 基于偏移量计算当前处理的 LogEntry 的 logIndex 值\n    final long logIndex = nextSendingIndex + offset;\n    // 从本地获取对应的 LogEntry 数据\n    final LogEntry entry = this.options.getLogManager().getEntry(logIndex);\n    if (entry == null) {\n        return false;\n    }\n    // 将 LogEntry 拆分为元数据和数据体分别填充 EntryMeta 和 RecyclableByteBufferList\n    emb.setTerm(entry.getId().getTerm());\n    // 设置 checksum\n    if (entry.hasChecksum()) {\n        emb.setChecksum(entry.getChecksum()); // since 1.2.6\n    }\n    // 设置 LogEntry 类型\n    emb.setType(entry.getType());\n    if (entry.getPeers() != null) {\n        Requires.requireTrue(!entry.getPeers().isEmpty(), \"Empty peers at logIndex=%d\", logIndex);\n        fillMetaPeers(emb, entry);\n    } else {\n        Requires.requireTrue(entry.getType() != EnumOutter.EntryType.ENTRY_TYPE_CONFIGURATION,\n                \"Empty peers but is ENTRY_TYPE_CONFIGURATION type at logIndex=%d\", logIndex);\n    }\n    // 设置数据长度\n    final int remaining = entry.getData() != null ? entry.getData().remaining() : 0;\n    emb.setDataLen(remaining);\n    // 填充数据到 dataBuffer\n    if (entry.getData() != null) {\n        // should slice entry data\n        dataBuffer.add(entry.getData().slice());\n    }\n    return true;\n}\n```\n\n上述实现依据偏移量计算得到最终的 logIndex 值，然后调用 `LogManagerImpl#getEntry` 方法从文件系统加载获取到对应的 LogEntry 数据，最后将 LogEntry 中的元数据和数据体拆分后分别填充到 EntryMeta 和 RecyclableByteBufferList 对象中。JRaft 默认采用 RocksDB 作为日志数据的存储引擎，其中 key 就是 LogEntry 对应的 logIndex 值，所以方法 `LogManagerImpl#getEntry` 的执行过程简单来说就是依据 logIndex 从 RocksDB 中获取对应数据的过程。\n\n如果从本地获取不到 logIndex 对应的日志数据，那么可能存在两种原因：\n\n1. 需要复制的数据已经变为快照形式存储。\n2. 没有可以复制的数据。\n\n针对第一种情况直接给目标 Follower 节点安装快照即可，针对第二种情况则立即退出当前 `Replicator#sendEntries` 方法，并设置一个回调等待新的日志数据。关于快照机制将在后面用专门的篇章进行介绍，这里我们主要来看一下针对情况二的处理过程，位于 `Replicator#waitMoreEntries` 方法中：\n\n```java\nprivate void waitMoreEntries(final long nextWaitIndex) {\n    try {\n        LOG.debug(\"Node {} waits more entries\", this.options.getNode().getNodeId());\n        // 已经设置过等待\n        if (this.waitId >= 0) {\n            return;\n        }\n        // 设置一个回调，当有可复制日志时触发再次往目标 Follower 节点发送数据\n        this.waitId = this.options.getLogManager().wait(\n                nextWaitIndex - 1,\n                (arg, errorCode) -> continueSending((ThreadId) arg, errorCode), this.id);\n        this.statInfo.runningState = RunningState.IDLE;\n    } finally {\n        this.id.unlock();\n    }\n}\n\n// com.alipay.sofa.jraft.storage.impl.LogManagerImpl#wait\npublic long wait(final long expectedLastLogIndex, final NewLogCallback cb, final Object arg) {\n    final WaitMeta wm = new WaitMeta(cb, arg, 0);\n    return notifyOnNewLog(expectedLastLogIndex, wm);\n}\n\nprivate long notifyOnNewLog(final long expectedLastLogIndex, final WaitMeta wm) {\n    this.writeLock.lock();\n    try {\n        // 已经有新的日志可复制，或者当前 LogManager 已被停止\n        if (expectedLastLogIndex != this.lastLogIndex || this.stopped) {\n            wm.errorCode = this.stopped ? RaftError.ESTOP.getNumber() : 0;\n            Utils.runInThread(() -> runOnNewLog(wm));\n            return 0L;\n        }\n        if (this.nextWaitId == 0) { //skip 0\n            ++this.nextWaitId;\n        }\n        final long waitId = this.nextWaitId++;\n        // 记录等待的信息\n        this.waitMap.put(waitId, wm);\n        return waitId;\n    } finally {\n        this.writeLock.unlock();\n    }\n}\n```\n\n上述实现会针对期望的 logIndex 设置一个回调，如果本地最新的 logIndex 超过该期望值则说明有新的日志数据可以被复制，会触发执行 `Replicator#continueSending` 操作，实现如下：\n\n```java\nstatic boolean continueSending(final ThreadId id, final int errCode) {\n    // 当前 Replicator 已被销毁\n    if (id == null) {\n        // It was destroyed already\n        return true;\n    }\n    final Replicator r = (Replicator) id.lock();\n    if (r == null) {\n        return false;\n    }\n    r.waitId = -1;\n    // 超时，重新发送探针请求\n    if (errCode == RaftError.ETIMEDOUT.getNumber()) {\n        r.blockTimer = null;\n        // Send empty entries after block timeout to check the correct\n        // _next_index otherwise the replicator is likely waits in executor.shutdown();\n        // _wait_more_entries and no further logs would be replicated even if the\n        // last_index of this followers is less than |next_index - 1|\n        r.sendEmptyEntries(false);\n    }\n    // LogManager 正常运行，继续尝试向目标 Follower 节点发送数据\n    else if (errCode != RaftError.ESTOP.getNumber()) {\n        // id is unlock in _send_entries\n        r.sendEntries();\n    }\n    // LogManager 被停止，停止向目标节点发送日志数据\n    else {\n        LOG.warn(\"Replicator {} stops sending entries.\", id);\n        id.unlock();\n    }\n    return true;\n}\n```\n\n由此可见，回调逻辑会再次尝试执行前面所介绍的 `Replicator#sendEntries` 逻辑。上述回调另外一个被触发的场景则在于调用 `LogManager#appendEntries` 追加新的日志数据的时候，这也是比较容易理解的。\n\n完成了对于 AppendEntries 请求的构造，接下去复制器 Replicator 会采用 RPC 的方式将该请求发送给目标 Follower 节点。下面来看一下 Follower 节点对于复制日志数据 AppendEntries 请求的处理过程，位于 `NodeImpl#handleAppendEntriesRequest` 方法中。关于该方法我们前面在分析探针请求时已经介绍过，所以下面重点来看一下 Follower 节点针对日志数据复制操作相关的处理逻辑，实现如下：\n\n```java\n// Parse request\nlong index = prevLogIndex;\nfinal List<LogEntry> entries = new ArrayList<>(entriesCount);\nByteBuffer allData = null;\nif (request.hasData()) {\n    allData = request.getData().asReadOnlyByteBuffer();\n}\n\nfinal List<RaftOutter.EntryMeta> entriesList = request.getEntriesList();\n// 遍历逐一解析请求中的 LogEntry 数据，记录到 entries 列表中\nfor (int i = 0; i < entriesCount; i++) {\n    index++;\n    // 获取 LogEntry 元数据信息\n    final RaftOutter.EntryMeta entry = entriesList.get(i);\n\n    // 基于元数据和数据体构造 LogEntry 对象\n    final LogEntry logEntry = logEntryFromMeta(index, allData, entry);\n\n    if (logEntry != null) {\n        // 如果启用了 checksum 机制，则校验 checksum 值\n        if (this.raftOptions.isEnableLogEntryChecksum() && logEntry.isCorrupted()) {\n            // checksum 值不匹配，说明数据可能被篡改\n            long realChecksum = logEntry.checksum();\n            LOG.error(\n                    \"Corrupted log entry received from leader, index={}, term={}, expectedChecksum={}, realChecksum={}\",\n                    logEntry.getId().getIndex(), logEntry.getId().getTerm(), logEntry.getChecksum(), realChecksum);\n            return RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(AppendEntriesResponse.getDefaultInstance(), RaftError.EINVAL,\n                            \"The log entry is corrupted, index=%d, term=%d, expectedChecksum=%d, realChecksum=%d\",\n                            logEntry.getId().getIndex(), logEntry.getId().getTerm(), logEntry.getChecksum(), realChecksum);\n        }\n        entries.add(logEntry);\n    }\n}\n\nfinal FollowerStableClosure closure = new FollowerStableClosure(request,\n        AppendEntriesResponse.newBuilder().setTerm(this.currTerm), this, done, this.currTerm);\n// 将 LogEntry 数据写入本地磁盘\nthis.logManager.appendEntries(entries, closure);\n// update configuration after _log_manager updated its memory status\ncheckAndSetConfiguration(true);\nreturn null;\n```\n\n针对复制日志数据的 AppendEntries 请求，Follower 节点会基于请求中的 LogEntry 元数据和数据体信息逐一解析构造对应的 LogEntry 对象（实现如下），并调用 `LogManager#appendEntries` 方法批量的将日志数据写入本地存储系统，关于 `LogManager#appendEntries` 方法已在前面分析过。\n\n```java\nprivate LogEntry logEntryFromMeta(final long index, final ByteBuffer allData, final RaftOutter.EntryMeta entry) {\n    // 忽略 ENTRY_TYPE_UNKNOWN 类型的 LogEntry 数据\n    if (entry.getType() != EnumOutter.EntryType.ENTRY_TYPE_UNKNOWN) {\n        // 给 LogEntry 对象填充基本的元数据信息\n        final LogEntry logEntry = new LogEntry();\n        logEntry.setId(new LogId(index, entry.getTerm()));\n        logEntry.setType(entry.getType());\n        if (entry.hasChecksum()) {\n            logEntry.setChecksum(entry.getChecksum()); // since 1.2.6\n        }\n\n        // 基于元数据中记录的数据长度获取对应的 LogEntry 数据体，并填充到 LogEntry 对象中\n        final long dataLen = entry.getDataLen();\n        if (dataLen > 0) {\n            final byte[] bs = new byte[(int) dataLen];\n            assert allData != null;\n            allData.get(bs, 0, bs.length);\n            logEntry.setData(ByteBuffer.wrap(bs));\n        }\n\n        // 针对 ENTRY_TYPE_CONFIGURATION 类型的 LogEntry，解析并填充集群节点配置数据\n\n        if (entry.getPeersCount() > 0) {\n            if (entry.getType() != EnumOutter.EntryType.ENTRY_TYPE_CONFIGURATION) {\n                throw new IllegalStateException(\n                        \"Invalid log entry that contains peers but is not ENTRY_TYPE_CONFIGURATION type: \" + entry.getType());\n            }\n\n            // 填充集群节点配置信息\n            fillLogEntryPeers(entry, logEntry);\n        } else if (entry.getType() == EnumOutter.EntryType.ENTRY_TYPE_CONFIGURATION) {\n            throw new IllegalStateException(\n                    \"Invalid log entry that contains zero peers but is ENTRY_TYPE_CONFIGURATION type\");\n        }\n        return logEntry;\n    }\n    return null;\n}\n```\n\n日志数据写入磁盘是一个异步的过程，当日志数据成功在 Follower 节点落盘之后，Follower 节点会向 Leader 节点发送 AppendEntries 响应。最后来看一下 Leader 节点针对复制日志数据的 AppendEntries 请求响应的处理过程，由前面对于 JRaft Pipeline 机制的介绍可知这里处理 AppendEntries 请求响应的过程由 `Replicator#onAppendEntriesReturned` 方法实现。前面在介绍探针请求时同样分析过该方法的实现，针对复制日志数据的 AppendEntries 请求响应的处理重点关注下面这样一段逻辑：\n\n```java\n// 如果是复制日志请求，当 Follower 节点复制成功之后需要尝试执行 BallotBox#commitAt 以检测当前日志是否被过半数的节点成功复制\nif (entriesSize > 0) {\n    if (r.options.getReplicatorType().isFollower()) {\n        // Only commit index when the response is from follower.\n        r.options.getBallotBox().commitAt(r.nextIndex, r.nextIndex + entriesSize - 1, r.options.getPeerId());\n    }\n    if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Replicated logs in [{}, {}] to peer {}\", r.nextIndex, r.nextIndex + entriesSize - 1, r.options.getPeerId());\n    }\n}\n```\n\n如果是针对复制日志数据的 AppendEntries 请求的响应，如果响应来自 Follower 节点则会触发执行 `BallotBox#commitAt` 方法以检查当前批次的日志数据是否能够被提交，即是否有超过半数的节点完成了对于该批次日志数据的复制操作，如果是则会触发 Leader 节点将该批次的日志数据标记为 committed。\n\n前面在介绍日志数据生成流程时我们也曾遇到过该方法，当 Leader 节点完成对于该批次日志数据的落盘之后会回调该方法检查该批次的日志数据是否允许被提交，只不过那时是由 Leader 节点触发这一检查的过程，而这里则是由各个 Follower 节点所触发，本质上这也是一种投票机制。关于 `BallotBox#commitAt` 方法的实现已在前面介绍日志生成流程时分析过，不再重复介绍。\n\n#### 心跳机制\n\n复制器 Replicator 中的字段 `Replicator#lastRpcSendTimestamp` 用于记录最近一次成功向目标 Follower 节点发送 RPC 请求的时间戳。上一篇我们在分析 JRaft 选主机制时曾介绍过 Leader 节点会基于该时间戳判断目标 Follower 节点是否处于活跃状态，所以我们可以认为该字段是目标 Follower 节点心跳正常的判定标志，对于一个心跳正常的 Follower 节点，该字段的值距离当前时间戳应该始终控制在一个合理的阈值范围内。\n\n前面介绍的探针请求和复制日志数据请求都会在处理请求响应时更新该字段，不过仅靠这两类请求触发时间戳更新显然是不够的，毕竟整个 JRaft 集群不会始终处于频繁的日志数据复制状态。为此，JRaft 还在复制器 Replicator 中实现了一套心跳机制，本小节我们就深入分析这一套心跳机制的执行流程。\n\n当启动一个复制器 Replicator 实例时（即调用 `Replicator#start` 方法）会执行 `Replicator#startHeartbeatTimer` 方法启动心跳计时器，该计时器会延迟指定时间（默认为 100ms）执行 `Replicator#onTimeout` 操作给当前复制器添加一个 `ETIMEDOUT` 事件，实现如下：\n\n```java\nprivate static void onTimeout(final ThreadId id) {\n    if (id != null) {\n        // ETIMEDOUT 错误会触发再次向目标节点发送心跳请求\n        id.setError(RaftError.ETIMEDOUT.getNumber());\n    } else {\n        LOG.warn(\"Replicator id is null when timeout, maybe it's destroyed.\");\n    }\n}\n```\n\n而复制器 Replicator 对于此类事件的处理逻辑就是调用 `Replicator#sendHeartbeat` 方法向目标 Follower 节点发送心跳请求：\n\n```java\nprivate static void sendHeartbeat(final ThreadId id) {\n    final Replicator r = (Replicator) id.lock();\n    if (r == null) {\n        return;\n    }\n    // 向目标 Follower 节点发送心跳请求\n    r.sendEmptyEntries(true);\n}\n```\n\n由上述实现可以看到，所谓的心跳请求本质上还是一个空的 AppendEntries 请求。关于方法 `Replicator#sendEmptyEntries` 在前面介绍探针请求时已经分析过，而关于心跳请求的实现逻辑如下：\n\n```java\nif (isHeartbeat) {\n    // Sending a heartbeat request\n    this.heartbeatCounter++;\n    RpcResponseClosure<AppendEntriesResponse> heartbeatDone;\n    // 参数指定的响应回调优先\n    if (heartBeatClosure != null) {\n        heartbeatDone = heartBeatClosure;\n    }\n    // 设置默认的心跳请求响应回调\n    else {\n        heartbeatDone = new RpcResponseClosureAdapter<AppendEntriesResponse>() {\n\n            @Override\n            public void run(final Status status) {\n                onHeartbeatReturned(Replicator.this.id, status, request, getResponse(), monotonicSendTimeMs);\n            }\n        };\n    }\n    // 发送心跳请求\n    this.heartbeatInFly = this.rpcService.appendEntries(\n            this.options.getPeerId().getEndpoint(),\n            request,\n            this.options.getElectionTimeoutMs() / 2,\n            heartbeatDone);\n}\n```\n\nFollower 节点对于心跳请求的处理逻辑与探针请求一致，所以下面来看一下 Leader 节点对于心跳请求响应的处理流程。对于发送心跳请求而言，JRaft 允许调用方自定义响应回调，目前这一块主要服务于线性一致性读操作，下面来分析一下默认的心跳请求响应回调逻辑，由 `Replicator#onHeartbeatReturned` 方法实现（省略部分 DEBUG 日志）：\n\n```java\nstatic void onHeartbeatReturned(final ThreadId id,\n                                final Status status,\n                                final AppendEntriesRequest request,\n                                final AppendEntriesResponse response,\n                                final long rpcSendTime) {\n    // 复制器已经被销毁\n    if (id == null) {\n        // replicator already was destroyed.\n        return;\n    }\n    final long startTimeMs = Utils.nowMs();\n    Replicator r;\n    if ((r = (Replicator) id.lock()) == null) {\n        return;\n    }\n    boolean doUnlock = true;\n    try {\n        // Follower 节点运行异常\n        if (!status.isOk()) {\n            r.state = State.Probe;\n            notifyReplicatorStatusListener(r, ReplicatorEvent.ERROR, status);\n            if (++r.consecutiveErrorTimes % 10 == 0) {\n                LOG.warn(\"Fail to issue RPC to {}, consecutiveErrorTimes={}, error={}\",\n                        r.options.getPeerId(), r.consecutiveErrorTimes, status);\n            }\n            // 重新启动心跳计时器\n            r.startHeartbeatTimer(startTimeMs);\n            return;\n        }\n        r.consecutiveErrorTimes = 0;\n        // 目标 Follower 节点的 term 值更大，说明有新的 Leader 节点\n        if (response.getTerm() > r.options.getTerm()) {\n            final NodeImpl node = r.options.getNode();\n            r.notifyOnCaughtUp(RaftError.EPERM.getNumber(), true);\n            // 销毁当前复制器\n            r.destroy();\n            // 递增当前节点的 term 值\n            node.increaseTermTo(response.getTerm(), new Status(RaftError.EHIGHERTERMRESPONSE,\n                    \"Leader receives higher term heartbeat_response from peer:%s\", r.options.getPeerId()));\n            return;\n        }\n        // Follower 节点拒绝响应，重新发送探针请求，并启动心跳计时器\n        if (!response.getSuccess() && response.hasLastLogIndex()) {\n            LOG.warn(\"Heartbeat to peer {} failure, try to send a probe request.\", r.options.getPeerId());\n            doUnlock = false;\n            r.sendEmptyEntries(false);\n            r.startHeartbeatTimer(startTimeMs);\n            return;\n        }\n\n        // 更新 RPC 请求时间戳\n        if (rpcSendTime > r.lastRpcSendTimestamp) {\n            r.lastRpcSendTimestamp = rpcSendTime;\n        }\n        // 启动心跳计时器\n        r.startHeartbeatTimer(startTimeMs);\n    } finally {\n        if (doUnlock) {\n            id.unlock();\n        }\n    }\n}\n```\n\n如果目标 Follower 节点运行异常，则不应该更新复制器 Replicator 的 `Replicator#lastRpcSendTimestamp` 字段，这无可厚非。如果目标 Follower 节点运行正常，但是拒绝当前的心跳请求，按照之前的总结分为以下三种原因：\n\n1. Follower 节点本地的 term 值相对于当前 Leader 节点更大。\n2. Follower 节点本地记录的 Leader 节点 ID 并不是当前 Leader 节点，即可能出现网络分区。\n3. Follower 节点与当前 Leader 节点的日志数据存在冲突。\n\n其中只有第三种情况会在响应中携带 Follower 节点的最新 logIndex 值，此时心跳请求会触发向目标 Follower 节点发送探针请求，并在探针请求响应中更新 RPC 发送时间戳。然而，不管是上述哪种原因导致 Follower 节点拒绝响应，亦或是同意响应，复制器 Replicator 都会再次调用 `Replicator#startHeartbeatTimer` 方法进入下一轮心跳进程。\n\n### 总结\n\n本文分析了 JRaft 关于 Raft 算法日志数据复制机制的设计与实现，包括日志的生成过程、探寻待发送的日志位置、复制日志数据、心跳机制，以及 Pipeline 机制等。日志数据复制是 Raft 算法运行的基础，是一项重要且频繁的操作，实现层面的优劣直接影响着 Raft 算法库的运行效率。为此，JRaft 引入了多种优化策略，包括 Follower 节点之间并发复制、批量发送，以及 Pipeline 机制。\n\n关于日志复制，实际上快照机制从广义上来说也属于日志复制范畴，准确来说是对日志复制的有一种优化手段，不过快照机制也有其自身独有的特点和应用场景，并且是一项可选的功能，所以我将其与常规的日志复制区别开来，下一篇将对该机制进行针对性的分析。\n\n### 参考\n\n1. [Raft Consensus Algorithm](https://raft.github.io/)\n2. [SOFA-JRaft 官网](https://www.sofastack.tech/projects/sofa-jraft/overview/)\n3. [SOFA-JRaft 日志复制：pipeline 实现剖析](https://www.sofastack.tech/blog/sofa-jraft-pipeline-principle/)\n","tags":["Raft","SOFA-JRaft"],"categories":["sofa"]},{"title":"SOFA-JRaft 源码解析：主节点选举机制","url":"/2020/06/08/sofa/sofa-jraft-leader-election/","content":"\n主节点选举（Leader Election）是 Raft 算法的核心组成部分，也是 Raft 算法库的主要应用场景之一。Raft 算法设计了 term 和 logIndex 两个属性，分别用于表示 Leader 节点的任期，以及集群运行期间接收到的指令对应的日志条目的 ID，这两个属性都是单调递增的。一个 Leader 节点在任期内会始终向其管理的所有 Follower 节点宣示主权，以避免这些 Follower 节点发动革命，推翻自己的政权，成为新的 Leader 节点。然而，世事无常，如果 Leader 节点因为某些原因不能或未能即时向某些 Follower 节点宣示自己的主权，则这些 Follower 节点在等待一段随机的时间之后就会尝试竞选成为新的 Leader 节点。\n\n之所以这里采用随机化的等待时间，是为了避免两个或多个 Follower 节点同时发起选举进程，进而出现这些节点都没有赢得过半数的选票。于是，这些节点又在同一时间发起下一轮选举进程，延长了集群无 Leader 节点的时间，而通过随机化各个 Follower 节点等待的时间则能够很好的解决此类问题。<!-- more -->\n\n当然，也并不是所有的 Follower 节点都有参选的资格，Raft 算法要求节点在给参选节点投票时必须保证参选节点满足以下两个条件之一：\n\n1. 参选节点的 term 值大于投票节点，否则拒绝为其投票。\n2. 如果参选节点与投票节点的 term 值相同，则需要保证参选节点的 logIndex 值不小于投票节点。\n\n这两个条件的目的都在于保证当前参选节点本地的日志数据不能比投票节点要陈旧。\n\n上一篇我们分析了 JRaft 算法库的整体架构和节点的初始化启动过程，当一个节点启动之后即会启动对应的预选举计时器，不断检查 Leader 节点的有效性，并随时准备发动新一轮的选举革命，本文我们就针对 JRaft 关于主节点选举的实现展开分析。\n\n### Leader 选举\n\nJRaft 在设计层面将选举的过程拆分为预选举和正式选举两个过程，之所以这样设计是为了避免无效的选举进程递增 term 值，进而造成浪费，同时也会导致正常运行的 Leader 节点执行角色降级。Raft 算法要求当节点接收到 term 值更大的请求时需要递增本地的 term 值，以此实现集群中 term 值的同步。对于 Leader 节点而言，当收到 term 值更大的请求时，该节点会认为集群中有新的 Leader 节点生成，于是需要执行角色降级。这一机制能够保证在出现网络分区等问题时，在网络恢复时能够促使 term 值较小的 Leader 节点退位为 Follower 节点，从而实现让集群达到一个新的平稳状态。然而，如果集群中某个 Follower 节点因为某些原因未能接收到 Leader 节点的主权宣示指令，就会一直尝试发动新一轮的选举革命，进而递增 term 值，导致 Leader 节点执行角色降级，最终影响整个集群的正常运行。\n\n预选举的引入则能够很好的解决此类问题，当一个 Follower 节点尝试发起一轮新的选举革命时，该节点不会立即递增 term 值，而是尝试将 term 值加 1 去试探性的征集选票，只有当集群中过半数的节点同意投票的前提下才会进入正式投票的环节，这样对于无效选举而言一般只会停留在预选举阶段，不会对集群的正常运行造成影响。\n\n下面来看一下 JRaft 关于预选举和正式选举的具体实现。\n\n#### 预选举\n\n当启动一个 JRaft 节点时，如果初始化集群节点配置不为空，则节点会调用 `NodeImpl#stepDown` 方法执行角色降级操作。所谓角色降级实际上是一个宽泛的说法，因为 `NodeImpl#stepDown` 方法会在多种场景下被调用。而这里调用该方法的背景是一个 FOLLOWER 节点刚刚启动的时候，所以除了初始化一些本地状态之外，整个角色降级过程重点做的一件事就是启动预选举计时器 electionTimer。\n\n预选举计时器 electionTimer 是一个典型的 RepeatedTimer 应用，关于 RepeatedTimer 的实现和运行机制我们在上一篇已经介绍过，本小节我们重点关注在预选举场景下该计时器针对 `RepeatedTimer#onTrigger` 方法的实现。\n\n```java\nthis.electionTimer = new RepeatedTimer(name, this.options.getElectionTimeoutMs(),\n        TIMER_FACTORY.getElectionTimer(this.options.isSharedElectionTimer(), name)) {\n\n    @Override\n    protected void onTrigger() {\n        handleElectionTimeout();\n    }\n\n    @Override\n    protected int adjustTimeout(final int timeoutMs) {\n        return randomTimeout(timeoutMs);\n    }\n};\n```\n\n方法 `RepeatedTimer#onTrigger` 会被计时器周期性调度，而具体的执行逻辑则委托给 `NodeImpl#handleElectionTimeout` 方法执行。为了尽量避免多个节点同时发起预选举请求，计时器 electionTimer 覆盖实现了 `RepeatedTimer#adjustTimeout` 方法，以实现对于调度周期进行随机化处理，默认随机区间为 1~2s。\n\n方法 `NodeImpl#handleElectionTimeout` 是预选举的入口，实现如下：\n\n```java\nprivate void handleElectionTimeout() {\n    boolean doUnlock = true;\n    this.writeLock.lock();\n    try {\n        // 预选举必须由 Follower 节点发起\n        if (this.state != State.STATE_FOLLOWER) {\n            return;\n        }\n\n        // 与当前 Leader 节点的租约还有效，暂不发起预选举\n        if (isCurrentLeaderValid()) {\n            return;\n        }\n\n        /* 尝试开始发起预选举 */\n\n        // 清空本地记录的 leaderId\n        resetLeaderId(PeerId.emptyPeer(),\n                new Status(RaftError.ERAFTTIMEDOUT, \"Lost connection from leader %s.\", this.leaderId));\n\n        // 基于节点优先级判断是否继续发起预选举\n        if (!allowLaunchElection()) {\n            return;\n        }\n\n        doUnlock = false;\n        // 发起预选举\n        preVote();\n    } finally {\n        if (doUnlock) {\n            this.writeLock.unlock();\n        }\n    }\n}\n```\n\n上述方法的执行流程可以概括如下：\n\n1. 如果当前节点不是 FOLLOWER 角色，则放弃预选举；\n2. 否则，如果当前节点与 Leader 节点之间的租约仍然有效，则放弃预选举；\n3. 否则，清空本地记录的 Leader 节点 ID，回调 `FSMCaller#onStopFollowing` 方法；\n4. 基于节点优先级判断是否允许发起预选举，如果允许则发起预选举进程。\n\nFollower 节点会在本地记录最近一次收到来自 Leader 节点的 RPC 请求时间戳，如果该时间戳距离当前时间小于选举超时时间，则说明当前节点与 Leader 节点之间的租约仍然有效，无需继续发起预选举。\n\n方法 `NodeImpl#resetLeaderId` 会清空本地记录的 Leader 节点 ID，如果当前节点不是 Leader 角色，并且正在追随某个 Leader 节点，则该方法会回调 `FSMCaller#onStopFollowing` 方法将停止追随的事件透传给状态机。业务可以通过覆盖实现 `StateMachine#onStopFollowing` 方法捕获这一事件。\n\n如果当前节点的优先级允许当前节点继续发起预选举，则接下去会调用 `NodeImpl#preVote` 方法发起预选举进程，具体实现如下：\n\n```java\nprivate void preVote() {\n    long oldTerm;\n    try {\n        LOG.info(\"Node {} term {} start preVote.\", getNodeId(), this.currTerm);\n        // 当前节点正在安装快照，则放弃预选举\n        if (this.snapshotExecutor != null && this.snapshotExecutor.isInstallingSnapshot()) {\n            LOG.warn(\"Node {} term {} doesn't do preVote when installing snapshot as the configuration may be out of date.\",\n                    getNodeId(), this.currTerm);\n            return;\n        }\n        // 当前节点不是一个有效的节点\n        if (!this.conf.contains(this.serverId)) {\n            LOG.warn(\"Node {} can't do preVote as it is not in conf <{}>.\", getNodeId(), this.conf);\n            return;\n        }\n        oldTerm = this.currTerm;\n    } finally {\n        this.writeLock.unlock();\n    }\n\n    // 从本地磁盘获取最新的 LogId\n    final LogId lastLogId = this.logManager.getLastLogId(true);\n\n    boolean doUnlock = true;\n    this.writeLock.lock();\n    try {\n        // pre_vote need defense ABA after unlock&writeLock\n        if (oldTerm != this.currTerm) {\n            LOG.warn(\"Node {} raise term {} when get lastLogId.\", getNodeId(), this.currTerm);\n            return;\n        }\n\n        // 初始化预选举选票\n        this.prevVoteCtx.init(this.conf.getConf(), this.conf.isStable() ? null : this.conf.getOldConf());\n        // 遍历向除自己以外的所有连通节点发送 RequestVote RPC 请求，以征集选票\n        for (final PeerId peer : this.conf.listPeers()) {\n            if (peer.equals(this.serverId)) {\n                continue;\n            }\n            if (!this.rpcService.connect(peer.getEndpoint())) {\n                LOG.warn(\"Node {} channel init failed, address={}.\", getNodeId(), peer.getEndpoint());\n                continue;\n            }\n            final OnPreVoteRpcDone done = new OnPreVoteRpcDone(peer, this.currTerm);\n            done.request = RequestVoteRequest.newBuilder() //\n                    .setPreVote(true) // it's a pre-vote request. 标记为预选举\n                    .setGroupId(this.groupId) //\n                    .setServerId(this.serverId.toString()) //\n                    .setPeerId(peer.toString()) //\n                    .setTerm(this.currTerm + 1) // next term，预选举阶段不会真正递增 term 值\n                    .setLastLogIndex(lastLogId.getIndex()) //\n                    .setLastLogTerm(lastLogId.getTerm()) //\n                    .build();\n            // 发送请求\n            this.rpcService.preVote(peer.getEndpoint(), done.request, done);\n        }\n        // 自己给自己投上一票\n        this.prevVoteCtx.grant(this.serverId);\n        // 检查是否赢得选票\n        if (this.prevVoteCtx.isGranted()) {\n            doUnlock = false;\n            // 如果赢得选票，则继续发起选举进程\n            electSelf();\n        }\n    } finally {\n        if (doUnlock) {\n            this.writeLock.unlock();\n        }\n    }\n}\n```\n\n预选举的整体执行流程可以概括如下：\n\n1. 校验当前节点是否正在安装快照，如果是则放弃预选举；\n2. 校验当前节点是否位于节点配置列表中，如果不是则说明当前节点不是一个有效节点，放弃预选举；\n3. 从本地磁盘获取最新的 LogId，包含 logIndex 和 term 值；\n4. 初始化预选举选票 Ballot 实例；\n5. 遍历向除自己以外的所有连通节点发送 RequestVote RPC 请求，以征集选票，同时给自己投上一票；\n6. 如果票数过半，则执行 `NodeImpl#electSelf` 操作进入正式投票环节。\n\n整体流程比较直观，其中方法 `NodeImpl#electSelf` 属于正式投票环境，我们将在下一小节展开分析，本小节我们继续关注以下两个方面：\n\n1. LogManager 加载最新 logIndex 和对应 term 值的过程。\n2. 节点对于 RequestVote RPC 预选举请求的处理过程。\n\n##### 加载最新 LogId 数据\n\n上一篇我们分析了 LogManager 的初始化过程，本小节我们继续分析 LogManager 是如何从本地加载返回最新的 logIndex 和对应 term 值数据的，即 `LogManager#getLastLogId` 方法。该方法接收一个 boolean 类型参数，用于设置是否需要将内存中的数据刷盘，实现如下：\n\n```java\npublic LogId getLastLogId(final boolean isFlush) {\n    LastLogIdClosure c;\n    this.readLock.lock();\n    try {\n        // 直接返回内存中记录的 lastLogIndex，以及对应的 term 值\n        if (!isFlush) {\n            if (this.lastLogIndex >= this.firstLogIndex) {\n                return new LogId(this.lastLogIndex, unsafeGetTerm(this.lastLogIndex));\n            }\n            return this.lastSnapshotId;\n        }\n        // 将内存中的数据刷盘，并返回最新的 logIndex 和对应的 term 值\n        else {\n            // 生成快照之后未产生新的数据\n            if (this.lastLogIndex == this.lastSnapshotId.getIndex()) {\n                return this.lastSnapshotId;\n            }\n            c = new LastLogIdClosure();\n            // 往消息队列中发布一个 LAST_LOG_ID 事件\n            offerEvent(c, EventType.LAST_LOG_ID);\n        }\n    } finally {\n        this.readLock.unlock();\n    }\n\n    // 等待刷盘完成\n    try {\n        c.await();\n    } catch (final InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new IllegalStateException(e);\n    }\n    return c.lastLogId;\n}\n```\n\n前面在分析 LogManager 初始化过程时我们介绍了 LogManager 在初始化期间会启动一个 Disruptor 消息队列，并对其运行流程进行了简单的介绍。上述方法如果设置 `isFlush = true` 则会往该队列提交一个 `LAST_LOG_ID` 类型事件，并阻塞等待该事件处理完成。方法 `StableClosureEventHandler#onEvent` 中实现了对 Disruptor 中消息的处理逻辑，并定义了一个 AppendBatcher 类型的属性用于缓存收集到的 LogEntry 数据。在响应 `LAST_LOG_ID` 事件之前，StableClosureEventHandler 会调用 `AppendBatcher#flush` 方法将收集到的 LogEntry 数据刷盘，实现如下：\n\n```java\nLogId flush() {\n    if (this.size > 0) {\n        // 将数据落盘，并返回最新的 LogId\n        this.lastId = appendToStorage(this.toAppend);\n        for (int i = 0; i < this.size; i++) {\n            // 清空缓存的 LogEntry 数据\n            this.storage.get(i).getEntries().clear();\n            Status st = null;\n            try {\n                if (LogManagerImpl.this.hasError) {\n                    // LogManager 运行异常\n                    st = new Status(RaftError.EIO, \"Corrupted LogStorage\");\n                } else {\n                    st = Status.OK();\n                }\n                // 回调响应\n                this.storage.get(i).run(st);\n            } catch (Throwable t) {\n                LOG.error(\"Fail to run closure with status: {}.\", st, t);\n            }\n        }\n        this.toAppend.clear();\n        this.storage.clear();\n\n    }\n    this.size = 0;\n    this.bufferSize = 0;\n    return this.lastId;\n}\n\nprivate LogId appendToStorage(final List<LogEntry> toAppend) {\n    LogId lastId = null;\n    if (!this.hasError) {\n        final long startMs = Utils.monotonicMs();\n        final int entriesCount = toAppend.size();\n        this.nodeMetrics.recordSize(\"append-logs-count\", entriesCount);\n        try {\n            // ... metrics\n            // 将 LogEntry 写入 RocksDB\n            final int nAppent = this.logStorage.appendEntries(toAppend);\n            if (nAppent != entriesCount) {\n                LOG.error(\"**Critical error**, fail to appendEntries, nAppent={}, toAppend={}\", nAppent, toAppend.size());\n                reportError(RaftError.EIO.getNumber(), \"Fail to append log entries\");\n            }\n            // 获取最新的 LogId\n            if (nAppent > 0) {\n                lastId = toAppend.get(nAppent - 1).getId();\n            }\n            toAppend.clear();\n        } finally {\n            this.nodeMetrics.recordLatency(\"append-logs\", Utils.monotonicMs() - startMs);\n        }\n    }\n    return lastId;\n}\n```\n\n上述实现最终会调用 `LogStorage#appendEntries` 方法将数据落盘，并返回最新的 LogId 实例。LogStorage 默认的实现是 RocksDBLogStorage 类，即将数据写入 RocksDB 存储引擎，如下：\n\n```java\npublic int appendEntries(final List<LogEntry> entries) {\n    if (entries == null || entries.isEmpty()) {\n        return 0;\n    }\n    final int entriesCount = entries.size();\n    final boolean ret = executeBatch(batch -> {\n        final WriteContext writeCtx = newWriteContext();\n        // 遍历分类型将 LogEntry 写入 RocksDB\n        for (int i = 0; i < entriesCount; i++) {\n            final LogEntry entry = entries.get(i);\n            // 配置类型的 LogEntry，编码之后写入 default 和 conf column family\n            if (entry.getType() == EntryType.ENTRY_TYPE_CONFIGURATION) {\n                addConfBatch(entry, batch);\n            }\n            // 其它类型的 LogEntry，编码之后写入 default column family\n            else {\n                writeCtx.startJob();\n                addDataBatch(entry, batch, writeCtx);\n            }\n        }\n        writeCtx.joinAll();\n        // 模板方法\n        doSync();\n    });\n\n    if (ret) {\n        return entriesCount;\n    } else {\n        return 0;\n    }\n}\n```\n\n上一篇曾介绍过 RocksDBLogStorage 设置了两个 column family，即 conf family 和 data family，其中后者复用了 RocksDB 提供的默认 column family。由上述实现可以看到，JRaft 针对配置类型的 LogEntry 会同时写入这两个 family 中，而其它类型的 LogEntry 仅会写入到 data family 中。\n\n##### RequestVote 预选举请求处理\n\n发起预选举的节点会以 RPC 的方式向集群中的其它节点发送 RequestVote RPC 请求，以征集选票，各节点会基于本地的运行状态决定是否为其投上自己的一票。需要注意的两点是：\n\n1. 预选举阶段的 RequestVote 请求会设置 `preVote = true`，以标识自己是一个预选举请求，用来与正式投票阶段的 RequestVote 请求请求相区别。\n2. 为了避免 term 值无谓的递增，预选举阶段不会真正递增 term 值，而只是将 term 加 1 进行试探性的发起投票。\n\n方法 `RaftServerService#handlePreVoteRequest` 实现了对于预选举阶段 RequestVote 请求的处理逻辑：\n\n```java\npublic Message handlePreVoteRequest(final RequestVoteRequest request) {\n    boolean doUnlock = true;\n    this.writeLock.lock();\n    try {\n        // 当前节点处于非活跃状态，响应错误\n        if (!this.state.isActive()) {\n            LOG.warn(\"Node {} is not in active state, currTerm={}.\", getNodeId(), this.currTerm);\n            return RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(RequestVoteResponse.getDefaultInstance(), RaftError.EINVAL,\n                            \"Node %s is not in active state, state %s.\", getNodeId(), this.state.name());\n        }\n        // 解析发起投票的节点 ID\n        final PeerId candidateId = new PeerId();\n        if (!candidateId.parse(request.getServerId())) {\n            // 解析错误，响应错误\n            LOG.warn(\"Node {} received PreVoteRequest from {} serverId bad format.\", getNodeId(), request.getServerId());\n            return RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(RequestVoteResponse.getDefaultInstance(), RaftError.EINVAL,\n                            \"Parse candidateId failed: %s.\", request.getServerId());\n        }\n        boolean granted = false;\n        // noinspection ConstantConditions\n        do {\n            // 当前节点与对应 leader 节点之间的租约仍然有效，拒绝投票\n            if (this.leaderId != null && !this.leaderId.isEmpty() && isCurrentLeaderValid()) {\n                LOG.info(\"Node {} ignore PreVoteRequest from {}, term={}, currTerm={}, because the leader {}'s lease is still valid.\",\n                        getNodeId(), request.getServerId(), request.getTerm(), this.currTerm, this.leaderId);\n                break;\n            }\n            // 发起投票节点的 term 值小于当前节点，拒绝投票\n            if (request.getTerm() < this.currTerm) {\n                LOG.info(\"Node {} ignore PreVoteRequest from {}, term={}, currTerm={}.\",\n                        getNodeId(), request.getServerId(), request.getTerm(), this.currTerm);\n                // A follower replicator may not be started when this node become leader, so we must check it.\n                // 如果当前节点是 leader 节点，检查与发起投票节点之间的复制关系\n                checkReplicator(candidateId);\n                break;\n            } else if (request.getTerm() == this.currTerm + 1) {\n                // A follower replicator may not be started when this node become leader, so we must check it.\n                // check replicator state\n                checkReplicator(candidateId);\n            }\n            doUnlock = false;\n            this.writeLock.unlock();\n\n            // 获取本地最新的 LogId\n            final LogId lastLogId = this.logManager.getLastLogId(true);\n\n            doUnlock = true;\n            this.writeLock.lock();\n            // 封装请求中的 logIndex 和 term 值\n            final LogId requestLastLogId = new LogId(request.getLastLogIndex(), request.getLastLogTerm());\n            // 如果请求的 term 值更大，或者在 term 值相等的前提下，请求的 logIndex 不小于当前节点的 logIndex 值，\n            // 则投上自己的一票\n            granted = requestLastLogId.compareTo(lastLogId) >= 0;\n\n            LOG.info(\n                    \"Node {} received PreVoteRequest from {}, term={}, currTerm={}, granted={}, requestLastLogId={}, lastLogId={}.\",\n                    getNodeId(), request.getServerId(), request.getTerm(), this.currTerm, granted, requestLastLogId,\n                    lastLogId);\n        } while (false);\n\n        // 响应\n        return RequestVoteResponse.newBuilder() //\n                .setTerm(this.currTerm) //\n                .setGranted(granted) //\n                .build();\n    } finally {\n        if (doUnlock) {\n            this.writeLock.unlock();\n        }\n    }\n}\n```\n\n整体响应预选举 RequestVote 请求的执行流程可以概括为：\n\n1. 如果当前节点处于非活跃状态，则响应错误；\n2. 否则，解析候选节点的节点 ID，如果解析出错，则响应错误；\n3. 否则，如果当前节点与对应 Leader 节点之间的租约仍然有效，则拒绝投票；\n4. 否则，如果候选节点的 term 值相较于当前节点小，则拒绝投票；如果当前节点正好是 Leader 节点，还需要检查候选节点与当前节点之间的复制关系；\n5. 否则，获取本地最新的 logIndex 和对应的 term 值，如果候选节点的 term 和 logIndex 值更新，则同意投票，否则拒绝投票。\n\n如果当前节点是 Leader 节点，但是仍然有节点发起预选举进程，则说明当前节点与目标节点之间的复制关系存在问题，需要重新建立复制关系，并启动对应的复制器 Replicator。关于 Replicator，我们将会在后面介绍日志复制机制时再深入分析，这里暂且跳过。\n\n发起预选举的节点在发送 RequestVote RPC 请求时会为每个请求绑定一个 OnPreVoteRpcDone 回调，当目标节点返回响应时会应用该回调以处理 RequestVote 响应。具体的处理过程由 `NodeImpl#handlePreVoteResponse` 方法实现：\n\n```java\npublic void handlePreVoteResponse(final PeerId peerId, final long term, final RequestVoteResponse response) {\n    boolean doUnlock = true;\n    this.writeLock.lock();\n    try {\n        // 当前节点已经不是 FOLLOWER 角色，可能已经预选举成功了，忽略响应\n        if (this.state != State.STATE_FOLLOWER) {\n            LOG.warn(\"Node {} received invalid PreVoteResponse from {}, \" +\n                    \"state not in STATE_FOLLOWER but {}.\", getNodeId(), peerId, this.state);\n            return;\n        }\n        // 当前节点的 term 值已经发生变化，忽略响应\n        if (term != this.currTerm) {\n            LOG.warn(\"Node {} received invalid PreVoteResponse from {}, \" +\n                    \"term={}, currTerm={}.\", getNodeId(), peerId, term, this.currTerm);\n            return;\n        }\n        // 目标节点的 term 值较当前节点更大，需要 stepdown，主要是更新本地的 term 值\n        if (response.getTerm() > this.currTerm) {\n            LOG.warn(\"Node {} received invalid PreVoteResponse from {}, term {}, expect={}.\",\n                    getNodeId(), peerId, response.getTerm(), this.currTerm);\n            stepDown(response.getTerm(), false, new Status(RaftError.EHIGHERTERMRESPONSE,\n                    \"Raft node receives higher term pre_vote_response.\"));\n            return;\n        }\n        LOG.info(\"Node {} received PreVoteResponse from {}, term={}, granted={}.\",\n                getNodeId(), peerId, response.getTerm(), response.getGranted());\n        // check granted quorum?\n        if (response.getGranted()) {\n            // 目标节点同意投票\n            this.prevVoteCtx.grant(peerId);\n            // 检查是否预选举成功\n            if (this.prevVoteCtx.isGranted()) {\n                doUnlock = false;\n                // 进入正式投票环境\n                electSelf();\n            }\n        }\n    } finally {\n        if (doUnlock) {\n            this.writeLock.unlock();\n        }\n    }\n}\n```\n\n对于预选举 RequestVote 响应的整体处理流程可以概括如下：\n\n1. 校验当前节点是否仍然是 FOLLOWER 角色，如果不是则忽略响应，可能已经预选举成功了；\n2. 否则，校验当前节点的 term 值是否发生变化，如果是则忽略响应；\n3. 否则，如果目标节点的 term 值较当前节点更大，则忽略响应，并执行 stepdown；\n4. 否则，如果目标节点拒绝投票，则忽略响应；\n5. 否则，如果目标节点同意投票，则更新得票数，并检查是否预选举成功，如果是则进入正式投票环节。\n\n如果当前节点在预选举期间收到 term 值更大的 RequestVote 响应，则会执行 stepdown 逻辑。此时节点的角色仍然是 FOLLOWER，所以除了重置本地状态和再次启动预选举计时器之外，一个重要的工作就是更新当前节点的 term 值，以保证与当前集群已知的最大 term 值看齐。\n\nJRaft 在实现层面大量应用了回调机制，例如上述在处理预选举响应时会让每个目标节点的响应在同意投票的前提下都会回调触发一次 `Ballot#grant` 操作以更新得票数，并调用 `Ballot#isGranted` 方法检查得票数是否过半，如果是则进入正式投票的环节。此类异步回调机制在整个 JRaft 设计和实现中比较常见，其思想值得借鉴，不过重度依赖回调可能会让程序陷入 [Callback Hell](http://callbackhell.com/)，需要把控尺度。\n\n#### 正式选举\n\n当预选举成功之后，节点接下去会执行 `NodeImpl#electSelf` 方法进入正式选举进程。实际上，正式选举与预选举在执行流程上基本相同，但是仍然有些细微的差别，本小节一起来分析一下。\n\n触发正式选举进程，除了发生在预选举成功之后之外，主要还包括另外两个场景：\n\n1. 在只有一个节点的情况下，此时该节点一定能够竞选成功，所以没有进行预选举的必要。\n2. 正式选举阶段超时，此时需要再次发起一轮新的正式选举进程，这也是正式选举计时器 voteTimer 的职责。\n\n方法 `NodeImpl#electSelf` 的实现如下：\n\n```java\nprivate void electSelf() {\n    long oldTerm;\n    try {\n        LOG.info(\"Node {} start vote and grant vote self, term={}.\", getNodeId(), this.currTerm);\n        // 当前节点不是一个合法节点\n        if (!this.conf.contains(this.serverId)) {\n            LOG.warn(\"Node {} can't do electSelf as it is not in {}.\", getNodeId(), this.conf);\n            return;\n        }\n        // 当前节点第一次尝试正式选举，需要暂时停止预选举计时器，避免期间再次触发预选举\n        if (this.state == State.STATE_FOLLOWER) {\n            LOG.debug(\"Node {} stop election timer, term={}.\", getNodeId(), this.currTerm);\n            this.electionTimer.stop();\n        }\n        // 清空本地记录的 Leader 节点 ID\n        resetLeaderId(PeerId.emptyPeer(), new Status(RaftError.ERAFTTIMEDOUT,\n                \"A follower's leader_id is reset to NULL as it begins to request_vote.\"));\n        // 切换角色为 CANDIDATE\n        this.state = State.STATE_CANDIDATE;\n        // 正式投票环境真正递增 term 值，而预选举阶段不会\n        this.currTerm++;\n        // 更新 votedId 字段，标记投票给自己\n        this.votedId = this.serverId.copy();\n        LOG.debug(\"Node {} start vote timer, term={} .\", getNodeId(), this.currTerm);\n        // 启动正式选举计时器，当选举超时会再次触发正式选举进程\n        this.voteTimer.start();\n        // 初始化正式选举选票\n        this.voteCtx.init(this.conf.getConf(), this.conf.isStable() ? null : this.conf.getOldConf());\n        oldTerm = this.currTerm;\n    } finally {\n        this.writeLock.unlock();\n    }\n\n    // 从本地加载最新的 logIndex 和对应的 term 值\n    final LogId lastLogId = this.logManager.getLastLogId(true);\n\n    this.writeLock.lock();\n    try {\n        // vote need defense ABA after unlock&writeLock\n        if (oldTerm != this.currTerm) {\n            LOG.warn(\"Node {} raise term {} when getLastLogId.\", getNodeId(), this.currTerm);\n            return;\n        }\n        // 遍历向除自己以外的所有连通节点发送 RequestVote RPC 请求，以征集选票\n        for (final PeerId peer : this.conf.listPeers()) {\n            if (peer.equals(this.serverId)) {\n                continue;\n            }\n            if (!this.rpcService.connect(peer.getEndpoint())) {\n                LOG.warn(\"Node {} channel init failed, address={}.\", getNodeId(), peer.getEndpoint());\n                continue;\n            }\n            final OnRequestVoteRpcDone done = new OnRequestVoteRpcDone(peer, this.currTerm, this);\n            done.request = RequestVoteRequest.newBuilder() //\n                    .setPreVote(false) // It's not a pre-vote request. 标记是正式选举\n                    .setGroupId(this.groupId) //\n                    .setServerId(this.serverId.toString()) //\n                    .setPeerId(peer.toString()) //\n                    .setTerm(this.currTerm) // 这里是递增后的 term 值\n                    .setLastLogIndex(lastLogId.getIndex()) //\n                    .setLastLogTerm(lastLogId.getTerm()) //\n                    .build();\n            // 发送 RPC 请求\n            this.rpcService.requestVote(peer.getEndpoint(), done.request, done);\n        }\n\n        // 更本地元数据信息\n        this.metaStorage.setTermAndVotedFor(this.currTerm, this.serverId);\n        // 给自己投上一票\n        this.voteCtx.grant(this.serverId);\n        // 检查是否竞选成功\n        if (this.voteCtx.isGranted()) {\n            // 成为 leader 节点\n            becomeLeader();\n        }\n    } finally {\n        this.writeLock.unlock();\n    }\n}\n```\n\n正式选举进程的整体执行流程可以概括如下：\n\n1. 校验当前节点是否是合法节点，即属于集群节点配置集合中的一员，如果不是则放弃参选；\n2. 如果当前节点是 FOLLOWER 角色，说明是刚刚从预选举阶段过渡而来，需要停止预选举计时器 electionTimer，避免期间再次发起新的预选举进程；\n3. 重置本地记录的 leader 节点的 ID；\n4. 切换节点为 CANDIDATE 角色、递增 term 值，以及更新 votedId 为当前节点 ID；\n5. 启动正式选举计时器 voteTimer，用于当正式选举超时时，再次发起一轮新的正式选举进程；\n6. 初始化正式选票 Ballot 实例；\n7. 获取本地最新的 logIndex 和对应的 term 值；\n8. 遍历向除自己以外的所有连通节点发送 RequestVote RPC 请求，以征集选票，同时给自己投上一票；\n9. 更新本地元数据信息，即 term 值和 votedId 值；\n10. 如果票数过半，则执行 `NodeImpl#becomeLeader` 操作以切换角色为 LEADER，即竞选成功。\n\n总的来说，正式选举与预选举阶段的执行流程基本相同，不过在正式选举阶段会真正递增 term 值。\n\n下面来看一下节点对于正式选举 RequestVote RPC 请求的处理过程，实现位于 `NodeImpl#handleRequestVoteRequest` 方法中：\n\n```java\npublic Message handleRequestVoteRequest(final RequestVoteRequest request) {\n    boolean doUnlock = true;\n    this.writeLock.lock();\n    try {\n        // 节点处于非活跃状态，响应错误\n        if (!this.state.isActive()) {\n            LOG.warn(\"Node {} is not in active state, currTerm={}.\", getNodeId(), this.currTerm);\n            return RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(RequestVoteResponse.getDefaultInstance(), RaftError.EINVAL,\n                            \"Node %s is not in active state, state %s.\", getNodeId(), this.state.name());\n        }\n        // 解析发起正式选举的节点 ID\n        final PeerId candidateId = new PeerId();\n        // 解析失败，响应错误\n        if (!candidateId.parse(request.getServerId())) {\n            LOG.warn(\"Node {} received RequestVoteRequest from {} serverId bad format.\", getNodeId(), request.getServerId());\n            return RpcFactoryHelper //\n                    .responseFactory() //\n                    .newResponse(RequestVoteResponse.getDefaultInstance(), RaftError.EINVAL,\n                            \"Parse candidateId failed: %s.\", request.getServerId());\n        }\n\n        // noinspection ConstantConditions\n        do {\n            // check term\n            if (request.getTerm() >= this.currTerm) {\n                LOG.info(\"Node {} received RequestVoteRequest from {}, term={}, currTerm={}.\",\n                        getNodeId(), request.getServerId(), request.getTerm(), this.currTerm);\n                // 候选节点的 term 值大于当前节点，执行 stepdown\n                if (request.getTerm() > this.currTerm) {\n                    // increase current term, change state to follower\n                    stepDown(request.getTerm(), false, new Status(RaftError.EHIGHERTERMRESPONSE,\n                            \"Raft node receives higher term RequestVoteRequest.\"));\n                }\n            }\n            // 候选节点的 term 值小于当前节点，拒绝投票\n            else {\n                // ignore older term\n                LOG.info(\"Node {} ignore RequestVoteRequest from {}, term={}, currTerm={}.\",\n                        getNodeId(), request.getServerId(), request.getTerm(), this.currTerm);\n                break;\n            }\n            doUnlock = false;\n            this.writeLock.unlock();\n\n            // 从本地获取最新的 logIndex 和对应的 term 值\n            final LogId lastLogId = this.logManager.getLastLogId(true);\n\n            doUnlock = true;\n            this.writeLock.lock();\n            // vote need ABA check after unlock&writeLock\n            if (request.getTerm() != this.currTerm) {\n                LOG.warn(\"Node {} raise term {} when get lastLogId.\", getNodeId(), this.currTerm);\n                break;\n            }\n\n            // 如果 logIsOk，则说明候选节点的 term 值大于当前节点，或者 term 相同，但是候选节点的 logIndex 不比当前节点小\n            final boolean logIsOk = new LogId(request.getLastLogIndex(), request.getLastLogTerm())\n                    .compareTo(lastLogId) >= 0;\n\n            // 如果 logIsOk，且当前节点目前没有投票给其它节点\n            if (logIsOk && (this.votedId == null || this.votedId.isEmpty())) {\n                stepDown(request.getTerm(), false, new Status(RaftError.EVOTEFORCANDIDATE,\n                        \"Raft node votes for some candidate, step down to restart election_timer.\"));\n                this.votedId = candidateId.copy();\n                // 更新本地元数据信息\n                this.metaStorage.setVotedFor(candidateId);\n            }\n        } while (false);\n\n        // 发送 RequestVote RPC 响应\n        return RequestVoteResponse.newBuilder() //\n                .setTerm(this.currTerm) //\n                .setGranted(request.getTerm() == this.currTerm && candidateId.equals(this.votedId)) //\n                .build();\n    } finally {\n        if (doUnlock) {\n            this.writeLock.unlock();\n        }\n    }\n}\n```\n\n响应正式选举 RequestVote 请求的整体执行流程可以概括为：\n\n1. 如果当前节点处于非活跃状态，则响应错误；\n2. 否则，解析候选节点的节点 ID，如果解析出错则响应错误；\n3. 否则，如果候选节点的 term 值小于当前节点，则拒绝投票；\n4. 否则，如果候选节点的 term 值大于当前节点，则需要执行 stepdown；\n5. 如果候选节点的 term 值更新，或者 term 值相同但是对应的 logIndex 不小于当前节点，且当前节点未投票给其它节点，则同意投票，同时更新本地元数据信息；\n6. 否则，拒绝投票。\n\n关于步骤 4，此时处理 RequestVote RPC 请求的节点角色仍然是 FOLLOWER，所以除了重置本地状态和再次启动预选举计时器之外，一个重要的工作就是更新当前节点的 term 值，以保证与当前集群已知的最大 term 值看齐。\n\n发起正式选举请求的节点在发送 RequestVote RPC 请求时会为每个请求绑定一个 OnRequestVoteRpcDone 回调，当目标节点返回响应时会应用该回调以处理 RequestVote 响应。具体的处理过程由 `NodeImpl#handleRequestVoteResponse` 方法实现：\n\n```java\npublic void handleRequestVoteResponse(final PeerId peerId, final long term, final RequestVoteResponse response) {\n    this.writeLock.lock();\n    try {\n        // 当前节点已经不是 CANDIDATE 角色，可能以及竞选成功，或者被打回 FOLLOWER 角色了，忽略响应\n        if (this.state != State.STATE_CANDIDATE) {\n            LOG.warn(\"Node {} received invalid RequestVoteResponse from {}, state not in STATE_CANDIDATE but {}.\",\n                    getNodeId(), peerId, this.state);\n            return;\n        }\n\n        // 期间 term 值已经发生变化，忽略响应\n        if (term != this.currTerm) {\n            LOG.warn(\"Node {} received stale RequestVoteResponse from {}, term={}, currTerm={}.\",\n                    getNodeId(), peerId, term, this.currTerm);\n            return;\n        }\n\n        // 目标节点的 term 值比当前节点大，需要执行 stepdown\n        if (response.getTerm() > this.currTerm) {\n            LOG.warn(\"Node {} received invalid RequestVoteResponse from {}, term={}, expect={}.\",\n                    getNodeId(), peerId, response.getTerm(), this.currTerm);\n            stepDown(response.getTerm(), false, new Status(RaftError.EHIGHERTERMRESPONSE,\n                    \"Raft node receives higher term request_vote_response.\"));\n            return;\n        }\n        // check granted quorum?\n        if (response.getGranted()) {\n            this.voteCtx.grant(peerId);\n            // 如果票数过半，则竞选成功\n            if (this.voteCtx.isGranted()) {\n                becomeLeader();\n            }\n        }\n    } finally {\n        this.writeLock.unlock();\n    }\n}\n```\n\n对于正式选举 RequestVote 响应的整体处理流程可以概括如下：\n\n1. 校验当前节点是不是 CANDIDATE 角色，如果不是则可能已经竞选成功，或者被打回成了 FOLLOWER 角色，忽略响应；\n2. 否则，校验等待响应期间节点的 term 值是否发生变化，如果是则忽略响应；\n3. 否则，如果目标节点的 term 值相较于当前节点更大，则需要忽略响应，并执行 stepdown；\n4. 否则，如果目标节点同意投票，则更新选票计数，否则忽略响应；\n5. 如果票数过半，则执行 `NodeImpl#becomeLeader` 方法成为 LEADER 角色。\n\n关于步骤 3，当前节点角色为 CANDIDATE，所以执行 stepdown 会让当前节点停止正式选举计时器，并切换角色为 FOLLOWER，并再次启动预选举计时器。此外，还会更新当前节点的 term 值，以保证与当前集群已知的最大 term 值看齐。\n\n如果当前节点票数过半，则接下去会调用 `NodeImpl#becomeLeader` 方法执行从 CANDIDATE 到 LEADER 的角色转变，实现如下：\n\n```java\nprivate void becomeLeader() {\n    // 前置角色必须是 CANDIDATE\n    Requires.requireTrue(this.state == State.STATE_CANDIDATE, \"Illegal state: \" + this.state);\n    LOG.info(\"Node {} become leader of group, term={}, conf={}, oldConf={}.\",\n            getNodeId(), this.currTerm, this.conf.getConf(), this.conf.getOldConf());\n    // 停止正式选举计时器\n    stopVoteTimer();\n    // 切换角色为 LEADER\n    this.state = State.STATE_LEADER;\n    // 更新本地记录的 leader 节点 ID\n    this.leaderId = this.serverId.copy();\n    // 设置复制器组的 term 值\n    this.replicatorGroup.resetTerm(this.currTerm);\n\n    // 处理 Follower 节点：遍历将集群中除自己以外的 Follower 节点纳为自己的 Follower，并建立到这些节点的复制关系\n    for (final PeerId peer : this.conf.listPeers()) {\n        if (peer.equals(this.serverId)) {\n            continue;\n        }\n        LOG.debug(\"Node {} add a replicator, term={}, peer={}.\", getNodeId(), this.currTerm, peer);\n        if (!this.replicatorGroup.addReplicator(peer)) {\n            LOG.error(\"Fail to add a replicator, peer={}.\", peer);\n        }\n    }\n\n    // 处理 Learner 节点：遍历将集群中除自己以外的 Learner 节点纳为自己的 Learner，并建立到这些节点的复制关系\n    // Learner 节点只是复制日志，不会对日志的提交做决策\n    for (final PeerId peer : this.conf.listLearners()) {\n        LOG.debug(\"Node {} add a learner replicator, term={}, peer={}.\", getNodeId(), this.currTerm, peer);\n        if (!this.replicatorGroup.addReplicator(peer, ReplicatorType.Learner)) {\n            LOG.error(\"Fail to add a learner replicator, peer={}.\", peer);\n        }\n    }\n\n    // 重置选票箱\n    this.ballotBox.resetPendingIndex(this.logManager.getLastLogIndex() + 1);\n    // Register _conf_ctx to reject configuration changing before the first log is committed.\n    if (this.confCtx.isBusy()) {\n        throw new IllegalStateException();\n    }\n    // 将当前集群配置信息写入日志\n    this.confCtx.flush(this.conf.getConf(), this.conf.getOldConf());\n    // 启动 stepdown 计时器\n    this.stepDownTimer.start();\n}\n```\n\n整体的执行流程可以概括为：\n\n1. 校验当前节点角色是否为 CANDIDATE，LEADER 角色的前置角色必须是 CANDIDATE；\n2. 停止正式选举计时器 voteTimer；\n3. 切换节点角色为 LEADER；\n4. 建立到除自己以外的所有节点之间的复制关系，包括 Follower 和 Learner；\n5. 重置选票箱 BallotBox；\n6. 将当前集群的节点配置信息记录到日志中；\n7. 启动 stepdown 计时器 stepDownTimer。\n\nJRaft 中的节点区分 Learner 和非 Learner 角色，官方对于 Learner 角色的说明如下：\n\n> Learner 节点也叫只读节点，只读节点类似于 Follower 节点，将从 Leader 复制日志并应用到本地状态机中，但是不参与选举，复制日志成功也不会被认为是多数派的一员。简而言之，除了复制日志以外，只读成员不参与其他任何 Raft 算法过程。一般应用在为某个服务创建一个只读服务的时候，实现类似读写分离的效果，或者数据冷备等场景。\n\n当一个节点竞选成功成为 LEADER 角色之后，按照 Raft 的强 Leader 约束，所有集群中的其它节点将成为该 Leader 节点的 Follower 节点。所以，Leader 节点需要建立到这些节点的复制关系，包括 Learner 和非 Learner 节点。关于 `ReplicatorGroup#addReplicator` 的实现将在后面介绍日志复制机制时再展开分析。\n\n方法 `ConfigurationCtx#flush` 会将当前集群的节点配置信息作为当前节点成为 LEADER 角色之后的第一条日志同步给集群中的 Follower 节点，关于日志复制机制这里先不展开，后面将用一篇文章针对性介绍。这里需要关注的一点是 Leader 节点在将日志数据同步出去之前会设置一个 ConfigurationChangeDone 回调，并在日志数据被 committed 之后触发执行 `ConfigurationChangeDone#run` 方法。实现如下：\n\n```java\npublic void run(final Status status) {\n    if (status.isOk()) {\n        // 尝试让集群节点配置趋于稳定\n        onConfigurationChangeDone(this.term);\n        if (this.leaderStart) {\n            // 回调状态机 StateMachine#onLeaderStart 逻辑\n            getOptions().getFsm().onLeaderStart(this.term);\n        }\n    } else {\n        LOG.error(\"Fail to run ConfigurationChangeDone, status: {}.\", status);\n    }\n}\n```\n\n上述方法在节点成为 Leader 时会回调由应用程序实现的 `StateMachine#onLeaderStart` 方法。此外，方法 `NodeImpl#onConfigurationChangeDone` 则尝试让集群节点配置趋于稳定，实现如下：\n\n```java\npublic void onConfigurationChangeDone(final long term) {\n    this.writeLock.lock();\n    try {\n        // 期间 term 值发生变更，或者当前节点已经不是 Leader，直接跳过\n        if (term != this.currTerm || this.state.compareTo(State.STATE_TRANSFERRING) > 0) {\n            LOG.warn(\"Node {} process onConfigurationChangeDone at term {} while state={}, currTerm={}.\",\n                    getNodeId(), term, this.state, this.currTerm);\n            return;\n        }\n        // 将集群配置状态切换到下一个阶段\n        this.confCtx.nextStage();\n    } finally {\n        this.writeLock.unlock();\n    }\n}\n```\n\n在 Leader 选举场景下，集群节点配置上下文 ConfigurationCtx 的 stage 分为 `STAGE_STABLE` 和 `STAGE_JOINT` 两类，前者表示集群配置已经趋于稳定，而后者则表示集群目前存在新老配置过渡的情况。ConfigurationCtx 针对这两类 stage 的处理逻辑实现如下：\n\n```java\n// com.alipay.sofa.jraft.core.NodeImpl.ConfigurationCtx#nextStage\ncase STAGE_JOINT:\n    this.stage = Stage.STAGE_STABLE;\n    // 再次应用配置变更，剔除老的配置信息\n    this.node.unsafeApplyConfiguration(new Configuration(this.newPeers, this.newLearners), null, false);\n    break;\ncase STAGE_STABLE:\n    // 当前集群节点配置是否包含当前节点\n    final boolean shouldStepDown = !this.newPeers.contains(this.node.serverId);\n    reset(new Status());\n    if (shouldStepDown) {\n        this.node.stepDown(this.node.currTerm, true,\n                new Status(RaftError.ELEADERREMOVED, \"This node was removed.\"));\n    }\n    break;\n```\n\n具体执行逻辑如上述代码注释。关于 Raft 算法的集群节点配置变更算是一个相对复杂的问题，这里不打算展开说明，后续考虑用一篇文章针对性介绍。\n\n此外，在节点成为 LEADER 角色之后会将集群配置信息作为第一条日志进行提交，还有另外一个考虑。当一个节点刚刚竞选成为 LEADER 角色时，此时该节点本地的 committedIndex 值并不一定是当前整个系统范围内最新的 committedIndex 值，这会影响线性一致性读结果的准确性，而通过提交日志操作则能够保证新的 Leader 节点的 committedIndex 被更新为集群范围内的最新值。\n\n### Leader 让权\n\nLeader 节点需要定期检查自己的权威是否持续有效，即集群中过半数的 Follower 节点都能响应自己的心跳请求，如果不是则需要让权。这一过程由 stepdown 计时器 stepDownTimer 负责，由前面 `NodeImpl#becomeLeader` 方法的实现也可以看到在节点成为 LEADER 角色之后会启动 stepdown 计时器。该计时器的核心逻辑由 `NodeImpl#handleStepDownTimeout` 方法实现：\n\n```java\nprivate void handleStepDownTimeout() {\n    this.writeLock.lock();\n    try {\n        // 当前节点不是 LEADER 角色，无需让权\n        if (this.state.compareTo(State.STATE_TRANSFERRING) > 0) {\n            LOG.debug(\"Node {} stop step-down timer, term={}, state={}.\", getNodeId(), this.currTerm, this.state);\n            return;\n        }\n        final long monotonicNowMs = Utils.monotonicMs();\n        // 检查集群中是否有超过半数的 Follower 节点仍然在响应自己的心跳请求，如果不是则执行让权操作\n        checkDeadNodes(this.conf.getConf(), monotonicNowMs);\n        if (!this.conf.getOldConf().isEmpty()) {\n            checkDeadNodes(this.conf.getOldConf(), monotonicNowMs);\n        }\n    } finally {\n        this.writeLock.unlock();\n    }\n}\n\nprivate void checkDeadNodes(final Configuration conf, final long monotonicNowMs) {\n    // Check learner replicators at first.\n    for (PeerId peer : conf.getLearners()) {\n        // 确定到所有 Learner 节点的复制关系都建立了\n        checkReplicator(peer);\n    }\n    // Ensure quorum nodes alive.\n    final List<PeerId> peers = conf.listPeers();\n    final Configuration deadNodes = new Configuration();\n    // 如果集群中认同当前 Leader 节点的 Follower 节点数过半，则无需让权\n    if (checkDeadNodes0(peers, monotonicNowMs, true, deadNodes)) {\n        return;\n    }\n    LOG.warn(\"Node {} steps down when alive nodes don't satisfy quorum, \" +\n            \"term={}, deadNodes={}, conf={}.\", getNodeId(), this.currTerm, deadNodes, conf);\n    final Status status = new Status();\n    status.setError(RaftError.ERAFTTIMEDOUT, \"Majority of the group dies: %d/%d\", deadNodes.size(), peers.size());\n    // 集群中认同当前 Leader 节点的 Follower 节点数小于一半，执行让权操作\n    stepDown(this.currTerm, false, status);\n}\n```\n\n其中方法 `NodeImpl#checkDeadNodes0` 会检查目标 Follower 节点与当前 Leader 节点最近一次的 RPC 请求时间戳，以此决定对应的租约是否仍然有效，实现如下：\n\n```java\nprivate boolean checkDeadNodes0(final List<PeerId> peers,\n                                final long monotonicNowMs,\n                                final boolean checkReplicator,\n                                final Configuration deadNodes) {\n    // 获取租约时长，默认为选举超时的 90%\n    final int leaderLeaseTimeoutMs = this.options.getLeaderLeaseTimeoutMs();\n    int aliveCount = 0;\n    // 记录向所有活跃节点发送 RPC 请求的最小时间戳\n    long startLease = Long.MAX_VALUE;\n    // 遍历逐个检查目标 Follower 节点\n    for (final PeerId peer : peers) {\n        if (peer.equals(this.serverId)) {\n            aliveCount++;\n            continue;\n        }\n        // 检查到目标节点之间的复制关系，避免因为缺失复制关系而误将目标节点判为死亡\n        if (checkReplicator) {\n            checkReplicator(peer);\n        }\n        // 获取最近一次成功向目标节点发送 RPC 请求的时间戳\n        final long lastRpcSendTimestamp = this.replicatorGroup.getLastRpcSendTimestamp(peer);\n        // 到目标节点的租约仍然有效，则视目标节点仍然活跃\n        if (monotonicNowMs - lastRpcSendTimestamp <= leaderLeaseTimeoutMs) {\n            aliveCount++; // 活跃节点数加 1\n            // 更新向所有活跃节点发送 RPC 请求的最小时间戳\n            if (startLease > lastRpcSendTimestamp) {\n                startLease = lastRpcSendTimestamp;\n            }\n            continue;\n        }\n        // 记录死亡节点\n        if (deadNodes != null) {\n            deadNodes.addPeer(peer);\n        }\n    }\n    // 活跃节点数过半，说明当前 Leader 节点仍然有效，更新时间戳（向所有活跃节点发送 RPC 请求的最小时间戳）\n    if (aliveCount >= peers.size() / 2 + 1) {\n        updateLastLeaderTimestamp(startLease);\n        return true;\n    }\n    return false;\n}\n```\n\n如果过半数的 Follower 节点对应的租约都失效，则当前 Leader 节点需要执行让权操作，因为集群有可能正在或已经选举出新的 Leader 节点。如果过半数的 Follower 节点对应的租约仍然有效，则上述操作会使用 `NodeImpl#lastLeaderTimestamp` 字段记录向这些 Follower 节点成功发送 RPC 请求的最早时间。该字段对于 Leader 节点而言用于在 LeaseRead 策略的线性一致性读场景下判断当前 Leader 节点是否仍然有效，具体将在后面介绍线性一致性读机制的文章中展开介绍。\n\n让权操作的过程由 `NodeImpl#stepDown` 方法实现，该方法我们在前面已经多次遇到过，只是每次调用时节点的状态不同而已。此时，节点以 LEADER 角色调用该方法，除了将角色切换成 FOLLOWER、初始化本地状态，以及启动预选举计时器 electionTimer 之外，在此之前还会执行如下一段逻辑：\n\n```java\n// 停止 stepdown 计时器\nstopStepDownTimer();\n// 清空选票箱\nthis.ballotBox.clearPendingTasks();\n// signal fsm leader stop immediately\nif (this.state == State.STATE_LEADER) {\n    // 向状态机调度器发布 LEADER_STOP 事件\n    onLeaderStop(status);\n}\n```\n\n状态机调度器的运行机制我们在前面已经介绍过，`LEADER_STOP` 状态机事件会触发 FSMCaller 回调应用程序实现的 `StateMachine#onLeaderStop` 方法，这与我们前面介绍的回调应用程序实现的 `StateMachine#onLeaderStart` 方法相呼应。\n\n### 总结\n\n主节点选举是 Raft 算法的核心组成部分，是支持 Raft 集群运行所不可或缺的一部分。Raft 算法采用 Strong Leader 的设计，要求整个 Raft 集群必须只有一个 Leader 节点，所有其它 Follower 节点必须服从于 Leader 节点。这为简化共识算法的设计和实现起到了积极的作用，但我们也不能否认 Leader 节点在整个 Raft 算法的运行过程中负担了太多。\n\n本文我们从源码层面分析了 JRaft 算法库关于主节点选举机制的实现。有别于 Raft 算法，JRaft 将主节点选举拆分为预选举和正式选举两个阶段，以此避免无效的选举影响 Leader 节点的正常运行，进而最终影响整个集群的稳定性。此外，通过实现我们也能感受到计时器在 Raft 算法设计中的重要地位，而随机化计时时间这么一个小小的优化则解决了协议运行所面临的重大隐患。\n\n### 参考\n\n1. [Raft Consensus Algorithm](https://raft.github.io/)\n2. [SOFA-JRaft 官网](https://www.sofastack.tech/projects/sofa-jraft/overview/)\n3. [SOFA-JRaft：选举机制剖析](https://www.sofastack.tech/blog/sofa-jraft-election-mechanism/)\n","tags":["Raft","SOFA-JRaft"],"categories":["sofa"]},{"title":"SOFA-JRaft 源码解析：节点的启动过程","url":"/2020/06/01/sofa/sofa-jraft-node-startup/","content":"\n在《[理解 Raft 分布式共识算法](/2020/01/01/protocol/raft/)》一文中，我们对于 Raft 算法的理论进行了介绍。过去几年，围绕 Raft 算法涌现出了一系列各类语言的实现（参考 [Raft 算法官网](https://raft.github.io/#implementations)），这也充分证明了该算法相对于 Paxos 算法在理解和实现层面的友好性。从本文开始，我就以 [SOFA-JRaft](https://www.sofastack.tech/projects/sofa-jraft/overview/) 为例，用多篇文章来分析一个生产级别的 Raft 算法应该如何实现。\n\nSOFA-JRaft 是一个基于 Raft 算法的 java 语言实现算法库，提供生产级别的稳定性、容错性，以及高性能，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。<!-- more -->\n\n本系列文章将从源码层面剖析 SOFA-JRaft 的设计与实现，区别于 `SOFA:JRaftLab/` 项目中的一系列文章侧重于介绍 SOFA-JRaft 各模块的设计，本系列文章更加侧重于 SOFA-JRaft 各模块的实现，从实现层面再反观 SOFA-JRaft 的架构设计。\n\n注：本系列文章如不做特殊说明，均使用 JRaft 指代 SOFA-JRaft，使用 Raft 指代 Raft 算法。\n\n### Leader 选举示例\n\n在正式开始之前还是先引用一个 JRaft 的官方示例，演示如何基于 JRaft 实现分布式场景下的主节点选举。ElectionBootstrap 是整个示例的驱动类，对应的 main 函数实现如下：\n\n```java\npublic static void main(final String[] args) {\n    if (args.length < 4) {\n        System.out.println(\n                \"Useage : java com.alipay.sofa.jraft.example.election.ElectionBootstrap {dataPath} {groupId} {serverId} {initConf}\");\n        System.out.println(\n                \"Example: java com.alipay.sofa.jraft.example.election.ElectionBootstrap /tmp/server1 election_test 127.0.0.1:8081 127.0.0.1:8081,127.0.0.1:8082,127.0.0.1:8083\");\n        System.exit(1);\n    }\n    final String dataPath = args[0]; // 数据根路径\n    final String groupId = args[1]; // 组 ID\n    final String serverIdStr = args[2]; // 节点地址\n    final String initialConfStr = args[3]; // 初始节点列表\n\n    // 节点初始化参数设置\n    final ElectionNodeOptions electionOpts = new ElectionNodeOptions();\n    electionOpts.setDataPath(dataPath);\n    electionOpts.setGroupId(groupId);\n    electionOpts.setServerAddress(serverIdStr);\n    electionOpts.setInitialServerAddressList(initialConfStr);\n\n    final ElectionNode node = new ElectionNode();\n    // 注册监听器，监听当前节点竞选 leader 成功或 stepdown\n    node.addLeaderStateListener(new LeaderStateListener() {\n\n        final PeerId serverId = node.getNode().getLeaderId();\n        final String ip = serverId.getIp();\n        final int port = serverId.getPort();\n\n        @Override\n        public void onLeaderStart(long leaderTerm) {\n            System.out.println(\"[ElectionBootstrap] Leader's ip is: \" + ip + \", port: \" + port);\n            System.out.println(\"[ElectionBootstrap] Leader start on term: \" + leaderTerm);\n        }\n\n        @Override\n        public void onLeaderStop(long leaderTerm) {\n            System.out.println(\"[ElectionBootstrap] Leader stop on term: \" + leaderTerm);\n        }\n    });\n\n    // 初始化并启动节点\n    node.init(electionOpts);\n}\n```\n\n由上述实现可以看出在 Leader 选举场景下启动一个 JRaft 节点需要指定 4 个参数，包括：\n\n- 数据存储根路径，用于存储日志、元数据，以及快照数据。\n- 组 ID，一个组可以看做是一个独立的 Raft 集群，JRaft 支持 MULTI-RAFT-GROUP。\n- 节点地址，即当前节点的 IP 和端口号。\n- 初始集群节点列表，即初始构成 JRaft 集群的节点列表。\n\nElectionNode 是整个启动示例的核心实现类，方法 `ElectionNode#init` 实现了初始化和启动单个 JRaft 节点的逻辑，如下：\n\n```java\npublic boolean init(final ElectionNodeOptions opts) {\n    // 已经启动，避免重复启动\n    if (this.started) {\n        LOG.info(\"[ElectionNode: {}] already started.\", opts.getServerAddress());\n        return true;\n    }\n\n    // 构造 Raft 节点配置对象\n    NodeOptions nodeOpts = opts.getNodeOptions();\n    if (nodeOpts == null) {\n        nodeOpts = new NodeOptions();\n    }\n\n    // 设置选举状态机\n    this.fsm = new ElectionOnlyStateMachine(this.listeners);\n    nodeOpts.setFsm(this.fsm);\n\n    // 初始化集群节点配置\n    final Configuration initialConf = new Configuration();\n    if (!initialConf.parse(opts.getInitialServerAddressList())) {\n        throw new IllegalArgumentException(\"Fail to parse initConf: \" + opts.getInitialServerAddressList());\n    }\n    // Set the initial cluster configuration\n    nodeOpts.setInitialConf(initialConf);\n\n    // 创建数据存储路径，用于存储日志和元数据信息\n    final String dataPath = opts.getDataPath();\n    try {\n        FileUtils.forceMkdir(new File(dataPath));\n    } catch (final IOException e) {\n        LOG.error(\"Fail to make dir for dataPath {}.\", dataPath);\n        return false;\n    }\n    // Set the data path\n    // Log, required\n    nodeOpts.setLogUri(Paths.get(dataPath, \"log\").toString());\n    // Metadata, required\n    nodeOpts.setRaftMetaUri(Paths.get(dataPath, \"meta\").toString());\n    // 对于 Leader 选举而言，无需启用快照机制\n    // nodeOpts.setSnapshotUri(Paths.get(dataPath, \"snapshot\").toString());\n\n    final String groupId = opts.getGroupId();\n    final PeerId serverId = new PeerId();\n    if (!serverId.parse(opts.getServerAddress())) {\n        throw new IllegalArgumentException(\"Fail to parse serverId: \" + opts.getServerAddress());\n    }\n\n    // 创建并初始化 raft 节点，以 RPC 服务的形式运行\n    final RpcServer rpcServer = RaftRpcServerFactory.createRaftRpcServer(serverId.getEndpoint());\n    this.raftGroupService = new RaftGroupService(groupId, serverId, nodeOpts, rpcServer);\n    this.node = this.raftGroupService.start();\n    if (this.node != null) {\n        this.started = true;\n    }\n    return this.started;\n}\n```\n\n实现一个 JRaft 节点的初始化和启动过程主要分为两个步骤：\n\n1. 构造 Raft 节点配置 NodeOptions 对象；\n2. 初始化并启动节点，以 RPC 服务的方式运行。\n\n构建 NodeOptions 配置对象的过程比较简单，这里主要说明一下状态机 StateMachine 选项。以典型的基于 JRaft 实现的 KV 数据库为例，当我们往数据库中写入一条数据时，对于 JRaft 而言就像是我们往 Leader 节点发送了一条指令。Leader 节点会将该指令封装成一条日志条目 LogEntry 记录到本地，并复制给集群中的其它 Follower 节点。当集群中过半数节点都完成了对该 LogEntry 的复制之后，Leader 节点认为可以提交该条目（即将该 LogEntry 的状态修改为 committed），并在未来的某个时刻将该 LogEntry 中的指令应用到本地存储介质中。\n\n整个流程中封装指令为 LogEntry 对象，接着将 LogEntry 复制到大部分 Follower 节点，并提交该 LogEntry 的过程都是通用的，由 JRaft 负责实现。然而，对于指令的解析和应用则需要结合具体的应用场景，以 KV 数据库场景为例，需要解析出 LogEntry 中的指令，并依据指令类型决定对相应的 key 做下一步具体操作，是更新还是删除。JRaft 定义了一个 StateMachine 接口，并通过 `StateMachine#onApply` 方法将已经成功同步给集群中过半数节点的 LogEntry 对应的指令透传给用户，由用户去实现对指令的处理逻辑。\n\n继续回到本示例，Leader 选举是 Raft 算法内置的功能，可以不涉及用户指令，所以上述示例对于 StateMachine 接口的实现类 ElectionOnlyStateMachine 也仅仅是简单打印了些日志，这里不再展开。\n\nJRaft 节点的初始化和启动过程由 RaftGroupService 类封装，JRaft 将其定义为一个框架类，用于封装 JRaft 节点的创建和启动过程。方法 `RaftGroupService#start` 实现如下：\n\n```java\npublic synchronized Node start(final boolean startRpcServer) {\n    if (this.started) {\n        return this.node;\n    }\n    // 校验节点地址的有效性，不允许设置 IP 为 0.0.0.0\n    if (this.serverId == null\n            || this.serverId.getEndpoint() == null\n            || this.serverId.getEndpoint().equals(new Endpoint(Utils.IP_ANY, 0))) {\n        throw new IllegalArgumentException(\"Blank serverId:\" + this.serverId);\n    }\n\n    // 组 ID 不允许为空\n    if (StringUtils.isBlank(this.groupId)) {\n        throw new IllegalArgumentException(\"Blank group id\" + this.groupId);\n    }\n\n    // 记录进程内的 RPC 服务地址列表\n    NodeManager.getInstance().addAddress(this.serverId.getEndpoint());\n\n    // 创建并初始化 raft 节点\n    this.node = RaftServiceFactory.createAndInitRaftNode(this.groupId, this.serverId, this.nodeOptions);\n    if (startRpcServer) {\n        // 启动节点\n        this.rpcServer.init(null);\n    } else {\n        LOG.warn(\"RPC server is not started in RaftGroupService.\");\n    }\n    this.started = true;\n    LOG.info(\"Start the RaftGroupService successfully.\");\n    return this.node;\n}\n```\n\n其中创建并初始化 JRaft 节点的过程实际上是委托给了 `Node#init` 方法执行。Node 接口用于描绘一个 JRaft 节点，是整个 JRaft 算法库中最核心的类，本系列文章对于 JRaft 设计和实现的分析基本上都围绕着 Node 接口展开。我们将在本文的后面小节对 JRaft 节点的初始化过程进行展开分析。\n\n### 整体架构设计\n\n作为本系列文章的第一篇，在开始剖析源码之前，我打算用一小节的篇幅对 JRaft 的整体架构设计进行一个简单的介绍，这样能够让读者对 JRaft 的实现有一个整体层面的认知。\n\n![image](/images/2020/jraft-architecture.png)\n\n上图描绘了 JRaft 的整体架构设计，可以大致将 JRaft 的实现分为以下几个模块：\n\n- __数据存储模块__ ：包括日志数据存储、元数据存储，以及快照数据存储。\n- __日志复制模块__ ：JRaft 针对每个 Follower 节点都会为其创建并绑定一个复制器 Replicator 实例，Replicator 主要负责向对应的 Follower 节点复制数据、安装快照，以及维持心跳。ReplicatorGroup 负责管理一个 group 维度下的所有复制器 Replicator 实例。\n- __周期性任务计时器__ ：计时器在整个 Raft 算法的选主过程中起着至关重要的作用，JRaft 默认借鉴 Netty 的单层时间轮算法实现了一个高效的计时器，并应用到预选举、正式选举、周期性生成快照，以及 Leader 节点角色降级等多个计时场景。\n- __选票箱模块__ ：Raft 算法的共识决策采用多数投票机制，所以选票和选票箱是对这一机制的直观实现。\n- __集群配置管理模块__ ：Raft 作为一个服务于分布式应用的协议，免不了会遇到节点的上下线、网络分区等问题，所以需要对集群中的节点进行管理，以保证整个协议的正常运行。\n- __状态机调度模块__ ：前面我们已经对状态机 StateMachine 进行了一个简单的介绍，而状态机调度器 FSMCaller 相当于在 JRaft 集群与业务 StateMachine 实现之间建立了一座桥梁，用于调度业务 StateMachine 的运行。\n- __CLI 模块__ ：CLI 即 Client CommandLine Service，是在 JRaft 节点提供的 RPC 服务中暴露的一系列用于管理 JRaft 集群的服务接口，例如增删节点、变更节点配置、重置节点配置，以及转移 Leader 节点等功能。\n\n作为基于 JRaft 算法库实现的应用程序，我们通常可以基于 CLI 服务管理 JRaft 集群，实现 StateMachine 接口以感知 JRaft 集群的运行状态，以及调用 `Node#apply` 方法向 JRaft 集群提交指令。这些指令在被 JRaft 成功复制到过半数的节点上之后，最终会通过调用 `StateMachine#onApply` 方法透传给业务，由业务负责处理这些指令。\n\n### 节点初始化\n\n在对 JRaft 的整体架构设计有一个基本的认知之后，本文的最后我们来分析一下 JRaft 节点的初始化启动过程。前面我们通过 Leader 选举的例子演示了 JRaft 的基本使用，JRaft 的使用可以简单概括为以下四个步骤：\n\n1. 实现 StateMachine 接口，并创建状态机实例；\n2. 初始化 NodeOptions 配置对象，用于设置节点的运行参数；\n3. 基于 NodeOptions 配置对象创建并初始化 Node 实例；\n4. 启动节点，以 RPC 服务的方式运行。\n\n其中步骤 1 和 2 都比较简单，通过前面的示例可以一目了然，本小节我们重点分析一下步骤 3 和 4，看看 JRaft 是如何初始化和启动一个 JRaft 参与节点的。我们从 `Node#init` 方法切入，该方法实现如下：\n\n```java\npublic boolean init(final NodeOptions opts) {\n    Requires.requireNonNull(opts, \"Null node options\");\n    Requires.requireNonNull(opts.getRaftOptions(), \"Null raft options\");\n    Requires.requireNonNull(opts.getServiceFactory(), \"Null jraft service factory\");\n    this.serviceFactory = opts.getServiceFactory();\n    this.options = opts;\n    this.raftOptions = opts.getRaftOptions();\n    this.metrics = new NodeMetrics(opts.isEnableMetrics());\n    this.serverId.setPriority(opts.getElectionPriority());\n    this.electionTimeoutCounter = 0;\n\n    // 节点 IP 不允许设置为 0.0.0.0\n    if (this.serverId.getIp().equals(Utils.IP_ANY)) {\n        LOG.error(\"Node can't started from IP_ANY.\");\n        return false;\n    }\n\n    // 正常在初始化 Node 之前需要调用 NodeManager#addAddress 方法记录当前节点地址\n    if (!NodeManager.getInstance().serverExists(this.serverId.getEndpoint())) {\n        LOG.error(\"No RPC server attached to, did you forget to call addService?\");\n        return false;\n    }\n\n    // 创建并初始化延时任务调度器 TimerManager，负责 JRaft 内部的延时任务调度\n    this.timerManager = TIMER_FACTORY.getRaftScheduler(\n            this.options.isSharedTimerPool(),\n            this.options.getTimerPoolSize(), \"JRaft-Node-ScheduleThreadPool\");\n\n    // Init timers\n    final String suffix = getNodeId().toString();\n\n    // 创建正式选举计时器（周期： 1s ~ 2s）\n    String name = \"JRaft-VoteTimer-\" + suffix;\n    this.voteTimer = new RepeatedTimer(name, this.options.getElectionTimeoutMs(),\n            TIMER_FACTORY.getVoteTimer(this.options.isSharedVoteTimer(), name)) {\n\n        @Override\n        protected void onTrigger() {\n            handleVoteTimeout();\n        }\n\n        @Override\n        protected int adjustTimeout(final int timeoutMs) {\n            return randomTimeout(timeoutMs);\n        }\n    };\n\n    // 创建预选举计时器（周期：1s ~ 2s）\n    name = \"JRaft-ElectionTimer-\" + suffix;\n    this.electionTimer = new RepeatedTimer(name, this.options.getElectionTimeoutMs(),\n            TIMER_FACTORY.getElectionTimer(this.options.isSharedElectionTimer(), name)) {\n\n        @Override\n        protected void onTrigger() {\n            handleElectionTimeout();\n        }\n\n        @Override\n        protected int adjustTimeout(final int timeoutMs) {\n            return randomTimeout(timeoutMs);\n        }\n    };\n\n    // 创建角色降级计时器（周期：0.5s）\n    name = \"JRaft-StepDownTimer-\" + suffix;\n    this.stepDownTimer = new RepeatedTimer(name, this.options.getElectionTimeoutMs() >> 1,\n            TIMER_FACTORY.getStepDownTimer(this.options.isSharedStepDownTimer(), name)) {\n\n        @Override\n        protected void onTrigger() {\n            handleStepDownTimeout();\n        }\n    };\n\n    // 创建快照周期性生成计时器（周期：1h）\n    name = \"JRaft-SnapshotTimer-\" + suffix;\n    this.snapshotTimer = new RepeatedTimer(name, this.options.getSnapshotIntervalSecs() * 1000,\n            TIMER_FACTORY.getSnapshotTimer(this.options.isSharedSnapshotTimer(), name)) {\n\n        private volatile boolean firstSchedule = true;\n\n        @Override\n        protected void onTrigger() {\n            handleSnapshotTimeout();\n        }\n\n        @Override\n        protected int adjustTimeout(final int timeoutMs) {\n            if (!this.firstSchedule) {\n                return timeoutMs;\n            }\n\n            // Randomize the first snapshot trigger timeout\n            this.firstSchedule = false;\n            if (timeoutMs > 0) {\n                int half = timeoutMs / 2;\n                return half + ThreadLocalRandom.current().nextInt(half);\n            } else {\n                return timeoutMs;\n            }\n        }\n    };\n\n    // 创建集群节点配置管理器\n    this.configManager = new ConfigurationManager();\n\n    // 初始化 Task 处理相关的 disruptor 队列，用于异步处理业务调用 Node#apply 方法向集群提交的 Task 列表\n    this.applyDisruptor = DisruptorBuilder.<LogEntryAndClosure>newInstance() //\n            .setRingBufferSize(this.raftOptions.getDisruptorBufferSize()) //\n            .setEventFactory(new LogEntryAndClosureFactory()) //\n            .setThreadFactory(new NamedThreadFactory(\"JRaft-NodeImpl-Disruptor-\", true)) //\n            .setProducerType(ProducerType.MULTI) //\n            .setWaitStrategy(new BlockingWaitStrategy()) //\n            .build();\n    this.applyDisruptor.handleEventsWith(new LogEntryAndClosureHandler());\n    this.applyDisruptor.setDefaultExceptionHandler(new LogExceptionHandler<Object>(getClass().getSimpleName()));\n    this.applyQueue = this.applyDisruptor.start();\n    if (this.metrics.getMetricRegistry() != null) {\n        this.metrics.getMetricRegistry().register(\"jraft-node-impl-disruptor\", new DisruptorMetricSet(this.applyQueue));\n    }\n\n    // 创建状态机调度器\n    this.fsmCaller = new FSMCallerImpl();\n\n    // 初始化日志数据存储模块\n    if (!initLogStorage()) {\n        LOG.error(\"Node {} initLogStorage failed.\", getNodeId());\n        return false;\n    }\n\n    // 初始化元数据存储模块\n    if (!initMetaStorage()) {\n        LOG.error(\"Node {} initMetaStorage failed.\", getNodeId());\n        return false;\n    }\n\n    // 初始化状态机调度器\n    if (!initFSMCaller(new LogId(0, 0))) {\n        LOG.error(\"Node {} initFSMCaller failed.\", getNodeId());\n        return false;\n    }\n\n    // 创建并初始化选票箱 BallotBox，每个节点绑定一个选票箱\n    this.ballotBox = new BallotBox();\n    final BallotBoxOptions ballotBoxOpts = new BallotBoxOptions();\n    ballotBoxOpts.setWaiter(this.fsmCaller);\n    // closureQueue 在初始化 FSMCaller 时创建，相互共用\n    ballotBoxOpts.setClosureQueue(this.closureQueue);\n    if (!this.ballotBox.init(ballotBoxOpts)) {\n        LOG.error(\"Node {} init ballotBox failed.\", getNodeId());\n        return false;\n    }\n\n    // 初始化快照数据存储模块\n    if (!initSnapshotStorage()) {\n        LOG.error(\"Node {} initSnapshotStorage failed.\", getNodeId());\n        return false;\n    }\n\n    // 对日志数据进行一致性校验\n    final Status st = this.logManager.checkConsistency();\n    if (!st.isOk()) {\n        LOG.error(\"Node {} is initialized with inconsistent log, status={}.\", getNodeId(), st);\n        return false;\n    }\n\n    // 初始化集群节点配置，优先从日志中恢复\n    this.conf = new ConfigurationEntry();\n    this.conf.setId(new LogId());\n    // if have log using conf in log, else using conf in options\n    if (this.logManager.getLastLogIndex() > 0) {\n        checkAndSetConfiguration(false);\n    } else {\n        this.conf.setConf(this.options.getInitialConf());\n        // 以初始节点中的最大优先级初始化 targetPriority，用于控制当前节点是否继续发起预选举\n        this.targetPriority = getMaxPriorityOfNodes(this.conf.getConf().getPeers());\n    }\n\n    // 如果初始集群列表不为空，则需要校验其有效性，即 peers 不为空，且不能和 learners 有交集\n    if (!this.conf.isEmpty()) {\n        Requires.requireTrue(this.conf.isValid(), \"Invalid conf: %s\", this.conf);\n    } else {\n        LOG.info(\"Init node {} with empty conf.\", this.serverId);\n    }\n\n    // TODO RPC service and ReplicatorGroup is in cycle dependent, refactor it\n    // 创建复制器 Replicator 管理组\n    this.replicatorGroup = new ReplicatorGroupImpl();\n    // 创建 RPC 客户端\n    this.rpcService = new DefaultRaftClientService(this.replicatorGroup);\n    final ReplicatorGroupOptions rgOpts = new ReplicatorGroupOptions();\n    rgOpts.setHeartbeatTimeoutMs(heartbeatTimeout(this.options.getElectionTimeoutMs()));\n    rgOpts.setElectionTimeoutMs(this.options.getElectionTimeoutMs());\n    rgOpts.setLogManager(this.logManager);\n    rgOpts.setBallotBox(this.ballotBox);\n    rgOpts.setNode(this);\n    rgOpts.setRaftRpcClientService(this.rpcService);\n    rgOpts.setSnapshotStorage(this.snapshotExecutor != null ? this.snapshotExecutor.getSnapshotStorage() : null);\n    rgOpts.setRaftOptions(this.raftOptions);\n    rgOpts.setTimerManager(this.timerManager);\n\n    // Adds metric registry to RPC service.\n    this.options.setMetricRegistry(this.metrics.getMetricRegistry());\n\n    // 初始化 RPC 客户端\n    if (!this.rpcService.init(this.options)) {\n        LOG.error(\"Fail to init rpc service.\");\n        return false;\n    }\n    // 初始化复制器管理组\n    this.replicatorGroup.init(new NodeId(this.groupId, this.serverId), rgOpts);\n\n    // 创建并初始化只读服务，用于支持线性一致性读\n    this.readOnlyService = new ReadOnlyServiceImpl();\n    final ReadOnlyServiceOptions rosOpts = new ReadOnlyServiceOptions();\n    rosOpts.setFsmCaller(this.fsmCaller);\n    rosOpts.setNode(this);\n    rosOpts.setRaftOptions(this.raftOptions);\n    if (!this.readOnlyService.init(rosOpts)) {\n        LOG.error(\"Fail to init readOnlyService.\");\n        return false;\n    }\n\n    // 切换节点角色为 FOLLOWER\n    this.state = State.STATE_FOLLOWER;\n\n    if (LOG.isInfoEnabled()) {\n        LOG.info(\"Node {} init, term={}, lastLogId={}, conf={}, oldConf={}.\",\n                getNodeId(), this.currTerm, this.logManager.getLastLogId(false), this.conf.getConf(), this.conf.getOldConf());\n    }\n\n    // 如果启用了快照生成机制，则启动周期性快照生成任务\n    if (this.snapshotExecutor != null && this.options.getSnapshotIntervalSecs() > 0) {\n        LOG.debug(\"Node {} start snapshot timer, term={}.\", getNodeId(), this.currTerm);\n        this.snapshotTimer.start();\n    }\n\n    // 尝试角色降级，主要用于初始化本地状态，并启动预选举计时器\n    if (!this.conf.isEmpty()) {\n        stepDown(this.currTerm, false, new Status());\n    }\n\n    if (!NodeManager.getInstance().add(this)) {\n        LOG.error(\"NodeManager add {} failed.\", getNodeId());\n        return false;\n    }\n\n    // Now the raft node is started , have to acquire the writeLock to avoid race conditions\n    this.writeLock.lock();\n    // 如果当前集群只有自己一个节点，则尝试选举自己为主节点\n    if (this.conf.isStable() && this.conf.getConf().size() == 1 && this.conf.getConf().contains(this.serverId)) {\n        // The group contains only this server which must be the LEADER, trigger the timer immediately.\n        electSelf();\n    } else {\n        this.writeLock.unlock();\n    }\n\n    return true;\n}\n```\n\n整个 JRaft 节点的初始化过程执行了大量的工作，整体可以概括为以下几个方面：\n\n- 创建并初始化延时任务调度器 TimerManager，主要用于处理内部的延时任务（与周期性任务相区分）。\n- 创建计时器，用于执行周期性任务，包括：预选举计时器（electionTimer）、正式选举计时器（voteTimer）、角色降级计时器（stepDownTimer），以及快照周期性生成计时器（snapshotTimer）。\n- 创建集群节点配置管理器 ConfigurationManager，并初始化集群节点配置信息。\n- 初始化 Task 处理相关的 disruptor 队列，用于异步处理业务调用 `Node#apply` 方法向集群提交的 Task 列表。\n- 初始化日志数据存储模块，并对日志数据执行一致性校验。\n- 初始化元数据存储模块。\n- 初始化快照数据存储模块。\n- 创建并初始化状态机调度器 FSMCaller。\n- 创建并初始化选票箱 BallotBox。\n- 创建并初始化复制器管理组 ReplicatorGroup。\n- 创建并初始化 RPC 客户端 RaftClientService。\n- 创建并初始化只读服务 ReadOnlyService，用于支持线性一致性读。\n- 如果启用了快照生成机制，则启动周期性快照生成任务。\n- 如果初始集群节点不为空，则尝试执行角色降级（stepdown），以对本地状态进行初始化，并启动预选举计时器。\n- 如果集群只有当前这一个节点，则尝试选举自己为 Leader。\n\n下面挑选几个稍微复杂一点的展开说明。\n\n#### 周期任务调度器\n\nRaft 算法的运行依赖于超时机制，所以在实现层面需要提供对应的计时器，用于调度周期性任务。上面在初始化 JRaft 节点期间构造了一系列的计时器，包括：预选举计时器（electionTimer）、正式选举计时器（voteTimer）、角色降级计时器（stepDownTimer），以及周期性快照生成计时器（snapshotTimer）。本小节将分析这些计时器背后的实现，即 RepeatedTimer 类。\n\n首先，我们先来体验一下 RepeatedTimer 的使用方式，如下：\n\n```java\nprivate static class TestRepeatedTimer extends RepeatedTimer {\n\n    public TestRepeatedTimer(String name, int timeoutMs) {\n        super(name, timeoutMs);\n    }\n\n    @Override\n    protected void onTrigger() {\n        System.out.println(\"on trigger\");\n    }\n\n    @Override\n    protected int adjustTimeout(int timeoutMs) {\n        // 随机化计时周期\n        return RandomUtils.nextInt(timeoutMs);\n    }\n\n}\n\nfinal TestRepeatedTimer timer = new TestRepeatedTimer(\"test\", (int) TimeUnit.SECONDS.toMillis(1L));\ntimer.start();\n```\n\n上述示例中我们通过继承 RepeatedTimer 抽象类定义了一个测试用的 TestRepeatedTimer 实现类，该实现类会周期性的往控制台打印“on trigger”字符串。方法 `RepeatedTimer#onTrigger` 是 RepeatedTimer 中声明的唯一一个抽象方法，我们需要通过该方法实现自己的周期性业务逻辑。上述示例中，我们还覆盖实现了 `RepeatedTimer#adjustTimeout` 方法，以实现在运行期间对计时周期进行随机化调整。最后，通过调用 `RepeatedTimer#start` 方法，我们可以启动该计时器。\n\n下面对 RepeatedTimer 的运行机制进行分析。RepeatedTimer 定义了如下构造方法：\n\n```java\npublic RepeatedTimer(final String name, final int timeoutMs) {\n    this(name, timeoutMs, new HashedWheelTimer(new NamedThreadFactory(name, true), 1, TimeUnit.MILLISECONDS, 2048));\n}\n\npublic RepeatedTimer(final String name, final int timeoutMs, final Timer timer) {\n    super();\n    this.name = name;\n    this.timeoutMs = timeoutMs;\n    this.stopped = true;\n    this.timer = Requires.requireNonNull(timer, \"timer\");\n}\n```\n\n其中 Timer 是一个接口（定义如下），其功能是延迟指定时间执行提交的任务，即 TimerTask。\n\n```java\npublic interface Timer {\n    Timeout newTimeout(final TimerTask task, final long delay, final TimeUnit unit);\n    Set<Timeout> stop();\n}\n```\n\n围绕 Timer 接口，JRaft 提供了 DefaultTimer 和 HashedWheelTimer 两个实现类，其中前者基于 JDK 内置的 ScheduledExecutorService 实现，后者则基于单层时间轮算法实现。相对而言，HashedWheelTimer 较 DefaultTimer 在性能和精度层面表现更优，所以 JRaft 将其作为默认 Timer 应用于 RepeatedTimer 中。\n\n本小节重点关注 RepeatedTimer 的实现机制，关于 HashedWheelTimer 的设计和实现可以参考 Netty 相关的源码分析文章。接下来，我们从 `RepeatedTimer#start` 方法开始，该方法用于启动对应的计时器，实现如下：\n\n```java\npublic void start() {\n    this.lock.lock();\n    try {\n        // 计时器已经被销毁，不允许再被启动\n        if (this.destroyed) {\n            return;\n        }\n        // 计时器处于运行中，不需要再启动\n        if (!this.stopped) {\n            return;\n        }\n        this.stopped = false;\n        if (this.running) {\n            return;\n        }\n        // 标识计时器已经在运行\n        this.running = true;\n        // 调度\n        schedule();\n    } finally {\n        this.lock.unlock();\n    }\n}\n```\n\n上述方法主要是设置一些本地状态标识，对于首次启动的计时器会调用 `RepeatedTimer#schedule` 方法开始调度执行周期性任务，该方法实现如下：\n\n```java\nprivate void schedule() {\n    // 正常来说，这里的 timeout 应该为 null，否则说明上一轮任务还未执行完毕，尝试取消运行\n    if (this.timeout != null) {\n        this.timeout.cancel();\n    }\n    // 创建一个新的任务\n    final TimerTask timerTask = timeout -> {\n        try {\n            RepeatedTimer.this.run();\n        } catch (final Throwable t) {\n            LOG.error(\"Run timer task failed, taskName={}.\", RepeatedTimer.this.name, t);\n        }\n    };\n    // 提交给 Timer 延迟运行（仅运行一次），这里会调用 adjustTimeout 方法，用于调整计时周期\n    this.timeout = this.timer.newTimeout(timerTask, adjustTimeout(this.timeoutMs), TimeUnit.MILLISECONDS);\n}\n\npublic void run() {\n    this.invoking = true;\n    try {\n        // 调用业务逻辑\n        onTrigger();\n    } catch (final Throwable t) {\n        LOG.error(\"Run timer failed.\", t);\n    }\n    boolean invokeDestroyed = false;\n    this.lock.lock();\n    try {\n        this.invoking = false;\n        // 计时器被停止\n        if (this.stopped) {\n            this.running = false;\n            invokeDestroyed = this.destroyed;\n        }\n        // 本次任务调度完成，重新发起调度下一轮任务\n        else {\n            this.timeout = null; // 注意这里的 timeout 被置为 null\n            schedule();\n        }\n    } finally {\n        this.lock.unlock();\n    }\n    // 在计时器被停止时回调 onDestroy 方法\n    if (invokeDestroyed) {\n        onDestroy();\n    }\n}\n```\n\n具体运行逻辑如上述代码注释，当一轮定时任务执行完成时，如果计时器未被停止，则会调用 `RepeatedTimer#schedule` 方法提交下一轮任务，以此实现周期性任务调度。不同于常规计时器始终按照相同的时间间隔调度任务，RepeatedTimer 定义了一个 `RepeatedTimer#adjustTimeout` 方法，以支持在运行期间对调度间隔进行动态调整。\n\n这一机制对于 Raft 算法而言尤为重要，在 Raft 集群节点运行期间可能存在两个 Follower 节点同时发起 Leader 选举进程的情况，如果这两个 Follower 节点正好都得到半数投票，则本轮选举失败，需要在下一轮调度周期再次发起 Leader 选举请求。如果计时器始终按照相同的时间间隔进行调度，则这两个节点将会在未来相同的时刻再次发起 Leader 选举请求，如果不幸再次均分投票，则又拉长了集群的无 Leader 节点窗口，而通过动态调整调度间隔这么一个简单的策略则能够很好的避免此类问题。\n\n#### 数据存储\n\nJRaft 的数据存储层主要包含对三类数据的存储：日志数据、元数据，以及快照数据。其中日志数据存储的也就是前面提及到的 LogEntry 数据，包含系统内部运行产生的日志，以及业务向集群提交 Task 所生成的日志，日志数据默认采用 RocksDB 进行存储；元数据用于记录当前节点的 currentTerm 值，以及投票 votedFor 信息；快照数据是对日志数据存储的一种优化手段，用于将那些已经被应用的日志进行压缩存储，以节省磁盘空间占用，同时缩短新接入节点同步集群数据的时间。\n\n##### 日志数据存储\n\nRaft 节点在初始化期间会调用 `NodeImpl#initLogStorage` 方法初始化日志数据存储模块，该方法实现如下：\n\n```java\nprivate boolean initLogStorage() {\n    Requires.requireNonNull(this.fsmCaller, \"Null fsm caller\");\n    // 实例化日志存储服务，基于 RocksDBLogStorage 实现类\n    this.logStorage = this.serviceFactory.createLogStorage(this.options.getLogUri(), this.raftOptions);\n    // 创建并初始化日志管理器\n    this.logManager = new LogManagerImpl();\n    final LogManagerOptions opts = new LogManagerOptions();\n    // 设置 LogEntry 编解码器工厂，默认使用 LogEntryV2CodecFactory\n    opts.setLogEntryCodecFactory(this.serviceFactory.createLogEntryCodecFactory());\n    // 设置日志存储服务\n    opts.setLogStorage(this.logStorage);\n    // 设置集群节点配置管理器\n    opts.setConfigurationManager(this.configManager);\n    // 设置状态机调度器\n    opts.setFsmCaller(this.fsmCaller);\n    opts.setNodeMetrics(this.metrics);\n    opts.setDisruptorBufferSize(this.raftOptions.getDisruptorBufferSize());\n    opts.setRaftOptions(this.raftOptions);\n    // 初始化 LogManager\n    return this.logManager.init(opts);\n}\n```\n\n整个方法的主要逻辑在于创建和初始化 LogManager 实例。LogManager 是一个接口，由名称可以推断出它是一个日志管理器，基于 LogStorage 提供了对于日志数据的读写功能，定义如下：\n\n```java\npublic interface LogManager extends Lifecycle<LogManagerOptions>, Describer {\n\n    void addLastLogIndexListener(final LastLogIndexListener listener);\n    void removeLastLogIndexListener(final LastLogIndexListener listener);\n    void join() throws InterruptedException;\n    void appendEntries(final List<LogEntry> entries, StableClosure done);\n    void setSnapshot(final SnapshotMeta meta);\n    void clearBufferedLogs();\n    LogEntry getEntry(final long index);\n    long getTerm(final long index);\n    long getFirstLogIndex();\n    long getLastLogIndex();\n    long getLastLogIndex(final boolean isFlush);\n    LogId getLastLogId(final boolean isFlush);\n    ConfigurationEntry getConfiguration(final long index);\n    ConfigurationEntry checkAndSetConfiguration(final ConfigurationEntry current);\n    long wait(final long expectedLastLogIndex, final NewLogCallback cb, final Object arg);\n    boolean removeWaiter(final long id);\n    void setAppliedId(final LogId appliedId);\n    Status checkConsistency();\n\n}\n```\n\n本文重点分析 JRaft 节点的初始化过程，所以不打算对 LogManager 接口中声明各个方法实现逐一展开分析，后续遇到对相应方法的调用时再结合上下文进行介绍。JRaft 针对 LogManager 接口提供了 LogManagerImpl 实现类，对应的 `LogManager#init` 方法实现如下：\n\n```java\npublic boolean init(final LogManagerOptions opts) {\n    this.writeLock.lock();\n    try {\n        if (opts.getLogStorage() == null) {\n            LOG.error(\"Fail to init log manager, log storage is null\");\n            return false;\n        }\n        this.raftOptions = opts.getRaftOptions();\n        this.nodeMetrics = opts.getNodeMetrics();\n        this.logStorage = opts.getLogStorage();\n        this.configManager = opts.getConfigurationManager();\n\n        LogStorageOptions lsOpts = new LogStorageOptions();\n        lsOpts.setConfigurationManager(this.configManager);\n        lsOpts.setLogEntryCodecFactory(opts.getLogEntryCodecFactory());\n\n        // 初始化日志存储服务\n        if (!this.logStorage.init(lsOpts)) {\n            LOG.error(\"Fail to init logStorage\");\n            return false;\n        }\n\n        // 基于日志初始化本地 logIndex 和 term 值\n        this.firstLogIndex = this.logStorage.getFirstLogIndex();\n        this.lastLogIndex = this.logStorage.getLastLogIndex();\n        this.diskId = new LogId(this.lastLogIndex, getTermFromLogStorage(this.lastLogIndex));\n        this.fsmCaller = opts.getFsmCaller();\n        // 创建对应的 Disruptor 队列，用于异步处理日志操作相关的事件\n        this.disruptor = DisruptorBuilder.<StableClosureEvent>newInstance() //\n                .setEventFactory(new StableClosureEventFactory()) //\n                .setRingBufferSize(opts.getDisruptorBufferSize()) //\n                .setThreadFactory(new NamedThreadFactory(\"JRaft-LogManager-Disruptor-\", true)) //\n                .setProducerType(ProducerType.MULTI) //\n                // Use timeout strategy in log manager. If timeout happens, it will called reportError to halt the node.\n                .setWaitStrategy(new TimeoutBlockingWaitStrategy(\n                        this.raftOptions.getDisruptorPublishEventWaitTimeoutSecs(), TimeUnit.SECONDS)) //\n                .build();\n        this.disruptor.handleEventsWith(new StableClosureEventHandler());\n        this.disruptor.setDefaultExceptionHandler(new LogExceptionHandler<Object>(this.getClass().getSimpleName(),\n                (event, ex) -> reportError(-1, \"LogManager handle event error\")));\n        this.diskQueue = this.disruptor.start();\n        // ... metrics\n    } finally {\n        this.writeLock.unlock();\n    }\n    return true;\n}\n```\n\n整个 LogManager 的初始化过程除了对本地变量进行赋值外，主要做了两件事情：\n\n1. 初始化日志存储服务 LogStorage 实例。\n2. 创建并启动一个 Disruptor 队列，用于异步处理日志操作相关的事件。\n\nLogStorage 接口定义了与 LogEntry 存储相关的 API，包括读写、截断，以及获取 logIndex 和 term 等。JRaft 默认基于 RocksDB 存储引擎对 LogEntry 提供本地存储和读写，相应的实现类包括 RocksDBLogStorage 和 RocksDBSegmentLogStorage。\n\n本文同样重点关注针对 LogStorage 的初始化过程，由 `RocksDBLogStorage#init` 方法实现，如下：\n\n```java\npublic boolean init(final LogStorageOptions opts) {\n    Requires.requireNonNull(opts.getConfigurationManager(), \"Null conf manager\");\n    Requires.requireNonNull(opts.getLogEntryCodecFactory(), \"Null log entry codec factory\");\n    this.writeLock.lock();\n    try {\n        // 已经初始化过，避免重复初始化\n        if (this.db != null) {\n            LOG.warn(\"RocksDBLogStorage init() already.\");\n            return true;\n        }\n        // LogEntry 解码器，默认使用 AutoDetectDecoder，支持 V1 和 V2 版本\n        this.logEntryDecoder = opts.getLogEntryCodecFactory().decoder();\n        // LogEntry 编码器，默认使用 V2Encoder\n        this.logEntryEncoder = opts.getLogEntryCodecFactory().encoder();\n        Requires.requireNonNull(this.logEntryDecoder, \"Null log entry decoder\");\n        Requires.requireNonNull(this.logEntryEncoder, \"Null log entry encoder\");\n        this.dbOptions = createDBOptions();\n        if (this.openStatistics) {\n            this.statistics = new DebugStatistics();\n            this.dbOptions.setStatistics(this.statistics);\n        }\n\n        // 设置 RocksDB WriteOptions\n        this.writeOptions = new WriteOptions();\n        this.writeOptions.setSync(this.sync);\n        // 设置 RocksDB ReadOptions\n        this.totalOrderReadOptions = new ReadOptions();\n        this.totalOrderReadOptions.setTotalOrderSeek(true);\n\n        // 打开本地存储引擎 RocksDB，并从本地 conf 日志中恢复集群节点配置和 firstLogIndex 数据\n        return initAndLoad(opts.getConfigurationManager());\n    } catch (final RocksDBException e) {\n        LOG.error(\"Fail to init RocksDBLogStorage, path={}.\", this.path, e);\n        return false;\n    } finally {\n        this.writeLock.unlock();\n    }\n\n}\n\nprivate boolean initAndLoad(final ConfigurationManager confManager) throws RocksDBException {\n    this.hasLoadFirstLogIndex = false;\n    this.firstLogIndex = 1;\n    final List<ColumnFamilyDescriptor> columnFamilyDescriptors = new ArrayList<>();\n    // 设置 RocksDB ColumnFamilyOptions\n    final ColumnFamilyOptions cfOption = createColumnFamilyOptions();\n    this.cfOptions.add(cfOption);\n    // Column family to store configuration log entry.\n    columnFamilyDescriptors.add(new ColumnFamilyDescriptor(\"Configuration\".getBytes(), cfOption));\n    // Default column family to store user data log entry.\n    columnFamilyDescriptors.add(new ColumnFamilyDescriptor(RocksDB.DEFAULT_COLUMN_FAMILY, cfOption));\n\n    // 打开 RocksDB，并初始化对应的 ColumnFamily\n    openDB(columnFamilyDescriptors);\n    // 从 conf 中加载集群节点配置，以及 firstLogIndex 值，并从本地剔除 firstLogIndex 之前的 conf 和 data 数据\n    load(confManager);\n    // 模板方法\n    return onInitLoaded();\n}\n```\n\nJRaft 在 RocksDB 中定义了两个 ColumnFamily，除了默认的 ColumnFamily 外，还定义了一个名为 `Configuration` 的 ColumnFamily 用于存储集群节点配置相关的 LogEntry 实例，而默认的 ColumnFamily 除了包含 `Configuration` 中的数据之外，还用于存储用户数据相关的 LogEntry 实例。本文如不做特殊说明，均使用 conf family 指代前者，使用 data family 指代后者。\n\n上述方法中我们重点看一下对于 `RocksDBLogStorage#load` 方法的调用，该方法会从头遍历 conf family 中的数据，以从中加载之前集群节点的配置信息和 firstLogIndex 值。实现如下：\n\n```java\nprivate void load(final ConfigurationManager confManager) {\n    checkState();\n    // 按顺序从头开始遍历处理 RocksDB Conf ColumnFamily 中的数据\n    try (final RocksIterator it = this.db.newIterator(this.confHandle, this.totalOrderReadOptions)) {\n        it.seekToFirst();\n        while (it.isValid()) {\n            final byte[] ks = it.key();\n            final byte[] bs = it.value();\n\n            // key 的长度为 8，说明是一个 LogEntry 数据，LogEntry 数据的 key 是一个 long 型的 logIndex\n            if (ks.length == 8) {\n                // 基于解码器解码\n                final LogEntry entry = this.logEntryDecoder.decode(bs);\n                if (entry != null) {\n                    // 仅处理 ENTRY_TYPE_CONFIGURATION 类型的 LogEntry\n                    if (entry.getType() == EntryType.ENTRY_TYPE_CONFIGURATION) {\n                        // 基于日志数据设置集群节点配置\n                        final ConfigurationEntry confEntry = new ConfigurationEntry();\n                        confEntry.setId(new LogId(entry.getId().getIndex(), entry.getId().getTerm()));\n                        confEntry.setConf(new Configuration(entry.getPeers(), entry.getLearners()));\n                        if (entry.getOldPeers() != null) {\n                            confEntry.setOldConf(new Configuration(entry.getOldPeers(), entry.getOldLearners()));\n                        }\n                        if (confManager != null) {\n                            confManager.add(confEntry);\n                        }\n                    }\n                } else {\n                    LOG.warn(\"Fail to decode conf entry at index {}, the log data is: {}.\", Bits.getLong(ks, 0), BytesUtil.toHex(bs));\n                }\n            }\n            // 不是 LogEntry，目前只能是 meta/firstLogIndex，用于记录 firstLogIndex 值\n            else {\n                if (Arrays.equals(FIRST_LOG_IDX_KEY, ks)) {\n                    // 初始化 firstLogIndex\n                    setFirstLogIndex(Bits.getLong(bs, 0));\n                    // 剔除 [0, firstLogIndex) 之间的 conf 和 data 数据\n                    truncatePrefixInBackground(0L, this.firstLogIndex);\n                } else {\n                    LOG.warn(\"Unknown entry in configuration storage key={}, value={}.\", BytesUtil.toHex(ks), BytesUtil.toHex(bs));\n                }\n            }\n            it.next();\n        }\n    }\n}\n```\n\n具体执行过程如上述代码注释。JRaft 在从本地读取到 firstLogIndex 值之后，会启动一个后台线程，用于对本地记录的位于 firstLogIndex 之前的 LogEntry 进行剔除，实现如下：\n\n```java\nprivate void truncatePrefixInBackground(final long startIndex, final long firstIndexKept) {\n    // delete logs in background.\n    Utils.runInThread(() -> {\n        this.readLock.lock();\n        try {\n            if (this.db == null) {\n                return;\n            }\n            // 模板方法\n            onTruncatePrefix(startIndex, firstIndexKept);\n            // 剔除 [startIndex, firstIndexKept) 之间的 conf 和 data 数据\n            this.db.deleteRange(this.defaultHandle, getKeyBytes(startIndex), getKeyBytes(firstIndexKept));\n            this.db.deleteRange(this.confHandle, getKeyBytes(startIndex), getKeyBytes(firstIndexKept));\n        } catch (final RocksDBException | IOException e) {\n            LOG.error(\"Fail to truncatePrefix {}.\", firstIndexKept, e);\n        } finally {\n            this.readLock.unlock();\n        }\n    });\n}\n```\n\n上述方法在启动初始化期间会将 `[0, firstLogIndex)` 之间的 LogEntry 从本地 RocksDB 中剔除。除此之外，方法 `LogStorage#truncatePrefix` 在执行时也是委托上述方法完成对从 firstLogIndex 到指定 logIndex 之间的日志数据进行剔除操作。\n\nLogManager 在初始化期间还会创建并启动一个 Disruptor 队列，用于异步处理日志操作相关的事件，包括获取最新的 LogId、日志截断、重置日志数据存储服务，以及关闭日志管理器等。\n\n方法 `LogManagerImpl#offerEvent` 定义了往该 Disruptor 消息队列发送消息的逻辑，而具体处理消息的逻辑则有 StableClosureEventHandler 类实现。StableClosureEventHandler 类实现自 EventHandler 接口，对应的 `StableClosureEventHandler#onEvent` 方法依据事件类型对消息实施分别处理，具体实现后续结合应用场景进行深入分析，这里不再展开。\n\nJRaft 节点在初始化期间还会调用 `LogManager#checkConsistency` 方法对日志数据进行一致性校验，实现如下：\n\n```java\npublic Status checkConsistency() {\n    this.readLock.lock();\n    try {\n        Requires.requireTrue(this.firstLogIndex > 0);\n        Requires.requireTrue(this.lastLogIndex >= 0);\n        // 未生成过快照，所以 firstLogIndex 应该是 1\n        if (this.lastSnapshotId.equals(new LogId(0, 0))) {\n            if (this.firstLogIndex == 1) {\n                return Status.OK();\n            }\n            return new Status(RaftError.EIO, \"Missing logs in (0, %d)\", this.firstLogIndex);\n        }\n        // 生成过快照，则需要保证快照与当前数据的连续性\n        else {\n            if (this.lastSnapshotId.getIndex() >= this.firstLogIndex - 1\n                    && this.lastSnapshotId.getIndex() <= this.lastLogIndex) {\n                return Status.OK();\n            }\n            return new Status(RaftError.EIO, \"There's a gap between snapshot={%d, %d} and log=[%d, %d] \",\n                    this.lastSnapshotId.toString(), this.lastSnapshotId.getTerm(), this.firstLogIndex, this.lastLogIndex);\n        }\n    } finally {\n        this.readLock.unlock();\n    }\n}\n```\n\n校验的逻辑主要是确保快照数据与当前数据的连续性，不允许存在数据断层。\n\n##### 元数据存储\n\nJRaft 节点在初始化期间会调用 `NodeImpl#initMetaStorage` 方法初始化元数据存储模块，这里的元数据包括 currentTerm 值和当前节点的 votedFor 信息。该方法实现如下：\n\n```java\nprivate boolean initMetaStorage() {\n    // 实例化元数据存储服务，基于 LocalRaftMetaStorage 实现类\n    this.metaStorage = this.serviceFactory\n            .createRaftMetaStorage(this.options.getRaftMetaUri(), this.raftOptions);\n    RaftMetaStorageOptions opts = new RaftMetaStorageOptions();\n    opts.setNode(this);\n    // 初始化元数据存储服务\n    if (!this.metaStorage.init(opts)) {\n        LOG.error(\"Node {} init meta storage failed, uri={}.\", this.serverId, this.options.getRaftMetaUri());\n        return false;\n    }\n    // 基于本地元数据恢复 currentTerm 和 votedFor 属性值\n    this.currTerm = this.metaStorage.getTerm();\n    this.votedId = this.metaStorage.getVotedFor().copy();\n    return true;\n}\n```\n\nJRaft 定义了 RaftMetaStorage 接口用于抽象元数据存储服务，该接口的定义如下：\n\n```java\npublic interface RaftMetaStorage extends Lifecycle<RaftMetaStorageOptions>, Storage {\n\n    boolean setTerm(final long term);\n    long getTerm();\n    boolean setVotedFor(final PeerId peerId);\n    PeerId getVotedFor();\n    boolean setTermAndVotedFor(final long term, final PeerId peerId);\n\n}\n```\n\n针对该接口，JRaft 提供了 LocalRaftMetaStorage 实现类，基于本地文件系统采用 protobuf 协议对元数据执行序列化之后进行存储。\n\nLocalRaftMetaStorage 在初始化时（即执行 `LocalRaftMetaStorage#init` 方法期间）会从本地文件系统加载并反序列化元数据，以初始化 currentTerm 和 votedFor 属性值。运行期间对于这两个属性值的更改全部记录在内存中，并在关闭时（即执行 `LocalRaftMetaStorage#shutdown` 方法期间）将内存中的数据序列化后落盘。\n\n##### 快照数据存储\n\nJRaft 节点在初始化期间会调用 `NodeImpl#initSnapshotStorage` 方法初始化快照数据存储。与日志数据存储模块的设计相类似，JRaft 针对快照数据存储模块同样采用了操作与存储相分离的策略，其中 SnapshotExecutor 主要负责生成和安装快照，而 SnapshotStorage 则主要负责针对快照文件的读写，以及从远端 Leader 节点拷贝快照数据。\n\n方法 `NodeImpl#initSnapshotStorage` 的实现如下：\n\n```java\nprivate boolean initSnapshotStorage() {\n    // 未设置 snapshotUri，说明不希望启动快照模块\n    if (StringUtils.isEmpty(this.options.getSnapshotUri())) {\n        LOG.warn(\"Do not set snapshot uri, ignore initSnapshotStorage.\");\n        return true;\n    }\n    // 实例化快照执行器，用于处理快照相关操作\n    this.snapshotExecutor = new SnapshotExecutorImpl();\n    final SnapshotExecutorOptions opts = new SnapshotExecutorOptions();\n    opts.setUri(this.options.getSnapshotUri());\n    opts.setFsmCaller(this.fsmCaller);\n    opts.setNode(this);\n    opts.setLogManager(this.logManager);\n    opts.setAddr(this.serverId != null ? this.serverId.getEndpoint() : null);\n    opts.setInitTerm(this.currTerm);\n    opts.setFilterBeforeCopyRemote(this.options.isFilterBeforeCopyRemote());\n    // get snapshot throttle\n    opts.setSnapshotThrottle(this.options.getSnapshotThrottle());\n    // 初始化快照执行器\n    return this.snapshotExecutor.init(opts);\n}\n```\n\n上述实现主要是用来创建和初始化 SnapshotExecutor，同时我们也可以看到快照机制对于 Raft 算法而言并不是必须的。如果一个应用并不会让 Raft 算法的运行产生大量的日志文件，或者对应的日志无法被压缩，则无需启动快照机制。JRaft 在初始化快照存储模块时会检查应用是否设置了 snapshotUri 参数，如果未设置则表明业务不希望启动快照机制。\n\nSnapshotExecutor 的初始化过程主要是从本地加载最新的快照文件数据，对应的 `SnapshotExecutorImpl#init` 方法实现如下：\n\n```java\npublic boolean init(final SnapshotExecutorOptions opts) {\n    if (StringUtils.isBlank(opts.getUri())) {\n        LOG.error(\"Snapshot uri is empty.\");\n        return false;\n    }\n    this.logManager = opts.getLogManager();\n    this.fsmCaller = opts.getFsmCaller();\n    this.node = opts.getNode();\n    this.term = opts.getInitTerm();\n    // 创建快照存储服务，基于 LocalSnapshotStorage 实现类\n    this.snapshotStorage = this.node.getServiceFactory()\n            .createSnapshotStorage(opts.getUri(), this.node.getRaftOptions());\n    if (opts.isFilterBeforeCopyRemote()) {\n        this.snapshotStorage.setFilterBeforeCopyRemote();\n    }\n    if (opts.getSnapshotThrottle() != null) {\n        this.snapshotStorage.setSnapshotThrottle(opts.getSnapshotThrottle());\n    }\n    // 初始化快照存储服务，主要工作是从本地删除除最后一次快照所生成的快照文件之外的其它快照数据文件\n    if (!this.snapshotStorage.init(null)) {\n        LOG.error(\"Fail to init snapshot storage.\");\n        return false;\n    }\n    final LocalSnapshotStorage tmp = (LocalSnapshotStorage) this.snapshotStorage;\n    if (tmp != null && !tmp.hasServerAddr()) {\n        tmp.setServerAddr(opts.getAddr());\n    }\n    // 打开快照文件读取器\n    final SnapshotReader reader = this.snapshotStorage.open();\n    if (reader == null) {\n        return true;\n    }\n    // 加载快照元数据信息\n    this.loadingSnapshotMeta = reader.load();\n    if (this.loadingSnapshotMeta == null) {\n        LOG.error(\"Fail to load meta from {}.\", opts.getUri());\n        Utils.closeQuietly(reader);\n        return false;\n    }\n    LOG.info(\"Loading snapshot, meta={}.\", this.loadingSnapshotMeta);\n    this.loadingSnapshot = true;\n    this.runningJobs.incrementAndGet();\n    final FirstSnapshotLoadDone done = new FirstSnapshotLoadDone(reader);\n    // 加载最近一次的快照数据\n    Requires.requireTrue(this.fsmCaller.onSnapshotLoad(done));\n    try {\n        done.waitForRun();\n    } catch (final InterruptedException e) {\n        LOG.warn(\"Wait for FirstSnapshotLoadDone run is interrupted.\");\n        Thread.currentThread().interrupt();\n        return false;\n    } finally {\n        Utils.closeQuietly(reader);\n    }\n    if (!done.status.isOk()) {\n        LOG.error(\"Fail to load snapshot from {}, FirstSnapshotLoadDone status is {}.\", opts.getUri(), done.status);\n        return false;\n    }\n    return true;\n}\n```\n\n关于加载快照数据的执行过程（即 `FSMCaller#onSnapshotLoad` 方法的实现）我们将在后面介绍 JRaft 快照机制的文章中针对性的介绍，这里暂且跳过。\n\n#### 状态机调度器\n\n前面我们曾简单介绍过 StateMachine 接口，JRaft 通过该接口抽象描述了 Raft 算法中引入的状态机。这也是 JRaft 向业务透传自己运行状态的核心接口，业务可以通过该接口捕获 JRaft 的运行事件。除了最核心的应用 LogEntry 中的指令外，还包括当前节点作为 LEADER 或 FOLLOWER 角色的启停事件、集群节点配置变更、快照加载与存储，以及集群运行错误与停机等。\n\nStateMachine 接口定义如下：\n\n```java\npublic interface StateMachine {\n\n    void onApply(final Iterator iter);\n    void onShutdown();\n    void onSnapshotSave(final SnapshotWriter writer, final Closure done);\n    boolean onSnapshotLoad(final SnapshotReader reader);\n    void onLeaderStart(final long term);\n    void onLeaderStop(final Status status);\n    void onError(final RaftException e);\n    void onConfigurationCommitted(final Configuration conf);\n    void onStopFollowing(final LeaderChangeContext ctx);\n    void onStartFollowing(final LeaderChangeContext ctx);\n\n}\n```\n\n那么 JRaft 是如何将这些事件通知到业务的呢？具体点来说，通知到业务实现的状态机的呢？这就是状态机调度器 FSMCaller 所做的工作。该接口定义如下：\n\n```java\npublic interface FSMCaller extends Lifecycle<FSMCallerOptions>, Describer {\n\n    void addLastAppliedLogIndexListener(final LastAppliedLogIndexListener listener);\n    boolean onCommitted(final long committedIndex);\n    boolean onSnapshotLoad(final LoadSnapshotClosure done);\n    boolean onSnapshotSave(final SaveSnapshotClosure done);\n    boolean onLeaderStop(final Status status);\n    boolean onLeaderStart(final long term);\n    boolean onStartFollowing(final LeaderChangeContext ctx);\n    boolean onStopFollowing(final LeaderChangeContext ctx);\n    boolean onError(final RaftException error);\n    long getLastAppliedIndex();\n    void join() throws InterruptedException;\n\n}\n```\n\n从 StateMachine 和 FSMCaller 接口的定义上是不是可以看出有一种相互呼应的感觉呢。简而言之，JRaft 通过调用 FSMCaller 中声明的方法实现将内部运行状态透传给业务，而 FSMCaller 在本地则基于 Disruptor 消息队列以事件的形式缓存这些内部状态，并通过异步的方式回调 StateMachine 接口声明的相应方法，这就是 FSMCaller 整体的运行逻辑。\n\n本小节重点介绍 FSMCaller 的初始化过程和整体执行流程，具体实现细节层面先不展开，留到后面结合具体场景再深入分析。\n\nJRaft 节点在初始化期间会调用 `NodeImpl#initFSMCaller` 方法对 FSMCaller 进行初始化，该方法实现如下：\n\n```java\nprivate boolean initFSMCaller(final LogId bootstrapId) {\n    if (this.fsmCaller == null) {\n        LOG.error(\"Fail to init fsm caller, null instance, bootstrapId={}.\", bootstrapId);\n        return false;\n    }\n    // 创建封装 Closure 的队列，基于 LinkedList 实现\n    this.closureQueue = new ClosureQueueImpl();\n    final FSMCallerOptions opts = new FSMCallerOptions();\n    opts.setAfterShutdown(status -> afterShutdown());\n    opts.setLogManager(this.logManager);\n    opts.setFsm(this.options.getFsm());\n    opts.setClosureQueue(this.closureQueue);\n    opts.setNode(this);\n    opts.setBootstrapId(bootstrapId);\n    opts.setDisruptorBufferSize(this.raftOptions.getDisruptorBufferSize());\n    // 初始化状态机调度器\n    return this.fsmCaller.init(opts);\n}\n```\n\nFSMCaller 在初始化期间（即执行 `FSMCallerImpl#init` 方法）除了完成一些属性的赋值工作外，主要是创建和启动了一个 Disruptor 队列，用于异步处理各种状态机事件：\n\n```java\nthis.disruptor = DisruptorBuilder.<ApplyTask>newInstance() //\n        .setEventFactory(new ApplyTaskFactory()) //\n        .setRingBufferSize(opts.getDisruptorBufferSize()) //\n        .setThreadFactory(new NamedThreadFactory(\"JRaft-FSMCaller-Disruptor-\", true)) //\n        .setProducerType(ProducerType.MULTI) //\n        .setWaitStrategy(new BlockingWaitStrategy()) //\n        .build();\nthis.disruptor.handleEventsWith(new ApplyTaskHandler());\nthis.disruptor.setDefaultExceptionHandler(new LogExceptionHandler<Object>(getClass().getSimpleName()));\nthis.taskQueue = this.disruptor.start();\n```\n\n方法 `FSMCallerImpl#enqueueTask` 用于往该 Disruptor 队列写入具体的状态机事件，而 FSMCallerImpl 之于 FSMCaller 接口中声明的方法在实现层面基本上都是简单的调用了该方法。这里以 `FSMCallerImpl#onCommitted` 方法为例，实现如下：\n\n```java\npublic boolean onCommitted(final long committedIndex) {\n    return enqueueTask((task, sequence) -> {\n        task.type = TaskType.COMMITTED;\n        task.committedIndex = committedIndex;\n    });\n}\n\nprivate boolean enqueueTask(final EventTranslator<ApplyTask> tpl) {\n    if (this.shutdownLatch != null) {\n        // Shutting down\n        LOG.warn(\"FSMCaller is stopped, can not apply new task.\");\n        return false;\n    }\n    // 尝试将事件发布到消息队列中\n    if (!this.taskQueue.tryPublishEvent(tpl)) {\n        setError(new RaftException(ErrorType.ERROR_TYPE_STATE_MACHINE,\n                new Status(RaftError.EBUSY, \"FSMCaller is overload.\")));\n        return false;\n    }\n    return true;\n}\n```\n\n那么 FSMCaller 又是怎么处理这些消息队列中的事件的呢？熟悉 Disruptor 的同学应该都知道这个时候应该去看 FSMCaller 是如何实现 EventHandler 接口的。FSMCaller 针对 EventHandler 接口定义了 ApplyTaskHandler 实现类：\n\n```java\nprivate class ApplyTaskHandler implements EventHandler<ApplyTask> {\n    // max committed index in current batch, reset to -1 every batch\n    private long maxCommittedIndex = -1;\n\n    @Override\n    public void onEvent(\n            final ApplyTask event, final long sequence, final boolean endOfBatch) throws Exception {\n        this.maxCommittedIndex = runApplyTask(event, this.maxCommittedIndex, endOfBatch);\n    }\n}\n```\n\nApplyTaskHandler 通过调用 `FSMCallerImpl#runApplyTask` 方法对 Disruptor 消息队列中缓存的状态机事件进行处理。该方法本质上是一个事件分发器，基于具体的状态机事件类型调用对应的 `do*` 方法实现对事件的处理操作。\n\n方法 `FSMCallerImpl#runApplyTask` 的实现比较直观，不再展开，关于各个 `do*` 方法的实现将留到后续结合具体场景展开分析。\n\n#### 选票箱\n\n投票机制是 Raft 算法运行的基础，JRaft 在实现上为每个节点都设置了一个选票箱 BallotBox 实例，用于对 LogEntry 是否提交进行仲裁。\n\nJRaft 节点在初始化期间会创建并初始化自己的选票箱，具体过程比较简单，实现如下：\n\n```java\nthis.ballotBox = new BallotBox();\nfinal BallotBoxOptions ballotBoxOpts = new BallotBoxOptions();\nballotBoxOpts.setWaiter(this.fsmCaller);\n// closureQueue 在初始化 FSMCaller 时创建，相互共用\nballotBoxOpts.setClosureQueue(this.closureQueue);\nif (!this.ballotBox.init(ballotBoxOpts)) {\n    LOG.error(\"Node {} init ballotBox failed.\", getNodeId());\n    return false;\n}\n```\n\n这里需要注意的一点是，BallotBox 中持有的 ClosureQueue 实例是在前面介绍的 `NodeImpl#initFSMCaller` 中创建的，所以 FSMCaller 和 BallotBox 对象持有的 ClosureQueue 实例是同一个。BallotBox 负责往 ClosureQueue 中写数据，而 FSMCaller 则负责从 ClosureQueue 中读数据。\n\n### 总结\n\n本文我们通过一个 Leader 选举的示例介绍了 JRaft 算法库的基本使用，并对 JRaft 的整体架构设计和节点的初始化过程进行了分析。总的来说，JRaft 在模块划分上还是比较清晰的，不过也有值得吐槽的一点，例如 Node 类的实现太重，是否可以通过类似状态模式一类的思想重构一下？\n\n### 参考\n\n1. [Raft Consensus Algorithm](https://raft.github.io/)\n2. [SOFA-JRaft 官网](https://www.sofastack.tech/projects/sofa-jraft/overview/)\n3. [SOFAJRaft：生产级高性能 Java 实现](https://www.sofastack.tech/blog/sofa-jraft-deep-dive/)\n4. [SOFAJRaft：生产级 Raft 算法库存储模块剖析](https://www.sofastack.tech/blog/sofa-jraft-algorithm-storage-module-deep-dive/)\n","tags":["Raft","SOFA-JRaft"],"categories":["sofa"]},{"title":"Theia：可扩展的注解式配置注入组件","url":"/2020/04/23/java/theia/","content":"\nTheia 是一个 java 语言编写的，支持自定义扩展的注解式配置加载与注入组件，旨在以注解的方式加载任何可以被表示成 [Properties](https://docs.oracle.com/cd/E23095_01/Platform.93/ATGProgGuide/html/s0204propertiesfileformat01.html) 对象的配置，并注入给目标对象，同时支持当配置内容发生变更时回调更新。配置文件的来源可以是本地文件、网络，以及第三方配置系统。Theia 默认支持从 ClassPath 加载本地配置文件，并支持以 SPI 的方式扩展以支持更多的配置来源，例如从 ZK 加载配置等。\n\n特性一览：\n\n- 支持以注解的方式加载多种配置数据源，并注入给配置对象。\n- 支持预注入，预注入会校验配置的合法性，如果不合法则会放弃注入，避免配置出错影响服务的正常运行。\n- 支持配置变更时回调更新，默认关闭，并允许用户配置是否启用。\n- 内置基本类型转换器，用于将 String 类型配置项转换成目标类型对象。\n- 支持自定义类型转换器，以实现一些定制化的类型转换。\n- 支持以原生字符串或 Properties 对象的形式注入。\n- 支持监听注入过程（InjectEventListener）和更新过程（UpdateEventListener）。\n- 支持加载系统环境变量，并注入给配置对象。\n- 支持 `${}` 占位符替换，使用指定的配置项替换占位符。\n- 支持以 SPI 的方式扩展以支持更多类型的配置数据源。\n- 对于 Spring 应用，支持自动扫描、加载并初始化配置对象。\n\n<!-- more -->\n\n开源地址：[https://github.com/plotor/theia](https://github.com/plotor/theia)\n\n### 快速接入\n\n这里以加载并注入 ClassPath 配置文件 `configurable_options.properties` 为例，接入过程分为 4 步：\n\n1. 定义一个实现了 Options 接口的配置类 ExampleOptions；\n2. 为 ExampleOptions 类添加 `@Configurable` 注解，用于指定配置数据源路径；\n3. 调用 `ConfigManager#initialize` 方法初始化所有被管理的配置项；\n4. 调用 `ConfigManager#getOptions` 方法拿到目标 options 实例，以获取对应的配置信息。\n\nExampleOptions 的部分实现如下，完整实现可以参考源码：\n\n```java\n@Configurable(Constants.CP_PREFIX + \"configurable_options\")\npublic class ExampleOptions extends AbstractOptions {\n\n    private static final long serialVersionUID = -8145624960779711094L;\n\n    @Attribute(name = \"myFiles\")\n    private File[] files;\n\n    @Attribute(defaultValue = \"15\")\n    private int number;\n\n    @Attribute(name = \"property.message\")\n    private String propMessage;\n\n    @Attribute(defaultValue = \"1780000\")\n    public long longValue;\n\n    @Attribute(name = \"another.long.value\", defaultValue = \"1000000\")\n    public long anotherLongValue;\n\n    private Double floatingPointNumber;\n\n    @Attribute\n    private String fieldMessage;\n\n    @Attribute\n    private Boolean trueFalse;\n\n    @Attribute(name = \"list\", converter = ListConverter.class)\n    public List<String> list;\n\n    @Attribute(converter = SetConverter.class)\n    public Set<String> set;\n\n    // ... 省略部分实现\n\n    @Override\n    public void update() {\n        // 当配置发生变更时回调执行此方法\n    }\n\n    @Override\n    public boolean validate() {\n        // 此处实现配置校验逻辑\n    }\n\n}\n```\n\n初始化配置管理器：\n\n```java\nfinal ConfigManager configManager = ConfigManager.getInstance();\n// 初始化配置管理器\nconfigManager.initialize(\"org.zhenchao.theia.example\");\n// 获取 options 实例\nfinal ExampleOptions options = configManager.getOptions(ExampleOptions.class);\n// 获取具体的配置项\nSystem.out.println(options.getPropMessage());\n```\n\n好啦，就这么简单，接下去就可以愉快的使用配置项啦！\n\n如果是 Spring 应用，则只需要在对应的 Options 类上添加 `@Component` 注解，并在 Spring 配置文件中添加如下配置：\n\n```xml\n<bean class=\"org.zhenchao.theia.SpringInitializer\"/>\n```\n\nSpring 框架在启动期间会自动扫描所有被 `@Component` 注解的配置 Options 类，并完成加载和初始化过程。\n\n### 使用指南\n\n本小节针对快速接入中的各个步骤进行详细说明。首先来看 __步骤 1__ ，对于需要注入的 options，需要先实现 Options 接口，或继承 AbstractOptions 抽象类。Options 接口定义如下：\n\n```java\npublic interface Options extends Serializable {\n\n    /**\n     * This method will be invoked after successfully injected.\n     */\n    void update();\n\n    /**\n     * Validate that the configuration is correctly.\n     *\n     * @return {@code true} means correctly, or {@code false}.\n     */\n    boolean validate();\n\n}\n```\n\n其中 `Options#update` 方法会在成功完成注入时回调，可以用于对配置字段的二次解析。方法 `Options#validate` 需要由应用自己实现对于配置的合法性校验，该方法会在预注入时调用，如果返回 false 则会放弃后续的正式注入操作，并抛出异常。\n\n然后（ __步骤 2__ ），需要使用 `@Configurable` 注解为 options 关联对应的数据源，该注解定义如下：\n\n```java\npublic @interface Configurable {\n\n    /** The configuration resource, eg. ZK:/theia/example */\n    String resource() default \"\";\n\n    /** Alias for {@link #resource()} */\n    String value() default \"\";\n\n    /**\n     * Auto configure setting.\n     *\n     * {@code true} means the options will be detected and auto injected,\n     * otherwise you should instantiate and configure the options by manual.\n     */\n    boolean autoConfigure() default true;\n\n    /**\n     * Autoload configuration when found source update.\n     * {@code true} means ignore the {@link Constants#COMMONS_CONFIG_AUTOLOAD} config,\n     * default is {@link false}.\n     */\n    boolean autoload() default false;\n\n}\n```\n\n配置项 `Configurable#autoConfigure` 默认为 true，表示允许 ConfigManager 在初始化时自动实例化并注入配置项值，否则需要由开发人员自己完成实例化，并主动调用 `ConfigInjector#configureBean(Options)` 方法完成配置项值的注入。\n\n配置项 `Configurable#autoload` 默认为 false，当设置为 true 时则会在每次配置变更时回调执行 `Options#update` 方法，而忽略 `__commons_config_autoload` 配置。该配置项主要应用于加载 raw text 的场景，此时源配置不满足 Properties 文件格式，所以不能简单的添加 `__commons_config_autoload=true` 配置项以控制是否回调更新，这种场景下可以通过 `Configurable#autoload` 配置项来默认启用更新。\n\n完成与数据源的关联之后，接下来（ __步骤 3__ ）需要使用 `@Attribute` 注解为各个字段关联对应的配置项，注解定义如下：\n\n```java\npublic @interface Attribute {\n\n    /** Property name */\n    String name() default \"\";\n\n    /** Alias for {@link #name()} */\n    String value() default \"\";\n\n    /**\n     * Configure required.\n     *\n     * {@code true} means this field must be configured, otherwise will throw {@link ConfigException}.\n     */\n    boolean required() default true;\n\n    /** The default value when missing config. */\n    String defaultValue() default \"\";\n\n    /** Whether inject this field with {@link java.util.Properties} or {@link String} raw type. */\n    boolean raw() default false;\n\n    /** Convert the string to target field type. */\n    Class<? extends Converter> converter() default VoidConverter.class;\n\n}\n```\n\n各个配置项说明如下：\n\n- `name` 和 `value`：用于将当前 field 与对应的配置项名称进行关联，如果未指定则以当前属性名称作为配置项名称，强烈建议配置。\n- `required`：表示当前配置项是必须的，默认为 true，如果未指定默认值，且对应的配置项缺失则会抛出 ConfigException 异常。\n- `defaultValue`：默认值，如果对应的配置项缺失，则采用默认值注入。\n- `raw`：是否以原生类型（String 或 Properties）进行注入，需要注意的是，一个 options 中只能定义一个 `raw=true` 的配置项，且与一般的注入方式互斥。\n- `converter`：自定义类型转换器，会将 String 类型转换成目标类型后再进行注入。\n\n注解 `@Attribute` 可以修饰 field，也可以修饰 getter 或 setter 方法，如果未明确指定 `name`，则会基于注解的属性或方法（getter 或 setter）自动计算 `name` 值，但是强烈建议手动配置 `name` 值，避免出错。类型转换器不是必须的，配置库内置了对以下类型的自动转换：\n\n类型 | 转换器 | 说明\n--- | --- | ---\nboolean | BooleanConverter | 用于将字符串转换成 boolean 类型\nchar | CharacterConverter | 用于将字符串转换成 char 类型，提取字符串的首字母\nbyte | NumberConverter | 用于将字符串转换成 byte 类型，可以使用 `@NumberRadix` 指定原始值的进制类型，默认为 10 进制\nshort | NumberConverter | 用于将字符串转换成 short 类型，可以使用 `@NumberRadix` 指定原始值的进制类型，默认为 10 进制\nint | NumberConverter | 用于将字符串转换成 int 类型，可以使用 `@NumberRadix` 指定原始值的进制类型，默认为 10 进制\nlong | NumberConverter | 用于将字符串转换成 long 类型，可以使用 `@NumberRadix` 指定原始值的进制类型，默认为 10 进制\nfloat | NumberConverter | 用于将字符串转换成 float 类型，可以使用 `@NumberRadix` 指定原始值的进制类型，默认为 10 进制\ndouble | NumberConverter | 用于将字符串转换成 double 类型，可以使用 `@NumberRadix` 指定原始值的进制类型，默认为 10 进制\nString | StringConverter | 以字符串类型进行注入，区别于 raw 类型的 String 注入，后者使用整个配置文件进行注入\nArray | ArrayConverter | 用于将字符串按照英文逗号进行分割，并转换成目标数组类型，仅支持一维数组转换\nDate | DateConverter | 用于将字符串转换成 Date 类型，需要指定 `@DatePattern`\nCalendar | CalendarConverter | 用于将字符串转换成 Calendar 类型，依赖 DateConverter\nObject | GenericConverter | 将字符串转换成目标类型，相应的类需要具备一个包含 String 类型参数的构造方法\n\n以上转换器无需手动指定，配置库会依据目标类型自动检测，如果手动指定了类型转换器，则优先级更高。\n\n最后（ __步骤 4__ ），需要调用 `ConfigManager#initialize` 方法初始化和注入所有的配置项，如下：\n\n```java\nfinal ConfigManager configManager = ConfigManager.getInstance();\nfinal int count = configManager.initialize(\"org.zhenchao.theia.manager\");\nAssert.assertEquals(4, count);\nAssert.assertNotNull(configManager.getOptions(Options1.class));\nAssert.assertNotNull(configManager.getOptions(Options2.class));\nAssert.assertNotNull(configManager.getOptions(Options3.class));\nAssert.assertNotNull(configManager.getOptions(Options4.class));\nAssert.assertNull(configManager.getOptions(Options5.class));\nAssert.assertSame(configManager.getOptions(Options1.class), configManager.getOptions(Options1.class));\nAssert.assertNotSame(configManager.getOptions(Options1.class), configManager.getOptions(Options2.class));\n\n// configure by manual\nfinal Options5 options5 = new Options5();\nconfigManager.getInjector().configureBean(options5);\nAssert.assertNotNull(configManager.getOptions(Options5.class));\nAssert.assertSame(options5, configManager.getOptions(Options5.class));\n```\n\nConfigManager 在执行初始化（即调用 `ConfigManager#initialize` 方法）时允许指定扫描 Options 的根包名，如果没有设置则会扫描所有的包，推荐设置。\n\nConfigManager 提供了 `ConfigManager#getOptions` 方法用于依据类型获取对应的 options 实例。\n\n工具类 Parser 定义了 `Parser#toList` 和 `Parser#toSet` 方法，抽象了字符串数组到 List 和 Set 类型的转换，可以依据场景考虑使用。\n\n最后来聊聊监听机制，配置库定义了两种监听器：InjectEventListener 和 UpdateEventListener。其中，InjectEventListener 用于监听注入过程，定义如下：\n\n```java\npublic interface InjectEventListener extends EventListener {\n\n    /**\n     * This method will be invoked before injection.\n     *\n     * @param options The options bean that will be injected.\n     */\n    void prevHandle(final Options options);\n\n    /**\n     * This method will be invoked after injection.\n     *\n     * @param options The options bean that has been injected.\n     */\n    void postHandle(final Options options);\n\n}\n```\n\n此类监听器会在执行注入过程前后被调用，可以调用 `ConfigInjector#registerInjectListener` 方法和 `ConfigInjector#removeInjectListener` 方法分别注册和注销监听器。\n\nUpdateEventListener 则用于监听更新过程，定义如下：\n\n```java\npublic interface UpdateEventListener extends EventListener {\n\n    /**\n     * This method will be invoked before update.\n     *\n     * @param options The options bean that will be updated.\n     */\n    void prevHandle(Options options);\n\n    /**\n     * This method will be invoked after update.\n     *\n     * @param options The options bean that has been updated.\n     */\n    void postHandle(Options options);\n\n}\n```\n\n此类监听器会在调用 `Options#update` 方法前后被调用，可以调用 `ConfigInjector#registerUpdateListener` 方法和 `ConfigInjector#removeUpdateListener` 方法分别注册和注销监听器。\n\n### 如何扩展\n\n除了内建对 ClassPath 路径下配置的加载，Theia 还允许用户对支持的配置数据源进行扩展。接入一个新的数据源只需要继承 AbstractSourceProvider 抽象类即可，然后在项目的 `/META-INF/services` 目录下新建一个名为 `org.zhenchao.theia.source.provider.SourceProvider` 的文件，添加以下内容：\n\n```text\norg.zhenchao.theia.source.provider.ClasspathSourceProvider\n// your source provider class name here\n```\n\n配置库基于 jdk 内置的 SPI 机制加载所有的 SourceProvider。最后调用 `ConfUtils#registerPrefix` 静态方法注册对应的 prefix 标识即可。\n\n下面以从 zookeeper 加载配置为例演示如何实现扩展，首先继承 AbstractSourceProvider 实现一个 ZkSourceProvider，如下：\n\n```java\npublic class ZkSourceProvider extends AbstractSourceProvider implements SourceProvider {\n\n    private final CuratorFramework zkClient;\n\n    private final Set<Source> sourceRegistry = new HashSet<>();\n\n    public ZkSourceProvider() {\n        RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n        this.zkClient = CuratorFrameworkFactory.newClient(\"127.0.0.1:2181\", retryPolicy);\n        this.zkClient.start();\n    }\n\n    @Override\n    protected Properties doLoadProperties(final Source source, final PropertiesBuilder builder) throws ConfigException {\n        final Class<?> optionsClass = source.getOptionsClass();\n        final String resourceName = this.resourceName(source);\n        log.info(\"Load zk configuration, resource[{}], options[{}].\", resourceName, optionsClass);\n\n        try {\n            final String zkPath = this.toZkPath(resourceName);\n            final byte[] bytes = zkClient.getData().forPath(zkPath);\n            if (null == bytes || 0 == bytes.length) {\n                log.warn(\"No zk property value resolved, path[{}].\", zkPath);\n                return builder.build();\n            }\n            final String data = Bytes.toString(bytes);\n            if (StringUtils.isBlank(data)) {\n                log.warn(\"No zk property value resolved, path[{}].\", zkPath);\n                return builder.build();\n            }\n\n            if (log.isDebugEnabled()) {\n                log.debug(\"Get zk property, path[{}], value[{}].\", zkPath, data);\n            }\n\n            final Properties properties = this.toProperties(data);\n            if (!properties.isEmpty()) {\n                builder.addAll(ConfUtils.toMap(properties));\n            }\n            return builder.build();\n        } catch (Throwable t) {\n            log.error(\"Load zk configuration error, resource[{}], optionsClass[{}]\", resourceName, optionsClass, t);\n            throw new ConfigException(\"load zk configuration error, \" +\n                    \"resource: \" + resourceName + \", options: \" + optionsClass, t);\n        }\n\n    }\n\n    @Override\n    public void postLoad(Source source) {\n        if (!this.tryRegisterListener(source)) {\n            throw new IllegalStateException(\"register zk listener error, \" +\n                    \"resource: \" + source.getResourceName() + \", options: \" + source.getOptionsClass());\n        }\n    }\n\n    @Override\n    protected String resourceName(Source source) {\n        String resourceName = source.getResourceName();\n        Validate.isTrue(ConfUtils.isZkResource(resourceName), \"invalid zk resource name: \" + resourceName);\n        return resourceName;\n    }\n\n    @Override\n    public boolean support(Source source) {\n        return StringUtils.startsWithIgnoreCase(super.resourceName(source), Constants.ZK_PREFIX);\n    }\n\n    @Override\n    public int priority() {\n        return 0;\n    }\n\n    private String toZkPath(String resourceName) {\n        return resourceName.substring(Constants.ZK_PREFIX.length()).trim();\n    }\n\n    /**\n     * Register zk data change listener.\n     *\n     * @param source\n     * @return\n     */\n    private boolean tryRegisterListener(final Source source) {\n        if (sourceRegistry.contains(source)) {\n            return true;\n        }\n\n        final String zkPath = this.toZkPath(this.resourceName(source));\n        log.info(\"Register zk data change listener for path[{}].\", zkPath);\n        try {\n            zkClient.getData()\n                    .usingWatcher((CuratorWatcher) event -> {\n                        final Watcher.Event.EventType eventType = event.getType();\n                        // uninterested zk event\n                        if (!Watcher.Event.EventType.NodeDataChanged.equals(eventType)) {\n                            log.info(\"Uninterested zk event type: {}, and ignore it.\", eventType);\n                            return;\n                        }\n\n                        final String eventPath = event.getPath();\n                        try {\n                            if (zkPath.equals(eventPath)) {\n                                log.info(\"Refresh zk configuration, path[{}].\", eventPath);\n                                ConfigInjector.getInstance().reload(source);\n                            } else {\n                                log.debug(\"[{}] unexpected change, and ignore it, path[{}].\", zkPath, eventPath);\n                            }\n                        } catch (Throwable t) {\n                            throw new ConfigException(\"refresh zk configuration error, path: \" + eventPath, t);\n                        }\n                    })\n                    .forPath(zkPath);\n        } catch (Throwable t) {\n            log.error(\"Try register zk data change listener error, path: {}\", zkPath, t);\n            return false;\n        }\n        sourceRegistry.add(source);\n        return true;\n    }\n}\n```\n\n然后编写 `/META-INF/services/org.zhenchao.theia.source.provider.SourceProvider` 文件：\n\n```text\norg.zhenchao.theia.source.provider.ClasspathSourceProvider\norg.zhenchao.theia.source.provider.ZkSourceProvider\n```\n\n最后一步，注册 prefix 标识（不区分大小写）：\n\n```java\nConfUtils.registerPrefix(\"ZK\");\n```\n\n### 实现原理\n\nTheia 在设计和实现上主要分为两大模块：\n\n1. 从数据源拉取配置数据，并封装成 Properties 对象；\n2. 基于反射机制从 Properties 对象中获取对应的配置项并注入给目标对象对应的属性上。\n\n同时监听数据源，当数据源更新时以回调的方式更新本地配置。\n\n整体设计图如下：\n\n![image](/images/2020/theia.png)\n\nSourceProvider 用于从数据源加载配置数据并封装成 Properties 对象，同时注册到对应数据源的监听器以监听配置更新。ConfigInjector 会解析 options 配置，并从 Properties 中获取对应的配置项，调用类型转换器 Converter 转成目标类型，并最终注入到目标 options 中。\n\n### 注意事项\n\n1. 对于同一类 options 而言，不允许注册多个实例，否则会抛出 ConfigException 异常。\n2. 如果希望在注入时支持系统环境变量，可以构造一个 `new PropertiesBuilderFactory(true, true)` 对象，并调用 `ConfigInjector#setBuilderFactory` 方法予以设置。\n3. 方法 `ConfigInjector#reset` 会清空 ConfigInjector 管理的所有 options 实例，但是不会清空对应 options 实例已注入的属性值。\n4. 方法 `ConfigManager#reset` 会在 `ConfigInjector#reset` 的基础上清空 ConfigManager 的初始化状态。\n5. raw 类型是唯一的，且与一般类型互斥。\n6. 不允许注入 static 类型的属性。\n7. 自定义类型转换器的优先级高于系统内建的类型转换器，在实现自定义转换器时请保证代码质量。\n8. 尽量认真实现 `Options#validate` 方法，对配置的正确性严格控制。\n9. 被 ConfigInjector 管理的 options 实例是可能被多线程共享的，最好只允许配置库对实例进行修改。\n10. 请勿在 Listener、`Options#update` 和 `Options#validate` 中实现阻塞逻辑。\n\n### 鸣谢\n\n设计灵感来自 [zlib-config](https://github.com/rchargel/zlib-config)，在此表示感谢。\n","tags":["Theia"],"categories":["java"]},{"title":"理解 Raft 分布式共识算法","url":"/2020/01/01/protocol/raft/","content":"\nRaft 算法是一类基于日志复制的分布式共识算法，旨在提供与 [Multi-Paxos](https://en.wikipedia.org/wiki/Paxos_(computer_science)) 共识算法相同的容错性和性能的前提下，追求更好的可理解性和工程可实现性。Paxos 算法为分布式系统面临的共识问题提供了解决思路，但其难以理解的特性一直被大家所诟病，更不用说工程实现，这也是 Raft 算法诞生的主要动因。\n\nRaft 算法的作者认为可理解性和工程可实现性也是一个优秀分布式共识算法所应该具备的特性，并通过以下两点保证算法的可理解性：\n\n- __问题分解__ ：将分布式共识问题拆分成主节点选举、日志复制、安全点，以及成员变更 4 个独立子问题逐一进行解决。\n- __简化状态__ ：通过增强某些阶段的一致性程度（例如约束能够成为下一任 Leader 的参选节点条件），以减少算法需要考虑的系统状态数量。\n\n<!-- more -->\n\n要理解 Raft 算法的运行机制，我们应该先对其应用场景有一个感知。以一个简单的分布式 KV 系统为例，在这个系统中会有多个参与节点，其中各个节点都持有数据的完整副本。系统可以响应用户的读写请求，并且能够保证读写操作的线性一致性语义，即当用户成功写入某个 `<key, value>` 键值对之后，后续不论从哪个节点发起读请求，都能够读取到写入时间点之后的数据。一个典型的分布式 KV 系统往往限制只有 Leader 节点能够响应数据更新请求，但是所有的节点都能够响应读请求，因为大多数的应用场景都具备读多写少的特性。\n\n如何保证各个节点都持有数据的完整副本是该 KV 系统所面临的问题，这也是分布式系统所面临的典型问题。惯用的解决思路是引入日志文件，每条日志对应用户的一次更新操作（也叫指令）。日志在 Leader 节点生成，并复制给集群中所有的参与节点。如果能够保证每个节点复制的日志都是完整且与 Leader 节点日志具备相同的写入顺序，那么只要在各个节点本地按序重放这些日志所承载的指令，就能够实现让各个节点的数据副本状态在未来的某个时间点达成最终一致。这也是可复制状态机（Replicated State Machines）的基本思想，如下图：\n\n![image](/images/2020/raft-replicated-state-machine.png)\n\n从目前来看，在这个分布式 KV 系统中我们主要面临两个问题：\n\n1. 如何正确选举出一个 Leader 节点？\n2. 如何实现日志数据从 Leader 向其它节点有序且一致的复制？\n\n这也是 Raft 算法要解决的两个基本问题。当然，在解决这两个问题的过程中会面临许多安全问题，我们会专门用一小节去讨论这些问题。\n\n在正式介绍 Raft 算法的运行机制之前，我们先对 Raft 算法的一些基本属性和关键特性做一个简单的介绍。\n\n首先来看基本属性，主要包含 term 和 logIndex 这两个概念，说明如下：\n\n- __term__ ：中文译为“任期”，更加形象一点可以将其理解为“朝代”，而 Leader 节点就是具体某个朝代的君王（不同于实际中一个朝代可能有多任君王，这里限制一个朝代只能有一位君王），当改朝换代时对应的 term 值也会递增（初始为 0，单调递增）。\n- __logIndex__ ：Raft 算法采用日志记录用户的操作指令，并通过为每条日志分配一个 index 以维护日志的顺序性。Raft 算法要求在同一任期内 logIndex 是单调递增且不重复的，一些实现则更进一步要求在整个算法运行期间 logIndex 始终是单调递增且不重复的。\n\n在一个分布式系统中往往需要引入时钟的概念，并且为了避免物理时钟偏差对于系统正确性的影响，分布式系统往往选用逻辑时钟。属性 term 和 logIndex 结合在一起可以充当 Raft 算法的逻辑时钟，用于衡量一条日志的时间顺序，具体会在下文进一步说明。类比时钟的概念，我们自然也就能够理解 Raft 算法为什么要限制 term 和 logIndex 必须是单调递增的，且不允许重复和被更改。\n\n关于 logIndex 属性，还有两个特殊的位置值需要说明：\n\n- __committedLogIndex__ ：一条日志被标记为 committed 的条件是这条日志成功被复制到集群中过半数的节点上，lastCommittedLogIndex 小于等于 lastLogIndex。\n- __appliedLogIndex__ ：一条日志被标记为 applied 的条件是这条日志所承载的指令被成功应用到业务状态机中，lastAppliedLogIndex 小于等于 lastCommittedLogIndex，即一条能够被 applied 的日志前提一定是被 committed 的。\n\n再来了解一下 Raft 算法的关键特性：\n\n- __Strong Leader__ ：一个集群在同一任期内只能包含一个 Leader 节点，日志数据仅从 Leader 节点单向流向其它 Follower 节点，这样的设计简化了对日志副本的管理，同时让算法更加易于理解。\n- __Leader Election__ ：基于随机计时器触发 Leader 选举进程，相对于固定周期的超时策略，随机化超时周期这么一个小小的改动却能更加简单和高效的解决选举分裂问题。\n- __Membership Changes__ ：基于联合共识机制处理集群节点的变更事件，在过渡期间允许两种不同的节点配置方案共存，以保证集群在节点变更期间仍然能够正常运行。\n\n本文我们重点介绍主节点选举、日志复制，以及过程中需要考虑的一些安全点。在介绍主节点选举和日志复制机制时我们重点关注算法的运行流程，一些需要考虑的安全问题将留到安全点小节进行统一探讨。\n\n### 主节点选举\n\nRaft 算法中的节点分为三类角色：Leader、Candidate 和 Follower。一个任期内集群中的所有节点只能包含一个 Leader 节点，剩余的节点均为 Follower 节点，而 Candidate 节点是 Follower 尝试竞选成为下一任 Leader 节点的中间状态。下图演示了一个节点角色演变的过程：\n\n![image](/images/2020/raft-node-lifecycle.png)\n\nRaft 算法基于心跳机制触发主节点选举进程。一个 Leader 节点在位期间会始终向所有的 Follower 节点发送心跳请求以宣示自己的权威，如果一个 Follower 节点在一段时间内没有收到来自 Leader 节点的心跳，则会认为“皇帝已经驾崩了”，于是切换状态为 Candidate 尝试谋权篡位，竞选成为下一任 Leader。\n\nRaft 算法基于投票机制实现主节点选举，所以一个节点竞选的过程本质上就是向集群中其它节点征集选票的过程。Raft 集群中的节点一般采用 RPC 的方式进行通信，所以参选节点会向集群中的所有节点发送 RequestVote RPC 请求以征集选票（同时会为自己投上一票），请求内容如下：\n\n> - __term__ ：参选节点的任期值（当前任期值加 1），即如果该节点成功当选 Leader 的任期值。\n> - __candidateId__ ：参选节点的节点 ID。\n> - __lastLogIndex__ ：参选节点本地最后一条日志对应的 logIndex 值。\n> - __lastLogTerm__ ：参选节点本地最后一条日志对应的 term 值。\n\n为保证一个任期内只有一个 Leader 节点被选出，Raft 算法要求节点在一个任期内只能投票给一个参选节点，按照先来先服务的原则。如果接收到请求的节点当前未投票给任何参选节点，则会判断请求是否满足：\n\n1. 参选节点的 term 值大于等于当前节点的 term 值。\n2. 如果 term 值相等，则参选节点的 lastLogIndex 大于等于当前节点的 lastLogIndex 值。\n\n只有在同时满足上述两个条件时，当前节点才会为参选节点投上自己宝贵的一票，并承诺在当前任期内不会再投票给任何其它参选节点。\n\n节点针对参选节点的 RequestVote 响应中会携带以下信息：\n\n> - __term__ ：当前投票节点的任期值。\n> - __voteGranted__ ：是否同意投票。\n\n参选节点在一轮征集选票的过程中可能会遇到以下三种情况：\n\n1. 参选节点赢得集群中过半数的选票。\n2. 接收到的 RequestVote 响应中包含比自己任期更大的 term 值，说明已有其它节点竞选 Leader 成功。\n3. 没有任何一个节点赢得选票，即本轮竞选没有任何一个节点胜出。\n\n针对 __情况一__ ，说明该参选节点竞选 Leader 成功。为了防止某些节点谋权篡位，该节点需要立即向集群中的所有节点发送心跳请求以宣示自己的权威。\n\n针对 __情况二__ ，如果该 Leader 节点的任期较当前节点更大，则当前节点需要转变为 Follower 节点以服从新 Leader 节点的统治，否则可以无视该“Leader”节点，继续发动革命以推翻其政权。\n\n针对 __情况三__ ，说明有至少两个以上的参选节点同时发起了选举进程，并瓜分了选票，导致没有一个节点赢得过半数的选票。此时，这些节点只能在等待一段时间后继续发起一轮新的选举进程以打破这种僵持的状态。\n\n为了尽量避免出现第三种情况，一个简单且有效的解决方案就是随机化每个节点发起选举进程的超时时间。只要这些节点不是同一时刻发动革命，那么打成平手的概率将大大降低。\n\n关于主节点选举还有另外一个需要考虑的问题，即某些节点因为一些原因（比如网络延迟、节点负载较高等）未能正常接收到来自 Leader 节点的权威宣示通知，导致这些节点经常误认为“皇帝驾崩了”，尝试谋权篡位。按照 Raft 算法的主节点选举设计，这些“捣乱”的节点会提升 term 值以发起选举进程，但是因为大多数节点与 Leader 节点的租约是有效的，所以很多时候这些“捣乱”节点的谋权篡位计划只能以失败告终。然而，这类无谓的举动会导致对 term 值的浪费，对集群运行的稳定性构成威胁。\n\n为了解决此类问题，我们可以将选举进程拆分为预选举和正式选举两个阶段。一个节点在发起正式选举之前必须先经过一轮预选举，预选举区别于正式选举的地方在于参选节点并不会真正递增 term 值，而是尝试以 `term + 1` 的任期值去试探性的征集选票。如果预选举能够成功才会真正递增 term 值，并进入正式选举环节开始征集选票，否则对集群的运行状态不会构成影响。\n\n### 日志复制\n\n在正确选举出 Leader 节点之后，接下来 Raft 算法需要解决的核心问题就剩下如何将日志数据有序的从 Leader 节点复制给集群所有的 Follower 节点，并保证各个节点上日志数据的一致性了。\n\nRaft 算法中的日志分为两类：一类是系统运行期间内部产生的日志，比如集群节点配置变更信息；另外一类就是用户向 Raft 集群提交请求所生成的日志，这类日志会承载用户的操作指令，也是 Raft 日志的主要形式。不过 Raft 算法在执行日志复制时并不区分日志的类型，而是统一处理。\n\nLeader 节点会以并发的形式向各个 Follower 节点复制日志数据，如果一条日志被集群中过半数的节点成功复制，则视该日志为 committed，即已提交。对于 committed 的日志，节点本地的可复制状态机会解析并应用其中所承载的指令，然后将其标记为 applied。\n\n![image](/images/2020/raft-log.png)\n\nRaft 算法中的日志除了承载操作指令外，至少还包含 term 和 logIndex 两个基本属性（如上图），并且承诺：\n\n1. 如果两条日志具备相同的 term 和 logIndex，则这两条日志所承载的指令必然是相同的。\n2. 如果两条日志具备相同的 term 和 logIndex，则这两条日志的前置日志也是相同的，即具备相同的 term、logIndex 和指令。\n\n关于 __承诺一__ ，Raft 算法要求在同一个 term 内 logIndex 必须是单调递增且不允许重复和被更改的，所以能够保证。\n\n关于 __承诺二__ ，Raft 算法在发送日志复制请求时会携带前置日志的 term 和 logIndex 值（即 prevLogTerm 和 prevLogIndex），只有在 prevLogTerm 和 prevLogIndex 匹配的情况下才能成功响应请求。如果 prevLogTerm 和 prevLogIndex 不匹配，则说明当前节点可能是新加入的、或者之前服从于其它 Leader，亦或当前节点之前是 Leader 节点。为了兑现承诺二，Leader 节点需要与该 Follower 节点向前追溯找到 term 和 logIndex 匹配的那条日志，并使用 Leader 节点的日志强行覆盖该 Follower 此后的日志数据。\n\nLeader 节点一般基于 RPC 请求的方式向目标 Follower 节点复制日志数据，对应的复制日志 AppendEntries RPC 请求内容如下：\n\n> - __term__ ：Leader 节点的任期值。\n> - __leaderId__ ：Leader 节点 ID，Follower 节点可以据此将请求重定向给 Leader 节点。\n> - __prevLogIndex__ ：前置日志的 logIndex 值。\n> - __prevLogTerm__ ：前置日志的 term 值。\n> - __entries__ ：本次请求复制的日志数据集合，如果为空的话可以充当心跳请求。\n> - __leaderCommit__ ：Leader 节点的 lastCommittedLogIndex 值。\n\nFollower 节点关于 AppendEntries 响应的内容如下：\n\n> - __term__ ：Follower 节点的 term 值，如果相较于 Leader 节点更大，则 Leader 节点会更新自己的 term 值并退位。\n> - __success__ ：标识 Follower 节点是否成功复制请求中的日志数据。\n\nFollower 节点在接收到 AppendEntries 请求之后会按照以下流程进行处理：\n\n1. 如果请求中的 term 值小于自己的 term 值，说明请求来源 Leader 节点已经失效，则拒绝请求，并返回自己的 term 值；\n2. 如果对应 prevLogTerm 和 prevLogIndex 的日志与本地不匹配，则拒绝请求，以兑现承诺二；\n3. 如果本地存在一条日志的 logIndex 和 prevLogIndex 相等，但是对应的 term 值和 prevLogTerm 不相同，则需要删除包含这条日志的所有后继日志，以兑现承诺二。如果采用全局递增的 logIndex 设计，则不会出现此类情况；\n4. 在保证 prevLogTerm 和 prevLogIndex 匹配的情况下，如果本地不包含请求中的日志数据，则往本地追加日志数据；\n5. 如果请求中的 leaderCommit 相较于本地记录的 committedLogIndex 更大，则更新本地 committedLogIndex 值为 `min(leaderCommit, lastLogIndex)`。\n\n在实现层面，作为 Leader 节点可以为每个 Follower 节点启动一个线程专门负责往该 Follower 节点复制日志数据并维护心跳。考虑各个 Follower 节点的负载和网络连通性，这样的设计能够保证往各个 Follower 节点复制日志数据进程是相互独立的。如果某个 Follower 节点所属的宿主机或网络出现问题，则对应的线程需要重试 AppendEntries 请求直到成功为止，但这并不会影响往其它 Follower 节点复制日志数据的进程。\n\n### 安全点\n\n上面我们介绍了 Raft 算法关于主节点选举和日志数据复制机制的设计，总的来说还是比较容易理解的。然而，到目前为止我们都是建立在一个理想运行环境下，实际运行中我们面临的情况要复杂很多，作为一个分布式共识算法，应该提供在面对复杂环境下的各种容错机制。本小节我们就一起来探讨实际运行过程中可能存在的安全问题，以及 Raft 算法是如何解决的。\n\n#### Leader 节点宕机\n\n通过前面对于主节点选举机制的介绍可知，Raft 算法会在 Leader 节点宕机时基于超时机制从集群节点中选举出一个新的 Leader 节点。设想如果新选出的 Leader 节点并未完全同步前任 Leader 节点已经 committed 的日志数据，那么按照 Raft 算法日志复制的规则，新 Leader 节点会强行覆盖集群中其它节点与自己冲突的日志数据。如果某些节点已经将这些被覆盖的日志所承载的指令应用到了自己的状态机中，那么就会导致节点之间数据的不一致，所以在执行主节点选举时不应该赋予所有的节点都有竞选成功的机会。\n\nRaft 算法解决上述问题的思路是限制只有包含所有已经 committed 日志的节点才有机会竞选成功。这也是为什么参选节点在征集选票时，Raft 算法对于投票节点是否同意投票需要添加如下两条限制：\n\n1. 参选节点的 term 值大于等于投票节点的 term 值。\n2. 如果 term 值相等，则参选节点的 lastLogIndex 大于等于投票节点的 lastLogIndex 值。\n\n那么这两个条件就一定能够保证新选出的 Leader 节点一定包含所有已经 committed 的日志吗？我们需要先明确以下两点：\n\n1. 一条日志被 committed 的条件是这条日志被集群中 __过半数__ 以上的节点成功复制。\n2. 一个节点能够竞选 Leader 成功的条件是该节点赢得集群中 __过半数__ 以上节点的选票。\n\n所以上面这两个“过半数”能够保证至少有一个节点既包含最新的一条被 committed 的日志，同时又给参选节点投上了自己的一票。然后附加上主节点选举的约束条件，可以得出新选举出的 Leader 节点的日志一定比该节点更新，所以新选举出的 Leader 节点一定包含最新一条被 committed 的日志。\n\n上述分析说明在 Leader 切换的过程中，新任 Leader 不会覆盖前任 Leader 已经 committed 的日志，也就不会导致数据不一致。\n\n![image](/images/2020/raft-apply-task.png)\n\nLeader 节点宕机除了影响主节点选举，还会影响日志复制。上面这幅时序图描述了 Raft 集群处理客户端提交指令请求并复制日志的过程，Leader 节点可能在任何阶段发生宕机，下面来探讨一下在 Leader 节点发生宕机时，Raft 算法如何保证数据的一致性。\n\n- __Leader 在将日志复制给 Follower 节点之前宕机__\n\nLeader 节点在为指令生成完日志之后会将对应的日志写入本地存储系统，然后开始并发将该日志复制给集群中所有的 Follower 节点。如果 Leader 节点在开始复制之前发生宕机，则对应的日志目前处于 uncommitted 状态。新选举出来的 Leader 节点一定不包含该日志，所以当上一任 Leader 节点从宕机中恢复并以 Follower 角色启动后，新任 Leader 会以本地的日志强行覆盖与其冲突的日志。因为该条日志对应的指令并未被应用到状态机，所以也就不会导致数据不一致。\n\n- __Leader 在将日志复制给 Follower 节点之间宕机__\n\nLeader 节点在将日志复制给 Follower 节点之间发生宕机，此时该日志处于 uncommitted 状态。这一阶段分为两种情况：\n\n1. 复制给了集群中小部分的 Follower 节点。\n2. 复制给了集群中大部分的 Follower 节点。\n\n对于 __情况一__ ，新任 Leader 节点不一定包含该日志，如果包含则按照第二种情况予以处理，如果不包含则新任 Leader 会以本地的日志强行覆盖与其冲突的日志。因为该条日志对应的指令并未被应用到状态机，所以也就不会导致数据不一致。\n\n对于 __情况二__ ，则新任 Leader 节点一定包含该日志，但并不知道前任 Leader 是否已经提交了该日志，所以不能依据前任 Leader 节点的状态做决策，需要继续完成对于该日志的复制。我们可以认为对于已经 committed 的日志，新任 Leader 能够确定这些日志已经或未来一定能够被集群中所有的节点成功复制，但是对于那些 uncommitted 的日志，新任 Leader 节点需要再次尝试将其复制给各个 Follower 节点，并依据自己的复制状态决定是否提交这些日志。\n\n针对第二情况一种极端的情形就是 Leader 节点在准备提交该日志之前发生宕机。\n\n- __Leader 在响应客户端之前宕机__\n\nLeader 节点在响应客户端之前发生宕机，此时该日志在 Leader 本地已经处于 committed 状态，所以新任 Leader 本地一定包含该日志。然而，新任 Leader 可能还未被通知该日志已经被提交，但是按照 Raft 算法的日志复制机制，该日志未来一定会被新任 Leader 标记为 committed。\n\n此种情形下，客户端会因为等待超时而误认为本次指令提交失败，所以会尝试重新提交指令，客户端需要考虑指令的幂等性问题。\n\n#### Follower 或 Candidate 节点宕机\n\n相对于 Leader 节点宕机而言，Follower 或 Candidate 节点发生宕机的处理过程要简单许多。Candidate 是节点参与竞选的中间状态，如果出现宕机只会导致该节点竞选失败，不会对集群的运行状态构成影响。Follower 节点在整个算法运行期间始终被动的接收请求，并且 Raft 算法要求当向一个 Follower 节点复制日志失败时，Leader 节点应该循环重试直到复制成功。所以，当一个 Follower 节点从宕机中恢复运行，则会从宕机的位置继续开始复制日志，而不会丢失日志。\n\n#### 时间层面考量\n\n在设计一个分布式系统时我们往往需要基于时间去判断事件的先后顺序，这里的时间应该依赖于逻辑时钟而非物理时钟。前面曾提及过在整个 Raft 算法的设计中，结合 term 和 logIndex 这两个维度可以充当逻辑时钟的概念。此外，因为 Raft 算法的正常运行依赖于超时策略，所以还需要考虑以下几个层面的时间问题：\n\n- __broadcastTime__ ：集群机器之间的平均网络延迟。\n- __electionTimeout__ ：Raft 节点的选举超时时间。\n- __MTBF__ ：机器宕机的平均时间间隔。\n\n如果要保证 Raft 算法的正常运行，则需要满足 `broadcastTime << electionTimeout << MTBF`。\n\n前面我们介绍了 Leader 节点会周期性的向所有 Follower 节点发送心跳以宣示自己的权威，每轮心跳都是一次 RPC 请求，这中间涉及到网络的延迟开销 broadcastTime。Follower 节点如果在等待 electionTimeout 之后还未收到来自 Leader 的心跳请求则会认为“皇帝驾崩了”，于是尝试执行谋权篡位计划。所以需要保证 broadcastTime 远小于 electionTimeout，以避免网络平均延迟对于集群正常运行的影响。\n\n此外，在 Leader 宕机与选举出新任 Leader 之间，整个集群处于无主的状态，我们应该尽可能缩短此类状态的持续时间，而控制的参数就是 electionTimeout 的最小值，所以 electionTimeout 需要在保证大于 broadcastTime 的前提下远小于一个集群中机器的平均故障间隔时间 MTBF。\n\n#### 网络分区问题\n\n在一个分布式系统中，网络分区是我们无法回避的问题。对于 Raft 算法而言，当出现网络分区时会让一个 Raft 集群分裂成两个甚至多个较小的 Raft 集群，好在 Raft 仍然能够保证在网络出现分区时的数据一致性。\n\n![image](/images/2020/raft-network-partition.png)\n\n如上图，假设我们现在有一个包含 5 个节点的 Raft 集群，网络分区导致该集群分裂成了两个小集群 A 和 B，其中 A 包含 3 个节点（L1 是 Leader），B 包含 2 个节点（L2 是 Leader）。当我们向该集群提交指令时，因为存在两个 Leader 节点，所以节点 L1 或 L2 都有可能会响应我们的请求（节点总数为 5）：\n\n- 如果请求发送给了 L1 节点，因为节点 L1 所属集群包含 3 个节点，所以提交给该分区的指令对应的日志存在被 committed 的可能性，此时 3 个节点均成功复制了日志。\n- 如果请求发送给了 L2 节点，因为节点 L2 所属集群包含 2 个节点，所以提交给该集群的指令对应的日志因不满足过半数的条件而无法被提交。\n\n当网络分区恢复时，因为 L1 节点的日志相对于 L2 节点更新，所以节点 L2 会主动从 Leader 角色切换为 Follower 角色，对应的未提交日志会被 L1 节点强行覆盖掉，集群数据重新恢复一致。因为整个过程中节点 L2 不会提交任何日志，所以也就不会应用任何指令到状态机，但是网络分区期间，L2 所属集群的数据状态滞后于整个集群，路由到该集群的请求读取不到最新的数据状态。\n\n此外，还有一种导致网络分区的场景并不是因为网络本身出现问题，而是因为集群节点变更所导致。因为 Raft 的主节点选举基于多数投票机制，如果因为新节点的加入导致集群出现两个“大多数”的情况就可能会导致选举出两个 Leader 节点。为了避免此类问题，Raft 算法中提出了一种联合共识（Joint Consensus）的解决思路，允许在集群节点变更期间新旧节点配置共存。然而，事实表明联合共识机制对于工程实现并不友好，所以作者在其博士毕业 [论文](https://github.com/ongardie/dissertation) 中又对该机制进行了改进，通过限制一次仅允许增加或移除单个节点来简化工程实现。改进后的策略能够保证在集群节点变更期间，新旧配置中的大多数始终包含一个共同的节点，因为该共同节点只会认可一个 Leader，从而保证在集群配置变更期间不会选举出两个不同的 Leader 节点。关于 Raft 算法集群节点配置变更策略的具体流程，建议读者阅读 Raft 算法作者的博士毕业论文，因这一部分对于整体理解 Raft 算法的影响不大，本文不打算展开说明。\n\n### 总结\n\n本文我们重点分析了 Raft 算法的主节点选举和日志复制机制，这也是 Raft 算法的两大核心所在，同时我们也对算法所面临的安全问题进行了探讨。Raft 算法的宗旨在于保证算法正确性的前提下提升算法的可理解性和工程可实现性，作者也确实做到了这一点。不过如果希望实现一个生产级别的 Raft 算法库，我们还需要考虑的更多，例如日志数据快照、集群节点变更、线性一致性语义，以及算法性能和网络开销优化等。我将在后续的文章中以 [SOFA-JRaft](https://github.com/sofastack/sofa-jraft) 为例从源码层面分析如何实现 Raft 算法。\n\n### 参考\n\n1. [The Raft Consensus Algorithm](https://raft.github.io/)\n2. [In Search of an Understandable Consensus Algorithm (Extended Version)](https://raft.github.io/raft.pdf)\n3. [Consensus: Bridging Theory and Practice](https://github.com/ongardie/dissertation)\n","tags":["分布式","分布式共识","Raft"],"categories":["protocol"]},{"title":"Kafka 源码解析：集群协同运行控制器","url":"/2019/06/26/kafka/kafka-controller/","content":"\nKafka 集群由一系列的 broker 节点构成，在这些 broker 节点中会选举一个节点成为所有 broker 节点的 leader（称之为 kafka controller），其余的 broker 节点均为 follower 角色。Kafka Controller 负责管理集群中所有 topic 分区和副本的状态，协调集群中所有 broker 节点的运行，同时也负责 Kafka 与 ZK 之间的交互，下文中如果不特殊说明，Kafka Controller 均指代 leader 角色。<!-- more -->\n\n### KafkaController 组件的定义与启动\n\nKafka 定义了 KafkaController 类来描述 Kafka Controller，KafkaController 类的字段定义如下：\n\n```scala\nclass KafkaController(val config: KafkaConfig, // 配置信息\n                      zkUtils: ZkUtils, // ZK 交互工具类\n                      val brokerState: BrokerState, // 描述 broker 节点的状态\n                      time: Time, // 时间戳工具类\n                      metrics: Metrics,\n                      threadNamePrefix: Option[String] = None) extends Logging with KafkaMetricsGroup {\n\n    /** 标识是否启动 */\n    private var isRunning = true\n    /** 维护上下文信息，缓存 ZK 中记录的整个集群的元数据信息 */\n    val controllerContext = new ControllerContext(zkUtils)\n    /** 管理集群中所有分区状态的状态机 */\n    val partitionStateMachine = new PartitionStateMachine(this)\n    /** 管理集群中所有副本状态的状态机 */\n    val replicaStateMachine = new ReplicaStateMachine(this)\n    /** 用于故障转移，选举 leader */\n    private val controllerElector = new ZookeeperLeaderElector(\n        controllerContext, ZkUtils.ControllerPath, onControllerFailover, onControllerResignation, config.brokerId, time)\n    /** 分区再平衡定时任务调度器 */\n    private val autoRebalanceScheduler = new KafkaScheduler(1)\n    /** 用于对指定的 topic 执行删除操作 */\n    var deleteTopicManager: TopicDeletionManager = _\n    /** Leader 副本选举策略 */\n    val offlinePartitionSelector = new OfflinePartitionLeaderSelector(controllerContext, config)\n    private val reassignedPartitionLeaderSelector = new ReassignedPartitionLeaderSelector(controllerContext)\n    private val preferredReplicaPartitionLeaderSelector = new PreferredReplicaPartitionLeaderSelector(controllerContext)\n    private val controlledShutdownPartitionLeaderSelector = new ControlledShutdownLeaderSelector(controllerContext)\n    /** 用于批量向 broker 节点发送请求 */\n    private val brokerRequestBatch = new ControllerBrokerRequestBatch(this)\n    /** ZK 监听器 */\n    private val partitionReassignedListener = new PartitionsReassignedListener(this)\n    private val preferredReplicaElectionListener = new PreferredReplicaElectionListener(this)\n    private val isrChangeNotificationListener = new IsrChangeNotificationListener(this)\n\n    // ... 省略方法定义\n\n}\n```\n\n在 Kafka 服务启动时，每个 broker 节点都会创建对应的 Kafka Controller 实例，并调用 `KafkaController#startup` 方法启动运行：\n\n```scala\ndef startup(): Unit = {\n    inLock(controllerContext.controllerLock) {\n        info(\"Controller starting up\")\n        // 注册 SessionExpirationListener 监听器，监听 Controller 与 ZK 的连接状态\n        this.registerSessionExpirationListener()\n        // 标识当前 controller 已经启动，现在还是 follower 角色\n        isRunning = true\n        // 启动故障转移机制\n        controllerElector.startup\n        info(\"Controller startup complete\")\n    }\n}\n```\n\n启动过程中会注册 SessionExpirationListener 监听器监听 Kafka Controller 与 ZK 之间的连接状态，并启动故障转移机制，在初始启动时可以借助该机制为集群选择 leader 角色。这里先了解一下启动的流程，关于 ZK 监听机制和故障转移机制，留到下面的小节中针对性分析。\n\n### 上下文信息管理\n\nControllerContext 类用于管理 Kafka Controller 的上下文信息，并提供与集群中所有 broker 之间建立连接并通信的功能。ControllerContext 类的字段定义如下：\n\n```scala\nclass ControllerContext(val zkUtils: ZkUtils) {\n\n    /** 管理 controller 与集群中其它 broker 之间的连接 */\n    var controllerChannelManager: ControllerChannelManager = _\n    /** 记录正在关闭的 brokerId 集合 */\n    var shuttingDownBrokerIds: mutable.Set[Int] = mutable.Set.empty\n    /** controller 的年代信息，初始为 0，每次重新选举之后值加 1 */\n    var epoch: Int = KafkaController.InitialControllerEpoch - 1\n    /** 年代信息对应的 ZK 版本，初始为 0  */\n    var epochZkVersion: Int = KafkaController.InitialControllerEpochZkVersion - 1\n    /** 集群中全部的 topic 集合  */\n    var allTopics: Set[String] = Set.empty\n    /** 记录每个分区对应的 AR 集合 */\n    var partitionReplicaAssignment: mutable.Map[TopicAndPartition, Seq[Int]] = mutable.Map.empty\n    /** 记录每个分区的 leader 副本所在的 brokerId、ISR 集合，以及 controller 年代信息 */\n    var partitionLeadershipInfo: mutable.Map[TopicAndPartition, LeaderIsrAndControllerEpoch] = mutable.Map.empty\n    /** 记录正在重新分配副本的分区 */\n    val partitionsBeingReassigned: mutable.Map[TopicAndPartition, ReassignedPartitionsContext] = new mutable.HashMap\n    /** 记录了正在进行优先副本选举的分区 */\n    val partitionsUndergoingPreferredReplicaElection: mutable.Set[TopicAndPartition] = new mutable.HashSet\n    /** 记录了当前可用的 broker 集合 */\n    private var liveBrokersUnderlying: Set[Broker] = Set.empty\n    /** 记录了当前可用的 brokerId 集合 */\n    private var liveBrokerIdsUnderlying: Set[Int] = Set.empty\n\n    // ... 省略方法定义\n\n}\n```\n\nControllerContext 类提供了对这些字段管理的方法，实现比较简单，不展开分析。\n\n下面我们重点看一下 ControllerChannelManager 类定义，该类用于建立到集群中所有 broker 节点的连接，并与之通信。ControllerChannelManager 类定义了 `ControllerChannelManager#brokerStateInfo` 字段，用于记录到对应 broker 节点的通讯相关信息。ControllerChannelManager 类在被实例化时会调用 `ControllerChannelManager#addNewBroker` 方法初始化 `ControllerChannelManager#brokerStateInfo` 字段，为每个可用的 broker 节点构造一个 ControllerBrokerStateInfo 对象，其中封装了目标 broker 节点信息、网络客户端对象、缓存请求的队列，以及请求发送线程对象，ControllerBrokerStateInfo 样例类定义如下：\n\n```scala\ncase class ControllerBrokerStateInfo(networkClient: NetworkClient,\n                                     brokerNode: Node,\n                                     messageQueue: BlockingQueue[QueueItem],\n                                     requestSendThread: RequestSendThread)\n```\n\n方法 `ControllerChannelManager#addNewBroker` 的实现如下：\n\n```scala\nprivate def addNewBroker(broker: Broker) {\n    // 创建消息队列，用于存放发往指定 broker 节点的请求\n    val messageQueue = new LinkedBlockingQueue[QueueItem]\n    debug(\"Controller %d trying to connect to broker %d\".format(config.brokerId, broker.id))\n    val brokerEndPoint = broker.getBrokerEndPoint(config.interBrokerListenerName)\n    val brokerNode = new Node(broker.id, brokerEndPoint.host, brokerEndPoint.port)\n    // 创建网络连接客户端\n    val networkClient = {\n        val channelBuilder = ChannelBuilders.clientChannelBuilder(\n            config.interBrokerSecurityProtocol,\n            LoginType.SERVER,\n            config.values,\n            config.saslMechanismInterBrokerProtocol,\n            config.saslInterBrokerHandshakeRequestEnable\n        )\n        val selector = new Selector(\n            NetworkReceive.UNLIMITED,\n            Selector.NO_IDLE_TIMEOUT_MS,\n            metrics,\n            time,\n            \"controller-channel\",\n            Map(\"broker-id\" -> broker.id.toString).asJava,\n            false,\n            channelBuilder\n        )\n        new NetworkClient(\n            selector,\n            new ManualMetadataUpdater(Seq(brokerNode).asJava),\n            config.brokerId.toString,\n            1,\n            0,\n            Selectable.USE_DEFAULT_BUFFER_SIZE,\n            Selectable.USE_DEFAULT_BUFFER_SIZE,\n            config.requestTimeoutMs,\n            time,\n            false\n        )\n    }\n\n    // 创建请求发送线程对象\n    val threadName = threadNamePrefix match {\n        case None => \"Controller-%d-to-broker-%d-send-thread\".format(config.brokerId, broker.id)\n        case Some(name) => \"%s:Controller-%d-to-broker-%d-send-thread\".format(name, config.brokerId, broker.id)\n    }\n    val requestThread = new RequestSendThread(\n        config.brokerId, controllerContext, messageQueue, networkClient, brokerNode, config, time, threadName)\n    requestThread.setDaemon(false)\n\n    // 记录到 brokerStateInfo 集合\n    brokerStateInfo.put(broker.id, ControllerBrokerStateInfo(networkClient, brokerNode, messageQueue, requestThread))\n}\n```\n\nRequestSendThread 类继承自 ShutdownableThread 抽象类，所以我们重点来看一下 `RequestSendThread#doWork` 方法实现：\n\n```scala\noverride def doWork(): Unit = {\n\n    def backoff(): Unit = CoreUtils.swallowTrace(Thread.sleep(100))\n\n    // 获取缓冲队列中的 QueueItem 对象，封装了请求类型、请求对象，以及响应回调函数\n    val QueueItem(apiKey, requestBuilder, callback) = queue.take()\n\n    import NetworkClientBlockingOps._ // 阻塞模式\n\n    var clientResponse: ClientResponse = null\n    try {\n        lock synchronized {\n            var isSendSuccessful = false // 标识请求是否发送成功\n            while (isRunning.get() && !isSendSuccessful) {\n                // 当 broker 节点宕机后，会触发 ZK 的监听器调用 removeBroker 方法停止当前线程，在停止前会一直尝试重试\n                try {\n                    // 阻塞等待指定 broker 节点是否允许接收请求\n                    if (!brokerReady()) {\n                        isSendSuccessful = false\n                        backoff() // 等待 100 毫秒\n                    } else {\n                        // 创建并发送请求，同时阻塞等待响应\n                        val clientRequest = networkClient.newClientRequest(brokerNode.idString, requestBuilder, time.milliseconds(), true)\n                        clientResponse = networkClient.blockingSendAndReceive(clientRequest)(time)\n                        isSendSuccessful = true\n                    }\n                } catch {\n                    // ... 省略异常处理，如果发送失败，则断开连接，并等待一段时间后重试\n                }\n            }\n\n            // 解析响应\n            if (clientResponse != null) {\n                // 解析请求类型\n                val api = ApiKeys.forId(clientResponse.requestHeader.apiKey)\n                // 只允许 LEADER_AND_ISR、STOP_REPLICA，以及 UPDATE_METADATA_KEY 这 3 种请求类型\n                if (api != ApiKeys.LEADER_AND_ISR && api != ApiKeys.STOP_REPLICA && api != ApiKeys.UPDATE_METADATA_KEY)\n                    throw new KafkaException(s\"Unexpected apiKey received: $apiKey\")\n\n                // 执行响应回调函数\n                val response = clientResponse.responseBody\n                if (callback != null) {\n                    callback(response)\n                }\n            }\n        }\n    } catch {\n        // ... 省略异常处理\n    }\n}\n```\n\nRequestSendThread 线程在运行期间会循环消费存放请求的阻塞队列，队列元素的类型为 QueueItem，其中封装了具体的请求类型、请求对象，以及响应回调函数。如果存在待发送的请求对象则会向目标 broker 节点发送请求，并阻塞等待响应，当拿到响应对象之后调用响应函数进行处理。ControllerChannelManager 的发送请求函数 `ControllerChannelManager#sendRequest` 本质上就是将请求信息封装成 QueueItem 对象，并记录到请求阻塞队列中，然后交由 RequestSendThread 线程异步处理。\n\n### 批量发送请求\n\nControllerBrokerRequestBatch 类实现了向所有可用 broker 节点批量发送 LeaderAndIsrRequest、StopReplicaRequest 和 UpdateMetadataRequest 请求的功能，它定义了 3 个集合分别缓存这 3 类请求的相关信息，并提供了相关方法用于添加待发送的请求信息，以及批量发送请求。ControllerBrokerRequestBatch 类的字段定义如下：\n\n```scala\nclass ControllerBrokerRequestBatch(controller: KafkaController) extends Logging {\n\n    /** Controller 上下文信息 */\n    val controllerContext: ControllerContext = controller.controllerContext\n    /** Controller 节点 ID */\n    val controllerId: Int = controller.config.brokerId\n    /** 记录发往指定 broker 节点的 LeaderAndIsrRequest 请求所需的信息 */\n    val leaderAndIsrRequestMap = mutable.Map.empty[Int, mutable.Map[TopicPartition, PartitionStateInfo]]\n    /** 记录发往指定 broker 节点的 StopReplicaRequest 请求所需的信息 */\n    val stopReplicaRequestMap = mutable.Map.empty[Int, Seq[StopReplicaRequestInfo]]\n    /** UpdateMetadataRequest 请求对应的目标 brokerId 集合 */\n    val updateMetadataRequestBrokerSet = mutable.Set.empty[Int]\n    /** UpdateMetadataRequest 请求对应的请求信息 */\n    val updateMetadataRequestPartitionInfoMap = mutable.Map.empty[TopicPartition, PartitionStateInfo]\n\n    // ... 省略方法定义\n\n}\n```\n\nControllerBrokerRequestBatch 提供了 `ControllerBrokerRequestBatch#newBatch` 方法用于校验缓存相应请求信息的 3 个集合是否为空，如果不为空则抛出异常，表示此时还存在未发送完成的请求，不允许添加新的待发送请求对象。同时，也提供了 `ControllerBrokerRequestBatch#clear` 方法用于清空这 3 个集合。\n\n下面列出的 3 个方法分别用于往对应集合中添加相应的请求信息：\n\n1. `ControllerBrokerRequestBatch#addLeaderAndIsrRequestForBrokers`：用于往 leaderAndIsrRequestMap 集合中添加待发送的 LeaderAndIsrRequest 请求所需的数据，并构造发往所有可用 broker 节点的 UpdateMetadataRequest 请求，缓存到 updateMetadataRequestPartitionInfoMap 集合中等待发送。\n2. `ControllerBrokerRequestBatch#addStopReplicaRequestForBrokers`：用于往 stopReplicaRequestMap 集合中添加待发送的 StopReplicaRequest 请求所需的数据。\n3. `ControllerBrokerRequestBatch#addUpdateMetadataRequestForBrokers`：用于往 updateMetadataRequestPartitionInfoMap 集合中添加 UpdateMetadataRequest 请求所需的数据。\n\n方法 `ControllerBrokerRequestBatch#sendRequestsToBrokers` 会遍历处理这 3 个集合，并调用 `KafkaController#sendRequest` 方法发送请求，底层还是依赖于前面分析过的 RequestSendThread 线程执行异步请求操作。\n\nControllerBrokerRequestBatch 类中定义的方法在实现上都比较直观，这里不展开分析。\n\n### 分区状态管理\n\nPartitionStateMachine 定义了 Kafka Controller 的分区状态机，用于管理集群中分区的状态信息，每个 Kafka Controller 都定义了自己的分区状态机，但只有在当前 Controller 实例成为 leader 角色时才会启动运行名下的状态机。分区状态机使用 PartitionState 特质定义分区的状态，同时提供了多个样例对象实现，分别表示不同的分区状态。分区状态样例对象说明：\n\n1. __NewPartition__ ：新创建出来的分区对应的状态，此时分区可能已经被分配了 AR 集合，但是还没有分配 ISR 集合和 leader 副本。\n2. __OnlinePartition__ ：当一个分区选举出 leader 副本之后，该分区即处于此状态。\n3. __OfflinePartition__ ：如果一个分区的 leader 副本失效，则切换成此状态。\n4. __NonExistentPartition__ ：描述一个不存在的分区，或者之前存在但是现在已经被删除了。\n\n分区状态转换图如下：\n\n![image](/images/2019/kafka-partition-state.png)\n\nPartitionStateMachine 的字段定义如下：\n\n```scala\nclass PartitionStateMachine(controller: KafkaController) extends Logging {\n\n    /** Controller 的上下文信息 */\n    private val controllerContext = controller.controllerContext\n    /** Controller 节点的 ID */\n    private val controllerId = controller.config.brokerId\n    /** ZK 工具类 */\n    private val zkUtils = controllerContext.zkUtils\n    /** 记录每个分区对应的分区状态信息 */\n    private val partitionState: mutable.Map[TopicAndPartition, PartitionState] = mutable.Map.empty\n    /** 用于向指定的 broker 批量发送请求 */\n    private val brokerRequestBatch = new ControllerBrokerRequestBatch(controller)\n    /** 表示分区状态机是否已经启动 */\n    private val hasStarted = new AtomicBoolean(false)\n    /** 默认 leader 副本选举器 */\n    private val noOpPartitionLeaderSelector = new NoOpLeaderSelector(controllerContext)\n    /** 用于监听 topic 变化的 ZK 监听器 */\n    private val topicChangeListener = new TopicChangeListener(controller)\n    /** 用于监听 topic 删除的 ZK 监听器 */\n    private val deleteTopicsListener = new DeleteTopicsListener(controller)\n    /** 记录监听对应 topic 分区变化的监听器集合 */\n    private val partitionModificationsListeners: mutable.Map[String, PartitionModificationsListener] = mutable.Map.empty\n\n    // ... 省略方法定义\n\n}\n```\n\n当 Kafka Controller 实例从 follower 角色选举成为 leader 角色时，会调用 `PartitionStateMachine#startup` 方法启动对应的分区状态机，该方法实现如下：\n\n```scala\ndef startup() {\n    // 初始化本地记录的所有分区状态\n    this.initializePartitionState()\n    // 标识分区状态机已经启动\n    hasStarted.set(true)\n    // 尝试将集群中所有 OfflinePartition 或 NewPartition 状态的可用分区切换成 OnlinePartition 状态\n    this.triggerOnlinePartitionStateChange()\n}\n```\n\n分区状态机使用 `PartitionStateMachine#partitionState` 字段记录集群中所有可用分区的状态，在启动时会初始化该字段，即初始化每个 topic 分区对应的状态信息，尝试将所有 OfflinePartition 或 NewPartition 状态的可用分区切换成 OnlinePartition 状态。\n\n方法 `PartitionStateMachine#initializePartitionState` 会遍历集群中所有的 topic 分区，并尝试获取分区对应的 leader 副本和 ISR 集合等信息，如果这些信息不存在则将对应分区初始化为 NewPartition 状态。否则，校验分区 leader 副本所在的 broker 节点是否可用，如果可用则将对应分区初始化为 OnlinePartition 状态，如果不可用则将对应分区初始化为 OfflinePartition 状态。方法实现如下：\n\n```scala\nprivate def initializePartitionState() {\n    // 遍历集群中的所有分区\n    for (topicPartition <- controllerContext.partitionReplicaAssignment.keys) {\n        // 获取对应分区 leader 副本所在的 brokerId、ISR 集合，以及 controller 年代信息\n        controllerContext.partitionLeadershipInfo.get(topicPartition) match {\n            // 存在 leader 副本和 ISR 集合\n            case Some(currentLeaderIsrAndEpoch) =>\n                // 分区 leader 副本所在的 broker 可用，初始化分区为 OnlinePartition 状态\n                if (controllerContext.liveBrokerIds.contains(currentLeaderIsrAndEpoch.leaderAndIsr.leader))\n                    partitionState.put(topicPartition, OnlinePartition)\n                // 分区 leader 副本所在的 broker 不可用，初始化为 OfflinePartition 状态\n                else\n                    partitionState.put(topicPartition, OfflinePartition)\n            // 如果不存在，则说明是一个新创建的分区，设置分区状态为 NewPartition\n            case None =>\n                partitionState.put(topicPartition, NewPartition)\n        }\n    }\n}\n```\n\n方法 `PartitionStateMachine#triggerOnlinePartitionStateChange` 会遍历所有可用的分区（不包含那些待删除的 topic 名下的分区），并尝试对状态为 OfflinePartition 或 NewPartition 的分区执行状态切换，切换成 OnlinePartition 状态。方法实现如下：\n\n```scala\ndef triggerOnlinePartitionStateChange() {\n    try {\n        // 校验待发送的请求集合，确保历史的请求已经全部发送完毕\n        brokerRequestBatch.newBatch()\n        // 遍历处理集群中所有的分区，不包含正在等待被删除的 topic 的分区，尝试切换分区状态为 OnlinePartition\n        for ((topicAndPartition, partitionState) <- partitionState\n             if !controller.deleteTopicManager.isTopicQueuedUpForDeletion(topicAndPartition.topic)) {\n            // 对于 OfflinePartition 或 NewPartition 状态的分区，尝试将对应分区状态修改为 OnlinePartition 状态\n            if (partitionState.equals(OfflinePartition) || partitionState.equals(NewPartition))\n                this.handleStateChange(\n                    topicAndPartition.topic,\n                    topicAndPartition.partition,\n                    OnlinePartition,\n                    controller.offlinePartitionSelector,\n                    (new CallbackBuilder).build)\n        }\n        // 发送请求\n        brokerRequestBatch.sendRequestsToBrokers(controller.epoch)\n    } catch {\n        // ... 省略异常处理\n    }\n}\n```\n\n而具体执行分区状态切换的操作则交由 `PartitionStateMachine#handleStateChange` 方法完成，关于该方法的实现将在接下来的小节中进行分析。\n\n#### 分区状态切换\n\n分区状态机定义了 `PartitionStateMachine#handleStateChanges` 方法用于将指定的 topic 分区集合中的分区状态切换成指定的目标状态，方法实现如下：\n\n```scala\ndef handleStateChanges(partitions: Set[TopicAndPartition], // 待处理的 topic 分区集合\n                       targetState: PartitionState, // 目标分区状态\n                       leaderSelector: PartitionLeaderSelector = noOpPartitionLeaderSelector, // 分区 leader 副本选择器\n                       callbacks: Callbacks = (new CallbackBuilder).build) {\n    info(\"Invoking state change to %s for partitions %s\".format(targetState, partitions.mkString(\",\")))\n    try {\n        // 校验待发送的请求集合，确保历史的请求已经全部发送完毕\n        brokerRequestBatch.newBatch()\n        // 遍历待处理的 topic 分区集合，执行分区状态切换\n        partitions.foreach { topicAndPartition =>\n            this.handleStateChange(topicAndPartition.topic, topicAndPartition.partition, targetState, leaderSelector, callbacks)\n        }\n        // 发送请求\n        brokerRequestBatch.sendRequestsToBrokers(controller.epoch)\n    } catch {\n        // ... 省略异常处理\n    }\n}\n```\n\n其中核心实现在于 `PartitionStateMachine#handleStateChange` 方法，前面分析分区状态机启动过程时也提到了该方法，下面一起来看一下该方法的具体实现（省略了日志打点）：\n\n```scala\nprivate def handleStateChange(topic: String, partition: Int,\n                              targetState: PartitionState,\n                              leaderSelector: PartitionLeaderSelector, // 执行 leader 选举的选择器\n                              callbacks: Callbacks) {\n    val topicAndPartition = TopicAndPartition(topic, partition)\n\n    // 检测当前分区状态机是否已经启动，只有 kafka controller leader 的分区状态机才需要启动，如果没有启动则抛出异常\n    if (!hasStarted.get)\n        throw new StateChangeFailedException((\"Controller %d epoch %d initiated state change for partition %s to %s failed because \" +\n                \"the partition state machine has not started\").format(controllerId, controller.epoch, topicAndPartition, targetState))\n\n    // 获取分区的当前状态，没有则初始化为 NonExistentPartition 状态\n    val currState = partitionState.getOrElseUpdate(topicAndPartition, NonExistentPartition)\n    try {\n        // 在转换开始之前，会依据于 targetState 检查分区的前置状态是否合法\n        targetState match {\n            case NewPartition =>\n                // 如果目标状态为 NewPartition，则前置状态必须是 NonExistentPartition\n                this.assertValidPreviousStates(topicAndPartition, List(NonExistentPartition), NewPartition)\n                // 切换分区状态为 NewPartition\n                partitionState.put(topicAndPartition, NewPartition)\n            case OnlinePartition =>\n                // 如果目标状态为 OnlinePartition，则前置状态必须是 NewPartition, OnlinePartition, OfflinePartition 中的一个\n                this.assertValidPreviousStates(topicAndPartition, List(NewPartition, OnlinePartition, OfflinePartition), OnlinePartition)\n                partitionState(topicAndPartition) match {\n                    case NewPartition =>\n                        // 如果前置状态是 NewPartition，则需要为分区分配 leader 副本和 ISR 集合\n                        this.initializeLeaderAndIsrForPartition(topicAndPartition)\n                    case OfflinePartition =>\n                        // 如果前置状态是 OfflinePartition，则需要为分区选举新的 leader 副本\n                        this.electLeaderForPartition(topic, partition, leaderSelector)\n                    case OnlinePartition => // invoked when the leader needs to be re-elected\n                        // 如果前置状态为 OnlinePartition，则需要为分区重新选举新的 leader 副本\n                        this.electLeaderForPartition(topic, partition, leaderSelector)\n                    case _ => // should never come here since illegal previous states are checked above\n                }\n                // 设置分区状态为 OnlinePartition\n                partitionState.put(topicAndPartition, OnlinePartition)\n            case OfflinePartition =>\n                // 如果目标状态为 OfflinePartition，则前置状态必须是 NewPartition, OnlinePartition, OfflinePartition 中的一个\n                this.assertValidPreviousStates(topicAndPartition, List(NewPartition, OnlinePartition, OfflinePartition), OfflinePartition)\n                // 设置分区状态为 OfflinePartition\n                partitionState.put(topicAndPartition, OfflinePartition)\n            case NonExistentPartition =>\n                // 如果目标状态为 NonExistentPartition，则前置状态必须是 OfflinePartition\n                this.assertValidPreviousStates(topicAndPartition, List(OfflinePartition), NonExistentPartition)\n                // 设置分区状态为 NonExistentPartition\n                partitionState.put(topicAndPartition, NonExistentPartition)\n        }\n    } catch {\n        // ... 省略异常处理\n    }\n}\n```\n\n分区状态切换的整体实现思路是依据切换的目标状态对当前分区状态执行校验，保证当前分区状态属于合法的目标切换状态的前置状态。方法 `PartitionStateMachine#assertValidPreviousStates` 实现了前置状态的校验，如果前置状态不合法则会抛出异常。\n\n如果目标切换状态是 NewPartition、OfflinePartition 和 NonExistentPartition 中的一个，则切换的过程比较简单。下面主要来看一下目标状态为 OnlinePartition 的分区状态切换，按照前置状态分为 3 种场景：\n\n1. 如果前置分区状态为 NewPartition，则需要为对应 topic 分区分配 leader 副本和 ISR 集合。\n2. 如果前置分区状态为 OfflinePartition，则需要为对应 topic 分区选举新的 leader 副本。\n3. 如果前置分区状态为 OnlinePartition，则需要为对应 topic 分区重新选举新的 leader 副本。\n\n场景 2 和 3 具体由 `PartitionStateMachine#electLeaderForPartition` 方法实现，我们将在稍后分析分区 leader 副本选举机制时介绍该方法，这里先来看一下场景 1，具体由 `PartitionStateMachine#initializeLeaderAndIsrForPartition` 方法实现：\n\n```scala\nprivate def initializeLeaderAndIsrForPartition(topicAndPartition: TopicAndPartition) {\n    // 获取分区的 AR 集合\n    val replicaAssignment = controllerContext.partitionReplicaAssignment(topicAndPartition)\n    // 获取 AR 集合中可用的副本集合\n    val liveAssignedReplicas = replicaAssignment.filter(r => controllerContext.liveBrokerIds.contains(r))\n    liveAssignedReplicas.size match {\n        // 没有可用的副本，抛出异常\n        case 0 =>\n            val failMsg = \"encountered error during state change of partition %s from New to Online, assigned replicas are [%s], live brokers are [%s]. No assigned replica is alive.\"\n                    .format(topicAndPartition, replicaAssignment.mkString(\",\"), controllerContext.liveBrokerIds)\n            stateChangeLogger.error(\"Controller %d epoch %d \".format(controllerId, controller.epoch) + failMsg)\n            throw new StateChangeFailedException(failMsg)\n        case _ =>\n            debug(\"Live assigned replicas for partition %s are: [%s]\".format(topicAndPartition, liveAssignedReplicas))\n            // 将可用的 AR 集合中的第一个副本选为 leader 副本\n            val leader = liveAssignedReplicas.head\n            // 创建 LeaderIsrAndControllerEpoch 对象，其中的 ISR 集合是可用的 AR 集合\n            val leaderIsrAndControllerEpoch = LeaderIsrAndControllerEpoch(new LeaderAndIsr(leader, liveAssignedReplicas.toList), controller.epoch)\n            debug(\"Initializing leader and isr for partition %s to %s\".format(topicAndPartition, leaderIsrAndControllerEpoch))\n            try {\n                // 将分区 leader 副本和 ISR 集合等信息写入 ZK，路径：/brokers/topics/{topic_name}/partitions/{partitionId}/state\n                zkUtils.createPersistentPath(\n                    getTopicPartitionLeaderAndIsrPath(topicAndPartition.topic, topicAndPartition.partition),\n                    zkUtils.leaderAndIsrZkData(leaderIsrAndControllerEpoch.leaderAndIsr, controller.epoch))\n                // 更新本地缓存的指定 topic 分区的相关信息\n                controllerContext.partitionLeadershipInfo.put(topicAndPartition, leaderIsrAndControllerEpoch)\n                // 添加 LeaderAndIsrRequest 请求，待发送\n                brokerRequestBatch.addLeaderAndIsrRequestForBrokers(\n                    liveAssignedReplicas, topicAndPartition.topic, topicAndPartition.partition, leaderIsrAndControllerEpoch, replicaAssignment)\n            } catch {\n                // ... 省略异常处理\n            }\n    }\n}\n```\n\n对于 NewPartition 状态的 topic 分区而言，会从该分区可用的副本中选举第 1 个副本作为 leader 副本，并将所有可用的副本添加到 ISR 集合中，然后将这些信息记录到 ZK 中，同时向对应 broker 节点发送 LeaderAndIsrRequest 请求，以执行分区副本角色切换。\n\n#### 分区 leader 副本选举\n\n分区状态机定义了 `PartitionStateMachine#electLeaderForPartition` 方法，基于给定的分区 leader 副本选择器对指定 topic 分区执行 leader 副本选择操作。方法实现如下：\n\n```scala\ndef electLeaderForPartition(topic: String, partition: Int, leaderSelector: PartitionLeaderSelector) {\n    val topicAndPartition = TopicAndPartition(topic, partition)\n    try {\n        var zookeeperPathUpdateSucceeded: Boolean = false\n        var newLeaderAndIsr: LeaderAndIsr = null\n        var replicasForThisPartition: Seq[Int] = Seq.empty[Int]\n        while (!zookeeperPathUpdateSucceeded) {\n            // 从 ZK 获取分区当前的 leader 副本、ISR 集合、zkVersion 等信息，如果不存在则抛出异常\n            val currentLeaderIsrAndEpoch = this.getLeaderIsrAndEpochOrThrowException(topic, partition)\n            val currentLeaderAndIsr = currentLeaderIsrAndEpoch.leaderAndIsr\n            val controllerEpoch = currentLeaderIsrAndEpoch.controllerEpoch\n            // 检测 controller 的年代信息，如果当前年代信息小于 ZK 中记录的年代信息，则说明存在新的 controller，需要放弃本次选举操作\n            if (controllerEpoch > controller.epoch) {\n                // ... 抛出 StateChangeFailedException 异常，省略\n            }\n            // 使用指定的 leader 副本选举器选择新的 leader 副本和 ISR 集合\n            val (leaderAndIsr, replicas) = leaderSelector.selectLeader(topicAndPartition, currentLeaderAndIsr)\n            // 将新的 leader 副本和 ISR 集合信息转换成 JSON 格式记录到 ZK，路径：/brokers/topics/{topic_name}/partitions/{partitionId}/state\n            val (updateSucceeded, newVersion) = ReplicationUtils.updateLeaderAndIsr(\n                zkUtils, topic, partition, leaderAndIsr, controller.epoch, currentLeaderAndIsr.zkVersion)\n            newLeaderAndIsr = leaderAndIsr\n            newLeaderAndIsr.zkVersion = newVersion\n            zookeeperPathUpdateSucceeded = updateSucceeded\n            replicasForThisPartition = replicas\n        }\n        val newLeaderIsrAndControllerEpoch = LeaderIsrAndControllerEpoch(newLeaderAndIsr, controller.epoch)\n        // 更新本地缓存的指定 topic 分区的相关信息\n        controllerContext.partitionLeadershipInfo.put(TopicAndPartition(topic, partition), newLeaderIsrAndControllerEpoch)\n        // 获取指定分区的 AR 集合\n        val replicas = controllerContext.partitionReplicaAssignment(TopicAndPartition(topic, partition))\n        // 添加 LeaderAndIsrRequest 请求，待发送\n        brokerRequestBatch.addLeaderAndIsrRequestForBrokers(replicasForThisPartition, topic, partition, newLeaderIsrAndControllerEpoch, replicas)\n    } catch {\n        // ... 省略异常处理\n    }\n    debug(\"After leader election, leader cache is updated to %s\".format(controllerContext.partitionLeadershipInfo.map(l => (l._1, l._2))))\n}\n```\n\n在执行分区 leader 副本选举时会基于给定的分区 leader 副本选择器为对应 topic 分区选择新的 leader 副本，并返回新的 ISR 集合，因为对应分区的状态信息发生了变更，所以需要将更新后的分区状态更新到 ZK，并向集群中所有可用的 broker 节点发送 LeaderAndIsrRequest 请求，通知对应 broker 节点执行分区副本角色切换，并更新本地缓存的集群元数据信息。\n\nPartitionLeaderSelector 特质抽象定义了分区 leader 副本选择器，定义如下：\n\n```scala\ntrait PartitionLeaderSelector {\n\n    /**\n     * 选举分区 leader 副本\n     *\n     * @param topicAndPartition   需要执行 leader 副本选举的分区\n     * @param currentLeaderAndIsr 目标分区当前 leader 副本、ISR 集合\n     * @return 选举后的新的 leader 副本和新 ISR 集合信息，以及需要接收 LeaderAndIsrRequest 的 brokerId 集合\n     * @throws NoReplicaOnlineException 如果 AR 集合中不存在可用的副本，则抛出异常\n     */\n    def selectLeader(topicAndPartition: TopicAndPartition, currentLeaderAndIsr: LeaderAndIsr): (LeaderAndIsr, Seq[Int])\n\n}\n```\n\nKafka 目前围绕 PartitionLeaderSelector 特质定义了 5 种分区 leader 副本选择策略：\n\n1. NoOpLeaderSelector\n2. OfflinePartitionLeaderSelector\n3. ReassignedPartitionLeaderSelector\n4. PreferredReplicaPartitionLeaderSelector\n5. ControlledShutdownLeaderSelector\n\n其中 NoOpLeaderSelector 在实现上最简单，它实际上并没有做什么事情，只是将参数传递的目标分区当前 leader 副本和 ISR 集合作为结果直接返回，下面来具体分析一下剩余 4 种分区 leader 选择策略。\n\n##### OfflinePartitionLeaderSelector\n\nOfflinePartitionLeaderSelector 分区 leader 副本选择器会尝试从 ISR 集合中选择新的 leader 副本，如果 ISR 集合中不存在可用的副本，则在配置允许的情况下尝试从 AR 集合中选择新的 leader 副本。策略实现如下：\n\n```scala\ndef selectLeader(topicAndPartition: TopicAndPartition, currentLeaderAndIsr: LeaderAndIsr): (LeaderAndIsr, Seq[Int]) = {\n    controllerContext.partitionReplicaAssignment.get(topicAndPartition) match {\n        // 处理分区的 AR 集合\n        case Some(assignedReplicas) =>\n            // 获取分区 AR 集合中可用的副本\n            val liveAssignedReplicas = assignedReplicas.filter(r => controllerContext.liveBrokerIds.contains(r))\n            // 获取 ISR 集合中可用的副本\n            val liveBrokersInIsr = currentLeaderAndIsr.isr.filter(r => controllerContext.liveBrokerIds.contains(r))\n            val currentLeaderEpoch = currentLeaderAndIsr.leaderEpoch\n            val currentLeaderIsrZkPathVersion = currentLeaderAndIsr.zkVersion\n\n            // 依据 ISR 集合中是否有可用的副本决定是从 ISR 集合中选举新的 leader 副本，还是从 AR 集合中选举新的 leader 副本\n            val newLeaderAndIsr =\n                if (liveBrokersInIsr.isEmpty) { // 如果 ISR 集合中不存在可用的副本\n                    // 依据配置（unclean.leader.election.enable）决定是否从 AR 集合中选择 leader 副本，如果不允许则抛出异常\n                    if (!LogConfig.fromProps(config.originals, AdminUtils.fetchEntityConfig(\n                        controllerContext.zkUtils, ConfigType.Topic, topicAndPartition.topic)).uncleanLeaderElectionEnable) {\n                        // ... 抛出 NoReplicaOnlineException 异常，省略\n                    }\n                    debug(\"No broker in ISR is alive for %s. Pick the leader from the alive assigned replicas: %s\".format(topicAndPartition, liveAssignedReplicas.mkString(\",\")))\n                    if (liveAssignedReplicas.isEmpty) {\n                        // AR 集合中没有可用副本，直接抛出异常\n                        // ... 抛出 NoReplicaOnlineException 异常，省略\n                    } else {\n                        // 从 AR 集合可用的副本中选取第一个副本作为新的 leader 副本，新的 ISR 集合中只有新的 leader 副本自己\n                        ControllerStats.uncleanLeaderElectionRate.mark()\n                        val newLeader = liveAssignedReplicas.head\n                        warn(\"No broker in ISR is alive for %s. Elect leader %d from live brokers %s. There's potential data loss.\".format(topicAndPartition, newLeader, liveAssignedReplicas.mkString(\",\")))\n                        new LeaderAndIsr(newLeader, currentLeaderEpoch + 1, List(newLeader), currentLeaderIsrZkPathVersion + 1)\n                    }\n                } else { // ISR 集合中存在可用的副本\n                    val liveReplicasInIsr = liveAssignedReplicas.filter(r => liveBrokersInIsr.contains(r))\n                    // 从 ISR 集合中选择第一个副本作为新的 leader 副本，以 ISR 集合中可用的副本集合作为新的 ISR 集合\n                    val newLeader = liveReplicasInIsr.head\n                    debug(\"Some broker in ISR is alive for %s. Select %d from ISR %s to be the leader.\".format(topicAndPartition, newLeader, liveBrokersInIsr.mkString(\",\")))\n                    // 构造 LeaderAndIsr 对象并返回\n                    new LeaderAndIsr(newLeader, currentLeaderEpoch + 1, liveBrokersInIsr, currentLeaderIsrZkPathVersion + 1)\n                }\n            info(\"Selected new leader and ISR %s for offline partition %s\".format(newLeaderAndIsr.toString(), topicAndPartition))\n\n            // 需要向 AR 集合中所有的可用副本所在 broker 节点发送 LeaderAndIsrRequest 请求\n            (newLeaderAndIsr, liveAssignedReplicas)\n        // 当前 topic 分区没有可用的副本\n        case None =>\n            throw new NoReplicaOnlineException(\"Partition %s doesn't have replicas assigned to it\".format(topicAndPartition))\n    }\n}\n```\n\n如果是从 ISR 集合中选择新的 leader 副本，则以 ISR 集合中所有可用的副本作为新的 ISR 集合。如果是从 AR 集合中选择新的 leader 副本，则需要配置 `unclean.leader.election.enable=true`，这种情况下 ISR 集合只包含 leader 副本。\n\n##### ReassignedPartitionLeaderSelector\n\nReassignedPartitionLeaderSelector 分区 leader 副本选择器在副本重新分配的前提下会选择既位于新分配的 AR 集合中，同时又位于 ISR 集合中的副本作为新的 leader 副本，并以之前的 ISR 集合作为新的 ISR 集合。策略实现如下：\n\n```scala\ndef selectLeader(topicAndPartition: TopicAndPartition, currentLeaderAndIsr: LeaderAndIsr): (LeaderAndIsr, Seq[Int]) = {\n    // 获取新分配的 AR 集合\n    val reassignedInSyncReplicas = controllerContext.partitionsBeingReassigned(topicAndPartition).newReplicas\n    val currentLeaderEpoch = currentLeaderAndIsr.leaderEpoch\n    val currentLeaderIsrZkPathVersion = currentLeaderAndIsr.zkVersion\n    // 新选择的 leader 副本必须在新分配的 AR 集合和 ISR 集合中\n    val aliveReassignedInSyncReplicas = reassignedInSyncReplicas\n            .filter(r => controllerContext.liveBrokerIds.contains(r) && currentLeaderAndIsr.isr.contains(r))\n    val newLeaderOpt = aliveReassignedInSyncReplicas.headOption\n    newLeaderOpt match {\n        // 存在满足条件的 leader 副本，以之前的 ISR 集合作为新的 ISR 集合\n        case Some(newLeader) =>\n            (new LeaderAndIsr(newLeader, currentLeaderEpoch + 1, currentLeaderAndIsr.isr, currentLeaderIsrZkPathVersion + 1), reassignedInSyncReplicas)\n        // 不存在满足条件的 leader 副本，抛出异常\n        case None =>\n            reassignedInSyncReplicas.size match {\n                case 0 =>\n                    throw new NoReplicaOnlineException(\"List of reassigned replicas for partition %s is empty. Current leader and ISR: [%s]\".format(topicAndPartition, currentLeaderAndIsr))\n                case _ =>\n                    throw new NoReplicaOnlineException(\"None of the reassigned replicas for partition %s are in-sync with the leader. Current leader and ISR: [%s]\".format(topicAndPartition, currentLeaderAndIsr))\n            }\n    }\n}\n```\n\n由上述实现可以看出，如果不存在满足条件的副本则会抛出异常。\n\n##### PreferredReplicaPartitionLeaderSelector\n\nPreferredReplicaPartitionLeaderSelector 分区 leader 副本选择器尝试选择优先副本（AR 集合中的第一个副本）作为 leader 副本，前提是该副本必须位于 ISR 集合中，并且以当前 ISR 集合作为新的 ISR 集合。策略实现如下：\n\n```scala\ndef selectLeader(topicAndPartition: TopicAndPartition, currentLeaderAndIsr: LeaderAndIsr): (LeaderAndIsr, Seq[Int]) = {\n    // 获取分区 AR 集合\n    val assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)\n    // 以分区 AR 集合的第一个副本作为优先副本\n    val preferredReplica = assignedReplicas.head\n    val currentLeader = controllerContext.partitionLeadershipInfo(topicAndPartition).leaderAndIsr.leader\n    if (currentLeader == preferredReplica) {\n        // 优先副本已经是 leader 副本\n        throw new LeaderElectionNotNeededException(\"Preferred replica %d is already the current leader for partition %s\".format(preferredReplica, topicAndPartition))\n    } else {\n        info(\"Current leader %d for partition %s is not the preferred replica.\".format(currentLeader, topicAndPartition) + \" Triggering preferred replica leader election\")\n        // 如果优先副本所在的 broker 节点可用，且位于 ISR 集合中，则选择成为新的 leader 副本\n        if (controllerContext.liveBrokerIds.contains(preferredReplica) && currentLeaderAndIsr.isr.contains(preferredReplica)) {\n            (new LeaderAndIsr(preferredReplica, currentLeaderAndIsr.leaderEpoch + 1, currentLeaderAndIsr.isr, currentLeaderAndIsr.zkVersion + 1), assignedReplicas)\n        } else {\n            throw new StateChangeFailedException(\"Preferred replica %d for partition \".format(preferredReplica) + \"%s is either not alive or not in the isr. Current leader and ISR: [%s]\".format(topicAndPartition, currentLeaderAndIsr))\n        }\n    }\n}\n```\n\n由上述实现可以看出，如果优先副本所在 broker 节点不可用，或者优先副本不位于 ISR 集合中，则会抛出异常。\n\n##### ControlledShutdownLeaderSelector\n\nControlledShutdownLeaderSelector 分区 leader 副本选择器会尝试将副本所在 broker 节点正在关闭的副本从 ISR 集合中移除，并将 ISR 集合中剩下的副本作为新的 ISR 集合，同时从中选择一个副本作为新的 leader 副本。策略实现如下：\n\n```scala\ndef selectLeader(topicAndPartition: TopicAndPartition, currentLeaderAndIsr: LeaderAndIsr): (LeaderAndIsr, Seq[Int]) = {\n    val currentLeaderEpoch = currentLeaderAndIsr.leaderEpoch\n    val currentLeaderIsrZkPathVersion = currentLeaderAndIsr.zkVersion\n    val currentLeader = currentLeaderAndIsr.leader\n    val assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)\n    // 获取当前可用的 brokerId 集合\n    val liveOrShuttingDownBrokerIds = controllerContext.liveOrShuttingDownBrokerIds\n    val liveAssignedReplicas = assignedReplicas.filter(r => liveOrShuttingDownBrokerIds.contains(r))\n    // 从当前 ISR 集合中移除副本所在 broker 节点正在关闭的副本\n    val newIsr = currentLeaderAndIsr.isr.filter(brokerId => !controllerContext.shuttingDownBrokerIds.contains(brokerId))\n    // 从可用的 AR 集合中选择位于新的 ISR 集合中的副本作为 leader 副本\n    liveAssignedReplicas.find(newIsr.contains) match {\n        case Some(newLeader) =>\n            debug(\"Partition %s : current leader = %d, new leader = %d\".format(topicAndPartition, currentLeader, newLeader))\n            (LeaderAndIsr(newLeader, currentLeaderEpoch + 1, newIsr, currentLeaderIsrZkPathVersion + 1), liveAssignedReplicas)\n        case None =>\n            throw new StateChangeFailedException(\"No other replicas in ISR %s for %s besides shutting down brokers %s\".format(currentLeaderAndIsr.isr.mkString(\",\"), topicAndPartition, controllerContext.shuttingDownBrokerIds.mkString(\",\")))\n    }\n}\n```\n\n### 副本状态管理\n\nReplicaStateMachine 定义了 Kafka Controller 的副本状态机，用于管理集群中副本的状态信息，每个 Kafka Controller 都定义了自己的副本状态机，但是只有在当前 Controller 实例成为 leader 角色时才会启动运行名下的状态机。副本状态机使用 ReplicaState 特质定义副本的状态，同时提供了多个样例对象实现，分别表示不同的副本状态。副本状态样例对象说明：\n\n1. __NewReplica__ ：新创建出来的副本对应的状态，处于该状态的副本只能是 follower 副本。\n2. __OnlineReplica__ ：当副本成为 AR 集合中的一员即位于该状态，此时副本既可以是 leader 角色，也可以是 follower 角色。\n3. __OfflineReplica__ ：当副本所在的 broker 节点宕机后，副本所对应的状态。\n4. __ReplicaDeletionStarted__ ：当开始删除副本时，会先将副本切换成该状态，然后开始执行删除操作。\n5. __ReplicaDeletionSuccessful__ ：当副本被成功删除后对应的状态。\n6. __ReplicaDeletionIneligible__ ：当副本删除失败后对应的状态。\n7. __NonExistentReplica__ ：一个被成功删除的副本，最终将切换成该状态。\n\n![image](/images/2019/kafka-replica-state.png)\n\nReplicaStateMachine 的字段定义如下：\n\n```scala\nclass ReplicaStateMachine(controller: KafkaController) extends Logging {\n\n    /** Controller 上下文信息 */\n    private val controllerContext = controller.controllerContext\n    /** Controller 的 ID */\n    private val controllerId = controller.config.brokerId\n    /** ZK 工具类 */\n    private val zkUtils = controllerContext.zkUtils\n    /** 记录每个副本对应的状态 */\n    private val replicaState: mutable.Map[PartitionAndReplica, ReplicaState] = mutable.Map.empty\n    /** ZK 监听器，用于监听 broker 节点的上下线 */\n    private val brokerChangeListener = new BrokerChangeListener(controller)\n    /** 用于向 broker 节点批量发送请求 */\n    private val brokerRequestBatch = new ControllerBrokerRequestBatch(controller)\n    /** 标识当前副本状态机是否成功启动 */\n    private val hasStarted = new AtomicBoolean(false)\n\n    // ... 省略方法定义\n\n}\n```\n\n当 Kafka Controller 实例从 follower 角色选举成为 leader 角色时，会调用 `ReplicaStateMachine#startup` 方法启动对应的副本状态机，该方法实现如下：\n\n```scala\ndef startup() {\n    // 初始化每个 topic 分区 AR 集合中的副本状态\n    this.initializeReplicaState()\n    // 标识当前副本状态机启动成功\n    hasStarted.set(true)\n    // 尝试将所有可用副本切换成 OnlineReplica 状态\n    this.handleStateChanges(controllerContext.allLiveReplicas(), OnlineReplica)\n}\n```\n\n副本状态机使用 `ReplicaStateMachine#replicaState` 字段记录集群中所有副本的状态，在启动时会初始化该字段，即初始化每个副本的状态信息，尝试将所有可用的副本状态切换成 OnlineReplica 状态，而将所有不可用的副本切换成 ReplicaDeletionIneligible 状态。\n\n方法 `ReplicaStateMachine#initializeReplicaState` 会遍历处理每个 topic 分区的 AR 集合，并依据副本所在 broker 节点是否可用对本地记录的副本状态执行初始化操作，方法实现如下：\n\n```scala\nprivate def initializeReplicaState() {\n    for ((topicPartition, assignedReplicas) <- controllerContext.partitionReplicaAssignment) {\n        val topic = topicPartition.topic\n        val partition = topicPartition.partition\n        // 遍历每个分区的 AR 集合，初始化对应分区的状态\n        assignedReplicas.foreach { replicaId =>\n            val partitionAndReplica = PartitionAndReplica(topic, partition, replicaId)\n            // 将可用的副本初始化为 OnlineReplica 状态\n            if (controllerContext.liveBrokerIds.contains(replicaId)) replicaState.put(partitionAndReplica, OnlineReplica)\n            // 将不可用的副本初始化为 ReplicaDeletionIneligible 状态\n            else replicaState.put(partitionAndReplica, ReplicaDeletionIneligible)\n        }\n    }\n}\n```\n\n方法 `ReplicaStateMachine#handleStateChanges` 会遍历所有可用的副本，并尝试将对应副本的状态切换成 OnlineReplica 状态，方法实现如下：\n\n```scala\ndef handleStateChanges(replicas: Set[PartitionAndReplica],\n                       targetState: ReplicaState,\n                       callbacks: Callbacks = (new CallbackBuilder).build) {\n    if (replicas.nonEmpty) {\n        info(\"Invoking state change to %s for replicas %s\".format(targetState, replicas.mkString(\",\")))\n        try {\n            // 校验待发送的请求集合，确保历史的请求已经全部发送完毕\n            brokerRequestBatch.newBatch()\n            // 遍历切换每个副本的状态\n            replicas.foreach(r => this.handleStateChange(r, targetState, callbacks))\n            // 发送请求\n            brokerRequestBatch.sendRequestsToBrokers(controller.epoch)\n        } catch {\n            case e: Throwable => error(\"Error while moving some replicas to %s state\".format(targetState), e)\n        }\n    }\n}\n```\n\n具体的状态切换交由 `ReplicaStateMachine#handleStateChange` 方法实现，这也是 ReplicaStateMachine 中定义的最核心的方法，实现如下（省略了部分日志打点）：\n\n```scala\ndef handleStateChange(partitionAndReplica: PartitionAndReplica, targetState: ReplicaState, callbacks: Callbacks) {\n    val topic = partitionAndReplica.topic\n    val partition = partitionAndReplica.partition\n    val replicaId = partitionAndReplica.replica\n    val topicAndPartition = TopicAndPartition(topic, partition)\n    // 检测副本状态机是否已经启动\n    if (!hasStarted.get)\n        throw new StateChangeFailedException(\n            \"Controller %d epoch %d initiated state change of replica %d for partition %s to %s failed because replica state machine has not started\"\n                    .format(controllerId, controller.epoch, replicaId, topicAndPartition, targetState))\n\n    // 获取指定副本当前的状态，如果不存在则初始化为 NonExistentReplica 状态\n    val currState = replicaState.getOrElseUpdate(partitionAndReplica, NonExistentReplica)\n    try {\n        // 获取分区的 AR 集合\n        val replicaAssignment = controllerContext.partitionReplicaAssignment(topicAndPartition)\n        // 在转换开始之前，会依据于目标状态检查副本的前置状态是否合法\n        targetState match {\n            case NewReplica =>\n                // 如果目标状态为 NewReplica，则前置状态必须是 NonExistentReplica\n                this.assertValidPreviousStates(partitionAndReplica, List(NonExistentReplica), targetState)\n                // 从 ZK 获取分区的 leader 副本和 ISR 集合等信息\n                val leaderIsrAndControllerEpochOpt = ReplicationUtils.getLeaderIsrAndEpochForPartition(zkUtils, topic, partition)\n                leaderIsrAndControllerEpochOpt match {\n                    case Some(leaderIsrAndControllerEpoch) =>\n                        // NewReplica 状态的副本不能是 leader 角色\n                        if (leaderIsrAndControllerEpoch.leaderAndIsr.leader == replicaId)\n                            throw new StateChangeFailedException(\"Replica %d for partition %s cannot be moved to NewReplica\"\n                                    .format(replicaId, topicAndPartition) + \"state as it is being requested to become leader\")\n                        // 向该副本所在 broker 节点发送 LeaderAndIsrRequest 请求，并发送 UpdateMetadataRequest 给所有可用的 broker 节点\n                        brokerRequestBatch.addLeaderAndIsrRequestForBrokers(\n                            List(replicaId), topic, partition, leaderIsrAndControllerEpoch, replicaAssignment)\n                    case None => // new leader request will be sent to this replica when one gets elected\n                }\n                // 更新当前副本状态为 NewReplica\n                replicaState.put(partitionAndReplica, NewReplica)\n            case ReplicaDeletionStarted =>\n                // 如果目标状态为 ReplicaDeletionStarted，则前置状态必须是 OfflineReplica\n                this.assertValidPreviousStates(partitionAndReplica, List(OfflineReplica), targetState)\n                // 更新当前副本状态为 ReplicaDeletionStarted\n                replicaState.put(partitionAndReplica, ReplicaDeletionStarted)\n                // 向该副本所在 broker 节点发送 StopReplicaRequest 请求\n                brokerRequestBatch.addStopReplicaRequestForBrokers(\n                    List(replicaId), topic, partition, deletePartition = true, callbacks.stopReplicaResponseCallback)\n            case ReplicaDeletionIneligible =>\n                // 如果目标状态为 ReplicaDeletionIneligible，则前置状态必须是 ReplicaDeletionStarted\n                this.assertValidPreviousStates(partitionAndReplica, List(ReplicaDeletionStarted), targetState)\n                // 更新当前副本状态为 ReplicaDeletionIneligible\n                replicaState.put(partitionAndReplica, ReplicaDeletionIneligible)\n            case ReplicaDeletionSuccessful =>\n                // 如果目标状态为 ReplicaDeletionSuccessful，则前置状态必须是 ReplicaDeletionStarted\n                this.assertValidPreviousStates(partitionAndReplica, List(ReplicaDeletionStarted), targetState)\n                // 更新当前副本状态为 ReplicaDeletionSuccessful\n                replicaState.put(partitionAndReplica, ReplicaDeletionSuccessful)\n            case NonExistentReplica =>\n                // 如果目标状态为 NonExistentReplica，则前置状态必须是 ReplicaDeletionSuccessful\n                this.assertValidPreviousStates(partitionAndReplica, List(ReplicaDeletionSuccessful), targetState)\n                // 从对应 topic 分区的 AR 集合中移除当前副本\n                val currentAssignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)\n                controllerContext.partitionReplicaAssignment.put(topicAndPartition, currentAssignedReplicas.filterNot(_ == replicaId))\n                // 移除副本缓存在本地的状态\n                replicaState.remove(partitionAndReplica)\n            case OnlineReplica =>\n                // 如果目标状态为 OnlineReplica，则前置状态必须是 NewReplica、OnlineReplica、OfflineReplica 和 ReplicaDeletionIneligible 中的一个\n                this.assertValidPreviousStates(partitionAndReplica,\n                    List(NewReplica, OnlineReplica, OfflineReplica, ReplicaDeletionIneligible), targetState)\n                replicaState(partitionAndReplica) match {\n                    case NewReplica =>\n                        // 如果前置状态是 NewReplica，则尝试将当前副本添加到对应分区的 AR 集合中\n                        val currentAssignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)\n                        if (!currentAssignedReplicas.contains(replicaId))\n                            controllerContext.partitionReplicaAssignment.put(topicAndPartition, currentAssignedReplicas :+ replicaId)\n                    case _ =>\n                        // 检测是否存在 leader 副本\n                        controllerContext.partitionLeadershipInfo.get(topicAndPartition) match {\n                            // 如果存在 leader 副本，则向该副本所在 broker 节点发送 LeaderAndIsrRequest 请求，并发送 UpdateMetadataRequest 给所有可用的 broker 节点\n                            case Some(leaderIsrAndControllerEpoch) =>\n                                brokerRequestBatch.addLeaderAndIsrRequestForBrokers(\n                                    List(replicaId), topic, partition, leaderIsrAndControllerEpoch, replicaAssignment)\n                                replicaState.put(partitionAndReplica, OnlineReplica)\n                            // 不存在 leader 副本\n                            case None => // that means the partition was never in OnlinePartition state, this means the broker never\n                            // started a log for that partition and does not have a high watermark value for this partition\n                        }\n                }\n                // 更新当前副本状态为 OnlineReplica\n                replicaState.put(partitionAndReplica, OnlineReplica)\n            case OfflineReplica =>\n                // 如果目标状态为 OfflineReplica，则前置状态必须是 NewReplica、OnlineReplica、OfflineReplica 和 ReplicaDeletionIneligible 中的一个\n                this.assertValidPreviousStates(partitionAndReplica,\n                    List(NewReplica, OnlineReplica, OfflineReplica, ReplicaDeletionIneligible), targetState)\n                // 向副本所在 broker 节点发送 StopReplicaRequest 请求\n                brokerRequestBatch.addStopReplicaRequestForBrokers(List(replicaId), topic, partition, deletePartition = false)\n                // As an optimization, the controller removes dead replicas from the ISR\n                val leaderAndIsrIsEmpty: Boolean =\n                    controllerContext.partitionLeadershipInfo.get(topicAndPartition) match {\n                        case Some(_) =>\n                            // 将当前副本从所在分区的 ISR 集合中移除\n                            controller.removeReplicaFromIsr(topic, partition, replicaId) match {\n                                case Some(updatedLeaderIsrAndControllerEpoch) =>\n                                    // send the shrunk ISR state change request to all the remaining alive replicas of the partition.\n                                    val currentAssignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)\n                                    if (!controller.deleteTopicManager.isPartitionToBeDeleted(topicAndPartition)) {\n                                        // 向除当前副本以外可用的 AR 集合副本发送 LeaderAndIsrRequest 请求，并向集群中所有可用的 broker 发送 UpdateMetadataRequest 请求\n                                        brokerRequestBatch.addLeaderAndIsrRequestForBrokers(currentAssignedReplicas.filterNot(_ == replicaId),\n                                            topic, partition, updatedLeaderIsrAndControllerEpoch, replicaAssignment)\n                                    }\n                                    // 更新当前副本状态为 OfflineReplica\n                                    replicaState.put(partitionAndReplica, OfflineReplica)\n                                    false\n                                case None =>\n                                    true\n                            }\n                        case None =>\n                            true\n                    }\n                if (leaderAndIsrIsEmpty && !controller.deleteTopicManager.isPartitionToBeDeleted(topicAndPartition))\n                    throw new StateChangeFailedException(\n                        \"Failed to change state of replica %d for partition %s since the leader and isr path in zookeeper is empty\".format(replicaId, topicAndPartition))\n        }\n    }\n    catch {\n        // ... 省略异常处理\n    }\n}\n```\n\n同前面分析过的分区状态切换 `PartitionStateMachine#handleStateChange` 方法类似，副本状态的整体实现思路同样是依据切换的目标状态对当前副本状态执行校验，保证当前副本状态属于合法的目标切换状态的前置状态。方法 `ReplicaStateMachine#assertValidPreviousStates` 实现了前置状态的校验，如果前置状态不合法则会抛出异常。具体的副本状态切换逻辑如上述方法中的代码注释，思想上类似前面介绍的分区状态切换的实现，这里不再展开分析。\n\n### Topic 删除机制\n\nTopicDeletionManager 负责对管理员指定的 topic 执行删除操作，它定义了 DeleteTopicsThread 线程，采用异步的方式删除待删除的 topic 集合。TopicDeletionManager 的字段定义如下：\n\n```scala\nclass TopicDeletionManager(controller: KafkaController,\n                           initialTopicsToBeDeleted: Set[String] = Set.empty,\n                           initialTopicsIneligibleForDeletion: Set[String] = Set.empty) extends Logging {\n\n    /** Controller 上下文 */\n    val controllerContext: ControllerContext = controller.controllerContext\n    /** 管理分区状态的状态机 */\n    val partitionStateMachine: PartitionStateMachine = controller.partitionStateMachine\n    /** 管理副本状态的状态机 */\n    val replicaStateMachine: ReplicaStateMachine = controller.replicaStateMachine\n    /** 条件对象，用于同步其他线程与 deleteTopicsThread 线程 */\n    val deleteTopicsCond: Condition = deleteLock.newCondition()\n    /** 标识 topic 删除操作是否开始 */\n    val deleteTopicStateChanged: AtomicBoolean = new AtomicBoolean(false)\n    /** 执行 topic 删除操作的线程 */\n    var deleteTopicsThread: DeleteTopicsThread = _\n    /** 是否允许删除 topic，对应 delete.topic.enable 配置  */\n    val isDeleteTopicEnabled: lang.Boolean = controller.config.deleteTopicEnable\n    /** 记录待删除的 topic 集合 */\n    val topicsToBeDeleted: mutable.Set[String] = if (isDeleteTopicEnabled) {\n        mutable.Set.empty[String] ++ initialTopicsToBeDeleted\n    } else {\n        // 如果配置不允许删除，则将对应的 topic 从 ZK 对应节点（/admin/delete_topics）下移除\n        val zkUtils = controllerContext.zkUtils\n        for (topic <- initialTopicsToBeDeleted) {\n            val deleteTopicPath = getDeleteTopicPath(topic)\n            info(\"Removing \" + deleteTopicPath + \" since delete topic is disabled\")\n            zkUtils.zkClient.delete(deleteTopicPath)\n        }\n        mutable.Set.empty[String]\n    }\n    /** 记录不可删除的 topic 集合 */\n    val topicsIneligibleForDeletion: mutable.Set[String] = mutable.Set.empty[String] ++ (initialTopicsIneligibleForDeletion & topicsToBeDeleted)\n    /** 记录待删除的分区集合 */\n    val partitionsToBeDeleted: mutable.Set[TopicAndPartition] = topicsToBeDeleted.flatMap(controllerContext.partitionsForTopic)\n\n    // ... 省略方法定义\n\n}\n```\n\nKafka 提供了 `delete.topic.enable` 配置项，用于配置是否启用 topic 删除机制，如果未开启则不会真正执行删除操作，而是将指定的待删除 topic 信息从 `/admin/delete_topics` 节点下移除。另外，由上面的字段定义可以看到 TopicDeletionManager 还管理了不可删除的 topic 集合，当一个 topic 满足以下条件之一时，我们认为暂时不能对其执行删除操作：\n\n1. Topic 的某个分区正在执行副本重新分配。\n2. Topic 的某个分区正在执行优先副本选举。\n3. Topic 的某个副本不可用，即所在的 broker 节点宕机。\n\n当 Kafka Controller 实例成为 leader 角色时会调用 `TopicDeletionManager#start` 方法启动 topic 删除机制，该方法主要用于启动后台删除线程 DeleteTopicsThread：\n\n```scala\ndef start() {\n    if (isDeleteTopicEnabled) {\n        deleteTopicsThread = new DeleteTopicsThread()\n        // 表示 topic 删除操作开始运行\n        if (topicsToBeDeleted.nonEmpty) deleteTopicStateChanged.set(true)\n        // 启动后台删除线程\n        deleteTopicsThread.start()\n    }\n}\n```\n\nDeleteTopicsThread 继承自 ShutdownableThread 抽象类，其 `DeleteTopicsThread#doWork` 方法实现如下：\n\n```scala\noverride def doWork() {\n    // 等待线程被唤醒\n    awaitTopicDeletionNotification()\n\n    if (!isRunning.get) return\n\n    inLock(controllerContext.controllerLock) {\n        // 获取并处理待删除的 topic 集合\n        val topicsQueuedForDeletion = Set.empty[String] ++ topicsToBeDeleted\n        topicsQueuedForDeletion.foreach { topic =>\n            // 如果当前 topic 的所有副本都已经被成功删除\n            if (controller.replicaStateMachine.areAllReplicasForTopicDeleted(topic)) {\n                // 变更 topic 及其分区和副本的状态，并从 ZK 和 Controller 上下文中移除 topic 相关的信息\n                completeDeleteTopic(topic)\n                info(\"Deletion of topic %s successfully completed\".format(topic))\n            }\n            // 如果当前 topic 存在未完成删除的副本\n            else {\n                // 如果任一副本处于 ReplicaDeletionStarted 状态，则等待\n                if (controller.replicaStateMachine.isAtLeastOneReplicaInDeletionStartedState(topic)) {\n                    // ... 暂时先跳过该 topic，这里省略日志打点\n                }\n                // 否则说明 topic 还未达到执行删除的条件，或者存在某个副本删除失败（对应 ReplicaDeletionIneligible 状态）\n                else {\n                    // 如果任一副本处于 ReplicaDeletionIneligible 状态，则将对应状态重置为 OfflineReplica 状态后重试\n                    if (controller.replicaStateMachine.isAnyReplicaInState(topic, ReplicaDeletionIneligible)) {\n                        markTopicForDeletionRetry(topic)\n                    }\n                }\n            }\n\n            // 检测当前 topic 是否可以删除\n            if (isTopicEligibleForDeletion(topic)) {\n                info(\"Deletion of topic %s (re)started\".format(topic))\n                // 开始执行 topic 删除操作\n                onTopicDeletion(Set(topic))\n            } else if (isTopicIneligibleForDeletion(topic)) {\n                info(\"Not retrying deletion of topic %s at this time since it is marked ineligible for deletion\".format(topic))\n            }\n        }\n    }\n}\n```\n\nTopic 删除的执行流程可以概括为：\n\n1. 获取待删除的 topic 集合；\n2. 如果 topic 的所有副本都已经成功被删除，则变更 topic 及其分区和副本的状态，并从 ZK 和 Controller 上下文中移除 topic 相关信息；\n3. 否则，如果 topic 存在任一副本处于删除准备的状态（ReplicaDeletionStarted），则跳过当前 topic 继续处理其它 topic；\n4. 否则，如果 topic 存在任一副本处于删除失败的状态（ReplicaDeletionIneligible），则尝试将对应副本状态重置为 OfflineReplica，等待后续删除重试；\n5. 检测当前 topic 是否可以被删除，如果可以则开始执行删除操作。\n\n下面来重点分析一下步骤 2 和 5。 __步骤 2__ 用于对已经成功被删除的 topic 执行一些后置清理工作，包括注销 ZK 监听器、切换分区和副本的状态，以及从 ZK 和 Controller 上下文中清除 topic 相关的数据等，具体实现如下：\n\n```scala\nprivate def completeDeleteTopic(topic: String) {\n    // 1. 注销 PartitionModificationsListener 监听器\n    partitionStateMachine.deregisterPartitionChangeListener(topic)\n\n    // 2. 将指定 topic 下被成功删除的副本状态切换成 NonExistentReplica\n    val replicasForDeletedTopic = controller.replicaStateMachine.replicasInState(topic, ReplicaDeletionSuccessful)\n    replicaStateMachine.handleStateChanges(replicasForDeletedTopic, NonExistentReplica)\n\n    // 3. 将指定 topic 下所有的 topic 分区状态切换成 NonExistentPartition\n    val partitionsForDeletedTopic = controllerContext.partitionsForTopic(topic)\n    partitionStateMachine.handleStateChanges(partitionsForDeletedTopic, OfflinePartition)\n    partitionStateMachine.handleStateChanges(partitionsForDeletedTopic, NonExistentPartition)\n\n    // 4. 将 topic 及其分区从待删除集合中移除\n    topicsToBeDeleted -= topic\n    partitionsToBeDeleted.retain(_.topic != topic)\n\n    // 5. 清除 ZK 上与该 topic 相关的数据\n    val zkUtils = controllerContext.zkUtils\n    zkUtils.zkClient.deleteRecursive(getTopicPath(topic))\n    zkUtils.zkClient.deleteRecursive(getEntityConfigPath(ConfigType.Topic, topic))\n    zkUtils.zkClient.delete(getDeleteTopicPath(topic))\n\n    // 6. 清空 Controller 上下文中与该 topic 相关的数据\n    controllerContext.removeTopic(topic)\n}\n```\n\n__步骤 5__ 负责向所有可用的 broker 节点发送 UpdateMetadataRequest 请求，通知这些节点相关 topic 需要被删除，并对 topic 名下分区的 AR 集合执行删除操作。一个 topic 可以执行删除需要满足以下 2 个条件：\n\n1. Topic 待删除，且还未开始进行删除操作。\n2. Topic 未标记为不可删除。\n\n对于同时满足上述条件的 topic 会调用 `TopicDeletionManager#onTopicDeletion` 方法执行删除操作：\n\n```scala\nprivate def onTopicDeletion(topics: Set[String]) {\n    info(\"Topic deletion callback for %s\".format(topics.mkString(\",\")))\n    val partitions = topics.flatMap(controllerContext.partitionsForTopic)\n    // 向所有可用的 broker 节点发送 UpdateMetadataRequest 请求，通知当前 topic 需要被删除\n    controller.sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq, partitions)\n    // 按照 topic 进行分组\n    val partitionReplicaAssignmentByTopic = controllerContext.partitionReplicaAssignment.groupBy(p => p._1.topic)\n    // 开始执行分区的删除操作\n    topics.foreach { topic =>\n        this.onPartitionDeletion(partitionReplicaAssignmentByTopic(topic).keySet)\n    }\n}\n```\n\n方法 `TopicDeletionManager#onPartitionDeletion` 只是简单获取了对应 topic 分区的 AR 集合，并调用 `TopicDeletionManager#startReplicaDeletion` 方法对这些副本执行删除操作：\n\n```scala\nprivate def startReplicaDeletion(replicasForTopicsToBeDeleted: Set[PartitionAndReplica]) {\n    replicasForTopicsToBeDeleted.groupBy(_.topic).keys.foreach { topic =>\n        // 获取 topic 名下所有可用的副本集合\n        val aliveReplicasForTopic = controllerContext.allLiveReplicas().filter(p => p.topic == topic)\n        // 获取 topic 名下中所有的不可用副本集合\n        val deadReplicasForTopic = replicasForTopicsToBeDeleted -- aliveReplicasForTopic\n        // 获取 topic 名下所有已完成删除的副本集合\n        val successfullyDeletedReplicas = controller.replicaStateMachine.replicasInState(topic, ReplicaDeletionSuccessful)\n        // 获取 topic 名下未完成删除的 topic 集合\n        val replicasForDeletionRetry = aliveReplicasForTopic -- successfullyDeletedReplicas\n        // 将不可用副本状态变更为 ReplicaDeletionIneligible\n        replicaStateMachine.handleStateChanges(deadReplicasForTopic, ReplicaDeletionIneligible)\n        // 将待删除的副本状态变更为 OfflineReplica，用于关闭 follower 对于 leader 的 fetch 请求\n        replicaStateMachine.handleStateChanges(replicasForDeletionRetry, OfflineReplica)\n        debug(\"Deletion started for replicas %s\".format(replicasForDeletionRetry.mkString(\",\")))\n        // 将待删除的副本状态变更为 ReplicaDeletionStarted，标记当前副本准备好开始删除\n        controller.replicaStateMachine.handleStateChanges(replicasForDeletionRetry, ReplicaDeletionStarted,\n            new Callbacks.CallbackBuilder().stopReplicaCallback(deleteTopicStopReplicaCallback).build)\n        // 如果 topic 存在不可用的副本，标记该 topic 不可删除\n        if (deadReplicasForTopic.nonEmpty) {\n            debug(\"Dead Replicas (%s) found for topic %s\".format(deadReplicasForTopic.mkString(\",\"), topic))\n            markTopicIneligibleForDeletion(Set(topic))\n        }\n    }\n}\n\nprivate def deleteTopicStopReplicaCallback(stopReplicaResponseObj: AbstractResponse, replicaId: Int) {\n    val stopReplicaResponse = stopReplicaResponseObj.asInstanceOf[StopReplicaResponse]\n    debug(\"Delete topic callback invoked for %s\".format(stopReplicaResponse))\n    val responseMap = stopReplicaResponse.responses.asScala\n    // 获取删除失败的分区集合\n    val partitionsInError =\n        if (stopReplicaResponse.errorCode != Errors.NONE.code) responseMap.keySet\n        else responseMap.filter { case (_, error) => error != Errors.NONE.code }.keySet\n    // 获取删除失败的副本集合\n    val replicasInError = partitionsInError.map(p => PartitionAndReplica(p.topic, p.partition, replicaId))\n    inLock(controllerContext.controllerLock) {\n        // 将删除失败的副本状态切换成 ReplicaDeletionIneligible，并唤醒删除线程再次尝试删除\n        this.failReplicaDeletion(replicasInError)\n        // 存在某些副本被成功删除，将这些副本状态切换成 ReplicaDeletionSuccessful\n        if (replicasInError.size != responseMap.size) {\n            val deletedReplicas = responseMap.keySet -- partitionsInError // 已经成功删除的副本\n            this.completeReplicaDeletion(deletedReplicas.map(p => PartitionAndReplica(p.topic, p.partition, replicaId)))\n        }\n    }\n}\n```\n\n对于删除失败的副本会将其状态切换成 ReplicaDeletionIneligible，并唤醒删除线程再次尝试删除；对于删除成功的副本则将其状态置为 ReplicaDeletionSuccessful。如果一个待删除 topic 所有的副本状态均为 ReplicaDeletionSuccessful，则 DeleteTopicsThread 线程会对该 topic 执行后置清理工作，即我们前面分析的步骤 2。\n\n### 副本再分配机制\n\nKafka Controller 提供了分区副本再分配机制，用于为指定的 topic 分区重新分配副本。当一个 Kafka Controller 实例竞选成为 leader 角色，或者管理员手动指定需要为某些 topic 分区重新分配副本时会触发该机制。这里我们以 Kafka Controller 实例竞选成为 leader 角色触发分区副本再分配的场景为例进行说明，关于管理员手动触发的场景留到后面分析 ZK 监听机制时再进行分析，实际上二者只是入口不同，具体的执行流程还是一样的。\n\n我们从 `KafkaController#maybeTriggerPartitionReassignment` 方法开始说起，当 Kafka Controller 实例竞选成为 leader 角色时会触发执行该方法。在 Controller 的上下文中定义了 `ControllerContext#partitionsBeingReassigned` 字段，用于记录需要和正在执行副本再分配操作的 topic 分区。而 `KafkaController#maybeTriggerPartitionReassignment` 方法只是简单了遍历了该字段，并调用 `KafkaController#initiateReassignReplicasForTopicPartition` 方法为每个需要执行副本再分配的 topic 分区执行再分配操作。\n\n在开始分析相关实现之前，我们需要明确 2 个概念：RAR 和 OAR，其中 RAR 表示分区新分配的 AR 集合，OAR 表示分区之前的 AR 集合。下面开始分析方法实现：\n\n```scala\ndef initiateReassignReplicasForTopicPartition(topicAndPartition: TopicAndPartition, reassignedPartitionContext: ReassignedPartitionsContext) {\n    // 获取新分配的 AR 集合：RAR\n    val newReplicas = reassignedPartitionContext.newReplicas\n    val topic = topicAndPartition.topic\n    val partition = topicAndPartition.partition\n    try {\n        // 获取指定 topic 分区之前的 AR 集合：OAR\n        val assignedReplicasOpt = controllerContext.partitionReplicaAssignment.get(topicAndPartition)\n        assignedReplicasOpt match {\n            case Some(assignedReplicas) =>\n                // 如果新旧副本未发生变化（OAR == RAR），则无需再分配\n                if (assignedReplicas == newReplicas) {\n                    throw new KafkaException(\"Partition %s to be reassigned is already assigned to replicas\".format(topicAndPartition) + \" %s. Ignoring request for partition reassignment\".format(newReplicas.mkString(\",\")))\n                } else {\n                    info(\"Handling reassignment of partition %s to new replicas %s\".format(topicAndPartition, newReplicas.mkString(\",\")))\n                    // 为分区注册一个 ReassignedPartitionsIsrChangeListener 监听器\n                    this.watchIsrChangesForReassignedPartition(topic, partition, reassignedPartitionContext)\n                    controllerContext.partitionsBeingReassigned.put(topicAndPartition, reassignedPartitionContext)\n                    // 标记 topic 为不可删除，因为需要执行副本再分配操作\n                    deleteTopicManager.markTopicIneligibleForDeletion(Set(topic))\n                    // 执行副本再分配操作\n                    this.onPartitionReassignment(topicAndPartition, reassignedPartitionContext)\n                }\n            case None => throw new KafkaException(\"Attempt to reassign partition %s that doesn't exist\".format(topicAndPartition))\n        }\n    } catch {\n        // ... 省略异常处理\n    }\n}\n```\n\n如果新分配的副本集合较当前的 AR 集合有变更，则会触发执行再分配操作，在开始操作之前，需要为对应 topic 分区注册一个 ReassignedPartitionsIsrChangeListener 监听器，并标记分区所属的 topic 不可被删除。ReassignedPartitionsIsrChangeListener 用于监听当前分区 ISR 集合的变化，具体实现我们留到后面的小节中针对性分析，下面重点来看一下 `KafkaController#onPartitionReassignment` 方法实现：\n\n```scala\ndef onPartitionReassignment(topicAndPartition: TopicAndPartition, reassignedPartitionContext: ReassignedPartitionsContext) {\n    // 获取新分配的副本集合 RAR\n    val reassignedReplicas = reassignedPartitionContext.newReplicas\n    // 如果新分配的副本集合存在一个或多个副本不位于 ISR 集合中\n    if (!this.areReplicasInIsr(topicAndPartition.topic, topicAndPartition.partition, reassignedReplicas)) {\n        info(\"New replicas %s for partition %s being \".format(reassignedReplicas.mkString(\",\"), topicAndPartition) + \"reassigned not yet caught up with the leader\")\n        // 获取新添加的副本集合：RAR - OAR\n        val newReplicasNotInOldReplicaList = reassignedReplicas.toSet -- controllerContext.partitionReplicaAssignment(topicAndPartition).toSet\n        // 获取全部的副本集合：RAR + OAR\n        val newAndOldReplicas = (reassignedPartitionContext.newReplicas ++ controllerContext.partitionReplicaAssignment(topicAndPartition)).toSet\n        // 1. 将 topic 的全部副本集合（OAR + RAR）更新到 Controller 上下文和 ZK\n        this.updateAssignedReplicasForPartition(topicAndPartition, newAndOldReplicas.toSeq)\n        // 2. 向 topic 的全部副本集合（OAR + RAR）所在的 broker 节点发送 LeaderAndIsrRequest 请求\n        this.updateLeaderEpochAndSendRequest(topicAndPartition, controllerContext.partitionReplicaAssignment(topicAndPartition), newAndOldReplicas.toSeq)\n        // 3. 将新增的副本（RAR - OAR）状态切换成 NewReplica\n        this.startNewReplicasForReassignedPartition(topicAndPartition, reassignedPartitionContext, newReplicasNotInOldReplicaList)\n        info(\"Waiting for new replicas %s for partition %s being \".format(reassignedReplicas.mkString(\",\"), topicAndPartition) + \"reassigned to catch up with the leader\")\n    }\n    // 如果新分配的副本全部位于 ISR 集合中\n    else {\n        // 1. 获取旧的副本集合（OAR - RAR）\n        val oldReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition).toSet -- reassignedReplicas.toSet\n        // 2. 将新分配的副本集合（RAR）中所有副本的状态切换成 OnlineReplica\n        reassignedReplicas.foreach { replica =>\n            replicaStateMachine.handleStateChanges(Set(PartitionAndReplica(topicAndPartition.topic, topicAndPartition.partition, replica)), OnlineReplica)\n        }\n        // 3. 更新本地记录的分区 AR 集合（OAR -> RAR），同时按需选择新的 leader 副本，并通知到集群中相关节点\n        this.moveReassignedPartitionLeaderIfRequired(topicAndPartition, reassignedPartitionContext)\n        // 4. 将旧的副本状态切换成 NonExistentReplica\n        this.stopOldReplicasOfReassignedPartition(topicAndPartition, reassignedPartitionContext, oldReplicas)\n        // 5. 更新 ZK 中记录对应分区的 AR 集合（RAR）\n        this.updateAssignedReplicasForPartition(topicAndPartition, reassignedReplicas)\n        // 6. 将对应 topic 分区的副本再分配信息从 ZK 和上下文中移除\n        this.removePartitionFromReassignedPartitions(topicAndPartition)\n        info(\"Removed partition %s from the list of reassigned partitions in zookeeper\".format(topicAndPartition))\n        controllerContext.partitionsBeingReassigned.remove(topicAndPartition)\n        // 7. 向所有可用的 broker 节点发送 UpdateMetadataRequest 请求，通知副本再分配后的集群状态信息\n        this.sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq, Set(topicAndPartition))\n        // 8. 取消相关 topic 的不可删除标记，并唤醒 DeleteTopicsThread 线程\n        deleteTopicManager.resumeDeletionForTopics(Set(topicAndPartition.topic))\n    }\n}\n```\n\n如果 RAR 中存在一个或多个副本不在 ISR 集合中，则再分配的执行流程如下：\n\n1. 以 OAR + RAR 中全部副本集合作为对应 topic 分区的 AR 集合，更新到 ZK 和 Controller 上下文中；\n2. 向 OAR + RAR 中全部副本所在的 broker 节点发送 LeaderAndIsrRequest 请求，更新对应节点缓存的分区 leader 副本的年代信息；\n3. 切换新增的副本（RAR - OAR）状态为 NewReplica。\n\n这一场景下再分配操作并未执行完成，实际上大部分再分配操作新分配的 RAR 集合中都包含一个或多个不存在于 ISR 集合中的副本，所以上面的执行流程可以看做是副本再分配操作的前置流程。当这些新增的副本在运行一段时间之后，与 leader 副本进行同步，并逐一加入到 ISR 集合之后会触发 ReassignedPartitionsIsrChangeListener 监听器，回调执行后续的流程（即 RAR 中的副本全部存在于 ISR 集合中）。\n\n如果 RAR 中的副本均包含在对应分区的 ISR 集合中，则再分配的执行流程如下：\n\n1. 切换 RAR 中所有副本的状态为 OnlineReplica；\n2. 使用 RAR 集合更新对应 topic 分区的 AR 集合，并在 leader 副本不在 RAR 集合中或所在的 broker 节点失效的情况下，基于 ReassignedPartitionLeaderSelector 分区 leader 副本选择器重新选择新的 leader 副本；\n3. 切换旧的副本（OAR - RAR）状态为 NonExistentReplica；\n4. 更新 ZK 中记录的对应分区的 AR 集合；\n5. 从 ZK 和 Controller 上下文中移除对应 topic 分区的副本再分配信息；\n6. 向所有可用的 broker 节点发送 UpdateMetadataRequest 请求，更新副本再分配后的集群状态信息；\n7. 取消对应 topic 的不可删除标记（前面有标记为不可删除），并唤醒 DeleteTopicsThread 线程。\n\n各步骤的方法实现都比较简单，这里不再继续深入。\n\n### ZK 监听机制\n\nKafka 与 ZK 的交互依赖于 [zkclient](https://github.com/sgroschupf/zkclient) 客户端，zkclient 定义了 3 种类型的监听器接口实现：IZkDataListener、IZkChildListener 和 IZkStateListener。其中 IZkDataListener 用于监听指定节点数据的变化，IZkChildListener 用于监听指定节点下子节点的变化，IZkStateListener 则用于监听 ZK 连接状态的变化。本小节我们重点关注与 Kafka Controller 相关的 ZK 监听器实现。\n\n#### ZK 连接状态监听器\n\nSessionExpirationListener 实现了 IZkStateListener 接口，用于监听 Kafka Controller 与 ZK 之间的连接状态。SessionExpirationListener 提供了 `SessionExpirationListener#handleNewSession` 方法实现，当与 ZK 建立新的连接会话时会触发回调该方法，尝试选举新的 leader 角色。方法实现如下：\n\n```scala\ndef handleNewSession() {\n    info(\"ZK expired; shut down all controller components and try to re-elect\")\n    // 如果 ZK 上记录的 controller leader 不是当前 broker 节点\n    if (controllerElector.getControllerID != config.brokerId) {\n        // 尝试清理 controller 之前的状态\n        onControllerResignation()\n        inLock(controllerContext.controllerLock) {\n            // 尝试竞选成为新的 controller leader\n            controllerElector.elect\n        }\n    } else {\n        info(\"ZK expired, but the current controller id %d is the same as this broker id, skip re-elect\".format(config.brokerId))\n    }\n}\n```\n\n当 broker 与 ZK 建立新的会话时，上述方法会检查当前 ZK 上记录的 leader 节点是否是当前实例所在的节点，如果不是的话则需要调用 `KafkaController#onControllerResignation` 执行一些状态清理工作（因为当前节点之前可能是 leader 角色），然后调用 `ZookeeperLeaderElector#elect` 方法基于 ZK 的临时节点机制尝试竞选成为新的 leader。关于 `ZookeeperLeaderElector#elect` 方法，我们在后面会专门分析，这里先来看一下  `KafkaController#onControllerResignation` 方法实现：\n\n```scala\ndef onControllerResignation() {\n    debug(\"Controller resigning, broker id %d\".format(config.brokerId))\n\n    // 取消 ZK 上的监听器\n    this.deregisterIsrChangeNotificationListener()\n    this.deregisterReassignedPartitionsListener()\n    this.deregisterPreferredReplicaElectionListener()\n\n    // 关闭 topic 删除机制\n    if (deleteTopicManager != null) deleteTopicManager.shutdown()\n\n    // 关闭 partition-rebalance 分区再平衡定时任务\n    if (config.autoLeaderRebalanceEnable) autoRebalanceScheduler.shutdown()\n\n    inLock(controllerContext.controllerLock) {\n        // 取消所有的 ReassignedPartitionsIsrChangeListener 监听器\n        this.deregisterReassignedPartitionsIsrChangeListeners()\n        // 关闭分区状态机\n        partitionStateMachine.shutdown()\n        // 关闭副本状态机\n        replicaStateMachine.shutdown()\n        // 关闭 ControllerChannelManager，断开与集群中其他 broker 节点之间的连接\n        if (controllerContext.controllerChannelManager != null) {\n            controllerContext.controllerChannelManager.shutdown()\n            controllerContext.controllerChannelManager = null\n        }\n        // 清除 controller 年代信息\n        controllerContext.epoch = 0\n        controllerContext.epochZkVersion = 0\n        // 切换 broker 节点的状态\n        brokerState.newState(RunningAsBroker)\n\n        info(\"Broker %d resigned as the controller\".format(config.brokerId))\n    }\n}\n```\n\n上述方法会在 Kafka Controller 由 leader 角色降级为 follower 角色时被触发，具体的执行逻辑如代码注释。\n\n#### ZK 节点状态监听器\n\n##### TopicChangeListener\n\nTopicChangeListener 实现了 IZkChildListener 接口，用于监听 `/brokers/topics` 节点，当有新的 topic 创建或者删除已有 topic 时，会触发执行相应的回调：\n\n```scala\ndef doHandleChildChange(parentPath: String, children: Seq[String]) {\n    inLock(controllerContext.controllerLock) {\n        if (hasStarted.get) {\n            try {\n                // 获取 /brokers/topics 路径下的子节点，即当前有效的 topic 集合\n                val currentChildren = {\n                    debug(\"Topic change listener fired for path %s with children %s\".format(parentPath, children.mkString(\",\")))\n                    children.toSet\n                }\n                // 获取新添加的 topic 集合\n                val newTopics = currentChildren -- controllerContext.allTopics\n                // 获取已删除的 topic 集合\n                val deletedTopics = controllerContext.allTopics -- currentChildren\n                // 更新本地记录的所有 topic 集合\n                controllerContext.allTopics = currentChildren\n\n                // 从 ZK 读取新增分区的 AR 集合，路径：/brokers/topics/{topic_name}\n                val addedPartitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(newTopics.toSeq)\n                // 更新上下文中记录的每个分区对应的 AR 集合\n                controllerContext.partitionReplicaAssignment =\n                        controllerContext.partitionReplicaAssignment.filter(p => !deletedTopics.contains(p._1.topic))\n                controllerContext.partitionReplicaAssignment ++= addedPartitionReplicaAssignment\n                info(\"New topics: [%s], deleted topics: [%s], new partition replica assignment [%s]\".format(newTopics, deletedTopics, addedPartitionReplicaAssignment))\n                // 处理新增的 topic，及其新增的分区\n                if (newTopics.nonEmpty)\n                    controller.onNewTopicCreation(newTopics, addedPartitionReplicaAssignment.keySet)\n            } catch {\n                case e: Throwable => error(\"Error while handling new topic\", e)\n            }\n        }\n    }\n}\n```\n\n上述方法基于 ZK 感知当前新增和已删除的 topic 集合，并更新本地记录的可用的 topic 集合，及其分区的 AR 集合信息。对于新增的 topic 集合，Kafka Controller 会调用 `KafkaController#onNewTopicCreation` 方法为每个 topic 注册一个 PartitionModificationsListener 监听器，同时切换对应 topic 新增分区及其副本的状态，使其能够上线运行。相关实现如下：\n\n```scala\ndef onNewTopicCreation(topics: Set[String], newPartitions: Set[TopicAndPartition]) {\n    info(\"New topic creation callback for %s\".format(newPartitions.mkString(\",\")))\n    // 为每个新增的 topic 注册一个 PartitionModificationsListener 监听器\n    topics.foreach(topic => partitionStateMachine.registerPartitionChangeListener(topic))\n    // 切换新增分区及其副本状态\n    this.onNewPartitionCreation(newPartitions)\n}\n\ndef onNewPartitionCreation(newPartitions: Set[TopicAndPartition]) {\n    info(\"New partition creation callback for %s\".format(newPartitions.mkString(\",\")))\n    // 将所有新增的分区状态转换为 NewPartition\n    partitionStateMachine.handleStateChanges(newPartitions, NewPartition)\n    // 将新增分区的所有副本都转换为 NewReplica，向副本所在 broker 节点发送 LeaderAndIsrRequest 请求，并发送 UpdateMetadataRequest 给所有可用的 broker 节点\n    replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), NewReplica)\n    // 为所有新增的分区分配 leader 副本和 ISR 集合，并将分区状态转换为 OnlinePartition\n    partitionStateMachine.handleStateChanges(newPartitions, OnlinePartition, offlinePartitionSelector)\n    // 将新增分区的所有副本状态转换为 OnlineReplica，并尝试将副本添加到 AR 集合中\n    replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), OnlineReplica)\n}\n```\n\n由上面的实现可以看出，分区和副本的状态并非是一次性切换成 Online 状态的，而是先切换成 New 状态，再切换成 Online 状态，期间会为分区分配 leader 副本和 ISR 集合，并尝试将新的副本添加到对应分区的 AR 集合中。\n\n##### DeleteTopicsListener\n\nDeleteTopicsListener 实现了 IZkChildListener 接口，用于监听 `/admin/delete_topics` 节点，当管理员指定要删除一些 topic 时，对应的 topic 会被写入到该 ZK 节点下，然后触发执行 DeleteTopicsListener 的回调方法 `DeleteTopicsListener#doHandleChildChange`，实现如下：\n\n```scala\ndef doHandleChildChange(parentPath: String, children: Seq[String]) {\n    inLock(controllerContext.controllerLock) {\n        // 从 ZK 获取待删除的 topic 集合\n        var topicsToBeDeleted = children.toSet\n        debug(\"Delete topics listener fired for topics %s to be deleted\".format(topicsToBeDeleted.mkString(\",\")))\n        // 检查 topic 是否存在，对于不存在的 topic 直接将其从 /admin/delete_topics 路径下删除\n        val nonExistentTopics = topicsToBeDeleted -- controllerContext.allTopics\n        if (nonExistentTopics.nonEmpty) {\n            warn(\"Ignoring request to delete non-existing topics \" + nonExistentTopics.mkString(\",\"))\n            nonExistentTopics.foreach(topic => zkUtils.deletePathRecursive(getDeleteTopicPath(topic)))\n        }\n        topicsToBeDeleted --= nonExistentTopics\n\n        // 如果允许删除 topic，对应 delete.topic.enable 配置\n        if (controller.config.deleteTopicEnable) {\n            if (topicsToBeDeleted.nonEmpty) {\n                info(\"Starting topic deletion for topics \" + topicsToBeDeleted.mkString(\",\"))\n                // 检查待删除的 topic 是否处于不可删除的情况\n                topicsToBeDeleted.foreach { topic =>\n                    // 1. 检测待删除的 topic 是否有分区正在进行优先副本选举\n                    val preferredReplicaElectionInProgress =\n                        controllerContext.partitionsUndergoingPreferredReplicaElection.map(_.topic).contains(topic)\n                    // 2. 检测待删除的 topic 是否有分区正在进行副本再分配\n                    val partitionReassignmentInProgress =\n                        controllerContext.partitionsBeingReassigned.keySet.map(_.topic).contains(topic)\n                    // 如果满足上述 2 个条件之一，则将 topic 标记为不可删除\n                    if (preferredReplicaElectionInProgress || partitionReassignmentInProgress)\n                        controller.deleteTopicManager.markTopicIneligibleForDeletion(Set(topic))\n                }\n                // 将可删除的 topic 提交给 TopicDeletionManager 执行删除操作\n                controller.deleteTopicManager.enqueueTopicsForDeletion(topicsToBeDeleted)\n            }\n        } else {\n            // 如果配置不允许删除 topic，则从 ZK 上删除对应的节点（/admin/delete_topics）\n            for (topic <- topicsToBeDeleted) {\n                info(\"Removing \" + getDeleteTopicPath(topic) + \" since delete topic is disabled\")\n                zkUtils.zkClient.delete(getDeleteTopicPath(topic))\n            }\n        }\n    }\n}\n```\n\n当检测到有新的 topic 需要被删除时，上述方法会获取需要被删除的 topic 集合，并判定对应的 topic 是否是有效的（是否是真实存在的），如果无效则直接将相关删除信息从 ZK 节点下移除，对于有效的 topic 集合，在配置（对应 `delete.topic.enable` 配置）允许的情况下会检查待删除的 topic 分区是否满足以下 2 个条件：\n\n1. 存在正在进行优先副本选举的分区。\n2. 存在正在进行副本重新分配的分区。\n\n如果待删除分区满足上述 2 个条件之一则将其标记为不可删除，否则将对应的 topic 提交给 TopicDeletionManager 执行删除操作。TopicDeletionManager 会将待删除的 topic 及其分区集合添加到 TopicDeletionManager 定义的待删除集合中，并唤醒 DeleteTopicsThread 线程执行删除操作。关于 TopicDeletionManager 的运行机制可以参考前面小节的分析。\n\n##### BrokerChangeListener\n\nBrokerChangeListener 实现了IZkChildListener 接口，用于监听 `/broker/ids` 节点，当有 broker 节点上线或者下线时，会触发执行相应的回调：\n\n```scala\ndef doHandleChildChange(parentPath: String, currentBrokerList: Seq[String]) {\n    info(\"Broker change listener fired for path %s with children %s\".format(parentPath, currentBrokerList.sorted.mkString(\",\")))\n    inLock(controllerContext.controllerLock) {\n        if (hasStarted.get) {\n            ControllerStats.leaderElectionTimer.time {\n                try {\n                    // 从 ZK 获取 broker 节点列表\n                    val curBrokers = currentBrokerList.map(_.toInt).toSet.flatMap(zkUtils.getBrokerInfo)\n                    val curBrokerIds = curBrokers.map(_.id)\n                    val liveOrShuttingDownBrokerIds = controllerContext.liveOrShuttingDownBrokerIds\n                    // 筛选新增的 broker 节点列表\n                    val newBrokerIds = curBrokerIds -- liveOrShuttingDownBrokerIds\n                    // 筛选故障的 broker 节点列表\n                    val deadBrokerIds = liveOrShuttingDownBrokerIds -- curBrokerIds\n                    val newBrokers = curBrokers.filter(broker => newBrokerIds(broker.id))\n                    // 更新 Controller 上下文信息\n                    controllerContext.liveBrokers = curBrokers\n                    val newBrokerIdsSorted = newBrokerIds.toSeq.sorted\n                    val deadBrokerIdsSorted = deadBrokerIds.toSeq.sorted\n                    val liveBrokerIdsSorted = curBrokerIds.toSeq.sorted\n                    info(\"Newly added brokers: %s, deleted brokers: %s, all live brokers: %s\"\n                            .format(newBrokerIdsSorted.mkString(\",\"), deadBrokerIdsSorted.mkString(\",\"), liveBrokerIdsSorted.mkString(\",\")))\n                    // 创建 controller 到新增的 broker 节点之间的网络连接，并启动请求发送线程\n                    newBrokers.foreach(controllerContext.controllerChannelManager.addBroker)\n                    // 关闭 controller 到故障的 broker 节点之间的网络连接\n                    deadBrokerIds.foreach(controllerContext.controllerChannelManager.removeBroker)\n                    // 如果存在新增的 broker 节点，通知集群中的其它 broker 节点，并上线新增的分区副本等\n                    if (newBrokerIds.nonEmpty) controller.onBrokerStartup(newBrokerIdsSorted)\n                    // 如果存在故障的 broker 节点，则下线故障 broker 节点上的分区和副本，并通知到集群中的其它 broker 节点\n                    if (deadBrokerIds.nonEmpty) controller.onBrokerFailure(deadBrokerIdsSorted)\n                } catch {\n                    case e: Throwable => error(\"Error while handling broker changes\", e)\n                }\n            }\n        }\n    }\n}\n```\n\n对于新上线的 broker 节点会触发 Kafka Controller 创建到这些节点的网络连接，并通知集群中所有可用的 broker 节点有新的 broker 节点上线，同时切换新增 broker 节点上的分区副本状态，以上线对外提供服务。相关实现位于 `KafkaController#onBrokerStartup` 方法中：\n\n```scala\ndef onBrokerStartup(newBrokers: Seq[Int]) {\n    info(\"New broker startup callback for %s\".format(newBrokers.mkString(\",\")))\n    val newBrokersSet = newBrokers.toSet\n\n    // 1. 向集群中所有可用的 broker 节点发送 UpdateMetadataRequest 请求，发送的是所有的分区信息，通知节点有新的 broker 加入\n    this.sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)\n\n    // 2. 将新增的 broker 节点上的副本状态设置为 OnlineReplica，以上线对外提供服务\n    val allReplicasOnNewBrokers = controllerContext.replicasOnBrokers(newBrokersSet)\n    replicaStateMachine.handleStateChanges(allReplicasOnNewBrokers, OnlineReplica)\n\n    // 3. 尝试将状态为 OfflinePartition 和 NewPartition 的分区设置为 OnlinePartition，以触发失效分区的 leader 副本选举\n    partitionStateMachine.triggerOnlinePartitionStateChange()\n\n    // 4. 检查正在重新分配副本的分区是否需要重新分配副本\n    val partitionsWithReplicasOnNewBrokers = controllerContext.partitionsBeingReassigned.filter {\n        case (_, reassignmentContext) => reassignmentContext.newReplicas.exists(newBrokersSet.contains)\n    }\n    partitionsWithReplicasOnNewBrokers.foreach(p => onPartitionReassignment(p._1, p._2))\n\n    // 5. 如果新增 broker 上有待删除的 topic 的副本，则唤醒 DeleteTopicsThread 线程进行删除，因为对应 topic 之前可能因为该副本失效而被标记为不可删除\n    val replicasForTopicsToBeDeleted = allReplicasOnNewBrokers.filter(p => deleteTopicManager.isTopicQueuedUpForDeletion(p.topic))\n    if (replicasForTopicsToBeDeleted.nonEmpty) {\n        info(\"Some replicas %s for topics scheduled for deletion %s are on the newly restarted brokers %s. Signaling restart of topic deletion for these topics\"\n                .format(replicasForTopicsToBeDeleted.mkString(\",\"), deleteTopicManager.topicsToBeDeleted.mkString(\",\"), newBrokers.mkString(\",\")))\n        deleteTopicManager.resumeDeletionForTopics(replicasForTopicsToBeDeleted.map(_.topic))\n    }\n}\n```\n\n对于已经下线的 broker 节点会触发 Kafka Controller 关闭到这些节点的网络连接，并将分配给故障节点的副本置为 OfflineReplica 状态。如果某些分区的 leader 副本正好位于故障 broker 节点上，则需要将这些分区置为 OfflinePartition 状态，并通知到集群中所有可用的 broker 节点。相关实现位于 `KafkaController#onBrokerFailure` 方法中：\n\n```scala\ndef onBrokerFailure(deadBrokers: Seq[Int]) {\n    info(\"Broker failure callback for %s\".format(deadBrokers.mkString(\",\")))\n    // 移除正在关闭的 broker 节点\n    val deadBrokersThatWereShuttingDown = deadBrokers.filter(id => controllerContext.shuttingDownBrokerIds.remove(id))\n    info(\"Removed %s from list of shutting down brokers.\".format(deadBrokersThatWereShuttingDown))\n    val deadBrokersSet = deadBrokers.toSet\n    // 1. 如果分区 leader 副本在故障 broker 节点上，将分区状态设置为 OfflinePartition\n    val partitionsWithoutLeader = controllerContext.partitionLeadershipInfo.filter(partitionAndLeader =>\n        deadBrokersSet.contains(partitionAndLeader._2.leaderAndIsr.leader) &&\n                !deleteTopicManager.isTopicQueuedUpForDeletion(partitionAndLeader._1.topic)).keySet\n    partitionStateMachine.handleStateChanges(partitionsWithoutLeader, OfflinePartition)\n\n    // 2. 尝试将 OfflinePartition 状态的分区切换成 OnlinePartition 状态\n    partitionStateMachine.triggerOnlinePartitionStateChange()\n\n    // 3. 获取分配给故障 broker 节点的副本集合，将这些副本设置为 OfflineReplica 状态\n    val allReplicasOnDeadBrokers = controllerContext.replicasOnBrokers(deadBrokersSet)\n    val activeReplicasOnDeadBrokers = allReplicasOnDeadBrokers.filterNot(p => deleteTopicManager.isTopicQueuedUpForDeletion(p.topic))\n    replicaStateMachine.handleStateChanges(activeReplicasOnDeadBrokers, OfflineReplica)\n\n    // 4. 检查故障 broker 节点上是否有待删除的 topic 副本，如果存在则将其状态转换成 ReplicaDeletionIneligible 状态，并标记 topic 不可删除\n    val replicasForTopicsToBeDeleted = allReplicasOnDeadBrokers.filter(p => deleteTopicManager.isTopicQueuedUpForDeletion(p.topic))\n    if (replicasForTopicsToBeDeleted.nonEmpty) {\n        deleteTopicManager.failReplicaDeletion(replicasForTopicsToBeDeleted)\n    }\n\n    // 5. 向所有可用 broker 节点发送 UpdateMetadataRequest 请求，通知部分分区已经失效\n    if (partitionsWithoutLeader.isEmpty) {\n        this.sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)\n    }\n}\n```\n\n##### IsrChangeNotificationListener\n\nIsrChangeNotificationListener 实现了 IZkChildListener 接口，用于监听 `/isr_change_notification` 节点，当监听到某些分区的 ISR 集合发生变化时，会触发执行相应的回调：\n\n```scala\ndef doHandleChildChange(parentPath: String, currentChildren: Seq[String]): Unit = {\n    inLock(controller.controllerContext.controllerLock) {\n        debug(\"ISR change notification listener fired\")\n        try {\n            // 从 ZK 上读取 ISR 集合发生变更的 topic 分区集合\n            val topicAndPartitions = currentChildren.flatMap(getTopicAndPartition).toSet\n            if (topicAndPartitions.nonEmpty) {\n                // 从 ZK 读取指定分区的 leader 副本、ISR 集合等信息，更新 Controller 上下文\n                controller.updateLeaderAndIsrCache(topicAndPartitions)\n                // 向集群所有可用的 broker 节点发送 UpdateMetadataRequest 请求，更新对应 broker 节点缓存的集群元数据信息\n                processUpdateNotifications(topicAndPartitions)\n            }\n        } finally {\n            // 删除 /isr_change_notification/partitions 路径下已经处理的信息\n            currentChildren.map(x => controller.controllerContext.zkUtils.deletePath(ZkUtils.IsrChangeNotificationPath + \"/\" + x))\n        }\n    }\n}\n\nprivate def processUpdateNotifications(topicAndPartitions: immutable.Set[TopicAndPartition]) {\n    val liveBrokers: Seq[Int] = controller.controllerContext.liveOrShuttingDownBrokerIds.toSeq\n    debug(\"Sending MetadataRequest to Brokers:\" + liveBrokers + \" for TopicAndPartitions:\" + topicAndPartitions)\n    controller.sendUpdateMetadataRequest(liveBrokers, topicAndPartitions)\n}\n```\n\n相关逻辑如代码注释，比较简单。\n\n#### ZK 数据状态监听器\n\n##### LeaderChangeListener\n\nLeaderChangeListener 实现了 IZkDataListener 接口，用于监听 `/controller` 节点，当节点数据发生变更或被删除时，会触发执行相应的回调：\n\n```scala\ndef handleDataChange(dataPath: String, data: Object) {\n    val shouldResign = inLock(controllerContext.controllerLock) {\n        val amILeaderBeforeDataChange = amILeader\n        // 更新本地记录的新的 controller leader 的 ID\n        leaderId = KafkaController.parseControllerId(data.toString)\n        info(\"New leader is %d\".format(leaderId))\n        // 之前是 leader，但是现在切换成了 follower 角色\n        amILeaderBeforeDataChange && !amILeader\n    }\n    // 如果当前 broker 由 leader 变为 follower，则需要执行相应的清理工作\n    if (shouldResign) onResigningAsLeader()\n}\n\ndef handleDataDeleted(dataPath: String) {\n    val shouldResign = inLock(controllerContext.controllerLock) {\n        debug(\"%s leader change listener fired for path %s to handle data deleted: trying to elect as a leader\".format(brokerId, dataPath))\n        amILeader\n    }\n\n    // 如果 ZK 上记录的 leader 节点被删除，且当前节点之前是 leader，则需要执行相应的清理工作\n    if (shouldResign) onResigningAsLeader()\n\n    // 尝试竞选成为新的 leader\n    inLock(controllerContext.controllerLock) {\n        elect\n    }\n}\n```\n\n具体的回调逻辑如代码注释，其中 `ZookeeperLeaderElector#elect` 方法的实现将留到后面的小节中进行分析，另外回调方法 `ZookeeperLeaderElector#onResigningAsLeader` 实际上就是 `KafkaController#onControllerResignation` 方法，这个在前面已经分析过，不再重复撰述。\n\n##### PartitionModificationsListener\n\nPartitionModificationsListener 实现了 IZkDataListener 接口，用于监听 `/brokers/topics/{topic_name}` 节点，当某个 topic 的分区发生变化时（即增加分区，因为分区数目只增不减），会触发执行相应的回调：\n\n```scala\ndef doHandleDataChange(dataPath: String, data: AnyRef) {\n    inLock(controllerContext.controllerLock) {\n        try {\n            info(s\"Partition modification triggered $data for path $dataPath\")\n            // 从 ZK 获取 topic 的分区和副本信息\n            val partitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(List(topic))\n            // 筛选新增的分区和副本信息\n            val partitionsToBeAdded = partitionReplicaAssignment\n                    .filter(p => !controllerContext.partitionReplicaAssignment.contains(p._1))\n            // 如果 topic 待删除\n            if (controller.deleteTopicManager.isTopicQueuedUpForDeletion(topic))\n                error(\"Skipping adding partitions %s for topic %s since it is currently being deleted\".format(partitionsToBeAdded.map(_._1.partition).mkString(\",\"), topic))\n            else {\n                // 对于正常运行的 topic 的新增分区，更新分区的 AR 集合\n                if (partitionsToBeAdded.nonEmpty) {\n                    info(\"New partitions to be added %s\".format(partitionsToBeAdded))\n                    // 将新增的分区信息添加到 controller 上下文中\n                    controllerContext.partitionReplicaAssignment ++= partitionsToBeAdded\n                    // 切换新增分区及其副本的状态，使其上线对外提供服务\n                    controller.onNewPartitionCreation(partitionsToBeAdded.keySet)\n                }\n            }\n        } catch {\n            case e: Throwable => error(\"Error while handling add partitions for data path \" + dataPath, e)\n        }\n    }\n}\n```\n\n上述回调方法针对正常运行的 topic，如果有新增分区则会切换这些新增分区和副本的状态，使这些分区和副本能够上线对外提供服务。其中 `KafkaController#onNewTopicCreation` 方法已在前面分析过，这里不再重复撰述。\n\n##### PreferredReplicaElectionListener\n\nPreferredReplicaElectionListener 实现了 IZkDataListener 接口，用于监听 `/admin/preferred_replica_election` 节点，为指定的 topic 分区选举优先副本作为 leader 副本，以保证集群中 leader 副本的均衡分布。相关回调方法实现如下（省略了日志打点）：\n\n```scala\ndef doHandleDataChange(dataPath: String, data: AnyRef) {\n    inLock(controllerContext.controllerLock) {\n        // 获取需要进行优先副本选举的 topic 分区集合\n        val partitionsForPreferredReplicaElection = PreferredReplicaLeaderElectionCommand.parsePreferredReplicaElectionData(data.toString)\n        // 过滤已经处于优先副本选举的分区\n        val partitions = partitionsForPreferredReplicaElection -- controllerContext.partitionsUndergoingPreferredReplicaElection\n        // 过滤掉待删除的 topic 分区\n        val partitionsForTopicsToBeDeleted = partitions.filter(p => controller.deleteTopicManager.isTopicQueuedUpForDeletion(p.topic))\n        // 对剩余的分区执行优先副本选举\n        controller.onPreferredReplicaElection(partitions -- partitionsForTopicsToBeDeleted)\n    }\n}\n```\n\n当管理员手动指定某些 topic 分区需要执行优先副本选举时，相应的信息会被写入到 `/admin/preferred_replica_election` 节点下，然后触发执行上述回调方法。对于这些指定需要执行优先副本选举，且对应 topic 正常运行的分区，最终会调用 `KafkaController#onPreferredReplicaElection` 方法基于 PreferredReplicaPartitionLeaderSelector 分区 leader 副本选择器选举 leader 副本。方法实现如下：\n\n```scala\ndef onPreferredReplicaElection(partitions: Set[TopicAndPartition], isTriggeredByAutoRebalance: Boolean = false) {\n    info(\"Starting preferred replica leader election for partitions %s\".format(partitions.mkString(\",\")))\n    try {\n        // 将分区添加到参与优先副本选举的分区集合中\n        controllerContext.partitionsUndergoingPreferredReplicaElection ++= partitions\n        // 设置对应的 topic 为不可删除\n        deleteTopicManager.markTopicIneligibleForDeletion(partitions.map(_.topic))\n        // 设置分区为 OnlinePartition 状态，并使用优先副本选择器重选 leader 副本，同时更新 ZK 和发送 LeaderAndIsrRequest 和 UpdateMetadataRequest 请求\n        partitionStateMachine.handleStateChanges(partitions, OnlinePartition, preferredReplicaPartitionLeaderSelector)\n    } catch {\n        case e: Throwable => error(\"Error completing preferred replica leader election for partitions %s\".format(partitions.mkString(\",\")), e)\n    } finally {\n        // 清理 ZK 和上下文中记录的相关数据\n        this.removePartitionsFromPreferredReplicaElection(partitions, isTriggeredByAutoRebalance)\n        // 将 topic 恢复为可删除，并唤醒 DeleteTopicsThread 线程\n        deleteTopicManager.resumeDeletionForTopics(partitions.map(_.topic))\n    }\n}\n```\n\n关于 PreferredReplicaPartitionLeaderSelector 的实现，在前面已经分析过，这里不再重复撰述。\n\n##### PartitionsReassignedListener\n\nPartitionsReassignedListener 实现了 IZkDataListener 接口，用于监听 `/admin/reassign_partitions` 节点，当管理员指定需要为某些 topic 重新分配副本时，相关信息会写入到该节点下，并触发执行相应的回调：\n\n```scala\ndef doHandleDataChange(dataPath: String, data: AnyRef) {\n    debug(\"Partitions reassigned listener fired for path %s. Record partitions to be reassigned %s\".format(dataPath, data))\n    // 从 ZK 读取分区副本的再分配信息\n    val partitionsReassignmentData = ZkUtils.parsePartitionReassignmentData(data.toString)\n    // 过滤掉正在进行再分配的分区集合\n    val partitionsToBeReassigned = inLock(controllerContext.controllerLock) {\n        partitionsReassignmentData.filterNot(p => controllerContext.partitionsBeingReassigned.contains(p._1))\n    }\n    partitionsToBeReassigned.foreach { partitionToBeReassigned =>\n        inLock(controllerContext.controllerLock) {\n            // 检测 topic 是否为待删除的 topic，如果是的话则放弃对名下分区的再分配操作\n            if (controller.deleteTopicManager.isTopicQueuedUpForDeletion(partitionToBeReassigned._1.topic)) {\n                error(\"Skipping reassignment of partition %s for topic %s since it is currently being deleted\".format(partitionToBeReassigned._1, partitionToBeReassigned._1.topic))\n                controller.removePartitionFromReassignedPartitions(partitionToBeReassigned._1)\n            } else {\n                val context = ReassignedPartitionsContext(partitionToBeReassigned._2)\n                // 为副本再分配做一些前期准备工作\n                controller.initiateReassignReplicasForTopicPartition(partitionToBeReassigned._1, context)\n            }\n        }\n    }\n}\n```\n\n相关执行逻辑比较简单，如代码注释，其中 `KafkaController#initiateReassignReplicasForTopicPartition` 方法已经在前面分析过，不再重复撰述。\n\n##### ReassignedPartitionsIsrChangeListener\n\nReassignedPartitionsIsrChangeListener 实现了 IZkDataListener 接口，用于监听指定 topic 分区的状态变更（关注 ISR 集合的变更），相关回调实现如下（省略部分日志打点）：\n\n```scala\ndef doHandleDataChange(dataPath: String, data: AnyRef) {\n    inLock(controllerContext.controllerLock) {\n        debug(\"Reassigned partitions isr change listener fired for path %s with children %s\".format(dataPath, data))\n        val topicAndPartition = TopicAndPartition(topic, partition)\n        try {\n            controllerContext.partitionsBeingReassigned.get(topicAndPartition) match {\n                // 对应的 topic 分区正在执行副本再分配操作\n                case Some(reassignedPartitionContext) =>\n                    // 从 ZK 上获取对应 topic 分区的 leader 副本和 ISR 集合\n                    val newLeaderAndIsrOpt = zkUtils.getLeaderAndIsrForPartition(topic, partition)\n                    newLeaderAndIsrOpt match {\n                        case Some(leaderAndIsr) => // check if new replicas have joined ISR\n                            val caughtUpReplicas = reassignedReplicas & leaderAndIsr.isr.toSet\n                            // 如果 RAR 中的副本已经全部进入 ISR 集合中\n                            if (caughtUpReplicas == reassignedReplicas) {\n                                // 执行副本再分配的后续操作\n                                controller.onPartitionReassignment(topicAndPartition, reassignedPartitionContext)\n                            } else {\n                                // 啥也不干，等待下一次回调\n                            }\n                        case None => error(\"Error handling reassignment of partition %s to replicas %s as it was never created\".format(topicAndPartition, reassignedReplicas.mkString(\",\")))\n                    }\n                // 对应的 topic 分区已经完成副本再分配操作\n                case None =>\n            }\n        } catch {\n            case e: Throwable => error(\"Error while handling partition reassignment\", e)\n        }\n    }\n}\n```\n\n上述回调主要的逻辑就是判断对应 topic 分区重新分配的 RAR 集合中的副本是否都已经进入 ISR 集合，如果是的话则触发执行 `KafkaController#onPartitionReassignment` 方法的后续操作，否则什么也不做，继续等待下一次回调。建议将该监听器与前面第 7 小节结合起来看，能够更好的梳理整个副本再分配的执行流程。\n\n### 故障转移机制\n\n一个 Kafka 集群包含多个 broker 节点，每个 broker 节点上都会运行一个 Kafka Controller 实例，但是这些实例中只有一个是 leader 角色，其余均为 follower 角色，这些 follower 会在 leader 节点宕机时竞选成为新的 leader，以保证集群的可用性。\n\nKafka 定义了 ZookeeperLeaderElector 类来处理故障转移，用于在 leader 节点宕机时从 follower 节点中选举新的 leader。ZookeeperLeaderElector 的字段定义如下：\n\n```scala\nclass ZookeeperLeaderElector(controllerContext: ControllerContext, // Controller 上下文对象\n                             electionPath: String, // /controller\n                             onBecomingLeader: () => Unit, // KafkaController#onControllerFailover\n                             onResigningAsLeader: () => Unit, // KafkaController#onControllerResignation\n                             brokerId: Int, // broker 节点 ID\n                             time: Time // 时间戳工具类\n                            ) extends LeaderElector with Logging {\n\n    /** 当前 controller leader 的 ID */\n    var leaderId: Int = -1\n    /** 监听 ZK 的 /controller 节点的数据变化 */\n    val leaderChangeListener = new LeaderChangeListener\n\n    // ... 省略方法定义\n\n}\n```\n\nZookeeperLeaderElector 的 `ZookeeperLeaderElector#startup` 方法会在 Kafka Controller 启动时被调用，以启动故障转移机制。该方法会在 `/controller` 节点上注册 LeaderChangeListener 监听器，并尝试竞选成为新的 leader。方法实现如下：\n\n```scala\ndef startup {\n    inLock(controllerContext.controllerLock) {\n        // 注册 ZK 监听器，监听 /controller 节点下的数据变更\n        controllerContext.zkUtils.zkClient.subscribeDataChanges(electionPath, leaderChangeListener)\n        // 执行 leader 选举\n        elect\n    }\n}\n```\n\n方法 `ZookeeperLeaderElector#elect` 已在前面多次提及过，用于执行 leader 选举，该方法主要在以下 3 种场景下被触发：\n\n1. Kafka Controller 实例启动时。\n2. ZK 节点 `/controller` 下的数据被清除时。\n3. Broker 节点与 ZK 重新建立会话时。\n\n下面来看一下 `ZookeeperLeaderElector#elect` 方法的实现，该方法基于 ZK 的临时节点机制竞选 leader 角色，并返回当前节点是不是新的 leader 角色：\n\n```scala\ndef elect: Boolean = {\n    val timestamp = time.milliseconds.toString\n    val electString = Json.encode(Map(\"version\" -> 1, \"brokerid\" -> brokerId, \"timestamp\" -> timestamp))\n\n    // 获取 ZK 中记录的 controller leader 的 ID\n    leaderId = this.getControllerID\n    // 已经存在 controller leader，放弃选举\n    if (leaderId != -1) {\n        debug(\"Broker %d has been elected as leader, so stopping the election process.\".format(leaderId))\n        return amILeader\n    }\n\n    try {\n        // 尝试创建 ZK 临时节点，如果临时节点已经存在，则抛出异常\n        val zkCheckedEphemeral = new ZKCheckedEphemeral(electionPath,\n            electString,\n            controllerContext.zkUtils.zkConnection.getZookeeper,\n            JaasUtils.isZkSecurityEnabled)\n        zkCheckedEphemeral.create()\n        info(brokerId + \" successfully elected as leader\")\n        // 创建成功，更新 leader 节点 ID\n        leaderId = brokerId\n        // 回调\n        onBecomingLeader()\n    } catch {\n        // leader 已经存在\n        case _: ZkNodeExistsException =>\n            // If someone else has written the path, then\n            leaderId = getControllerID\n        case e2: Throwable =>\n            error(\"Error while electing or becoming leader on broker %d\".format(brokerId), e2)\n            // 重置 leaderId，并删除 /controller 节点\n            resign()\n    }\n    // 检测当前 broker 节点是否成为 leader\n    amILeader\n}\n```\n\n基于 ZK 的临时节点机制实施 leader 选举是一个比较典型且成熟的方案，在很多分布式系统中均有应用。ZK 临时节点的特性就在于当 broker 节点与 ZK 断开连接时，之前创建的临时节点会被删除，如果对应的临时节点已经存在，则其它节点再次尝试创建时会抛出 ZkNodeExistsException 异常。如果当前 broker 节点成功竞选成为新的 leader，则会回调 `ZookeeperLeaderElector#onBecomingLeader` 方法，对应 `KafkaController#onControllerFailover` 实现：\n\n```scala\ndef onControllerFailover() {\n    if (isRunning) {\n        info(\"Broker %d starting become controller state transition\".format(config.brokerId))\n        // 1. 从 ZK 读取历史 controller 年代信息，并更新 Controller 上下文\n        this.readControllerEpochFromZookeeper()\n        // 2. 递增 controller 年代信息，并更新到 ZK\n        this.incrementControllerEpoch(zkUtils.zkClient)\n\n        // 3. 注册 ZK 监听器\n\n        this.registerReassignedPartitionsListener() // 注册 PartitionsReassignedListener\n        this.registerIsrChangeNotificationListener() // 注册 IsrChangeNotificationListener\n        this.registerPreferredReplicaElectionListener() // 注册 PreferredReplicaElectionListener\n        partitionStateMachine.registerListeners() // 注册 TopicChangeListener 和 DeleteTopicsListener\n        replicaStateMachine.registerListeners() // 注册 BrokerChangeListener\n\n        // 4. 初始化 Controller 上下文信息\n        this.initializeControllerContext()\n\n        // 5. 向集群中所有可用的 broker 发送 UpdateMetadataRequest 请求，更新对应节点缓存的集群元数据\n        this.sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)\n\n        // 6. 启动副本状态机，并初始化各个副本的状态\n        replicaStateMachine.startup()\n\n        // 7. 启动分区状态机，并初始化各个分区的状态\n        partitionStateMachine.startup()\n\n        // 8. 为所有的 topic 注册 PartitionModificationsListener 监听器\n        controllerContext.allTopics.foreach(topic => partitionStateMachine.registerPartitionChangeListener(topic))\n        info(\"Broker %d is ready to serve as the new controller with epoch %d\".format(config.brokerId, epoch))\n\n        // 9. 处理副本需要再分配的分区\n        this.maybeTriggerPartitionReassignment()\n\n        // 10. 处理需要进行优先副本选举的分区\n        this.maybeTriggerPreferredReplicaElection()\n\n        // 11. 依据配置决定是否开启分区自动均衡的功能\n        if (config.autoLeaderRebalanceEnable) {\n            info(\"starting the partition rebalance scheduler\")\n            // 启用定时任务，周期性检测\n            autoRebalanceScheduler.startup()\n            autoRebalanceScheduler.schedule(\n                \"partition-rebalance-thread\",\n                checkAndTriggerPartitionRebalance,\n                5,\n                config.leaderImbalanceCheckIntervalSeconds.toLong,\n                TimeUnit.SECONDS)\n        }\n        // 12. 启动 TopicDeletionManager，用于对指定的 topic 执行删除操作\n        deleteTopicManager.start()\n    } else\n          info(\"Controller has been shut down, aborting startup/failover\")\n}\n```\n\n上述方法实现了一个 broker 节点竞选成为新的 leader 之后所需要执行的一些初始化操作，其中一些步骤已经在前面分析过了，例如状态机的启动和初始化过程、分区副本再分配机制等，下面重点来看一下步骤 4 和 11。\n\n#### 初始化上下文信息\n\n前面我们分析了管理 Kafka Controller 上下文的类 ControllerContext， __步骤 4__ 实现了当一个 broker 节点由 follower 角色切换成 leader 角色时对上下文执行初始化的操作。相关实现位于 `KafkaController#initializeControllerContext` 方法中：\n\n```scala\nprivate def initializeControllerContext() {\n    // 读取 /brokers/ids 节点，初始化可用的 broker 集合\n    controllerContext.liveBrokers = zkUtils.getAllBrokersInCluster.toSet\n    // 读取 /brokers/topics 节点，初始化集群中全部的 topic 集合\n    controllerContext.allTopics = zkUtils.getAllTopics.toSet\n    // 读取 /brokers/topics/{topic_name}/partitions 节点，初始化每个分区的 AR 集合\n    controllerContext.partitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(controllerContext.allTopics.toSeq)\n    controllerContext.partitionLeadershipInfo = new mutable.HashMap[TopicAndPartition, LeaderIsrAndControllerEpoch]\n    controllerContext.shuttingDownBrokerIds = mutable.Set.empty[Int]\n    // 读取 /brokers/topics/{topic_name}/partition/{partitionId}/stat 节点，初始化每个 topic 分区的 leader 副本和 ISR 集合等信息\n    this.updateLeaderAndIsrCache()\n    // 启动 ControllerChannelManager，用于建立到集群中所有 broker 节点的连接，并与之通信\n    this.startChannelManager()\n    // 读取 /admin/preferred_replica_election 节点，初始化需要执行优先副本选举的分区\n    this.initializePreferredReplicaElection()\n    // 读取 /admin/reassign_partitions 节点，初始化需要进行副本重新分配的分区\n    this.initializePartitionReassignment()\n    // 启动 TopicDeletionManager，用于管理待删除的 topic 和不可删除的 topic 集合\n    this.initializeTopicDeletion()\n}\n```\n\n#### 分区再平衡机制\n\n本小节介绍的分区再平衡机制与前面分析消费者和 GroupCoordinator 组件时提到的分区再分配机制不同，分区再分配的目的在于为一个 group 名下的消费者分配分区，而分区再平衡的目的在于将 topic 分区的 leader 副本尽量均匀分散在不同的 broker 节点上，以保证各个 broker 节点的负载均衡。\n\n__步骤 11__ 依据配置 `auto.leader.rebalance.enable` 决定是否启动 partition-rebalance-thread 定时任务，以对集群中的 topic 分区执行再平衡策略，从而保证各个 broker 节点的负载均衡。当一个 topic 被新建时，topic 名下的分区和分区对应的 leader 副本会尽可能均衡分散到集群中的 broker 节点上，但是随着服务的运行可能存在一些 boker 节点的失效，从而逐渐让各个 broker 节点上运行的分区 leader 副本数目失衡，造成某些 broker 节点负载较高，最终影响 Kafka 的性能。定时任务 partition-rebalance-thread 的作用在于主动发现负载较高的 broker 节点，并执行分区 leader 副本再平衡操作。\n\n相关逻辑位于 `KafkaController#checkAndTriggerPartitionRebalance` 方法中：\n\n```scala\nprivate def checkAndTriggerPartitionRebalance(): Unit = {\n    if (isActive) {\n        trace(\"checking need to trigger partition rebalance\")\n        // 获取所有可用的副本集合，key 是优先副本所在的 broker 节点 ID\n        var preferredReplicasForTopicsByBrokers: Map[Int, Map[TopicAndPartition, Seq[Int]]] = null\n        inLock(controllerContext.controllerLock) {\n            // 获取优先副本所在的 broker 节点 ID 与分区的对应关系\n            preferredReplicasForTopicsByBrokers =\n                    controllerContext.partitionReplicaAssignment\n                            // 过滤掉待删除的 topic\n                            .filterNot(p => deleteTopicManager.isTopicQueuedUpForDeletion(p._1.topic))\n                            // 按照第一个副本（优先副本） ID 进行分组\n                            .groupBy { case (_, assignedReplicas) => assignedReplicas.head }\n        }\n        debug(\"preferred replicas by broker \" + preferredReplicasForTopicsByBrokers)\n\n        // 计算每个 broker 节点的副本不均衡比率（imbalanceRatio）\n        preferredReplicasForTopicsByBrokers.foreach { case (leaderBroker, topicAndPartitionsForBroker) =>\n            var imbalanceRatio: Double = 0\n            // 计算存在 leader 副本，但不是以优先副本作为 leader 副本的分区副本集合\n            var topicsNotInPreferredReplica: Map[TopicAndPartition, Seq[Int]] = null\n            inLock(controllerContext.controllerLock) {\n                topicsNotInPreferredReplica = topicAndPartitionsForBroker.filter { case (topicPartition, _) =>\n                    controllerContext.partitionLeadershipInfo.contains(topicPartition) && // 存在 leader 副本\n                            controllerContext.partitionLeadershipInfo(topicPartition).leaderAndIsr.leader != leaderBroker // 且 leader 副本不是优先副本\n                }\n                debug(\"topics not in preferred replica \" + topicsNotInPreferredReplica)\n                val totalTopicPartitionsForBroker = topicAndPartitionsForBroker.size\n                val totalTopicPartitionsNotLedByBroker = topicsNotInPreferredReplica.size\n                // 计算当前 broker 节点的 imbalance 比率：（不是以优先副本作为 leader 副本的分区数 / 所在 broker 节点的总分区数）\n                imbalanceRatio = totalTopicPartitionsNotLedByBroker.toDouble / totalTopicPartitionsForBroker\n                trace(\"leader imbalance ratio for broker %d is %f\".format(leaderBroker, imbalanceRatio))\n            }\n\n            // 当 broker 节点上的不均衡比率大于阈值（对应 leader.imbalance.per.broker.percentage 配置）时，触发优先副本选举机制\n            if (imbalanceRatio > (config.leaderImbalancePerBrokerPercentage.toDouble / 100)) {\n                topicsNotInPreferredReplica.keys.foreach { topicPartition =>\n                    inLock(controllerContext.controllerLock) {\n                        // 对满足条件的 topic 分区，执行优先副本选举\n                        if (controllerContext.liveBrokerIds.contains(leaderBroker) && // 对应的 broker 节点是有效的\n                                controllerContext.partitionsBeingReassigned.isEmpty && // 没有分区正在执行副本再分配\n                                controllerContext.partitionsUndergoingPreferredReplicaElection.isEmpty && // 没有分区正在执行优先副本选举\n                                !deleteTopicManager.isTopicQueuedUpForDeletion(topicPartition.topic) && // 分区所属 topic 正常运行\n                                controllerContext.allTopics.contains(topicPartition.topic)) { // 分区所属 topic 是有效的\n                            // 执行优先副本选举\n                            onPreferredReplicaElection(Set(topicPartition), isTriggeredByAutoRebalance = true)\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```\n\n分区 leader 副本再平衡的执行流程可以概括如下：\n\n1. 获取所有分区及其副本集合，按照优先副本 ID 进行组织；\n2. 计算各个 broker 节点的不均衡比率；\n3. 当某个 broker 节点的不均衡比率超过阈值时，按条件执行优先副本选举。\n\n一个 broker 节点不均衡比率在计算上等于 __节点上不是以优先副本作为 leader 副本的分区数除以 broker 节点上运行的分区总数__ ，当不均衡比率超过 `leader.imbalance.per.broker.percentage` 配置时，如果对应 topic 分区同时满足以下条件则触发优先副本选举，保证 broker 节点的负载均衡：\n\n1. 对应的 broker 节点是有效的。\n2. 没有分区正在执行副本再分配。\n3. 没有分区正在执行优先副本选举。\n4. 分区所属 topic 是有效且正常运行的。\n\n### Controlled Shutdown 机制\n\n前面分析过 BrokerChangeListener 监听器，用于处理 boker 节点上下线的逻辑，这里的下线预示着对应的 broker 节点已经失效，而实际运维中还存在另外一种下线的场景，即由管理员主动触发下线（例如迁移机房、升级软件，修改 Kafka 配置等）。这一场景下对应的 broker 节点是正常运行的，如果我们需要下线这一类 broker 节点，Kafka 提供了更加温柔的方式，即 Controlled Shutdown 机制。相对于 broker 节点的宕机，Controlled Shutdown 关停 broker 节点的优势在于：\n\n1. 可以让日志数据全部落盘，避免重新上线后的日志恢复操作。\n2. 可以对 leader 副本位于待下线 broker 节点上的分区进行迁移，保证分区的可用性。\n\n当管理员希望对目标 broker 节点执行 Controlled Shutdown 操作时，可以使用命令行工具向 Kafka Controller 发送 ControlledShutdownRequest 请求，相应的处理逻辑位于 `KafkaController#shutdownBroker` 方法中，实现如下：\n\n```scala\ndef shutdownBroker(id: Int): Set[TopicAndPartition] = {\n    // 保证当前 Controller 是 leader 角色\n    if (!isActive) {\n        throw new ControllerMovedException(\"Controller moved to another broker. Aborting controlled shutdown\")\n    }\n\n    controllerContext.brokerShutdownLock synchronized {\n        info(\"Shutting down broker \" + id)\n        inLock(controllerContext.controllerLock) {\n            // 校验目标 broker 节点是否处于运行中，对于不存在或已经关闭的 broker 节点不需要执行关闭操作\n            if (!controllerContext.liveOrShuttingDownBrokerIds.contains(id)) throw new BrokerNotAvailableException(\"Broker id %d does not exist.\".format(id))\n            // 记录正在关闭的 broker 节点 ID\n            controllerContext.shuttingDownBrokerIds.add(id)\n        }\n\n        // 获取待关闭 broker 节点上所有的分区和副本信息\n        val allPartitionsAndReplicationFactorOnBroker: Set[(TopicAndPartition, Int)] =\n            inLock(controllerContext.controllerLock) {\n                controllerContext.partitionsOnBroker(id).map(topicAndPartition =>\n                    (topicAndPartition, controllerContext.partitionReplicaAssignment(topicAndPartition).size))\n            }\n\n        // 遍历处理待关闭 broker 节点上的分区和副本\n        allPartitionsAndReplicationFactorOnBroker.foreach {\n            case (topicAndPartition, replicationFactor) =>\n                // Move leadership serially to relinquish lock.\n                inLock(controllerContext.controllerLock) {\n                    controllerContext.partitionLeadershipInfo.get(topicAndPartition).foreach { currLeaderIsrAndControllerEpoch =>\n                        // 如果开启了副本机制\n                        if (replicationFactor > 1) {\n                            // 如果分区 leader 副本位于待关闭的 broker 节点上\n                            if (currLeaderIsrAndControllerEpoch.leaderAndIsr.leader == id) {\n                                // 使用 ControlledShutdownLeaderSelector 选择器重新为分区选择新的 leader 和 ISR 集合，\n                                // 并将结果写入 ZK，然后发送 LeaderAndIsrRequest 和 UpdateMetadataRequest 请求给集群中相应 broker 节点\n                                partitionStateMachine.handleStateChanges(\n                                    Set(topicAndPartition), OnlinePartition, controlledShutdownPartitionLeaderSelector)\n                            }\n                            // 如果分区 leader 副本不位于待关闭的 broker 节点上\n                            else {\n                                try {\n                                    // 发送 StopReplicaRequest 请求给待关闭的 broker 节点，关闭分区位于该节点上的副本（不删除副本）\n                                    brokerRequestBatch.newBatch()\n                                    brokerRequestBatch.addStopReplicaRequestForBrokers(\n                                        Seq(id), topicAndPartition.topic, topicAndPartition.partition, deletePartition = false)\n                                    brokerRequestBatch.sendRequestsToBrokers(epoch)\n                                } catch {\n                                    // ... 省略异常处理\n                                }\n                                // 将副本状态切换成 OfflineReplica，并尝试从 ISR 集合中移除，同时通知到集群中相应 broker 节点\n                                replicaStateMachine.handleStateChanges(\n                                    Set(PartitionAndReplica(topicAndPartition.topic, topicAndPartition.partition, id)), OfflineReplica)\n                            }\n                        }\n                    }\n                }\n        }\n\n        // 统计 leader 副本依然处于待关闭 broker 节点上的分区数目\n        def replicatedPartitionsBrokerLeads(): Iterable[TopicAndPartition] = inLock(controllerContext.controllerLock) {\n            trace(\"All leaders = \" + controllerContext.partitionLeadershipInfo.mkString(\",\"))\n            controllerContext.partitionLeadershipInfo.filter {\n                case (topicAndPartition, leaderIsrAndControllerEpoch) =>\n                    leaderIsrAndControllerEpoch.leaderAndIsr.leader == id &&\n                            controllerContext.partitionReplicaAssignment(topicAndPartition).size > 1\n            }.keys\n        }\n\n        replicatedPartitionsBrokerLeads().toSet\n    }\n}\n```\n\n对于位于待关停的 broker 节点上的分区，如果启用了副本机制则需要判断分区 leader 副本是否位于待关停的 broker 节点上，如果是的话则需要使用 ControlledShutdownLeaderSelector 分区 leader 副本选择器为当前分区重新分配新的 leader 副本和 ISR 集合，并将结果通知给集群中相应的 broker 节点；如果分区 leader 副本不位于待关停 broker 节点上则直接向该节点发送 StopReplicaRequest 请求，关闭节点上的副本即可，这里可能涉及到分区 ISR 集合的变更，需要将变更的结果通知给集群中相应的 broker 节点。\n\n### 总结\n\n本文介绍了 Kafka Controller 组件的功能与实现，在一个 Kafka 集群中运行着多个 broker 节点，这些节点在启动时彼此是相互独立的，但是依托于 Kafka Controller 组件可以协调这些 broker 节点的运行，以集群的身份统一对外提供服务。Kafka Controller 提供了对集群中所有分区和副本的状态管理、集群上下文信息管理、副本再分配、分区再平衡、Controlled Shutdown 机制、故障转移机制，以及与 ZK 交互等功能，可以看做是 Kafka 集群的中央控制器。\n","tags":["Kafka"],"categories":["kafka"]},{"title":"Kafka 源码解析：Group 协调管理机制","url":"/2019/06/25/kafka/kafka-group-coordinator/","content":"\n在 Kafka 的设计中，消费者一般都有一个 group 的概念（当然，也存在不属于任何 group 的消费者），将多个消费者组织成一个 group 可以提升消息的消费处理能力，同时又能保证消息消费的顺序性，不重复或遗漏消费。一个 group 名下的消费者包含一个 leader 角色和多个 follower 角色，虽然在消费消息方面这两类角色是等价的，但是 leader 角色相对于 follower 角色还担负着管理整个 group 的职责。当 group 中有新的消费者加入，或者某个消费者因为一些原因退出当前 group 时，亦或是订阅的 topic 分区发生变化时，都需要为 group 名下的消费者重新分配分区，在服务端确定好分区分配策略之后，具体执行分区分配的工作则交由 leader 消费者负责，并在完成分区分配之后将分配结果反馈给服务端。<!-- more -->\n\n前面在分析消费者运行机制时曾多次提到 GroupCoordinator 类，本篇我们就来分析一下 GroupCoordinator 组件的作用和实现。GroupCoordinator 组件主要功能包括对隶属于同一个 group 的消费者进行分区分配、维护内部 offset topic，以及管理消费者和消费者所属的 group 信息等。集群中的每一个 broker 节点在启动时都会创建并启动一个 GroupCoordinator 实例，每个实例都会管理集群中所有消费者 group 的一个子集。\n\n### GroupCoordinator 组件的定义与启动\n\nGroupCoordinator 类的字段定义如下：\n\n```scala\nclass GroupCoordinator(\n                       val brokerId: Int, // 所属的 broker 节点的 ID\n                       val groupConfig: GroupConfig, // Group 配置对象，记录了 group 中 session 过期的最小时长和最大时长，即超时时长的合法区间\n                       val offsetConfig: OffsetConfig, // 记录 OffsetMetadata 相关的配置项\n                       val groupManager: GroupMetadataManager, // 负责管理 group 元数据以及对应的 offset 信息\n                       val heartbeatPurgatory: DelayedOperationPurgatory[DelayedHeartbeat], // 管理 DelayedHeartbeat 延时任务的炼狱\n                       val joinPurgatory: DelayedOperationPurgatory[DelayedJoin], // 管理 DelayedJoin 延时任务的炼狱\n                       time: Time) extends Logging {\n\n    /** 标识当前 GroupCoordinator 实例是否启动 */\n    private val isActive = new AtomicBoolean(false)\n\n    // ... 省略方法定义\n\n}\n```\n\n其中 GroupMetadataManager 类主要用于管理消费者 group 的元数据信息和 offset 相关信息，字段定义如下：\n\n```scala\nclass GroupMetadataManager(val brokerId: Int, // 所属 broker 节点 ID\n                           val interBrokerProtocolVersion: ApiVersion, // kafka 版本信息\n                           val config: OffsetConfig, // 记录 OffsetMetadata 相关的配置项\n                           replicaManager: ReplicaManager, // 管理 broker 节点上 offset topic 的分区信息\n                           zkUtils: ZkUtils,\n                           time: Time) extends Logging with KafkaMetricsGroup {\n\n    /** 消息压缩类型 */\n    private val compressionType: CompressionType = CompressionType.forId(config.offsetsTopicCompressionCodec.codec)\n    /** 缓存每个 group 在服务端对应的 GroupMetadata 对象  */\n    private val groupMetadataCache = new Pool[String, GroupMetadata]\n    /** 正在加载的 offset topic 分区的 ID 集合 */\n    private val loadingPartitions: mutable.Set[Int] = mutable.Set()\n    /** 已经加载完成的 offset topic 分区的 ID 集合 */\n    private val ownedPartitions: mutable.Set[Int] = mutable.Set()\n    /** 标识 GroupCoordinator 正在关闭 */\n    private val shuttingDown = new AtomicBoolean(false)\n    /** 记录 offset topic 的分区数目 */\n    private val groupMetadataTopicPartitionCount = getOffsetsTopicPartitionCount\n    /** 用于调度 delete-expired-consumer-offsets 和 GroupCoordinator 迁移等任务 */\n    private val scheduler = new KafkaScheduler(threads = 1, threadNamePrefix = \"group-metadata-manager-\")\n\n    // ... 省略方法定义\n\n}\n```\n\nKafka 服务在启动时针对每一个 broker 节点都会创建一个 GroupCoordinator 实例，并调用 `GroupCoordinator#startup` 方法启动运行。GroupCoordinator 在启动时主要是调用了 `GroupMetadataManager#enableMetadataExpiration` 方法启动 delete-expired-group-metadata 定时任务：\n\n```scala\ndef startup(enableMetadataExpiration: Boolean = true) {\n    info(\"Starting up.\")\n    if (enableMetadataExpiration) groupManager.enableMetadataExpiration()\n    isActive.set(true)\n    info(\"Startup complete.\")\n}\n\ndef enableMetadataExpiration() {\n    // 启动定时任务调度器\n    scheduler.startup()\n\n    // 启动 delete-expired-group-metadata 定时任务\n    scheduler.schedule(name = \"delete-expired-group-metadata\",\n        fun = cleanupGroupMetadata,\n        period = config.offsetsRetentionCheckIntervalMs,\n        unit = TimeUnit.MILLISECONDS)\n}\n```\n\n定时任务 delete-expired-group-metadata 的主要作用在于从 group 的元数据信息中移除那些已经过期的 topic 分区对应的 offset 元数据，并将这些元数据以消息的形式记录到 offset topic 中，具体执行流程如下：\n\n1. 依据当前时间戳计算并获取已经过期的 topic 分区对应的 offset 元数据信息；\n2. 将状态为 Empty 且名下记录的所有 offset 元数据都已经过期的 group 切换成 Dead 状态；\n3. 如果 group 已经失效，则从 GroupCoordinator 本地移除对应的元数据信息，并与步骤 1 中获取到的 offset 元数据信息一起封装成消息记录到 offset topic 中。\n\n具体逻辑由 `GroupMetadataManager#cleanupGroupMetadata` 方法实现，如下：\n\n```scala\nprivate[coordinator] def cleanupGroupMetadata(): Unit = {\n    this.cleanupGroupMetadata(None)\n}\n\ndef cleanupGroupMetadata(deletedTopicPartitions: Option[Seq[TopicPartition]]) {\n    val startMs = time.milliseconds()\n    var offsetsRemoved = 0\n\n    // 遍历处理每个 group 对应的元数据信息\n    groupMetadataCache.foreach { case (groupId, group) =>\n        val (removedOffsets, groupIsDead, generation) = group synchronized {\n            // 计算待移除的 topic 分区对应的 offset 元数据信息\n            val removedOffsets = deletedTopicPartitions match {\n                // 从 group 元数据信息中移除指定的 topic 分区集合\n                case Some(topicPartitions) => group.removeOffsets(topicPartitions)\n                // 移除那些 offset 元数据已经过期的，且没有 offset 待提交的 topic 分区集合\n                case None => group.removeExpiredOffsets(startMs)\n            }\n\n            // 如果 group 当前状态为 Empty，且名下 topic 分区所有的 offset 已经过期，则将该 group 状态切换成 Dead\n            if (group.is(Empty) && !group.hasOffsets) {\n                info(s\"Group $groupId transitioned to Dead in generation ${group.generationId}\")\n                group.transitionTo(Dead)\n            }\n            (removedOffsets, group.is(Dead), group.generationId)\n        }\n\n        // 获取 group 对应在 offset topic 中的分区编号\n        val offsetsPartition = partitionFor(groupId)\n        val appendPartition = new TopicPartition(Topic.GroupMetadataTopicName, offsetsPartition)\n        getMagic(offsetsPartition) match {\n            // 对应 group 由当前 GroupCoordinator 进行管理\n            case Some(magicValue) =>\n                val timestampType = TimestampType.CREATE_TIME\n                val timestamp = time.milliseconds()\n                // 获取当前 group 在 offset topic 中的分区对象\n                val partitionOpt = replicaManager.getPartition(appendPartition)\n                partitionOpt.foreach { partition =>\n                    // 遍历处理每个待移除的 topic 分区对应的 offset 元数据信息，封装成消息数据\n                    val tombstones = removedOffsets.map { case (topicPartition, offsetAndMetadata) =>\n                        trace(s\"Removing expired/deleted offset and metadata for $groupId, $topicPartition: $offsetAndMetadata\")\n                        val commitKey = GroupMetadataManager.offsetCommitKey(groupId, topicPartition)\n                        Record.create(magicValue, timestampType, timestamp, commitKey, null)\n                    }.toBuffer\n                    trace(s\"Marked ${removedOffsets.size} offsets in $appendPartition for deletion.\")\n\n                    // 如果当前 group 已经失效，则从本地移除对应的元数据信息，并将 group 信息封装成消息，\n                    // 如果 generation 为 0 则表示当前 group 仅仅使用 kafka 存储 offset 信息\n                    if (groupIsDead && groupMetadataCache.remove(groupId, group) && generation > 0) {\n                        tombstones += Record.create(magicValue, timestampType, timestamp, GroupMetadataManager.groupMetadataKey(group.groupId), null)\n                        trace(s\"Group $groupId removed from the metadata cache and marked for deletion in $appendPartition.\")\n                    }\n\n                    if (tombstones.nonEmpty) {\n                        try {\n                            // 往 offset topic 中追加消息，不需要 ack，如果失败则周期性任务稍后会重试\n                            partition.appendRecordsToLeader(MemoryRecords.withRecords(timestampType, compressionType, tombstones: _*))\n                            offsetsRemoved += removedOffsets.size\n                            trace(s\"Successfully appended ${tombstones.size} tombstones to $appendPartition for expired/deleted offsets and/or metadata for group $groupId\")\n                        } catch {\n                            case t: Throwable =>\n                                error(s\"Failed to append ${tombstones.size} tombstones to $appendPartition for expired/deleted offsets and/or metadata for group $groupId.\", t)\n                        }\n                    }\n                }\n\n            case None =>\n                info(s\"BrokerId $brokerId is no longer a coordinator for the group $groupId. Proceeding cleanup for other alive groups\")\n        }\n    }\n\n    info(s\"Removed $offsetsRemoved expired offsets in ${time.milliseconds() - startMs} milliseconds.\")\n}\n```\n\n### Group 状态定义与转换\n\nGroupState 特质定义了 group 的状态，并由 GroupCoordinator 进行维护。围绕 GroupState 特质，Kafka 实现了 5 个样例对象，分别用于描述 group 的 5 种状态：\n\n1. __PreparingRebalance__ ：表示 group 正在准备执行分区再分配操作。\n2. __AwaitingSync__ ：表示 group 正在等待 leader 消费者的分区分配结果，新版本已更名为 CompletingRebalance。\n3. __Stable__ ：表示 group 处于正常运行状态。\n4. __Dead__ ：表示 group 名下已经没有消费者，且对应的元数据已经（或正在）被删除。\n5. __Empty__ ：表示 group 名下已经没有消费者，并且正在等待记录的所有 offset 元数据过期。\n\nGroup 状态之间的转换以及转换原因如下图和表所示：\n\n![image](/images/2019/kafka-group-state.png)\n\n当前状态 | 目标状态 | 转换原因\n--- | --- | ---\nPreparingRebalance | AwaitingSync | group 之前名下所有的消费者都已经申请加入，或者等待消费者申请加入超时。\nPreparingRebalance | Empty | group 名下的所有消费者都已经离开。\nPreparingRebalance | Dead | group 对应的元数据信息被移除。\nAwaitingSync | Stable | group 收到来自 leader 消费者的分区分配结果。\nAwaitingSync | PreparingRebalance | 1. 有消费者申请加入或退出； 2. 名下消费者更新了元数据信息； 3. 名下消费者心跳超时。\nAwaitingSync | Dead | group 对应的元数据信息被移除。\nStable | PreparingRebalance | 1. 有消费者申请加入或退出； 2. 名下消费者心跳超时。\nStable | Dead | group 对应的元数据信息被移除。\nEmpty | PreparingRebalance | 有消费者申请加入。\nEmpty | Dead | 1. group 名下所有的 offset 元数据信息已经过期； 2. group 对应的元数据信息被移除。\nDead | 无 |\n\n### 故障转移机制\n\n在 Kafka 0.8.2.2 版本中引入了使用 offset topic 存储消费 offset 位置数据，以解决之前版本中采用 ZK 存储所面临的性能压力和不稳定性，并由 GroupCoordinator 组件负责维护。Offset topic 与 Kafka 中的普通 topic 除了用途上的区别之外，在性质上没有任何区别，Kafka 默认为 offset topic 设置了 50 个分区，每个分区分配 3 个副本。当某个 broker 节点宕机时，如果该节点上正好运行着 offset topic 某个分区的 leader 副本，考虑服务可用性需要选举一个位于其它可用 broker 节点上的满足条件的 follower 副本作为新的 leader 副本，同时由位于该 broker 节点上的 GroupCoordinator 实例继续维护对应的 offset topic 分区。因为涉及到 GroupCoordinator 实例的变更，所以需要在新的 GroupCoordinator 实例接管维护这些 offset topic 分区时，需要在这些 GroupCoordinator 实例上恢复对应 group 的元数据信息（一个 offset topic 分区中记录了一批 group 的元数据和 offset 消费数据）。\n\n之前的文章在分析 Kafka 的分区副本机制时曾介绍了对 LeaderAndIsrRequest 请求的处理，ReplicaManager 定义了 `ReplicaManager#becomeLeaderOrFollower` 方法用于对指定 topic 分区的副本执行角色切换。该方法接收一个 `(Iterable[Partition], Iterable[Partition]) => Unit` 类型的回调函数，用于分别处理完成 leader 角色和 follower 角色切换的分区对象集合，回调函数的具体定义位于 `KafkaApis#handleLeaderAndIsrRequest` 方法中，实现如下：\n\n```scala\n// 完成 GroupCoordinator 的迁移操作\ndef onLeadershipChange(updatedLeaders: Iterable[Partition], updatedFollowers: Iterable[Partition]) {\n    updatedLeaders.foreach { partition =>\n        // 仅处理 offset topic，当 broker 节点维护 offset topic 分区的 leader 副本时回调执行\n        if (partition.topic == Topic.GroupMetadataTopicName) coordinator.handleGroupImmigration(partition.partitionId)\n    }\n    updatedFollowers.foreach { partition =>\n        // 仅处理 offset topic，当 broker 节点维护 offset topic 分区的 follower 副本时回调执行\n        if (partition.topic == Topic.GroupMetadataTopicName) coordinator.handleGroupEmigration(partition.partitionId)\n    }\n}\n```\n\n由上述实现可以看到该回调函数仅处理 offset topic 对应的分区，当 GroupCoordinator 实例开始维护 offset topic 某个分区的 leader 副本时会触发执行 `GroupCoordinator#handleGroupImmigration` 方法，而当 GroupCoordinator 实例开始维护 offset topic 某个分区的 follower 副本时会触发执行 `GroupCoordinator#handleGroupEmigration` 方法，下面分别对这两个方法的实现进行分析。\n\n方法 `GroupCoordinator#handleGroupImmigration` 的实现如下：\n\n```scala\ndef handleGroupImmigration(offsetTopicPartitionId: Int) {\n    groupManager.loadGroupsForPartition(offsetTopicPartitionId, onGroupLoaded)\n}\n\nprivate def onGroupLoaded(group: GroupMetadata) {\n    group synchronized {\n        info(s\"Loading group metadata for ${group.groupId} with generation ${group.generationId}\")\n        assert(group.is(Stable) || group.is(Empty))\n        // 遍历更新当前 group 名下所有消费者的心跳信息\n        group.allMemberMetadata.foreach(completeAndScheduleNextHeartbeatExpiration(group, _))\n    }\n}\n```\n\n关于 `GroupCoordinator#completeAndScheduleNextHeartbeatExpiration` 方法的执行逻辑我们将在下一小节进行分析，这里我们主要来看一下 `GroupMetadataManager#loadGroupsForPartition` 方法的实现，该方法会基于 offset topic 更新对应 group 的元数据，并初始化每个 topic 分区对应的 offset 信息：\n\n```scala\ndef loadGroupsForPartition(offsetsPartition: Int, onGroupLoaded: GroupMetadata => Unit) {\n    // 构建 offset topic 对应的 topic 分区对象\n    val topicPartition = new TopicPartition(Topic.GroupMetadataTopicName, offsetsPartition)\n\n    def doLoadGroupsAndOffsets() {\n        info(s\"Loading offsets and group metadata from $topicPartition\")\n\n        inLock(partitionLock) {\n            // 检测当前 offset topic 分区是否正在加载，如果已经处于加载中则返回\n            if (loadingPartitions.contains(offsetsPartition)) {\n                info(s\"Offset load from $topicPartition already in progress.\")\n                return\n            } else {\n                loadingPartitions.add(offsetsPartition)\n            }\n        }\n\n        try {\n            // 基于 offset topic 加载更新对应 group 的元数据信息，初始化每个 topic 分区对应的 offset 信息\n            this.loadGroupsAndOffsets(topicPartition, onGroupLoaded)\n        } catch {\n            case t: Throwable => error(s\"Error loading offsets from $topicPartition\", t)\n        } finally {\n            inLock(partitionLock) {\n                ownedPartitions.add(offsetsPartition)\n                loadingPartitions.remove(offsetsPartition)\n            }\n        }\n    }\n\n    // 异步调度执行\n    scheduler.schedule(topicPartition.toString, doLoadGroupsAndOffsets)\n}\n```\n\n具体加载更新的过程采用异步调度的策略执行，实现位于 `GroupMetadataManager#loadGroupsAndOffsets` 方法中，该方法会读取对应 topic 分区下的所有消息数据，并依据消息的类型分别处理：\n\n```scala\nprivate[coordinator] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit) {\n    // 获取指定 topic 分区的 HW 值\n    def highWaterMark: Long = replicaManager.getHighWatermark(topicPartition).getOrElse(-1L)\n\n    val startMs = time.milliseconds()\n    // 获取并处理 topic 分区对应的 Log 对象\n    replicaManager.getLog(topicPartition) match {\n        case None =>\n            // 不存在\n            warn(s\"Attempted to load offsets and group metadata from $topicPartition, but found no log\")\n        case Some(log) =>\n            var currOffset = log.logStartOffset\n            val buffer = ByteBuffer.allocate(config.loadBufferSize)\n\n            // 记录 topic 分区与对应的 offset 信息映射关系\n            val loadedOffsets = mutable.Map[GroupTopicPartition, OffsetAndMetadata]()\n            val removedOffsets = mutable.Set[GroupTopicPartition]()\n\n            // 记录 group 与对应的 group 元数据信息映射关系\n            val loadedGroups = mutable.Map[String, GroupMetadata]()\n            val removedGroups = mutable.Set[String]()\n\n            // 从 Log 对象中第一个 LogSegment 开始读取日志数据，直到 HW 位置为止，\n            // 加载 offset 信息和 group 元数据信息\n            while (currOffset < highWaterMark && !shuttingDown.get()) {\n                buffer.clear()\n                // 读取日志数据到内存\n                val fileRecords = log\n                        .read(currOffset, config.loadBufferSize, maxOffset = None, minOneMessage = true)\n                        .records.asInstanceOf[FileRecords]\n                val bufferRead = fileRecords.readInto(buffer, 0)\n\n                // 遍历处理消息集合（深层迭代）\n                MemoryRecords.readableRecords(bufferRead).deepEntries.asScala.foreach { entry =>\n                    val record = entry.record\n                    require(record.hasKey, \"Group metadata/offset entry key should not be null\")\n\n                    // 依据消息的 key 决定当前消息的类型\n                    GroupMetadataManager.readMessageKey(record.key) match {\n                        // 如果是记录 offset 的消息\n                        case offsetKey: OffsetKey =>\n                            val key = offsetKey.key\n                            if (record.hasNullValue) {\n                                // 删除标记，则移除对应的 offset 信息\n                                loadedOffsets.remove(key)\n                                removedOffsets.add(key)\n                            } else {\n                                // 非删除标记，解析并更新 key 对应 offset 信息\n                                val value = GroupMetadataManager.readOffsetMessageValue(record.value)\n                                loadedOffsets.put(key, value)\n                                removedOffsets.remove(key)\n                            }\n                        // 如果是记录 group 元数据的消息\n                        case groupMetadataKey: GroupMetadataKey =>\n                            val groupId = groupMetadataKey.key\n                            val groupMetadata = GroupMetadataManager.readGroupMessageValue(groupId, record.value)\n                            if (groupMetadata != null) {\n                                // 非删除标记，记录加载的 group 元数据信息\n                                trace(s\"Loaded group metadata for group $groupId with generation ${groupMetadata.generationId}\")\n                                removedGroups.remove(groupId)\n                                loadedGroups.put(groupId, groupMetadata)\n                            } else {\n                                // 删除标记\n                                loadedGroups.remove(groupId)\n                                removedGroups.add(groupId)\n                            }\n                        // 未知的消息 key 类型\n                        case unknownKey =>\n                            throw new IllegalStateException(s\"Unexpected message key $unknownKey while loading offsets and group metadata\")\n                    }\n\n                    currOffset = entry.nextOffset\n                }\n            }\n\n            // 将在 offset topic 中存在 offset 信息的 topic 分区以是否在 offset topic 中包含 group 元数据信息进行区分\n            val (groupOffsets, emptyGroupOffsets) = loadedOffsets\n                    .groupBy(_._1.group)\n                    .mapValues(_.map { case (groupTopicPartition, offset) => (groupTopicPartition.topicPartition, offset) })\n                    .partition { case (group, _) => loadedGroups.contains(group) }\n\n            // 遍历处理在 offset topic 中存在 group 元数据信息的 group\n            loadedGroups.values.foreach { group =>\n                val offsets = groupOffsets.getOrElse(group.groupId, Map.empty[TopicPartition, OffsetAndMetadata])\n                // 更新 group 对应的元数据信息，主要是更新名下每个 topic 分区对应的 offset 信息\n                loadGroup(group, offsets)\n                onGroupLoaded(group)\n            }\n\n            // 遍历处理在 offset topic 中不存在 group 元数据信息的 group，但是存在 offset 信息，新建一个\n            emptyGroupOffsets.foreach { case (groupId, offsets) =>\n                val group = new GroupMetadata(groupId)\n                // 更新 group 对应的元数据信息，主要是更新名下每个 topic 分区对应的 offset 信息\n                loadGroup(group, offsets)\n                onGroupLoaded(group)\n            }\n\n            // 检测需要删除的 group 元数据信息，如果对应 group 在本地有记录且在 offset topic 中存在 offset 信息，\n            // 则不应该删除，此类 group 一般仅依赖 kafka 存储 offset 信息，而不存储对应的 group 元数据信息\n            removedGroups.foreach { groupId =>\n                if (groupMetadataCache.contains(groupId) && !emptyGroupOffsets.contains(groupId))\n                    throw new IllegalStateException(s\"Unexpected unload of active group $groupId while loading partition $topicPartition\")\n            }\n\n    }\n}\n```\n\nOffset topic 中主要记录了 group 的元数据和对应的 offset 的消费位置信息，上述方法会分别解析这两类数据并据此来恢复 GroupCoordinator 本地记录的对应 group 的元数据信息。如果 offset topic 中包含对应 group 的元数据信息则恢复时会直接复用，否则会创建一个空的 GroupMetadata 对象（这类 group 一般仅使用 Kafka 存储 offset 位置数据），并应用 `GroupMetadataManager#loadGroup` 方法更新 group 名下每个 topic 分区的 offset 值，同时将 group 元数据记录到 GroupCoordinator 本地缓存中：\n\n```scala\nprivate def loadGroup(group: GroupMetadata, offsets: Map[TopicPartition, OffsetAndMetadata]): Unit = {\n    // 遍历处理每个 topic 分区的 offset 信息，兼容更新老版本的过期时间\n    val loadedOffsets = offsets.mapValues { offsetAndMetadata =>\n        // 对应老版本的 offset 元数据，设置过期时间戳为 commit 时间加上系统默认的保留时间（默认为 24 小时）\n        if (offsetAndMetadata.expireTimestamp == OffsetCommitRequest.DEFAULT_TIMESTAMP)\n            offsetAndMetadata.copy(expireTimestamp = offsetAndMetadata.commitTimestamp + config.offsetsRetentionMs)\n        else\n            offsetAndMetadata\n    }\n    trace(s\"Initialized offsets $loadedOffsets for group ${group.groupId}\")\n    // 更新 group 名下每个 topic 分区的 offset 信息\n    group.initializeOffsets(loadedOffsets)\n\n    // 更新 group 对应的元数据信息\n    val currentGroup = this.addGroup(group)\n    if (group != currentGroup)\n        debug(s\"Attempt to load group ${group.groupId} from log with generation ${group.generationId} failed because there is already a cached group with generation ${currentGroup.generationId}\")\n}\n```\n\n下面继续来看 GroupCoordinator 实例开始维护 offset topic 某个分区的 follower 副本的执行逻辑，实现位于 `GroupCoordinator#handleGroupEmigration` 方法中：\n\n```scala\ndef handleGroupEmigration(offsetTopicPartitionId: Int) {\n    groupManager.removeGroupsForPartition(offsetTopicPartitionId, onGroupUnloaded)\n}\n\nprivate def onGroupUnloaded(group: GroupMetadata) {\n    group synchronized {\n        info(s\"Unloading group metadata for ${group.groupId} with generation ${group.generationId}\")\n        val previousState = group.currentState\n        // 将当前 group 切换成 Dead 状态\n        group.transitionTo(Dead)\n\n        // 依据前置状态分别处理\n        previousState match {\n            case Empty | Dead =>\n            case PreparingRebalance =>\n                // 遍历响应所有消费者的 JoinGroupRequest 请求，返回 NOT_COORDINATOR_FOR_GROUP 错误码\n                for (member <- group.allMemberMetadata) {\n                    if (member.awaitingJoinCallback != null) {\n                        member.awaitingJoinCallback(joinError(member.memberId, Errors.NOT_COORDINATOR_FOR_GROUP.code))\n                        member.awaitingJoinCallback = null\n                    }\n                }\n                // 尝试执行 DelayedJoin 延时任务\n                joinPurgatory.checkAndComplete(GroupKey(group.groupId))\n            case Stable | AwaitingSync =>\n                // 遍历响应所有消费者的 JoinGroupRequest 请求，返回 NOT_COORDINATOR_FOR_GROUP 错误码\n                for (member <- group.allMemberMetadata) {\n                    if (member.awaitingSyncCallback != null) {\n                        member.awaitingSyncCallback(Array.empty[Byte], Errors.NOT_COORDINATOR_FOR_GROUP.code)\n                        member.awaitingSyncCallback = null\n                    }\n                    // 尝试执行 DelayHeartbeat 延时任务\n                    heartbeatPurgatory.checkAndComplete(MemberKey(member.groupId, member.memberId))\n                }\n        }\n    }\n}\n```\n\n当 GroupCoordinator 不再管理相应的 group 时，会将本地记录的 group 状态切换成 Dead，同时针对来自该 group 名下消费者的 JoinGroupRequest 请求均会响应 `NOT_COORDINATOR_FOR_GROUP` 错误。此外，还会从本地移除之前管理的 offset topic 分区对象，以及对应的 group 元数据信息，实现如下：\n\n```scala\ndef removeGroupsForPartition(offsetsPartition: Int, onGroupUnloaded: GroupMetadata => Unit) {\n    // 构建 offset topic 对应的 topic 分区对象\n    val topicPartition = new TopicPartition(Topic.GroupMetadataTopicName, offsetsPartition)\n\n    // 异步调度执行\n    scheduler.schedule(topicPartition.toString, removeGroupsAndOffsets)\n\n    def removeGroupsAndOffsets() {\n        var numOffsetsRemoved = 0\n        var numGroupsRemoved = 0\n\n        inLock(partitionLock) {\n            // 从已经加载完成的 offset topic 分区集合中移除指定的分区，表示当前 GroupCoordinator 实例不再管理对应的 group\n            ownedPartitions.remove(offsetsPartition)\n\n            // 遍历移除本地缓存的 group 对应的元数据信息\n            for (group <- groupMetadataCache.values) {\n                if (partitionFor(group.groupId) == offsetsPartition) {\n                    onGroupUnloaded(group)\n                    groupMetadataCache.remove(group.groupId, group)\n                    numGroupsRemoved += 1\n                    numOffsetsRemoved += group.numOffsets\n                }\n            }\n        }\n\n    }\n}\n```\n\n### 心跳报活机制\n\n消费者依赖于心跳机制向 GroupCoordinator 报活，向对应的 GroupCoordinator 实例发送 HeartbeatRequest 请求，GroupCoordinator 实例同样依赖于消费者的心跳来判断消费者的上下线。KafkaApis 定义了 `KafkaApis#handleHeartbeatRequest` 方法处理 HeartbeatRequest 请求，具体的处理逻辑则委托给 `GroupCoordinator#handleHeartbeat` 方法执行，该方法首先会校验目标 GroupCoordinator 实例是合法且能够处理当前请求，然后依据目标 group 的状态对本次心跳请求进行处理。只有当目标 group 处于 PreparingRebalance 或 Stable 状态时，且当前消费者确实属于该 group 才能够正常响应请求，对于处于其它状态的 group 而言只是简单返回对应的错误码。\n\n正常响应 HeartbeatRequest 请求的逻辑位于 `GroupCoordinator#completeAndScheduleNextHeartbeatExpiration` 方法中，实现如下：\n\n```scala\nprivate def completeAndScheduleNextHeartbeatExpiration(group: GroupMetadata, member: MemberMetadata) {\n    // 更新对应消费者的心跳时间\n    member.latestHeartbeat = time.milliseconds()\n    // 获取 DelayedHeartbeat 延时任务关注的消费者\n    val memberKey = MemberKey(member.groupId, member.memberId)\n    // 尝试完成之前添加的 DelayedHeartbeat 延时任务\n    heartbeatPurgatory.checkAndComplete(memberKey)\n\n    // 计算下一次的心跳超时时间\n    val newHeartbeatDeadline = member.latestHeartbeat + member.sessionTimeoutMs\n    // 创建新的 DelayedHeartbeat 延时任务，并添加到炼狱中进行管理\n    val delayedHeartbeat = new DelayedHeartbeat(this, group, member, newHeartbeatDeadline, member.sessionTimeoutMs)\n    heartbeatPurgatory.tryCompleteElseWatch(delayedHeartbeat, Seq(memberKey))\n}\n```\n\n对于 HeartbeatRequest 请求的正常响应会更新当前消费者的最近一次心跳时间，并尝试完成关注该消费者的 DelayedHeartbeat 延时任务，同时创建新的 DelayedHeartbeat 延时任务，延迟时间为下次心跳超时时间。在整个 GroupCoordinator 实现中有多个地方调用了上述方法，这也意味着心跳机制不单单依赖于 HeartbeatRequest 请求，实际上只要是消费者发往 GroupCoordinator 的请求都可以携带心跳信息，例如 JoinGroupRequest、SyncGroupRequest，以及 OffsetCommitRequest 等等。\n\n下面来看一下延时任务 DelayedHeartbeat 的实现，重点看一下 `DelayedHeartbeat#tryComplete` 方法和 `DelayedHeartbeat#onExpiration` 方法，这两个方法分别调用了 `GroupCoordinator#tryCompleteHeartbeat` 和 `GroupCoordinator#onExpireHeartbeat` 方法，而 `DelayedHeartbeat#onComplete` 方法则是一个空实现，也就是说延时任务 DelayedHeartbeat 的真正执行逻辑就是从炼狱中删除该延时任务，这也符合心跳机制的目的，正常的心跳无需多做处理，只有在消费者的心跳超时时才需要处理相关异常的情况。\n\n方法 `GroupCoordinator#tryCompleteHeartbeat` 会检测当前消费者的状态，如果满足以下 3 个条件之一则强制执行 DelayedHeartbeat 延时任务，表示对应消费者心跳正常：\n\n1. 消费者正在等待 JoinGroupResponse 或 SyncGroupResponse 响应。\n2. 消费者最近一次心跳时间距离延时任务到期时间在消费者会话超时时间范围内。\n3. 消费者已经离开之前所属的 group。\n\n方法 `GroupCoordinator#onExpireHeartbeat` 会检测当前消费者是否已经离线，如果是则依据所属 group 的当前状态执行：\n\n1. 如果目标 group 已经失效（Dead/Empty），则什么也不做；\n2. 如果目标 group 处于正常运行状态（Stable），或者正在等待 leader 消费者的分区分配结果（AwaitingSync），则因当前消费者的下线可能导致之前的分区分配结果已经失效，所以需要重新分配分区；\n3. 如果目标 group 处于准备执行分区再分配状态（PreparingRebalance），则无需请求再次重新分配分区，但是因为当前消费者的下线，可能让关注目标 group 的 DelayedJoin 延时任务满足执行条件，所以尝试执行。\n\n具体逻辑实现位于 `GroupCoordinator#onMemberFailure` 方法中，实现如下：\n\n```scala\nprivate def onMemberFailure(group: GroupMetadata, member: MemberMetadata) {\n    trace(\"Member %s in group %s has failed\".format(member.memberId, group.groupId))\n    // 将对应的消费者从 GroupMetadata 中删除\n    group.remove(member.memberId)\n    group.currentState match {\n        // 对应 group 已经失效，什么也不做\n        case Dead | Empty =>\n        // 之前的分区分配结果可能已经失效，切换 GroupMetadata 状态为 PreparingRebalance，准备再次重新分配分区\n        case Stable | AwaitingSync => this.maybePrepareRebalance(group)\n        // 某个消费者下线，可能满足关注该 group 的 DelayedJoin 的执行条件，尝试执行\n        case PreparingRebalance => joinPurgatory.checkAndComplete(GroupKey(group.groupId))\n    }\n}\n```\n\n其中 `GroupCoordinator#maybePrepareRebalance` 方法的执行逻辑将在下一小节介绍分区再分配机制时进行分析。\n\n### 分区再分配机制\n\n前面在分析消费者运行机制时，我们曾站在消费者的视角分析了分区再分配机制的执行过程，本小节我们继续从服务端的视角介绍集群对分区再分配操作过程中涉及到的来自消费者的请求的处理细节，主要包括 GroupCoordinatorRequest、JoinGroupResult 和 SyncGroupRequest 这 3 个请求。\n\n![image](/images/2019/kafka-group-rebalance.png)\n\n上述时序图描绘了分区再分配期间客户端与服务端的交互过程。\n\n#### GroupCoordinatorRequest 请求处理\n\n当消费者与 GroupCoordinator 进行交互之前，需要先发送 GroupCoordinatorRequest 请求到负载较小的 broker 节点，以获取管理当前 group 的 GroupCoordinator 实例所在的 broker 节点的位置信息。KafkaApis 提供了 `KafkaApis#handleGroupCoordinatorRequest` 方法用于处理 GroupCoordinatorRequest 请求，方法实现如下：\n\n```scala\ndef handleGroupCoordinatorRequest(request: RequestChannel.Request) {\n    val groupCoordinatorRequest = request.body.asInstanceOf[GroupCoordinatorRequest]\n\n    // 权限验证\n    if (!authorize(request.session, Describe, new Resource(Group, groupCoordinatorRequest.groupId))) {\n        val responseBody = new GroupCoordinatorResponse(Errors.GROUP_AUTHORIZATION_FAILED.code, Node.noNode)\n        requestChannel.sendResponse(new RequestChannel.Response(request, responseBody))\n    } else {\n        // 获取 group 对应的 offset topic 的分区 ID\n        val partition = coordinator.partitionFor(groupCoordinatorRequest.groupId)\n        // 从 MetadataCache 中获取 offset topic 的相关信息，如果未创建则进行创建\n        val offsetsTopicMetadata = this.getOrCreateGroupMetadataTopic(request.listenerName)\n\n        val responseBody = if (offsetsTopicMetadata.error != Errors.NONE) {\n            // 创建 offset topic 信息失败\n            new GroupCoordinatorResponse(Errors.GROUP_COORDINATOR_NOT_AVAILABLE.code, Node.noNode)\n        } else {\n            // 获取当前 group 对应 offset topic 分区 leader 副本所在的节点\n            val coordinatorEndpoint = offsetsTopicMetadata.partitionMetadata().asScala\n                    .find(_.partition == partition)\n                    .map(_.leader())\n\n            // 创建 GroupCoordinatorResponse 对象，将 leader 副本所在节点信息返回给客户端\n            coordinatorEndpoint match {\n                case Some(endpoint) if !endpoint.isEmpty => new GroupCoordinatorResponse(Errors.NONE.code, endpoint)\n                case _ => new GroupCoordinatorResponse(Errors.GROUP_COORDINATOR_NOT_AVAILABLE.code, Node.noNode)\n            }\n        }\n\n        trace(\"Sending consumer metadata %s for correlation id %d to client %s.\".format(responseBody, request.header.correlationId, request.header.clientId))\n        // 将响应对象加入到 channel 中，等待发送\n        requestChannel.sendResponse(new RequestChannel.Response(request, responseBody))\n    }\n}\n```\n\nKafka 会依据请求的 group 的 ID 查找对应 offset topic 分区 leader 副本所在的 broker 节点，并将节点信息封装成 GroupCoordinatorResponse 响应发送给消费者。接下来消费者会向对应的 broker 节点建立连接并发送 JoinGroupRequest 请求申请加入对应的 group。\n\n#### JoinGroupRequest 请求处理\n\n针对来自消费者申请加入指定 group 的 JoinGroupRequest 请求，GroupCoordinator 实例会为 group 中的消费者确定最终的分区分配策略，并选举新的 group leader 消费者。KafkaApis 定义了 `KafkaApis#handleJoinGroupRequest` 方法处理 JoinGroupRequest 请求，不过该方法只是简单解析了请求对象，并执行权限校验，以及定义了回调函数用于向客户端发送 JoinGroupResponse 响应，具体处理请求的过程则交由 `GroupCoordinator#handleJoinGroup` 方法实现：\n\n```scala\ndef handleJoinGroup(groupId: String,\n                    memberId: String,\n                    clientId: String,\n                    clientHost: String,\n                    rebalanceTimeoutMs: Int,\n                    sessionTimeoutMs: Int,\n                    protocolType: String,\n                    protocols: List[(String, Array[Byte])],\n                    responseCallback: JoinCallback) {\n    if (!isActive.get) {\n        // GroupCoordinator 实例未启动\n        responseCallback(joinError(memberId, Errors.GROUP_COORDINATOR_NOT_AVAILABLE.code))\n    } else if (!validGroupId(groupId)) {\n        // groupId 不合法\n        responseCallback(joinError(memberId, Errors.INVALID_GROUP_ID.code))\n    } else if (!isCoordinatorForGroup(groupId)) {\n        // 当前 GroupCoordinator 实例并不负责管理当前 group\n        responseCallback(joinError(memberId, Errors.NOT_COORDINATOR_FOR_GROUP.code))\n    } else if (isCoordinatorLoadingInProgress(groupId)) {\n        // 当前 GroupCoordinator 实例正在加载该 group 对应的 offset topic 分区信息\n        responseCallback(joinError(memberId, Errors.GROUP_LOAD_IN_PROGRESS.code))\n    } else if (sessionTimeoutMs < groupConfig.groupMinSessionTimeoutMs || sessionTimeoutMs > groupConfig.groupMaxSessionTimeoutMs) {\n        // 会话时长超时，保证消费者是活跃的\n        responseCallback(joinError(memberId, Errors.INVALID_SESSION_TIMEOUT.code))\n    } else {\n        // 获取并处理 group 对应的元数据信息\n        groupManager.getGroup(groupId) match {\n            // 对应的 group 不存在\n            case None =>\n                if (memberId != JoinGroupRequest.UNKNOWN_MEMBER_ID) {\n                    // 指定了消费者 ID，但是对应的 group 不存在，则拒绝请求\n                    responseCallback(joinError(memberId, Errors.UNKNOWN_MEMBER_ID.code))\n                } else {\n                    // group 不存在，且消费者 ID 未知的情况下，创建 GroupMetadata 对象，并将消费者加入到对应的 group，同时执行分区再均衡操作\n                    val group = groupManager.addGroup(new GroupMetadata(groupId))\n                    this.doJoinGroup(group, memberId, clientId, clientHost, rebalanceTimeoutMs, sessionTimeoutMs, protocolType, protocols, responseCallback)\n                }\n            // 对应的 group 存在，将消费者加入到对应的 group，并执行分区再均衡操作\n            case Some(group) =>\n                this.doJoinGroup(group, memberId, clientId, clientHost, rebalanceTimeoutMs, sessionTimeoutMs, protocolType, protocols, responseCallback)\n        }\n    }\n}\n```\n\nGroupCoordinator 实例在具体处理 JoinGroupRequest 请求之前，首先会执行一系列的校验操作以保证发送请求的消费者和目标 group 都是合法的，且对应的 GroupCoordinator 能够正常处理当前请求。如果目标 group 不存在，则在未指定对应的消费者 ID 时会首先新建 group，然后将当前消费者添加到对应 group 中开始执行分区再分配操作。方法 `GroupCoordinator#doJoinGroup` 会校验消费者 ID （如果指定的话）能否被当前 group 识别，以及消费者指定的分区分配策略能否被当前 group 支持，如果这些条件都不能满足，则没有必要再继续为该消费者分配分区，方法实现如下：\n\n```scala\nprivate def doJoinGroup(group: GroupMetadata,\n                        memberId: String,\n                        clientId: String,\n                        clientHost: String,\n                        rebalanceTimeoutMs: Int,\n                        sessionTimeoutMs: Int,\n                        protocolType: String,\n                        protocols: List[(String, Array[Byte])],\n                        responseCallback: JoinCallback) {\n\n    group synchronized {\n        if (!group.is(Empty)\n                // 消费者指定的分区分配策略，对应的 group 不支持\n                && (group.protocolType != Some(protocolType) || !group.supportsProtocols(protocols.map(_._1).toSet))) {\n            responseCallback(joinError(memberId, Errors.INCONSISTENT_GROUP_PROTOCOL.code))\n        } else if (memberId != JoinGroupRequest.UNKNOWN_MEMBER_ID && !group.has(memberId)) {\n            // 消费者 ID 不能够被识别\n            responseCallback(joinError(memberId, Errors.UNKNOWN_MEMBER_ID.code))\n        } else {\n            // 依据 group 的当前状态分别进行处理\n            group.currentState match {\n                // 目标 group 已经失效\n                case Dead =>\n                    // 对应的 group 的元数据信息已经被删除，说明已经迁移到其它 GroupCoordinator 实例或者不再可用，直接返回错误码\n                    responseCallback(joinError(memberId, Errors.UNKNOWN_MEMBER_ID.code))\n                // 目标 group 正在执行分区再均衡操作\n                case PreparingRebalance =>\n                    if (memberId == JoinGroupRequest.UNKNOWN_MEMBER_ID) {\n                        // 对于未知 ID 的消费者申请加入，创建对应的元数据信息，并分配 ID，同时切换 group 的状态为 PreparingRebalance，准备执行分区再分配\n                        this.addMemberAndRebalance(rebalanceTimeoutMs, sessionTimeoutMs, clientId, clientHost, protocolType, protocols, group, responseCallback)\n                    } else {\n                        // 对于已知 ID 的消费者重新申请加入，更新对应的元数据信息，同时切换 group 的状态为 PreparingRebalance，准备执行分区再分配\n                        val member = group.get(memberId)\n                        this.updateMemberAndRebalance(group, member, protocols, responseCallback)\n                    }\n                // 目标 group 正在等待 leader 消费者的分区分配结果\n                case AwaitingSync =>\n                    if (memberId == JoinGroupRequest.UNKNOWN_MEMBER_ID) {\n                        // 对于未知 ID 的消费者申请加入，创建对应的元数据信息，并分配 ID，同时切换 group 的状态为 PreparingRebalance，准备执行分区再分配\n                        this.addMemberAndRebalance(rebalanceTimeoutMs, sessionTimeoutMs, clientId, clientHost, protocolType, protocols, group, responseCallback)\n                    } else {\n                        // 对于已知 ID 的消费者重新申请加入\n                        val member = group.get(memberId)\n                        if (member.matches(protocols)) {\n                            // 分区分配策略未发生变化，返回 GroupMetadata 的信息\n                            responseCallback(JoinGroupResult(\n                                members = if (memberId == group.leaderId) {\n                                    group.currentMemberMetadata\n                                } else {\n                                    Map.empty\n                                },\n                                memberId = memberId,\n                                generationId = group.generationId,\n                                subProtocol = group.protocol,\n                                leaderId = group.leaderId,\n                                errorCode = Errors.NONE.code))\n                        } else {\n                            // 分区分配策略发生变化，更新对应的元数据信息，同时切换 group 的状态为 PreparingRebalance，准备执行分区再分配\n                            this.updateMemberAndRebalance(group, member, protocols, responseCallback)\n                        }\n                    }\n                // 目标 group 运行正常，或者正在等待 offset 过期\n                case Empty | Stable =>\n                    if (memberId == JoinGroupRequest.UNKNOWN_MEMBER_ID) {\n                        // 对于未知 ID 的消费者申请加入，创建对应的元数据信息，并分配 ID，同时切换 group 的状态为 PreparingRebalance，准备执行分区再分配\n                        this.addMemberAndRebalance(rebalanceTimeoutMs, sessionTimeoutMs, clientId, clientHost, protocolType, protocols, group, responseCallback)\n                    } else {\n                        // 对于已知 ID 的消费者重新申请加入\n                        val member = group.get(memberId)\n                        if (memberId == group.leaderId || !member.matches(protocols)) {\n                            // 当前消费者是 group leader 或支持的分区分配策略发生变化，更新对应的元数据信息，同时切换 group 的状态为 PreparingRebalance，准备执行分区再分配\n                            this.updateMemberAndRebalance(group, member, protocols, responseCallback)\n                        } else {\n                            // 分区分配策略未发生变化，返回 GroupMetadata 信息\n                            responseCallback(JoinGroupResult(\n                                members = Map.empty,\n                                memberId = memberId,\n                                generationId = group.generationId,\n                                subProtocol = group.protocol,\n                                leaderId = group.leaderId,\n                                errorCode = Errors.NONE.code))\n                        }\n                    }\n            }\n\n            // 如果当前 group 正在准备执行分区再分配，尝试执行 DelayedJoin 延时任务\n            if (group.is(PreparingRebalance)) joinPurgatory.checkAndComplete(GroupKey(group.groupId))\n        }\n    }\n}\n```\n\n对于满足条件的消费者来说，需要依据 group 的当前运行状态分而治之。如果当前 group 的状态为 Dead，则说明对应的 group 不再可用，或者已经由其它 GroupCoordinator 实例管理，直接响应 `UNKNOWN_MEMBER_ID` 错误，消费者可以再次请求获取新接管的 GroupCoordinator 实例所在的位置信息。\n\n如果当前 group 的状态为 PreparingRebalance，则说明对应的 group 正在准备执行分区再分配操作，此时：\n\n- 对于新加入的消费者（未指定 ID），首先需要为其创建消费者 ID 和元数据信息，并交由目标 group 进行管理，然后开始执行分区再分配操作。\n- 对于已存在的消费者（已指定 ID），首先需要更新消费者最终的分区分配策略和回调响应函数，然后开始执行分区再分配操作。\n\n如果当前 group 的状态为 AwaitingSync，则说明对应的 group 正在等待 leader 消费者的分区分配结果，此时：\n\n- 对于新加入的消费者（未指定 ID），首先需要为其创建消费者 ID 和元数据信息，并交由目标 group 进行管理，然后开始执行分区再分配操作。\n- 对于已存在的消费者（已指定 ID），如果分区分配策略未发生变化则无需再重复分配，如果分区分配策略发生变化则需要先更新消费者最终的分区分配策略和回调响应函数，然后开始执行分区再分配操作。\n\n如果当前 group 的状态为 Empty 或 Stable，则说明对应的 group 目前处于一个正常运行的状态，此时：\n\n- 对于新加入的消费者（未指定 ID），首先需要为其创建消费者 ID 和元数据信息，并交由目标 group 进行管理，然后开始执行分区再分配操作。\n- 对于已存在的消费者（已指定 ID），如果不是 leader，或者分区分配策略未发生变化，则无需再重复分配，否则需要先更新消费者最终的分区分配策略和回调响应函数，然后开始执行分区再分配操作。\n\n上述过程中多次调用了 `GroupCoordinator#addMemberAndRebalance` 方法为消费者创建元数据信息并分配 ID，并将对应的消费者元数据信息记录到 group 元数据信息中。方法 `GroupMetadata#add` 定义了 __如果当前 group 名下还未选举 leader 消费者，则以第一个加入到当前 group 的消费者作为 leader 角色__ ，然后调用 `GroupCoordinator#updateMemberAndRebalance` 方法更新消费者的分区分配策略和响应回调函数。这两个方法分别实现如下：\n\n```scala\nprivate def addMemberAndRebalance(rebalanceTimeoutMs: Int,\n                                  sessionTimeoutMs: Int,\n                                  clientId: String,\n                                  clientHost: String,\n                                  protocolType: String,\n                                  protocols: List[(String, Array[Byte])],\n                                  group: GroupMetadata,\n                                  callback: JoinCallback): MemberMetadata = {\n    // 基于 UUID 生成消费者的 ID\n    val memberId = clientId + \"-\" + group.generateMemberIdSuffix\n    // 创建新的 MemberMetadata 元数据信息对象\n    val member = new MemberMetadata(memberId, group.groupId, clientId, clientHost, rebalanceTimeoutMs, sessionTimeoutMs, protocolType, protocols)\n    // 设置回调函数，即 KafkaApis#sendResponseCallback 方法，用于向客户端发送 JoinGroupResponse 响应\n    member.awaitingJoinCallback = callback\n    // 添加到 GroupMetadata 中，第一个加入 group 的消费者成为 leader 角色\n    group.add(member)\n    // 尝试切换 group 的状态为 PreparingRebalance\n    this.maybePrepareRebalance(group)\n    member\n}\n\nprivate def updateMemberAndRebalance(group: GroupMetadata,\n                                     member: MemberMetadata,\n                                     protocols: List[(String, Array[Byte])],\n                                     callback: JoinCallback) {\n    // 更新 MemberMetadata 支持的协议\n    member.supportedProtocols = protocols\n    // 更新 MemberMetadata 的响应回调函数\n    member.awaitingJoinCallback = callback\n    // 尝试执行状态切换\n    this.maybePrepareRebalance(group)\n}\n```\n\n由上述实现可以看到这两个方法最终都调用了 `GroupCoordinator#maybePrepareRebalance` 方法，该方法会校验 group 的当前状态，如果是 Stable、AwaitingSync，以及 Empty 中的一种，则会调用 `GroupCoordinator#prepareRebalance` 方法切换 group 的状态为 PreparingRebalance，并创建相应的 DelayedJoin 延时任务，等待 group 名下所有的消费者发送 JoinGroupRequest 请求申请加入到当前 group 中。\n\n```scala\nprivate def prepareRebalance(group: GroupMetadata) {\n    // 如果处于 AwaitingSync 状态，说明在等待 leader 消费者的分区分配结果，\n    // 此时对于来自 follower 的 SyncGroupRequest 请求，直接响应 REBALANCE_IN_PROGRESS 错误\n    if (group.is(AwaitingSync)) resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)\n\n    // 将 group 状态切换成 PreparingRebalance 状态，准备执行分区再分配操作\n    group.transitionTo(PreparingRebalance)\n    info(\"Preparing to restabilize group %s with old generation %s\".format(group.groupId, group.generationId))\n\n    // 分区再均衡超时时长是所有消费者设置的超时时长的最大值\n    val rebalanceTimeout = group.rebalanceTimeoutMs\n    // 创建 DelayedJoin 延时任务，用于等待消费者申请加入当前 group\n    val delayedRebalance = new DelayedJoin(this, group, rebalanceTimeout)\n    val groupKey = GroupKey(group.groupId) // 关注当前 group\n    // 将延时任务添加到炼狱中进行管理\n    joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))\n}\n```\n\n上述方法首先会校验 group 当前状态是不是 AwaitingSync，如果是则说明当前 GroupCoordinator 实例正在等待 leader 消费者的分区分配的结果，此时如果有来自 follower 消费者的 SyncGroupRequest 请求，则直接响应 `REBALANCE_IN_PROGRESS` 错误，同时需要清空 group 名下所有消费者记录的分区分配信息。然后切换 group 的状态为 PreparingRebalance，表示开始准备执行分区再分配，并创建 DelayedJoin 延时任务等待 group 名下所有消费者发送 JoinGroupRequest 请求申请加入当前 group。\n\n下面来看一下延时任务 DelayedJoin 的实现，这里的延时时长等于 group 名下所有消费者设置的超时时长的最大值。我们重点看一下 `DelayedJoin#tryComplete` 和 `DelayedJoin#onComplete` 方法，这两个方法分别调用了 `GroupCoordinator#tryCompleteJoin` 和 `GroupCoordinator#onCompleteJoin` 方法。其中 `GroupCoordinator#tryCompleteJoin` 方法基于消费者元数据信息 `MemberMetadata#awaitingJoinCallback` 字段判断 group 名下已知的消费者是否都已经发送了 JoinGroupRequest 请求，如果是则强制完成 DelayedJoin 延时任务，方法实现如下：\n\n```scala\ndef tryCompleteJoin(group: GroupMetadata, forceComplete: () => Boolean): Boolean = {\n    group synchronized {\n        // 判断所有已知的消费者是否是否都已经申请加入，\n        // 基于 awaitingJoinCallback 回调函数，只有发送了 JoinGroupRequest 请求的消费者才会设置该回调\n        if (group.notYetRejoinedMembers.isEmpty) forceComplete() else false\n    }\n}\n\ndef notYetRejoinedMembers: List[MemberMetadata] = members.values.filter(_.awaitingJoinCallback == null).toList\n```\n\n消费者元数据信息的 `MemberMetadata#awaitingJoinCallback` 字段实际上就是在 `KafkaApis#handleJoinGroupRequest` 方法中定义的 sendResponseCallback 回调函数，用于向客户端发送 JoinGroupResponse 响应。所以这里我们可以依据该字段判断对应消费者是否发送了 JoinGroupRequest 请求，因为只有发送了该请求才会为 `MemberMetadata#awaitingJoinCallback` 字段赋值。\n\n当延时任务 DelayedJoin 被执行时会触发调用 `GroupCoordinator#onCompleteJoin` 方法，实现如下：\n\n```scala\ndef onCompleteJoin(group: GroupMetadata) {\n    var delayedStore: Option[DelayedStore] = None\n    group synchronized {\n        // 移除那些已知的但是未申请重新加入当前 group 的消费者\n        group.notYetRejoinedMembers.foreach { failedMember => group.remove(failedMember.memberId) }\n\n        if (!group.is(Dead)) {\n            // 递增 group 的年代信息，并选择 group 最终使用的分区分配策略，如果 group 名下存在消费者则切换状态为 AwaitingSync，否则切换成 Empty\n            group.initNextGeneration()\n            if (group.is(Empty)) {\n                info(s\"Group ${group.groupId} with generation ${group.generationId} is now empty\")\n                // 如果 group 名下已经没有消费者，将空的分区分配信息记录到 offset topic\n                delayedStore = groupManager.prepareStoreGroup(group, Map.empty, error => {\n                    if (error != Errors.NONE) {\n                        warn(s\"Failed to write empty metadata for group ${group.groupId}: ${error.message}\")\n                    }\n                })\n            } else {\n                info(s\"Stabilized group ${group.groupId} generation ${group.generationId}\")\n                // 向 group 名下所有的消费者发送 JoinGroupResponse 响应，\n                for (member <- group.allMemberMetadata) {\n                    assert(member.awaitingJoinCallback != null)\n                    val joinResult = JoinGroupResult(\n                        members = if (member.memberId == group.leaderId) {\n                            group.currentMemberMetadata\n                        } else {\n                            Map.empty\n                        },\n                        memberId = member.memberId,\n                        generationId = group.generationId,\n                        subProtocol = group.protocol,\n                        leaderId = group.leaderId,\n                        errorCode = Errors.NONE.code)\n\n                    // 该回调函数在 KafkaApis#handleJoinGroupRequest 中定义（对应 sendResponseCallback 方法），用于将响应对象放入 channel 中等待发送\n                    member.awaitingJoinCallback(joinResult)\n                    member.awaitingJoinCallback = null\n                    // 心跳机制\n                    this.completeAndScheduleNextHeartbeatExpiration(group, member)\n                }\n            }\n        }\n    }\n    // 往 offset topic 中追加消息\n    delayedStore.foreach(groupManager.store)\n}\n```\n\nDelayedJoin 延时任务在等待期间主要是等待关注的 group 名下的消费者发送 JoinGroupRequest 请求的情况，一旦任务满足执行条件（也可能是因为超时）则执行：\n\n1. 剔除那些已知的但是未申请重新加入当前 group 的消费者；\n2. 如果目标 group 状态已经为 Dead，则结束任务；\n3. 否则，递增 group 的年代信息，并为 group 名下的消费者确定最终的分区分配策略，同时依据名下是否存在消费者来将 group 状态切换成 AwaitingSync 或 Empty；\n4. 如果切换后的 group 状态为 Empty，则将空的分区分配结果追加到 topic offset 中；\n5. 如果切换后的 group 状态为 AwaitingSync，则向 group 名下所有的消费者发送 JoinGroupResponse 响应，并等待 leader 消费者的 SyncGroupRequest 请求反馈分区的分配结果。\n\n其中 __步骤 3__ 的实现位于 `GroupMetadata#initNextGeneration` 方法中，该方法会依据 group 名下是否存在消费者将 group 切换成相应的状态，如果名下存在消费者还会确定最终的分区分配策略。方法实现如下：\n\n```scala\ndef initNextGeneration(): Unit = {\n    assert(notYetRejoinedMembers == List.empty[MemberMetadata])\n    if (members.nonEmpty) {\n        generationId += 1\n        // 基于投票的方式选择一个所有消费者都支持的分区分配策略\n        protocol = selectProtocol\n        transitionTo(AwaitingSync)\n    } else {\n        generationId += 1\n        protocol = null\n        transitionTo(Empty)\n    }\n}\n```\n\n确定最终的分区分配策略， __简单来说就是从消费者都支持的分区分配策略中投票选举一个得票最高的策略作为最终策略__ ，实现如下：\n\n```scala\ndef selectProtocol: String = {\n    if (members.isEmpty)\n        throw new IllegalStateException(\"Cannot select protocol for empty group\")\n\n    // 计算所有消费者都支持的分区分配策略\n    val candidates = candidateProtocols\n\n    // 选择所有消费者都支持的协议作为候选协议集合，\n    // 每个消费者都会通过 vote 方法进行投票（为支持的协议中的第一个协议投一票），\n    // 最终选择投票最多的分区分配策略\n    val votes: List[(String, Int)] = allMemberMetadata\n            .map(_.vote(candidates))\n            .groupBy(identity)\n            .mapValues(_.size)\n            .toList\n\n    votes.maxBy(_._2)._1\n}\n```\n\n其中 `MemberMetadata#vote` 方法的投票策略实际上就是从消费者自身支持的分区分配策略和 group 名下所有消费者都支持的分区分配策略中选择第 1 个进行投票。\n\n__步骤 4__ 的实现位于 `GroupMetadataManager#prepareStoreGroup` 方法中，这一步主要的逻辑就是基于分区分配结果（不过这里的分区分配结果是空集合）创建 Kafka 消息，并写入到 offset topic 中。方法实现如下：\n\n```scala\ndef prepareStoreGroup(group: GroupMetadata,\n                      groupAssignment: Map[String, Array[Byte]],\n                      responseCallback: Errors => Unit): Option[DelayedStore] = {\n    // 依据 group 对应 offset topic 分区的消息版本进行处理\n    getMagic(partitionFor(group.groupId)) match {\n        case Some(magicValue) =>\n            val groupMetadataValueVersion = {\n                if (interBrokerProtocolVersion < KAFKA_0_10_1_IV0) 0.toShort\n                else GroupMetadataManager.CURRENT_GROUP_VALUE_SCHEMA_VERSION\n            }\n\n            val timestampType = TimestampType.CREATE_TIME\n            val timestamp = time.milliseconds()\n            // 创建记录 GroupMetadata 信息的消息，其中 value 是分区的分配结果\n            val record = Record.create(magicValue, timestampType, timestamp,\n                GroupMetadataManager.groupMetadataKey(group.groupId),\n                GroupMetadataManager.groupMetadataValue(group, groupAssignment, version = groupMetadataValueVersion))\n\n            // 获取 group 对应的 offset topic 分区对象\n            val groupMetadataPartition = new TopicPartition(Topic.GroupMetadataTopicName, partitionFor(group.groupId))\n            // 构造 offset topic 分区与消息集合的映射关系\n            val groupMetadataRecords = Map(groupMetadataPartition -> MemoryRecords.withRecords(timestampType, compressionType, record))\n            val generationId = group.generationId\n\n            // ... 省略 putCacheCallback 回调函数，该函数在消息完成追加到 offset topic 之后被回调，后面再进行分析\n\n            // 这里并没有真正追加消息，而是记录到 DelayedStore 中，具体追加由 GroupMetadataManager#store 方法追加\n            Some(DelayedStore(groupMetadataRecords, putCacheCallback))\n\n        case None =>\n            responseCallback(Errors.NOT_COORDINATOR_FOR_GROUP)\n            None\n    }\n}\n```\n\n方法会基于分区分配结果创建 Kafka 消息并写入到 offset topic 对应的分区中（前面的小节分析 GroupCoordinator 故障转移时有基于此类消息在新的 GroupCoordinator 节点上恢复 group 的元数据信息），需要注意的是这里并没有执行真正的写入操作，而是将待写入的数据和写入完成的回调函数封装成 DelayedStore 对象，等待后续调用 `GroupMetadataManager#store` 方法时才执行真正的写入操作：\n\n```scala\ndef store(delayedStore: DelayedStore) {\n    // 调用 ReplicaManager#appendRecords 方法往 offset topic 中追加消息\n    replicaManager.appendRecords(\n        config.offsetCommitTimeoutMs.toLong,\n        config.offsetCommitRequiredAcks, // -1，需要 ISR 集合中所有的副本都同步了该消息才认为消息成功追加\n        internalTopicsAllowed = true, // 指定允许向内部 topic 追加消息，即 offset topic\n        delayedStore.partitionRecords, // 分区与对应消息之间的映射\n        delayedStore.callback) // 回调函数\n}\n```\n\n上述方法中的回调函数实际上也就是在 `GroupMetadataManager#prepareStoreGroup` 方法中定义的 putCacheCallback 方法，当消息被追加到 offset topic 中后会回调执行该方法：\n\n```scala\ndef putCacheCallback(responseStatus: Map[TopicPartition, PartitionResponse]) {\n    if (responseStatus.size != 1 || !responseStatus.contains(groupMetadataPartition))\n        throw new IllegalStateException(\"Append status %s should only have one partition %s\".format(responseStatus, groupMetadataPartition))\n\n    // 获取消息追加响应结果\n    val status = responseStatus(groupMetadataPartition)\n\n    val responseError = if (status.error == Errors.NONE) {\n        // 追加成功\n        Errors.NONE\n    } else {\n        // ... 追加异常，对错误码执行一些转换操作，省略\n    }\n\n    // 执行回调函数\n    responseCallback(responseError)\n}\n```\n\n当消息被追加到 offset topic 中之后会依据消息的追加结果封装成对应的错误码，并回调 responseCallback 方法，这是一个 `Errors => Unit` 的函数，在本步骤中该函数只是简单的在追加失败时打印一行警告日志，毕竟追加的消息本来就是空的。\n\n#### SyncGroupRequest 请求处理\n\n对于 GroupCoordinator 实例而言，分区再分配操作的最后一步是处理来自 leader 消费者的 SyncGroupRequest 请求，以获取 leader 消费者基于服务端确定的分区分配策略为当前 group 名下消费者分配分区的结果信息。KafkaApis 中定义了 `KafkaApis#handleSyncGroupRequest` 方法处理该请求，而具体的处理逻辑则交由 `GroupCoordinator#handleSyncGroup` 方法实现，该方法首先会校验 GroupCoordinator 实例的运行状态，保证能够处理来自对应消费者的 SyncGroupRequest 请求，具体处理逻辑实现如下：\n\n```scala\nprivate def doSyncGroup(group: GroupMetadata,\n                        generationId: Int,\n                        memberId: String,\n                        groupAssignment: Map[String, Array[Byte]],\n                        responseCallback: SyncCallback) {\n    var delayedGroupStore: Option[DelayedStore] = None\n\n    group synchronized {\n        if (!group.has(memberId)) {\n            // 当前消费者不属于该 group\n            responseCallback(Array.empty, Errors.UNKNOWN_MEMBER_ID.code)\n        } else if (generationId != group.generationId) {\n            // group 年代信息不合法\n            responseCallback(Array.empty, Errors.ILLEGAL_GENERATION.code)\n        } else {\n            group.currentState match {\n                case Empty | Dead =>\n                    // 直接返回错误码\n                    responseCallback(Array.empty, Errors.UNKNOWN_MEMBER_ID.code)\n                case PreparingRebalance =>\n                    // 直接返回错误码\n                    responseCallback(Array.empty, Errors.REBALANCE_IN_PROGRESS.code)\n                case AwaitingSync =>\n                    // 设置对应消费者的响应回调函数\n                    group.get(memberId).awaitingSyncCallback = responseCallback\n                    // 仅处理来自 leader 消费者发来的 SyncGroupRequest 请求\n                    if (memberId == group.leaderId) {\n                        info(s\"Assignment received from leader for group ${group.groupId} for generation ${group.generationId}\")\n                        // 将未分配分区的消费者对应的分区分配结果填充为空的字节数组\n                        val missing = group.allMembers -- groupAssignment.keySet\n                        val assignment = groupAssignment ++ missing.map(_ -> Array.empty[Byte]).toMap\n\n                        // 将 GroupMetadata 相关信息以消息的形式写入到对应的 offset topic 分区中\n                        delayedGroupStore = groupManager.prepareStoreGroup(group, assignment,\n                            // ... 追加消息完成的回调响应逻辑，省略，后面针对性分析\n                            )\n                    }\n                case Stable =>\n                    // 将已有的分区分配结果返回给当前消费者\n                    val memberMetadata = group.get(memberId)\n                    responseCallback(memberMetadata.assignment, Errors.NONE.code)\n                    // 心跳相关操作\n                    this.completeAndScheduleNextHeartbeatExpiration(group, group.get(memberId))\n            }\n        }\n    }\n\n    // 执行写 offset topic 逻辑\n    delayedGroupStore.foreach(groupManager.store)\n}\n```\n\nGroupCoordinator 依赖于目标 group 的当前状态对 SyncGroupRequest 请求分而治之，对于 Empty、Dead 和 PreparingRebalance 状态而言直接返回对应的错误码，此时没有正常响应 SyncGroupRequest 请求的意义和条件，下面主要分析一下 AwaitingSync 和 Stable 状态。\n\n对于 AwaitingSync 状态而言，此时 GroupCoordinator 正在等待 leader 消费者的分区分配结果（即 SyncGroupRequest 请求），所以位于此状态的 group 只处理来自 leader 消费者的 SyncGroupRequest 请求。如果消费者的数目多于 topic 的分区数，则多出来的消费者不会分配分区，因为 Kafka 在设计上要求一个分区至多被一个消费者消费，所以这些多出来的消费者的分区分配信息会被置空。然后 GroupCoordinator 实例会调用 `GroupMetadataManager#prepareStoreGroup` 方法将分区分配信息写入到 offset topic 中，该方法的执行逻辑已在前面分析过，所以这里不再重复撰述，重点来看一下该方法的回调函数实现。我们前面已经介绍了当消息完成追加到 offset topic 中之后会回调参数指定的回调函数，而这里的回调逻辑实现如下：\n\n```scala\n(error: Errors) => {\n    group synchronized {\n        // 检查 group 的状态（正在等待 leader 消费者将分区的分配结果发送给 GroupCoordinator）和年代信息\n        if (group.is(AwaitingSync) && generationId == group.generationId) {\n            if (error != Errors.NONE) {\n                // 清空分区的分配结果，并发送异常响应\n                resetAndPropagateAssignmentError(group, error)\n                // 切换 group 状态为 PreparingRebalance，再次尝试分配分区\n                maybePrepareRebalance(group)\n            } else {\n                // 设置分区的分配结果，发送正常的 SyncGroupResponse 响应\n                setAndPropagateAssignment(group, assignment)\n                group.transitionTo(Stable)\n            }\n        }\n    }\n}\n```\n\n如果追加消息失败，则在回调逻辑中会清空分区的分配结果，并将错误信息返回给 leader 消费者，同时 GroupCoordinator 实例会切换状态为 PreparingRebalance 准备再次尝试分配分区。如果追加消息成功，则会将分区分配结果更新到 group 名下对应消费者的元数据信息中，同时向 leader 消费者响应正常的 SyncGroupResponse，同时切换 group 的状态为 Stable，开始正常运行。\n\n对于 Stable 状态而言，此时 group 处于正常运行中，所以对于来自消费者的 SyncGroupRequest 请求，只是简单将历史的分区分配结果直接返回，不做特殊处理。\n\n### 消费者请求处理\n\n#### OffsetFetchRequest 请求处理\n\n当完成执行分区再分配操作之后，消费者一般会被重新分配新的分区，此时消费者需要向集群发送 OffsetFetchRequest 请求以获取对应 topic 分区上次消费者的 offset 值，并从该位置继续消费，以防止消息的重复消费或遗漏消费。\n\nKafkaApis 定义了 `KafkaApis#handleOffsetFetchRequest` 方法用于处理 OffsetFetchRequest 请求，该方法会对请求的 topic 分区执行权限校验，如果校验通过则会依据请求中指定的版本号决定是从 ZK 还是 offset topic 中获取目标 topic 分区的 offset 位置信息。目前新版本的 Kafka 为了避免 ZK 压力对于服务可用性的影响，已经默认使用 offset topic 取代 ZK 记录消费者消费的 offset 位置信息，所以本小节仅介绍基于 offset topic 的 OffsetFetchRequest 请求处理过程。\n\n具体的处理逻辑交由 `GroupCoordinator#handleFetchOffsets` 方法执行，如果在请求中未指明要获取 offset 的 topic 分区，则表示期望获取当前 group 范围内所有 topicc 分区最近一次提交的 offset 值。方法实现如下：\n\n```scala\ndef handleFetchOffsets(groupId: String, partitions: Option[Seq[TopicPartition]] = None): (Errors, Map[TopicPartition, OffsetFetchResponse.PartitionData]) = {\n    if (!isActive.get) {\n        // 当前 GroupCoordinator 实例未启动运行\n        (Errors.GROUP_COORDINATOR_NOT_AVAILABLE, Map())\n    } else if (!isCoordinatorForGroup(groupId)) {\n        // 当前 GroupCoordinator 实例并不负责管理当前 group\n        debug(\"Could not fetch offsets for group %s (not group coordinator).\".format(groupId))\n        (Errors.NOT_COORDINATOR_FOR_GROUP, Map())\n    } else if (isCoordinatorLoadingInProgress(groupId)) {\n        // 当前 GroupCoordinator 实例正在加载该 group 对应的 offset topic 分区信息\n        (Errors.GROUP_LOAD_IN_PROGRESS, Map())\n    } else {\n        // 返回指定 topic 分区集合对应的最近一次提交的 offset 位置信息\n        (Errors.NONE, groupManager.getOffsets(groupId, partitions))\n    }\n}\n\ndef getOffsets(groupId: String, topicPartitionsOpt: Option[Seq[TopicPartition]]): Map[TopicPartition, OffsetFetchResponse.PartitionData] = {\n    trace(\"Getting offsets of %s for group %s.\".format(topicPartitionsOpt.getOrElse(\"all partitions\"), groupId))\n    // 获取 group 对应的元数据信息\n    val group = groupMetadataCache.get(groupId)\n    if (group == null) {\n        // group 对应的元数据信息不存在，则统一返回 offset 为 -1\n        topicPartitionsOpt.getOrElse(Seq.empty[TopicPartition]).map { topicPartition =>\n            (topicPartition, new OffsetFetchResponse.PartitionData(OffsetFetchResponse.INVALID_OFFSET, \"\", Errors.NONE))\n        }.toMap\n    } else {\n        group synchronized {\n            if (group.is(Dead)) {\n                // 对应的 group 名下已经没有消费者，并且元数据信息已经被删除\n                topicPartitionsOpt.getOrElse(Seq.empty[TopicPartition]).map { topicPartition =>\n                    (topicPartition, new OffsetFetchResponse.PartitionData(OffsetFetchResponse.INVALID_OFFSET, \"\", Errors.NONE))\n                }.toMap\n            } else {\n                topicPartitionsOpt match {\n                    // 请求未指定 topic 分区，表示请求 group 名下全部 topic 分区对应的最近一次提交的 offset 值\n                    case None =>\n                        group.allOffsets.map { case (topicPartition, offsetAndMetadata) =>\n                            topicPartition -> new OffsetFetchResponse.PartitionData(offsetAndMetadata.offset, offsetAndMetadata.metadata, Errors.NONE)\n                        }\n                    // 查找指定 topic 分区集合对应的最近一次提交的 offset 值\n                    case Some(_) =>\n                        topicPartitionsOpt.getOrElse(Seq.empty[TopicPartition]).map { topicPartition =>\n                            val partitionData = group.offset(topicPartition) match {\n                                case None =>\n                                    new OffsetFetchResponse.PartitionData(OffsetFetchResponse.INVALID_OFFSET, \"\", Errors.NONE)\n                                case Some(offsetAndMetadata) =>\n                                    new OffsetFetchResponse.PartitionData(offsetAndMetadata.offset, offsetAndMetadata.metadata, Errors.NONE)\n                            }\n                            topicPartition -> partitionData\n                        }.toMap\n                }\n            }\n        }\n    }\n}\n```\n\nGroup 元数据信息的 `GroupMetadata#offsets` 字段缓存了每个 topic 分区最近一次提交的 offset 位置信息和用户自定义数据，所以这里只要获取对应 topic 分区的 offset 值即可。\n\n#### OffsetCommitRequest 请求处理\n\n消费者在完成对指定 offset 的消费之后，会基于配置和相应的场景以 OffsetCommitRequest 请求的方式向服务端提交该 offset 值。服务端在接收到 OffsetCommitRequest 请求之后，需要为每个消费者记录对应 topic 分区的消费位置。\n\nKafkaApis 定义了 `KafkaApis#handleOffsetCommitRequest` 方法用于处理 OffsetCommitRequest 请求，该方法会校验目标 topic 是否存在，以及是否有对于该 topic 的读取权限，如果满足条件则会依据请求中指定的版本号决定将对应的 offset 位置信息记录到 ZK 还是 offset topic，本小节同样仅介绍基于 offset topic 的 OffsetCommitRequest 请求处理过程。\n\n具体的处理逻辑交由 `GroupCoordinator#handleCommitOffsets` 方法执行，该方法首先会校验 GroupCoordinator 的状态，确保能够正常处理当前 OffsetCommitRequest 请求，并在允许的条件下调用 `GroupCoordinator#doCommitOffsets` 方法将 offset 消费位置信息封装成消息追加到 offset topic 中：\n\n```scala\nprivate def doCommitOffsets(group: GroupMetadata,\n                            memberId: String,\n                            generationId: Int,\n                            offsetMetadata: immutable.Map[TopicPartition, OffsetAndMetadata],\n                            responseCallback: immutable.Map[TopicPartition, Short] => Unit) {\n    var delayedOffsetStore: Option[DelayedStore] = None\n\n    group synchronized {\n        if (group.is(Dead)) {\n            // 目标 group 已经失效，直接响应错误码\n            responseCallback(offsetMetadata.mapValues(_ => Errors.UNKNOWN_MEMBER_ID.code))\n        } else if (generationId < 0 && group.is(Empty)) {\n            // 目标 group 的信息不是由 kafka 维护，而仅仅依赖于 kafka 记录 offset 消费信息\n            delayedOffsetStore = groupManager.prepareStoreOffsets(group, memberId, generationId, offsetMetadata, responseCallback)\n        } else if (group.is(AwaitingSync)) {\n            // 目标 group 目前正在执行分区再分配操作\n            responseCallback(offsetMetadata.mapValues(_ => Errors.REBALANCE_IN_PROGRESS.code))\n        } else if (!group.has(memberId)) {\n            // 目标 group 并不包含当前消费者\n            responseCallback(offsetMetadata.mapValues(_ => Errors.UNKNOWN_MEMBER_ID.code))\n        } else if (generationId != group.generationId) {\n            // 目标 group 年代信息不一致\n            responseCallback(offsetMetadata.mapValues(_ => Errors.ILLEGAL_GENERATION.code))\n        } else {\n            // 将记录 offset 信息的消息追加到对应的 offset topic 对应分区中\n            val member = group.get(memberId)\n            completeAndScheduleNextHeartbeatExpiration(group, member)\n            delayedOffsetStore = groupManager.prepareStoreOffsets(group, memberId, generationId, offsetMetadata, responseCallback)\n        }\n    }\n\n    // 执行真正的追加消息操作\n    delayedOffsetStore.foreach(groupManager.store)\n}\n```\n\n具体追加消息到 offset topic 的过程已在前面分析过，不再重复撰述。\n\n#### LeaveGroupRequest 请求处理\n\n当消费者取消对指定 topic 的订阅，或者配置了 `internal.leave.group.on.close=true` 指明在关闭消费者时一同退出所属的 group，以及消费者因一些异常原因离线时，会向对应的 GroupCoordinator 节点发送 LeaveGroupRequest 请求，已告知集群对应的消费者已经失效，可能需要触发分区再分配操作。\n\nKafkaApis 定义了 `KafkaApis#handleLeaveGroupRequest` 方法用于处理 LeaveGroupRequest 请求，该方法首先会对消费者执行权限校验，并在权限校验通过的前提下委托 GroupCoordinator 处理相应的离线策略。具体逻辑实现位于 `GroupCoordinator#handleLeaveGroup` 方法中：\n\n```scala\ndef handleLeaveGroup(groupId: String, memberId: String, responseCallback: Short => Unit) {\n    if (!isActive.get) {\n        // GroupCoordinator 实例未启动\n        responseCallback(Errors.GROUP_COORDINATOR_NOT_AVAILABLE.code)\n    } else if (!isCoordinatorForGroup(groupId)) {\n        // 当前 GroupCoordinator 实例并不负责管理当前 group\n        responseCallback(Errors.NOT_COORDINATOR_FOR_GROUP.code)\n    } else if (isCoordinatorLoadingInProgress(groupId)) {\n        // 当前 GroupCoordinator 实例正在加载该 group 对应的 offset topic 分区信息\n        responseCallback(Errors.GROUP_LOAD_IN_PROGRESS.code)\n    } else {\n        groupManager.getGroup(groupId) match {\n            // 对应的 group 不存在或已经失效\n            case None =>\n                responseCallback(Errors.UNKNOWN_MEMBER_ID.code)\n            case Some(group) =>\n                group synchronized {\n                    if (group.is(Dead) || !group.has(memberId)) {\n                        responseCallback(Errors.UNKNOWN_MEMBER_ID.code)\n                    } else {\n                        val member = group.get(memberId)\n                        // 设置 MemberMetadata#isLeaving 为 true，并尝试完成对应的 DelayedHeartbeat 延时任务\n                        this.removeHeartbeatForLeavingMember(group, member)\n                        // 从 group 元数据信息中移除对应的 MemberMetadata 对象，并切换状态\n                        this.onMemberFailure(group, member)\n                        // 调用回调响应函数\n                        responseCallback(Errors.NONE.code)\n                    }\n                }\n        }\n    }\n}\n```\n\n如果发送 LeaveGroupRequest 请求的消费者所属的 group 存在且运行正常，则服务端首先会将对应消费者元数据信息的 `MemberMetadata#isLeaving` 字段设置为 true，标识当前消费者已经离线，并尝试触发关注当前消费者的 DelayedHeartbeat 延时任务。此外，还会将该消费者从之前所属的 group 元数据信息中移除，并依据 group 当前的状态决定是触发分区再分配操作，还是触发执行关注该 group 的 DelayedJoin 延时任务，相关实现位于 `GroupCoordinator#onMemberFailure` 方法中，前面已经分析过该方法，这里不再重复撰述。\n\n### 总结\n\n本文我们分析了 GroupCoordinator 组件的作用和实现，该组件与消费者之间关系密切，消费者在运行期间除了从 ReplicaManager 组件拉取消息进行消费，剩余的交互基本都由 GroupCoordinator 组件负责处理。Kafka 依赖该组件对消费者所属的 group 实施管理，并对 group 名下的消费者进行协调，主要提供了分区分配与再平衡支持、记录 group 的消费 offset 位置信息，以及维护与消费者之间的心跳等功能。此外，GroupCoordinator 内置了故障转移机制，以保证在 topic offset 对应分区 leader 副本失效时，能够切换到新的 GroupCoordinator 实例继续对外提供服务。\n","tags":["Kafka"],"categories":["kafka"]},{"title":"Kafka 源码解析：分区多副本容错机制","url":"/2019/06/24/kafka/kafka-replica/","content":"\n在分布式应用中，通常会引入冗余策略来保证集群中节点在宕机时的服务可用性，Kafka 在设计上也是如此。Kafka 会为每个 topic 分区创建多个副本，并将这些副本分散在多台 broker 节点上，以避免单点问题。一个分区的副本集合包含一个 leader 角色和多个 follower 角色，其中 leader 副本主要负责响应客户端对于指定 topic 分区消息的读写，并管理集合中的其它 follower 副本，而 follower 副本则主要负责与 leader 副本间保持数据同步，保证在 leader 副本失效时能够有新的 follower 选举成为新的 leader，以维持 Kafka 服务的正常运行。<!-- more -->\n\n### Replica 组件\n\nReplica 类用于定义 Kafka 中的副本，副本除了有前面介绍的 leader 和 follower 角色之分外，也区分 __本地副本__ 和 __远程副本__ ，其中本地副本是指与其关联的 Log 对象位于相同 broker 节点上，而远程副本的 Log 对象则位于其它 broker 节点上。对于远程副本而言，当前 broker 节点仅维护其 LEO 位置信息。 __远程副本的主要作用在于协助 leader 副本维护分区的 HW 位置值__ ，具体过程将在后面分析 HW 位置管理时进行说明。\n\n在前面介绍 Kafka 的日志存储机制时我们知道一个 topic 分区对应一个 Log 对象，而在设计上为了避免单点问题，一个 topic 分区又会包含多个副本，这些副本分布在多个不相同的 broker 节点上，如果某个副本正好位于其所属的 Log 对象所在的 broker 节点上，我们称之为本地副本，否则即为远程副本。\n\n下面来看一下 Replica 类的字段定义：\n\n```scala\nclass Replica(val brokerId: Int, // 当前副本所在的 broker 的 ID\n              val partition: Partition, // 当前副本所属的 topic 分区对象\n              time: Time = Time.SYSTEM, // 时间戳工具\n              initialHighWatermarkValue: Long = 0L, // 初始 HW 值\n              val log: Option[Log] = None // 当前副本所属的 Log 对象，如果是远程副本，该字段为空，通过该字段可以区分是本地副本还是远程副本\n             ) extends Logging {\n\n    /**\n     * 记录副本的 HW 值，消费者只能读取 HW 之前的消息，之后的消息对消费者不可见，\n     * 由 leader 副本维护，当消息被 ISR 集合中所有副本成功同步时更新该字段。\n     */\n    @volatile private[this] var highWatermarkMetadata = new LogOffsetMetadata(initialHighWatermarkValue)\n    /**\n     * 记录副本所属 Log 对象最后一条消息的 offset 值：\n     * - 如果是本地副本，可以直接从 Log#nextOffsetMetadata 字段中获取；\n     * - 如果是远程副本，则由其它 broker 发送请求来更新该值。\n     */\n    @volatile private[this] var logEndOffsetMetadata = LogOffsetMetadata.UnknownOffsetMetadata\n    /** 缓存上次从 leader 拉取消息时 leader 副本的 LEO 值 */\n    @volatile private[this] var lastFetchLeaderLogEndOffset = 0L\n    /** 记录上次从 leader 拉取消息的时间戳 */\n    @volatile private[this] var lastFetchTimeMs = 0L\n    /** 记录当前 follower 从 leader 拉取消息的最近一次时间戳，用于标识当前 follower 滞后 leader 的程度 */\n    @volatile private[this] var _lastCaughtUpTimeMs = 0L\n    /** 副本所属 topic 分区对象 */\n    val topicPartition: TopicPartition = partition.topicPartition\n\n    // ... 省略方法定义\n\n}\n```\n\n对于本地副本来说会持有所属 Log 对象的引用，可以基于这一点来判定当前副本是本地副本还是远程副本。此外，Replica 对象还记录了当前副本的 LEO 和 HW 值，以及最近一次从 leader 副本拉取消息的时间戳，同时还定义了相关方法用于维护这些信息，下面分别来看一下维护 LEO 和 HW 值的方法。\n\n```scala\ndef updateLogReadResult(logReadResult: LogReadResult) {\n    // 更新 _lastCaughtUpTimeMs 值，记录了 follower 从 leader 拉取消息的最新时间\n    if (logReadResult.info.fetchOffsetMetadata.messageOffset >= logReadResult.leaderLogEndOffset)\n        _lastCaughtUpTimeMs = math.max(_lastCaughtUpTimeMs, logReadResult.fetchTimeMs)\n    else if (logReadResult.info.fetchOffsetMetadata.messageOffset >= lastFetchLeaderLogEndOffset)\n             _lastCaughtUpTimeMs = math.max(_lastCaughtUpTimeMs, lastFetchTimeMs)\n\n    // 如果当前副本是远程副本，则更新当前副本的 LEO 值\n    logEndOffset = logReadResult.info.fetchOffsetMetadata\n    // 更新本地记录的从 leader 拉取消息时 leader 副本的 LEO 值\n    lastFetchLeaderLogEndOffset = logReadResult.leaderLogEndOffset\n    // 更新本地记录的从 leader 拉取消息的时间戳\n    lastFetchTimeMs = logReadResult.fetchTimeMs\n}\n\nprivate def logEndOffset_=(newLogEndOffset: LogOffsetMetadata) {\n    if (isLocal) {\n        // 如果是本地副本无需更新 LEO 值，而是由对应 Log 对象的 Log#logEndOffsetMetadata 字段决定\n        throw new KafkaException(s\"Should not set log end offset on partition $topicPartition's local replica $brokerId\")\n    } else {\n        // 如果当前副本是远程副本，则更新副本的 LEO 值\n        logEndOffsetMetadata = newLogEndOffset\n        trace(s\"Setting log end offset for replica $brokerId for partition $topicPartition to [$logEndOffsetMetadata]\")\n    }\n}\n```\n\n方法 `Replica#updateLogReadResult` 用于更新当前 Replica 对象的 LEO 值。对于 follower 来说，当从 leader 完成一次消息同步操作后，follower 会更新本地记录的 LEO 值，并更新相应的时间戳信息，其中 `_lastCaughtUpTimeMs` 字段用于记录 follower 最近一次成功从 leader 拉取消息的时间戳，可以标识当前 follower 相对于 leader 的滞后程度。\n\n由上面的实现可以看出，只有远程副本需要更新 LEO 值，因为远程副本未持有所属 Log 对象的引用，需要通过本地字段缓存当前副本的 LEO 值。Replica 类定义了 `Replica#logEndOffset` 方法用于获取当前副本的 LEO 值：\n\n```scala\ndef logEndOffset: LogOffsetMetadata = if (isLocal) log.get.logEndOffsetMetadata else logEndOffsetMetadata\n```\n\n对于本地副本来说，可以调用其持有的 Log 对象的 `Log#logEndOffsetMetadata` 方法直接获取对应的 LEO 值，而对于远程副本来说则返回本地缓存的 LEO 值。\n\n对于 HW 值而言，Replica 同样提供了更新的方法（如下），需要注意的一点是这里仅更新本地副本的 HW 值，因为远程副本所在的 broker 节点仅维护副本的 LEO 位置信息 ：\n\n```scala\ndef highWatermark_=(newHighWatermark: LogOffsetMetadata) {\n    if (isLocal) {\n        // 如果是本地副本，则更新对应的 HW 值\n        highWatermarkMetadata = newHighWatermark\n        trace(s\"Setting high watermark for replica $brokerId partition $topicPartition to [$newHighWatermark]\")\n    } else {\n        throw new KafkaException(s\"Should not set high watermark on partition $topicPartition's non-local replica $brokerId\")\n    }\n}\n```\n\n同时，Replica 也提供了获取当前副本 HW 值的方法，实现如下：\n\n```scala\ndef highWatermark: LogOffsetMetadata = highWatermarkMetadata\n```\n\n### Partition 组件\n\nPartition 类用于定义 Kafka 中的分区，一个 topic 可以设置多个分区。前面在介绍 Kafka 架构与核心概念时曾提及过，Kafka 之所以需要引入分区的概念，主要是希望利用分布式系统中的多节点来提升 Kafka 集群的性能和可扩展性。因为一个 topic 的各个分区可以分布在不同的 broker 节点上，进而就能将 topic 的消息数据分散在这些 broker 节点上存储，对于消息的读写压力就可以由这些节点进行分摊。当我们感知到一个 topic 的消息读写量较大时，我们可以适当增加分区的数目来实现扩容的目的。设想如果我们不引入分区策略，而是由一个 broker 节点完整负责一个 topic，考虑每个 topic 之间的消息数据量和读写量可能存在较大差别，那么各个 broker 节点在负载均衡性上也会有较大的差异，最终影响的是集群整体的可用性。\n\n此外，为了保证高可用性，Kafka 会为每个分区设置多个副本，Partition 提供了管理这些副本的方法，包括执行副本角色切换、维护 ISR 集合、管理 HW 值和 LEO 值，以及调用日志存储系统写入日志数据等。\n\n下面来看一下 Partition 类的字段定义：\n\n```scala\nclass Partition(val topic: String, // 分区所属的 topic\n                val partitionId: Int, // 分区编号\n                time: Time, // 时间戳工具\n                replicaManager: ReplicaManager // 副本管理\n               ) extends Logging with KafkaMetricsGroup {\n\n    /** topic 分区对象 */\n    val topicPartition = new TopicPartition(topic, partitionId)\n    /** 当前 broker 的 ID */\n    private val localBrokerId = replicaManager.config.brokerId\n    /** 管理分区日志数据 */\n    private val logManager = replicaManager.logManager\n    /** ZK 工具类 */\n    private val zkUtils = replicaManager.zkUtils\n    /** AR 集合，维护当前分区全部副本的集合，key 是副本 ID */\n    private val assignedReplicaMap = new Pool[Int, Replica]\n    /** leader 副本的年代信息 */\n    @volatile private var leaderEpoch: Int = LeaderAndIsr.initialLeaderEpoch - 1\n    /** leader 副本的 ID */\n    @volatile var leaderReplicaIdOpt: Option[Int] = None\n    /** 当前分区的 ISR 集合 */\n    @volatile var inSyncReplicas: Set[Replica] = Set.empty[Replica]\n    /** 当前集群控制器的年代信息，会在切换副本角色时进行更新 */\n    private var controllerEpoch: Int = KafkaController.InitialControllerEpoch - 1\n\n    // ... 省略方法定义\n\n}\n```\n\nPartition 中提供了多种方法实现，按照功能划分可以将其中的核心方法划分为以下 5 类：\n\n1. 副本对象操作：getOrCreateReplica / getReplica / removeReplica\n2. 副本角色切换：makeLeader / makeFollower\n3. 日志数据操作：delete / appendRecordsToLeader\n4. ISR 集合管理：maybeExpandIsr / maybeShrinkIsr\n5. HW 和 LEO 位置管理：checkEnoughReplicasReachOffset / maybeIncrementLeaderHW / updateReplicaLogReadResult\n\n下面按照分类对这些方法逐一进行分析。\n\n#### 副本对象操作\n\nPartition 对象定义了 `Partition#assignedReplicaMap` 字段用于记录了隶属于当前分区的所有副本 Replica 对象，即 AR 集合，并提供了相关方法用于管理该字段。其中 `Partition#getReplica` 方法和 `Partition#removeReplica` 方法分别用于从字段中获取和移除指定副本 ID 对应的副本 Replica 对象，实现比较简单。\n\n本小节我们主要对 `Partition#getOrCreateReplica` 方法进行分析，该方法相对于 `Partition#getReplica` 方法的区别在于当给定的副本 ID 在本地找不到对应的副本 Replica 对象时，会创建一个新的 Replica 对象。方法实现如下：\n\n```scala\ndef getOrCreateReplica(replicaId: Int = localBrokerId): Replica = {\n    // 尝试从 AR 集合中获取 replicaId 对应的 Replica 对象，如果不存在则创建一个\n    assignedReplicaMap.getAndMaybePut(replicaId, {\n        // 如果是本地副本\n        if (this.isReplicaLocal(replicaId)) {\n            // 获取 log 相关配置信息，ZK 中的配置会覆盖默认配置\n            val config = LogConfig.fromProps(logManager.defaultConfig.originals, AdminUtils.fetchEntityConfig(zkUtils, ConfigType.Topic, topic))\n\n            // 创建 topic 分区对应的 Log 对象，如果已经存在则直接返回\n            val log = logManager.createLog(topicPartition, config)\n\n            // 加载对应 log 目录下的 replication-offset-checkpoint 文件，其中记录了每个 topic 分区的 HW 值\n            val checkpoint = replicaManager.highWatermarkCheckpoints(log.dir.getParentFile.getAbsolutePath)\n            val offsetMap = checkpoint.read()\n\n            // 获取当前 topic 分区对应的 HW 值，并与 LEO 比较，选择较小的值作为此副本的 HW 位置\n            val offset = math.min(offsetMap.getOrElse(topicPartition, 0L), log.logEndOffset)\n\n            // 创建 Replica 对象\n            new Replica(replicaId, this, time, offset, Some(log))\n        }\n        // 如果是远程副本，无需加载本地对应的日志数据\n        else new Replica(replicaId, this, time)\n    })\n}\n```\n\n如果参数指定的副本 ID 对应的副本 Replica 对象在本地 AR 集合中不存在，则方法会执行创建对应的 Replica 对象。这里区分本地副本和远程副本，对于远程副本来说创建的过程如上述代码所示，比较简单，而对于本地副本来说，因为本地副本持有副本所属分区对应的 Log 对象，所以需要加载相关数据信息，包括配置、初始 HW 值，以及分区对应的 Log 对象。其中构造 Log 对象的过程由 `LogManager#createLog` 方法实现：\n\n```scala\ndef createLog(topicPartition: TopicPartition, config: LogConfig): Log = {\n    logCreationOrDeletionLock synchronized {\n        // 获取指定 topic 分区对应的 Log 对象\n        getLog(topicPartition).getOrElse {\n            // 如果存在多个 log 目录，则选择 Log 数目最少的目录\n            val dataDir = this.nextLogDir()\n            // 创建当前 topic 分区对应的日志目录\n            val dir = new File(dataDir, topicPartition.topic + \"-\" + topicPartition.partition)\n            dir.mkdirs()\n            // 创建 Log 对象\n            val log = new Log(dir, config, recoveryPoint = 0L, scheduler, time)\n            // 缓存到本地 logs 字段中\n            logs.put(topicPartition, log)\n            info(\"Created log for partition [%s,%d] in %s with properties {%s}.\"\n                    .format(topicPartition.topic, topicPartition.partition, dataDir.getAbsolutePath, config.originals.asScala.mkString(\", \")))\n            log\n        }\n    }\n}\n```\n\n#### 副本角色切换\n\n副本有 leader 和 follower 角色之分，Partition 分别提供了 `Partition#makeLeader` 方法和 `Partition#makeFollower` 方法用于将本地副本切换成相应的 leader 和 follower 角色。\n\n##### 切换本地副本为 leader 角色\n\n方法 `Partition#makeLeader` 用于将本地副本切换成 leader 角色，实现如下：\n\n```scala\ndef makeLeader(controllerId: Int, partitionStateInfo: PartitionState, correlationId: Int): Boolean = {\n    val (leaderHWIncremented, isNewLeader) = inWriteLock(leaderIsrUpdateLock) {\n        // 1. 更新本地记录的 controller 的年代信息\n        controllerEpoch = partitionStateInfo.controllerEpoch\n\n        // 2. 获取/创建请求信息中 AR 和 ISR 集合中所有副本对应的 Replica 对象\n        val allReplicas = partitionStateInfo.replicas.asScala.map(_.toInt)\n        allReplicas.foreach(replica => getOrCreateReplica(replica))\n        val newInSyncReplicas = partitionStateInfo.isr.asScala.map(r => getOrCreateReplica(r)).toSet\n\n        // 3. 移除本地缓存的所有已过期的的副本对象\n        (assignedReplicas.map(_.brokerId) -- allReplicas).foreach(removeReplica)\n\n        // 4. 更新本地记录的分区 leader 副本相关信息\n        inSyncReplicas = newInSyncReplicas // 更新 ISR 集合\n        leaderEpoch = partitionStateInfo.leaderEpoch // 更新 leader 副本的年代信息\n        zkVersion = partitionStateInfo.zkVersion // 更新 ZK 的版本信息\n\n        // 5. 检测分区 leader 副本是否发生变化\n        val isNewLeader =\n            if (leaderReplicaIdOpt.isDefined && leaderReplicaIdOpt.get == localBrokerId) {\n                false // 未发生变化\n            } else {\n                // leader 发生变化，更新分区 leader 副本 ID\n                leaderReplicaIdOpt = Some(localBrokerId)\n                true\n            }\n\n        // 6. 遍历所有的 follower 副本，更新对应副本的相关时间戳信息\n        val leaderReplica = getReplica().get // 获取 leader 副本 Replica 对象\n        val curLeaderLogEndOffset = leaderReplica.logEndOffset.messageOffset // 获取 leader 副本的 LEO 值\n        val curTimeMs = time.milliseconds\n        (assignedReplicas - leaderReplica).foreach { replica =>\n            val lastCaughtUpTimeMs = if (inSyncReplicas.contains(replica)) curTimeMs else 0L\n            replica.resetLastCaughtUpTime(curLeaderLogEndOffset, curTimeMs, lastCaughtUpTimeMs)\n        }\n\n        // 7. 如果当前 leader 是新选举出来的，则修正 leader 副本的 HW 值，并重置本地缓存的所有远程副本的相关信息\n        if (isNewLeader) {\n            // 尝试修正新 leader 副本的 HW 值\n            leaderReplica.convertHWToLocalOffsetMetadata()\n            // 重置本地缓存的所有远程副本的相关信息\n            assignedReplicas.filter(_.brokerId != localBrokerId).foreach(_.updateLogReadResult(LogReadResult.UnknownLogReadResult))\n        }\n\n        // 8. 尝试后移 leader 副本的 HW 值\n        (maybeIncrementLeaderHW(leaderReplica), isNewLeader)\n    }\n\n    // 9. 如果 leader 副本的 HW 值增加了，则尝试执行监听当前 topic 分区的 DelayedFetch 和 DelayedProduce 任务\n    if (leaderHWIncremented) tryCompleteDelayedRequests()\n\n    isNewLeader\n}\n```\n\n切换副本为 leader 角色的整体流程可以概括为：\n\n1. 更新本地记录的 kafka controller 的年代信息；\n2. 获取分区新的 AR 集合和 ISR 集合中所有副本对应的 Replica 对象，如果不存在则创建；\n3. 移除本地缓存的对应分区已经过期的副本 Replica 对象；\n4. 更新本地记录的分区 leader 副本的相关信息，包括 ISR 集合、leader 副本的年代信息等；\n5. 检测分区 leader 副本是否发生变化，如果当前副本之前是 follower 角色，或者对应的 topic 分区的副本之前未分配给当前 broker 节点，则说明对应 topic 分区的 leader 副本发生了变化；\n6. 遍历所有的 follower 副本，更新对应副本的相关时间戳信息，包括最近一次从 leader 副本拉取消息的时间戳，以及 leader 副本的 LEO 值等；\n7. 如果当前 leader 副本是新选举出来的，则尝试修正对应副本的 HW 值，并重置本地缓存的所有远程副本的相关信息；\n8. 尝试后移 leader 副本的 HW 值；\n9. 如果上一步后移了 leader 副本的 HW 值，则尝试执行监听当前 topic 分区的 DelayedFetch 和 DelayedProduce 延时任务，因为等待的条件可能已经满足。\n\n其中，方法 `Partition#maybeIncrementLeaderHW` 用于尝试向后移动 leader 副本的 HW 值，相关实现我们将在本篇的后续部分进行分析。\n\n##### 切换本地副本为 follower 角色\n\n方法 `Partition#makeFollower` 用于将本地副本切换成 follower 角色，实现如下：\n\n```scala\ndef makeFollower(controllerId: Int, partitionStateInfo: PartitionState, correlationId: Int): Boolean = {\n    inWriteLock(leaderIsrUpdateLock) {\n        val allReplicas = partitionStateInfo.replicas.asScala.map(_.toInt)\n        val newLeaderBrokerId: Int = partitionStateInfo.leader\n\n        // 1. 更新本地记录的 controller 的年代信息\n        controllerEpoch = partitionStateInfo.controllerEpoch\n\n        // 2. 获取/创建请求信息中所有副本对应的 Replica 对象\n        allReplicas.foreach(r => getOrCreateReplica(r))\n\n        // 3. 移除本地缓存的所有已过期的的副本对象\n        (assignedReplicas.map(_.brokerId) -- allReplicas).foreach(removeReplica)\n\n        // 4. 更新本地记录的分区 leader 副本相关信息，其中 ISR 集合由 leader 副本维护，将 follower 副本上的 ISR 集合置空\n        inSyncReplicas = Set.empty[Replica]\n        leaderEpoch = partitionStateInfo.leaderEpoch // 更新 leader 副本的年代信息\n        zkVersion = partitionStateInfo.zkVersion // 更新 zk 版本信息\n\n        // 5. 检测分区 leader 副本是否发生变化，如果发生变化则更新本地记录的 ID 值\n        if (leaderReplicaIdOpt.isDefined && leaderReplicaIdOpt.get == newLeaderBrokerId) {\n            false\n        } else {\n            // 发生变化，更新本地记录的分区 leader 副本的 ID\n            leaderReplicaIdOpt = Some(newLeaderBrokerId)\n            true\n        }\n    }\n}\n```\n\n切换副本为 follower 角色的整体流程可以概括为：\n\n1. 更新本地记录的 kafka controller 的年代信息；\n2. 获取分区新的 AR 集合中所有副本对应的 Replica 对象，如果不存在则创建；\n3. 移除本地缓存的已经过期的副本 Replica 对象；\n4. 更新本地记录的分区 leader 副本的相关信息，因为 ISR 集合由 leader 副本管理，所以需要将 follower 副本记录的 ISR 集合置为空；\n5. 检测分区 leader 副本是否发生变化，如果发生变化则需要更新本地记录的 leader 副本的 ID。\n\n相对于切换成 leader 角色来说，将本地副本切换成 follower 的过程要简单许多。\n\n#### 日志数据操作\n\nPartition 提供了 `Partition#delete` 方法和 `Partition#appendRecordsToLeader` 方法用于操作日志数据，其中前者用于清空当前分区记录的副本相关信息，包括 AR 集合、ISR 集合，以及 leader 副本的 ID 值等信息，并异步删除分区对应的日志文件和索引文件（由 `LogManager#asyncDelete` 方法实现，会将日志文件和索引文件添加 `.delete` 标记删除后缀，并交由定时任务执行删除操作），而后者用于往当前分区的 leader 副本追加消息。删除操作的实现比较简单，这里重点来看一下往 leader 副本追加消息的过程，实现如下：\n\n```scala\ndef appendRecordsToLeader(records: MemoryRecords, requiredAcks: Int = 0): LogAppendInfo = {\n    val (info, leaderHWIncremented) = inReadLock(leaderIsrUpdateLock) {\n        leaderReplicaIfLocal match {\n            // 只有 leader 副本支持追加消息操作\n            case Some(leaderReplica) =>\n                // 获取 leader 副本对应的 Log 对象\n                val log = leaderReplica.log.get\n                // 对应 min.insync.replicas 配置，表示 ISR 集合的最小值\n                val minIsr = log.config.minInSyncReplicas\n                // 获取当前分区 ISR 集合的大小\n                val inSyncSize = inSyncReplicas.size\n\n                // 如果用户指定 acks = -1，但是当前 ISR 集合小于允许的最小值，则不允许追加消息，防止数据丢失\n                if (inSyncSize < minIsr && requiredAcks == -1) {\n                    throw new NotEnoughReplicasException(\n                        \"Number of insync replicas for partition %s is [%d], below required minimum [%s]\".format(topicPartition, inSyncSize, minIsr))\n                }\n\n                // 往 leader 副本的 Log 对象中追加消息\n                val info = log.append(records)\n                // 有新的日志数据被追加，尝试执行监听当前 topic 分区的 DelayedFetch 延时任务\n                replicaManager.tryCompleteDelayedFetch(TopicPartitionOperationKey(this.topic, this.partitionId))\n                // 尝试后移 leader 副本的 HW 值\n                (info, maybeIncrementLeaderHW(leaderReplica))\n\n            // 如果不是 leader 副本，则抛出异常\n            case None =>\n                throw new NotLeaderForPartitionException(\"Leader not local for partition %s on broker %d\".format(topicPartition, localBrokerId))\n        }\n    }\n\n    // 如果 leader 副本的 HW 值增加了，则尝试执行监听当前 topic 分区的 DelayedFetch 和 DelayedProduce 任务\n    if (leaderHWIncremented) tryCompleteDelayedRequests()\n\n    info\n}\n```\n\n首先我们多次提到的一点是，Kafka 只允许往目标 topic 分区的 leader 副本追加消息，而 follower 只能从 leader 副本同步消息，所以如果当前追加操作的是 follower 副本，则会抛出异常。\n\n对于 leader 副本来说，在具体执行追加操作之前，如果用户指定了 acks 参数为 -1，即要求所有 ISR 副本在全部收到消息后才允许对客户端进行成功响应，那么会先检测当前分区的 ISR 集合中的副本数目是否大于等于配置的阈值（对应 `min.insync.replicas` 配置），如果数目不达标则会拒绝执行追加操作，防止数据丢失。具体追加消息数据的操作交由 `Log#append` 方法执行，该方法已经在前面的文章中分析过，这里不再重复撰述。完成了消息数据的追加操作后，Kafka 会立即尝试执行监听当前 topic 分区的 DelayedFetch 延时任务，避免让客户端和 follower 副本等待太久或超时，此外还会尝试后移 leader 副本的 HW 值。\n\n#### ISR 集合管理\n\n分区 leader 副本的一个重要的职责就是维护当前分区的 ISR 集合。在分布式应用中，考虑网络、机器性能等因素，follower 副本同步 leader 副本数据的状态是在动态变化的，如果一个 follower 副本与 leader 副本之间存在较大的同步延迟，则不应该被加入到 ISR 集合中，否则应该被纳入到 ISR 集合中的一员，从而能够在 leader 副本失效时，竞选成为新的 leader 副本，以保证 Kafka 服务的可用性。\n\nPartition 类型分别定义了 `Partition#maybeExpandIsr` 方法和 `Partition#maybeShrinkIsr` 方法，用于将指定的副本在满足条件下加入到 ISR 集合中，以及依据给定的时间阈值将滞后于 leader 副本超过阈值时间的 follower 副本移出 ISR 集合。首先来看一下 `Partition#maybeExpandIsr` 方法的实现：\n\n```scala\ndef maybeExpandIsr(replicaId: Int, logReadResult: LogReadResult) {\n    val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) {\n        leaderReplicaIfLocal match {\n            // 只有当本地副本是 leader 副本时，才执行扩张操作，因为 ISR 集合由 leader 副本维护\n            case Some(leaderReplica) =>\n                // 获取目标 follower 副本对应的 Replica 对象\n                val replica = getReplica(replicaId).get\n                // 获取 leader 副本对应的 HW 值\n                val leaderHW = leaderReplica.highWatermark\n                // 判断当前 follower 是否应该被加入到 ISR 集合，并在成功加入后更新相关信息\n                if (!inSyncReplicas.contains(replica) // follower 副本不在 ISR 集合中\n                        && assignedReplicas.map(_.brokerId).contains(replicaId) // AR 集合中包含该 follower 副本\n                        && replica.logEndOffset.offsetDiff(leaderHW) >= 0) { // follower 副本的 LEO 已经追赶上 leader 副本的 HW 值\n                    // 将 follower 副本添加到 ISR 集合中\n                    val newInSyncReplicas = inSyncReplicas + replica\n                    info(s\"Expanding ISR for partition $topicPartition from ${inSyncReplicas.map(_.brokerId).mkString(\",\")} to ${newInSyncReplicas.map(_.brokerId).mkString(\",\")}\")\n                    // 更新 ZK 和本地记录的新的 ISR 集合信息\n                    this.updateIsr(newInSyncReplicas)\n                    replicaManager.isrExpandRate.mark()\n                }\n                // 尝试后移 leader 副本的 HW 值\n                this.maybeIncrementLeaderHW(leaderReplica, logReadResult.fetchTimeMs)\n\n            // 如果不是 leader 副本，啥也不干\n            case None => false\n        }\n    }\n\n    // 如果 leader 副本的 HW 值发生变化，尝试执行监听当前 topic 分区的 DelayedFetch 和 DelayedProduce 延时任务\n    if (leaderHWIncremented) tryCompleteDelayedRequests()\n}\n```\n\nISR 集合的扩张和收缩操作均由 leader 副本负责，对于给定的 follower 副本如果同时满足以下条件，则将其添加到 ISR 集合中：\n\n1. 目标 follower 副本不在当前分区的 ISR 集合中；\n2. 目标 follower 副本位于当前分区的 AR 集合中；\n3. 目标 follower 副本的 LEO 值已经追赶上对应 leader 副本的 HW 值。\n\n对于同时满足上述条件的 follower 副本，Kafka 会将其添加到对应 topic 分区的 ISR 集合中，并将新的 ISR 集合信息记录到 ZK，同时更新 leader 副本本地记录的 ISR 集合。\n\n方法 `Partition#maybeShrinkIsr` 用于收缩当前分区的 ISR 集合，实现如下：\n\n```scala\ndef maybeShrinkIsr(replicaMaxLagTimeMs: Long) {\n    val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) {\n        leaderReplicaIfLocal match {\n            // 只有当本地副本是 leader 副本时，才执行缩减操作，因为 ISR 集合由 leader 副本维护\n            case Some(leaderReplica) =>\n                // 从 ISR 集合中获取滞后的 follower 副本集合\n                val outOfSyncReplicas = this.getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs)\n                if (outOfSyncReplicas.nonEmpty) {\n                    // 将滞后的 follower 副本从 ISR 集合中剔除\n                    val newInSyncReplicas = inSyncReplicas -- outOfSyncReplicas\n                    assert(newInSyncReplicas.nonEmpty)\n                    info(\"Shrinking ISR for partition [%s,%d] from %s to %s\".format(topic, partitionId,\n                        inSyncReplicas.map(_.brokerId).mkString(\",\"), newInSyncReplicas.map(_.brokerId).mkString(\",\")))\n                    // 将新的 ISR 集合信息上报给 ZK，同时更新本地记录的 ISR 集合信息\n                    this.updateIsr(newInSyncReplicas)\n                    replicaManager.isrShrinkRate.mark()\n                    // 尝试后移 leader 副本的 HW 值\n                    this.maybeIncrementLeaderHW(leaderReplica)\n                } else {\n                    false\n                }\n            // 如果不是 leader 副本，则啥也不做\n            case None => false\n        }\n    }\n\n    // 如果 leader 副本的 HW 值发生变化，尝试执行监听当前 topic 分区的 DelayedFetch 和 DelayedProduce 延时任务\n    if (leaderHWIncremented) tryCompleteDelayedRequests()\n}\n\ndef getOutOfSyncReplicas(leaderReplica: Replica, maxLagMs: Long): Set[Replica] = {\n    // 获取 ISR 集合中所有的 follower 副本\n    val candidateReplicas = inSyncReplicas - leaderReplica\n    // 获取超过给定时间（对应 replica.lag.time.max.ms 配置）未向 leader 副本请求拉取消息的 follower 副本集合\n    val laggingReplicas = candidateReplicas.filter(r => (time.milliseconds - r.lastCaughtUpTimeMs) > maxLagMs)\n    laggingReplicas\n}\n```\n\n对于 ISR 集合中的 follower 副本，如果其最近一次成功从 leader 副本拉取数据的时间戳相对于当前时间超过指定的阈值（对应 `replica.lag.time.max.ms` 配置，默认为 10 秒），则将其从 ISR 集合中移出，而不管当前 follower 副本与 leader 副本的数据延迟差异。一旦 follower 被从 ISR 踢出，Kafka 会将新的 ISR 集合信息上报给 ZK，同时更新 leader 副本本地记录的 ISR 集合。\n\n#### HW 和 LEO 位置管理\n\nPartition 定义了 `Partition#checkEnoughReplicasReachOffset` 方法和 `Partition#maybeIncrementLeaderHW` 方法，分别用于检测指定 offset 之前的消息是否已经被 ISR 集合中足够多的 follower 副本确认（ack），以及尝试向后移动 leader 副本的 HW 值。先来看一下 `Partition#checkEnoughReplicasReachOffset` 方法，实现如下：\n\n```scala\ndef checkEnoughReplicasReachOffset(requiredOffset: Long): (Boolean, Errors) = {\n    leaderReplicaIfLocal match {\n        // 如果当前副本是 leader 副本\n        case Some(leaderReplica) =>\n            // 获取 ISR 集合\n            val curInSyncReplicas = inSyncReplicas\n\n            // 对应 min.insync.replicas 配置\n            val minIsr = leaderReplica.log.get.config.minInSyncReplicas\n\n            // 如果当前请求的 offset 小于等于 HW 的 offset\n            if (leaderReplica.highWatermark.messageOffset >= requiredOffset) {\n                // 如果当前分区的 ISR 集合大小大于等于允许的最小值\n                if (minIsr <= curInSyncReplicas.size) (true, Errors.NONE)\n                // 否则返回 NOT_ENOUGH_REPLICAS_AFTER_APPEND 错误\n                else (true, Errors.NOT_ENOUGH_REPLICAS_AFTER_APPEND)\n            } else {\n                // 如果当前请求的 offset 大于 HW，则直接返回 false，因为 HW 之后的消息对于客户端不可见\n                (false, Errors.NONE)\n            }\n\n        // 如果当前副本是 follower 副本，则返回 NOT_LEADER_FOR_PARTITION 错误\n        case None => (false, Errors.NOT_LEADER_FOR_PARTITION)\n    }\n}\n```\n\n方法 `Partition#checkEnoughReplicasReachOffset` 接收一个 requiredOffset 参数，用于检测该 offset 之前的消息是否已经被确认，本质上就是将该 offset 与 leader 副本的 HW 值进行比较，如果 leader 副本的 HW 值大于等于该 offset 值，则认为之前的消息已经全部被确认。\n\n```scala\nprivate def maybeIncrementLeaderHW(leaderReplica: Replica, curTime: Long = time.milliseconds): Boolean = {\n    // 获取位于 ISR 集合中，或最近一次从 leader 拉取消息的时间戳位于指定时间范围（对应 replica.lag.time.max.ms 配置）内的所有副本的 LEO 值\n    val allLogEndOffsets = assignedReplicas.filter { replica =>\n        curTime - replica.lastCaughtUpTimeMs <= replicaManager.config.replicaLagTimeMaxMs || inSyncReplicas.contains(replica)\n    }.map(_.logEndOffset)\n\n    // 以这些副本中最小的 LEO 值作为 leader 副本新的 HW 值\n    val newHighWatermark = allLogEndOffsets.min(new LogOffsetMetadata.OffsetOrdering)\n\n    // 比较新旧 HW 值，如果旧的 HW 小于新的 HW，或者旧的 HW 对应的 LogSegment 的 baseOffset 小于新的 HW 的 LogSegment 对象的 baseOffset，则更新\n    val oldHighWatermark = leaderReplica.highWatermark\n    if (oldHighWatermark.messageOffset < newHighWatermark.messageOffset || oldHighWatermark.onOlderSegment(newHighWatermark)) {\n        leaderReplica.highWatermark = newHighWatermark\n        debug(\"High watermark for partition [%s,%d] updated to %s\".format(topic, partitionId, newHighWatermark))\n        true\n    } else {\n        debug(\"Skipping update high watermark since Old hw %s is larger than new hw %s for partition [%s,%d]. All leo's are %s\"\n                .format(oldHighWatermark, newHighWatermark, topic, partitionId, allLogEndOffsets.mkString(\",\")))\n        false\n    }\n}\n```\n\n上述方法曾在前面的分析中多次出现，用于尝试后移 leader 副本的 HW 位置，其核心思想是选取 ISR 集合中副本最小的 LEO 值作为 leader 副本的新 HW 值，如果计算出来的 HW 值大于 leader 副本当前的 HW 值，则进行更新。考虑到一些位于 ISR 集合之外但是有机会加入 ISR 集合的副本加入 ISR 集合有一个延迟的过程，所以这里也考虑了这些滞后于 leader 副本时间较小的 follower 副本。\n\n前面我们曾提及过远程副本的作用在于协助 leader 副本更新分区 HW 值，这里我们具体说明一下这一过程。分区 leader 副本所在的 broker 节点以远程副本的形式记录着所有 follower 副本的 LEO 值，当 follower 副本从 leader 副本同步数据时会告知 leader 副本从什么位置开始拉取数据，leader 副本会使用该 offset 值更新远程副本的 LEO 位置值。当 leader 副本需要更新分区 HW 值时会从所有远程副本中筛选出那些位于 ISR 集合中，或者与 leader 副本之间同步时间间隔位于 `replica.lag.time.max.ms` 内的副本，当这些副本中最小的 LEO 值大于当前 leader 副本的 HW 值时，则更新 leader 副本的 HW 值。\n\nPartition 提供了 `Partition#updateReplicaLogReadResult` 方法用于更新指定 follower 副本的 LEO 值（具体通过调用 `Replica#updateLogReadResult` 方法实现），并在完成更新之后尝试调用 `Partition#maybeExpandIsr` 方法来扩张 ISR 集合，整体过程实现比较简单，不再展开。\n\nFollower 副本在与 leader 副本进行数据同步时，会将从 leader 副本获取到的 HW 值与当前副本的 LEO 值进行比对，并选择较小者作为当前 follower 副本的 HW 值。这样就产生了一个问题，即 follower 副本的 HW 值与 leader 副本的 HW 值是有差距的，当选举某个 HW 滞后的 follower 副本作为新的 leader 时需要对数据进行截断，从而存在丢失消息的风险。为此，Kafka 0.11 版本引入了 Leader Epoch 机制以解决这一问题，关于 Leader Epoch 机制我们以后再补充说明。\n\n### ReplicaManager 组件\n\nReplicaManager 类用于管理分布在当前 broker 节点上的所有分区的副本信息，主要提供了创建并获取指定 topic 分区对象、副本管理、日志数据读写、副本角色转换，以及更新当前 broker 节点缓存的整个集群中全部分区的状态信息等功能。ReplicaManager 的字段定义如下：\n\n```scala\nclass ReplicaManager(val config: KafkaConfig, // 相关配置对象\n                     metrics: Metrics,\n                     time: Time, // 时间戳工具\n                     val zkUtils: ZkUtils, // ZK 工具类\n                     scheduler: Scheduler, // 定时任务调度器\n                     val logManager: LogManager, // 用于对分区日志数据执行读写操作\n                     val isShuttingDown: AtomicBoolean, // 标记 kafka 服务是否正在执行关闭操作\n                     quotaManager: ReplicationQuotaManager,\n                     threadNamePrefix: Option[String] = None) extends Logging with KafkaMetricsGroup {\n\n    /**\n     * 记录 kafka controller 的年代信息，当重新选择 controller leader 时会递增该字段，\n     * 用于校验来自 controller 的请求的年代信息，防止处理来自老的 controller 的请求\n     */\n    @volatile var controllerEpoch: Int = KafkaController.InitialControllerEpoch - 1\n    /** 本地 broker 的 ID */\n    private val localBrokerId = config.brokerId\n    /** 记录当前 broker 管理的所有分区信息，如果不存在则创建 */\n    private val allPartitions = new Pool[TopicPartition, Partition](Some(tp => new Partition(tp.topic, tp.partition, time, this)))\n    /** 管理向 leader 副本发送 FetchRequest 请求的 ReplicaFetcherThread 线程 */\n    val replicaFetcherManager = new ReplicaFetcherManager(config, this, metrics, time, threadNamePrefix, quotaManager)\n    /** 标记 highwatermark-checkpoint 定时任务是否已经启动 */\n    private val highWatermarkCheckPointThreadStarted = new AtomicBoolean(false)\n    /** 记录每个 log 目录与对应 topic 分区 HW 值的映射关系 */\n    val highWatermarkCheckpoints: Predef.Map[String, OffsetCheckpoint] = config.logDirs.map(dir =>\n        (new File(dir).getAbsolutePath, new OffsetCheckpoint(new File(dir, ReplicaManager.HighWatermarkFilename)))).toMap\n    /** 标记 highwatermark-checkpoint 定时任务是否已经启动 */\n    private var hwThreadInitialized = false\n    /** 记录 ISR 集合发生变化的 topic 分区信息 */\n    private val isrChangeSet: mutable.Set[TopicPartition] = new mutable.HashSet[TopicPartition]()\n    private val lastIsrChangeMs = new AtomicLong(System.currentTimeMillis())\n    private val lastIsrPropagationMs = new AtomicLong(System.currentTimeMillis())\n    /** 管理 DelayedProduce 延时任务的炼狱 */\n    val delayedProducePurgatory: DelayedOperationPurgatory[DelayedProduce] = DelayedOperationPurgatory[DelayedProduce](\n        purgatoryName = \"Produce\", localBrokerId, config.producerPurgatoryPurgeIntervalRequests)\n    /** 管理 DelayedFetch 延时任务的炼狱 */\n    val delayedFetchPurgatory: DelayedOperationPurgatory[DelayedFetch] = DelayedOperationPurgatory[DelayedFetch](\n        purgatoryName = \"Fetch\", localBrokerId, config.fetchPurgatoryPurgeIntervalRequests)\n\n        // ... 省略相关方法定义\n\n}\n```\n\nKafka 服务在启动时会创建 ReplicaManager 对象，并调用 `ReplicaManager#startup` 方法启动 ReplicaManager 管理的定时任务，即 isr-expiration 和 isr-change-propagation 定时任务。实现如下：\n\n```scala\ndef startup() {\n    // 定时检测当前 broker 节点管理的每个分区是否需要缩减 ISR 集合，并执行缩减操作\n    scheduler.schedule(\"isr-expiration\", maybeShrinkIsr, period = config.replicaLagTimeMaxMs / 2, unit = TimeUnit.MILLISECONDS)\n    // 定时将 ISR 集合发生变化的 topic 分区记录到 ZK\n    scheduler.schedule(\"isr-change-propagation\", maybePropagateIsrChanges, period = 2500L, unit = TimeUnit.MILLISECONDS)\n}\n```\n\n定时任务 isr-expiration 周期性执行 `ReplicaManager#maybeShrinkIsr` 方法，尝试缩减当前 broker 节点管理的分区对应的 ISR 集合，具体缩减操作由 `Partition#maybeShrinkIsr` 方法实现，前面已经分析过，不再重复撰述。\n\n定时任务 isr-change-propagation 周期性将 ISR 集合发生变化的 topic 副本信息更新到 ZK 相应节点下，Kafka 集群控制器基于 ZK 的 Watcher 机制监听相应节点，并在节点内容发生变化时向所有可用的 broker 节点发送 UpdateMetadataRequest 请求，以更新相应 broker 节点本地管理的整个集群中所有分区的状态信息。定时任务的执行逻辑由 `ReplicaManager#maybePropagateIsrChanges` 方法实现：\n\n```scala\ndef maybePropagateIsrChanges() {\n    val now = System.currentTimeMillis()\n    isrChangeSet synchronized {\n        // 定期将 ISR 集合发生变化的分区记录到 ZK，kafka controller 对相应 ZK 路径添加了 Watcher，\n        // 当 Watcher 被触发后会向所有可用的 broker 节点发送 UpdateMetadataRequest 请求，以更新 broker 节点缓存的所有分区状态信息\n        if (isrChangeSet.nonEmpty &&\n                // 最后一次有 ISR 集合发生变化的时间距离现在已经超过 5 秒\n                (lastIsrChangeMs.get() + ReplicaManager.IsrChangePropagationBlackOut < now\n                        // 上次写入 ZK 的时间距离现在已经超过 1 分钟\n                        || lastIsrPropagationMs.get() + ReplicaManager.IsrChangePropagationInterval < now)) {\n            // 将 ISR 集合发生变更的 topic 分区信息记录到 ZK\n            ReplicationUtils.propagateIsrChanges(zkUtils, isrChangeSet)\n            isrChangeSet.clear()\n            lastIsrPropagationMs.set(now)\n        }\n    }\n}\n```\n\n为了避免频繁操作 ZK，上述方法在设计上添加了一定的过滤条件，只有当最近一次 ISR 集合变化的时间距离现在超过 5 秒，或者距离上一次操作 ZK 已经超过 1 分钟，才允许再次操作 ZK。Kafka Controller 在成为 leader 角色时会在相应 ZK 路径上注册 Watcher 监听器，当监听到有数据变化时，会构建 UpdateMetadataRequest 请求对象发送给所有可用的 broker 节点，以更新 broker 节点本地缓存的整个集群所有分区的状态信息。\n\nReplicaManager 提供了 `ReplicaManager#maybeUpdateMetadataCache` 方法来处理 UpdateMetadataRequest 请求，方法实现如下：\n\n```scala\ndef maybeUpdateMetadataCache(correlationId: Int,\n                             updateMetadataRequest: UpdateMetadataRequest,\n                             metadataCache: MetadataCache): Seq[TopicPartition] = {\n    replicaStateChangeLock synchronized {\n        // 校验 controller 的年代信息，避免处理来自已经过期的 controller 的请求\n        if (updateMetadataRequest.controllerEpoch < controllerEpoch) {\n            val stateControllerEpochErrorMessage = (\"Broker %d received update metadata request with correlation id %d from an \" +\n                    \"old controller %d with epoch %d. Latest known controller epoch is %d\").format(localBrokerId,\n                correlationId, updateMetadataRequest.controllerId, updateMetadataRequest.controllerEpoch, controllerEpoch)\n            stateChangeLogger.warn(stateControllerEpochErrorMessage)\n            throw new ControllerMovedException(stateControllerEpochErrorMessage)\n        } else {\n            // 更新所有分区的状态信息，并返回需要被移除的分区集合\n            val deletedPartitions = metadataCache.updateCache(correlationId, updateMetadataRequest)\n            // 更新本地缓存的 controller 年代信息\n            controllerEpoch = updateMetadataRequest.controllerEpoch\n            deletedPartitions\n        }\n    }\n}\n```\n\n上述方法首先会校验当前 UpdateMetadataRequest 请求的年代信息，避免处理那些来自老的 kafka controller 的请求。对于合法的 UpdateMetadataRequest 请求，则会调用 `MetadataCache#updateCache` 方法更新所有分区的状态信息，并返回需要被移除的分区集合，同时更新本地缓存的 kafka controller 的年代信息。关于 MetadataCache 类的实现，留到后面针对性分析，这里先不展开。\n\n除了上面介绍的 2 个定时任务以外，ReplicaManager 还定义了另外一个定时任务 highwatermark-checkpoint，该任务周期性将当前 broker 节点管理的每个 topic 分区的 HW 值更新到对应 log 目录下的 replication-offset-checkpoint 文件中。相关逻辑由 `ReplicaManager#startHighWaterMarksCheckPointThread` 方法实现：\n\n```scala\ndef startHighWaterMarksCheckPointThread(): Unit = {\n    if (highWatermarkCheckPointThreadStarted.compareAndSet(false, true))\n        scheduler.schedule(\n            \"highwatermark-checkpoint\",\n            checkpointHighWatermarks,\n            period = config.replicaHighWatermarkCheckpointIntervalMs,\n            unit = TimeUnit.MILLISECONDS)\n}\n\ndef checkpointHighWatermarks() {\n    // 获取所有分区全部的本地副本 Replica 对象\n    val replicas = allPartitions.values.flatMap(_.getReplica(localBrokerId))\n    // 按照副本所在的 log 目录进行分组\n    val replicasByDir = replicas.filter(_.log.isDefined).groupBy(_.log.get.dir.getParentFile.getAbsolutePath)\n    // 遍历将位于相同 log 目录下的分区 HW 值，写入到对应的 replication-offset-checkpoint 文件中\n    for ((dir, reps) <- replicasByDir) {\n        // 获取每个 topic 分区对应的 HW 值\n        val hwms: Map[TopicPartition, Long] = reps.map(r => r.partition.topicPartition -> r.highWatermark.messageOffset).toMap\n        try {\n            // 更新对应 log 目录下的 replication-offset-checkpoint 文件\n            highWatermarkCheckpoints(dir).write(hwms)\n        } catch {\n            case e: IOException =>\n                fatal(\"Error writing to highwatermark file: \", e)\n                Runtime.getRuntime.halt(1)\n        }\n    }\n}\n```\n\n具体执行逻辑如代码注释，比较简单。该定时任务会在当前 ReplicaManager 首次收到来自 kafka controller 的 LeaderAndIsrRequest 请求时被启动。\n\n#### 消息同步机制\n\n为了支持在 topic 分区 leader 副本失效时，有新的副本可以继续对外提供服务，Kafka 为副本引入了 leader/follower 模型设计，follower 副本在平时并不负责与客户端进行交互，主要职责在于从 leader 副本同步消息数据，以备在 leader 副本失效时可以从所有符合条件的 follower 副本中选举一个新的 leader 副本，从而避免对应 topic 的长时间停车，本小节我们重点来分析一下 follower 副本从 leader 副本同步消息的操作。\n\nReplicaManager 使用 ReplicaFetcherManager 管理 follower 副本与 leader 副本的同步工作，ReplicaFetcherManager 继承自 AbstractFetcherManager 抽象类。ReplicaFetcherManager 将当前 broker 节点管理的分区对应的副本按照一定的条件进行分组，并为每个组创建一个 fetcher 线程，用于从对应 leader 副本所在的 broker 节点拉取指定 offset 的消息数据。\n\nFetcher 线程由 ReplicaFetcherThread 实现，ReplicaFetcherThread 继承自 AbstractFetcherThread 抽象类。每个 ReplicaFetcherManager 维护了一个 `HashMap[BrokerAndFetcherId, AbstractFetcherThread]` 类型的 `AbstractFetcherManager#fetcherThreadMap` 集合，用于记录每个分组对应的 fetcher 线程对象，其中 BrokerAndFetcherId 封装了目标 broker 节点的 id、host、port，以及对应 fetcher 线程 ID 等信息。\n\nReplicaFetcherManager 提供了多个方法用于管理 `AbstractFetcherManager#fetcherThreadMap` 集合，主要包括：\n\n1. `AbstractFetcherManager#addFetcherForPartitions`：将指定的待同步 topic 分区分组，并为每个分组创建并启动一个 fetcher 线程，从指定的 offset 开始与 leader 副本进行同步。\n2. `AbstractFetcherManager#removeFetcherForPartitions`：停止对指定 topic 分区集合的副本同步任务。\n3. `AbstractFetcherManager#shutdownIdleFetcherThreads`：关闭空闲的 fetcher 线程，相应线程不再为任何 topic 分区执行同步工作。\n\n上述方法中 2 和 3 在实现上都比较简单，下面重点来看一下方法 1，实现如下：\n\n```scala\ndef addFetcherForPartitions(partitionAndOffsets: Map[TopicPartition, BrokerAndInitialOffset]) {\n    mapLock synchronized {\n        val partitionsPerFetcher = partitionAndOffsets.groupBy {\n            case (topicPartition, brokerAndInitialOffset) =>\n                // 由分区所属的 topic 和分区编号计算得到对应的 fetcher 线程 ID，并与 broker 的网络位置信息组成 key，然后按 key 进行分组，\n                // 后面会为每组分配一个 fetcher 线程，每个线程只连接一个 broker，可以同时为组内多个分区的 follower 副本执行同步操作。\n                BrokerAndFetcherId(brokerAndInitialOffset.broker, this.getFetcherId(topicPartition.topic, topicPartition.partition))\n        }\n\n        // 启动所有的的 fetcher 线程，如果对应线程不存在，则创建并启动\n        for ((brokerAndFetcherId, partitionAndOffsets) <- partitionsPerFetcher) {\n            var fetcherThread: AbstractFetcherThread = null\n            fetcherThreadMap.get(brokerAndFetcherId) match {\n                case Some(f) => fetcherThread = f\n                case None =>\n                    // 创建 ReplicaFetcherThread 线程对象，并记录到 fetcherThreadMap 集合中\n                    fetcherThread = this.createFetcherThread(brokerAndFetcherId.fetcherId, brokerAndFetcherId.broker)\n                    fetcherThreadMap.put(brokerAndFetcherId, fetcherThread)\n                    fetcherThread.start() // 启动线程\n            }\n\n            // 将 topic 分区和同步起始位置传递给 fetcher 线程，并唤醒 fetcher 线程开始同步\n            fetcherThreadMap(brokerAndFetcherId).addPartitions(partitionAndOffsets.map {\n                case (tp, brokerAndInitOffset) => tp -> brokerAndInitOffset.initOffset\n            })\n        }\n    }\n}\n```\n\n上述方法首先会考虑目标 broker 节点的网络位置信息（brokerId、host 和 port）和 fetcher 线程的 ID 对待同步的 topic 分区进行分组，并以这些信息作为对应 fetcher 线程对象在 `AbstractFetcherManager#fetcherThreadMap` 集合中的 key，如果 key 对应的 fetcher 线程对象不存在则会创建并启动新的线程，同时将待同步 topic 分区的同步起始 offset 传递给对应线程，然后唤醒线程执行。创建 fetcher 线程的实现如下：\n\n```scala\noverride def createFetcherThread(fetcherId: Int, sourceBroker: BrokerEndPoint): AbstractFetcherThread = {\n    val threadName = threadNamePrefix match {\n        case None => \"ReplicaFetcherThread-%d-%d\".format(fetcherId, sourceBroker.id)\n        case Some(p) => \"%s:ReplicaFetcherThread-%d-%d\".format(p, fetcherId, sourceBroker.id)\n    }\n    new ReplicaFetcherThread(threadName, fetcherId, sourceBroker, brokerConfig, replicaMgr, metrics, time, quotaManager)\n}\n```\n\nReplicaFetcherThread 继承自 ShutdownableThread 抽象方法，所以在线程被启动之后会循环调度执行 `AbstractFetcherThread#doWork` 方法，该方法会构造 FetchRequest 请求从 leader 副本拉取指定 offset 对应的消息数据，并处理 FetchResponse 响应。方法实现如下：\n\n```scala\noverride def doWork() {\n    val fetchRequest = inLock(partitionMapLock) {\n        // 创建 FetchRequest 请求对象\n        val fetchRequest = this.buildFetchRequest(partitionStates.partitionStates.asScala.map { state =>\n            state.topicPartition -> state.value\n        })\n        // 如果没有拉取消息的需求，则等待一会后重试\n        if (fetchRequest.isEmpty) {\n            trace(\"There are no active partitions. Back off for %d ms before sending a fetch request\".format(fetchBackOffMs))\n            partitionMapCond.await(fetchBackOffMs, TimeUnit.MILLISECONDS)\n        }\n        fetchRequest\n    }\n    // 发送 FetchRequest 请求，并处理 FetchResponse 响应\n    if (!fetchRequest.isEmpty) this.processFetchRequest(fetchRequest)\n}\n```\n\n上述方法仅仅是构造了 FetchRequest 请求，而发送和处理响应的过程则由 `AbstractFetcherThread#processFetchRequest` 方法实现：\n\n```scala\nprivate def processFetchRequest(fetchRequest: REQ) {\n    val partitionsWithError = mutable.Set[TopicPartition]()\n    var responseData: Seq[(TopicPartition, PD)] = Seq.empty\n\n    // 1. 发送 FetchRequest 请求，并阻塞等待响应\n    try {\n        trace(\"Issuing to broker %d of fetch request %s\".format(sourceBroker.id, fetchRequest))\n        responseData = this.fetch(fetchRequest) // 模板方法\n    } catch {\n        // ... 省略异常处理\n    }\n    fetcherStats.requestRate.mark()\n\n    // 2. 处理响应\n    if (responseData.nonEmpty) {\n        inLock(partitionMapLock) {\n            // 遍历处理每个 topic 分区对应的响应\n            responseData.foreach { case (topicPartition, partitionData) =>\n                val topic = topicPartition.topic\n                val partitionId = topicPartition.partition\n                Option(partitionStates.stateValue(topicPartition)).foreach(currentPartitionFetchState =>\n                    // 如果从发送 FetchRequest 请求到收到响应期间，offset 没有发生变化，则追加收到的日志数据\n                    if (fetchRequest.offset(topicPartition) == currentPartitionFetchState.offset) {\n                        Errors.forCode(partitionData.errorCode) match {\n                            case Errors.NONE =>\n                                try {\n                                    // 获取返回的消息集合\n                                    val records = partitionData.toRecords\n                                    // 获取返回的最后一条消息的 offset 值\n                                    val newOffset = records.shallowEntries.asScala.lastOption.map(_.nextOffset).getOrElse(currentPartitionFetchState.offset)\n\n                                    fetcherLagStats.getAndMaybePut(topic, partitionId).lag = Math.max(0L, partitionData.highWatermark - newOffset)\n                                    // 将从 leader 副本获取到的消息追加到当前 follower 副本对应的 Log 对象中\n                                    this.processPartitionData(topicPartition, currentPartitionFetchState.offset, partitionData)\n\n                                    val validBytes = records.validBytes\n                                    if (validBytes > 0) {\n                                        // 更新本地缓存的 fetch 状态\n                                        partitionStates.updateAndMoveToEnd(topicPartition, new PartitionFetchState(newOffset))\n                                        fetcherStats.byteRate.mark(validBytes)\n                                    }\n                                } catch {\n                                    // ... 省略异常处理\n                                }\n                            // follower 请求的 offset 超出了 leader 的 LEO 值\n                            case Errors.OFFSET_OUT_OF_RANGE =>\n                                try {\n                                    // 计算有效的 offset，并更新本地缓存的 fetch 状态\n                                    val newOffset = this.handleOffsetOutOfRange(topicPartition)\n                                    partitionStates.updateAndMoveToEnd(topicPartition, new PartitionFetchState(newOffset))\n                                    error(\"Current offset %d for partition [%s,%d] out of range; reset offset to %d\".format(currentPartitionFetchState.offset, topic, partitionId, newOffset))\n                                } catch {\n                                    // ... 省略异常处理\n                                }\n                            // ... 其他异常\n                        }\n                    })\n            }\n        }\n    }\n\n    // 对于操作存在异常的 topic 分区，暂停发送 FetchRequest 请求，休息一会儿\n    if (partitionsWithError.nonEmpty) {\n        debug(\"handling partitions with error for %s\".format(partitionsWithError))\n        this.handlePartitionsWithErrors(partitionsWithError)\n    }\n}\n```\n\n由上述实现可以看到方法 `AbstractFetcherThread#processFetchRequest` 主要做了两件事情：发送 FetchRequest 请求并阻塞等待响应，以及处理响应。其中发送 FetchRequest 请求的过程由 `ReplicaFetcherThread#fetch` 方法实现，该方法使用 NetworkClient 的阻塞版本 NetworkClientBlockingOps 向目标 broker 节点发送 FetchRequest 请求，并阻塞等待响应结果，然后将针对每个 topic 分区的响应结果封装成 PartitionData 对象交由后续处理。\n\n在遍历处理对于每个 topic 分区的 FetchResponse 响应时，分为 3 种情况：\n\n1. 正常响应，拉回指定 offset 对应的消息数据。\n2. 异常响应，请求的 offset 不在 leader 副本允许的范围内。\n3. 其它异常响应。\n\n对于 __第 1 种情况__ 来说，会调用 `ReplicaFetcherThread#processPartitionData` 方法将从对应 leader 副本拉取回来的消息数据写入 follower 副本对应的 Log 对象中，并更新本地缓存的对应分区的消息同步状态信息。方法实现如下：\n\n```scala\ndef processPartitionData(topicPartition: TopicPartition, fetchOffset: Long, partitionData: PartitionData) {\n    try {\n        val replica = replicaMgr.getReplica(topicPartition).get\n        val records = partitionData.toRecords\n\n        // 如果拉取到的消息数据过大，则打印异常\n        this.maybeWarnIfOversizedRecords(records, topicPartition)\n\n        if (fetchOffset != replica.logEndOffset.messageOffset)\n            throw new RuntimeException(\"Offset mismatch for partition %s: fetched offset = %d, log end offset = %d.\".format(topicPartition, fetchOffset, replica.logEndOffset.messageOffset))\n\n        // 将消息追加到 Log 中，因为 leader 已经为消息分配了 offset，所以 follower 无需在对消息分配 offset 值\n        replica.log.get.append(records, assignOffsets = false)\n\n        // 更新对应 follower 副本的 HW 值\n        val followerHighWatermark = replica.logEndOffset.messageOffset.min(partitionData.highWatermark)\n        replica.highWatermark = new LogOffsetMetadata(followerHighWatermark)\n\n        if (quota.isThrottled(topicPartition)) quota.record(records.sizeInBytes)\n    } catch {\n        case e: KafkaStorageException =>\n            fatal(s\"Disk error while replicating data for $topicPartition\", e)\n            Runtime.getRuntime.halt(1)\n    }\n}\n```\n\n追加消息数据由对应副本持有的 Log 对象的 `Log#append` 方法完成，如果成功追加则会更新副本对应的 HW 值。\n\n如果在执行同步操作时，某个 topic 分区出现异常，则需要依据对应的异常类型分别处理，如果是除 `OFFSET_OUT_OF_RANGE` 以外的错误（对应 __第 3 种情况__ ），则会暂停到对应分区 leader 副本同步数据的请求，休整一段时间（对应 `replica.fetch.backoff.ms` 配置）之后再继续，对应 `ReplicaFetcherThread#handlePartitionsWithErrors` 方法实现，比较简单。\n\n下面来看一下 __第 2 种情况__ ，如果同步操作请求的 offset 不合法，即位于 leader 副本的 `[startOffset, LEO]` 之外，则需要修正本地缓存的对应副本的同步状态信息，修正 offset 的过程由 `ReplicaFetcherThread#handleOffsetOutOfRange` 方法实现，这里需要区分 2 种情况：\n\n1. 请求同步的 offset 大于对应 leader 副本的 LEO 值。\n2. 请求同步的 offset 小于对应 leader 副本的 startOffset 值。\n\n一般 follower 副本的 LEO 值都是小于等于 leader 副本的 LEO 值，但是如果发生以下场景（unclean leader election），则可能出现 follower 副本的 LEO 值大于 leader 副本的 LEO 值，此时如果 follower 副本请求同步 leader 副本就有可能出现请求的 offset 大于目标 leader 副本的 LEO 值的情况。这类场景的发生过程为（令场景中 follower 副本为 F）：\n\n1. F 副本失效，期间 F 所属分区的 leader 副本继续追加消息数据；\n2. F 副本失效后恢复，继续从 leader 副本同步数据，但是在追赶上 leader 副本之前，所有 ISR 集合中的副本全部失效；\n3. 为了保证 Kafka 服务的正常运行，选举 F 成为对应 topic 分区新的 leader 副本，并开始负责处理来自生产者的消息读写请求；\n4. 上一任 leader 从失效中恢复，并成为 follower 角色，此时其 LEO 值很有可能大于 F 的 LEO 值。\n\n针对这种情况简单的处理方式是将 follower 副本的消息进行截断，但是 Kafka 也提供了 `unclean.leader.election.enable` 配置，允许在发生这种情况时停服。相关实现如下：\n\n```scala\ndef handleOffsetOutOfRange(topicPartition: TopicPartition): Long = {\n    val replica = replicaMgr.getReplica(topicPartition).get\n\n    // 发送 ListOffsetRequest 请求，获取 leader 副本的 LEO 值\n    val leaderEndOffset: Long = this.earliestOrLatestOffset(topicPartition, ListOffsetRequest.LATEST_TIMESTAMP, brokerConfig.brokerId)\n\n    // 如果 leader 副本的 LEO 值落后于 follower 副本的 LEO 值\n    if (leaderEndOffset < replica.logEndOffset.messageOffset) {\n        // 依据配置（unclean.leader.election.enable）决定是否需要停机\n        if (!LogConfig.fromProps(brokerConfig.originals,\n            AdminUtils.fetchEntityConfig(replicaMgr.zkUtils, ConfigType.Topic, topicPartition.topic)).uncleanLeaderElectionEnable) {\n            // Log a fatal error and shutdown the broker to ensure that data loss does not unexpectedly occur.\n            fatal(\"Exiting because log truncation is not allowed for partition %s,\".format(topicPartition) +\n                    \" Current leader %d's latest offset %d is less than replica %d's latest offset %d\"\n                            .format(sourceBroker.id, leaderEndOffset, brokerConfig.brokerId, replica.logEndOffset.messageOffset))\n            System.exit(1)\n        }\n\n        warn(\"Replica %d for partition %s reset its fetch offset from %d to current leader %d's latest offset %d\"\n                .format(brokerConfig.brokerId, topicPartition, replica.logEndOffset.messageOffset, sourceBroker.id, leaderEndOffset))\n        // 将分区对应的 Log 截断到 leader 副本的 LEO 位置，从该位置开始重新与 leader 副本进行同步\n        replicaMgr.logManager.truncateTo(Map(topicPartition -> leaderEndOffset))\n\n        // 返回下次获取消息的 offset 位置\n        leaderEndOffset\n    } else {\n        // ... 第 2 种情况\n    }\n}\n```\n\n有时候 leader 副本的 LEO 值也会明显领先于某个 follower 副本的 LEO 值，此时 follower 请求同步 leader 副本时可能出现请求同步的 offset 小于对应 leader 副本的 startOffset 值。出现这种情况的原因一般有以下 2 种：\n\n1. follower 副本长时间失效，期间 leader 副本不断在追加新的数据，等到 follower 再次上线时，leader 副本对应 offset 位置的日志数据已被定时任务清除。\n2. 出现前面介绍的 unclean leader election 场景，follower 在执行截断操作到 HW 位置后，offset 仍然大于新 leader 的 LEO 值，此时执行同步会导致 OffsetOutOfRangeException 异常，follower 在处理该异常的期间，leader 副本因为追加了大量的数据而导致 follower 再次请求同步时，offset 小于 leader 副本的 startOffset 值。\n\n出现以上这 2 种情况只需要将 follower 同步请求同步的 offset 置为 leader 副本的 startOffset 即可，此外还需要清空 follower 副本的 Log 对象，因为其中的数据已经全部失效，没有继续保留的意义。相关实现如下：\n\n```scala\ndef handleOffsetOutOfRange(topicPartition: TopicPartition): Long = {\n    val replica = replicaMgr.getReplica(topicPartition).get\n\n    // 发送 ListOffsetRequest 请求，获取 leader 副本的 LEO 值\n    val leaderEndOffset: Long = this.earliestOrLatestOffset(topicPartition, ListOffsetRequest.LATEST_TIMESTAMP, brokerConfig.brokerId)\n\n    // 如果 leader 副本的 LEO 值落后于 follower 副本的 LEO 值\n    if (leaderEndOffset < replica.logEndOffset.messageOffset) {\n        // ... 第 1 种情况\n    } else {\n        // 发送 ListOffsetRequest 请求，获取 leader 副本的 startOffset 值\n        val leaderStartOffset: Long = this.earliestOrLatestOffset(topicPartition, ListOffsetRequest.EARLIEST_TIMESTAMP, brokerConfig.brokerId)\n        warn(\"Replica %d for partition %s reset its fetch offset from %d to current leader %d's start offset %d\"\n                .format(brokerConfig.brokerId, topicPartition, replica.logEndOffset.messageOffset, sourceBroker.id, leaderStartOffset))\n        // 选择下次获取消息的起始 offset 值\n        val offsetToFetch = Math.max(leaderStartOffset, replica.logEndOffset.messageOffset)\n        // 如果当前 leader 的 startOffset 大于对应副本的 LEO 值，则将该副本的 Log 全部截断，并创建新的 activeSegment 对象\n        if (leaderStartOffset > replica.logEndOffset.messageOffset)\n            replicaMgr.logManager.truncateFullyAndStartAt(topicPartition, leaderStartOffset)\n\n        // 返回下次获取消息的 offset 位置\n        offsetToFetch\n    }\n}\n```\n\n上述方法 `AbstractFetcherThread#handleOffsetOutOfRange` 还会在 `AbstractFetcherThread#addPartitions` 方法中被调用，该方法用于为每个 topic 分区构造合法的分区同步状态 PartitionFetchState 对象，并更新本地缓存，同时唤醒消息数据同步操作，前面分析过的 `AbstractFetcherManager#addFetcherForPartitions` 调用了该方法。实现如下：\n\n```scala\ndef addPartitions(partitionAndOffsets: Map[TopicPartition, Long]) {\n    partitionMapLock.lockInterruptibly()\n    try {\n        // 基于指定的 offset 构造每个 topic 分区合法的 PartitionFetchState 对象，忽略已经存在的 topic 分区\n        val newPartitionToState = partitionAndOffsets\n                .filter { case (tp, _) => !partitionStates.contains(tp) }\n                .map { case (tp, offset) =>\n                    // 基于指定的 offset 创建对应的 PartitionFetchState 对象，如果 offset 无效，则尝试解析得到合法的 offset 值\n                    val fetchState =\n                        if (PartitionTopicInfo.isOffsetInvalid(offset)) new PartitionFetchState(this.handleOffsetOutOfRange(tp))\n                        else new PartitionFetchState(offset)\n                    tp -> fetchState\n                }\n        // 获取并更新本地缓存的已有的 topic 分区与 PartitionFetchState 对象之间的映射关系\n        val existingPartitionToState = partitionStates.partitionStates.asScala.map { state => state.topicPartition -> state.value }.toMap\n        partitionStates.set((existingPartitionToState ++ newPartitionToState).asJava)\n        // 唤醒当前 fetcher 线程，执行同步操作\n        partitionMapCond.signalAll()\n    } finally {\n        partitionMapLock.unlock()\n    }\n}\n```\n\n该方法中调用 `AbstractFetcherThread#handleOffsetOutOfRange` 方法的目的在于当参数未指定 offset 时，利用该方法获取合法的同步 offset 值。\n\n#### 副本角色切换\n\nReplicaManager 定义了 `ReplicaManager#becomeLeaderOrFollower` 方法，用于处理来自 kafka controller 的 LeaderAndIsrRequest 请求，指导位于当前 broker 节点上的相应分区副本的角色切换工作。方法实现如下：\n\n```scala\ndef becomeLeaderOrFollower(correlationId: Int,\n                           leaderAndISRRequest: LeaderAndIsrRequest,\n                           metadataCache: MetadataCache,\n                           onLeadershipChange: (Iterable[Partition], Iterable[Partition]) => Unit): BecomeLeaderOrFollowerResult = {\n\n    replicaStateChangeLock synchronized {\n        // 用于记录每个分区角色切换操作的状态码\n        val responseMap = new mutable.HashMap[TopicPartition, Short]\n        // 校验 controller 的年代信息，避免处理来自已经过期的 controller 的请求\n        if (leaderAndISRRequest.controllerEpoch < controllerEpoch) {\n            BecomeLeaderOrFollowerResult(responseMap, Errors.STALE_CONTROLLER_EPOCH.code)\n        } else {\n            val controllerId = leaderAndISRRequest.controllerId\n            // 1. 更新本地缓存的 kafka controller 的年代信息\n            controllerEpoch = leaderAndISRRequest.controllerEpoch\n\n            // 2. 校验请求的 leader 副本的年代信息，以及是否由当前 broker 节点管理，将满足条件的分区信息记录到 partitionState 集合中\n            val partitionState = new mutable.HashMap[Partition, PartitionState]()\n            leaderAndISRRequest.partitionStates.asScala.foreach { case (topicPartition, stateInfo) =>\n                // 获取/创建指定 topic 分区的 Partition 对象\n                val partition = this.getOrCreatePartition(topicPartition)\n                // 获取 leader 副本的年代信息\n                val partitionLeaderEpoch = partition.getLeaderEpoch\n                // 校验 leader 副本的年代信息，需要保证请求中的 leader 副本的年代信息大于本地缓存的 topic 分区 leader 副本的年代信息\n                if (partitionLeaderEpoch < stateInfo.leaderEpoch) {\n                    // 如果请求的分区副本位于当前 broker 节点上，记录到 partitionState 集合中\n                    if (stateInfo.replicas.contains(localBrokerId))\n                        partitionState.put(partition, stateInfo)\n                    else {\n                        // 请求的分区副本不在当前 broker 节点上，响应 UNKNOWN_TOPIC_OR_PARTITION 错误\n                        responseMap.put(topicPartition, Errors.UNKNOWN_TOPIC_OR_PARTITION.code)\n                    }\n                } else {\n                    // 请求中的 leader 副本的年代信息小于等于本地记录的对应 topic 分区 leader 副本的年代信息，响应 STALE_CONTROLLER_EPOCH 错误\n                    responseMap.put(topicPartition, Errors.STALE_CONTROLLER_EPOCH.code)\n                }\n            }\n\n            // 3. 将请求对象中的分区集合分割成 leader 和 follower 两类，并执行角色切换\n            val partitionsTobeLeader = partitionState.filter { case (_, stateInfo) => stateInfo.leader == localBrokerId }\n            val partitionsToBeFollower = partitionState -- partitionsTobeLeader.keys\n\n            // 3.1 将指定分区的副本切换成 leader 角色\n            val partitionsBecomeLeader = if (partitionsTobeLeader.nonEmpty)\n                                             this.makeLeaders(controllerId, controllerEpoch, partitionsTobeLeader, correlationId, responseMap)\n                                         else\n                                             Set.empty[Partition]\n\n            // 3.2 将指定分区的副本切换成 follower 角色\n            val partitionsBecomeFollower = if (partitionsToBeFollower.nonEmpty)\n                                               this.makeFollowers(controllerId, controllerEpoch, partitionsToBeFollower, correlationId, responseMap, metadataCache)\n                                           else\n                                               Set.empty[Partition]\n\n            // 4. 如果 highwatermark-checkpoint 定时任务尚未启动，则执行启动\n            if (!hwThreadInitialized) {\n                this.startHighWaterMarksCheckPointThread()\n                hwThreadInitialized = true\n            }\n\n            // 5. 关闭空闲的 fetcher 线程\n            replicaFetcherManager.shutdownIdleFetcherThreads()\n\n            // 6. 执行回调函数，完成 GroupCoordinator 的迁移操作\n            onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)\n\n            // 7. 封装结果对象返回\n            BecomeLeaderOrFollowerResult(responseMap, Errors.NONE.code)\n        }\n    }\n}\n```\n\n副本角色切换的整体执行流程可以概括为：\n\n1. 更新本地缓存的 kafka controller 的年代信息；\n2. 校验请求的合法性，确保请求操作对应的分区 leader 副本年代信息合法，以及请求操作的分区副本位于当前 broker 节点上；\n3. 对请求的分区副本按照角色分类，并执行角色切换；\n4. 如果 highwatermark-checkpoint 定时任务尚未启动，则执行启动；\n5. 关闭空闲的副本数据同步 fetcher 线程；\n6. 因为副本角色发生变化，可能影响消费者的消费操作，尝试执行 GroupCoordinator 迁移操作；\n7. 封装响应结果返回。\n\n上面的步骤中我们重点来看一下步骤 3，关于 GroupCoordinator 将留到后面的篇章中针对性分析。步骤 3 首先会将待处理的副本集合按照角色分为 leader 和 follower 两组，然后针对 leader 分组调用 `ReplicaManager#makeLeaders` 方法将对应的分区切换成 leader 角色，调用 `ReplicaManager#makeFollowers` 方法将对应的分区切换成 follower 角色。\n\n方法 `ReplicaManager#makeLeaders` 的实现如下：\n\n```scala\nprivate def makeLeaders(controllerId: Int,\n                        epoch: Int,\n                        partitionState: Map[Partition, PartitionState], // 记录需要切换成 leader 角色的分区副本信息\n                        correlationId: Int,\n                        responseMap: mutable.Map[TopicPartition, Short]): Set[Partition] = {\n\n    // 初始化每个 topic 分区的错误码为 NONE\n    for (partition <- partitionState.keys)\n        responseMap.put(partition.topicPartition, Errors.NONE.code)\n\n    val partitionsToMakeLeaders: mutable.Set[Partition] = mutable.Set()\n    try {\n        // 如果对应的副本当前是 follower 角色，需要要先停止这些副本的消息同步工作\n        replicaFetcherManager.removeFetcherForPartitions(partitionState.keySet.map(_.topicPartition))\n\n        // 遍历处理 partitionState 集合，将其中记录的分区转换成 leader 角色\n        partitionState.foreach {\n            case (partition, partitionStateInfo) =>\n                // 调用 Partition#makeLeader 方法，将分区的本地副本切换成 leader 角色\n                if (partition.makeLeader(controllerId, partitionStateInfo, correlationId))\n                    partitionsToMakeLeaders += partition // 记录成功完成 leader 角色切换的副本对应的分区\n                else\n                    // ... 省略日志打点\n        }\n    } catch {\n        // ... 省略异常处理\n    }\n\n    partitionsToMakeLeaders\n}\n```\n\n切换副本角色为 leader 的过程比较简单，首先停止这些待切换 follower 副本的数据同步 fetcher 线程，然后调用 `Partition#makeLeader` 方法逐个将副本切换成 leader 角色，该方法已在前面分析过，不再重复撰述。\n\n方法 `ReplicaManager#makeFollowers` 的实现如下：\n\n```scala\nprivate def makeFollowers(controllerId: Int,\n                          epoch: Int,\n                          partitionState: Map[Partition, PartitionState],\n                          correlationId: Int,\n                          responseMap: mutable.Map[TopicPartition, Short],\n                          metadataCache: MetadataCache): Set[Partition] = {\n\n    // 初始化每个 topic 分区的错误码为 NONE\n    for (partition <- partitionState.keys)\n        responseMap.put(partition.topicPartition, Errors.NONE.code)\n\n    val partitionsToMakeFollower: mutable.Set[Partition] = mutable.Set()\n    try {\n        partitionState.foreach {\n            case (partition, partitionStateInfo) =>\n                // 检测 leader 副本所在的 broker 是否可用\n                val newLeaderBrokerId = partitionStateInfo.leader\n                metadataCache.getAliveBrokers.find(_.id == newLeaderBrokerId) match {\n                    // 仅对 leader 副本所在 broker 节点可用的副本执行角色切换\n                    case Some(_) =>\n                        // 调用 Partition#makeFollower 方法，将分区的本地副本切换成 follower 角色\n                        if (partition.makeFollower(controllerId, partitionStateInfo, correlationId))\n                            partitionsToMakeFollower += partition // 记录成功完成 follower 角色切换的副本对应的分区\n                        else\n                            // ... 省略日志打点\n                    // 对应 leader 副本所在的 broker 节点失效\n                    case None =>\n                        // 即使 leader 副本所在的 broker 不可用，也要创建本地副本对象，主要是为了在 checkpoint 文件中记录此分区的 HW 值\n                        partition.getOrCreateReplica()\n                }\n        }\n\n        // 停止与旧的 leader 副本同步的 fetcher 线程\n        replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))\n\n        // 由于 leader 副本发生变化，所以新旧 leader 在 [HW, LEO] 之间的消息可能不一致，\n        // 但是 HW 之前的消息是一致的，所以将 Log 截断到 HW 位置，可能会出现 unclean leader election 的场景\n        logManager.truncateTo(partitionsToMakeFollower.map { partition =>\n            (partition.topicPartition, partition.getOrCreateReplica().highWatermark.messageOffset)\n        }.toMap)\n\n        // 尝试完成监听对应分区的 DelayedProduce 和 DelayedFetch 延时任务\n        partitionsToMakeFollower.foreach { partition =>\n            val topicPartitionOperationKey = new TopicPartitionOperationKey(partition.topicPartition)\n            this.tryCompleteDelayedProduce(topicPartitionOperationKey)\n            this.tryCompleteDelayedFetch(topicPartitionOperationKey)\n        }\n\n        // 检测 ReplicaManager 的运行状态\n        if (isShuttingDown.get()) {\n            // ... 省略日志打点\n        }\n        // 重新启用与新 leader 副本同步的 fetcher 线程\n        else {\n            val partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map(partition =>\n                partition.topicPartition -> BrokerAndInitialOffset(\n                    metadataCache.getAliveBrokers.find(_.id == partition.leaderReplicaIdOpt.get).get.getBrokerEndPoint(config.interBrokerListenerName),\n                    partition.getReplica().get.logEndOffset.messageOffset)).toMap\n            // 为需要同步的分区创建并启动同步线程，从指定的 offset 开始与 leader 副本进行同步\n            replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)\n        }\n    } catch {\n        // ... 省略异常处理\n    }\n\n    partitionsToMakeFollower\n}\n```\n\n切换副本为 follower 角色的过程相对要复杂一些，整体执行流程可以概括为：\n\n1. 检测对应新的 leader 副本所在 broker 节点是否可用，如果不可用则无需执行切换操作，否则调用 `Partition#makeFollower` 方法执行副本角色切换；\n2. 停止待切换副本的数据同步 fetcher 线程；\n3. 由于 leader 副本发生变化，新旧 leader 在 `[HW, LEO]` 之间的数据可能不一致，所以需要将当前副本截断到 HW 位置，以保证数据一致性；\n4. 尝试完成监听对应分区的 DelayedProduce 和 DelayedFetch 延时任务；\n5. 为新的 follower 副本集合创建并启动对应的数据同步 fetcher 线程（如果已存在，则复用）。\n\n上述过程中涉及到的相关方法已经在前面分析过，不再重复撰述。\n\n#### 分区与副本管理\n\nReplicaManager 定义了 `ReplicaManager#getOrCreatePartition` 方法和 `ReplicaManager#getPartition` 方法用于获取本地缓存的指定 topic 分区的 Partition 对象，二者的区别在于前者会在本地检索不到目标 topic 分区时创建对应的 Partition 对象。同时，ReplicaManager 还提供了 `ReplicaManager#getReplicaOrException`、`ReplicaManager#getLeaderReplicaIfLocal`，以及 `ReplicaManager#getReplica` 方法用于获取指定 topic 分区的指定副本对象，实现上都比较简单，不展开分析。\n\n下面来重点看一下关闭副本的 `ReplicaManager#stopReplicas` 方法实现，当 broker 节点收到来自 kafka controller 的 StopReplicaRequest 请求时，会关闭指定的副本，包括停止副本的数据同步 fetcher 线程，以及依据参数决定是否删除副本对应的 Log 对象和文件，并清空本地缓存的相关信息。方法实现如下：\n\n```scala\ndef stopReplicas(stopReplicaRequest: StopReplicaRequest): (mutable.Map[TopicPartition, Short], Short) = {\n    replicaStateChangeLock synchronized {\n        val responseMap = new collection.mutable.HashMap[TopicPartition, Short]\n        // 校验 controller 的年代信息，避免处理来自已经过期的 controller 的请求\n        if (stopReplicaRequest.controllerEpoch() < controllerEpoch) {\n            (responseMap, Errors.STALE_CONTROLLER_EPOCH.code)\n        } else {\n            val partitions = stopReplicaRequest.partitions.asScala\n            // 更新本地记录的 kafka controller 的年代信息\n            controllerEpoch = stopReplicaRequest.controllerEpoch\n            // 停止对指定分区的数据同步 fetcher 线程\n            replicaFetcherManager.removeFetcherForPartitions(partitions)\n            for (topicPartition <- partitions) {\n                // 关闭指定分区的副本\n                val errorCode = this.stopReplica(topicPartition, stopReplicaRequest.deletePartitions())\n                responseMap.put(topicPartition, errorCode)\n            }\n            (responseMap, Errors.NONE.code)\n        }\n    }\n}\n\ndef stopReplica(topicPartition: TopicPartition, deletePartition: Boolean): Short = {\n    val errorCode = Errors.NONE.code\n    getPartition(topicPartition) match {\n        case Some(_) =>\n            // 如果 deletePartition = true，则删除分区对应的副本及其日志和索引文件\n            if (deletePartition) {\n                // 从本地移除指定的 topic 分区\n                val removedPartition = allPartitions.remove(topicPartition)\n                if (removedPartition != null) {\n                    // 删除分区的日志和索引文件，并清空本地缓存的相关信息\n                    removedPartition.delete() // this will delete the local log\n                    val topicHasPartitions = allPartitions.keys.exists(tp => topicPartition.topic == tp.topic)\n                    if (!topicHasPartitions) BrokerTopicStats.removeMetrics(topicPartition.topic)\n                }\n            }\n        // 本地未缓存对应的分区（一般发生在对应的 topic 已经被删除，但是期间 broker 宕机了），直接尝试对应的删除日志和索引文件\n        case None =>\n            if (deletePartition && logManager.getLog(topicPartition).isDefined) logManager.asyncDelete(topicPartition)\n    }\n    errorCode\n}\n```\n\n如果在 StopReplicaRequest 请求中指明了要删除对应 topic 分区的日志和索引文件，则方法会调用 `Partition#delete` 方法执行删除操作，并清空本地缓存的相关信息。如果某个 broker 节点在宕机中恢复后，之前管理的 topic 分区很可能已经被分配到新的 broker 节点上，此时该 broker 节点已经不再管理相应的 topic 分区对象，如果收到相应的 StopReplicaRequest 请求，则仍然会调用 `LogManager#asyncDelete` 方法尝试删除之前遗留的日志文件和索引文件。\n\n#### 日志数据读写\n\nReplicaManager 提供了 `ReplicaManager#appendRecords` 方法，用于处理 ProduceRequest 请求，将给定的日志数据追加到对应 topic 分区的 leader 副本中。方法实现如下：\n\n```scala\ndef appendRecords(timeout: Long,\n                  requiredAcks: Short,\n                  internalTopicsAllowed: Boolean,\n                  entriesPerPartition: Map[TopicPartition, MemoryRecords],\n                  responseCallback: Map[TopicPartition, PartitionResponse] => Unit) {\n\n    // 如果 acks 参数合法\n    if (this.isValidRequiredAcks(requiredAcks)) {\n        val sTime = time.milliseconds\n        // 将消息追加到 Log 对象中\n        val localProduceResults = this.appendToLocalLog(internalTopicsAllowed, entriesPerPartition, requiredAcks)\n        debug(\"Produce to local log in %d ms\".format(time.milliseconds - sTime))\n\n        // 封装数据追加结果\n        val produceStatus = localProduceResults.map { case (topicPartition, result) =>\n            topicPartition -> ProducePartitionStatus(\n                result.info.lastOffset + 1, // 下一次请求日志的 offset 值\n                new PartitionResponse(result.error, result.info.firstOffset, result.info.logAppendTime)) // response status\n        }\n\n        // 如果需要生成 DelayedProduce 延时任务\n        if (this.delayedRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) {\n            // 创建 DelayedProduce 延时任务对象，将回调响应函数封装到延时任务对象中\n            val produceMetadata = ProduceMetadata(requiredAcks, produceStatus)\n            val delayedProduce = new DelayedProduce(timeout, produceMetadata, this, responseCallback)\n\n            // 创建当前延时任务监听的一系列 key 对象，监听本次追加操作的所有 topic 分区\n            val producerRequestKeys = entriesPerPartition.keys.map(new TopicPartitionOperationKey(_)).toSeq\n\n            // 尝试执行延时任务，如果还未到期则将任务交由炼狱管理\n            delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)\n        } else {\n            // 无需生成 DelayedProduce 延时任务，立即响应\n            val produceResponseStatus = produceStatus.mapValues(status => status.responseStatus)\n            responseCallback(produceResponseStatus)\n        }\n    } else {\n        // 对应的 acks 参数错误，构造 INVALID_REQUIRED_ACKS 响应\n        val responseStatus = entriesPerPartition.map { case (topicPartition, _) =>\n            topicPartition -> new PartitionResponse(\n                Errors.INVALID_REQUIRED_ACKS, LogAppendInfo.UnknownLogAppendInfo.firstOffset, Record.NO_TIMESTAMP)\n        }\n        // 回调响应\n        responseCallback(responseStatus)\n    }\n}\n```\n\n如果请求的 acks 参数合法，则会调用 `ReplicaManager#appendToLocalLog` 方法往相应 leader 副本对应的 Log 对象中追加日志数据，并依据以下条件决定是否延时响应：\n\n1. acks 参数为 -1，表示需要 ISR 集合中全部的 follower 副本确认追加的消息数据；\n2. 请求添加的消息数据不为空；\n3. 至少有一个 topic 分区的消息追加成功。\n\n如果上面 3 个条件同时满足，则方法会创建对应的 DelayedProduce 延时任务对象，并交由相应的炼狱进行管理。DelayedProduce 对象封装了响应回调函数（即 `KafkaApis#handleProducerRequest` 方法中定义的 sendResponseCallback 方法），当 ISR 集合中所有的 follower 副本完成对本次追加的日志数据的同步操作之后会触发响应操作，这里延时任务监听的 key 是 topic 分区对象，当某个 topic 分区完成消息追加操作时可以提前触发延时任务执行。关于 DelayedProduce 延时任务我们已经在前面分析过，读者可以将上述逻辑与上一篇中对 DelayedProduce 的分析结合起来进一步加深理解。\n\n方法 `ReplicaManager#appendToLocalLog` 的实现如下：\n\n```scala\nprivate def appendToLocalLog(internalTopicsAllowed: Boolean, // 是否允许往内部 topic 追加消息\n                             entriesPerPartition: Map[TopicPartition, MemoryRecords], // 对应分区需要追加的消息数据\n                             requiredAcks: Short // acks\n                            ): Map[TopicPartition, LogAppendResult] = {\n\n    // 遍历处理每个 topic 分区及其待追加的消息数据\n    entriesPerPartition.map { case (topicPartition, records) =>\n        // 如果追加的对象是内部 topic，依据参数 internalTopicsAllowed 决定是否追加\n        if (Topic.isInternal(topicPartition.topic) && !internalTopicsAllowed) {\n            (topicPartition, LogAppendResult(\n                LogAppendInfo.UnknownLogAppendInfo,\n                Some(new InvalidTopicException(s\"Cannot append to internal topic ${topicPartition.topic}\"))))\n        } else {\n            try {\n                // 获取 topic 分区对应的 Partition 对象\n                val partitionOpt = this.getPartition(topicPartition)\n                val info = partitionOpt match {\n                    // 往 leader 副本对应的 Log 对象中追加消息数据\n                    case Some(partition) => partition.appendRecordsToLeader(records, requiredAcks)\n                    // 找不到 topic 分区对应的 Partition 对象\n                    case None => throw new UnknownTopicOrPartitionException(\"Partition %s doesn't exist on %d\".format(topicPartition, localBrokerId))\n                }\n\n                // 返回每个分区写入的消息结果\n                (topicPartition, LogAppendResult(info))\n            } catch {\n                // ... 省略异常处理\n            }\n        }\n    }\n}\n```\n\n上述方法最终调用了 `Partition#appendRecordsToLeader` 方法将消息数据追加到指定 topic 分区的 leader 副本中。\n\nReplicaManager 定义了 `ReplicaManager#fetchMessages` 方法，用于处理来自消费者或 follower 副本读取消息数据的 FetchRequest 请求。方法实现如下：\n\n```scala\ndef fetchMessages(timeout: Long,\n                  replicaId: Int,\n                  fetchMinBytes: Int,\n                  fetchMaxBytes: Int,\n                  hardMaxBytesLimit: Boolean,\n                  fetchInfos: Seq[(TopicPartition, PartitionData)],\n                  quota: ReplicaQuota = UnboundedQuota,\n                  responseCallback: Seq[(TopicPartition, FetchPartitionData)] => Unit) {\n    // 标记是否是来自 follower 的 fetch 请求\n    val isFromFollower = replicaId >= 0\n    // 是否只读 leader 副本的消息，一般 debug 模式下可以读 follower 副本的数据\n    val fetchOnlyFromLeader: Boolean = replicaId != Request.DebuggingConsumerId\n    // 是否只读已完成提交的消息（即 HW 之前的消息），如果是来自消费者的请求则该参数是 true，如果是 follower 则该参数是 false\n    val fetchOnlyCommitted: Boolean = !Request.isValidBrokerId(replicaId)\n\n    // 读取指定位置和大小的消息数据\n    val logReadResults = this.readFromLocalLog(\n        replicaId = replicaId,\n        fetchOnlyFromLeader = fetchOnlyFromLeader,\n        readOnlyCommitted = fetchOnlyCommitted,\n        fetchMaxBytes = fetchMaxBytes,\n        hardMaxBytesLimit = hardMaxBytesLimit,\n        readPartitionInfo = fetchInfos,\n        quota = quota)\n\n    // 如果当前是来自 follower 的同步消息数据请求，则更新 follower 副本的状态，\n    // 并尝试扩张 ISR 集合，同时尝试触发监听对应 topic 分区的 DelayedProduce 延时任务\n    if (Request.isValidBrokerId(replicaId))\n        this.updateFollowerLogReadResults(replicaId, logReadResults)\n\n    val logReadResultValues = logReadResults.map { case (_, v) => v }\n    val bytesReadable = logReadResultValues.map(_.info.records.sizeInBytes).sum\n    val errorReadingData = logReadResultValues.foldLeft(false)(\n        (errorIncurred, readResult) => errorIncurred || (readResult.error != Errors.NONE))\n\n    if (timeout <= 0 // 请求希望立即响应\n            || fetchInfos.isEmpty // 请求不期望有响应数据\n            || bytesReadable >= fetchMinBytes // 已经有足够的数据可以响应\n            || errorReadingData) { // 读取数据出现错误\n        val fetchPartitionData = logReadResults.map { case (tp, result) =>\n            tp -> FetchPartitionData(result.error, result.hw, result.info.records)\n        }\n        // 立即响应\n        responseCallback(fetchPartitionData)\n    } else {\n        // 构造 DelayedFetch 延时任务\n        val fetchPartitionStatus = logReadResults.map { case (topicPartition, result) =>\n            val fetchInfo = fetchInfos.collectFirst {\n                case (tp, v) if tp == topicPartition => v\n            }.getOrElse(sys.error(s\"Partition $topicPartition not found in fetchInfos\"))\n            (topicPartition, FetchPartitionStatus(result.info.fetchOffsetMetadata, fetchInfo))\n        }\n        val fetchMetadata = FetchMetadata(fetchMinBytes, fetchMaxBytes, hardMaxBytesLimit,\n            fetchOnlyFromLeader, fetchOnlyCommitted, isFromFollower, replicaId, fetchPartitionStatus)\n        val delayedFetch = new DelayedFetch(timeout, fetchMetadata, this, quota, responseCallback)\n\n        // 构造延时任务关注的 key，即相应的 topic 分区对象\n        val delayedFetchKeys = fetchPartitionStatus.map { case (tp, _) => new TopicPartitionOperationKey(tp) }\n\n        // 交由炼狱管理\n        delayedFetchPurgatory.tryCompleteElseWatch(delayedFetch, delayedFetchKeys)\n    }\n}\n```\n\n从指定 topic 分区 leader 副本拉取消息的整体执行流程如下：\n\n1. 从本地副本读取指定位置和大小的消息数据；\n2. 如果是来自 follower 副本的请求，则更新对应的 follower 副本的状态信息，并尝试扩张对应 topic 分区的 ISR 集合，同时尝试执行监听该分区的 DelayedProduce 延时任务；\n3. 判定是否需要对请求方进行立即响应，如果需要则立即触发响应回调函数；\n4. 否则，构造 DelayedFetch 延时任务，监听对应的 topic 分区对象，并交由炼狱管理。\n\n下面对上述各个步骤逐一进行分析，首先来看 __步骤 1__ ，对应 `ReplicaManager#readFromLocalLog` 方法，实现了从本地读取指定 topic 分区相应位置和大小的消息数据的功能，具体的消息数据读操作由 `Log#read` 方法实现。方法 `ReplicaManager#readFromLocalLog` 实现如下：\n\n```scala\ndef readFromLocalLog(replicaId: Int, // 请求的 follower 副本 ID\n                     fetchOnlyFromLeader: Boolean, // 是否只读 leader 副本的消息，一般 debug 模式下可以读 follower 副本的数据\n                     readOnlyCommitted: Boolean, // 是否只读已完成提交的消息（即 HW 之前的消息），如果是来自消费者的请求则该参数是 true，如果是 follower 则该参数是 false\n                     fetchMaxBytes: Int, // 最大 fetch 字节数\n                     hardMaxBytesLimit: Boolean,\n                     readPartitionInfo: Seq[(TopicPartition, PartitionData)], // 每个分区读取的起始 offset 和最大字节数\n                     quota: ReplicaQuota): Seq[(TopicPartition, LogReadResult)] = {\n\n    def read(tp: TopicPartition, fetchInfo: PartitionData, limitBytes: Int, minOneMessage: Boolean): LogReadResult = {\n        val offset = fetchInfo.offset\n        val partitionFetchSize = fetchInfo.maxBytes\n        try {\n            // 获取待读取消息的副本对象，一般都是从本地副本读取（debug 模式除外）\n            val localReplica = if (fetchOnlyFromLeader) getLeaderReplicaIfLocal(tp) else getReplicaOrException(tp)\n            // 计算读取消息的 offset 上界，如果是来自消费者的请求，则上界为 HW，如果是来自 follower 的请求，则上界为 LEO\n            val maxOffsetOpt = if (readOnlyCommitted) Some(localReplica.highWatermark.messageOffset) else None\n            val initialLogEndOffset = localReplica.logEndOffset.messageOffset // LEO\n            val initialHighWatermark = localReplica.highWatermark.messageOffset // HW\n            val fetchTimeMs = time.milliseconds\n            val logReadInfo = localReplica.log match {\n                case Some(log) =>\n                    val adjustedFetchSize = math.min(partitionFetchSize, limitBytes)\n                    // 从 Log 中读取消息数据\n                    val fetch = log.read(offset, adjustedFetchSize, maxOffsetOpt, minOneMessage)\n\n                    // 限流检测\n                    if (shouldLeaderThrottle(quota, tp, replicaId)) FetchDataInfo(fetch.fetchOffsetMetadata, MemoryRecords.EMPTY)\n                    // For FetchRequest version 3, we replace incomplete message sets with an empty one as consumers can make\n                    // progress in such cases and don't need to report a `RecordTooLargeException`\n                    else if (!hardMaxBytesLimit && fetch.firstEntryIncomplete) FetchDataInfo(fetch.fetchOffsetMetadata, MemoryRecords.EMPTY)\n                    else fetch\n\n                // 对应副本的 Log 对象不存在\n                case None =>\n                    error(s\"Leader for partition $tp does not have a local log\")\n                    FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY)\n            }\n\n            // 封装结果返回\n            LogReadResult(info = logReadInfo,\n                hw = initialHighWatermark,\n                leaderLogEndOffset = initialLogEndOffset,\n                fetchTimeMs = fetchTimeMs,\n                readSize = partitionFetchSize,\n                exception = None)\n        } catch {\n            // ... 省略异常处理\n        }\n    } // ~ end of read\n\n    var limitBytes = fetchMaxBytes\n    val result = new mutable.ArrayBuffer[(TopicPartition, LogReadResult)]\n    var minOneMessage = !hardMaxBytesLimit\n    // 遍历读取每个 topic 分区的消息数据\n    readPartitionInfo.foreach {\n        case (tp, fetchInfo) =>\n            val readResult = read(tp, fetchInfo, limitBytes, minOneMessage)\n            val messageSetSize = readResult.info.records.sizeInBytes\n            if (messageSetSize > 0) minOneMessage = false\n            limitBytes = math.max(0, limitBytes - messageSetSize)\n            result += (tp -> readResult)\n    }\n    result\n}\n```\n\n如果本次请求是由 follower 副本发起，则会执行 `ReplicaManager#updateFollowerLogReadResults` 方法（ __步骤 2__ ），该方法主要做了以下 4 件事情：\n\n1. 更新指定 follower 副本的状态信息（包括 LEO 值、最近一次成功从 leader 拉取消息的时间戳等）；\n2. 尝试扩张副本所属分区的 ISR 集合，因为 follower 的 LEO 值递增，可能已经符合加入 ISR 集合的条件；\n3. 因为有新的消息被成功追加，尝试后移对应 leader 副本的 HW 值；\n4. 尝试执行监听对应 topic 分区的 DelayedProduce 延时任务。\n\n方法 `ReplicaManager#updateFollowerLogReadResults` 的实现如下：\n\n```scala\nprivate def updateFollowerLogReadResults(replicaId: Int, readResults: Seq[(TopicPartition, LogReadResult)]) {\n    debug(\"Recording follower broker %d log read results: %s \".format(replicaId, readResults))\n    // 遍历处理对应 topic 分区的日志数据读取结果\n    readResults.foreach {\n        case (topicPartition, readResult) =>\n            getPartition(topicPartition) match {\n                case Some(partition) =>\n                    // 更新指定 follower 副本的状态，并尝试扩张对应分区的 ISR 集合，以及后移 leader 副本的 HW 值\n                    partition.updateReplicaLogReadResult(replicaId, readResult)\n                    // 尝试执行 DelayedProduce 延时任务，因为此时对应 topic 分区下已经有新的消息成功写入\n                    this.tryCompleteDelayedProduce(new TopicPartitionOperationKey(topicPartition))\n                case None =>\n                    warn(\"While recording the replica LEO, the partition %s hasn't been created.\".format(topicPartition))\n            }\n    }\n}\n```\n\n__步骤 3__ 会判定是否需要立即响应当前拉取消息的 FetchRequest 请求，如果满足以下条件之一则执行回调函数，立即响应请求：\n\n1. 请求指定期望立即响应。\n2. 请求不期望有响应数据。\n3. 当前已经有足够的响应数据。\n4. 读取日志数据期间出错。\n\n如果满足以上条件之一，则会立即触发执行回调函数（即 `KafkaApis#handleFetchRequest` 方法中定义的 sendResponseCallback 方法）响应请求，该函数已经在前面分析过，不再重复撰述。否则会构造 DelayedFetch 延时任务，并交由相应的炼狱进行管理（ __步骤 4__ ）。\n\n#### 集群分区状态管理\n\nKafka 的所有 broker 节点在本地均使用 MetadataCache 缓存整个集群上所有 topic 分区的状态信息，并由 kafka controller 通过 UpdateMetadataRequest 请求进行维护。MetadataCache 的字段定义如下：\n\n```scala\nprivate[server] class MetadataCache(brokerId: Int) extends Logging {\n\n    /** 缓存每个分区的状态信息 */\n    private val cache = mutable.Map[String, mutable.Map[Int, PartitionStateInfo]]() // [topic, [分区 ID, 分区状态信息]]\n    /** kafka controller leader 的 ID */\n    private var controllerId: Option[Int] = None\n    /** 记录当前可用的 broker 信息 */\n    private val aliveBrokers = mutable.Map[Int, Broker]()\n    /** 记录当前可用的 broker 节点信息 */\n    private val aliveNodes = mutable.Map[Int, collection.Map[ListenerName, Node]]()\n\n    // ... 省略方法定义\n\n}\n```\n\nReplicaManager 提供了 `ReplicaManager#maybeUpdateMetadataCache` 方法用于处理 UpdateMetadataRequest 请求，该方法首先会校验请求中 kafka controller 的年代信息，以避免处理来自已经过期的 kafka controller 的请求，对于合法的请求则会调用 `MetadataCache#updateCache` 方法更新本地缓存的整个集群的 topic 分区状态信息。前面我们已经分析了 `ReplicaManager#maybeUpdateMetadataCache` 方法，但对于其中调用的 `MetadataCache#updateCache` 方法未展开分析，这里我们继续分析一下该方法的实现：\n\n```scala\ndef updateCache(correlationId: Int, updateMetadataRequest: UpdateMetadataRequest): Seq[TopicPartition] = {\n    inWriteLock(partitionMetadataLock) {\n        // 更新本地缓存的 kafka controller 的 ID\n        controllerId = updateMetadataRequest.controllerId match {\n            case id if id < 0 => None\n            case id => Some(id)\n        }\n\n        // 清除本地缓存的集群可用的 broker 节点信息，并由 UpdateMetadataRequest 请求重新构建\n        aliveNodes.clear()\n        aliveBrokers.clear()\n        updateMetadataRequest.liveBrokers.asScala.foreach { broker =>\n            // aliveNodes 是一个请求热点，所以这里使用 java.util.HashMap 来提升性能，如果是 scala 2.10 之后可以使用 AnyRefMap 代替\n            val nodes = new java.util.HashMap[ListenerName, Node]\n            val endPoints = new mutable.ArrayBuffer[EndPoint]\n            broker.endPoints.asScala.foreach { ep =>\n                endPoints += EndPoint(ep.host, ep.port, ep.listenerName, ep.securityProtocol)\n                nodes.put(ep.listenerName, new Node(broker.id, ep.host, ep.port))\n            }\n            aliveBrokers(broker.id) = Broker(broker.id, endPoints, Option(broker.rack))\n            aliveNodes(broker.id) = nodes.asScala\n        }\n\n        // 基于 UpdateMetadataRequest 请求更新每个分区的状态信息，并返回需要被移除的分区集合\n        val deletedPartitions = new mutable.ArrayBuffer[TopicPartition]\n        updateMetadataRequest.partitionStates.asScala.foreach {\n            case (tp, info) =>\n                val controllerId = updateMetadataRequest.controllerId\n                val controllerEpoch = updateMetadataRequest.controllerEpoch\n                // 如果请求标记对应的 topic 分区需要被删除\n                if (info.leader == LeaderAndIsr.LeaderDuringDelete) {\n                    // 删除本地缓存的对应 topic 分区的状态信息\n                    this.removePartitionInfo(tp.topic, tp.partition)\n                    deletedPartitions += tp\n                } else {\n                    // PartitionState -> PartitionStateInfo\n                    val partitionInfo = this.partitionStateToPartitionStateInfo(info)\n                    // 更新本地缓存的对应 topic 分区的状态信息\n                    this.addOrUpdatePartitionInfo(tp.topic, tp.partition, partitionInfo)\n                }\n        }\n        deletedPartitions\n    }\n}\n```\n\nMetadataCache 使用 `MetadataCache#aliveBrokers` 和 `MetadataCache#aliveNodes` 字段记录整个集群中可用的 broker 节点信息，当收到来自 kafka controller 的 UpdateMetadataRequest 请求时，MetadataCache 会清空本地缓存，并由请求信息重新构建新的可用的 broker 节点信息。此外还会依据 UpdateMetadataRequest 请求更新本地缓存的整个集群 topic 分区的状态信息（对应 `MetadataCache#cache` 字段）。\n\nMetadataCache 提供了 `MetadataCache#getTopicMetadata` 方法用于获取本地缓存的指定 topic 的元数据信息，包括是否是内部 topic，以及对应 topic 下所有分区的元数据信息。方法实现如下：\n\n```scala\ndef getTopicMetadata(topics: Set[String],\n                     listenerName: ListenerName,\n                     errorUnavailableEndpoints: Boolean = false): Seq[MetadataResponse.TopicMetadata] = {\n    inReadLock(partitionMetadataLock) {\n        topics.toSeq.flatMap { topic =>\n            // 获取指定 topic 下分区元数据信息，并与 topic 一起构造 topic 元数据对象返回\n            this.getPartitionMetadata(topic, listenerName, errorUnavailableEndpoints).map { partitionMetadata =>\n                new MetadataResponse.TopicMetadata(Errors.NONE, topic, Topic.isInternal(topic), partitionMetadata.toBuffer.asJava)\n            }\n        }\n    }\n}\n\nprivate def getPartitionMetadata(\n                                 topic: String,\n                                 listenerName: ListenerName,\n                                 errorUnavailableEndpoints: Boolean): Option[Iterable[MetadataResponse.PartitionMetadata]] = {\n    // 遍历每个 topic 对应的分区集合\n    cache.get(topic).map { partitions =>\n        partitions.map { case (partitionId, partitionState) =>\n            val topicPartition = TopicAndPartition(topic, partitionId)\n\n            // 获取分区对应的 LeaderAndIsr 对象，其中封装了对应分区的 leader 副本 ID 和 ISR 集合等信息\n            val leaderAndIsr = partitionState.leaderIsrAndControllerEpoch.leaderAndIsr\n            // 获取 leader 副本所在的节点信息\n            val maybeLeader = this.getAliveEndpoint(leaderAndIsr.leader, listenerName)\n            // 获取分区的 AR 集合\n            val replicas = partitionState.allReplicas\n            // 获取 AR 集合中可用的副本对应的节点信息\n            val replicaInfo = this.getEndpoints(replicas, listenerName, errorUnavailableEndpoints)\n\n            maybeLeader match {\n                // 分区 leader 副本不可用\n                case None =>\n                    new MetadataResponse.PartitionMetadata(Errors.LEADER_NOT_AVAILABLE,\n                        partitionId, Node.noNode(), replicaInfo.asJava, java.util.Collections.emptyList())\n                case Some(leader) =>\n                    // 获取分区的 ISR 集合\n                    val isr = leaderAndIsr.isr\n                    // 获取 ISR 集合中可用的副本对应的节点信息\n                    val isrInfo = this.getEndpoints(isr, listenerName, errorUnavailableEndpoints)\n                    if (replicaInfo.size < replicas.size) {\n                        // 如果 AR 集合中存在不可用的副本，则返回 REPLICA_NOT_AVAILABLE 错误\n                        new MetadataResponse.PartitionMetadata(Errors.REPLICA_NOT_AVAILABLE, partitionId, leader, replicaInfo.asJava, isrInfo.asJava)\n                    } else if (isrInfo.size < isr.size) {\n                        // 如果 ISR 集合中存在不可用的的副本，则返回 REPLICA_NOT_AVAILABLE 错误\n                        new MetadataResponse.PartitionMetadata(Errors.REPLICA_NOT_AVAILABLE, partitionId, leader, replicaInfo.asJava, isrInfo.asJava)\n                    } else {\n                        // AR 集合和 ISR 集合中的副本都是可用的\n                        new MetadataResponse.PartitionMetadata(Errors.NONE, partitionId, leader, replicaInfo.asJava, isrInfo.asJava)\n                    }\n            }\n        }\n    }\n}\n```\n\n方法 `MetadataCache#getPartitionMetadata` 会校验对应分区的 AR 集合和 ISR 集合中的副本是否可用，如果存在不可用的副本则会返回 `REPLICA_NOT_AVAILABLE` 错误，如果分区的副本均可用则会返回分区的元数据信息，包括分区 ID、leader 副本所在节点信息、AR 集合，以及 ISR 集合。\n\n### 总结\n\n本文我们分析了 Kafka 的分区副本实现机制，了解到 Kafka 会为每个 topic 分区设置多个副本，并基于 leader/follower 模式将这些副本分为一个 leader 角色和多个 follower 角色。在 topic 分区正常运行期间，由 leader 副本负责处理来自客户端的消息读写请求，而 follower 副本仅负责从 leader 副本同步消息数据。一旦 leader 副本失效，Kafka 会从位于 ISR 集合中的 follower 副本中选择一个成为新的 leader 副本，以保证对应的 topic 能够继续对外提供服务。\n\n冗余策略在分布式计算和存储领域是一种简单且有效的可靠性保障措施，了解 Kafka 的分区副本实现机制能够指导我们更好的设计实现自己的分布式应用。\n","tags":["Kafka"],"categories":["kafka"]},{"title":"Kafka 源码解析：延时任务调度策略","url":"/2019/06/23/kafka/kafka-purgatory/","content":"\nKafka 一些组件的命名很是有趣，比如炼狱（purgatory）、死神（reaper）等，在日常开发中也建议大家在类和方法命名上能够以一些能够表达类或方法意图的人或事物的名词进行命名，让项目显得更加的生动。今天我们要分析的组件就是以 purgatory 命名的 DelayedOperationPurgatory，DelayedOperationPurgatory 是一个相对独立的组件，我们可以将其抽取出来用于自己的日常项目中，DelayedOperationPurgatory 主要用于管理延时任务，底层依赖于分层时间轮算法实现。\n\n说到延时任务调度，对于 java 开发者来说，日常用到比较多的可能是 JDK 自带的 Timer、ScheduledThreadPoolExecutor 和 DelayQueue 等，但是对于 Kafka 这类需要频繁执行复杂延时任务的分布式系统来说，这些组件在性能上还稍显不足，所以 Kafka 自定义了分层时间轮算法，提供了 `O(m)` 时间复杂度（m 为时间轮层级数）的任务插入性能和 `O(1)` 时间复杂度的任务删除性能，要优于 JDK 自带的基于堆实现的 `O(log(n))` 时间复杂度的延时任务调度组件。<!-- more -->\n\n传统的时间轮算法在实现上采用单环实现，环上对应指定数量的时间格，然后将延时任务分散到对应的时间格上，随着时间指针的推进触发相应的任务执行。这样设计的缺点在于只能添加位于一个特定区间内的延时任务，如果延时任务的跨度较长，则时间轮需要被设计的非常大，在一定程度上是一种浪费，同时也无法彻底解决其表现力不足的问题。分层时间轮则采用多环实现，每个环的时间格在粒度上存在差异（一般上层时间轮一格的时间跨度等于下层整个时间轮的跨度），通过多环嵌套能够让时间轮表示任意延迟时长的任务调度。\n\n时间轮算法定义了从时间维度触发延时任务的执行，实际应用中可能还需要允许从其他维度对延迟任务在到达延时时间之前提前触发。为此，Kafka 定义了 DelayedOperation 和 DelayedOperationPurgatory 组件，通过在注册延时任务时让每个延时任务关注一个或多个 key，当这些 key 状态发生变更时触发调用对应的延时任务，以实现对延时任务的多维度控制。\n\n### 分层时间轮\n\nKafka 的分层时间轮算法在实现上主要涉及 TimingWheel、TimerTaskList、TimerTaskEntry，以及 TimerTask 这 4 个类，各个类的作用说明如下：\n\n- __TimerTask__ ：特质类型，用于描述延时任务。\n- __TimerTaskList__ ：时间格，采用环形双向链表实现，记录位于同一个时间格中的延时任务。\n- __TimerTaskEntry__ ：时间格链表中的一个结点，是对延时任务 TimerTask 的封装。\n- __TimingWheel__ ：时间轮，采用定长数组记录放置时间格。\n\n#### TimerTask 和 TimerTaskEntry\n\n本小节来看一下分层时间轮算法的具体实现，首先来看一下对于延时任务的描述，即 TimerTask 特质，而 TimerTask 特质和类 TimerTaskEntry 在实现上是相互引用的，所以需要将这两者结合起来分析。TimerTask 继承了 Runnable 接口，其字段定义如下：\n\n```scala\ntrait TimerTask extends Runnable {\n\n    /** 当前任务的延迟时长（单位：毫秒） */\n    val delayMs: Long\n    /** 封装当前定时任务的链表节点 */\n    private[this] var timerTaskEntry: TimerTaskEntry = _\n\n    // ... 省略方法定义\n\n}\n```\n\n其中，字段 `TimerTask#delayMs` 用于设置当前延时任务的延时时长，例如延迟 1 分钟执行，则 delayMs 即等于 `1 * 60 * 1000`，即 60000 毫秒。而字段 `TimerTask#timerTaskEntry` 则用于封装当前延时任务并记录到时间格中，属于延时任务与时间格之间建立关系的桥梁。TimerTask 中定义了绑定和获取 timerTaskEntry 的方法 `TimerTask#setTimerTaskEntry` 和 `TimerTask#getTimerTaskEntry`。\n\n需要知晓的一点是，如果当前任务之前已经被添加到时间格中，即对应的 timerTaskEntry 已经被赋值过，当再次执行绑定时，如果是绑定到新的时间格结点则需要先从之前绑定的时间格中移除当前延时任务。此外，`TimerTask#cancel` 方法用于取消对应的延时任务，实际上就是调用 `TimerTaskEntry#remove` 方法从时间格中移除对应的结点。\n\nTimerTaskEntry 类本质上是一个链表结点的定义，其字段定义了结点的前置和后置指针，以及所属的时间格，类字段定义如下：\n\n```scala\nprivate[timer] class TimerTaskEntry(val timerTask: TimerTask, // 封装的延时任务\n                                    val expirationMs: Long // 延时时间戳，即延时任务的延时时间 + 当前时间戳\n                                   ) extends Ordered[TimerTaskEntry] {\n\n    /** 所属时间格 */\n    @volatile var list: TimerTaskList = _\n    /** 后置指针 */\n    var next: TimerTaskEntry = _\n    /** 前置指针 */\n    var prev: TimerTaskEntry = _\n\n    // ... 省略方法定义\n\n}\n```\n\nTimerTaskEntry 类对象在被构造时会建立延时任务与结点之间的映射关系，并提供了获取延时任务取消状态，以及移除对应延时任务的操作。这里的 `TimerTaskEntry#expirationMs` 字段是延时任务到期时间戳，也就是延时任务应该被触发执行的时间戳，在计算上等于延时任务的 `TimerTask#delayMs` 时间加上任务被添加到时间轮中的时间戳。\n\n#### TimerTaskList\n\nTimerTaskList 描述了时间轮的一格（即时间格），在实现上采用双向链表实现，用于封装位于特定时间区间范围内的所有的延时任务，其字段定义如下：\n\n```scala\nprivate[timer] class TimerTaskList(taskCounter: AtomicInteger) extends Delayed {\n\n    /** 根结点 */\n    private[this] val root = new TimerTaskEntry(null, -1)\n    root.next = root\n    root.prev = root\n    /** 记录当前时间格对应时间区间上界 */\n    private[this] val expiration = new AtomicLong(-1L)\n\n    // ... 省略方法定义\n\n}\n```\n\nTimerTaskList 的默认构造方法接收一个 AtomicInteger 类型的计数器变量，该变量在整个时间轮设计中是共享的，用于记录整个分层时间轮中持有的延时任务总数。同时 TimerTaskList 还定义了一个 `TimerTaskList#expiration` 字段，用于记录当前时间格对应时间区间的上界。TimerTaskList 提供了添加和移除延时任务的方法：`TimerTaskList#add` 和 `TimerTaskList#remove`。需要注意的一点是，如果当前添加的延时任务在之前被添加过，则再次添加时会先移除之前的添加记录。同时，TimerTaskList 还提供了 `TimerTaskList#flush` 方法，该方法接收一个 `TimerTaskEntry => Unit` 类型的函数 f，用于从当前时间格中移除所有延时任务，并对每个任务应用 f 函数，在后面分析推进时间轮指针时将会看到，借助 `TimerTaskList#flush` 方法可以执行一个时间格中所有到期且未被取消的任务，并对未到期的任务重新放入对应层级的时间轮中，继续等待调度。\n\n#### TimingWheel\n\n介绍完了 TimerTask、TimerTaskEntry 和 TimerTaskList，最后来重点看一下分层时间轮 TimingWheel 的实现，其字段定义如下：\n\n```scala\nprivate[timer] class TimingWheel(tickMs: Long, // 当前时间轮中一格的时间跨度\n                                 wheelSize: Int, // 时间轮的格数\n                                 startMs: Long, // 当前时间轮的创建时间\n                                 taskCounter: AtomicInteger, // 各层级时间轮共用的任务计数器，用于记录时间轮中总的任务数\n                                 queue: DelayQueue[TimerTaskList]) { // 各个层级时间轮共用一个任务队列\n\n    /** 时间轮指针，将时间轮划分为到期部分和未到期部分 */\n    private[this] var currentTime = startMs - (startMs % tickMs) // 修剪成 tickMs 的倍数，近似等于创建时间\n    /**\n     * 当前时间轮的时间跨度，\n     * 只能处理时间范围在 [currentTime, currentTime + interval] 之间的延时任务，超过该范围则需要将任务添加到上层时间轮中\n     */\n    private[this] val interval = tickMs * wheelSize\n    /** 每一项都对应时间轮中的一格 */\n    private[this] val buckets = Array.tabulate[TimerTaskList](wheelSize) { _ => new TimerTaskList(taskCounter) }\n    /** 对于上层时间轮的引用 */\n    @volatile private[this] var overflowWheel: TimingWheel = _\n\n    // ... 省略方法定义\n\n}\n```\n\n一个时间轮中包含多个时间格，TimingWheel 使用 `TimingWheel#wheelSize` 字段记录单层时间轮中的时间格格数，并使用 `TimingWheel#tickMs` 字段记录一个时间格的时间跨度，同时用一个数组 `TimingWheel#buckets` 记录这些时间格。作为分层结构设计，TimingWheel 定义了 `TimingWheel#overflowWheel` 字段用于对上层时间轮进行引用，上层时间轮的时间格跨度为当前时间轮的总时间跨度，对应 `TimingWheel#interval` 字段。一个 TimingWheel 对应的具体延时任务处理时间是在 `[startMs - (startMs % tickMs), startMs - (startMs % tickMs) + interval)` 之间，超过该区间的任务将会被提交给上层时间轮进行管理。字段 `TimingWheel#currentTime` 表示对应时间轮的指针，在 TimingWheel 刚刚被构造出来时，其值等于 `startMs - (startMs % tickMs)`，之所以需要减去 `(startMs % tickMs)`，是为了保持与 tickMs 对齐。各层级的 TimingWheel 共用一个 DelayQueue 对象，其中记录了所有的延时任务，DelayQueue 的每个结点对应一个隶属于某个时间轮的时间格对象。\n\n介绍完了 TimingWheel 的字段定义，我们来看一下 TimingWheel 的方法实现，TimingWheel 总共定义了 3 个方法：`TimingWheel#addOverflowWheel`、`TimingWheel#add` 和 `TimingWheel#advanceClock`。\n\n方法 `TimingWheel#addOverflowWheel` 用于添加并初始化上层时间轮，在 Kafka 的分层时间轮算法设计中，上层时间轮是按需添加的，只要在当前时间轮容纳不了给定的延时任务时，才会触发将该延时任务提交给上层时间轮管理，此时如果上层时间轮还未定义，则会调用该方法初始化上层时间轮。方法实现如下：\n\n```scala\nprivate[this] def addOverflowWheel(): Unit = {\n    synchronized {\n        if (overflowWheel == null) {\n            // 创建上层时间轮\n            overflowWheel = new TimingWheel(\n                tickMs = interval, // tickMs 是当前时间轮的时间跨度 interval\n                wheelSize = wheelSize, // 时间轮的格数不变\n                startMs = currentTime, // 创建时间即当前时间\n                taskCounter = taskCounter, // 全局唯一的任务计数器\n                queue // 全局唯一的任务队列\n            )\n        }\n    }\n}\n```\n\n创建上层时间轮无非就是新建一个 TimingWheel 对象，并赋值给当前时间轮的 `TimingWheel#overflowWheel` 字段。这里需要注意的地方就是对应上层时间轮的字段赋值，由方法实现可以看出上层时间轮中每一个时间格的时间跨度 tickMs 等于当前时间轮的总时间跨度 interval，而时间格格数仍保持不变，对应的任务计数器 taskCounter 和任务队列 queue 都是全局共用的。\n\n方法 `TimingWheel#add` 用于往时间轮中添加延时任务，该方法接收一个 TimerTaskEntry 类型对象，即对延时任务 TimerTask 的封装。方法实现如下：\n\n```scala\ndef add(timerTaskEntry: TimerTaskEntry): Boolean = {\n    // 获取任务的到期时间戳\n    val expiration = timerTaskEntry.expirationMs\n    if (timerTaskEntry.cancelled) {\n        // 任务已经被取消，则不应该被添加\n        false\n    } else if (expiration < currentTime + tickMs) {\n        // 任务已经到期，则不应该被添加\n        false\n    } else if (expiration < currentTime + interval) {\n        // 任务正好位于当前时间轮的时间跨度范围内，\n        // 依据任务的到期时间查找此任务所属的时间格，并将任务添加到对应的时间格中\n        val virtualId = expiration / tickMs\n        val bucket = buckets((virtualId % wheelSize.toLong).toInt)\n        bucket.add(timerTaskEntry)\n\n        // 更新对应时间格的时间区间上界，如果是第一次往对应时间格中添加延时任务，则需要将时间格记录到全局任务队列中\n        if (bucket.setExpiration(virtualId * tickMs)) {\n            queue.offer(bucket)\n        }\n        true\n    } else {\n        // 已经超出了当前时间轮的时间跨度范围，将任务添加到上层时间轮中\n        if (overflowWheel == null) this.addOverflowWheel()\n        overflowWheel.add(timerTaskEntry)\n    }\n}\n```\n\n上述方法的返回值为 Boolean 类型，后面的分析中将会看到，如果方法返回 false 且对应的任务未被取消，则会立即提交执行该任务。针对那些已经到期或已经被取消的任务会立即返回 false，这类任务不需要被添加到时间轮中。对于剩下的延时任务，如果任务的到期时间正好位于当前时间轮处理的时间区间内，则会将任务添加到时间轮对应的时间格中，同时将对应的时间格记录到全局 DelayQueue 中用于后续管理。如果待添加的延时任务已经超出了当前时间轮的处理范围，则会提交给上层时间轮进行管理，这一步会尝试触发创建并初始化上层时间轮。\n\n方法 `TimingWheel#advanceClock` 用于推动当前时间轮指针（对应 `TimingWheel#currentTime` 字段），如果存在上层时间轮，则会尝试继续推动上层时间轮。方法实现如下：\n\n```scala\ndef advanceClock(timeMs: Long): Unit = {\n    if (timeMs >= currentTime + tickMs) {\n        // 尝试推动指针，可能会往前推进多个时间格\n        currentTime = timeMs - (timeMs % tickMs)\n\n        // 尝试推动上层时间轮指针\n        if (overflowWheel != null)\n            overflowWheel.advanceClock(currentTime)\n    }\n}\n```\n\n### 定时器\n\n上面介绍的 TimingWheel 提供了添加延时任务和推进时间轮指针的操作，而具体执行延时任务的操作则交由定时器 SystemTimer 完成。SystemTimer 类实现了 Timer 特质，该特质描绘了定时器应该具备的基本方法，定义如下：\n\n```scala\ntrait Timer {\n\n    /**\n     * 添加延时任务，如果任务到期则会立即触发执行\n     *\n     * @param timerTask\n     */\n    def add(timerTask: TimerTask): Unit\n\n    /**\n     * 推动时间轮指针，期间会执行已经到期的任务\n     *\n     * @param timeoutMs\n     * @return 是否有任务被执行\n     */\n    def advanceClock(timeoutMs: Long): Boolean\n\n    /**\n     * 获取时间轮中等待被调度的任务数\n     *\n     * @return\n     */\n    def size: Int\n\n    /**\n     * 关闭定时器，丢弃未执行的延时任务\n     */\n    def shutdown(): Unit\n\n}\n```\n\nSystemTimer 类字段定义如下：\n\n```scala\nclass SystemTimer(executorName: String,\n                  tickMs: Long = 1, // 默认时间格时间为 1 毫秒\n                  wheelSize: Int = 20, // 默认时间格大小为 20\n                  startMs: Long = Time.SYSTEM.hiResClockMs // 时间轮启动时间戳\n                 ) extends Timer {\n\n    /** 延时任务执行线程池 */\n    private[this] val taskExecutor = Executors.newFixedThreadPool(1, new ThreadFactory() {\n        def newThread(runnable: Runnable): Thread = Utils.newThread(\"executor-\" + executorName, runnable, false)\n    })\n    /** 各层级时间轮共用的延时任务队列 */\n    private[this] val delayQueue = new DelayQueue[TimerTaskList]()\n    /** 各层级时间轮共用的任务计数器 */\n    private[this] val taskCounter = new AtomicInteger(0)\n    /** 分层时间轮中最底层的时间轮 */\n    private[this] val timingWheel = new TimingWheel(\n        tickMs = tickMs,\n        wheelSize = wheelSize,\n        startMs = startMs,\n        taskCounter = taskCounter,\n        delayQueue\n    )\n\n    // ... 省略方法定义\n\n}\n```\n\n由上面的字段定义可以看出 SystemTimer 是对时间轮 TimingWheel 的封装，并提供了线程池 taskExecutor 以执行到期的延时任务。SystemTimer 实现了 Timer 特质中声明的所有方法，其中 `SystemTimer#size` 和 `SystemTimer#shutdown` 方法的实现都比较简单，下面我们重点来看一下用于添加延时任务的 `SystemTimer#add` 方法，以及推动时间轮指针的 `SystemTimer#advanceClock` 方法实现。\n\n方法 `SystemTimer#add` 会将待添加的延时任务 TimerTask 对象封装成 TimerTaskEntry 对象添加到对应的时间格中，添加的过程调用的是 `TimingWheel#add` 方法。前面曾介绍过该方法会将未到期的延时任务添加到对应的时间轮中并返回 true，对于已到期或已经被取消的延时任务则会立即返回 false。由下面的实现可以看到，对于那些已经到期但是未被取消的任务，会立即被提交给执行线程予以执行。\n\n```scala\noverride def add(timerTask: TimerTask): Unit = {\n    readLock.lock()\n    try {\n        // 将 TimerTask 封装成 TimerTaskEntry 对象，并添加到时间轮中\n        this.addTimerTaskEntry(new TimerTaskEntry(timerTask, timerTask.delayMs + Time.SYSTEM.hiResClockMs))\n    } finally {\n        readLock.unlock()\n    }\n}\n\nprivate def addTimerTaskEntry(timerTaskEntry: TimerTaskEntry): Unit = {\n    // 往时间轮中添加延时任务，同时检测添加的任务是否已经到期\n    if (!timingWheel.add(timerTaskEntry)) {\n        // 任务到期但未被取消，则立即提交执行\n        if (!timerTaskEntry.cancelled)\n            taskExecutor.submit(timerTaskEntry.timerTask)\n    }\n}\n```\n\n方法 `SystemTimer#advanceClock` 用于推动时间轮指针，推动的操作本质上是调用 `TimingWheel#advanceClock` 方法实现，但是区别于 TimingWheel 中单纯的向前移动指针，方法 `SystemTimer#advanceClock` 会从全局任务队列中获取队头的时间格，并执行时间格中已到期的任务。方法实现如下：\n\n```scala\n/** 将延时任务重新添加到时间轮中 */\nprivate[this] val reinsert = (timerTaskEntry: TimerTaskEntry) => this.addTimerTaskEntry(timerTaskEntry)\n\n/**\n * 推进时间轮指针，同时处理时间格中到期的任务\n */\noverride def advanceClock(timeoutMs: Long): Boolean = {\n    // 超时等待获取时间格对象\n    var bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)\n    if (bucket != null) {\n        writeLock.lock()\n        try {\n            while (bucket != null) {\n                // 推进时间轮指针，对应的时间戳为当前时间格时间区间上界\n                timingWheel.advanceClock(bucket.getExpiration)\n                // 遍历处理当前时间格中的延时任务，提交执行到期但未被取消的任务，\n                // 对于未到期的任务重新添加到时间轮中继续等待被执行，期间可能会对任务在层级上执行降级\n                bucket.flush(reinsert)\n                bucket = delayQueue.poll()\n            }\n        } finally {\n            writeLock.unlock()\n        }\n        true\n    } else {\n        false\n    }\n}\n```\n\n前面我们曾分析过 `TimerTaskList#flush` 方法，知道该方法会从对应时间格中移除所有的延时任务并为每个任务应用参数给定的函数，而这里的函数定义则是 reinsert，该函数会对时间格中的每个延时任务应用上面分析过的 `SystemTimer#addTimerTaskEntry` 操作，即尝试将每个任务再次加入到对应的时间格，并执行已到期未被取消的任务。\n\n这里需要清楚的一点是，从当前时间格中移出但未到期的延时任务，当再次被添加到时间轮中时，不一定会被添加到原来的时间轮中，因为随着时间的流失，距离对应延时任务的时间差也越来越小，这个时候一般会发生时间轮的降级，即从一个较大（时间区间）粒度的时间轮中降落到粒度较小的时间轮中。实际上，从在时间轮中等待到被执行本质上也是一种降级操作，只是这里较小的时间粒度是 0，表示延时任务已经到期，需要立即被执行。\n\n### 炼狱\n\n上面介绍的定时器 SystemTimer 能够依据给定的延时时间延迟对任务的执行，而在实际应用中时间往往只是触发任务执行的维度之一，一些场景下我们需要对延时任务的执行更加灵活的控制。例如在生产者向服务端发送消息并等待服务端确认时，服务端需要依据客户端指定的 acks 参数等待指定数量的副本确认已完成对当前消息的复制操作才能向客户端发送确认的响应。这本质上是一个异步的操作，而具体的执行时机不能单方面用时间进行衡量，这个时候我们需要利用更多的信息对延迟任务的执行进行控制。\n\n#### DelayedOperation\n\nDelayedOperation 正是上面描述的这一类延时任务的抽象，它实现了 TimerTask 特质，并定义了以下方法：\n\n- __forceComplete__ ：强制执行延时任务，包括满足执行条件主动触发，以及延时到期。\n- __onComplete__ ：延时任务的具体执行逻辑，在整个延时任务的生命周期中只能被调用一次，且只能由 forceComplete 方法调用。\n- __onExpiration__ ：当延时任务因为时间到期被执行时会触发该方法中定义的逻辑。\n- __tryComplete__ ：检测是否满足延时任务执行条件，若满足则会调用 forceComplete 方法。\n- __safeTryComplete__ ：方法 tryComplete 的线程安全版本。\n- __isCompleted__ ：检测延时任务是否完成执行。\n\n上述方法中，除了 `DelayedOperation#forceComplete` 方法外，其余基本为抽象方法声明，这里主要看一下该方法的实现：\n\n```scala\ndef forceComplete(): Boolean = {\n    if (completed.compareAndSet(false, true)) { // CAS 操作修改 completed 字段\n        // 将当前延时任务从时间轮中移除\n        this.cancel()\n        // 立即触发执行延时任务\n        this.onComplete()\n        true\n    } else {\n        false\n    }\n}\n```\n\n当调用 `DelayedOperation#forceComplete` 方法时，会将当前延时任务从时间轮中移除并立即触发执行。\n\nDelayedOperation 实现了 TimerTask 特质，所以也间接实现了 Runnable 接口，当延时任务到期时会被提交给定时器的线程执行，其 `DelayedOperation#run` 方法实现如下：\n\n```scala\noverride def run(): Unit = {\n    if (forceComplete()) onExpiration()\n}\n```\n\n当延时任务到期时会触发 `DelayedOperation#forceComplete` 方法的执行，如果延时任务在其它线程中被执行，则 `DelayedOperation#forceComplete` 方法会立即返回 false，也就不会继续触发执行 `DelayedOperation#onExpiration` 方法。\n\nDelayedOperationPurgatory 类提供了对 DelayedOperation 管理的功能，DelayedOperationPurgatory 维护了一个 Pool 类型（key/value 类型）的 watchersForKey 对象，用于记录延时任务及其关注的 key 之间的映射关系，用于支持时间维度以外的其它维度操作。Pool 封装了 ConcurrentHashMap，并在 ConcurrentHashMap 的基础上添加了 `Pool#getAndMaybePut` 方法，用于在对应 key 不命中时使用给定的 value 更新键值对。Pool 的默认构造方法接收一个 `Option[K => V]` 类型的 valueFactory 参数，用于为 key 生成对应的 Watchers 对象。\n\n#### DelayedOperationPurgatory\n\nDelayedOperationPurgatory 类提供了对 DelayedOperation 进行管理的功能，其中定义的 Pool 对象的 key 是 Any 类型，表示可以使用任意类型的对象作为 key，而 value 则是 Watchers 类型，用于封装关注相同 key 的 DelayedOperation 集合，底层依赖于 ConcurrentLinkedQueue 实现。Watchers 中定义的方法实现将在后面分析 DelayedOperationPurgatory 类时一同分析。DelayedOperationPurgatory 类的字段定义如下：\n\n```scala\nclass DelayedOperationPurgatory[T <: DelayedOperation](purgatoryName: String,\n                                                       timeoutTimer: Timer, // 定时器\n                                                       brokerId: Int = 0, // 所在 broker 节点 ID\n                                                       purgeInterval: Int = 1000, // 执行清理操作的阈值\n                                                       reaperEnabled: Boolean = true // 是否启用后台指针推进器\n                                                      ) extends Logging with KafkaMetricsGroup {\n\n      /** 用于管理 DelayedOperation，其中 key 是 Watcher 中的 DelayedOperation 集合所关心的对象 */\n      private val watchersForKey = new Pool[Any, Watchers](Some((key: Any) => new Watchers(key)))\n      /** watchersForKey 读写锁 */\n      private val removeWatchersLock = new ReentrantReadWriteLock()\n      /** 记录当前 DelayedOperationPurgatory 中延时任务的个数 */\n      private[this] val estimatedTotalOperations = new AtomicInteger(0)\n      /**\n       * 主要具备 2 个作用：\n       *  1. 推进时间指针\n       *  2. 定期清理 watchersForKey 中已经完成的延时任务\n       */\n      private val expirationReaper = new ExpiredOperationReaper()\n\n    // ... 省略方法定义\n\n}\n```\n\n各字段的含义如代码注释，这里我们主要介绍一下 `DelayedOperationPurgatory#expirationReaper` 字段，它是 ExpiredOperationReaper 类型。ExpiredOperationReaper 是 DelayedOperationPurgatory 中定义的内部类，它继承自 ShutdownableThread 抽象类，所以我们可以知道它本质上是一个线程类，在构造 DelayedOperationPurgatory 对象时如果设置 `reaperEnabled=true` 则会启动该线程。ExpiredOperationReaper 类实现如下：\n\n```scala\nprivate class ExpiredOperationReaper extends ShutdownableThread(\"ExpirationReaper-%d\".format(brokerId), false) {\n\n    override def doWork() {\n        advanceClock(200L)\n    }\n\n}\n```\n\nExpiredOperationReaper 的主要作用是调用 `DelayedOperationPurgatory#advanceClock` 方法在后台推动时间轮指针，并定期清理当前 DelayedOperationPurgatory 中记录的所有已执行完成的延时任务。方法 `DelayedOperationPurgatory#advanceClock` 的实现如下：\n\n```scala\ndef advanceClock(timeoutMs: Long) {\n    // 尝试推进时间轮指针\n    timeoutTimer.advanceClock(timeoutMs)\n\n    // 如果当前炼狱中的已完成任务数超过给定阈值 purgeInterval，则尝试清理\n    if (estimatedTotalOperations.get - delayed > purgeInterval) {\n        estimatedTotalOperations.getAndSet(delayed())\n        debug(\"Begin purging watch lists\")\n        // 遍历各个 Watcher 集合，执行清理操作\n        val purged = allWatchers.map(_.purgeCompleted()).sum\n        debug(\"Purged %d elements from watch lists.\".format(purged))\n    }\n}\n```\n\n上述方法会调用定时器的 `SystemTimer#advanceClock` 方法推进时间轮指针，并估算当前 DelayedOperationPurgatory 中已经完成的延时任务数目是否超过设置的阈值 purgeInterval，默认为 1000，如果超过该阈值则会触发清理工作。清理期间会获取并处理所有在册的 Watchers 对象，通过调用每个 Watchers 对象的 `Watchers#purgeCompleted` 方法，对 Watchers 中已经执行完成的延时任务对象进行清理，如果某个 key 的 Watchers 对象在被清理之后不再包含任何等待执行的延时任务，则会调用 `DelayedOperationPurgatory#removeKeyIfEmpty` 方法将对应的 key 从 `DelayedOperationPurgatory#watchersForKey` 字段中一并移除，防止内存泄露。\n\n下面我们继续来看一下 DelayedOperationPurgatory 中剩余的两个主要方法实现，即 `DelayedOperationPurgatory#tryCompleteElseWatch` 和 `DelayedOperationPurgatory#checkAndComplete` 方法。\n\n方法 `DelayedOperationPurgatory#tryCompleteElseWatch` 用于往 DelayedOperationPurgatory 中添加延时任务，一个延时任务可以被同时关联到多个 key 对象上，这样可以从多个维度触发执行该延时任务。方法实现如下：\n\n```scala\ndef tryCompleteElseWatch(operation: T, watchKeys: Seq[Any]): Boolean = {\n    assert(watchKeys.nonEmpty, \"The watch key list can't be empty\")\n\n    // 1. 调用延时任务的 tryComplete 方法，尝试完成延迟操作\n    var isCompletedByMe = operation.safeTryComplete()\n    // 如果延时任务已经执行完成，则直接返回\n    if (isCompletedByMe) return true\n\n    // 2. 遍历处理 watchKeys，将延时任务添加其关心的 key 对应的 Watchers 中\n    var watchCreated = false\n    for (key <- watchKeys) {\n        // 如果待添加的延时任务已经执行完成，则放弃添加\n        if (operation.isCompleted) return false\n\n        // 添加延时任务添加到对应 key 的 Watchers 集合中，用于从时间维度以外的维度触发延时任务执行\n        this.watchForOperation(key, operation)\n\n        if (!watchCreated) {\n            watchCreated = true\n            // 延时任务计数加 1，一个延时任务可能会被添加到多个 key 对应的 Watchers 集合中，但是任务计数只会增加 1 次\n            estimatedTotalOperations.incrementAndGet()\n        }\n    }\n\n    // 3. 再次调用延时任务的 tryComplete 方法，尝试完成延迟操作\n    isCompletedByMe = operation.safeTryComplete()\n    if (isCompletedByMe) return true\n\n    // 4. 对于未执行的延时任务，尝试添加到定时器中，用于从时间维度触发延时任务执行\n    if (!operation.isCompleted) {\n        timeoutTimer.add(operation)\n        // 再次检测延时任务的执行情况，如果已经完成则从定时器中移除\n        if (operation.isCompleted) {\n            operation.cancel()\n        }\n    }\n\n    false\n}\n```\n\n注册延时任务的执行流程如下：\n\n1. 尝试执行延时任务，如果当前已经完成执行则返回；\n2. 否则，遍历给定的 key 集合，将延时任务添加到每个 key 的 Watchers 中，建立从多个维度触发延时任务执行的条件，期间如果延时任务已经完成执行，则不再继续添加；\n3. 再次尝试执行延时任务，如果当前已经完成执行则返回；\n4. 否则，将延时任务添加到定时器中，建立从时间维度触发延时任务执行的条件，如果期间任务已经完成执行，则从时间轮中取消任务。\n\n整个执行流程我们看到方法多次尝试执行延时任务，以保证对应的延时任务能够尽快被触发，同时减少 DelayedOperationPurgatory 不必要的开销。下面我们主要来看一下步骤 2 的执行逻辑，在该步骤中调用了 `DelayedOperationPurgatory#watchForOperation` 方法将当前延时任务对象添加到对应 key 的 Watchers 中，方法实现如下：\n\n```scala\nprivate def watchForOperation(key: Any, operation: T) {\n    inReadLock(removeWatchersLock) {\n        val watcher = watchersForKey.getAndMaybePut(key)\n        watcher.watch(operation)\n    }\n}\n```\n\n其中，方法 `Pool#getAndMaybePut` 会尝试获取 key 对应的 Watchers 对象，如果不存在则会创建，然后调用 `Watchers#watch` 方法将延时任务记录到 Watchers 对象的同步队列中。\n\n在整个 `DelayedOperationPurgatory#tryCompleteElseWatch` 方法的实现上我们可能会疑惑，为什么既要将延时任务添加到定时器 SystemTimer 中，同时还需要将延时任务添加到每个 key 的 Watchers 中？监听这些 key 的意义又是什么呢？\n\n要理解这一设计，就需要回到本小节开头我们对于 DelayedOperation 抽象类设计的讨论，既然已经有了定时器 SystemTimer 可以执行延时任务，为什么还要实现 DelayedOperation 和 DelayedOperationPurgatory 呢？因为单从时间维度不能覆盖所有的应用场景，而将延时任务记录到其关注的 key 对应的 Watchers 对象中，在相关条件满足时，我们可以通过 key 获取到对应的延时任务，并调用 `DelayedOperation#forceComplete` 方法提前执行满足执行条件的延时任务，从而能够从多个维度对延时任务进行控制。\n\n方法 `DelayedOperationPurgatory#checkAndComplete` 用于检测关注指定 key 的延时任务是否满足执行条件，如果满足则触发执行，方法实现如下：\n\n```scala\ndef checkAndComplete(key: Any): Int = {\n    // 获取 key 对应的 Watchers 对象\n    val watchers = inReadLock(removeWatchersLock) {\n        watchersForKey.get(key)\n    }\n    if (watchers == null) 0\n    // 如果存在对应的 Watchers 对象，则对记录在其中待执行的延时任务尝试触发执行，并移除已经执行完成的任务\n    else watchers.tryCompleteWatched()\n}\n\n// Watchers#tryCompleteWatched\ndef tryCompleteWatched(): Int = {\n    var completed = 0\n\n    // 遍历处理当前 Watchers 对象中的延时任务\n    val iter = operations.iterator()\n    while (iter.hasNext) {\n        val curr = iter.next()\n        // 如果对应的延时任务已经执行完成，则从 Watchers 中移除\n        if (curr.isCompleted) {\n            iter.remove()\n        }\n        // 尝试执行延时任务\n        else if (curr.safeTryComplete()) {\n            iter.remove()\n            completed += 1\n        }\n    }\n\n    // 如果 key 对应的 Watchers 已空，则将 key 从 watchersForKey 中移除，防止内存泄露\n    if (operations.isEmpty) removeKeyIfEmpty(key, this)\n\n    completed\n}\n```\n\n上述方法会获取指定 key 对应的 Watchers 对象，并遍历 Watchers 中记录的延时任务，如果对应的延时任务已经完成执行，则将其从 Watchers 对象中移除；否则，会调用 `DelayedOperation#safeTryComplete` 方法尝试执行对应的延时任务；如果当前 key 的 Watchers 对象已经没有待执行的延时任务，则将 key 从 DelayedOperationPurgatory 中移除，避免因为持有对应 key 对象的引用，导致无法被 GC，而最终导致内存泄露。\n\n### 基于炼狱的延时任务调度示例\n\n上面分析了这么多，本小节我们列举几个基于炼狱调度的真实延时任务示例，进一步加深对 Kafka 延时任务调度机制的理解。前面分析过的 DelayedOperation 是一个抽象类，围绕该抽象类派生出多个子类，本小节我们主要分析其中 2 个比较典型的延时任务实现：DelayedProduce 和 DelayedFetch。\n\n#### DelayedProduce\n\n当生产者追加消息到集群时（对应 ProduceRequest 请求），实际上是与对应 topic 分区的 leader 副本进行交互，当消息写入 leader 副本成功后，为了保证 leader 节点宕机时消息数据不丢失，一般需要将消息同步到位于 ISR 集合中的全部 follower 副本，只有当 ISR 集合中所有的 follower 副本成功完成对当前消息的记录之后才认为本次消息追加操作是成功的。这里就存在一个延时任务的适用场景，即当消息被成功追加到 leader 副本之后，我们需要创建一个延时任务等待 ISR 集合中所有的 follower 副本完成同步，并在同步操作完成之后对生产者的请求进行响应，Kafka 定义了 DelayedProduce 类来处理这类需求。\n\nDelayedProduce 继承自 DelayedOperation 抽象类，其字段定义如下：\n\n```scala\nclass DelayedProduce(delayMs: Long, // 延迟时长\n                 produceMetadata: ProduceMetadata, // 用于判断 DelayedProduce 是否满足执行条件\n                 replicaManager: ReplicaManager, // 副本管理器\n                 responseCallback: Map[TopicPartition, PartitionResponse] => Unit // 回调函数，在任务满足条件或到期时执行\n                ) extends DelayedOperation(delayMs) {\n\n// ... 省略方法定义\n\n}\n```\n\n其中 ReplicaManager 用于管理一个 broker 节点上的所有分区副本信息，我们将在下一篇中对其进行深入分析，这里我们主要来看一下 ProduceMetadata 样例类，定义如下：\n\n```scala\ncase class ProduceMetadata(produceRequiredAcks: Short, // 对应 acks 值设置\n                           produceStatus: Map[TopicPartition, ProducePartitionStatus]) { // 记录每个 topic 分区对应的消息追加状态\n}\n\ncase class ProducePartitionStatus(requiredOffset: Long, // 对应 topic 分区最后一条消息的 offset\n                                  responseStatus: PartitionResponse) { // 记录 ProducerResponse 中的错误码\n\n    /** 标识是否正在等待 ISR 集合中的 follower 副本从 leader 副本同步 requiredOffset 之前的消息 */\n    @volatile var acksPending = false\n\n}\n```\n\nProduceMetadata 类记录了当前延时任务所关注的 topic 分区的消息追加状态，DelayedProduce 延时任务在被构造时会依据消息写入对应 topic 分区 leader 副本是否成功来对其进行初始化：\n\n```scala\n// 依据消息写入 leader 分区操作的错误码对 produceMetadata 的 produceStatus 进行初始化\nproduceMetadata.produceStatus.foreach { case (topicPartition, status) =>\n    if (status.responseStatus.error == Errors.NONE) {\n        // 对应 topic 分区消息写入 leader 副本成功，等待其它副本同步\n        status.acksPending = true\n        status.responseStatus.error = Errors.REQUEST_TIMED_OUT // 默认错误码\n    } else {\n        // 对应 topic 分区消息写入 leader 副本失败，无需等待\n        status.acksPending = false\n    }\n}\n```\n\n下面来看一下 `DelayedProduce#tryComplete` 方法实现，该方法会检测当前延时任务所关注的 topic 分区的运行状态，当满足以下 3 个条件之一时则认为无需再继续等待对应的 topic 分区：\n\n1. 对应 topic 分区的 leader 副本不再位于当前 broker 节点上。\n2. 检查 ISR 集合中的所有 follower 副本是否完成同步时出现异常。\n3. ISR 集合中所有的 follower 副本完成了同步操作。\n\n```scala\noverride def tryComplete(): Boolean = {\n    // 遍历处理所有的 topic 分区\n    produceMetadata.produceStatus.foreach { case (topicPartition, status) =>\n        trace(s\"Checking produce satisfaction for $topicPartition, current status $status\")\n        // 仅处理正在等待 follower 副本复制的分区\n        if (status.acksPending) {\n            val (hasEnough, error) = replicaManager.getPartition(topicPartition) match {\n                case Some(partition) =>\n                    // 检测对应分区本次追加的最后一条消息是否已经被 ISR 集合中所有的 follower 副本同步\n                    partition.checkEnoughReplicasReachOffset(status.requiredOffset)\n                case None =>\n                    // 找不到对应的分区对象，说明对应分区的 leader 副本已经不在当前 broker 节点上\n                    (false, Errors.UNKNOWN_TOPIC_OR_PARTITION)\n            }\n            // 出现异常，或所有的 ISR 副本已经同步完成\n            if (error != Errors.NONE || hasEnough) {\n                status.acksPending = false // 不再等待\n                status.responseStatus.error = error\n            }\n        }\n    }\n\n    // 如果所有的 topic 分区都已经满足了 DelayedProduce 的执行条件，即不存在等待 ack 的分区，则结束本次延时任务\n    if (!produceMetadata.produceStatus.values.exists(_.acksPending))\n        forceComplete()\n    else\n        false\n}\n```\n\n如果所有的 topic 分区均不再处于等待状态，则上述方法会触发执行 `DelayedProduce#forceComplete` 操作，即调用 `DelayedProduce#onComplete` 方法以回调的形式将各个 topic 分区对应的响应状态发送给客户端。\n\n#### DelayedFetch\n\n消费者和 follower 副本均会向目标 topic 分区的 leader 副本所在 broker 节点发送 FetchRequest 请求来拉取消息，从接收到请求到准备消息数据，再到发送响应之间的过程同样适用于延时任务，Kafka 定义了 DelayedFetch 类来处理这类需求。\n\nDelayedFetch 同样继承自 DelayedOperation 抽象类，其字段定义如下：\n\n```scala\nclass DelayedFetch(delayMs: Long, // 延时任务延迟时长\n               fetchMetadata: FetchMetadata, // 记录对应 topic 分区的状态信息，用于判定当前延时任务是否满足执行条件\n               replicaManager: ReplicaManager, // 副本管理器\n               quota: ReplicaQuota,\n               responseCallback: Seq[(TopicPartition, FetchPartitionData)] => Unit // 响应回调函数\n              ) extends DelayedOperation(delayMs) {\n\n    // ... 省略方法定义\n\n}\n```\n\n其中 FetchMetadata 类型字段 `DelayedFetch#fetchMetadata` 用于记录当前延时任务关注的 topic 分区的状态信息，用于判定当前延时任务是否满足执行条件。样例类 FetchMetadata 的定义如下：\n\n```scala\ncase class FetchMetadata(fetchMinBytes: Int, // 读取的最小字节数\n                         fetchMaxBytes: Int, // 读取的最大字节数\n                         hardMaxBytesLimit: Boolean,\n                         fetchOnlyLeader: Boolean, // 是否只读 leader 副本的消息，一般 debug 模式下可以读 follower 副本的数据\n                         fetchOnlyCommitted: Boolean, // 是否只读已完成提交的消息（即 HW 之前的消息），如果是来自消费者的请求则该参数是 true，如果是 follower 则该参数是 false\n                         isFromFollower: Boolean, // fetch 请求是否来自 follower\n                         replicaId: Int, // fetch 的副本 ID\n                         fetchPartitionStatus: Seq[(TopicPartition, FetchPartitionStatus)]) { // 记录每个 topic 分区的 fetch 状态\n\n}\n\ncase class FetchPartitionStatus(startOffsetMetadata: LogOffsetMetadata, fetchInfo: PartitionData) {\n\n}\n```\n\n下面来看一下 `DelayedFetch#tryComplete` 方法的实现，当满足以下 4 个条件之一时会触发执行延时任务：\n\n1. 对应 topic 分区的 leader 副本不再位于当前 broker 节点上。\n2. 请求拉取消息的 topic 分区在当前 broker 节点上找不到。\n3. 请求拉取消息的 offset 不位于 activeSegment 对象上，可能已经创建了新的 activeSegment，或者 Log 被截断。\n4. 累计读取的字节数已经达到所要求的最小字节数。\n\n```scala\noverride def tryComplete(): Boolean = {\n    var accumulatedSize = 0\n    var accumulatedThrottledSize = 0\n    // 遍历处理当前延时任务关注的所有 topic 分区的状态信息\n    fetchMetadata.fetchPartitionStatus.foreach { case (topicPartition, fetchStatus) =>\n        // 获取上次拉取消息的结束 offset\n        val fetchOffset = fetchStatus.startOffsetMetadata\n        try {\n            if (fetchOffset != LogOffsetMetadata.UnknownOffsetMetadata) {\n                // 获取 topic 分区的 leader 副本\n                val replica = replicaManager.getLeaderReplicaIfLocal(topicPartition)\n                // 依据发起请求是消费者还是 follower 来确定拉取消息的结束 offset\n                val endOffset = if (fetchMetadata.fetchOnlyCommitted) replica.highWatermark else replica.logEndOffset\n\n                // 校验上次拉取消息完成之后，endOffset 是否发生变化，如果未发送变化则说明数据不够，没有继续的必要，否则继续执行\n                if (endOffset.messageOffset != fetchOffset.messageOffset) {\n                    if (endOffset.onOlderSegment(fetchOffset)) {\n                        // 条件 3，endOffset 相对于 fetchOffset 较小，说明请求不位于当前 activeSegment 上\n                        debug(\"Satisfying fetch %s since it is fetching later segments of partition %s.\".format(fetchMetadata, topicPartition))\n                        return forceComplete()\n                    } else if (fetchOffset.onOlderSegment(endOffset)) {\n                        // 条件 3，fetchOffset 位于 endOffset 之前，但是 fetchOffset 落在老的 LogSegment 上，而非 activeSegment 上\n                        debug(\"Satisfying fetch %s immediately since it is fetching older segments.\".format(fetchMetadata))\n                        if (!replicaManager.shouldLeaderThrottle(quota, topicPartition, fetchMetadata.replicaId)) return forceComplete()\n                    } else if (fetchOffset.messageOffset < endOffset.messageOffset) {\n                        // fetchOffset 和 endOffset 位于同一个 LogSegment 上，计算累计读取的字节数\n                        val bytesAvailable = math.min(endOffset.positionDiff(fetchOffset), fetchStatus.fetchInfo.maxBytes)\n                        if (quota.isThrottled(topicPartition)) accumulatedThrottledSize += bytesAvailable\n                        else accumulatedSize += bytesAvailable\n                    }\n                }\n            }\n        } catch {\n            // 条件 2，请求 fetch 的 topic 分区在当前 broker 节点上找不到\n            case _: UnknownTopicOrPartitionException => // Case B\n                debug(\"Broker no longer know of %s, satisfy %s immediately\".format(topicPartition, fetchMetadata))\n                return forceComplete()\n            // 条件 1，对应 topic 分区的 leader 副本不再位于当前 broker 节点上\n            case _: NotLeaderForPartitionException => // Case A\n                debug(\"Broker is no longer the leader of %s, satisfy %s immediately\".format(topicPartition, fetchMetadata))\n                return forceComplete()\n        }\n    }\n\n    // 条件 4，累计读取的字节数已经达到最小字节限制\n    if (accumulatedSize >= fetchMetadata.fetchMinBytes\n            || ((accumulatedSize + accumulatedThrottledSize) >= fetchMetadata.fetchMinBytes && !quota.isQuotaExceeded()))\n        forceComplete()\n    else\n        false\n}\n```\n\n如果延时任务满足执行条件，则会触发执行 `DelayedFetch#forceComplete` 方法，即调用 `DelayedFetch#onComplete` 方法以回调的形式将各个 topic 分区对应的响应数据封装成 FetchPartitionData 对象发送给请求方。\n\n### 总结\n\n本文介绍了 Kafka 基于分层时间轮算法实现的延时任务调度策略，相对于 JDK 内建的实现具备更加高效的性能，并支持除时间维度以外多维度的任务触发机制。这一部分的相关实现相对比较独立和通用，感兴趣的读者可以将其抽取出来作为基础组件用于自己的项目中。\n","tags":["Kafka"],"categories":["kafka"]},{"title":"Kafka 源码解析：日志数据存储机制","url":"/2019/06/22/kafka/kafka-log-manage/","content":"\n日志数据（亦称消息数据）的存储机制在 Kafka 整个设计与实现中既基础又核心。Kafka 采用本地文件系统对日志数据进行存储，并允许为一个 broker 节点设置多个 log 文件目录，每个 log 目录下存储的数据又按照 topic 分区进行划分，其中包含了一个 topic 分区名下消息数据对应的多组日志和索引文件。\n\nKafka 定义了 LogSegment 类和 Log 类对日志和索引数据进行管理，并定义了 LogManager 类管理一个 broker 节点下的所有 Log 对象，同时基于 Log 对象提供了对日志数据的加载、创建、删除，以及查询等功能，同时还维护了多个定时任务对日志数据执行清理、删除、刷盘，以及记录 HW 位置等操作，并提供了对 key 重复的消息数据执行压缩的机制。<!-- more -->\n\n![image](/images/2019/kafka-log-organization.png)\n\n上图展示了 topic、partition、replica、Log 和 LogSegment 之间的组织关系。在具体实现时组织如下：\n\n- 一个 broker 节点允许指定多个 log 目录，每个目录下包含多个以“topic-partition”命名的目录，即一个 log 目录下存储了多个 topic 分区对应的消息数据，并且一个 topic 分区只允许属于一个 log 目录。\n- 每个 topic 分区目录下包含多组日志（log）和索引（index、timeindex）文件，Kafka 定义了 LogSegment 类用于封装一组日志和索引文件。\n- 每个 topic 分区对应一个 Log 类对象（一个 broker 节点上只允许存放分区的一个副本，所以从 broker 视角来看一个分区对应一个 Log 类对象），其中包含了一系列隶属对应 topic 分区的 LogSegment 对象，Log 类采用跳跃表（SkipList）数据结构对这些 LogSegment 对象进行管理。\n\n![image](/images/2019/kafka-log-file.png)\n\n上图进一步展示了 Log 与 LogSegment 之间的组织关系，以及 LogSegment 在 Log 中基于 SkipList 的组织形式（其中青色小圆圈表示单个 LogSegment 对象）。\n\n### LogSegment 组件\n\n每个 topic 分区目录下通常会包含多个 log 文件，这些 log 文件 __以其中保存的消息的起始 offset 命名__ 。每个 log 文件由一个 LogSegment 对象进行管理，其中还包含了对应的 index 和 timeindex 文件。下面是关于某个 topic 分区目录下的文件列表（生产环境中一个 topic 分区目录下一般存在多组类似下面这样的文件）：\n\n```bash\n$ ls topic-default-0/\n00000000000000000122.index  00000000000000000122.log  00000000000000000122.timeindex\n```\n\nLogSegment 类的字段定义如下：\n\n```scala\nclass LogSegment(val log: FileRecords, // log 文件对象\n                 val index: OffsetIndex, // index 文件对象\n                 val timeIndex: TimeIndex, // timeindex 文件对象\n                 val baseOffset: Long, // 当前日志分片文件中第一条消息的 offset 值\n                 val indexIntervalBytes: Int, // 索引项之间间隔的最小字节数，对应 index.interval.bytes 配置\n                 val rollJitterMs: Long,\n                 time: Time) extends Logging {\n\n    /** 当前 LogSegment 的创建时间 */\n    private var created = time.milliseconds\n    /** 自上次添加索引项后，在 log 文件中累计加入的消息字节数 */\n    private var bytesSinceLastIndexEntry = 0\n    /** The timestamp we used for time based log rolling */\n    private var rollingBasedTimestamp: Option[Long] = None\n    /** 已追加消息的最大时间戳 */\n    @volatile private var maxTimestampSoFar = timeIndex.lastEntry.timestamp\n    /** 已追加的具备最大时间戳的消息对应的 offset */\n    @volatile private var offsetOfMaxTimestamp = timeIndex.lastEntry.offset\n\n    // ... 省略方法定义\n\n}\n```\n\n其中 FileRecords 类用于封装和管理对应的 log 文件，OffsetIndex 类用于封装和管理对应的 index 文件，TimeIndex 类用于封装和管理对应的 timeindex 文件。这是支撑 Kafka 日志数据存储的 3 个基础类，要理解 Kafka 的日志存储机制，我们需要先理解这 3 个类的定义。\n\n- __FileRecords__\n\nFileRecords 类用于描述和管理日志（分片）文件数据，对应一个 log 文件，其字段定义如下：\n\n```java\npublic class FileRecords extends AbstractRecords implements Closeable {\n\n    /** 标识是否为日志文件分片 */\n    private final boolean isSlice;\n    /** 分片的起始位置 */\n    private final int start;\n    /** 分片的结束位置 */\n    private final int end;\n    /** 浅层拷贝 */\n    private final Iterable<FileChannelLogEntry> shallowEntries;\n    /** 如果是分片则表示分片的大小（end - start），如果不是分片则表示整个日志文件的大小 */\n    private final AtomicInteger size;\n    /** 读写对应的日志文件的通道 */\n    private final FileChannel channel;\n    /** 日志文件对象 */\n    private volatile File file;\n\n    // ... 省略方法定义\n\n}\n```\n\nFileRecords 主要定义了对日志数据的追加、读取、删除、查找、截断，以及刷盘等操作，并依赖于 LogEntry 类对单条日志数据的 offset 和 value 进行封装，同时提供了对 log 文件中日志数据的 __浅层遍历__ 和 __深层遍历__ 操作。日志数据在追加到 log 文件中之前可能会执行压缩操作，所谓浅层遍历是指在遍历 log 文件中的日志数据时将压缩后的数据看做是一个整体，而深层遍历则会尝试对这部分日志数据执行解压缩，并返回解压缩后的单条消息。\n\n下面的示例中展示了一个具体的日志文件数据的部分内容（即前面提及的 `00000000000000000122.log` 文件）：\n\n```text\nLogEntry(122, Record(magic = 1, attributes = 0, compression = NONE, crc = 300223964, CreateTime = 1553937143494, key = 4 bytes, value = 16 bytes))\nLogEntry(123, Record(magic = 1, attributes = 0, compression = NONE, crc = 1516889930, CreateTime = 1553937143505, key = 4 bytes, value = 16 bytes))\nLogEntry(124, Record(magic = 1, attributes = 0, compression = NONE, crc = 1201423931, CreateTime = 1553937143507, key = 4 bytes, value = 16 bytes))\nLogEntry(125, Record(magic = 1, attributes = 0, compression = NONE, crc = 1592544380, CreateTime = 1553937143507, key = 4 bytes, value = 16 bytes))\nLogEntry(126, Record(magic = 1, attributes = 0, compression = NONE, crc = 599198486, CreateTime = 1553937143508, key = 4 bytes, value = 16 bytes))\nLogEntry(127, Record(magic = 1, attributes = 0, compression = NONE, crc = 980691361, CreateTime = 1553937143509, key = 4 bytes, value = 16 bytes))\nLogEntry(128, Record(magic = 1, attributes = 0, compression = NONE, crc = 4047753804, CreateTime = 1553937143511, key = 4 bytes, value = 16 bytes))\nLogEntry(129, Record(magic = 1, attributes = 0, compression = NONE, crc = 4289660679, CreateTime = 1553937143511, key = 4 bytes, value = 16 bytes))\nLogEntry(130, Record(magic = 1, attributes = 0, compression = NONE, crc = 4016824904, CreateTime = 1553937143512, key = 4 bytes, value = 16 bytes))\nLogEntry(131, Record(magic = 1, attributes = 0, compression = NONE, crc = 3305927143, CreateTime = 1553937143512, key = 4 bytes, value = 16 bytes))\nLogEntry(132, Record(magic = 1, attributes = 0, compression = NONE, crc = 3847705666, CreateTime = 1553937143513, key = 4 bytes, value = 16 bytes))\n\n...\n```\n\n上面的示例中我们基于深层遍历调用 `LogEntry#toString` 方法打印了单条消息的概要信息。\n\n- __OffsetIndex__\n\nOffsetIndex 类用于描述和管理索引文件数据，定义了对 index 文件的检索、追加，以及截断等功能。一个 OffsetIndex 对象对应一个 index 文件，用于提高消息检索的性能。下面的示例中展示了一个具体的 index 文件数据的部分内容（即前面提及的 `00000000000000000122.index` 文件）：\n\n```text\n165, 8910\n252, 13608\n355, 19170\n658, 35532\n961, 51894\n1191, 64314\n1494, 80676\n1797, 97038\n2100, 113400\n2403, 129762\n\n...\n```\n\nOffsetIndex 的索引项由 8 个字节构成，其中前面 4 个字节表示消息的相对 offset，后面 4 个字节表示消息所在文件的物理地址（position），其中相对 offset 参考的偏移量是对应文件的起始 offset，这样的设计将原本 long 类型（8 字节）的消息 offset 转换成 int 类型（4 字节）的相对 offset 进行存储，能够减少空间占用。此外，Kafka 在构造 index 文件（包括下面要介绍的 timeindex 文件）时并不会针对每个 offset 都建立对应的索引项，而是采用隔一段区间打一个点的稀疏索引机制，以进一步减少对磁盘空间的消耗。\n\n- __TimeIndex__\n\nTimeIndex 类同样用于描述和管理索引文件数据，提供了基于时间戳检索日志数据的功能，对应 timeindex 文件。区别于 OffsetIndex 的地方在于 TimeIndex 的索引项由 12 个字节构成，其中前面 8 个字节表示当前 offset 之前已追加消息的最大时间戳（毫秒），后面 4 个字节表示相对 offset，等价于 OffsetIndex 索引项的前 4 个字节。下面的示例中展示了一个具体的 timeindex 文件数据的部分内容（即前面提及的 `00000000000000000122.timeindex` 文件）：\n\n```text\n1553937143565, 251\n1553937143570, 284\n1553937143594, 649\n1553937143609, 944\n1553937143631, 1166\n1553937143652, 1483\n1553937143669, 1770\n1553937143691, 2096\n1553937143707, 2378\n1553937143714, 2676\n\n...\n```\n\nLogSegment 可以看做是对一组日志和索引文件数据的封装，并提供了对这些数据执行追加、读取、截断、删除、刷盘，以及重建等功能。本小节接下来的内容，我们重点分析一下 LogSegment 中主要的日志和索引文件数据操作方法，包括：`LogSegment#append`、`LogSegment#read` 和 `LogSegment#recover` 方法，其它方法在实现上都比较简单，读者要是感兴趣的话可以自己阅读源码。\n\n#### 追加日志数据\n\n本小节来看一下 `LogSegment#append` 方法的实现，该方法用于往当前 LogSegment 对应的 log 文件中追加消息数据，并在需要时更新对应的 index 和 timeindex 索引数据。方法实现如下：\n\n```scala\ndef append(firstOffset: Long, // 待追加消息的起始 offset\n           largestOffset: Long, // 待追加消息中的最大 offset\n           largestTimestamp: Long, // 待追加消息中的最大时间戳\n           shallowOffsetOfMaxTimestamp: Long, // 最大时间戳消息对应的 offset\n           records: MemoryRecords) { // 待追加的消息数据\n    if (records.sizeInBytes > 0) {\n        trace(\"Inserting %d bytes at offset %d at position %d with largest timestamp %d at shallow offset %d\"\n                .format(records.sizeInBytes, firstOffset, log.sizeInBytes(), largestTimestamp, shallowOffsetOfMaxTimestamp))\n        // 获取物理位置（当前分片的大小）\n        val physicalPosition = log.sizeInBytes()\n        if (physicalPosition == 0) rollingBasedTimestamp = Some(largestTimestamp)\n\n        require(canConvertToRelativeOffset(largestOffset), \"largest offset in message set can not be safely converted to relative offset.\")\n\n        // 将消息数据追加到 log 文件\n        val appendedBytes = log.append(records)\n        trace(s\"Appended $appendedBytes to ${log.file()} at offset $firstOffset\")\n\n        // 更新已追加的消息对应的最大时间戳，及其 offset\n        if (largestTimestamp > maxTimestampSoFar) {\n            maxTimestampSoFar = largestTimestamp\n            offsetOfMaxTimestamp = shallowOffsetOfMaxTimestamp\n        }\n\n        // 如果当前累计追加的日志字节数超过阈值（对应 index.interval.bytes 配置）\n        if (bytesSinceLastIndexEntry > indexIntervalBytes) {\n            // 更新 index 和 timeindex 文件\n            index.append(firstOffset, physicalPosition)\n            timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp)\n            bytesSinceLastIndexEntry = 0 // 重置当前累计追加的日志字节数\n        }\n        // 更新累计加入的日志字节数\n        bytesSinceLastIndexEntry += records.sizeInBytes\n    }\n}\n```\n\n如果当前追加的消息数据是有效的，则 LogSegment 会调用 `FileRecords#append` 方法将消息数据追加到对应的 log 文件中，并更新本地记录的已追加消息的最大时间戳及其 offset。前面我们介绍了 Kafka 并不会对每条消息都建立索引，而是采用稀疏索引的策略间隔指定大小的字节数（对应 `index.interval.bytes` 配置）建立索引项，如果当前累计追加的消息字节数超过该配置值，则 Kafka 会更新对应的 index 和 timeindex 数据。\n\n#### 读取日志数据\n\n下面来看一下 `LogSegment#read` 方法，该方法用于从 LogSegment 对应的 log 文件中读取指定区间的消息数据，读取的消息内容由 startOffset、maxOffset、maxSize 和 maxPosition 这 4 个参数确定。方法实现如下：\n\n```scala\ndef read(startOffset: Long, // 读取消息的起始 offset\n         maxOffset: Option[Long], // 读取消息的结束 offset\n         maxSize: Int, // 读取消息的最大字节数\n         maxPosition: Long = size, // 读取消息的最大物理地址\n         minOneMessage: Boolean = false): FetchDataInfo = {\n\n    if (maxSize < 0)\n        throw new IllegalArgumentException(\"Invalid max size for log read (%d)\".format(maxSize))\n\n    // 获取当前 log 文件的字节大小\n    val logSize = log.sizeInBytes // this may change, need to save a consistent copy\n    // 获取小于等于 startOffset 的最大 offset 对应的物理地址 position\n    val startOffsetAndSize = this.translateOffset(startOffset)\n\n    // 如果读取的位置超出了当前文件，直接返回 null\n    if (startOffsetAndSize == null) return null\n\n    val startPosition = startOffsetAndSize.position // 起始 position\n    val offsetMetadata = new LogOffsetMetadata(startOffset, baseOffset, startPosition)\n\n    // 更新读取消息的最大字节数\n    val adjustedMaxSize = if (minOneMessage) math.max(maxSize, startOffsetAndSize.size) else maxSize\n    // 如果请求读取的消息最大字节数为 0，则返回一个空的结果对象\n    if (adjustedMaxSize == 0)\n        return FetchDataInfo(offsetMetadata, MemoryRecords.EMPTY)\n\n    // 计算待读取的字节数\n    val length = maxOffset match {\n        // 如果未指定读取消息的结束位置\n        case None =>\n            // 直接读取到指定的最大物理地址\n            min((maxPosition - startPosition).toInt, adjustedMaxSize)\n        // 如果指定了读取消息的结束位置\n        case Some(offset) =>\n            // 如果结束位置小于起始位置，则直接返回一个空的结果对象\n            if (offset < startOffset)\n                return FetchDataInfo(offsetMetadata, MemoryRecords.EMPTY)\n            // 将结束位置 offset 转换成对应的物理地址\n            val mapping = this.translateOffset(offset, startPosition)\n            // 如果结束位置 maxOffset 超出当前日志文件，则使用日志文件长度\n            val endPosition = if (mapping == null) logSize else mapping.position\n            // 由 maxOffset、maxPosition，以及 maxSize 共同决定最终读取长度\n            min(min(maxPosition, endPosition) - startPosition, adjustedMaxSize).toInt\n    }\n\n    // 读取对应的消息数据，并封装成 FetchDataInfo 对象返回\n    FetchDataInfo(\n        offsetMetadata,\n        log.read(startPosition, length),\n        firstEntryIncomplete = adjustedMaxSize < startOffsetAndSize.size)\n}\n```\n\n上述方法的主要逻辑在于确定读取消息的起始位置和读取长度，并最终需要调用 `FileRecords#read` 方法读取消息数据，该方法接收 2 个参数：position 和 size。参数 position 指代读取消息的起始物理地址，而 size 指代读取消息的字节数，而上述方法的主要逻辑就在于基于参数给定的 4 个坐标来确定 position 和 size 值。\n\n参数 startOffset 设置了当前要读取的消息的起始相对 offset，而 position 是物理地址，所以需要调用 `LogSegment#translateOffset` 方法进行转换，该方法基于 __二分查找算法__ 从 index 文件中获取小于等于 startOffset 的最大 offset 对应的物理地址。实现如下：\n\n```scala\nprivate[log] def translateOffset(offset: Long, startingFilePosition: Int = 0): LogEntryPosition = {\n    // 基于二分查找获取小于等于参数 offset 的最大 offset，返回 offset 与对应的物理地址\n    val mapping = index.lookup(offset)\n    // 查找对应的物理地址 position\n    log.searchForOffsetWithSize(offset, max(mapping.position, startingFilePosition))\n}\n```\n\n确定好读取的起始物理地址之后，接下来就需要计算读取的消息字节数 size 值，另外 3 个参数（maxOffset、maxSize 和 maxPosition）用来约束生成 size 值，策略如下：\n\n1. 如果未指定 maxOffset，则 size 等于 `max((maxPosition - startPosition), maxSize)`；\n2. 如果指定了 maxOffset，需要保证 maxOffset 大于等于 startOffset，然后获取 maxOffset 对应的物理地址，并将该物理地址与 maxPosition 进行比较，选择较小的一个与 startPosition 计算得到对应的 size 值，并保证该 size 值不超过 maxSize。\n\n如果能够基于参数计算得到正确的 position 和 size 值，则方法会依据这两个值调用 `FileRecords#read` 方法读取对应的消息数据，并封装成 FetchDataInfo 对象返回。\n\n#### 重建索引数据\n\n最后来看一下 `LogSegment#recover` 方法，该方法用于对 log 文件重建相应的 index 和 timeindex 文件，并校验 log 中数据的有效性。方法实现如下：\n\n```scala\ndef recover(maxMessageSize: Int): Int = {\n    // 清空 index 和 timeindex 文件\n    index.truncate()\n    index.resize(index.maxIndexSize)\n    timeIndex.truncate()\n    timeIndex.resize(timeIndex.maxIndexSize)\n    var validBytes = 0 // 记录通过验证的字节数\n    var lastIndexEntry = 0 // 最后一个索引项对应的物理地址\n    maxTimestampSoFar = Record.NO_TIMESTAMP\n    try {\n        // 遍历 log 文件，重建索引\n        for (entry <- log.shallowEntries(maxMessageSize).asScala) {\n            // 获取对应的消息 Record 对象\n            val record = entry.record\n            // 校验消息数据的有效性，如果存在问题则抛出异常\n            record.ensureValid()\n\n            // 更新本地记录的消息最大时间戳及其 offset 值\n            if (record.timestamp > maxTimestampSoFar) {\n                maxTimestampSoFar = record.timestamp\n                offsetOfMaxTimestamp = entry.offset\n            }\n\n            // 如果当前字节减去上一次记录索引的字节超过设置的索引项之间间隔的最小字节数，则添加索引项\n            if (validBytes - lastIndexEntry > indexIntervalBytes) {\n                val startOffset = entry.firstOffset\n                index.append(startOffset, validBytes)\n                timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp)\n                lastIndexEntry = validBytes\n            }\n            validBytes += entry.sizeInBytes()\n        }\n    } catch {\n        case e: CorruptRecordException =>\n            logger.warn(\"Found invalid messages in log segment %s at byte offset %d: %s.\".format(log.file.getAbsolutePath, validBytes, e.getMessage))\n    }\n    // 截断日志和索引文件中无效的字节\n    val truncated = log.sizeInBytes - validBytes\n    log.truncateTo(validBytes)\n    index.trimToValidSize()\n    // A normally closed segment always appends the biggest timestamp ever seen into log segment, we do this as well.\n    timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp, skipFullCheck = true)\n    timeIndex.trimToValidSize()\n    truncated\n}\n```\n\n重建的过程实际上就是遍历 log 文件，并依据设置的索引项最小间隔字节数（对应 `index.interval.bytes` 配置）区间建立稀疏索引，期间会基于 `Record#ensureValid` 方法采用 CRC 校验消息数据的有效性，如果存在无效的数据，则退出循环并移除之后的日志和索引。\n\n### Log 组件\n\n在一个 log 目录下存在多个以“topic-partition”命名的分区目录，每个 topic 分区对应一个 Log 对象（更准确来说是一个分区副本对应一个 Log 对象），用于管理名下的 LogSegment 对象集合， __Log 类使用 SkipList 数据结构对 LogSegment 进行组织和管理__ 。在 SkipList 中以 LogSegment 的 baseOffset 为 key，以 LogSegment 对象自身作为 value。当读取消息数据时，我们可以基于 offset 快速定位到对应的 LogSegment 对象，然后调用 `LogSegment#read` 方法读取消息数据。当写入消息时，Kafka 并不允许向 SkipList 中的任意一个 LogSegment 对象追加数据，而只允许往 SkipList 中的最后一个 LogSegment 追加数据，Log 类提供了 `Log#activeSegment` 用于获取该 LogSegment 对象，称之为 activeSegment。\n\nLog 类的字段定义如下：\n\n```scala\nclass Log(@volatile var dir: File, // 当前 Log 对象对应的 topic 分区目录\n          @volatile var config: LogConfig, // 配置信息\n          @volatile var recoveryPoint: Long = 0L, // 恢复操作的起始 offset，即 HW 位置，之前的消息已经全部落盘\n          scheduler: Scheduler, // 定时任务调度器\n          time: Time = Time.SYSTEM) extends Logging with KafkaMetricsGroup {\n\n    /** 最近一次执行 flush 操作的时间 */\n    private val lastflushedTime = new AtomicLong(time.milliseconds)\n    /**\n     * 用于记录分配给当前消息的 offset，也是当前副本的 LEO 值:\n     * - messageOffset 记录了当前 Log 对象下一条待追加消息的 offset 值\n     * - segmentBaseOffset 记录了 activeSegment 对象的 baseOffset\n     * - relativePositionInSegment 记录了 activeSegment 对象的大小\n     */\n    @volatile private var nextOffsetMetadata: LogOffsetMetadata = _\n    /**\n     * 当前 Log 包含的 LogSegment 集合，SkipList 结构：\n     * - 以 baseOffset 作为 key\n     * - 以 LogSegment 对象作为 value\n     */\n    private val segments: ConcurrentNavigableMap[java.lang.Long, LogSegment] = new ConcurrentSkipListMap[java.lang.Long, LogSegment]\n    /** 基于 topic 分区目录解析得到对应的 topic 分区对象 */\n    val topicPartition: TopicPartition = Log.parseTopicPartitionName(dir)\n    private val tags = Map(\"topic\" -> topicPartition.topic, \"partition\" -> topicPartition.partition.toString)\n    /** 当前 Log 对象对应的分区目录名称 */\n    def name: String = dir.getName\n\n    // ... 省略方法定义\n\n}\n```\n\n#### 初始化加载日志数据\n\nLog 类在实例化时会调用 `Log#loadSegments` 方法加载对应 topic 分区目录下的 log、index 和 timeindex 文件。该方法主要做了以下 4 件事情：\n\n1. 删除标记为 deleted 或 cleaned 的文件，将标记为 swap 的文件加入到交换集合中，等待后续继续完成交换过程；\n2. 加载 topic 分区目录下全部的 log 文件和 index 文件，如果对应的 index 不存在或数据不完整，则重建；\n3. 遍历处理 1 中记录的 swap 文件，使用压缩后的 LogSegment 替换压缩前的 LogSegment 集合，并删除压缩前的日志和索引文件；\n4. 后处理，如果对应 SkipList 为空则新建一个空的 activeSegment，如果不为空则校验 recoveryPoint 之后数据的完整性。\n\n方法 `Log#loadSegments` 的实现比较冗长，下面我们分步骤逐一分析各个过程，首先来看 __步骤 1__ ，实现如下：\n\n```scala\n// 1. 删除标记为 deleted 或 cleaned 的文件，将标记为 swap 的文件加入到交换集合中，等待后续继续完成交换过程\nfor (file <- dir.listFiles if file.isFile) {\n    if (!file.canRead) throw new IOException(\"Could not read file \" + file)\n    val filename = file.getName\n    // 如果是标记为 deleted 或 cleaned 的文件，则删除：\n    // - 其中 deleted 文件是指标识需要被删除的 log 文件或 index 文件\n    // - 其中 cleaned 文件是指在执行日志压缩过程中宕机，文件中的数据状态不明确，无法正确恢复的文件\n    if (filename.endsWith(DeletedFileSuffix) || filename.endsWith(CleanedFileSuffix)) {\n        file.delete()\n    }\n    // 如果是标记为 swap 的文件（可用于交换的临时文件），则说明日志压缩过程已完成，但是在执行交换过程中宕机，\n    // 因为 swap 文件已经保存了日志压缩后的完整数据，可以进行恢复：\n    // 1. 如果 swap 文件是 log 文件，则删除对应的 index 文件，稍后 swap 操作会重建索引\n    // 2. 如果 swap 文件是 index 文件，则直接删除，后续加载 log 文件时会重建索引\n    else if (filename.endsWith(SwapFileSuffix)) {\n        // 移除 swap 后缀\n        val baseName = new File(CoreUtils.replaceSuffix(file.getPath, SwapFileSuffix, \"\"))\n        // 如果是 index 文件，则直接删除，因为后续可以重建\n        if (baseName.getPath.endsWith(IndexFileSuffix)) {\n            file.delete()\n        }\n        // 如果是 log 文件，则删除对应的 index 文件\n        else if (baseName.getPath.endsWith(LogFileSuffix)) {\n            val index = new File(CoreUtils.replaceSuffix(baseName.getPath, LogFileSuffix, IndexFileSuffix))\n            index.delete()\n            swapFiles += file // 将当前文件加入到 swap 集合中\n        }\n    }\n}\n```\n\n这一步会遍历当前 topic 分区目录下的文件，并处理标记为 deleted、cleaned 和 swap 的文件（以这些名称作为文件后缀名）。这 3 类文件对应的含义为：\n\n- __deleted 文件__ ：标识需要被删除的 log 文件和 index 文件。\n- __cleaned 文件__ ：在执行日志压缩过程中宕机，文件中的数据状态不明确，无法正确恢复的文件。\n- __swap 文件__ ：完成执行日志压缩后的文件，但是在替换原文件时宕机。\n\n针对 deleted 和 cleaned 文件直接删除即可，对于 swap 文件来说，因为其中的数据是完整的，所以可以继续使用，只需再次完成 swap 操作即可。Kafka 针对 swap 文件的处理策略为：\n\n1. 如果 swap 文件是 log 文件，则删除对应的 index 文件，稍后的 swap 操作会重建索引。\n2. 如果 swap 文件是 index 文件，则直接删除，后续加载 log 文件时会重建索引。\n\n完成了对于一些异常状态文件的处理，__步骤 2__ 开始真正执行加载 log 和 index 文件的操作，实现如下：\n\n```scala\n// 2. 加载 topic 分区目录下全部的 log 文件和 index 文件，如果对应的 index 文件不存在或数据不完整，则重建\nfor (file <- dir.listFiles if file.isFile) {\n    val filename = file.getName\n    // 处理 index 和 timeindex 文件\n    if (filename.endsWith(IndexFileSuffix) || filename.endsWith(TimeIndexFileSuffix)) {\n        // 如果索引文件没有对应的 log 文件，则删除 index 文件\n        val logFile =\n            if (filename.endsWith(TimeIndexFileSuffix))\n                new File(file.getAbsolutePath.replace(TimeIndexFileSuffix, LogFileSuffix))\n            else\n                new File(file.getAbsolutePath.replace(IndexFileSuffix, LogFileSuffix))\n        if (!logFile.exists) {\n            warn(\"Found an orphaned index file, %s, with no corresponding log file.\".format(file.getAbsolutePath))\n            file.delete()\n        }\n    }\n    // 处理 log 文件\n    else if (filename.endsWith(LogFileSuffix)) {\n        // 获取 baseOffset 值\n        val start = filename.substring(0, filename.length - LogFileSuffix.length).toLong\n        // 创建对应的 index 文件对象\n        val indexFile = Log.indexFilename(dir, start)\n        // 创建对应的 timeindex 文件对象\n        val timeIndexFile = Log.timeIndexFilename(dir, start)\n        val indexFileExists = indexFile.exists()\n        val timeIndexFileExists = timeIndexFile.exists()\n\n        // 创建对应的 LogSegment 对象\n        val segment = new LogSegment(\n            dir = dir,\n            startOffset = start,\n            indexIntervalBytes = config.indexInterval,\n            maxIndexSize = config.maxIndexSize,\n            rollJitterMs = config.randomSegmentJitter,\n            time = time,\n            fileAlreadyExists = true)\n\n        // 如果对应的 index 文件存在，则校验数据完整性，如果不完整则重建\n        if (indexFileExists) {\n            try {\n                // 校验 index 文件的完整性\n                segment.index.sanityCheck()\n                // 如果对应的 timeindex 文件不存在，则重置对应的 mmb 对象\n                if (!timeIndexFileExists)\n                    segment.timeIndex.resize(0)\n                // 校验 timeindex 文件的完整性\n                segment.timeIndex.sanityCheck()\n            } catch {\n                // 索引文件完整性异常，删除重建\n                case e: java.lang.IllegalArgumentException =>\n                    warn(s\"Found a corrupted index file due to ${e.getMessage}}. deleting ${timeIndexFile.getAbsolutePath}, \" + s\"${indexFile.getAbsolutePath} and rebuilding index...\")\n                    indexFile.delete()\n                    timeIndexFile.delete()\n                    segment.recover(config.maxMessageSize)\n            }\n        }\n        // 如果对应的 index 文件不存在，则重建\n        else {\n            error(\"Could not find index file corresponding to log file %s, rebuilding index...\".format(segment.log.file.getAbsolutePath))\n            segment.recover(config.maxMessageSize)\n        }\n        // 记录 LogSegment 对象到 segments 集合中\n        segments.put(start, segment)\n    }\n}\n```\n\n如果当前文件是 index 文件，但对应的 log 文件不存在，则直接删除，因为没有继续保留的意义。如果当前是 log 文件，则这一步会创建 log 文件对应的 LogSegment 对象并记录到 SkipList 中。期间会校验 log 文件对应的 index 和 timeindex 文件，如果索引文件不存在或其中的数据不完整，则会调用前面介绍的 `LogSegment#recover` 方法重建索引。\n\n步骤 1 中将需要继续执行 swap 操作的文件记录到了 swapFiles 集合中， __步骤 3__ 的逻辑就是继续完成 swap 操作，实现如下：\n\n```scala\n// 3. 遍历处理步骤 1 中记录的 swap 文件，使用压缩后的 LogSegment 替换压缩前的 LogSegment 集合，并删除压缩前的日志和索引文件\nfor (swapFile <- swapFiles) {\n    // 移除 “.swap” 后缀\n    val logFile = new File(CoreUtils.replaceSuffix(swapFile.getPath, SwapFileSuffix, \"\"))\n    val fileName = logFile.getName\n    // 基于 log 文件名得到对应的 baseOffset 值\n    val startOffset = fileName.substring(0, fileName.length - LogFileSuffix.length).toLong\n    val indexFile = new File(CoreUtils.replaceSuffix(logFile.getPath, LogFileSuffix, IndexFileSuffix) + SwapFileSuffix) // .index.swap\n    val index = new OffsetIndex(indexFile, baseOffset = startOffset, maxIndexSize = config.maxIndexSize)\n    val timeIndexFile = new File(CoreUtils.replaceSuffix(logFile.getPath, LogFileSuffix, TimeIndexFileSuffix) + SwapFileSuffix) // .timeindex.swap\n    val timeIndex = new TimeIndex(timeIndexFile, baseOffset = startOffset, maxIndexSize = config.maxIndexSize)\n    // 创建对应的 LogSegment 对象\n    val swapSegment = new LogSegment(FileRecords.open(swapFile),\n        index = index,\n        timeIndex = timeIndex,\n        baseOffset = startOffset,\n        indexIntervalBytes = config.indexInterval,\n        rollJitterMs = config.randomSegmentJitter,\n        time = time)\n    info(\"Found log file %s from interrupted swap operation, repairing.\".format(swapFile.getPath))\n    // 依据 log 文件重建索引文件，同时校验 log 文件中消息的合法性\n    swapSegment.recover(config.maxMessageSize)\n    // 查找 swapSegment 获取 [baseOffset, nextOffset] 区间对应的日志压缩前的 LogSegment 集合，\n    // 区间中的 LogSegment 数据都压缩到了 swapSegment 中\n    val oldSegments = this.logSegments(swapSegment.baseOffset, swapSegment.nextOffset())\n    // 将 swapSegment 对象加入到 segments 中，并将 oldSegments 中所有的 LogSegment 对象从 segments 中删除，\n    // 同时删除对应的日志文件和索引文件，最后移除文件的 \".swap\" 后缀\n    this.replaceSegments(swapSegment, oldSegments.toSeq, isRecoveredSwapFile = true)\n}\n```\n\n在完成对日志数据的压缩操作后，会将压缩的结果先保存为 swap 文件（以“.swap”作为文件后缀），并最终替换压缩前的日志文件，所以 swap 文件中的数据都是完整，只需要移除对应的“.swap”后缀，并构建对应的 LogSegment 对象即可。但是这里不能简单的将对应的 LogSegment 对象记录到 SkipList 中就万事大吉了，因为 SkipList 中还存在着压缩前的原文件对应的 LogSegment 对象集合，所以需要先将这些 LogSegment 对象集合及其对应的 log 文件和索引文件删除，这也是 `Log#replaceSegments` 方法的主要逻辑。\n\n完成了前 3 步的工作， __步骤 4__ 会对前面加载的数据进行校验，实现如下：\n\n```scala\n// 4. 后处理，如果对应 SkipList 为空，则新建一个空的 activeSegment，如果不为空则校验 HW 之后数据的完整性\nif (logSegments.isEmpty) {\n    // 如果 SkipList 为空，则需要创建一个 activeSegment，保证 SkipList 能够正常操作\n    segments.put(0L, new LogSegment(dir = dir,\n        startOffset = 0,\n        indexIntervalBytes = config.indexInterval,\n        maxIndexSize = config.maxIndexSize,\n        rollJitterMs = config.randomSegmentJitter,\n        time = time,\n        fileAlreadyExists = false,\n        initFileSize = this.initFileSize(),\n        preallocate = config.preallocate))\n} else {\n    // 如果 SkipList 不为空，则需要对其中的数据进行验证\n    if (!dir.getAbsolutePath.endsWith(Log.DeleteDirSuffix)) {\n        // 处理 broker 节点异常关闭导致的数据异常，需要验证 [recoveryPoint, activeSegment] 中的所有消息，并移除验证失败的消息\n        this.recoverLog()\n        // reset the index size of the currently active log segment to allow more entries\n        activeSegment.index.resize(config.maxIndexSize)\n        activeSegment.timeIndex.resize(config.maxIndexSize)\n    }\n}\n```\n\n如果前面的步骤中并未加载到任何数据，则对应的 SkipList 是空的，为了保证 SkipList 能够正常工作，需要为其添加一个空的 activeSegment 对象。如果 SkipList 不为空则需要依据 log 目录下是否存在“.kafka_cleanshutdown”文件来判定之前 broker 是否是正常关闭的，如果为非正常关闭则需要对 recoveryPoint 之后的数据进行校验，如果数据存在不完整则进行丢弃，相关实现位于 `Log#recoverLog` 中，比较简单，不再展开。\n\n#### 追加日志数据\n\nLog 类定义了 `Log#append` 方法，用于往 Log 对象中追加消息数据。需要注意的一点是，Log 对象使用 SkipList 管理多个 LogSegment，我们在执行追加消息时是不能够往 SkipList 中的任意 LogSegment 对象执行追加操作的，Kafka 设计仅允许往 activeSegment 对象中追加消息。方法 `Log#append` 实现如下：\n\n```scala\ndef append(records: MemoryRecords, assignOffsets: Boolean = true): LogAppendInfo = {\n    // 1. 解析、校验待追加的消息数据，封装成 LogAppendInfo 对象\n    val appendInfo = this.analyzeAndValidateRecords(records)\n    // 如果消息数据个数为 0，则直接返回\n    if (appendInfo.shallowCount == 0) return appendInfo\n\n    // 2. 剔除待追加消息中未通过验证的字节部分\n    var validRecords = this.trimInvalidBytes(records, appendInfo)\n\n    try {\n        // 将待追加消息中剩余有效的字节追加到 Log 对象中\n        lock synchronized {\n            // 3.1 如果指定需要分配 offset\n            if (assignOffsets) {\n                // 获取当前 Log 对象对应的最后一个 offset 值，以此开始向后分配 offset\n                val offset = new LongRef(nextOffsetMetadata.messageOffset)\n                // 更新待追加消息的 firstOffset 为 Log 对象最后一个 offset 值\n                appendInfo.firstOffset = offset.value\n                val now = time.milliseconds\n                val validateAndOffsetAssignResult = try {\n                    // 对消息（包括压缩后的）的 magic 值进行统一，验证数据完整性，并分配 offset，同时按要求更新消息的时间戳\n                    LogValidator.validateMessagesAndAssignOffsets(\n                        validRecords,\n                        offset,\n                        now,\n                        appendInfo.sourceCodec,\n                        appendInfo.targetCodec,\n                        config.compact,\n                        config.messageFormatVersion.messageFormatVersion,\n                        config.messageTimestampType,\n                        config.messageTimestampDifferenceMaxMs)\n                } catch {\n                    case e: IOException =>\n                        throw new KafkaException(\"Error in validating messages while appending to log '%s'\".format(name), e)\n                }\n                validRecords = validateAndOffsetAssignResult.validatedRecords\n                appendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestamp\n                appendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.shallowOffsetOfMaxTimestamp\n                // 更新待追加消息的 lastOffset 值\n                appendInfo.lastOffset = offset.value - 1\n                // 如果时间戳类型为 LOG_APPEND_TIME，则修改时间戳\n                if (config.messageTimestampType == TimestampType.LOG_APPEND_TIME)\n                    appendInfo.logAppendTime = now\n\n                // 如果在执行 validateMessagesAndAssignOffsets 操作时修改了消息的长度，则需要重新验证，防止消息过长\n                if (validateAndOffsetAssignResult.messageSizeMaybeChanged) {\n                    for (logEntry <- validRecords.shallowEntries.asScala) {\n                        if (logEntry.sizeInBytes > config.maxMessageSize) {\n                            BrokerTopicStats.getBrokerTopicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)\n                            BrokerTopicStats.getBrokerAllTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)\n                            throw new RecordTooLargeException(\n                                \"Message size is %d bytes which exceeds the maximum configured message size of %s.\".format(logEntry.sizeInBytes, config.maxMessageSize))\n                        }\n                    }\n                }\n            }\n            // 3.2 不需要分配 offset\n            else {\n                // 如果消息的 offset 不是单调递增，或者消息的 firstOffset 小于 Log 中记录的下一条消息 offset，则说明 appendInfo 非法\n                if (!appendInfo.offsetsMonotonic || appendInfo.firstOffset < nextOffsetMetadata.messageOffset)\n                    throw new IllegalArgumentException(\"Out of order offsets found in \" + records.deepEntries.asScala.map(_.offset))\n            }\n\n            // 4. 校验待追加消息的长度，保证不超过了单个 LogSegment 所允许的最大长度（对应 segment.bytes 配置）\n            if (validRecords.sizeInBytes > config.segmentSize) {\n                throw new RecordBatchTooLargeException(\n                    \"Message set size is %d bytes which exceeds the maximum configured segment size of %s.\".format(validRecords.sizeInBytes, config.segmentSize))\n            }\n\n            // 5. 获取 activeSegment 对象，如果需要则创建新的 activeSegment 对象\n            val segment = this.maybeRoll(\n                messagesSize = validRecords.sizeInBytes,\n                maxTimestampInMessages = appendInfo.maxTimestamp,\n                maxOffsetInMessages = appendInfo.lastOffset)\n\n\n            // 6. 往 activeSegment 中追加消息\n            segment.append(\n                firstOffset = appendInfo.firstOffset,\n                largestOffset = appendInfo.lastOffset,\n                largestTimestamp = appendInfo.maxTimestamp,\n                shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp,\n                records = validRecords)\n\n            // 7. 更新 LEO 中记录的当前 Log 最后一个 offset 值\n            this.updateLogEndOffset(appendInfo.lastOffset + 1)\n\n            trace(\"Appended message set to log %s with first offset: %d, next offset: %d, and messages: %s\"\n                    .format(this.name, appendInfo.firstOffset, nextOffsetMetadata.messageOffset, validRecords))\n\n            // 8. 如果刷盘时间间隔达到阈值（对应 flush.messages 配置），则执行刷盘\n            if (unflushedMessages >= config.flushInterval)\n                this.flush() // 将 [recoveryPoint, logEndOffset) 之间的数据刷盘\n\n            appendInfo\n        }\n    } catch {\n        case e: IOException => throw new KafkaStorageException(\"I/O exception in append to log '%s'\".format(name), e)\n    }\n}\n```\n\n追加消息数据操作的整体执行流程可以概括为：\n\n1. 解析并校验待追加的消息集合，将其封装成 LogAppendInfo 对象；\n2. 剔除待追加消息集合中未通过验证的字节部分；\n3. 如果指定需要为消息分配 offset，则对消息（包括压缩后的）执行分配 offset 操作，并对消息执行 magic 值统一、数据完整性校验，以及按需更新消息时间戳等操作；\n4. 如果指定不需要为消息分配 offset，则需要保证消息已有 offset 是单调递增，且起始 offset 不能小于当前 Log 对象中记录的下一条待追加消息的 offset；\n5. 校验处理后消息集合的总长度，保证不超过单个 LogSegment 对象所允许的最大长度；\n6. 获取目标 activeSegment 对象，如果需要则创建一个新的 activeSegment 对象并返回；\n7. 往目标 activeSegment 对象中追加消息数据，并更新当前 Log 对象中记录的下一条待追加消息的 offset 值；\n8. 如果当前时间距离上次执行刷盘操作的时间超过配置的时间间隔，则执行刷盘操作。\n\n下面我们分步骤对整个执行过程进行进一步分析，首先来看 __步骤 1__ ，实现位于 `Log#analyzeAndValidateRecords` 方法中，该方法对待追加的消息集合中的消息逐条进行解析和验证，并封装成 LogAppendInfo 对象返回。实现如下：\n\n```scala\nprivate def analyzeAndValidateRecords(records: MemoryRecords): LogAppendInfo = {\n    var shallowMessageCount = 0 // 消息条数\n    var validBytesCount = 0 // 通过验证的消息字节数\n    var firstOffset = -1L // 第一条消息的 offset\n    var lastOffset = -1L // 最后一条消息的 offset\n    var sourceCodec: CompressionCodec = NoCompressionCodec // 生产者使用的压缩方式\n    var monotonic = true // 标识生产者为消息分配的内部 offset 是否是单调递增的\n    var maxTimestamp = Record.NO_TIMESTAMP // 消息的最大时间戳\n    var offsetOfMaxTimestamp = -1L // 最大时间戳消息对应的 offset\n\n    // 基于浅层迭代器迭代，对于压缩的消息不会解压缩\n    for (entry <- records.shallowEntries.asScala) {\n        // 记录第一条消息的 offset\n        if (firstOffset < 0) firstOffset = entry.offset\n        // 如果是单调递增的话，则在遍历过程中 lastOffset 应该始终小于当前的 offset\n        if (lastOffset >= entry.offset) monotonic = false\n\n        // 记录最后一条消息的 offset\n        lastOffset = entry.offset\n        // 获取消息数据\n        val record = entry.record\n        // 如果待追加的消息长度大于允许的最大值（对应 max.message.bytes 配置），则抛出异常\n        val messageSize = entry.sizeInBytes\n        if (messageSize > config.maxMessageSize) {\n            BrokerTopicStats.getBrokerTopicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)\n            BrokerTopicStats.getBrokerAllTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)\n            throw new RecordTooLargeException(\"Message size is %d bytes which exceeds the maximum configured message size of %s.\".format(messageSize, config.maxMessageSize))\n        }\n\n        // CRC 校验\n        record.ensureValid()\n\n        // 记录当前消息集合中时间戳最大的消息，及其 offset\n        if (record.timestamp > maxTimestamp) {\n            maxTimestamp = record.timestamp\n            offsetOfMaxTimestamp = lastOffset\n        }\n\n        // 浅层消息数加 1\n        shallowMessageCount += 1\n        // 更新已验证的字节数\n        validBytesCount += messageSize\n\n        // 解析生产者使用的压缩方式\n        val messageCodec = CompressionCodec.getCompressionCodec(record.compressionType.id)\n        if (messageCodec != NoCompressionCodec) sourceCodec = messageCodec\n    }\n\n    // 解析服务端使用的压缩方式（对应 compression.type 配置）\n    val targetCodec = BrokerCompressionCodec.getTargetCompressionCodec(config.compressionType, sourceCodec)\n\n    // 封装成 LogAppendInfo 对象返回\n    LogAppendInfo(firstOffset, lastOffset, maxTimestamp, offsetOfMaxTimestamp,\n        Record.NO_TIMESTAMP, sourceCodec, targetCodec, shallowMessageCount, validBytesCount, monotonic)\n}\n```\n\n概括来说，上述方法主要做了以下 3 件事情：\n\n1. 对待追加消息集合中的每条消息执行 CRC 校验；\n2. 对待追加消息集合中的每条消息的长度进行校验，保证不超过允许的最大值（对应 `max.message.bytes` 配置）；\n3. 计算待追加消息集合中的 firstOffset、lastOffset、消息的条数、有消息的字节数、offset 是否单调递增，以及获取生产者所指定的消息压缩方式。\n\n__步骤 2__ 会依据步骤 1 中对消息的校验结果，对未通过验证的消息字节部分进行截断，实现位于 `Log#trimInvalidBytes` 方法中：\n\n```scala\nprivate def trimInvalidBytes(records: MemoryRecords, info: LogAppendInfo): MemoryRecords = {\n    // 获取已验证的字节数\n    val validBytes = info.validBytes\n    if (validBytes < 0)\n        throw new CorruptRecordException(\n            \"Illegal length of message set \" + validBytes + \" Message set cannot be appended to log. Possible causes are corrupted produce requests\")\n    // 所有的字节都是已验证的，则直接返回\n    if (validBytes == records.sizeInBytes) {\n        records\n    }\n    // 存在未通过验证的字节，对这些异常字节进行截断\n    else {\n        val validByteBuffer = records.buffer.duplicate()\n        validByteBuffer.limit(validBytes)\n        MemoryRecords.readableRecords(validByteBuffer)\n    }\n}\n```\n\n如果在调用 `Log#append` 方法时设置了参数 `assignOffsets = true`，则在追加消息数据之前会为消息重新分配 offset（对应 __步骤 3__ ），起始 offset 为当前 Log 对象中记录的下一条待追加消息的 offset 值。这一步主要做了以下几件事情：\n\n1. 更新待追加消息集合的 firstOffset 为当前 Log 对象中记录的下一条待追加消息对应的 offset 值；\n2. 对消息（包括压缩后的）的 magic 值进行统一，验证数据完整性，并分配 offset，同时按要求更新消息的时间戳；\n3. 更新待追加消息集合的 lastOffset 值；\n4. 如果配置了 `message.timestamp.type=LogAppendTime`，则设置日志追加时间戳；\n5. 对待追加消息集合中的消息进行逐条校验，避免存在过长的消息。\n\n我们重点看一下第 2 步，这一步会执行 offset 分配操作，实现如下：\n\n```scala\nprivate[kafka] def validateMessagesAndAssignOffsets(records: MemoryRecords, // 待追加的消息集合\n                                                    offsetCounter: LongRef, // 消息对应的 offset 操作对象\n                                                    now: Long, // 当前时间戳\n                                                    sourceCodec: CompressionCodec, // 生产者指定的消息压缩方式\n                                                    targetCodec: CompressionCodec, // 服务端指定的消息压缩方式\n                                                    compactedTopic: Boolean = false, // 配置的消息清理策略：compact 或 delete\n                                                    messageFormatVersion: Byte = Record.CURRENT_MAGIC_VALUE,\n                                                    messageTimestampType: TimestampType,\n                                                    messageTimestampDiffMaxMs: Long): ValidationAndOffsetAssignResult = {\n    // 如果未对消息进行压缩处理\n    if (sourceCodec == NoCompressionCodec && targetCodec == NoCompressionCodec) {\n        // 存在消息的 magic 值与指定的 magic 值不一致\n        if (!records.hasMatchingShallowMagic(messageFormatVersion)) {\n            // 对消息的 magic 值进行统一，同时为消息分配 offset\n            convertAndAssignOffsetsNonCompressed(\n                records, offsetCounter, compactedTopic, now, messageTimestampType, messageTimestampDiffMaxMs, messageFormatVersion)\n        } else {\n            // 所有消息的 magic 值均一致，则执行 offset 分配，以及验证操作\n            assignOffsetsNonCompressed(records, offsetCounter, now, compactedTopic, messageTimestampType, messageTimestampDiffMaxMs)\n        }\n    }\n    // 如果对消息进行了压缩\n    else {\n        // 对消息进行解压缩，对深层消息进行 magic 值统一，并执行 offset 分配，以及验证操作\n        validateMessagesAndAssignOffsetsCompressed(\n            records, offsetCounter, now, sourceCodec, targetCodec, compactedTopic, messageFormatVersion, messageTimestampType, messageTimestampDiffMaxMs)\n    }\n}\n```\n\n由上面的实现可以看到，不管消息是否经过压缩，如果指定了需要为消息分配 offset，则需要处理所有的消息，包括经过压缩过的消息。方法 `LogValidator#validateMessagesAndAssignOffsets` 的主要工作也就是依据消息是否被压缩来分别调用对应的方法对待追加消息统一 magic 值，并执行 offset 分配、数据完整性校验，以及按需更新消息时间戳等操作，如果消息是经过压缩的，那么会对其进行解压缩。相关的方法实现比较冗长，这里不再继续深入。\n\n如果指定不需要重新分配 offset 值，那么处理过程将会简单很多，仅仅需要验证消息已有的 offset 是否是单调递增的，并且待追加消息集合中消息的 firstOffset 不能小于 Log 对象中记录的下一条待追加消息的 offset 值，否则说明待追加的消息集合是非法的，这也是 __步骤 4__ 的主要工作。\n\n__步骤 5__ 会校验处理后消息集合的长度，保证不超过单个 LogSegment 对象所允许的最大长度（对应 `segment.bytes` 配置）。\n\n在完成了一系列准备工作之后，接下去可以将处理后的待追加消息数据写入 activeSegment 对象中。 __步骤 6__ 调用了 `Log#maybeRoll` 方法尝试从 SkipList 中获取目标 activeSegment 对象，并在需要时创建新的 activeSegment 对象。方法实现如下：\n\n```scala\nprivate def maybeRoll(messagesSize: Int, // 待追加的消息长度\n                      maxTimestampInMessages: Long, // 消息中的最大时间戳\n                      maxOffsetInMessages: Long // 消息的 lastOffset\n                     ): LogSegment = {\n    // 获取当前的 activeSegment 对象\n    val segment = activeSegment\n    val now = time.milliseconds\n    val reachedRollMs = segment.timeWaitedForRoll(now, maxTimestampInMessages) > config.segmentMs - segment.rollJitterMs\n    if (segment.size > config.segmentSize - messagesSize // 当前 activeSegment 在追加本次消息之后，长度超过 LogSegment 允许的最大值\n            || (segment.size > 0 && reachedRollMs) // 当前 activeSegment 的存活时间超过了允许的最大时间\n            || segment.index.isFull || segment.timeIndex.isFull // 索引文件满了\n            || !segment.canConvertToRelativeOffset(maxOffsetInMessages)) { // 当前消息的 lastOffset 相对于 baseOffset 超过了 Integer.MAX_VALUE\n        // 创建新的 activeSegment\n        this.roll(maxOffsetInMessages - Integer.MAX_VALUE)\n    } else {\n        // 不需要创建新的 activeSegment，直接返回\n        segment\n    }\n}\n```\n\n如果满足以下条件之一，则会创建一个新的 activeSegment 对象：\n\n1. 当前 activeSegment 对象在追加本次消息之后，长度超过 LogSegment 允许的最大值（对应 `segment.bytes` 配置）。\n2. 当前 activeSegment 对象的存活时间超过了允许的最大时间（对应 `segment.ms` 配置）。\n3. 对应的索引文件（index 和 timeindex）满了。\n\n创建新 activeSegment 对象的过程位于 `Log#roll` 方法中，这里先不展开，后面会专门进行分析。\n\n既然已经拿到了目标 activeSegment 对象，那么下一步（ __步骤 7__ ）就是将待追加的消息数据写入 activeSegment 对象中（调用 `LogSegment#append` 方法，前面已经分析过）。写入成功之后需要更新 Log 对象本地记录的下一条待追加消息对应的 offset 值。\n\n最后（ __步骤 8__ ），方法会检测当前时间距离上一次执行刷盘的时间是否超过配置的时间间隔（对应 `flush.messages` 配置），是则执行刷盘操作。相关实现位于 `Log#flush` 方法中：\n\n```scala\ndef flush(): Unit = this.flush(this.logEndOffset)\n\ndef flush(offset: Long): Unit = {\n    // 如果 offset 小于等于 recoveryPoint，则直接返回，因为之前的已经全部落盘了\n    if (offset <= recoveryPoint)\n        return\n    debug(\"Flushing log '\" + name + \" up to offset \" + offset + \", last flushed: \" + lastFlushTime + \" current time: \" + time.milliseconds + \" unflushed = \" + unflushedMessages)\n    // 获取 [recoveryPoint, offset) 之间的 LogSegment 对象\n    for (segment <- this.logSegments(recoveryPoint, offset))\n        segment.flush() // 执行刷盘操作，包括 log、index 和 timeindex 文件\n    lock synchronized {\n        // 如果当前已经刷盘的 offset 大于之前记录的 recoveryPoint，则更新 recoveryPoint\n        if (offset > recoveryPoint) {\n            // 更新 recoveryPoint 值\n            this.recoveryPoint = offset\n            // 更新最近一次执行 flush 的时间\n            lastflushedTime.set(time.milliseconds)\n        }\n    }\n}\n```\n\n执行刷盘操作之前会先将当前 offset 与 recoveryPoint 变量进行比较，这里的 offset 对应当前 Log 对象中记录的下一条待追加消息的 offset，而 recoveryPoint 变量在当前 Log 对象创建时指定，并在运行过程中更新，用于表示当前已经刷盘的日志数据对应的最大 offset 值。如果当前 offset 小于等于 recoveryPoint，则无需执行刷盘操作，因为 recoveryPoint 之前的数据已经全部落盘了。否则会调用 `Log#logSegments` 方法从当前 Log 对象的 SkipList 中获取位于 `[recoveryPoint, offset)` 区间的 LogSegment 对象集合，并应用 `LogSegment#flush` 方法对 LogSegment 相关的文件执行刷盘操作，包括 log、index 和 timeindex 文件。同时会更新 recoveryPoint 和 lastflushedTime 字段，后者用于记录最近一次执行刷盘操作的时间戳。\n\n#### 创建 Active Segment 对象\n\n既然上一小节提到了 `Log#roll` 方法，那么本小节就来分析一下该方法的实现，该方法用于创建一个新的 activeSegment 对象，并将上任的 activeSegment 对象中的数据落盘。方法实现如下：\n\n```scala\ndef roll(expectedNextOffset: Long = 0): LogSegment = {\n    val start = time.nanoseconds\n    lock synchronized {\n        // 获取 LEO 值\n        val newOffset = Math.max(expectedNextOffset, logEndOffset)\n        val logFile = Log.logFile(dir, newOffset) // 对应的 log 文件\n        val indexFile = indexFilename(dir, newOffset) // 对应的 index 文件\n        val timeIndexFile = timeIndexFilename(dir, newOffset) // 对应的 timeindex 文件\n        // 遍历检查，如果文件存在则删除\n        for (file <- List(logFile, indexFile, timeIndexFile); if file.exists) {\n            warn(\"Newly rolled segment file \" + file.getName + \" already exists; deleting it first\")\n            file.delete()\n        }\n\n        // 处理之前的 activeSegment 对象\n        segments.lastEntry() match {\n            case null =>\n            case entry =>\n                val seg: LogSegment = entry.getValue\n                // 追加最大时间戳与对应的 offset 到 timeindex 文件\n                seg.onBecomeInactiveSegment()\n                // 对 log、index 和 timeindex 文件进行截断处理，仅保留有效字节\n                seg.index.trimToValidSize()\n                seg.timeIndex.trimToValidSize()\n                seg.log.trim()\n        }\n\n        // 创建新的 activeSegment 对象\n        val segment = new LogSegment(\n            dir,\n            startOffset = newOffset,\n            indexIntervalBytes = config.indexInterval,\n            maxIndexSize = config.maxIndexSize,\n            rollJitterMs = config.randomSegmentJitter,\n            time = time,\n            fileAlreadyExists = false,\n            initFileSize = initFileSize(),\n            preallocate = config.preallocate)\n\n        // 添加新的 activeSegment 到 segments 跳跃表中\n        val prev = this.addSegment(segment)\n        // 如果对应位置已经存在 LogSegment，则抛出异常\n        if (prev != null)\n            throw new KafkaException(\"Trying to roll a new log segment for topic partition %s with start offset %d while it already exists.\".format(name, newOffset))\n\n        // 因为有新的 activeSegment 对象创建，所以更新 Log 中记录的 activeSegment 的 baseOffset 值，及其物理地址\n        this.updateLogEndOffset(nextOffsetMetadata.messageOffset)\n\n        // 执行 flush 操作，将上任 activeSegment 的数据落盘\n        scheduler.schedule(\"flush-log\", () => this.flush(newOffset))\n\n        info(\"Rolled new log segment for '\" + name + \"' in %.0f ms.\".format((System.nanoTime - start) / (1000.0 * 1000.0)))\n\n        // 返回新的 activeSegment 对象\n        segment\n    }\n}\n```\n\n创建一个新的 activeSegment 对象的过程比较直观，无非是创建一个新的 activeSegment 对象，并将其添加到 SkipList 中，同时需要更新 Log 对象本地记录的 activeSegment 对象的 baseOffset 及其物理地址。此外，我们需要将上一任 activeSegment 对象中的数据落盘，Kafka 为此注册了一个名为 flush-log 的定时任务异步处理该过程，需要注意的是这里的 flush-log 任务仅运行一次。这里的刷盘操作是将 recoveryPoint 到新 activeSegment 对象 baseOffset （不包括）之间的数据落盘，具体的落盘操作交由 `Log#flush` 方法执行，我们在前面已经分析过该方法，这里不再重复撰述。\n\n#### 读取日志数据\n\n下面接着来看一下从 Log 对象中读取日志数据的过程，位于 `Log#read` 方法中。不同于追加消息时只能操作 activeSegment 对象，读取消息可以从 SkipList 中任意一个 LogSegment 对象中进行读取。方法实现如下：\n\n```scala\ndef read(startOffset: Long, // 读取消息的起始 offset\n         maxLength: Int, // 读取消息的最大字节数\n         maxOffset: Option[Long] = None, // 读取消息的结束 offset\n         minOneMessage: Boolean = false): FetchDataInfo = {\n\n    trace(\"Reading %d bytes from offset %d in log %s of length %d bytes\".format(maxLength, startOffset, name, size))\n\n    // 将 nextOffsetMetadata 保存成局部变量，避免加锁带来的竞态条件\n    val currentNextOffsetMetadata = nextOffsetMetadata\n    // 获取 Log 本地记录的下一条待追加消息消息对应的 offset 值\n    val next = currentNextOffsetMetadata.messageOffset\n    // 边界检查\n    if (startOffset == next)\n        return FetchDataInfo(currentNextOffsetMetadata, MemoryRecords.EMPTY)\n\n    // 查找 baseOffset 小于等于 startOffset 且最大的 LogSegment 对象\n    var entry = segments.floorEntry(startOffset)\n\n    // 边界检查，Log 对象中记录的最后一条消息的真实 offset 应该是 next-1，next 指的是下一条追加消息的 offset\n    if (startOffset > next || entry == null)\n        throw new OffsetOutOfRangeException(\"Request for offset %d but we only have log segments in the range %s to %d.\".format(startOffset, segments.firstKey, next))\n\n    while (entry != null) {\n        // 获取待读取的最大物理地址\n        val maxPosition = {\n            // 如果当前读取的是 activeSegment 对象\n            if (entry == segments.lastEntry) {\n                // 从 nextOffsetMetadata 对象中获取 activeSegment 对应的最大物理地址\n                val exposedPos = nextOffsetMetadata.relativePositionInSegment.toLong\n                // 如果期间正好创建了一个新的 activeSegment 对象，那么这里拿到的应该是上一任 activeSegment 对象，\n                // 它已经不再活跃了，可以直接读取到结尾\n                if (entry != segments.lastEntry)\n                    entry.getValue.size\n                // 否则，直接返回 exposedPos，如果这里读取到 LogSegment 结尾的话，可能会出现 OffsetOutOfRangeException 异常\n                else\n                    exposedPos\n            }\n            // 如果当前读取的不是 activeSegment 对象，则直接读取到对应 LogSegment 的结尾\n            else {\n                entry.getValue.size\n            }\n        }\n\n        // 调用 LogSegment#read 方法读取消息\n        val fetchInfo = entry.getValue.read(startOffset, maxOffset, maxLength, maxPosition, minOneMessage)\n        if (fetchInfo == null) {\n            // 如果没有读取到消息，则尝试读取下一个 LogSegment 对象\n            entry = segments.higherEntry(entry.getKey)\n        } else {\n            return fetchInfo\n        }\n    }\n\n    // 未读取到 startOffset 之后的消息\n    FetchDataInfo(nextOffsetMetadata, MemoryRecords.EMPTY)\n}\n```\n\n读取日志数据的执行过程如代码注释，比较直观，在做好边界检查的前提下寻找小于 startOffset 的最大 baseOffset，并以此 offset 开始从 SkipList 中定位 LogSegment 对象，如果该 LogSegment 对象为空，则会继续读取下一个 LogSegment 对象。读取的过程区分是不是 activeSegment 对象，如果当前读取的 LogSegment 不是 activeSegment 对象，那么对应的 LogSegment 已经是“冷却”状态，所以我们可以直接将其中的数据全部读取出来返回，如果当前读取的是 activeSegment 对象，则需要以 Log 对象中记录的 activeSegment 对象的最大物理地址作为读取的上界，如果直接读取到 activeSegment 对象结尾可能导致 OffsetOutOfRangeException 异常。考虑下面这样一个场景（假设有读线程 A 和写线程 B）：\n\n> 1. A 线程请求读取 startOffset 为 101 之后的数据，刚好该请求落在了 activeSegment 对象上；\n> 2. B 线程调用 append 方法追加了 offset 为 [105, 109] 的消息集合，但是还未更新 Log 对象本地记录的下一条消息对应的 offset 值（此时仍为 105）；\n> 3. A 线程读取到了 [101, 109] 之间的数据，并且继续请求 startOffset 为 110 之后的数据，但是因为 `startOffset > next` 而抛出 OffsetOutOfRangeException 异常。\n\n所以对于 activeSegment 对象而言，我们应该以 Log 对象中记录的 activeSegment 对应的最大物理地址作为上界。另外一个需要考虑的问题是在读取 activeSegment 对象过程中，因为追加消息而产生了新的 activeSegment 对象的情况，那么此时 `Log#read` 方法持有的 activeSegment 对象就变成前任了，也就不会再有写操作同时发生的问题，所以可以直接读取到该 activeSegment 对象的结尾位置。\n\n#### 删除日志数据\n\n本章节的最后，一起来看一下 `Log#delete` 方法，该方法会删除当前 Log 对象对应 log 目录，以及目录下的所有文件，并清空 SkipList 对象。方法实现如下：\n\n```scala\nprivate[log] def delete() {\n    lock synchronized {\n        // 遍历 SkipList 中每个 LogSegment 对应的 log、index 和 timeindex 文件\n        logSegments.foreach(_.delete())\n        // 清空 SkipList 对象\n        segments.clear()\n        // 删除 log 目录及其目录下的所有文件和目录\n        Utils.delete(dir)\n    }\n}\n```\n\n具体逻辑如代码注释，比较简单。\n\n### LogManager 组件\n\nLogManager 是 Kafka 日志数据操作的入口，基于上一节分析的 Log 类对象提供了对日志数据的加载、创建、删除，以及查询等功能。我们在配置 Kafka 服务时，可以通过 `log.dirs` 配置项为一个 broker 节点指定多个 log 目录，这些目录均由 LogManager 负责管理。LogManager 在启动时会校验 `log.dirs` 配置，确保指定的 log 目录没有重复的配置且都是可读的，同时对于不存在的目录会执行创建。每个 log 目录下包含多个 topic 分区目录，每个 topic 分区目录由一个 Log 类对象对其进行管理，LogManager 会记录每个 topic 分区对象及其对应的 Log 类对象之间的映射关系。LogManager 类的字段定义如下：\n\n```scala\nclass LogManager(val logDirs: Array[File], // log 目录集合，对应 log.dirs 配置，一般选择 log 数目最少的目录进行创建\n                 val topicConfigs: Map[String, LogConfig], // topic 相关配置\n                 val defaultConfig: LogConfig,\n                 val cleanerConfig: CleanerConfig, // log cleaner 相关配置\n                 ioThreads: Int, // 每个 log 目录下分配的执行加载任务的线程数目\n                 val flushCheckMs: Long,\n                 val flushCheckpointMs: Long,\n                 val retentionCheckMs: Long,\n                 scheduler: Scheduler, // 定时任务调度器\n                 val brokerState: BrokerState, // 当前 broker 节点的状态\n                 time: Time) extends Logging {\n\n    /**\n     * 每个 log 目录下面都有一个 recovery-point-offset-checkpoint 文件，\n     * 记录了当前 log 目录每个 Log 的 recoveryPoint 信息，用于在 broker 启动时恢复日志数据\n     */\n    val RecoveryPointCheckpointFile = \"recovery-point-offset-checkpoint\"\n    /** 创建或删除 Log 时的锁对象 */\n    private val logCreationOrDeletionLock = new Object\n    /** 记录每个 topic 分区对象与 Log 对象之间的映射关系 */\n    private val logs = new Pool[TopicPartition, Log]()\n    /** 记录需要被删除的 Log 对象 */\n    private val logsToBeDeleted = new LinkedBlockingQueue[Log]()\n    /** 尝试对每个 log 目录在文件系统层面加锁，这里加的是进程锁 */\n    private val dirLocks = this.lockLogDirs(logDirs)\n    /**\n     * 遍历为每个 log 目录创建一个操作其名下 recovery-point-offset-checkpoint 文件的 OffsetCheckpoint 对象，\n     * 并建立映射关系\n     */\n    private val recoveryPointCheckpoints = logDirs.map(\n        // recovery-point-offset-checkpoint 文件\n        dir => (dir, new OffsetCheckpoint(new File(dir, RecoveryPointCheckpointFile)))).toMap\n    /** 用于清理过期或者过大的日志 */\n    val cleaner: LogCleaner = if (cleanerConfig.enableCleaner) new LogCleaner(cleanerConfig, logDirs, logs, time = time) else null\n\n    // ... 省略方法定义\n\n}\n```\n\nLogManager 在实例化过程中会执行以下操作：\n\n1. 遍历处理配置的 log 路径（对应 `log.dirs` 配置），如果对应的路径不存在则创建，同时校验路径是否存在重复、是否是目录，以及是否可读；\n2. 遍历配置的 log 目录，尝试对每个目录在文件系统层面加锁，这里加的是进程锁；\n3. 遍历配置的 log 目录，为每个目录下的 recovery-point-offset-checkpoint 文件创建对应的 OffsetCheckpoint 对象，用于管理每个 topic 分区对应的 HW offset 信息；\n4. 遍历配置的 log 目录，将每个 topic 分区对应的日志数据封装成 Log 对象，同时记录需要被删除的 topic 分区目录，等待后续删除。\n\n文件 recovery-point-offset-checkpoint 用于记录每个 topic 分区对应的 HW offset 信息，当 broker 节点重启时辅助恢复每个 topic 分区的日志数据。一个简单的文件示例如下：\n\n```text\n0\n8\ntopic-default 3 2271154\ntopic-default 2 2271351\ntopic-default 4 2271051\ntopic-default 0 2270751\ntopic-default 5 2271558\ntopic-default 1 2272018\ntopic-default 7 2271197\ntopic-default 6 2270673\n```\n\n其中第一行是版本号，第二行是记录条数，从第三行开始每一行都记录着“topic partition HW”信息。OffsetCheckpoint 类定义了 `OffsetCheckpoint#write` 和 `OffsetCheckpoint#read` 两个方法，用于对 recovery-point-offset-checkpoint 执行读写操作。\n\n步骤 4 会执行加载每个 log 目录下的日志文件，并为每个 topic 分区对应的日志目录创建一个 Log 对象，对于标记为需要删除的 topic 分区目录（对应“-delete”后缀的目录），则将其 Log 对象添加到 `LogManager#logsToBeDeleted` 字段中，等待后面的周期性任务（kafka-delete-logs）对其进行删除。相关实现位于 `LogManager#loadLogs` 方法中：\n\n```scala\nprivate def loadLogs(): Unit = {\n    info(\"Loading logs.\")\n    val startMs = time.milliseconds\n    // 用于记录所有 log 目录对应的线程池\n    val threadPools = mutable.ArrayBuffer.empty[ExecutorService]\n    val jobs = mutable.Map.empty[File, Seq[Future[_]]]\n\n    // 遍历处理每个 log 目录\n    for (dir <- this.logDirs) {\n        // 为每个 log 目录创建一个 ioThreads 大小的线程池\n        val pool = Executors.newFixedThreadPool(ioThreads)\n        threadPools.append(pool)\n\n        // 尝试获取 .kafka_cleanshutdown 文件，如果该文件存在则说明 broker 节点是正常关闭的\n        val cleanShutdownFile = new File(dir, Log.CleanShutdownFile)\n        if (cleanShutdownFile.exists) {\n            debug(\"Found clean shutdown file. Skipping recovery for all logs in data directory: \" + dir.getAbsolutePath)\n        } else {\n            // 当前 broker 不是正常关闭，设置 broker 状态为 RecoveringFromUncleanShutdown，表示正在从上次异常关闭中恢复\n            brokerState.newState(RecoveringFromUncleanShutdown)\n        }\n\n        // 读取每个 log 目录下的 recovery-point-offset-checkpoint 文件，返回 topic 分区对象与 HW 之间的映射关系\n        var recoveryPoints = Map[TopicPartition, Long]()\n        try {\n            recoveryPoints = this.recoveryPointCheckpoints(dir).read()\n        } catch {\n            case e: Exception =>\n                warn(\"Error occured while reading recovery-point-offset-checkpoint file of directory \" + dir, e)\n                warn(\"Resetting the recovery checkpoint to 0\")\n        }\n\n        // 遍历当前 log 目录的子目录，仅处理目录，忽略文件\n        val jobsForDir = for {\n            dirContent <- Option(dir.listFiles).toList\n            logDir <- dirContent if logDir.isDirectory\n        } yield {\n            // 为每个 Log 目录创建一个 Runnable 任务\n            CoreUtils.runnable {\n                debug(\"Loading log '\" + logDir.getName + \"'\")\n                // 依据目录名解析得到对应的 topic 分区对象\n                val topicPartition = Log.parseTopicPartitionName(logDir)\n                // 获取当前 topic 分区对应的配置\n                val config = topicConfigs.getOrElse(topicPartition.topic, defaultConfig)\n                // 获取 topic 分区对应的 HW 值\n                val logRecoveryPoint = recoveryPoints.getOrElse(topicPartition, 0L)\n\n                // 创建对应的 Log 对象，每个 topic 分区目录对应一个 Log 对象\n                val current = new Log(logDir, config, logRecoveryPoint, scheduler, time)\n                // 如果当前 log 是需要被删除的文件，则记录到 logsToBeDeleted 队列中，会有周期性任务对其执行删除操作\n                if (logDir.getName.endsWith(Log.DeleteDirSuffix)) { // -delete\n                    logsToBeDeleted.add(current)\n                } else {\n                    // 建立 topic 分区对象与其 Log 对象之间的映射关系，不允许一个 topic 分区对象对应多个目录\n                    val previous = logs.put(topicPartition, current)\n                    if (previous != null) {\n                        throw new IllegalArgumentException(\n                            \"Duplicate log directories found: %s, %s!\".format(current.dir.getAbsolutePath, previous.dir.getAbsolutePath))\n                    }\n                }\n            }\n        }\n\n        // 提交上面创建的任务，并将提交结果封装到 jobs 集合中，jobsForDir 是 List[Runnable] 类型\n        jobs(cleanShutdownFile) = jobsForDir.map(pool.submit)\n    }\n\n    // 阻塞等待上面提交的任务执行完成，即等待所有 log 目录下 topic 分区对应的目录文件加载完成\n    try {\n        for ((cleanShutdownFile, dirJobs) <- jobs) {\n            dirJobs.foreach(_.get)\n            // 删除对应的 .kafka_cleanshutdown 文件\n            cleanShutdownFile.delete()\n        }\n    } catch {\n        case e: ExecutionException =>\n            error(\"There was an error in one of the threads during logs loading: \" + e.getCause)\n            throw e.getCause\n    } finally {\n        // 遍历关闭线程池\n        threadPools.foreach(_.shutdown())\n    }\n\n    info(s\"Logs loading complete in ${time.milliseconds - startMs} ms.\")\n}\n```\n\nLogManager 在实例化时会为每个 log 目录创建一个指定大小的线程池，然后对目录下的子目录（不包括文件）进行并发加载，最终将每个 topic 分区目录下的日志相关数据封装成 Log 对象，并记录到 `LogManager#logs` 字段中，这是一个 `Pool[K, V]` 类型的字段，基于 ConcurrentHashMap 实现，其中这里的 key 为 Log 对象所属的 topic 分区对象。\n\n在 LogManager 启动时（对应 `LogManager#startup` 方法）会注册一个名为 kafka-delete-logs 的周期性任务，该任务会周期性调用 `LogManager#deleteLogs` 方法对标记为“-delete”的目录执行删除操作。方法实现如下：\n\n```scala\nprivate def deleteLogs(): Unit = {\n    try {\n        var failed = 0\n        // 如果存在需要删除的目录\n        while (!logsToBeDeleted.isEmpty && failed < logsToBeDeleted.size()) {\n            // 获取需要删除的目录对应的 Log 对象\n            val removedLog = logsToBeDeleted.take()\n            if (removedLog != null) {\n                try {\n                    // 调用 Log.delete 方法执行删除操作\n                    removedLog.delete()\n                    info(s\"Deleted log for partition ${removedLog.topicPartition} in ${removedLog.dir.getAbsolutePath}.\")\n                } catch {\n                    case e: Throwable =>\n                        error(s\"Exception in deleting $removedLog. Moving it to the end of the queue.\", e)\n                        failed = failed + 1\n                        // 如果删除异常，则归还，下一次周期性调用时再删除\n                        logsToBeDeleted.put(removedLog)\n                }\n            }\n        }\n    } catch {\n        case e: Throwable =>\n            error(s\"Exception in kafka-delete-logs thread.\", e)\n    }\n}\n```\n\n方法 `LogManager#deleteLogs` 会遍历 `LogManager#logsToBeDeleted` 队列，并对其中的 Log 对象调用 `Log#delete` 方法执行删除，如果删除异常则会归还到队列，并在下一次周期性调用时再尝试执行删除。方法 `Log#delete` 已经在前面分析过，这里不再重复撰述。\n\n#### 周期性定时任务\n\n前面分析了启动过程中激活的 kafka-delete-logs 周期性任务，下面继续来看一下 `LogManager#startup` 方法的剩余实现，该方法主要的逻辑就是启动 4 个周期性任务。在 Kafka 服务启动时会创建 LogManager 实例，并调用 `LogManager#startup` 方法，该方法实现如下：\n\n```scala\ndef startup() {\n    if (scheduler != null) {\n        // 1. 启动 kafka-log-retention 周期性任务，对过期或过大的日志文件执行清理工作\n        info(\"Starting log cleanup with a period of %d ms.\".format(retentionCheckMs))\n        scheduler.schedule(\"kafka-log-retention\",\n            this.cleanupLogs,\n            delay = InitialTaskDelayMs,\n            period = retentionCheckMs,\n            TimeUnit.MILLISECONDS)\n\n        // 2. 启动 kafka-log-flusher 周期性任务，对日志文件执行刷盘操作\n        info(\"Starting log flusher with a default period of %d ms.\".format(flushCheckMs))\n        scheduler.schedule(\"kafka-log-flusher\",\n            this.flushDirtyLogs,\n            delay = InitialTaskDelayMs,\n            period = flushCheckMs,\n            TimeUnit.MILLISECONDS)\n\n        // 3. 启动 kafka-recovery-point-checkpoint 周期性任务，更新 recovery-point-offset-checkpoint 文件\n        scheduler.schedule(\"kafka-recovery-point-checkpoint\",\n            this.checkpointRecoveryPointOffsets,\n            delay = InitialTaskDelayMs,\n            period = flushCheckpointMs,\n            TimeUnit.MILLISECONDS)\n\n        // 4. 启动 kafka-delete-logs 周期性任务，删除标记为需要被删除的 log 目录\n        scheduler.schedule(\"kafka-delete-logs\",\n            this.deleteLogs,\n            delay = InitialTaskDelayMs,\n            period = defaultConfig.fileDeleteDelayMs,\n            TimeUnit.MILLISECONDS)\n    }\n\n    // 启动 LogCleaner 线程\n    if (cleanerConfig.enableCleaner) cleaner.startup()\n}\n```\n\nLogManager 在启动过程中启动了 4 个周期性任务和 1 个 LogCleaner 线程，这 4 个周期性任务包括：\n\n1. __kafka-log-retention__ ：定期对过期或过大的日志文件执行清理操作。\n2. __kafka-log-flusher__ ：定期对日志文件执行刷盘操作。\n3. __kafka-recovery-point-checkpoint__ ：定期更新 recovery-point-offset-checkpoint 文件。\n4. __kafka-delete-logs__ ：定期删除标记为需要被删除的 log 目录。\n\n其中任务 4 我们已经在前面分析过，下面逐个来看一下前 3 个任务。 __任务 1__ 的实现位于 `LogManager#cleanupLogs` 方法中，该方法会遍历所有的 Log 对象，并从两个维度对执行清理工作：\n\n1. 时间维度：即保证 Log 对象中所有的 LogSegment 都是有效的，对于过期的 LogSegment 执行删除操作。\n2. 空间维度：既保证 Log 对象不应过大，对于超出的部分会执行删除操作。\n\n实现如下：\n\n```scala\ndef cleanupLogs() {\n    debug(\"Beginning log cleanup...\")\n    var total = 0\n    val startMs = time.milliseconds\n    // 遍历处理每个 topic 分区对应的 Log 对象，只有对应 Log 配置了 cleanup.policy=delete 才会执行删除\n    for (log <- allLogs(); if !log.config.compact) {\n        debug(\"Garbage collecting '\" + log.name + \"'\")\n        // 遍历删除当前 Log 对象中过期的 LogSegment 对象，并保证 Log 的大小在允许范围内（对应 retention.bytes 配置）\n        total += log.deleteOldSegments()\n    }\n    debug(\"Log cleanup completed. \" + total + \" files deleted in \" + (time.milliseconds - startMs) / 1000 + \" seconds\")\n}\n```\n\n清理操作仅处理配置了 `cleanup.policy=delete` 的 Log 对象，并调用 `Log#deleteOldSegments` 方法执行判定和删除操作。方法 `Log#deleteOldSegments` 中通过调用 `Log#deleteRetentionMsBreachedSegments` 对过期的 LogSegment 对象执行删除操作，并调用 `Log#deleteRetentionSizeBreachedSegments` 方法对当前 Log 对象的大小进行判定，如果超过设定大小，则会从 Log 对象中删除部分 LogSegment 对象，以保证最终的 Log 大小在允许范围内。这两个方法最终都是调用 `Log#deleteOldSegments` 方法执行具体的删除操作，该方法接收一个 `LogSegment => Boolean` 类的函数，如果某个 LogSegment 对象满足给定的谓语，则会应用 `Log#deleteSegment` 方法对该 LogSegment 执行删除操作。\n\n其中 `Log#deleteRetentionMsBreachedSegments` 方法给定的判定条件很简单（如下），比较当前 LogSegment 对象最大消息时间戳距离当前时间是否超过 `retention.ms` 毫秒，如果超过则认为该 LogSegment 已过期。\n\n```scala\nprivate def deleteRetentionMsBreachedSegments(): Int = {\n    if (config.retentionMs < 0) return 0\n    val startMs = time.milliseconds\n    // 如果 LogSegment 中最大时间戳距离当前已经超过配置时间，则删除\n    this.deleteOldSegments(startMs - _.largestTimestamp > config.retentionMs)\n}\n```\n\n而 `Log#deleteRetentionSizeBreachedSegments` 方法则会首先计算出当前 Log 超出设定值（对应 `retention.bytes` 配置）的字节数，然后对 Log 中的 LogSegment 对象遍历删除，直到 Log 的大小不再超出为止。实现如下：\n\n```scala\nprivate def deleteRetentionSizeBreachedSegments(): Int = {\n    if (config.retentionSize < 0 || size < config.retentionSize) return 0\n    // Log 的总大小减去允许的大小\n    var diff = size - config.retentionSize\n\n    def shouldDelete(segment: LogSegment): Boolean = {\n        // 大于等于 0 则说明仍然过大\n        if (diff - segment.size >= 0) {\n            diff -= segment.size\n            true\n        } else {\n            false\n        }\n    }\n\n    // 删除 Log 中超出大小的部分\n    this.deleteOldSegments(shouldDelete)\n}\n```\n\n接下来继续看一下公共逻辑 `Log#deleteOldSegments` 方法（实现如下），该方法会基于给定的谓语 predicate 从 Log 中选择需要被删除的 LogSegment 对象，并对每个需要被删除的 LogSegment 对象应用 `Log#deleteSegment` 方法进行删除，包括从 Log 对象中移除该 LogSegment 对象，以及删除 LogSegment 对应的 log、index 和 timeindex 文件。\n\n```scala\nprivate def deleteOldSegments(predicate: LogSegment => Boolean): Int = {\n    lock synchronized {\n        // 检查当前 Log 中的 LogSegment 是否满足删除条件，并返回需要被删除的 LogSegment 对象集合\n        val deletable = this.deletableSegments(predicate)\n        val numToDelete = deletable.size\n        if (numToDelete > 0) {\n            // 如果当前 Log 中所有的 LogSegment 对象都需要被删除，则在删除之前创建一个新的 activeSegment 对象，保证 Log 可以正常运行\n            if (segments.size == numToDelete) this.roll()\n            // 遍历删除需要删除的 LogSegment 对象及其相关数据文件\n            deletable.foreach(deleteSegment)\n        }\n        // 返回被删除的 LogSegment 数目\n        numToDelete\n    }\n}\n```\n\n如果本次删除操作需要删除 Log 中全部的 LogSegment 对象，则会调用 `Log#roll` 方法为当前 Log 对象的 SkipList 创建一个新的 activeSegment 对象，以保证 Log 的正常运行，该方法的实现在前面已经分析过，不再重复撰述。\n\n再来看一下周期性 __任务 2__ ，该任务用于定期对日志文件执行刷盘（flush）操作。相关逻辑实现位于 `LogManager#flushDirtyLogs` 方法中，该方法会遍历处理每个 topic 分区对应的 Log 对象，通过记录在 Log 对象中的上次执行 flush 的时间戳与当前时间对比，如果时间差值超过一定的阈值（对应 `flush.ms` 配置），则调用 `Log#flush` 方法执行刷盘操作，该方法的实现同样在前面已经分析过，不再重复撰述。\n\n接着来看一下周期性 __任务 3__ ，该任务用于定期更新每个 log 目录名下的 recovery-point-offset-checkpoint 文件。相关实现位于 `LogManager#checkpointRecoveryPointOffsets` 中：\n\n```scala\ndef checkpointRecoveryPointOffsets() {\n    // 为每个 log 目录应用 checkpointLogsInDir 方法\n    logDirs.foreach(checkpointLogsInDir)\n}\n\nprivate def checkpointLogsInDir(dir: File): Unit = {\n    // 获取指定 log 目录对应的 Map[TopicPartition, Log] 集合\n    val recoveryPoints = logsByDir.get(dir.toString)\n    if (recoveryPoints.isDefined) {\n        // 更新对应的 recovery-point-offset-checkpoint 文件\n        this.recoveryPointCheckpoints(dir).write(recoveryPoints.get.mapValues(_.recoveryPoint))\n    }\n}\n```\n\n方法会获取位于指定 log 目录下所有 topic 分区对应的 recoveryPoint 值（即当前已经落盘的日志的最大 offset），并全量更新 log 目录下的 recovery-point-offset-checkpoint 文件。\n\n#### 重复日志数据清理\n\n本小节来看一下 LogCleaner 线程，如果在配置中指定了 `log.cleaner.enable=true`，那么在 `LogManager#startup` 方法的最后会调用 `LogCleaner#startup` 方法启动 LogCleaner 线程对日志数据执行清理工作。前面我们在分析周期性任务 kafka-log-retention 时，已经知道该周期性任务会对日志中过大或过期的 LogSegment 对象执行清理操作，那么 LogCleaner 又是对什么执行清理呢？\n\n我们知道 Kafka 对于生产者发来的消息都是顺序追加到日志文件中的，而 Kafka 又采用本地文件系统对日志文件进行存储，所以随着时间的流逝日志文件会越来越大，其中存储的相当一部分消息数据都具备相同的 key。如果配置了 `cleanup.policy=compact` 策略，那么 Kafka 的 LogCleaner 线程就会对具备相同 key 的消息进行清理操作，仅保留当前具备最大 offset 的 key 的消息。\n\nLogCleaner 在执行清理操作时会将一个 log 分割成 clean 和 dirty 两部分。其中 clean 是上次完成清理的部分，Kafka 会在对应 log 目录下生成一个 cleaner-offset-checkpoint 文件，用于记录每个 topic 分区上一次执行清理操作的 offset 值，而 dirty 部分则是本次清理操作的目标区域，但是 dirty 中并不是所有的 LogSegment 对象都会执行清理操作，Kafka 又将这一部分分为了 cleanable 和 uncleanable 两块，能够被分为 uncleanable 的 LogSegment 对象包含两类：\n\n1. 当前 Log 对象中的 activeSegment 对象。\n2. LogSegment 对象中的最大消息时间戳距离当前时间位于配置的滞后压缩时间（对应 `min.compaction.lag.ms` 配置）范围内。\n\n其中不清理 activeSegment 对象，主要是为了防止竞态条件，因为 activeSegment 是可以写入的对象，这样会让清理操作变得复杂，且收益不大。\n\n下面我们从 `LogCleaner#startup` 方法开始，整个清理工作主要涉及 LogCleaner、LogCleanerManager、CleanerThread，以及 Cleaner 这 4 个类。方法 `LogCleaner#startup` 的主要作用就是启动注册在 LogCleaner 中的 CleanerThread 线程集合。CleanerThread 继承自 ShutdownableThread 抽象类，所以 `CleanerThread#doWork` 方法是其处理入口，该方法只是简单调用了 `CleanerThread#cleanOrSleep` 方法，后者会选取一个最需要被清理的 LogSegment 区间，并执行清理工作。相关实现如下：\n\n```scala\nprivate def cleanOrSleep() {\n    // 选取下一个最需要进行日志清理的 LogToClean 对象\n    val cleaned = cleanerManager.grabFilthiestCompactedLog(time) match {\n        // 没有需要被清理的 LogToClean 对象，休息一会后继续尝试\n        case None =>\n            false\n        // 执行消息清理操作\n        case Some(cleanable) =>\n            var endOffset = cleanable.firstDirtyOffset\n            try {\n                // 调用 Cleaner#clean 方法执行清理工作\n                val (nextDirtyOffset, cleanerStats) = cleaner.clean(cleanable)\n                recordStats(cleaner.id, cleanable.log.name, cleanable.firstDirtyOffset, endOffset, cleanerStats)\n                endOffset = nextDirtyOffset\n            } catch {\n                case _: LogCleaningAbortedException => // task can be aborted, let it go.\n            } finally {\n                // 对 Log 的清理状态进行转换，如果当前 topic 分区的清理状态是 LogCleaningInProgress，则更新 cleaner-offset-checkpoint 文件\n                cleanerManager.doneCleaning(cleanable.topicPartition, cleanable.log.dir.getParentFile, endOffset)\n            }\n            true\n    }\n\n    // 获取所有启用了 compact 和 delete 清理策略的 Log 对象，并将其对应的 topic 分区状态设置为 LogCleaningInProgress\n    val deletable: Iterable[(TopicPartition, Log)] = cleanerManager.deletableLogs()\n    deletable.foreach {\n        case (topicPartition, log) =>\n            try {\n                // 对设置了清理策略为 delete 的 LogSegment 执行删除操作，删除过期或过大的 LogSegment 对象。\n                log.deleteOldSegments()\n            } finally {\n                // 移除这些 topic 分区对应的 LogCleaningInProgress 状态\n                cleanerManager.doneDeleting(topicPartition)\n            }\n    }\n\n    // 如果没有需要执行清理的 LogToClean 对象，则休息一会后继续重试\n    if (!cleaned) backOffWaitLatch.await(config.backOffMs, TimeUnit.MILLISECONDS)\n}\n```\n\n清理操作的执行流程如下：\n\n1. 选取一个最需要进行日志清理的 LogToClean 对象，如果存在则执行清理操作；\n2. 如果配置了 `cleanup.policy=delete` 策略，则对 Log 对象中过大或过期的 LogSegment 对象执行删除操作；\n3. 如果没有需要进行清理的 LogToClean 对象，则休息一会儿后重试。\n\n其中第 2 步与前面介绍的周期性任务 kafka-log-retention 类似，这里我们重点来看一下第 1 步，这一步的核心操作是调用 `LogCleanerManager#grabFilthiestCompactedLog` 方法选取下一个最需要被清理的 LogToClean 对象，然后调用 `Cleaner#clean` 依据该对象执行清理操作。\n\n方法 `LogCleanerManager#grabFilthiestCompactedLog` 的实现如下：\n\n```scala\ndef grabFilthiestCompactedLog(time: Time): Option[LogToClean] = {\n    inLock(lock) {\n        val now = time.milliseconds\n        this.timeOfLastRun = now\n\n        // 读取 log 目录下的 cleaner-offset-checkpoint 文件，获取每个 topic 分区上次清理操作的 offset 边界\n        val lastClean = allCleanerCheckpoints\n        val dirtyLogs = logs.filter {\n            // 过滤掉 cleanup.policy 配置为 delete 的 Log 对象，因为不需要压缩\n            case (_, log) => log.config.compact // match logs that are marked as compacted\n        }.filterNot {\n            // 过滤掉所有正在执行清理工作的 Log 对象\n            case (topicPartition, _) => inProgress.contains(topicPartition) // skip any logs already in-progress\n        }.map {\n            // 将需要被清理的区间封装成 LogToClean 对象\n            case (topicPartition, log) => // create a LogToClean instance for each\n                // 计算需要执行清理操作的 offset 区间\n                val (firstDirtyOffset, firstUncleanableDirtyOffset) =\n                    LogCleanerManager.cleanableOffsets(log, topicPartition, lastClean, now)\n                // 构建清理区间对应的 LogToClean 对象\n                LogToClean(topicPartition, log, firstDirtyOffset, firstUncleanableDirtyOffset)\n        }.filter(ltc => ltc.totalBytes > 0) // 忽略待清理区间数据为空的 LogToClean 对象\n\n        // 获取待清理区间最大的 cleanableRatio 比率\n        this.dirtiestLogCleanableRatio = if (dirtyLogs.nonEmpty) dirtyLogs.max.cleanableRatio else 0\n        // 过滤掉所有 cleanableRatio 小于等于配置值（对应 min.cleanable.dirty.ratio 配置）的 LogToClean 对象\n        val cleanableLogs = dirtyLogs.filter(ltc => ltc.cleanableRatio > ltc.log.config.minCleanableRatio)\n        if (cleanableLogs.isEmpty) {\n            None\n        } else {\n            // 基于需要清理的数据占比选择最需要执行清理的 LogToClean 对象\n            val filthiest = cleanableLogs.max\n            // 更新对应 topic 分区的清理状态为 LogCleaningInProgress\n            inProgress.put(filthiest.topicPartition, LogCleaningInProgress)\n            Some(filthiest)\n        }\n    }\n}\n```\n\n上述方法的执行流程如下：\n\n1. 读取每个 log 目录下 cleaner-offset-checkpoint 文件，解析每个 topic 分区上次执行清理操作对应的 offset 值；\n2. 遍历处理 Log 对象集合，筛选符合要求的 Log 对象（Log 对象配置的清理策略 `cleanup.policy=compact`，且该 Log 对象当前没有正在执行清理操作），并与其需要被清理的区间一起封装成对应的 LogToClean 对象；\n3. 过滤掉不包含数据，以及待清理数据占比不超过指定阈值（对应 `min.cleanable.dirty.ratio` 配置）的 LogToClean 对象，并从剩下的 LogToClean 集合中选择待清理数据占比最高的 LogToClean 对象。\n\n计算待清理区间的过程由 `LogCleanerManager#cleanableOffsets` 方法实现，区间值包括 dirty 部分的起始 offset 值和 uncleanable LogSegment 对象的 baseOffset 值。方法实现如下：\n\n```scala\ndef cleanableOffsets(log: Log, // 待清理的 Log 对象\n                     topicPartition: TopicPartition, // 对应的 topic 分区对象\n                     lastClean: immutable.Map[TopicPartition, Long], // 记录每个 topic 分区上一次清理操作的结束 offset\n                     now: Long): (Long, Long) = {\n\n    // 获取当前 topic 分区上次清理的 offset，即下一次需要被清理的 Log 的起始 offset\n    val lastCleanOffset: Option[Long] = lastClean.get(topicPartition)\n\n    // 获取当前 Log 对象 SkipList 中首个 LogSegment 对应的 baseOffset\n    val logStartOffset = log.logSegments.head.baseOffset\n    // 计算下一次执行清理操作的起始 offset\n    val firstDirtyOffset = {\n        // 如果 cleaner-offset-checkpoint 中没有当前 topic 分区的相关记录或记录的 offset 小于 logStartOffset，\n        // 则以当前 Log 对象 SkipList 中的起始 logStartOffset 作为下一次需要被清理的起始 offset 位置\n        val offset = lastCleanOffset.getOrElse(logStartOffset)\n        if (offset < logStartOffset) {\n            // don't bother with the warning if compact and delete are enabled.\n            if (!isCompactAndDelete(log))\n                warn(s\"Resetting first dirty offset to log start offset $logStartOffset since the checkpointed offset $offset is invalid.\")\n            logStartOffset\n        } else {\n            offset\n        }\n    }\n\n    // 获取需要被清理的 LogSegment 对象，即在 firstDirtyOffset 到 activeSegment 之间的 LogSegment 对象集合\n    val dirtyNonActiveSegments = log.logSegments(firstDirtyOffset, log.activeSegment.baseOffset)\n    // 获取配置的清理滞后时间（对应 min.compaction.lag.ms 配置）\n    val compactionLagMs = math.max(log.config.compactionLagMs, 0L)\n\n    // 计算本次不应该被清理的 LogSegment 对应的最小 offset 值\n    val firstUncleanableDirtyOffset: Long = Seq(\n        // activeSegment 不能执行清理操作，避免竞态条件\n        Option(log.activeSegment.baseOffset),\n\n        // 寻找最大消息时间戳距离当前时间戳在清理滞后时间（compactionLagMs）范围内的 LogSegment 对应的最小 offset 值\n        if (compactionLagMs > 0) {\n            dirtyNonActiveSegments.find { s =>\n                // 如果 LogSegment 的最大消息时间戳距离当前在 compactionLagMs 范围内，则不能执行清理操作\n                val isUncleanable = s.largestTimestamp > now - compactionLagMs\n                debug(s\"Checking if log segment may be cleaned: log='${log.name}' segment.baseOffset=${s.baseOffset} segment.largestTimestamp=${s.largestTimestamp}; now - compactionLag=${now - compactionLagMs}; is uncleanable=$isUncleanable\")\n                isUncleanable\n            } map (_.baseOffset)\n        } else None\n    ).flatten.min\n\n    debug(s\"Finding range of cleanable offsets for log=${log.name} topicPartition=$topicPartition. Last clean offset=$lastCleanOffset now=$now => firstDirtyOffset=$firstDirtyOffset firstUncleanableOffset=$firstUncleanableDirtyOffset activeSegment.baseOffset=${log.activeSegment.baseOffset}\")\n\n    (firstDirtyOffset, firstUncleanableDirtyOffset)\n}\n```\n\n清理区间的起始 offset，即 firstDirtyOffset，一般都对应着 cleaner-offset-checkpoint 文件中记录的上次执行清理操作的结束 offset，但是考虑到当前 topic 分区可能是第一次执行清理操作，或者 offset 对应的 LogSegment 可能已经被删除，所以需要将其与当前 Log 对象的首个 LogSegment 的 baseOffset 进行对比，选择较大值。\n\n清理区间的结束 offset，即 firstUncleanableDirtyOffset，也就是 uncleanable 区间的起始 offset，我们在前面介绍了 uncleanable 区间包含 2 类 LogSegment 对象，即 activeSegment 对象和最大消息时间戳距离当前时间位于配置的滞后压缩时间范围内的 LogSegment 对象，在计算 firstUncleanableDirtyOffset 时，也就是从这两类 LogSegment 中寻找最小的 baseOffset 作为清理区间的结束 offset 值。\n\n下面来看一下 `Cleaner#clean` 方法，清理操作的具体执行过程正位于此，方法实现如下：\n\n```scala\nprivate[log] def clean(cleanable: LogToClean): (Long, CleanerStats) = {\n    // 记录消息清理的状态信息\n    val stats = new CleanerStats()\n\n    info(\"Beginning cleaning of log %s.\".format(cleanable.log.name))\n    val log = cleanable.log // 需要被清理的 Log 对象\n\n    info(\"Building offset map for %s...\".format(cleanable.log.name))\n    // 清理操作的 offset 上界\n    val upperBoundOffset = cleanable.firstUncleanableOffset\n\n    // 1. 遍历处理待清理区间的 LogSegment 对象，填充 offsetMap 对象，主要记录每个消息 key 及其对应清理区间内的最大 offset 值\n    this.buildOffsetMap(log, cleanable.firstDirtyOffset, upperBoundOffset, offsetMap, stats)\n    val endOffset = offsetMap.latestOffset + 1\n    stats.indexDone()\n\n    // 2. 计算删除标识\n    val deleteHorizonMs = log.logSegments(0, cleanable.firstDirtyOffset).lastOption match {\n        case None => 0L\n        case Some(seg) => seg.lastModified - log.config.deleteRetentionMs // delete.retention.ms\n    }\n\n    // determine the timestamp up to which the log will be cleaned，this is the lower of the last active segment and the compaction lag\n    val cleanableHorizonMs = log.logSegments(0, cleanable.firstUncleanableOffset).lastOption.map(_.lastModified).getOrElse(0L)\n\n    // 3. 对 [0, endOffset) 区间的 LogSegment 进行分组，并以组为单位执行清理操作\n    info(\"Cleaning log %s (cleaning prior to %s, discarding tombstones prior to %s)...\".format(log.name, new Date(cleanableHorizonMs), new Date(deleteHorizonMs)))\n    for (group <- this.groupSegmentsBySize(log.logSegments(0, endOffset), log.config.segmentSize, log.config.maxIndexSize, cleanable.firstUncleanableOffset))\n        this.cleanSegments(log, group, offsetMap, deleteHorizonMs, stats)\n\n    // record buffer utilization\n    stats.bufferUtilization = offsetMap.utilization\n\n    stats.allDone()\n\n    (endOffset, stats)\n}\n```\n\n整个清理过程中我们重点关注一下 offsetMap 的填充过程和分组清理数据的过程，这里的 offsetMap 是一个 Kafka 自定义实现的 SkimpyOffsetMap 类型，其中主要记录了每个消息的 key 和消息在清理区间的最大 offset 值的映射关系，后面需要依据该 offsetMap 来确定需要剔除和保留的消息。填充 offsetMap 的过程位于 `Cleaner#buildOffsetMap` 方法中，实现如下：\n\n```scala\nprivate[log] def buildOffsetMap(log: Log, // 待清理的 Log 对象\n                                start: Long, // 清理区间起始 offset\n                                end: Long, // 清理区间结束 offset\n                                map: OffsetMap, // 记录消息 key 及其对应的最大 offset\n                                stats: CleanerStats) {\n    map.clear()\n    // 获取 [start, end) 之间的 LogSegment 对象，这些对象是本次需要执行清理操作的\n    val dirty = log.logSegments(start, end).toBuffer\n    info(\"Building offset map for log %s for %d segments in offset range [%d, %d).\".format(log.name, dirty.size, start, end))\n\n    var full = false // 标识 map 是否被填充满了\n    for (segment <- dirty if !full) {\n        // 检查当前分区的压缩状态，确保不是 LogCleaningAborted 状态\n        this.checkDone(log.topicPartition)\n        // 处理当前 LogSegment 中的消息集合，以消息的 key 作为 key，以遍历范围内最大 offset 作为 value，填充 offsetMap\n        full = this.buildOffsetMapForSegment(log.topicPartition, segment, map, start, log.config.maxMessageSize, stats)\n    }\n    info(\"Offset map for log %s complete.\".format(log.name))\n}\n\nprivate def buildOffsetMapForSegment(topicPartition: TopicPartition,\n                                     segment: LogSegment,\n                                     map: OffsetMap,\n                                     start: Long,\n                                     maxLogMessageSize: Int,\n                                     stats: CleanerStats): Boolean = {\n    // 获取清理区间起始 offset 对应的消息物理地址\n    var position = segment.index.lookup(start).position\n    // 计算当前 map 的最大容量\n    val maxDesiredMapSize = (map.slots * dupBufferLoadFactor).toInt\n    // 遍历处理 LogSegment 对象中的消息\n    while (position < segment.log.sizeInBytes) {\n        // 再次校验当前分区的状态，确保不是 LogCleaningAborted 状态\n        this.checkDone(topicPartition)\n        readBuffer.clear()\n        // 读取消息集合\n        segment.log.readInto(readBuffer, position)\n        val records = MemoryRecords.readableRecords(readBuffer)\n        throttler.maybeThrottle(records.sizeInBytes)\n\n        val startPosition = position\n        // 深层迭代遍历消息集合\n        for (entry <- records.deepEntries.asScala) {\n            val message = entry.record\n            // 仅处理具备 key，且 offset 位于 start 之后的消息\n            if (message.hasKey && entry.offset >= start) {\n                // 如果 map 未满，将消息的 key 及其 offset 放入 map 中，这里会覆盖 offset 较小的 key\n                if (map.size < maxDesiredMapSize) map.put(message.key, entry.offset)\n                else return true // 标识 map 已满\n            }\n            stats.indexMessagesRead(1)\n        }\n        val bytesRead = records.validBytes\n        // 向前移动地址\n        position += bytesRead\n        stats.indexBytesRead(bytesRead)\n        // 如果 position 未向前移动，则说明未读取到一个完整的消息，需要对 buffer 进行扩容\n        if (position == startPosition) this.growBuffers(maxLogMessageSize)\n    } // ~ end while\n    // 重置 buffer\n    this.restoreBuffers()\n    false\n}\n```\n\n填充的过程比较直观，上述方法会遍历清理区间的消息集合直到 offsetMap 被填满或到达区间边界为止，并在遍历过程中将持有 key 的消息及其 offset 添加到 offsetMap 中，因为消息是顺序追加的，所以能够保证 offsetMap 中记录的是当前已处理消息的对应的最大 `key->offset` 映射。\n\n完成了 offsetMap 的填充，接下来方法会依据单个 LogSegment 对象和索引文件的大小上限对需要清理的 LogSegment 对象进行分组，以防止清理操作完成后生成的目标 LogSegment 对象过大或过小，保证尽量均衡。然后方法会遍历每个分组，对分组中的待清理 LogSegment 对象集合调用 `Cleaner#cleanSegments` 方法执行清理操作并生成最终的 LogSegment 对象替换清理操作前的 LogSegment 对象集合。方法的实现如下：\n\n```scala\nprivate[log] def cleanSegments(log: Log,\n                               segments: Seq[LogSegment],\n                               map: OffsetMap,\n                               deleteHorizonMs: Long,\n                               stats: CleanerStats) {\n    // 创建组内第一个 LogSegment 对象的 log 文件对应的“.cleaned”文件\n    val logFile = new File(segments.head.log.file.getPath + Log.CleanedFileSuffix)\n    logFile.delete()\n    // 创建 index 文件对应的“.cleaned”文件\n    val indexFile = new File(segments.head.index.file.getPath + Log.CleanedFileSuffix)\n    // 创建 timeindex 文件对应的“.cleaned”文件\n    val timeIndexFile = new File(segments.head.timeIndex.file.getPath + Log.CleanedFileSuffix)\n    indexFile.delete()\n    timeIndexFile.delete()\n    val records = FileRecords.open(logFile, false, log.initFileSize(), log.config.preallocate)\n    val index = new OffsetIndex(indexFile, segments.head.baseOffset, segments.head.index.maxIndexSize)\n    val timeIndex = new TimeIndex(timeIndexFile, segments.head.baseOffset, segments.head.timeIndex.maxIndexSize)\n    // 创建清理后数据对应的 LogSegment 对象\n    val cleaned = new LogSegment(records, index, timeIndex,\n        segments.head.baseOffset, segments.head.indexIntervalBytes, log.config.randomSegmentJitter, time)\n\n    try {\n        // 遍历处理需要清理的 LogSegment 对象，将清理后的数据记录到 cleaned 文件中\n        for (old <- segments) {\n            val retainDeletes = old.lastModified > deleteHorizonMs\n            info(\"Cleaning segment %s in log %s (largest timestamp %s) into %s, %s deletes.\"\n                    .format(old.baseOffset, log.name, new Date(old.largestTimestamp), cleaned.baseOffset, if (retainDeletes) \"retaining\" else \"discarding\"))\n            this.cleanInto(log.topicPartition, old, cleaned, map, retainDeletes, log.config.maxMessageSize, stats)\n        }\n\n        // 对 index 文件进行截断，剔除无效的字节\n        index.trimToValidSize()\n        // 对 timeindex 文件进行截断，剔除无效的字节\n        cleaned.onBecomeInactiveSegment()\n        timeIndex.trimToValidSize()\n\n        // 将 LogSegment 对象相关的文件刷盘\n        cleaned.flush()\n\n        // update the modification date to retain the last modified date of the original files\n        val modified = segments.last.lastModified\n        cleaned.lastModified = modified\n\n        // 使用清理后的 LogSegment 对象替换清理之前的 LogSegment 对象集合\n        info(\"Swapping in cleaned segment %d for segment(s) %s in log %s.\".format(cleaned.baseOffset, segments.map(_.baseOffset).mkString(\",\"), log.name))\n        log.replaceSegments(cleaned, segments)\n    } catch {\n        case e: LogCleaningAbortedException =>\n            cleaned.delete()\n            throw e\n    }\n}\n```\n\n整个清理操作的执行流程可以概括如下：\n\n1. 创建存储清理后数据的 LogSegment 对象，及其对应的 log、index 和 timeindex 文件，注意此时的文件都以 “.cleaned” 作为后缀；\n2. 遍历处理待清理 LogSegment 对象集合，对每个需要清理的 LogSegment 对象调用 `Cleaner#cleanInto` 方法执行清理操作，并将清理后的数据写入步骤 1 中创建的 LogSegment 对象中；\n3. 对 index 和 timeindex 文件进行截断，剔除无效字节；\n4. 将存储清理后数据的 LogSegment 对象相关文件进行刷盘；\n5. 使用存储清理后数据的 LogSegment 对象替换 SkipList 中对应的被清理之前的 LogSegment 对象集合。\n\n其中步骤 1 中创建的相关文件均以“.cleaned”作为文件名后缀，并在步骤 4 中将内存中的日志和索引数据落盘到对应文件中，而步骤 5 中除了会使用存储清理后数据的 LogSegment 对象替换 SkipList 中对应的被清理之前的 LogSegment 对象集合之外，还会将相关文件的后缀名由“.cleaned”改为“.swap”，并在完成剔除存储被清理之前数据的 LogSegment 对象集合后，移除文件的“.swap”后缀。前面我们在分析 `Log#loadSegments` 方法时曾说，如果当前 topic 分区目录下的 log 文件是以“.swap”作为后缀的，那么其中的数据是完整的，只是 broker 节点在执行交换（即移除“.swap”后缀）的过程中宕机了，再次加载时可以直接移除“.swap”后缀并加载，无需担心数据错乱或丢失，分析到这里应该对 broker 节点启动时加载数据文件的过程有更加深入的理解。\n\n下面我们主要来看一下 `Cleaner#cleanInto` 方法的实现，分析清理操作的具体执行过程，方法实现如下：\n\n```scala\nprivate[log] def cleanInto(topicPartition: TopicPartition, // 当前操作的 Log 对应的 topic 分区对象\n                           source: LogSegment, // 需要被清理的 LogSegment\n                           dest: LogSegment, // 清理后得到 LogSegment\n                           map: OffsetMap, // offsetMap\n                           retainDeletes: Boolean, // source.lastModified > deleteHorizonMs，当删除对应的 LogSegment 时，删除标记是否应该被保留\n                           maxLogMessageSize: Int,\n                           stats: CleanerStats) {\n\n    // 定义消息过滤器\n    val logCleanerFilter = new LogEntryFilter {\n        def shouldRetain(logEntry: LogEntry): Boolean = shouldRetainMessage(source, map, retainDeletes, logEntry, stats)\n    }\n\n    var position = 0\n    // 遍历处理待清理的 LogSegment 对象中的消息\n    while (position < source.log.sizeInBytes) {\n        // 校验对应 topic 分区的清理状态不为 LogCleaningAborted\n        this.checkDone(topicPartition)\n        // read a chunk of messages and copy any that are to be retained to the write buffer to be written out\n        readBuffer.clear()\n        writeBuffer.clear()\n\n        // 读取消息到 buffer\n        source.log.readInto(readBuffer, position)\n        val records = MemoryRecords.readableRecords(readBuffer)\n        throttler.maybeThrottle(records.sizeInBytes)\n        // 对消息进行过滤，对需要保留的消息写入到 buffer 中\n        val result = records.filterTo(topicPartition, logCleanerFilter, writeBuffer, maxLogMessageSize)\n        stats.readMessages(result.messagesRead, result.bytesRead)\n        stats.recopyMessages(result.messagesRetained, result.bytesRetained)\n\n        position += result.bytesRead\n\n        // 对于需要保留的消息，将其追加到清理后的 LogSegment 对象中\n        val outputBuffer = result.output\n        if (outputBuffer.position > 0) {\n            outputBuffer.flip()\n            val retained = MemoryRecords.readableRecords(outputBuffer)\n            dest.append(\n                firstOffset = retained.deepEntries.iterator.next().offset,\n                largestOffset = result.maxOffset,\n                largestTimestamp = result.maxTimestamp,\n                shallowOffsetOfMaxTimestamp = result.shallowOffsetOfMaxTimestamp,\n                records = retained)\n            throttler.maybeThrottle(outputBuffer.limit)\n        }\n\n        // 如果未能读取一条完整的消息，则需要对 buffer 进行扩容\n        if (readBuffer.limit > 0 && result.messagesRead == 0) growBuffers(maxLogMessageSize)\n    }\n    // 对 buffer 进行重置\n    this.restoreBuffers()\n}\n```\n\n上述方法会深层遍历待清理 LogSegment 对象中的每一条消息，并调用 `MemoryRecords#filterTo` 对消息执行过滤操作，保留同时满足以下条件的消息：\n\n1. 消息必须具备 key，且 key 包含在 offsetMap 中；\n2. 消息的 offset 要大于等于 offsetMap 中记录的对应的 offset 值；\n3. 如果对应的消息是删除标记，只有在允许保留该标记是才会保留。\n\n上述条件对应方法 `Cleaner#shouldRetainMessage` 实现，这里不再展开。在完成对一个消息集合的筛选操作之后，如果所有的消息均需要被保留，则只需要将消息集合写入到目标 buffer 中即可。否则，如果只有部分消息需要被保留，则需要对这部分保留的消息重新压缩（如果需要的话），然后写入目标 buffer 中。\n\n### 总结\n\n本文我们按照日志数据的组织结构由下往上分析了 LogSegment、Log 和 LogManager 组件，了解了 Kafka 的日志存储机制，其中 Log 用于存储和管理一个 topic 分区下的所有有效的消息数据，并将消息及其索引数据分片采用 LogSegment 对象进行管理。LogManager 实现了 4 个周期性任务分别用于对日志和索引数据执行定期清理、删除、刷盘，以及记录 HW 等操作，同时还维护了一个清理线程对具备相同 key 的重复消息数据进行清理，以减少对磁盘空间的无用消耗。LogManager 并没有提供对日志数据的读写操作，而是委托给相应 topic 分区的 Log 对象执行。\n","tags":["Kafka"],"categories":["kafka"]},{"title":"Kafka 源码解析：网络交互模型","url":"/2019/06/21/kafka/kafka-reactor/","content":"\n由上一篇分析可知，在 broker 节点启动过程中会创建一个 SocketServer 类型的对象，并调用其 `SocketServer#startup` 方法执行组件的启动过程。SocketServer 是 Kafka 对外提供网络服务的核心实现类，在 Kafka 运行过程中用于接收来自客户端和其它 broker 节点的网络请求。考虑到性能上的需求，SocketServer 采用了 [Reactor](http://www.zhenchao.org/2017/10/23/design-pattern/reactor/) 模式，并基于 java NIO 实现。\n\n参考如下示意图，Kafka 为 broker 所在宿主机的每一张网卡创建并绑定了一个 Acceptor 组件，用于接收并处理所有的连接请求；每个 Acceptor 组件维护多个 Processor 线程，其中每个 Processor 拥有专属的 Selector，用于从连接中读取请求和写回响应；每个 Acceptor 组件同时维护多个 Handler 线程，用于处理请求并生成响应传递给 Processor，而 Handler 与 Processor 之间通过请求队列进行通信。<!-- more -->\n\n![image](/images/2019/kafka-reactor.png)\n\n### SocketServer 组件\n\nSocketServer 是整个 kafka server 网络模型的管家类，主要用于构建和启动整个网络模块。SocketServer 类的字段定义如下：\n\n```scala\nclass SocketServer(val config: KafkaConfig,\n                   val metrics: Metrics,\n                   val time: Time,\n                   val credentialProvider: CredentialProvider) extends Logging with KafkaMetricsGroup {\n\n    /** 封装服务器对应的多张网卡，kafka 可以同时监听这些 IP 和端口，每个 EndPoint 对应一个 Acceptor */\n    private val endpoints: Map[ListenerName, EndPoint] = config.listeners.map(l => l.listenerName -> l).toMap\n    /** 每个 Acceptor 对应的 Processor 对应的线程数 */\n    private val numProcessorThreads = config.numNetworkThreads\n    /** broker 节点上 Processor 线程总数 */\n    private val totalProcessorThreads = numProcessorThreads * endpoints.size\n    /** 请求队列中缓存的最大请求个数 */\n    private val maxQueuedRequests = config.queuedMaxRequests\n    /** 每个 IP 允许创建的最大连接数 */\n    private val maxConnectionsPerIp = config.maxConnectionsPerIp\n    /** 针对特定 IP 指定的允许创建的最大连接数，会覆盖 maxConnectionsPerIp 配置 */\n    private val maxConnectionsPerIpOverrides = config.maxConnectionsPerIpOverrides\n    /** Processor 线程与 Handler 线程之间交换数据的通道 */\n    val requestChannel = new RequestChannel(totalProcessorThreads, maxQueuedRequests)\n    /** Acceptor 对象集合，每个 EndPoint 对应一个 Acceptor */\n    private[network] val acceptors = mutable.Map[EndPoint, Acceptor]()\n    /** Processor 对象集合，封装所有的 Processor 对象 */\n    private val processors = new Array[Processor](totalProcessorThreads)\n    /** 用于控制每个 IP 上的最大连接数 */\n    private var connectionQuotas: ConnectionQuotas = _\n\n    // ... 省略方法定义\n\n}\n```\n\n各字段的含义参考注释，其中 EndPoint 类用于封装服务器对应的 host、port，以及网络协议等信息，而 RequestChannel 类定义了 Processor 和 Handler 之间交换数据的通道，该类的字段定义如下：\n\n```scala\nclass RequestChannel(val numProcessors: Int, // Processor 线程总数\n                     val queueSize: Int // 请求队列的大小\n                    ) extends KafkaMetricsGroup {\n\n    /** 响应监听器列表，当 Handler 往响应队列写回响应数据时唤醒对应的 Processor 线程进行处理 */\n    private var responseListeners: List[Int => Unit] = Nil\n    /** 请求队列，所有的 Processor 共用一个 */\n    private val requestQueue = new ArrayBlockingQueue[RequestChannel.Request](queueSize)\n    /** 响应队列，每个 Processor 对应一个响应队列 */\n    private val responseQueues = new Array[BlockingQueue[RequestChannel.Response]](numProcessors)\n\n    // ... 省略方法定义\n\n}\n```\n\nRequestChannel 封装了请求队列和响应队列，这里需要注意的一点是请求队列是 Processor 线程共享的，而响应队列则是每个 Processor 线程专属的。Processor 负责将读取到的请求写入请求队列中，并从自己的响应队列中取出响应对象发送给请求方。Handler 负责从请求队列中读取请求进行处理，并在处理完成之后将响应对象写入到之前读取该请求的 Processor 的响应队列中。关于 Acceptor、Processor 和 Handler 的实现下文会专门进行分析，这里我们先来看一下 SocketServer 的启动逻辑，位于 `SocketServer#startup` 方法中，实现如下：\n\n```scala\ndef startup() {\n    synchronized {\n\n        // 创建控制 IP 最大连接数的 ConnectionQuotas 对象\n        connectionQuotas = new ConnectionQuotas(maxConnectionsPerIp, maxConnectionsPerIpOverrides)\n\n        // 指定 socket send buffer 的大小（对应 socket.send.buffer.bytes 配置）\n        val sendBufferSize = config.socketSendBufferBytes\n        // 指定 socket receive buffer 的大小（对应 socket.receive.buffer.bytes 配置）\n        val recvBufferSize = config.socketReceiveBufferBytes\n        // 获取 broker 节点 ID\n        val brokerId = config.brokerId\n\n        var processorBeginIndex = 0\n        // 遍历为每个 EndPoint，创建并绑定对应的 Acceptor 和 Processor\n        config.listeners.foreach { endpoint =>\n            val listenerName = endpoint.listenerName\n            val securityProtocol = endpoint.securityProtocol\n            val processorEndIndex = processorBeginIndex + numProcessorThreads\n\n            // 按照指定的 processor 线程数，为每个 EndPoint 创建对应数量的 Processor 对象，\n            // 编号区间 [processorBeginIndex, processorEndIndex)\n            for (i <- processorBeginIndex until processorEndIndex)\n                processors(i) = this.newProcessor(i, connectionQuotas, listenerName, securityProtocol)\n\n            // 为当前 EndPoint 创建并绑定一个 Acceptor 对象\n            val acceptor = new Acceptor(endpoint, sendBufferSize, recvBufferSize, brokerId,\n                processors.slice(processorBeginIndex, processorEndIndex), connectionQuotas)\n            acceptors.put(endpoint, acceptor)\n\n            // 启动 Acceptor 线程\n            Utils.newThread(s\"kafka-socket-acceptor-$listenerName-$securityProtocol-${endpoint.port}\", acceptor, false).start()\n\n            // 主线程等待 Acceptor 线程启动完成\n            acceptor.awaitStartup()\n\n            processorBeginIndex = processorEndIndex\n        }\n    }\n\n    info(\"Started \" + acceptors.size + \" acceptor threads\")\n}\n```\n\nSocketServer 启动过程中会遍历为当前 broker 节点上的每张网卡创建并绑定对应 Acceptor 对象，然后按照配置的 Processor 线程数（对应 `num.network.threads` 配置）为每个 Acceptor 创建并绑定对应数量的 Processor 实例，最后启动 Acceptor 线程。\n\n### Acceptor 组件\n\nAcceptor 主要负责接收来自客户端和其它 broker 节点的请求，并创建对应的 socket 连接交由 Processor 进行处理。Acceptor 类的字段定义如下：\n\n```scala\nprivate[kafka] class Acceptor(val endPoint: EndPoint, // 对应的网卡信息\n                              val sendBufferSize: Int, // socket send buffer size\n                              val recvBufferSize: Int, // socket receive buffer size\n                              brokerId: Int, // broker 节点 id\n                              processors: Array[Processor], // 绑定的 Processor 线程集合\n                              connectionQuotas: ConnectionQuotas // 控制 IP 连接数的对象\n                             ) extends AbstractServerThread(connectionQuotas) with KafkaMetricsGroup {\n\n    /** NIO Selector */\n    private val nioSelector = NSelector.open()\n    /** ServerSocketChannel 对象，监听对应网卡的指定端口 */\n    val serverChannel: ServerSocketChannel = this.openServerSocket(endPoint.host, endPoint.port)\n\n    // ... 省略方法定义\n\n}\n```\n\nSocketServer 在启动过程中会创建并启动 Acceptor 线程，由上面的定义可以看出 Acceptor 继承自 AbstractServerThread 抽象类，而 AbstractServerThread 实现了 Runnable 接口，并提供了对线程的基本管理方法。Acceptor 的具体执行逻辑位于 `Acceptor#run` 方法中：\n\n```scala\ndef run() {\n    // 注册监听 OP_ACCEPT 事件\n    serverChannel.register(nioSelector, SelectionKey.OP_ACCEPT)\n    // 标记当前线程启动完成，以便 SocketServer 能够继续为其它网卡创建并绑定对应的 Acceptor 线程\n    this.startupComplete()\n    try {\n        var currentProcessor = 0 // 当前生效的 processor 编号\n        while (isRunning) {\n            try {\n                // 等待关注的事件\n                val ready = nioSelector.select(500)\n                if (ready > 0) {\n                    val keys = nioSelector.selectedKeys()\n                    val iter = keys.iterator()\n                    // 遍历处理接收到的请求\n                    while (iter.hasNext && isRunning) {\n                        try {\n                            val key = iter.next\n                            iter.remove()\n                            // 如果是 OP_ACCEPT 事件，则调用 accept 方法进行处理\n                            if (key.isAcceptable)\n                                this.accept(key, processors(currentProcessor))\n                            else\n                                throw new IllegalStateException(\"Unrecognized key state for acceptor thread.\")\n                            // 基于轮询算法选择下一个 Processor 处理下一次请求，负载均衡\n                            currentProcessor = (currentProcessor + 1) % processors.length\n                        } catch {\n                            case e: Throwable => error(\"Error while accepting connection\", e)\n                        }\n                    }\n                }\n            } catch {\n                case e: ControlThrowable => throw e\n                case e: Throwable => error(\"Error occurred\", e)\n            }\n        }\n    } finally {\n        debug(\"Closing server socket and selector.\")\n        this.swallowError(serverChannel.close())\n        this.swallowError(nioSelector.close())\n        this.shutdownComplete()\n    }\n}\n\ndef accept(key: SelectionKey, processor: Processor) {\n    val serverSocketChannel = key.channel().asInstanceOf[ServerSocketChannel]\n    // 创建 SocketChannel 对象\n    val socketChannel = serverSocketChannel.accept()\n    try {\n        // 增加对应 IP 上的连接数，如果连接数超过阈值，则抛 TooManyConnectionsException 异常\n        connectionQuotas.inc(socketChannel.socket().getInetAddress)\n        // 配置 SocketChannel 对象，非阻塞模式\n        socketChannel.configureBlocking(false)\n        socketChannel.socket().setTcpNoDelay(true)\n        socketChannel.socket().setKeepAlive(true)\n        if (sendBufferSize != Selectable.USE_DEFAULT_BUFFER_SIZE)\n            socketChannel.socket().setSendBufferSize(sendBufferSize)\n\n        // 将 SocketChannel 交给 Processor 进行处理\n        processor.accept(socketChannel)\n    } catch {\n        // 连接数过多，关闭当前通道上的连接，并将连接计数减 1\n        case e: TooManyConnectionsException =>\n            info(\"Rejected connection from %s, address already has the configured maximum of %d connections.\".format(e.ip, e.count))\n            this.close(socketChannel)\n    }\n}\n```\n\n上述方法的执行逻辑是一个典型的 NIO server 的实现。Acceptor 会循环监听 `OP_ACCEPT` 事件，当有新的连接请求到达时会创建并配置连接对应的 SocketChannel 对象，并交由 Processor 处理（调用 `Processor#accept` 方法）。我们知道一个 Acceptor 上绑定了多个 Processor 线程，为了保证各个 Processor 的负载均衡，这里使用了简单的轮询算法，逐个选择 Processor 线程处理请求。\n\n对于新进来的请求，Acceptor 首先会使用 ConnectionQuotas 对象管理请求 IP 上的连接数，并在连接数超过配置的阈值（默认对应 `max.connections.per.ip` 配置，可以通过 `max.connections.per.ip.overrides` 配置覆盖默认配置）时触发限流机制，关闭当前连接的通道。\n\n### Processor 组件\n\nProcessor 主要负责读取来自请求方的请求，并向请求方发送响应，但是本身不负责对请求进行处理，而是委托给相应的 Handler 线程进行处理。Processor 中几个重要的字段定义如下：\n\n```scala\n/** Processor 与 Handler 线程之间传递请求数据的队列 */\nval requestChannel: RequestChannel\n/** 记录分配给当前 Processor 的待处理的 SocketChannel 对象 */\nprivate val newConnections = new ConcurrentLinkedQueue[SocketChannel]()\n/** 缓存未发送给客户端的响应，由于客户端不会进行确认，所以服务端在发送成功之后会将其移除 */\nprivate val inflightResponses = mutable.Map[String, RequestChannel.Response]()\n```\n\nAcceptor 线程在收到连接请求之后会将请求封装成 SocketChannel 对象，并调用 `Processor#accept` 方法将其分配给对应的 Processor 线程进行处理，该对象会被记录到 `Processor#newConnections` 字段中，并唤醒对应的 Processor 线程。方法 `Processor#accept` 的实现如下：\n\n```scala\ndef accept(socketChannel: SocketChannel) {\n    // 将 Acceptor 分配的 SocketChannel 对象缓存到同步队列中\n    newConnections.add(socketChannel)\n    // 唤醒 Processor 线程处理队列\n    this.wakeup() // 本质上调用 NIO Server 的 wakeup 方法\n}\n```\n\nProcessor 同样继承了 AbstractServerThread 抽象类，所以也是一个线程类实现。在创建 Acceptor 对象的过程中会遍历启动分配给当前 Acceptor 的 Processor 线程。\n\n```scala\nsynchronized {\n    // 遍历启动分配给当前 Acceptor 的 Processor 线程\n    processors.foreach { processor =>\n        Utils.newThread(\n            s\"kafka-network-thread-$brokerId-${endPoint.listenerName}-${endPoint.securityProtocol}-${processor.id}\",\n            processor, false).start()\n    }\n}\n```\n\nProcessor 的 `Processor#run` 方法在线程启动之后会一直循环处理 Acceptor 分配的请求，读取并封装请求数据到队列中，然后等待 Handler 线程处理。对于已经处理完成的请求对应的响应对象，Processor 线程会依据响应类型分而治之。方法 `Processor#run` 的实现如下：\n\n```scala\noverride def run() {\n    // 标识当前线程启动完成\n    this.startupComplete()\n    while (isRunning) {\n        try {\n            // 1. 遍历获取分配给当前 Processor 的 SocketChannel 对象，注册 OP_READ 事件\n            this.configureNewConnections()\n\n            // 2. 遍历处理当前 Processor 的响应队列，依据响应类型进行处理\n            this.processNewResponses()\n\n            // 3. 发送缓存的响应对象给客户端\n            this.poll()\n\n            // 4.\n            // 遍历处理 poll 操作放置在 Selector 的 completedReceives 队列中的请求，\n            // 封装请求信息为 Request 对象，并记录到请求队列中等待 Handler 线程处理，\n            // 同时标记当前 Selector 暂时不再接收新的请求\n            this.processCompletedReceives()\n\n            // 5.\n            // 遍历处理 poll 操作放置在 Selector 的 completedSends 队列中的请求，\n            // 将其从 inflightResponses 集合中移除，并标记当前 Selector 可以继续读取数据\n            this.processCompletedSends()\n\n            // 6.\n            // 遍历处理 poll 操作放置在 Selector 的 disconnected 集合中的断开的连接，\n            // 将连接对应的所有响应从 inflightResponses 中移除，同时更新对应 IP 的连接数\n            this.processDisconnected()\n        } catch {\n            case e: ControlThrowable => throw e\n            case e: Throwable =>\n                error(\"Processor got uncaught exception.\", e)\n        }\n    }\n\n    debug(\"Closing selector - processor \" + id)\n    // 关闭所有的连接以及选择器\n    this.swallowError(closeAll())\n    this.shutdownComplete()\n}\n```\n\n当 Processor 线程启动完成后会调用 `Processor#startupComplete` 方法标识当前线程启动完成，然后开始进入循环，依次执行以下操作：\n\n1. 遍历处理 Acceptor 分配给当前 Processor 的 SocketChannel 对象，注册 `OP_READ` 事件读取请求数据；\n2. 遍历处理 Processor 自己的响应队列，按照响应类型分别处理；\n3. 发送缓存的响应给请求方，并将读取到的请求、已经发送成功的请求，以及断开的连接分别放置到 Selector 的 completedReceives、completedSends 和 disconnected 集合中；\n4. 处理 Selector 的 completedReceives 集合，封装请求数据到请求队列中，等待 Handler 线程处理；\n5. 处理 Selector 的 completedSends 集合，将已经发送成功的响应从本地 inflightResponses 集合中移除；\n6. 处理 Selector 的 disconnected 集合，将已经断开的连接上的响应从 inflightResponses 集合中移除。\n\n下面对各个步骤逐一进行深入分析，首先来看 __步骤 1__ ，实现位于 `Processor#configureNewConnections` 方法中：\n\n```scala\nprivate def configureNewConnections() {\n    while (!newConnections.isEmpty) {\n        // 获取待处理 SocketChannel 对象\n        val channel = newConnections.poll()\n        try {\n            debug(s\"Processor $id listening to new connection from ${channel.socket.getRemoteSocketAddress}\")\n            val localHost = channel.socket().getLocalAddress.getHostAddress\n            val localPort = channel.socket().getLocalPort\n            val remoteHost = channel.socket().getInetAddress.getHostAddress\n            val remotePort = channel.socket().getPort\n            val connectionId = ConnectionId(localHost, localPort, remoteHost, remotePort).toString\n            // 注册 OP_READ 事件\n            selector.register(connectionId, channel)\n        } catch {\n            // 对于不致命的异常，则捕获并关闭对应的通道\n            case NonFatal(e) =>\n                val remoteAddress = channel.getRemoteAddress\n                this.close(channel)\n                error(s\"Processor $id closed connection from $remoteAddress\", e)\n        }\n    }\n}\n```\n\n前面我们曾介绍过 Acceptor 会将请求对应的 SocketChannel 对象记录到 `Processor#newConnections` 字段中，而这一步的主要任务就是遍历处理这些 SocketChannel 对象，分别将 Processor 对应的 Selector 注册到这些通道上（对应 `OP_READ` 事件），用于读取请求数据。\n\n__步骤 2__ 会遍历消费当前 Processor 的响应队列，按照响应的类型分别处理，实现位于 `Processor#processNewResponses` 方法中：\n\n```scala\nprivate def processNewResponses() {\n    // 获取当前 Processor 的响应队列\n    var curr = requestChannel.receiveResponse(id)\n    while (curr != null) {\n        try {\n            // 依据响应类型对响应进行处理\n            curr.responseAction match {\n                // 暂时没有响应需要发送，如果对应的通道未被关闭，则继续注册 OP_READ 事件读取请求数据\n                case RequestChannel.NoOpAction =>\n                    curr.request.updateRequestMetrics()\n                    trace(\"Socket server received empty response to send, registering for read: \" + curr)\n                    val channelId = curr.request.connectionId\n                    if (selector.channel(channelId) != null || selector.closingChannel(channelId) != null)\n                        selector.unmute(channelId) // 注册 OP_READ 事件\n                // 当前响应需要发送给请求方\n                case RequestChannel.SendAction =>\n                    // 发送该响应，并将响应对象记录到 inflightResponses 集合中\n                    this.sendResponse(curr)\n                // 需要关闭当前连接\n                case RequestChannel.CloseConnectionAction =>\n                    curr.request.updateRequestMetrics()\n                    trace(\"Closing socket connection actively according to the response code.\")\n                    // 关闭连接\n                    this.close(selector, curr.request.connectionId)\n            }\n        } finally {\n            // 获取下一个待处理的响应\n            curr = requestChannel.receiveResponse(id)\n        }\n    }\n}\n```\n\n我们知道 Processor 本身不负责处理请求，它只是封装请求交由 Handler 线程进行处理，同时每一个 Processor 会维护一个响应队列，Handler 线程在处理完请求之后会将对应的响应对象放置到对应 Processor 的响应队列中，而这一步会遍历处理该响应队列，并依据响应类型分而治之：\n\n1. 如果当前没有响应需要处理，那么会重新在对应的通道上注册 `OP_READ` 事件，以继续读取新的请求数据。\n2. 如果当前的响应需要发送给请求方，则会调用 `Processor#sendResponse` 方法发送响应，并将响应对象记录到 `Processor#inflightResponses` 字段中，表示该响应对象正在被发送。\n3. 如果当前的响应类型表示需要关闭对应的连接，则会调用 `Processor#close` 方法关闭对应的通道，并更新对应 IP 上的连接数。\n\n__步骤 3__ 会发送步骤 2 缓存的响应请求，并将读取到的请求、已经发送成功的请求，以及断开的连接分别放置到 Selector 的 completedReceives、completedSends 和 disconnected 集合中，而步骤 4 至 6 的逻辑则分别对应处理这 3 个集合。首先看一下 __步骤 4__ ，相应实现位于 `Processor#processCompletedReceives` 方法中：\n\n```scala\nprivate def processCompletedReceives() {\n    // 遍历处理接收到的请求\n    selector.completedReceives.asScala.foreach { receive =>\n        try {\n            // 获取请求对应的通道\n            val openChannel = selector.channel(receive.source)\n            // 创建通道对应的 Session 对象，用于权限控制\n            val session = {\n                // Only methods that are safe to call on a disconnected channel should be invoked on 'channel'.\n                val channel = if (openChannel != null) openChannel else selector.closingChannel(receive.source)\n                RequestChannel.Session(new KafkaPrincipal(KafkaPrincipal.USER_TYPE, channel.principal.getName), channel.socketAddress)\n            }\n            // 封装请求信息为 Request 对象\n            val req = RequestChannel.Request(\n                processor = id,\n                connectionId = receive.source,\n                session = session,\n                buffer = receive.payload,\n                startTimeMs = time.milliseconds,\n                listenerName = listenerName,\n                securityProtocol = securityProtocol)\n            // 将请求对象放入请求队列中，等待 Handler 线程处理\n            requestChannel.sendRequest(req)\n            // 取消注册的 OP_READ 事件，处理期间不再接收新的请求（即不读取新的请求数据）\n            selector.mute(receive.source)\n        } catch {\n            case e@(_: InvalidRequestException | _: SchemaException) =>\n                // note that even though we got an exception, we can assume that receive.source is valid. Issues with constructing a valid receive object were handled earlier\n                error(s\"Closing socket for ${receive.source} because of error\", e)\n                close(selector, receive.source)\n        }\n    }\n}\n```\n\n这一步会遍历处理 Selector 的 completedReceives 集合，对于收到的请求对象会读取请求数据，并封装成 Request 对象记录到请求队列 `Processor#requestChannel` 中，等待 Handler 线程处理，同时取消之前注册到对应通道的 `OP_READ` 事件，在处理完成之前不再读取新的请求数据。这里调用了 `RequestChannel#sendRequest` 方法将 Request 对象放置到一个被 Processor 共享的请求队列中，后续 Handler 线程会消费该队列处理对应的请求。\n\n__步骤 5__ 会遍历处理 Selector 的 completedSends 集合，其中存放了已经发送成功的响应，对于这些响应可以从 `Processor#inflightResponses` 中移除，实现如下：\n\n```scala\nprivate def processCompletedSends() {\n    // 遍历处理已经完全发送出去的请求\n    selector.completedSends.asScala.foreach { send =>\n        // 因为当前响应已经发送成功，从 inflightResponses 中移除，不需要客户端确认\n        val resp = inflightResponses.remove(send.destination).getOrElse {\n            throw new IllegalStateException(s\"Send for ${send.destination} completed, but not in `inflightResponses`\")\n        }\n        resp.request.updateRequestMetrics()\n        // 注册 OP_READ 事件，继续读取请求数据\n        selector.unmute(send.destination)\n    }\n}\n```\n\n__步骤 6__ 会遍历处理 Selector 的 disconnected 集合，对于已经断开的连接，将本地记录的待发送完成的响应对象从 `Processor#inflightResponses` 中移除，同时更新对应 IP 上的连接数，实现如下：\n\n```scala\nprivate def processDisconnected() {\n    // 遍历处理已经断开的连接\n    selector.disconnected.asScala.foreach { connectionId =>\n        val remoteHost = ConnectionId.fromString(connectionId).getOrElse {\n            throw new IllegalStateException(s\"connectionId has unexpected format: $connectionId\")\n        }.remoteHost\n        // 将连接对应的所有响应从 inflightResponses 中移除\n        inflightResponses.remove(connectionId).foreach(_.request.updateRequestMetrics())\n        // 对应的通道已经被关闭，所以需要减少对应 IP 上的连接数\n        connectionQuotas.dec(InetAddress.getByName(remoteHost))\n    }\n}\n```\n\n### Handler 组件\n\nProcessor 在将对应的 Request 请求对象记录到全局共享的请求队列之后，Handler 线程会消费该队列并处理对应的请求，同时将处理完成的请求对应的响应对象写入到之前读取该请求的 Processor 的响应队列中。Handler 的实现由 KafkaRequestHandler 和 KafkaRequestHandlerPool 两个类构成，其中 KafkaRequestHandlerPool 是对 KafkaRequestHandler 的封装，提供了对 Handler 线程的管理。KafkaRequestHandlerPool 的实现比较简单，我们主要来看一下 KafkaRequestHandler 的实现。KafkaRequestHandler 实现了 Runnable 接口，其 `KafkaRequestHandler#run` 方法实现如下：\n\n```scala\noverride def run() {\n    while (true) {\n        try {\n            var req: RequestChannel.Request = null\n            while (req == null) {\n                val startSelectTime = time.nanoseconds\n                // 从请求队列中获取 Processor 封装的请求\n                req = requestChannel.receiveRequest(300)\n                val idleTime = time.nanoseconds - startSelectTime\n                aggregateIdleMeter.mark(idleTime / totalHandlerThreads)\n            }\n\n            // 如果是 AllDone 请求，则退出当前线程\n            if (req eq RequestChannel.AllDone) {\n                debug(\"Kafka request handler %d on broker %d received shut down command\".format(id, brokerId))\n                return\n            }\n            req.requestDequeueTimeMs = time.milliseconds\n            trace(\"Kafka request handler %d on broker %d handling request %s\".format(id, brokerId, req))\n            // 处理请求，将响应写回到对应 Processor 的响应队列中，并唤醒 Processor 线程\n            apis.handle(req)\n        } catch {\n            case e: Throwable => error(\"Exception when handling request\", e)\n        }\n    }\n}\n```\n\n上述方法诠释了 Handler 的全部运行逻辑，首先调用 `RequestChannel#receiveRequest` 方法超时等待从全局请求队列中获取请求对象，如果获取到的请求对象是 `RequestChannel.AllDone` 类型，则说明当前请求退出相应线程，否则 Handler 线程会调用 `KafkaApis#handle` 方法对请求进行处理，并将响应结果写入到对应 Processor 的响应队列中。\n\nKafkaApis 类是 Kafka 中的一个核心类实现，用于分发各种类型的请求给到相应的组件，针对每一种请求都定义了相应的方法进行处理，上面调用 `KafkaApis#handle` 方法实现如下：\n\n```scala\ndef handle(request: RequestChannel.Request) {\n    try {\n        trace(\"Handling request:%s from connection %s;securityProtocol:%s,principal:%s\".\n                format(request.requestDesc(true), request.connectionId, request.securityProtocol, request.session.principal))\n        // 依据请求类型分发请求\n        ApiKeys.forId(request.requestId) match {\n            // 处理 ProduceRequest 请求\n            case ApiKeys.PRODUCE => handleProducerRequest(request)\n            // 处理 FetchRequest 请求\n            case ApiKeys.FETCH => handleFetchRequest(request)\n            // 处理 ListOffsetRequest 请求\n            case ApiKeys.LIST_OFFSETS => handleOffsetRequest(request)\n            // 处理 MetadataRequest 请求\n            case ApiKeys.METADATA => handleTopicMetadataRequest(request)\n            // 处理 LeaderAndIsrRequest 请求\n            case ApiKeys.LEADER_AND_ISR => handleLeaderAndIsrRequest(request)\n            // 处理 StopReplicaRequest 请求\n            case ApiKeys.STOP_REPLICA => handleStopReplicaRequest(request)\n            // 处理 UpdateMetadataRequest 请求\n            case ApiKeys.UPDATE_METADATA_KEY => handleUpdateMetadataRequest(request)\n            // 处理 ControlledShutdownRequest 请求\n            case ApiKeys.CONTROLLED_SHUTDOWN_KEY => handleControlledShutdownRequest(request)\n            // 处理 OffsetCommitRequest 请求\n            case ApiKeys.OFFSET_COMMIT => handleOffsetCommitRequest(request)\n            // 处理 OffsetFetchRequest 请求\n            case ApiKeys.OFFSET_FETCH => handleOffsetFetchRequest(request)\n            // 处理 GroupCoordinatorRequest 请求\n            case ApiKeys.GROUP_COORDINATOR => handleGroupCoordinatorRequest(request)\n            // 处理 JoinGroupRequest 请求\n            case ApiKeys.JOIN_GROUP => handleJoinGroupRequest(request)\n            // 处理 HeartbeatRequest 请求\n            case ApiKeys.HEARTBEAT => handleHeartbeatRequest(request)\n            // 处理 LeaveGroupRequest 请求\n            case ApiKeys.LEAVE_GROUP => handleLeaveGroupRequest(request)\n            // 处理 SyncGroupRequest 请求\n            case ApiKeys.SYNC_GROUP => handleSyncGroupRequest(request)\n            // 处理 DescribeGroupsRequest 请求\n            case ApiKeys.DESCRIBE_GROUPS => handleDescribeGroupRequest(request)\n            // 处理 ListGroupsRequest 请求\n            case ApiKeys.LIST_GROUPS => handleListGroupsRequest(request)\n            // 处理 SaslHandshakeRequest 请求\n            case ApiKeys.SASL_HANDSHAKE => handleSaslHandshakeRequest(request)\n            // 处理 ApiVersionsRequest 请求\n            case ApiKeys.API_VERSIONS => handleApiVersionsRequest(request)\n            // 处理 CreateTopicsRequest 请求\n            case ApiKeys.CREATE_TOPICS => handleCreateTopicsRequest(request)\n            // 处理 DeleteTopicsRequest 请求\n            case ApiKeys.DELETE_TOPICS => handleDeleteTopicsRequest(request)\n            case requestId => throw new KafkaException(\"Unknown api code \" + requestId)\n        }\n    } catch {\n        // ... 省略异常处理\n    } finally\n        request.apiLocalCompleteTimeMs = time.milliseconds\n}\n```\n\n枚举类 ApiKeys 为每一种请求类型定义了一个唯一的标识，KafkaApis 会依据具体的请求类型，将请求委托给对应的 `handle*` 方法进行处理，这些方法基本的执行逻辑可以概括为：\n\n1. 解析获取相应类型的请求对象；\n2. 权限校验；\n3. 委托对应的组件处理请求；\n4. 发送响应，或定义响应回调函数，并由具体的组件回调执行。\n\n相应的实现这里先不展开，后续分析具体组件时再针对性介绍。\n\n### 总结\n\n本文我们分析了 Kafka 的网络交互模型设计与实现，考虑到客户端与集群之间，以及 broker 节点之间的交互均基于请求进行通信，所以必须保证网络交互这一块的低延迟和高性能。相比于传统的“thread-per-connection”线程模型，Kafka 采用了 reactor 模式以满足实际的需求，并借助于 java NIO 进行实现。整个网络交互模型主要分为 Acceptor、Processor 和 Handler 三大组件，其中 Acceptor 负责接收请求，Processor 负责解析请求并发送响应，而具体的请求处理过程则交由 Handler 负责，其中的设计思想值得我们在开发自己的项目中借鉴。\n","tags":["Kafka"],"categories":["kafka"]},{"title":"Kafka 源码解析：Broker 节点的启动与关闭","url":"/2019/06/20/kafka/kafka-broker/","content":"\n从本篇开始我们分析 Kafka 服务端组件的实现。Kafka 集群由多个 broker 节点构成，每个节点上都运行着一个 Kafka 实例，这些实例之间基于 ZK 来发现彼此，并由集群控制器 KafkaController 统筹协调运行，彼此之间基于 socket 连接进行通信。本篇我们主要分析单个 broker 节点上 Kafka 实例的启动和关闭过程，关于集群整体的协调运行机制将在后面按照组件逐一进行分析。\n\nKafka 提供了 `kafka-server-start.sh` 脚本来简化服务的启动操作，脚本中通过调用 `kafka.Kafka` 类来启动 Kafka 服务，这也是 Kafka 整个服务端的驱动类。在 Kafka 服务启动过程中，首先会解析并封装命令行传递的参数，然后创建负责 Kafka 服务启动和关闭操作的 KafkaServerStartable 类对象，并调用 `KafkaServerStartable#startup` 方法启动服务。<!-- more -->\n\nKafka 驱动类的 main 方法实现如下：\n\n```scala\ndef main(args: Array[String]): Unit = {\n    try {\n        // 解析命令行参数\n        val serverProps = getPropsFromArgs(args)\n        // 创建 kafkaServerStartable 对象，期间会初始化监控上报程序\n        val kafkaServerStartable = KafkaServerStartable.fromProps(serverProps)\n\n        // 注册一个钩子方法，当 JVM 被关闭时执行 shutdown 逻辑，本质上是在执行 KafkaServer#shutdown 方法\n        Runtime.getRuntime.addShutdownHook(new Thread() {\n            override def run(): Unit = {\n                kafkaServerStartable.shutdown()\n            }\n        })\n\n        // 本质上调用的是 KafkaServer#startup 方法\n        kafkaServerStartable.startup()\n        // 阻塞等待 kafka server 运行线程关闭\n        kafkaServerStartable.awaitShutdown()\n    } catch {\n        case e: Throwable =>\n            fatal(e)\n            System.exit(1)\n    }\n    System.exit(0)\n}\n```\n\nKafkaServerStartable 实际只是对 KafkaServer 的简单封装，相应方法实现都只是简单调用了 KafkaServer 类中同名的方法，所以下文我们主要分析 KafkaServer 类的实现。KafkaServer 是对单个 broker 节点生命周期的描绘，其主要逻辑是用来启动和关闭单个 broker 节点，KafkaServer 类字段定义如下：\n\n```scala\nclass KafkaServer(val config: KafkaConfig, // 配置信息对象\n                  time: Time = Time.SYSTEM, // 时间戳工具\n                  threadNamePrefix: Option[String] = None,\n                  kafkaMetricsReporters: Seq[KafkaMetricsReporter] = List() // 监控上报程序\n                 ) extends Logging with KafkaMetricsGroup {\n\n    /** 标识节点已经启动完成 */\n    private val startupComplete = new AtomicBoolean(false)\n    /** 标识节点正在执行关闭操作 */\n    private val isShuttingDown = new AtomicBoolean(false)\n    /** 标识节点正在执行启动操作 */\n    private val isStartingUp = new AtomicBoolean(false)\n    /** 阻塞主线程等待 KafkaServer 的关闭 */\n    private var shutdownLatch = new CountDownLatch(1)\n    /** 记录 broker 节点的当前状态 */\n    val brokerState: BrokerState = new BrokerState\n    /** Api 接口类，用于分发各种类型的请求 */\n    var apis: KafkaApis = _\n    /** 权限控制相关 */\n    var authorizer: Option[Authorizer] = None\n    var credentialProvider: CredentialProvider = _\n    /** 网络 socket 服务 */\n    var socketServer: SocketServer = _\n    /** 简单的连接池实现，用于管理所有的 KafkaRequestHandler */\n    var requestHandlerPool: KafkaRequestHandlerPool = _\n    /** 日志数据管理 */\n    var logManager: LogManager = _\n    /** 管理当前 broker 节点上的分区副本 */\n    var replicaManager: ReplicaManager = _\n    /** topic 增删管理 */\n    var adminManager: AdminManager = _\n    /** 动态配置管理 */\n    var dynamicConfigHandlers: Map[String, ConfigHandler] = _\n    var dynamicConfigManager: DynamicConfigManager = _\n    /** group 协调管理组件 */\n    var groupCoordinator: GroupCoordinator = _\n    /** 集群控制组件 */\n    var kafkaController: KafkaController = _\n    /** 定时任务调度器 */\n    val kafkaScheduler = new KafkaScheduler(config.backgroundThreads)\n    /** broker 节点活跃性检查 */\n    var kafkaHealthcheck: KafkaHealthcheck = _\n    /** broker 缓存整个集群中全部分区的状态信息 */\n    var metadataCache: MetadataCache = _\n    /** ZK 操作工具类 */\n    var zkUtils: ZkUtils = _\n\n    // ... 省略方法定义\n\n}\n```\n\n在开始分析 KafkaServer 的启动和关闭逻辑之前，我们首先看一下最简单的 `KafkaServer#awaitShutdown` 方法实现。在 KafkaServer 中定义了一个 CountDownLatch 类型的 `KafkaServer#shutdownLatch` 字段，初始 count 值设置为 1，而 `KafkaServer#awaitShutdown` 方法只是简单的调用了 `CountDownLatch#await` 方法来阻塞主线程。当 `KafkaServer#shutdown` 方法执行完成后会调用 `CountDownLatch#countDown` 方法将 count 值设置为 0，从而让主线程从阻塞态中恢复，并最终关闭整个服务。\n\n### 服务启动过程分析\n\n方法 `KafkaServer#shutdown` 的实现我们稍后进行分析，下面首先看一下 Kafka 服务的启动过程，即 `KafkaServer#startup` 方法的实现。该方法实现较长，这里先对方法的整体执行流程进行概括，然后挑一些重点的步骤做进一步分析：\n\n1. 运行状态校验，如果当前 broker 节点正在执行关闭操作，则此时不允许再次启动服务，所以抛出异常；如果当前服务已经启动完成，即处于运行状态，则直接返回，不需要重复启动；否则设置正在启动标记；\n2. 设置当前 broker 节点的状态为 Starting，标识 broker 节点正在启动；\n3. 初始化定时任务调度器 KafkaScheduler；\n4. 创建 ZkUtils 工具类对象，用于操作 ZK，期间会在 ZK 上创建一些基本的节点；\n5. 从 ZK 上获取当前 broker 所属集群的 clusterId，如果不存在则创建一个；\n6. 获取当前 broker 节点的 brokerId；\n7. 初始化一些监控相关的配置；\n8. 创建并启动 LogManager，用于管理记录在本地的日志数据；\n9. 创建 MetadataCache 对象，用于为当前 broker 节点缓存整个集群中全部分区的状态信息；\n10. 创建并启动 SocketServer，用于接收并处理来自客户端和其它 broker 节点的请求；\n11. 创建并启动 ReplicaManager，用于管理当前 broker 节点上的分区副本信息；\n12. 创建并启动 KafkaController，每个 broker 节点都会创建并启动一个 KafkaController 实例，但是只有一个 broker 会成为 leader 角色，负责管理集群中所有的分区和副本的状态，也是集群与 ZK 进行交互的媒介；\n13. 创建并启动 GroupCoordinator，负责管理分配给当前 broker 节点的消费者 group 的一个子集；\n14. 创建并初始化 Authorizer 对象，用于权限管理；\n15. 创建 KafkaApis 对象，用于分发接收到的各种类型请求；\n16. 创建 KafkaRequestHandlerPool 线程池对象，用于管理所有 KafkaRequestHandler 线程；\n17. 创建并启动动态配置管理器，用于监听 ZK 的变更；\n18. 将自己的 brokerId 注册到 ZK 中（`/brokers/ids/{brokerId}` 路径，临时节点），用于标记当前 broker 节点是否存活；\n19. 设置当前 broker 节点的状态为 RunningAsBroker，表示当前 broker 节点已经启动完成，可以对外提供服务；\n20. 更新相关状态标记，标识当前节点的 Kafka 服务启动完成。\n\n下面针对上述流程中的 2、3、4 和 6 几个步骤做进一步说明，对于流程中涉及到的相关类（LogManager、SocketServer、ReplicaManager、KafkaController，以及 GroupCoordinator 等）的实例化和启动的过程会在后续的文章中针对性的分析。\n\n首先来看一下 __步骤 2__ ，这一步本身的逻辑比较简单，就是将当前 broker 节点的状态设置为 Starting，标识当前 broker 节点正在执行启动操作。我们主要来看一下 broker 节点的状态定义和状态转换，Kafka 为 broker 节点定义了 6 种状态，如下：\n\n```scala\nsealed trait BrokerStates { def state: Byte }\n\ncase object NotRunning extends BrokerStates { val state: Byte = 0 }\ncase object Starting extends BrokerStates { val state: Byte = 1 }\ncase object RecoveringFromUncleanShutdown extends BrokerStates { val state: Byte = 2 }\ncase object RunningAsBroker extends BrokerStates { val state: Byte = 3 }\ncase object PendingControlledShutdown extends BrokerStates { val state: Byte = 6 }\ncase object BrokerShuttingDown extends BrokerStates { val state: Byte = 7 }\n```\n\n关于每种状态的解释和状态转换图如下：\n\n- __NotRunning__ ：初始状态，标识当前 broker 节点未运行。\n- __Starting__ ：标识当前 broker 节点正在启动中。\n- __RecoveringFromUncleanShutdown__ ：标识当前 broker 节点正在从上次非正常关闭中恢复。\n- __RunningAsBroker__ ：标识当前 broker 节点启动成功，可以对外提供服务。\n- __PendingControlledShutdown__ ：标识当前 broker 节点正在等待 controlled shutdown 操作完成。\n- __BrokerShuttingDown__ ：标识当前 broker 节点正在执行 shutdown 操作。\n\n![image](/images/2019/kafka-broker-state.png)\n\n所谓 controlled shutdown，实际上是 Kafka 提供的一种友好的关闭 broker 节点的机制。除了因为硬件等原因导致的节点非正常关闭，一些场景下管理员也需要通过命令行发送 ControlledShutdownRequest 请求来主动关闭指定的 broker 节点，例如迁移机房、升级软件，修改 Kafka 配置等。关于 controlled shutdown 机制，我们将在后面分析 KafkaController 组件时再展开分析。\n\n下面继续来看一下 __步骤 3__ ，KafkaScheduler 是一个基于 ScheduledThreadPoolExecutor 的定时任务调度器实现，实现了 Scheduler 特质：\n\n```scala\ntrait Scheduler {\n    def startup()\n    def shutdown()\n    def isStarted: Boolean\n    def schedule(name: String, fun: () => Unit, delay: Long = 0, period: Long = -1, unit: TimeUnit = TimeUnit.MILLISECONDS)\n}\n```\n\n其中 startup 和 shutdown 方法分别用于启动和关闭调度器，而 isStarted 方法用于检测当前调度器是否已经启动，方法 schedule 用于注册需要进行周期性调度的任务。\n\n__步骤 4__ 调用了 `KafkaServer#initZk` 方法创建 ZkUtils 对象，ZkUtils 是对 [zkclient](https://github.com/sgroschupf/zkclient) 的封装，用于操作 ZK。方法 `KafkaServer#initZk` 会基于 `zookeeper.connect` 配置获取对应的 ZK 连接，并在 ZK 上创建一些基本的节点。主要的 ZK 节点包括：\n\n- `/brokers/ids/{id}`: 记录集群中可用的 broker 的 ID。\n- `/brokers/topics/{topic}/partitions`: 记录一个 topic 中所有分区的分配信息，以及 AR 集合。\n- `/brokers/topics/{topic}/partitions/{partition_id}/state`: 记录分区 leader 副本所在的 broker 节点 ID、年代信息、ISR 集合，以及 zkVersion 等。\n- `/controller`: 记录集群 controller leader 所在 broker 节点的 ID。\n- `/controller_epoch`: 记录集群 controller leader 的年代信息。\n- `/admin/reassign_partitions`: 记录需要执行副本重新分配的分区。\n- `/admin/preferred_replica_election`: 记录需要进行优先副本选举的分区，优先副本是在创建分区时指定的第一个副本。\n- `/admin/delete_topics`: 记录待删除的 topic 集合。\n- `/isr_change_notification`: 记录一段时间内 ISR 集合发生变化的分区。\n- `/config`: 记录一些配置信息。\n\n最后来看一下 __步骤 6__ 获取当前 broker 节点的 brokerId 的过程。我们在启动 Kafka 服务之前可以在配置中通过 `broker.id` 配置项为当前 broker 节点设置全局唯一的 ID，也可以指定让 Kafka 自动生成。解析 brokerId 的过程位于 `KafkaServer#getBrokerId` 方法中，实现如下：\n\n```scala\nprivate def getBrokerId: Int = {\n    // 获取配置的 brokerId\n    var brokerId = config.brokerId\n    val brokerIdSet = mutable.HashSet[Int]()\n\n    // 遍历 log.dirs 配置的 log 目录列表\n    for (logDir <- config.logDirs) {\n        // 在每一个 log 目录下面创建一个 meta.properties 文件，内容包含当前 broker 节点的 ID 和版本信息\n        val brokerMetadataOpt = brokerMetadataCheckpoints(logDir).read()\n        brokerMetadataOpt.foreach { brokerMetadata =>\n            brokerIdSet.add(brokerMetadata.brokerId)\n        }\n    }\n\n    if (brokerIdSet.size > 1) {\n        // 不允许多个 broker 节点共享同一个 log 目录\n        // ... 抛出 InconsistentBrokerIdException 异常，略\n    } else if (brokerId >= 0 && brokerIdSet.size == 1 && brokerIdSet.last != brokerId) {\n        // 配置的 brokerId 与 meta.properties 中记录的 brokerId 不一致\n        // ... 抛出 InconsistentBrokerIdException 异常，略\n    } else if (brokerIdSet.isEmpty && brokerId < 0 && config.brokerIdGenerationEnable) {\n        // 如果没有配置，则自动创建 brokerId，通过 ZK 保证 brokerId 的全局唯一性\n        brokerId = generateBrokerId\n    } else if (brokerIdSet.size == 1) {\n        // 从 meta.properties 中获取 brokerId\n        brokerId = brokerIdSet.last\n    }\n\n    brokerId\n}\n```\n\n在 broker 节点的每个 log 目录下有一个 `meta.properties` 文件，记录了当前 broker 节点的 ID 和版本信息。如果当前 broker 节点不是第一次启动，那么 Kafka 可以通过该文件约束 `broker.id` 配置需要前后保持一致。此外，Kafka 还通过该文件保证一个 log 目录不被多个 broker 节点共享。\n\n### 服务关闭过程分析\n\nBroker 节点在关闭对应的 Kafka 服务时，首先会设置状态为 BrokerShuttingDown，表示正在执行关闭操作，然后开始关闭注册的相关组件，并在这些组件全部关闭成功之后，更新 broker 状态为 NotRunning。相关实现位于 `KafkaServer#shutdown` 中：\n\n```scala\ndef shutdown() {\n    try {\n        info(\"shutting down\")\n\n        // 如果正在启动，则不允许关闭\n        if (isStartingUp.get)\n            throw new IllegalStateException(\"Kafka server is still starting up, cannot shut down!\")\n\n        if (shutdownLatch.getCount > 0 && isShuttingDown.compareAndSet(false, true)) {\n            CoreUtils.swallow(controlledShutdown())\n            // 设置 broker 状态为 BrokerShuttingDown，表示当前 broker 正在执行关闭操作\n            brokerState.newState(BrokerShuttingDown)\n\n            /* 依次关闭相应注册的组件 */\n\n            if (socketServer != null) CoreUtils.swallow(socketServer.shutdown())\n            if (requestHandlerPool != null) CoreUtils.swallow(requestHandlerPool.shutdown())\n            CoreUtils.swallow(kafkaScheduler.shutdown())\n            if (apis != null) CoreUtils.swallow(apis.close())\n            CoreUtils.swallow(authorizer.foreach(_.close()))\n            if (replicaManager != null) CoreUtils.swallow(replicaManager.shutdown())\n            if (adminManager != null) CoreUtils.swallow(adminManager.shutdown())\n            if (groupCoordinator != null) CoreUtils.swallow(groupCoordinator.shutdown())\n            if (logManager != null) CoreUtils.swallow(logManager.shutdown())\n            if (kafkaController != null) CoreUtils.swallow(kafkaController.shutdown())\n            if (zkUtils != null) CoreUtils.swallow(zkUtils.close())\n            if (metrics != null) CoreUtils.swallow(metrics.close())\n\n            // 设置 broker 状态为 NotRunning，表示关闭成功\n            brokerState.newState(NotRunning)\n\n            // 设置状态标记\n            startupComplete.set(false)\n            isShuttingDown.set(false)\n            CoreUtils.swallow(AppInfoParser.unregisterAppInfo(jmxPrefix, config.brokerId.toString))\n            shutdownLatch.countDown()\n            info(\"shut down completed\")\n        }\n    } catch {\n        case e: Throwable =>\n            fatal(\"Fatal error during KafkaServer shutdown.\", e)\n            isShuttingDown.set(false)\n            throw e\n    }\n}\n```\n\n整体执行流程如代码注释，比较简单，相关组件的关闭逻辑我们将在后续文章分析具体组件时再进行介绍。\n\n### 总结\n\n本文我们主要分析了 Kafka 服务启动和关闭的过程。Kafka 在设计上将各个主要功能模块都拆分成了一个个组件进行实现，服务启动的过程实际上就是实例化并启动各个组件的过程，关闭过程也是如此。到目前为止，我们主要是分析了服务整体启动的执行流程，关于各个组件的启动逻辑，将在后面的文章中分析具体组件时再针对性介绍。\n","tags":["Kafka"],"categories":["kafka"]},{"title":"Kafka 源码解析：消费者运行机制","url":"/2019/06/19/kafka/kafka-consumer/","content":"\n与上一篇介绍的 KafkaProducer 一样，Kafka 消费者 KafkaConsumer 同样是 Kafka 与开发者交互的媒介之一，负责从 Kafka 集群拉取消息给应用程序消费，并提交已经消费完成的 offset 值。此外，考虑到消费者上下线、topic 分区数目变更等情况，KafkaConsumer 还需要负责与服务端交互执行分区再分配操作，以保证消费者能够更加均衡的消费 topic 分区，从而提升消费的性能。\n\nKafka 定义了 group 的概念，将多个消费者实例组织成为一个 group，以丰富 Kafka 的应用场景。一个 group 名下可以包含任意数量的消费者实例，并从这些消费者中选择一个消费者担任 group 中的 Leader 消费者角色，负责管理 group 和其它 Follower 角色消费者的状态。当有消费者加入或离开当前 group 时，Group Leader 会依据集群确定的分区分配策略，为 group 名下所有消费者重新分配分区，以保证消息消费的均衡性。<!-- more -->\n\n本文我们同样先回忆一下 KafkaConsumer 的使用方式，然后重点分析消息的拉取过程、分区再分配机制，以及 offset 提交机制。\n\n### KafkaConsumer 使用示例\n\n我们仍然以 Kafka 内置的 java 客户端为例，介绍如何消费 Kafka 中的消息。示例如下：\n\n```java\nProperties properties = new Properties();\nproperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nproperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());\nproperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nproperties.put(ConsumerConfig.GROUP_ID_CONFIG, DEFAULT_GROUP);\nproperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"false\");\nKafkaConsumer<Integer, String> consumer = new KafkaConsumer<>(properties);\n// 订阅主题\nconsumer.subscribe(Collections.singleton(DEFAULT_TOPIC));\n\nwhile (!Thread.currentThread().isInterrupted()) {\n    ConsumerRecords<Integer, String> records = consumer.poll(TimeUnit.SECONDS.toMillis(1));\n    try {\n        for (final ConsumerRecord<Integer, String> record : records) {\n            // ... 这里是消费逻辑\n            this.printResult(record);\n        }\n        // 异步提交\n        consumer.commitAsync();\n    } catch (Throwable e) {\n        // ... 异常\n    } finally {\n        // 同步提交\n        consumer.commitSync();\n    }\n}\n```\n\n示例中消费消息依赖于 KafkaConsumer 对象，KafkaConsumer 类也是我们分析消费者运行机制的入口。创建 KafkaConsumer 类对象时我们需要指定 Kafka 集群地址，以及消息 key 和 value 的反序列化器。接着我们可以循环调用 `KafkaConsumer#poll` 方法从 Kafka 集群拉取消息进行消费，该方法接收一个 timeout 参数，用于设置等待消息返回的超时时间，如果设置为 0 则 Kafka 会立即从本地缓存的消息集合中获取符合期望的结果进行返回。\n\n读者可能对 `timeout=0` 的设置有些疑惑，认为这样的参数设置意义不大，因为一次网络请求多少都有时间上开销，这样的理解也是没有错的。但是后面在分析消息的消费过程时你将会看到，实际从集群拉取当前请求的消息的过程并不是在调用 poll 方法之后完成的。Kafka 为了性能考虑，在返回消息之前已经发送了下一次拉取消息的请求，这样处理消息的过程与请求下一轮消息的过程就是并行执行的。如果网络足够快，或者处理消息的逻辑足够耗时，则设置 `timeout=0` 是完全能够平滑工作的。\n\n示例中我们关闭了 offset 的自动提交策略，并在正常运行过程中启用异步提交来提升性能，只有当出现异常的情况下才会使用同步提交，以防止 offset 丢失。\n\n### 消息消费过程分析\n\n我们以 KafkaConsumer 类为入口开始分析消费者的运行机制，首先来看一下 KafkaConsumer 类的字段定义：\n\n```java\npublic class KafkaConsumer<K, V> implements Consumer<K, V> {\n\n    /** 客户端 ID 生成器 */\n    private static final AtomicInteger CONSUMER_CLIENT_ID_SEQUENCE = new AtomicInteger(1);\n    /** 客户端 ID */\n    private final String clientId;\n    /** 控制消费者与 GroupCoordinator 之间交互 */\n    private final ConsumerCoordinator coordinator;\n    /** key 反序列化器 */\n    private final Deserializer<K> keyDeserializer;\n    /** value 反序列化器 */\n    private final Deserializer<V> valueDeserializer;\n    /** 负责从服务端拉取消息 */\n    private final Fetcher<K, V> fetcher;\n    /** 拦截器集合， 在方法返回给用户之前进行拦截修改 */\n    private final ConsumerInterceptors<K, V> interceptors;\n    /** 时间戳工具 */\n    private final Time time;\n    /** 集群网络通信客户端，对 NetworkClient 的封装 */\n    private final ConsumerNetworkClient client;\n    /** 维护消费者的消费状态 */\n    private final SubscriptionState subscriptions;\n    /** 集群元数据 */\n    private final Metadata metadata;\n    /** 重试间隔 */\n    private final long retryBackoffMs;\n    /** 请求超时时间 */\n    private final long requestTimeoutMs;\n    /** 标识当前消费者是否关闭 */\n    private volatile boolean closed = false;\n    /** 记录当前正在使用 KafkaConsumer 的线程 ID，防止多个线程同时使用同一个 KafkaConsumer 对象 */\n    private final AtomicLong currentThread = new AtomicLong(NO_CURRENT_THREAD);\n    /** 记录线程重入次数 */\n    private final AtomicInteger refcount = new AtomicInteger(0);\n\n    // ... 省略方法定义\n\n}\n```\n\nKafkaConsumer 对象的构造的过程比较简单，这里不再展开。\n\n![image](/images/2019/kafka-consumer.png)\n\n与介绍 KafkaProducer 一样，在深入分析 KafkaConsumer 的运行机制之前，我们同样以一张图（如上图）从整体层面对消费消息的过程做一个整体的介绍。\n\n当消费者请求拉取消息消费时，KafkaConsumer 会首先检查当前是否需要执行分区再平衡操作。Kafka 限定一个分区至多只能被一个消费者消费，因为消费者可能会发生上下线操作，并且分区的数量也可能会增加，所以 Kafka 内置了分区再平衡机制，尽量保证将分区均匀分配给各个消费者。\n\n此外，为了提升消费的性能，Kafka 巧妙的将处理消息的过程与拉取消息的过程并行化。KafkaConsumer 在将消息返回给应用程序之前会发送拉取后续消息的请求，这样能够实现应用程序在处理消息的时候，KafkaConsumer 也在后台为应用程序准备下一轮需要消费的消息。所以，应用程序大多数时候都是直接从本地获取到缓存的消息数据，期间无需等待与 Kafka 集群的远程通信。\n\n上述是整个消费者运行机制的两个关键点，下面的小节我们将展开对整个消费者运行机制进行深入分析。\n\n#### 订阅主题\n\n在使用 KafkaConsumer 消费服务端消息之前，我们首先需要调用 `KafkaConsumer#subscribe` 方法订阅 topic 列表，该方法实现如下：\n\n```java\npublic void subscribe(Collection<String> topics, ConsumerRebalanceListener listener) {\n    // 防止一个 KafkaConsumer 对象被多个线程同时使用，以保证线程安全\n    this.acquire();\n    try {\n        if (topics == null) {\n            throw new IllegalArgumentException(\"Topic collection to subscribe to cannot be null\");\n        } else if (topics.isEmpty()) {\n            // 如果传递空的 topic 订阅列表，则视为解除订阅\n            this.unsubscribe();\n        } else {\n            // ... 校验输入的 topic 不为 null 或空，如果是则抛出 IllegalArgumentException 异常，省略\n\n            // 订阅当前 topic 列表\n            subscriptions.subscribe(new HashSet<>(topics), listener);\n            metadata.setTopics(subscriptions.groupSubscription());\n        }\n    } finally {\n        // 线程重入计数 refcount 减 1，如果 refcount = 0，则标记当前 KafkaConsumer 对象没有线程占用\n        this.release();\n    }\n}\n```\n\n在开始订阅 topic 之前会先校验 KafkaConsumer 对象是否被多个线程占用。我们知道 KafkaConsumer 不是线程安全的，KafkaConsumer 设置了两个字段 `KafkaConsumer#currentThread` 和 `KafkaConsumer#refcount` 用于控制访问当前 KafkaConsumer 对象的线程 ID 和线程重入次数。其中 currentThread 用于记录持有当前 KafkaConsumer 对象的线程 ID，refcount 则表示该线程的重入次数。对于这 2 个变量的控制，KafkaConsumer 一般会使用下面这样的模板代码：\n\n```java\nthis.acquire();\ntry {\n    // do somthing here\n} finally {\n    this.release();\n}\n```\n\n其中 `KafkaConsumer#acquire` 方法可以类比理解为加锁，而 `KafkaConsumer#release` 方法可以类比理解为释放锁。我们先来看一下 `KafkaConsumer#acquire` 方法，该方法首先会验证当前 KafkaConsumer 对象是否被关闭，如果没有被关闭则会继续验证当前操作线程是否是已经持有该 KafkaConsumer 对象的线程，如果不是且当前 KafkaConsumer 对象被其它线程持有，则会抛出异常，否则将重入计数 refcount 加 1。以此来保证一个 KafkaConsumer 对象在同一时段只能被同一个线程持有，但是允许同一个线程多次持有。方法 `KafkaConsumer#acquire` 实现如下：\n\n```java\nprivate void acquire() {\n    // 检测当前 consumer 是否关闭，如果关闭则抛出异常\n    this.ensureNotClosed();\n    long threadId = Thread.currentThread().getId();\n    // 如果存在多个线程使用同一个 consumer 对象，则抛出异常\n    if (threadId != currentThread.get() && !currentThread.compareAndSet(NO_CURRENT_THREAD, threadId)) {\n        throw new ConcurrentModificationException(\"KafkaConsumer is not safe for multi-threaded access\");\n    }\n    // 线程重入次数加 1\n    refcount.incrementAndGet();\n}\n```\n\n再来看一下 `KafkaConsumer#release` 方法的实现（如下），该方法逻辑比较简单，将重入计数 refcount 减 1，意味着本次线程退出当前临界区，如果重入计数为 0，则清空 currentThread，以允许其它线程获取锁。\n\n```java\nprivate void release() {\n    // 线程重入次数减 1\n    if (refcount.decrementAndGet() == 0) {\n        // 如果当前线程重入次数为 0，则表示当前 KafkaConsumer 对象没有线程占用\n        currentThread.set(NO_CURRENT_THREAD);\n    }\n}\n```\n\n在保证线程安全的前提下，方法 `KafkaConsumer#subscribe` 会对传递的 topic 集合进行校验，如果当前传递的 topic 集合为空，则视为取消订阅。取消订阅主要做了 2 件事情：\n\n1. 清空本地订阅的 topic 集合、清除本地记录的每个 topic 分区的消费状态，以及重置一些本地的变量。\n2. 构建并发送 LeaveGroupRequest 请求，告知服务端自己已经离开当前的 group。\n\n如果传递的 topic 集合不为空，则会调用 `SubscriptionState#subscribe` 方法订阅指定 topic 集合，实现如下：\n\n```java\npublic void subscribe(Set<String> topics, ConsumerRebalanceListener listener) {\n    if (listener == null) {\n        throw new IllegalArgumentException(\"RebalanceListener cannot be null\");\n    }\n    // 设置 topic 订阅模式为 AUTO_TOPICS\n    this.setSubscriptionType(SubscriptionType.AUTO_TOPICS);\n    this.listener = listener;\n    // 更新本地缓存的订阅的信息\n    this.changeSubscription(topics);\n}\n```\n\n同一个 KafkaConsumer 对象订阅主题的模式有 3 种，定义在 SubscriptionType 枚举类中（其中 NONE 指代未订阅任何主题）：\n\n```java\nprivate enum SubscriptionType {\n    NONE,\n    /** 按照指定的 topic 的名字进行订阅，自动分配分区 */\n    AUTO_TOPICS,\n    /** 按照正则匹配 topic 名称进行订阅，自动分配分区 */\n    AUTO_PATTERN,\n    /** 用户手动指定消费的 topic 以及分区 */\n    USER_ASSIGNED\n}\n```\n\n并且这些订阅模式之间是互斥的，即一个 KafkaConsumer 对象不允许同时使用多种模式进行订阅，相关控制位于 `SubscriptionState#setSubscriptionType` 方法中：\n\n```java\nprivate void setSubscriptionType(SubscriptionType type) {\n    if (this.subscriptionType == SubscriptionType.NONE) {\n        // NONE 表示没有设置过，设置为目标模式\n        this.subscriptionType = type;\n    } else if (this.subscriptionType != type) {\n        // 如果之前设置过，且目标模式不是之前的模式，则抛出异常\n        throw new IllegalStateException(SUBSCRIPTION_EXCEPTION_MESSAGE);\n    }\n}\n```\n\n如果当前的订阅模式合法，则会继续调用 `SubscriptionState#changeSubscription` 方法依据本次订阅的 topic 集合更新 `SubscriptionState#subscription` 和 `SubscriptionState#groupSubscription` 字段。其中 subscription 字段用于记录当前消费者订阅的 topic 集合，而 groupSubscription 字段则依据当前消费者是 Leader 还是 Follower 有所不同。如果是 Leader 则记录当前消费者所属 group 中所有消费者订阅的 topic 集合，如果是 Follower 则仅保存其自身订阅的 topic 集合。到这里，订阅 topic 的过程就算完成了，整个过程还未涉及到与集群的交互，这会在执行 `KafkaConsumer#poll` 时发生。\n\n#### 拉取消息\n\n在完成了对目标 topic 的订阅之后，下面继续分析从集群拉取消息的过程，位于 `KafkaConsumer#poll` 方法中，实现如下：\n\n```java\npublic ConsumerRecords<K, V> poll(long timeout) {\n    this.acquire();\n    try {\n        // 超时时间不允许设置为负数，但是允许设置为 0\n        if (timeout < 0) {\n            throw new IllegalArgumentException(\"Timeout must not be negative\");\n        }\n        // 当前消费者未订阅任何 topic\n        if (subscriptions.hasNoSubscriptionOrUserAssignment()) {\n            throw new IllegalStateException(\"Consumer is not subscribed to any topics or assigned any partitions\");\n        }\n\n        long start = time.milliseconds();\n        long remaining = timeout;\n        do {\n            // 拉取消息，优先从本地缓存中获取，如果没有则会请求服务端，期间会尝试执行分区再分配策略，以及异步提交 offset\n            Map<TopicPartition, List<ConsumerRecord<K, V>>> records = this.pollOnce(remaining);\n            if (!records.isEmpty()) {\n                /*\n                 * 为了提升效率，在对响应的消息处理之前，先发送下一次 fetch 请求，\n                 * 从而让处理消息的过程与拉取消息的过程并行，以减少等待网络 IO 的时间\n                 */\n                if (fetcher.sendFetches() > 0 || client.pendingRequestCount() > 0) {\n                    // 如果有待发送的请求，执行一次不可中断的 poll 请求\n                    client.pollNoWakeup();\n                }\n\n                if (this.interceptors == null) {\n                    return new ConsumerRecords<>(records);\n                } else {\n                    // 如果注册了拦截器，则在返回之前先应用拦截器\n                    return this.interceptors.onConsume(new ConsumerRecords<>(records));\n                }\n            }\n\n            long elapsed = time.milliseconds() - start;\n            remaining = timeout - elapsed;\n        } while (remaining > 0);\n        return ConsumerRecords.empty();\n    } finally {\n        this.release();\n    }\n}\n```\n\n上述方法返回一个 ConsumerRecords 对象，用于对从每个 topic 分区拉取回来的 ConsumerRecord 对象集合进行封装。前面我们在分析 KafkaProducer 时介绍了 ProducerRecord 类，用于封装 Producer 发送的每条消息，而 ConsumerRecord 类则与之对应，用于封装 Consumer 消费的每条消息。\n\n从集群拉取消息时需要指定响应超时时间 timeout 参数，该参数允许设置为非负数，前面我们已经介绍了 `timeout=0` 的意义，相应的逻辑位于这里实现。方法首先会调用 `KafkaConsumer#pollOnce` 从本地或服务端拉取一批消息，如果拉取成功（即返回结果不为空），方法并不会立即将结果返回，而是在返回之前尝试发送下一次拉取消息的请求。因为拉取消息涉及网络通信，需要与远端集群进行交互，比较耗时，而业务处理消息也是一个耗时的过程，Kafka 的设计者巧妙的将这两步并行执行，以提升效率。\n\n如果设置了 Consumer 拦截器，那么在返回待消费消息数据之前会先对消息执行拦截修改。Kafka 定义了 ConsumerInterceptor 接口，该接口定义如下：\n\n```java\npublic interface ConsumerInterceptor<K, V> extends Configurable {\n    ConsumerRecords<K, V> onConsume(ConsumerRecords<K, V> records);\n    void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets);\n    void close();\n}\n```\n\n其中 `ConsumerInterceptor#onConsume` 方法会在消息数据被返回给应用程序之前执行，如 `KafkaConsumer#poll` 方法所示，而方法 `ConsumerInterceptor#onCommit` 会在 offset 成功提交后被调用。\n\n下面先跳过 `KafkaConsumer#pollOnce` 方法来看一下 `Fetcher#sendFetches` 方法的实现，因为在 pollOnce 中同样调用了该方法，所以先了解其执行逻辑，以便于更好的理解 pollOnce 所做的工作。方法 `Fetcher#sendFetches` 的主要工作就是构建并向集群发送 FetchRequest 请求，以拉取指定 offset 的消息。Fetcher 类主要负责从服务端拉取消息，其字段定义如下：\n\n```java\npublic class Fetcher<K, V> implements SubscriptionState.Listener {\n\n    /** 网络客户端 */\n    private final ConsumerNetworkClient client;\n    /** 时间戳工具 */\n    private final Time time;\n    /** 服务端返回的消息并不是立即响应，而是累积到 minBytes 再响应 */\n    private final int minBytes;\n    /** 请求时指定的服务端最大响应字节数 */\n    private final int maxBytes;\n    /** 累积等待的最大时长，达到该时间时，即使消息数据量不够，也会执行响应 */\n    private final int maxWaitMs;\n    /** 每次 fetch 操作的最大字节数 */\n    private final int fetchSize;\n    /** 重试间隔时间戳 */\n    private final long retryBackoffMs;\n    /** 每次获取 record 的最大数量 */\n    private final int maxPollRecords;\n    /** 是否对结果执行 CRC 校验 */\n    private final boolean checkCrcs;\n    /** 集群元数据 */\n    private final Metadata metadata;\n    /** 记录每个 topic 分区的消息消费情况 */\n    private final SubscriptionState subscriptions;\n    /** 每个响应在解析之前都会先转换成 CompletedFetch 对象记录到该队列中 */\n    private final ConcurrentLinkedQueue<CompletedFetch> completedFetches;\n    /** key 反序列化器 */\n    private final Deserializer<K> keyDeserializer;\n    /** value 反序列化器 */\n    private final Deserializer<V> valueDeserializer;\n    /** 缓存，用于对响应结果进行解析 */\n    private final BufferSupplier decompressionBufferSupplier = BufferSupplier.create();\n    /** 保存响应的分区、消息 起始位移等 */\n    private PartitionRecords<K, V> nextInLineRecords = null;\n    /** 封装在解析指定 offset 时的异常信息 */\n    private ExceptionMetadata nextInLineExceptionMetadata = null;\n\n    // ... 省略方法定义\n\n}\n```\n\n下面来看一下 `Fetcher#sendFetches` 方法的实现：\n\n```java\npublic int sendFetches() {\n    // 获取可以 fetch 的 topic 分区，并创建到分区 leader 副本所在节点的 FetchRequest 请求\n    Map<Node, FetchRequest.Builder> fetchRequestMap = this.createFetchRequests();\n    // 遍历并往各个目标节点发送 FetchRequest 请求\n    for (Map.Entry<Node, FetchRequest.Builder> fetchEntry : fetchRequestMap.entrySet()) {\n        final FetchRequest.Builder request = fetchEntry.getValue();\n        final Node fetchTarget = fetchEntry.getKey();\n\n        // 往目标节点发送 FetchRequest 请求\n        log.debug(\"Sending fetch for partitions {} to broker {}\", request.fetchData().keySet(), fetchTarget);\n        client.send(fetchTarget, request)\n                // 添加监听器用于处理 FetchResponse 响应\n                .addListener(new RequestFutureListener<ClientResponse>() {\n                    @Override\n                    public void onSuccess(ClientResponse resp) {\n                        FetchResponse response = (FetchResponse) resp.responseBody();\n                        // 响应中的 topic 分区集合与请求的 topic 分区集合不匹配，忽略本次响应\n                        if (!matchesRequestedPartitions(request, response)) {\n                            log.warn(\"Ignoring fetch response containing partitions {} since it does not match the requested partitions {}\", response.responseData().keySet(), request.fetchData().keySet());\n                            return;\n                        }\n\n                        // 响应中的 topic 分区集合\n                        Set<TopicPartition> partitions = new HashSet<>(response.responseData().keySet());\n                        FetchResponseMetricAggregator metricAggregator = new FetchResponseMetricAggregator(sensors, partitions);\n                        // 遍历处理响应中的数据\n                        for (Map.Entry<TopicPartition, FetchResponse.PartitionData> entry : response.responseData().entrySet()) {\n                            TopicPartition partition = entry.getKey();\n                            // 当前 topic 分区对应请求的 offset\n                            long fetchOffset = request.fetchData().get(partition).offset;\n                            FetchResponse.PartitionData fetchData = entry.getValue();\n                            // 将结果包装成 CompletedFetch 缓存到 completedFetches 队列中\n                            completedFetches.add(new CompletedFetch(partition, fetchOffset, fetchData, metricAggregator, request.version()));\n                        }\n\n                        sensors.fetchLatency.record(resp.requestLatencyMs());\n                        sensors.fetchThrottleTimeSensor.record(response.getThrottleTime());\n                    }\n\n                    @Override\n                    public void onFailure(RuntimeException e) {\n                        log.debug(\"Fetch request to {} for partitions {} failed\", fetchTarget, request.fetchData().keySet(), e);\n                    }\n                });\n    }\n    // 返回本次发送的请求数目\n    return fetchRequestMap.size();\n}\n```\n\n上述方法的主要执行逻辑就是获取需要拉取消息的 topic 分区集合，并为每个分区创建对应的 FetchRequest 请求对象，同时将这些请求按照分区对应的 Leader 副本所在 broker 节点组成 `Map<Node, FetchRequest.Builder>` 集合。接着，方法会遍历处理该集合向对应节点发送 FetchRequest 请求，并注册 RequestFutureListener 监听器对响应结果进行处理。如果响应中的分区集合与请求时的分区集合能够匹配，则方法会遍历响应结果，并将每个分区 offset 对应的响应结果对象封装成 CompletedFetch 对象，记录到 `Fetcher#completedFetches` 同步队列中。CompletedFetch 仅仅是对响应的一个简单的封装，后面会消费该队列，并将获取到的 CompletedFetch 对象解析成 ConsumerRecord 对象封装到 PartitionRecords 中，该类记录了消息对应的分区、offset、消息集合，以及客户端消费的位置等信息。\n\n消费逻辑由 `Fetcher#fetchedRecords` 方法实现，如下：\n\n```java\n// 获取并移除队首元素\nCompletedFetch completedFetch = completedFetches.poll();\nif (completedFetch == null) break; // completedFetches 已空\ntry {\n    // 解析 CompletedFetch 成 PartitionRecords 对象\n    nextInLineRecords = this.parseCompletedFetch(completedFetch);\n} catch (KafkaException e) {\n    if (drained.isEmpty()) {\n        throw e;\n    }\n    // 封装当前分区 offset 对应的异常信息，在下次获取该分区 offset 消息时抛出\n    nextInLineExceptionMetadata = new ExceptionMetadata(completedFetch.partition, completedFetch.fetchedOffset, e);\n}\n\nprivate PartitionRecords<K, V> parseCompletedFetch(CompletedFetch completedFetch) {\n    TopicPartition tp = completedFetch.partition;\n    FetchResponse.PartitionData partition = completedFetch.partitionData;\n    long fetchOffset = completedFetch.fetchedOffset;\n    int bytes = 0;\n    int recordsCount = 0;\n    PartitionRecords<K, V> parsedRecords = null;\n    // 解析获取响应错误码\n    Errors error = Errors.forCode(partition.errorCode);\n    try {\n        // 当前 topic 分区不允许 fetch 消息，一般是因为当前正在执行分区再分配，或者消费者被暂停\n        if (!subscriptions.isFetchable(tp)) {\n            log.debug(\"Ignoring fetched records for partition {} since it is no longer fetchable\", tp);\n        }\n        // 正常响应\n        else if (error == Errors.NONE) {\n            // 获取 topic 分区对应的下次获取消息的 offset\n            Long position = subscriptions.position(tp);\n            if (position == null || position != fetchOffset) {\n                // 请求的 offset 与响应的不匹配\n                log.debug(\"Discarding stale fetch response for partition {} since its offset {} does not match the expected offset {}\", tp, fetchOffset, position);\n                return null;\n            }\n\n            List<ConsumerRecord<K, V>> parsed = new ArrayList<>();\n            boolean skippedRecords = false;\n            for (LogEntry logEntry : partition.records.deepEntries(decompressionBufferSupplier)) {\n                // 跳过请求 offset 位置之前的消息\n                if (logEntry.offset() >= position) {\n                    // 封装成 ConsumerRecord 对象\n                    parsed.add(this.parseRecord(tp, logEntry));\n                    bytes += logEntry.sizeInBytes();\n                } else {\n                    skippedRecords = true;\n                }\n            }\n            recordsCount = parsed.size();\n\n            log.trace(\"Adding fetched record for partition {} with offset {} to buffered record list\", tp, position);\n            // 封装结果为 PartitionRecords 对象\n            parsedRecords = new PartitionRecords<>(fetchOffset, tp, parsed);\n\n            // ... 省略一些异常情况的处理\n\n            // 更新本地记录的对应 topic 分区最新的 HW 值\n            if (partition.highWatermark >= 0) {\n                log.trace(\"Received {} records in fetch response for partition {} with offset {}\", parsed.size(), tp, position);\n                subscriptions.updateHighWatermark(tp, partition.highWatermark);\n            }\n        }\n        // ... 省略对于错误响应的处理\n    } finally {\n        completedFetch.metricAggregator.record(tp, bytes, recordsCount);\n    }\n\n    /*\n     * we move the partition to the end if we received some bytes or if there was an error.\n     * This way, it's more likely that partitions for the same topic can remain together (allowing for more efficient serialization).\n     */\n    if (bytes > 0 || error != Errors.NONE) {\n        subscriptions.movePartitionToEnd(tp);\n    }\n\n    return parsedRecords;\n}\n```\n\n从队列中获取到的 CompletedFetch 对象会调用 `Fetcher#parseCompletedFetch` 方法将其解析封装成 PartitionRecords 对象，并记录到 `Fetcher#nextInLineRecords` 字段中，等待后续处理。下面来完整看一下 `Fetcher#fetchedRecords` 方法的实现：\n\n```java\npublic Map<TopicPartition, List<ConsumerRecord<K, V>>> fetchedRecords() {\n    // 如果之前解析当前分区 offset 存在异常，处理该异常\n    if (nextInLineExceptionMetadata != null) {\n        ExceptionMetadata exceptionMetadata = nextInLineExceptionMetadata;\n        nextInLineExceptionMetadata = null;\n        TopicPartition tp = exceptionMetadata.partition;\n        // 如果当前消费者处于运行状态，但是期望的 offset 在解析响应时存在异常，则直接抛出\n        if (subscriptions.isFetchable(tp) && subscriptions.position(tp) == exceptionMetadata.fetchedOffset) {\n            throw exceptionMetadata.exception;\n        }\n    }\n\n    Map<TopicPartition, List<ConsumerRecord<K, V>>> drained = new HashMap<>();\n    int recordsRemaining = maxPollRecords; // 剩余获取 record 的数量\n    while (recordsRemaining > 0) {\n        // 如果当前 topic 分区没有可以处理的记录\n        if (nextInLineRecords == null || nextInLineRecords.isDrained()) {\n            // ... 解析 CompletedFetch 成 PartitionRecords 对象，上面已经分析过\n        } else {\n            TopicPartition partition = nextInLineRecords.partition;\n            // 从之前解析得到的 PartitionRecords 对象中拉取指定数量的消息\n            List<ConsumerRecord<K, V>> records = this.drainRecords(nextInLineRecords, recordsRemaining);\n            if (!records.isEmpty()) {\n                List<ConsumerRecord<K, V>> currentRecords = drained.get(partition);\n                if (currentRecords == null) {\n                    drained.put(partition, records);\n                } else {\n                    /*\n                     * 合并同一个分区的记录（发生的概率很小）\n                     *\n                     * this case shouldn't usually happen because we only send one fetch at a time per partition,\n                     * but it might conceivably happen in some rare cases (such as partition leader changes).\n                     * we have to copy to a new list because the old one may be immutable\n                     */\n                    List<ConsumerRecord<K, V>> newRecords = new ArrayList<>(records.size() + currentRecords.size());\n                    newRecords.addAll(currentRecords);\n                    newRecords.addAll(records);\n                    drained.put(partition, newRecords);\n                }\n                recordsRemaining -= records.size();\n            }\n        }\n    }\n\n    // 返回每个 topic 分区拉取到的消息\n    return drained;\n}\n```\n\n前面我们在分析消费 `Fetcher#completedFetches` 同步队列时，对于解析过程中出现异常的 topic 分区对应的 offset，会将异常信息封装成 ExceptionMetadata 对象，记录到 `Fetcher#nextInLineExceptionMetadata` 字段中，方法 `Fetcher#fetchedRecords` 一开始会先处理该异常。如果之前解析过程能够正常拿到消息并封装成 PartitionRecords 对象，那么接下来将会从对象中拉取指定数量的消息返回给用户。该过程位于 `Fetcher#drainRecords` 方法中，该方法会校验目标分区是否被分配给当前消费者，因为在执行分区再分配时，一个消费者消费的分区是可能变化的，我们将在后面对分区再分配的逻辑进行针对性分析。如果目标 topic 分区仍然是分配给当前消费者的，那么方法会在对应分区允许拉取消息的情况下，从之前解析得到的 PartitionRecords 中获取指定数量的消息，并更新客户端记录的位置信息，包括对应分区的 offset，以及 PartitionRecords 中缓存的消息集合的消费位置。最后将每个分区对应的消息集合封装成 `Map<TopicPartition, List<ConsumerRecord<K, V>>>` 集合返回。\n\n下面我们回到 KafkaConsumer 类，看一下 `KafkaConsumer#pollOnce` 方法的执行逻辑，了解了 `Fetcher#sendFetches` 和 `Fetcher#fetchedRecords` 的实现，再来看 pollOnce 方法会简单很多。该方法实现如下：\n\n```java\nprivate Map<TopicPartition, List<ConsumerRecord<K, V>>> pollOnce(long timeout) {\n    // 执行分区再分配策略，以及异步提交 offset\n    coordinator.poll(time.milliseconds());\n\n    if (!subscriptions.hasAllFetchPositions()) {\n        /*\n         * 如果存在没有分配 offset 的 topic 分区，则执行更新：\n         * 1. 如果需要重置，则按照指定策略重置 offset\n         * 2. 否则，尝试获取上次提交的 offset，如果结果为空则按照默认重置策略进行重置\n         * 3. 否则，使用上次提交的 offset 更新本地记录的 offset 值\n         */\n        this.updateFetchPositions(subscriptions.missingFetchPositions());\n    }\n\n    // 尝试从本地获取缓存的消息\n    Map<TopicPartition, List<ConsumerRecord<K, V>>> records = fetcher.fetchedRecords();\n    if (!records.isEmpty()) {\n        return records;\n    }\n\n    // 如果本地没有直接可用的消息，则创建 FetchRequest 请求，从集群拉取消息数据\n    fetcher.sendFetches();\n    long now = time.milliseconds();\n    long pollTimeout = Math.min(coordinator.timeToNextPoll(now), timeout);\n    // 发送 FetchRequest 请求\n    client.poll(pollTimeout, now, new PollCondition() {\n        @Override\n        public boolean shouldBlock() {\n            return !fetcher.hasCompletedFetches();\n        }\n    });\n\n    // 检查是否需要执行分区再分配，如果是则返回空的结果，以保证尽快对分区执行再平衡操作\n    if (coordinator.needRejoin()) {\n        return Collections.emptyMap();\n    }\n\n    // 获取 FetchRequest 请求返回的消息\n    return fetcher.fetchedRecords();\n}\n```\n\n在拉取消息之前会先尝试执行分区再分配策略，以及异步提交 offset，这 2 步我们先不展开，留到后面的小节中针对性分析。\n\n由于 Kafka 在设计上由消费者自己维护自身消费状态，所以在拉取消息之前需要确定是否需要更新消费者维护的分区 offset 信息，一方面是为了支持分区重置策略，另一方面也是配合分区再分配操作。KafkaConsumer 在拉取消息数据之前会调用 `SubscriptionState#hasAllFetchPositions` 方法检测分配给当前消费者的分区在本地是不是都记录着对应的 offset 值，如果存在没有记录 offset 值的分区，则需要调用 `KafkaConsumer#updateFetchPositions` 方法对这些分区进行更新：\n\n```java\nprivate void updateFetchPositions(Set<TopicPartition> partitions) {\n    // 对于需要重置 offset 的分区，请求分区 leader 副本所在节点获取对应的 offset 值\n    fetcher.resetOffsetsIfNeeded(partitions);\n\n    // 如果仍然存在没有分配 offset 的分区\n    if (!subscriptions.hasAllFetchPositions(partitions)) {\n        // 如果需要从 GroupCoordinator 获取上次提交的 offset，则发送 OffsetFetchRequest 请求更新\n        coordinator.refreshCommittedOffsetsIfNeeded();\n        /*\n         * 再次尝试对未分配 offset 的分区进行更新：\n         * 1. 如果需要重置，则按照指定策略重置 offset\n         * 2. 如果获取到的上次提交的 offset 为空，则按照默认重置策略进行重置\n         * 3. 使用上次提交的 offset 更新本地记录的 offset 值\n         */\n        fetcher.updateFetchPositions(partitions);\n    }\n}\n```\n\n然后，KafkaConsumer 会调用 `Fetcher#fetchedRecords` 方法尝试从本地获取每个 topic 分区对应的缓存消息。如果本地缓存不命中，则会继续调用 `Fetcher#sendFetches` 方法构建并发送 FetchRequest 请求，尝试从集群拉取消息。\n\n在调用 `Fetcher#fetchedRecords` 方法解析并返回服务端响应的消息之前，消费者会先检测当前是否需要执行分区再分配操作，如果需要则直接返回空的结果，这样在不超时的情况下，方法 `KafkaConsumer#pollOnce` 会立即被再次调用，从而开始对当前 topic 分区执行再分配，即调用 `ConsumerCoordinator#poll` 方法。我们会在后面的小节中对分区再分配和自动提交 offset 操作的逻辑展开分析，这里我们先来看一下 `ConsumerCoordinator#poll` 方法，了解这 2 个步骤的触发过程：\n\n```java\npublic void poll(long now) {\n    // 触发执行注册的监听 offset 提交完成的方法\n    this.invokeCompletedOffsetCommitCallbacks();\n\n    // 确保当前是 AUTO_TOPICS 或 AUTO_PATTERN（USER_ASSIGNED 不需要再平衡）订阅模式，\n    // 且目标 GroupCoordinator 节点可达，如果不可达，则会尝试寻找一个可用的节点\n    if (subscriptions.partitionsAutoAssigned() && this.coordinatorUnknown()) {\n        this.ensureCoordinatorReady();\n        now = time.milliseconds();\n    }\n\n    // 需要执行再平衡\n    if (this.needRejoin()) {\n        /*\n         * due to a race condition between the initial metadata fetch and the initial rebalance,\n         * we need to ensure that the metadata is fresh before joining initially.\n         * This ensures that we have matched the pattern against the cluster's topics at least once before joining.\n         *\n         * 如果是 AUTO_PATTERN 订阅模式，则检查是否需要更新集群元数据\n         */\n        if (subscriptions.hasPatternSubscription()) {\n            client.ensureFreshMetadata();\n        }\n\n        /*\n         * 1. 检查目标 GroupCoordinator 节点是否准备好接收请求\n         * 2. 启动心跳线程\n         * 3. 执行分区再分配操作\n         */\n        this.ensureActiveGroup();\n        now = time.milliseconds();\n    }\n\n    // 发送心跳\n    this.pollHeartbeat(now);\n    // 异步提交 offset\n    this.maybeAutoCommitOffsetsAsync(now);\n}\n```\n\n我们前面介绍了 Kafka 有 3 种订阅模式：`AUTO_TOPICS`、`AUTO_PATTERN`，和 `USER_ASSIGNED`。其中 `USER_ASSIGNED` 订阅模式是由用户手动指定消费的分区，所以这种模式下不需要执行分区再分配操作对消费者消费的分区进行动态再分配。对于另外 2 种订阅模式来说，如果需要执行分区再分配，则方法首先需要确保与服务端交互的 GroupCoordinator 实例所在 broker 节点是可用的，然后调用 `AbstractCoordinator#ensureActiveGroup` 方法执行具体的分区再分配操作，我们将在 2.3 小节对这一过程进行深入分析。如果启用了自动 offset 提交策略，上述方法在最后还会调用 `ConsumerCoordinator#maybeAutoCommitOffsetsAsync` 方法尝试提交当前消费完成的 offset 值，我们将在 2.4 小节对自动提交 offset 的过程展开分析。\n\n#### 分区再分配机制\n\n当我们使用 `AUTO_TOPICS` 或 `AUTO_PATTERN` 模式订阅 Kafka topic 时，我们并不需要考虑当前消费者具体消费哪个分区，Kafka 会依据分区分配策略为消费者分配一个或多个分区进行消费（一个分区至多被一个消费者消费，不允许多个消费者同时消费同一个分区）。但是消费者可能会中途加入，也可能会中途退出，topic 的分区数目也是允许改变的，此时就需要依赖分区再分配机制为注册的消费者重新分配分区。\n\n当一个消费者发送心跳信息时，如果在集群的响应中侦测到 `REBALANCE_IN_PROGRESS` 错误码，则该消费者会意识到所属 group 正在执行分区再分配操作，于是会停下手头上的工作加入到这一进程中来。分区再分配操作分为 3 个阶段，并且是一个与集群交互联动的过程，这里我们以客户端视角，当消费者检测到需要重新分配分区时会触发执行：\n\n1. 发送 GroupCoordinatorRequest 请求获取目标可用的 GroupCoordinator 实例所在的 broker 节点，如果没有则选择负载最小的节点并尝试建立连接；\n2. 向 GroupCoordinator 实例所在节点发送 JoinGroupRequest 请求申请加入目标 group。GroupCoordinator 实例会在既定时间范围内等待消费者的申请加入请求，如果提前检测到已经接收到 group 名下所有消费者的申请，或者等待时间超时，则会返回 JoinGroupResponse 响应，主要目的是告知谁是新的 Group Leader 消费者，以及最终确定的分区分配策略；\n3. Group Leader 依据指定的分区分配策略为当前 group 名下的消费者分配分区，并向目标 GroupCoordinator 实例所在节点发送 SyncGroupRequest 请求以告知最终的分区分配结果。\n\n![image](/images/2019/kafka-group-rebalance.png)\n\n上述时序图描绘了分区再分配期间客户端与服务端的交互过程。\n\n触发分区再分配操作的场景主要有以下 3 种：\n\n1. 有消费者加入或离开 group，这里的离开可能是主动离开，也可能是宕机、GC 卡顿，或者是取消了对目标 topic 的订阅等。\n2. 消费者订阅的 topic 的分区数目发生变化。\n3. 消费者 group 对应的 GroupCoordinator 节点发生变更。\n\n在 2.2 小节我们最后简单分析了 `ConsumerCoordinator#poll` 方法，该方法会调用 `ConsumerCoordinator#needRejoin` 检测是否需要执行分区再分配，并在需要的情况下予以执行。ConsumerCoordinator 是消费者执行分区再分配操作和 offset 提交的核心类，该类继承自 AbstractCoordinator 抽象类，首先来看一下这两个类的字段定义：\n\n- __AbstractCoordinator__\n\n```java\npublic abstract class AbstractCoordinator implements Closeable {\n\n    /** 分区再分配操作超时时间 */\n    protected final int rebalanceTimeoutMs;\n    /** 消费者与服务端会话超时时间，超过该时间则认为与服务端断开连接 */\n    private final int sessionTimeoutMs;\n    /** 指定消费者被关闭时是否离开所属 group，如果为 true 的话会触发分区再分配操作 */\n    private final boolean leaveGroupOnClose;\n    /** 心跳机制 */\n    private final Heartbeat heartbeat;\n    /** 执行心跳机制的线程 */\n    private HeartbeatThread heartbeatThread = null;\n    /** 当前消费者所属的 group */\n    protected final String groupId;\n    /** 网络通信客户端 */\n    protected final ConsumerNetworkClient client;\n    /** 时间戳工具 */\n    protected final Time time;\n    /** 重试时间间隔 */\n    protected final long retryBackoffMs;\n    /** 标记是否需要重新发送 {@link JoinGroupRequest} 的请求条件之一 */\n    private boolean rejoinNeeded = true;\n    /** 标记是否需要执行发送 {@link JoinGroupRequest} 请求前的准备工作 */\n    private boolean needsJoinPrepare = true;\n    /** 记录当前消费者的运行状态 */\n    private MemberState state = MemberState.UNJOINED;\n    /** 分区再分配操作请求对应的 future 对象，避免多个请求同时执行 */\n    private RequestFuture<ByteBuffer> joinFuture = null;\n    /** 服务端 GroupCoordinator 所在节点 */\n    private Node coordinator = null;\n    /** 服务端 GroupCoordinator 返回的年代信息，用于区分两次分区再分配操作 */\n    private Generation generation = Generation.NO_GENERATION;\n    /** 获取可用 GroupCoordinator 节点请求对应的 future，避免多个请求同时执行 */\n    private RequestFuture<Void> findCoordinatorFuture = null;\n\n    // ... 省略方法定义\n\n}\n```\n\n- __ConsumerCoordinator__\n\n```java\npublic final class ConsumerCoordinator extends AbstractCoordinator {\n\n    /**\n     * 消费者在发送 JoinGroupRequest 请求时会传递自己支持的分区分配策略，服务端会从所有消费者都支持的策略中选择一种，\n     * 并通知 group leader 使用此分配策略进行分配\n     */\n    private final List<PartitionAssignor> assignors;\n    /** 集群元数据信息 */\n    private final Metadata metadata;\n    /** 记录 topic 分区和 offset 的对应关系 */\n    private final SubscriptionState subscriptions;\n    /** 默认的 offset 提交完成时的 callback */\n    private final OffsetCommitCallback defaultOffsetCommitCallback;\n    /** 是否启用 offset 自动提交策略 */\n    private final boolean autoCommitEnabled;\n    /** offset 自动提交时间间隔 */\n    private final int autoCommitIntervalMs;\n    /** 注册的拦截器集合 */\n    private final ConsumerInterceptors<?, ?> interceptors;\n    /** 是否排除内部 topic，即 offset topic */\n    private final boolean excludeInternalTopics;\n    /** 记录正在等待异步提交 offset 的请求数目 */\n    private final AtomicInteger pendingAsyncCommits;\n    /** 记录每个 offset 提交对应的响应 callback */\n    private final ConcurrentLinkedQueue<OffsetCommitCompletion> completedOffsetCommits;\n    /** 标记当前消费者是不是 group leader */\n    private boolean isLeader = false;\n    /** 当前消费者成功订阅的 topic 集合 */\n    private Set<String> joinedSubscription;\n    /** 元数据快照，用于检测 topic 分区数量是否发生变化 */\n    private MetadataSnapshot metadataSnapshot;\n    /** 元数据快照，用于检测分区分配过程中分区数量是否发生变化 */\n    private MetadataSnapshot assignmentSnapshot;\n    /** 下一次自动提交 offset 的截止时间 */\n    private long nextAutoCommitDeadline;\n\n    // ... 省略方法定义\n\n}\n```\n\n下面我们开始分析分区再分配机制，首先来看一下判定需要执行分区再分配操作的条件，位于 `ConsumerCoordinator#needRejoin` 中，实现如下：\n\n```java\npublic boolean needRejoin() {\n    // USER_ASSIGNED 订阅模式不需要执行分区再分配\n    if (!subscriptions.partitionsAutoAssigned()) {\n        return false;\n    }\n    // 再平衡过程中分区数量发生变化\n    if (assignmentSnapshot != null && !assignmentSnapshot.equals(metadataSnapshot)) {\n        return true;\n    }\n    // 消费者 topic 订阅信息发生变化\n    if (joinedSubscription != null && !joinedSubscription.equals(subscriptions.subscription())) {\n        return true;\n    }\n    // 其它标识需要再平衡的操作，例如分区再分配执行失败、重置年代信息等\n    return super.needRejoin();\n}\n```\n\n如果判定需要执行分区再分配操作，消费者接下去会调用 `AbstractCoordinator#ensureActiveGroup` 方法确认所属 group 对应的目标 GroupCoordinator 实例所在节点是否准备好接收请求，如果对应节点不可用，则会发送 GroupCoordinatorRequest 请求查找负载较小且可用的节点，并与之建立连接。接着会调用 `AbstractCoordinator#joinGroupIfNeeded` 方法开始执行分区再分配策略，实现如下：\n\n```java\nvoid joinGroupIfNeeded() {\n    // 如果需要执行分区再分配，且目前正在进行中\n    while (this.needRejoin() || this.rejoinIncomplete()) {\n        // 再次检查目标 GroupCoordinator 节点是否准备好接收请求\n        this.ensureCoordinatorReady();\n\n        // 执行前期准备工作\n        if (needsJoinPrepare) {\n            /*\n             * 1. 如果开启了 offset 自动提交，则同步提交 offset\n             * 2. 调用注册的 ConsumerRebalanceListener 监听器的 onPartitionsRevoked 方法\n             * 3. 取消当前消费者的 leader 身份（如果是的话），恢复成为一个普通的消费者\n             */\n            this.onJoinPrepare(generation.generationId, generation.memberId);\n            needsJoinPrepare = false;\n        }\n\n        // 创建并发送 JoinGroupRequest 请求，申请加入目标 group\n        RequestFuture<ByteBuffer> future = this.initiateJoinGroup();\n        client.poll(future);\n        // 申请加入 group 完成，将 joinFuture 置为 null，表示允许发送下一次 JoinGroupRequest 请求\n        this.resetJoinGroupFuture();\n\n        // 执行分区分配成功\n        if (future.succeeded()) {\n            needsJoinPrepare = true;\n            this.onJoinComplete(generation.generationId, generation.memberId, generation.protocol, future.value());\n        }\n        // 执行分区分配失败，依据失败类型考虑是否重试\n        else {\n            RuntimeException exception = future.exception();\n            if (exception instanceof UnknownMemberIdException ||\n                    exception instanceof RebalanceInProgressException ||\n                    exception instanceof IllegalGenerationException) {\n                continue;\n            } else if (!future.isRetriable()) {\n                throw exception;\n            }\n            time.sleep(retryBackoffMs);\n        }\n    }\n}\n```\n\n在开始执行分区再分配操作之前需要执行一些前期准备工作，这里使用了 needsJoinPrepare 字段进行控制，如果当前正在执行分区再分配，则 needsJoinPrepare 字段会被标记为 false，以防止重复执行。准备工作的逻辑实现位于 `ConsumerCoordinator#onJoinPrepare` 方法中，主要做了 3 件事情：\n\n1. 如果开启了 offset 自动提交，则同步提交 offset 到集群。\n2. 激活注册的 ConsumerRebalanceListener 监听器的 onPartitionsRevoked 方法。\n3. 取消当前消费者的 Leader 身份（如果是的话），将其恢复成为一个普通的消费者。\n\n分区再分配操作之前需要提交当前消费者消费完成的 offset，因为当分区再分配完成之后，相应的分区可能会被分配给其它消费者，新的消费者需要依赖于前任消费者提交的 offset 来确定接下去消费的起始位置。所以，为了防止消息的遗漏或重复消费，在开始执行分区再分配之前，需要先提交当前消费者已经完成消费的 offset 值。\n\nConsumerRebalanceListener 监听器用于监听分区再分配操作，接口定义如下：\n\n```java\npublic interface ConsumerRebalanceListener {\n    void onPartitionsRevoked(Collection<TopicPartition> partitions);\n    void onPartitionsAssigned(Collection<TopicPartition> partitions);\n}\n```\n\n其中 onPartitionsRevoked 方法会在分区再分配操作之前被触发，也就是我们当前分析的位置，而 onPartitionsAssigned 方法则会在分区再分配操作完成之后被触发，调用的位置位于 `ConsumerCoordinator#onJoinComplete` 方法中，我们后面会对该方法进行分析。\n\n因为接下去要执行分区再分配操作，当操作完成之后会有新的 Group Leader 消费者被选出，如果当前消费者是 Leader 角色，那么此时需要剥夺其 Leader 身份，同时将其 `SubscriptionState#groupSubscription` 字段中记录的所属 group 名下所有消费者订阅的 topic 集合重置为当前消费者自己订阅的 topic 集合。\n\n完成了前期准备工作之后，消费者将正式开始执行分区再分配，这是一个客户端与服务端交互配合的过程，消费者需要构造并发送 JoinGroupResult 请求到对应的 GroupCoordinator 实例所在节点申请加入目标 group。这一过程位于 `AbstractCoordinator#initiateJoinGroup` 方法中，该方法的主要工作就是切换当前消费者的状态为 REBALANCING，创建并缓存 JoinGroupRequest 请求，并处理申请加入的结果。如果申请加入成功，则会切换当前消费者的状态为 STABLE，并重启心跳机制（为了避免心跳机制干扰分区再分配，在开始执行分区再分配之前会临时关闭心跳机制）；如果申请加入失败，则会切换当前消费者的状态为 UNJOINED。\n\nJoinGroupRequest 请求中包含了当前消费者的 ID，消费者所属 group 的 ID、消费者支持的分区策略、协议类型、以及会话超时时间等信息。构造、发送，以及处理 JoinGroupRequest 请求及其响应的过程位于 `AbstractCoordinator#sendJoinGroupRequest` 方法中，实现如下：\n\n```java\nprivate RequestFuture<ByteBuffer> sendJoinGroupRequest() {\n    if (this.coordinatorUnknown()) {\n        // 如果目标 GroupCoordinator 节点不可达，则返回异常\n        return RequestFuture.coordinatorNotAvailable();\n    }\n\n    log.info(\"(Re-)joining group {}\", groupId);\n    // 构建 JoinGroupRequest 请求\n    JoinGroupRequest.Builder requestBuilder = new JoinGroupRequest.Builder(\n            groupId,\n            sessionTimeoutMs,\n            generation.memberId,\n            protocolType(),\n            metadata()).setRebalanceTimeout(rebalanceTimeoutMs);\n\n    log.debug(\"Sending JoinGroup ({}) to coordinator {}\", requestBuilder, this.coordinator);\n    // 发送 JoinGroupRequest 请求，并注册结果处理器 JoinGroupResponseHandler\n    return client.send(coordinator, requestBuilder).compose(new JoinGroupResponseHandler());\n}\n```\n\n消费者通过注册结果处理器 JoinGroupResponseHandler 对请求的响应结果进行处理，如果是正常响应则会执行分区分配操作，核心逻辑实现如下：\n\n```java\nsynchronized (AbstractCoordinator.this) {\n    if (state != MemberState.REBALANCING) {\n        // 在接收到响应之前，消费者的状态发生变更（可能已经从所属 group 离开），抛出异常\n        future.raise(new UnjoinedGroupException());\n    } else {\n        // 基于响应，更新 group 的年代信息\n        generation = new Generation(\n                joinResponse.generationId(), joinResponse.memberId(), joinResponse.groupProtocol());\n        rejoinNeeded = false;\n        // 如果当前消费者是 group 中的 leader 角色\n        if (joinResponse.isLeader()) {\n            /*\n             * 基于分区分配策略执行分区分配，leader 需要关注当前 group 中所有消费者订阅的 topic，\n             * 并发送 SyncGroupRequest 请求反馈分区分配结果给 GroupCoordinator 节点\n             */\n            onJoinLeader(joinResponse)\n                    // 这里调用 chain 方法，是希望当 SyncGroupResponse 处理完成之后，能够将结果传递给 future\n                    .chain(future);\n        } else {\n            // 如果是 follower 消费者，则只关注自己订阅的 topic，这一步仅发送 SyncGroupRequest 请求\n            onJoinFollower().chain(future);\n        }\n    }\n}\n```\n\n在开始重新分配分区之前，消费者会确认当前状态是不是 REBALANCING，前面在发送 JoinGroupRequest 请求之前会将消费者状态变更为 REBALANCING，这里再次确认以防止在请求的过程中消费者的状态发生了变更，例如消费者因某种原理离开了所属的 group，这种情况下不应该再继续执行下去。如果状态未发生变更，那么会依据响应更新本地记录的状态信息（包括年代信息、标识不需要执行分区再分配等），然后依据当前消费者的角色（Leader/Follower）执行相应的逻辑。\n\n对于 Follower 消费者而言，响应 JoinGroupRequest 请求的逻辑只是构造一个包含空的分区分配结果的 SyncGroupRequest 请求，并附带上所属的 group 和自身 ID，以及 group 年代信息，发送给对应的 GroupCoordinator 节点，如果此时所属的 group 已经处于正常运行的状态，则该消费者会拿到分配给自己的分区信息。\n\n如果当前消费者是 Leader 角色，那么需要依据 GroupCoordinator 最终确定的分区分配策略为当前 group 名下所有的消费者分配分区，并发送 SyncGroupRequest 请求向对应的 GroupCoordinator 节点反馈最终的分区分配结果。方法 `AbstractCoordinator#onJoinLeader` 的实现如下：\n\n```java\nprivate RequestFuture<ByteBuffer> onJoinLeader(JoinGroupResponse joinResponse) {\n    try {\n        // 基于分区分配策略分配分区\n        Map<String, ByteBuffer> groupAssignment = this.performAssignment(\n                joinResponse.leaderId(), joinResponse.groupProtocol(), joinResponse.members());\n\n        // 创建 SyncGroupRequest 请求，反馈分区分配结果给 GroupCoordinator 节点\n        SyncGroupRequest.Builder requestBuilder =\n                new SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId, groupAssignment);\n        log.debug(\"Sending leader SyncGroup for group {} to coordinator {}: {}\", groupId, this.coordinator, requestBuilder);\n        // 发送 SyncGroupRequest 请求\n        return this.sendSyncGroupRequest(requestBuilder);\n    } catch (RuntimeException e) {\n        return RequestFuture.failure(e);\n    }\n}\n```\n\n分配分区的具体过程位于 `ConsumerCoordinator#performAssignment` 方法中，这是一个长长的方法实现，但是逻辑并不复杂，实现如下：\n\n```java\nprotected Map<String, ByteBuffer> performAssignment(String leaderId, // leader 消费者 ID\n                                                    String assignmentStrategy, // 服务端最终确定的分区分配策略\n                                                    Map<String, ByteBuffer> allSubscriptions // group 名下所有消费者的 topic 订阅信息\n) {\n    // 从消费者支持的分区分配策略集合中选择指定策略对应的分区分配器\n    PartitionAssignor assignor = this.lookupAssignor(assignmentStrategy);\n    if (assignor == null) {\n        throw new IllegalStateException(\"Coordinator selected invalid assignment protocol: \" + assignmentStrategy);\n    }\n\n    // 解析封装 topic 订阅信息\n    Set<String> allSubscribedTopics = new HashSet<>(); // 记录 group 名下所有消费者订阅的 topic 集合\n    Map<String, Subscription> subscriptions = new HashMap<>(); // Map<String, ByteBuffer> -> Map<String, Subscription>\n    for (Map.Entry<String, ByteBuffer> subscriptionEntry : allSubscriptions.entrySet()) {\n        // ByteBuffer -> Subscription\n        Subscription subscription = ConsumerProtocol.deserializeSubscription(subscriptionEntry.getValue());\n        subscriptions.put(subscriptionEntry.getKey(), subscription);\n        allSubscribedTopics.addAll(subscription.topics());\n    }\n\n    /*\n     * 对于 leader 消费者来说，需要关注 group 名下所有消费者订阅的 topic，\n     * 以保证当相应 topic 对应的元数据发生变化，能够感知\n     */\n    this.subscriptions.groupSubscribe(allSubscribedTopics);\n    metadata.setTopics(this.subscriptions.groupSubscription());\n\n    // 分区再分配之后，检测是否需要更新集群元数据信息，如果需要则立即更新\n    client.ensureFreshMetadata();\n    // 标记当前消费者为 leader 角色\n    isLeader = true;\n\n    log.debug(\"Performing assignment for group {} using strategy {} with subscriptions {}\", groupId, assignor.name(), subscriptions);\n\n    /*\n     * 基于分区分配器（range/round-robin）执行分区分配，\n     * 返回结果：key 是消费者 ID，value 是对应的分区分配结果\n     */\n    Map<String, Assignment> assignment = assignor.assign(metadata.fetch(), subscriptions);\n\n    // 记录所有完成分配的 topic 集合\n    Set<String> assignedTopics = new HashSet<>();\n    for (Assignment assigned : assignment.values()) {\n        for (TopicPartition tp : assigned.partitions())\n            assignedTopics.add(tp.topic());\n    }\n    // 如果 group 中存在一些已经订阅的 topic 并未分配，则日志记录\n    if (!assignedTopics.containsAll(allSubscribedTopics)) {\n        Set<String> notAssignedTopics = new HashSet<>(allSubscribedTopics);\n        notAssignedTopics.removeAll(assignedTopics);\n        log.warn(\"The following subscribed topics are not assigned to any members in the group {} : {} \", groupId, notAssignedTopics);\n    }\n\n    // 如果分配的 topic 集合包含一些未订阅的 topic 集合\n    if (!allSubscribedTopics.containsAll(assignedTopics)) {\n        // 日志记录这些未订阅的 topic\n        Set<String> newlyAddedTopics = new HashSet<>(assignedTopics);\n        newlyAddedTopics.removeAll(allSubscribedTopics);\n        log.info(\"The following not-subscribed topics are assigned to group {}, and their metadata will be fetched from the brokers : {}\", groupId, newlyAddedTopics);\n\n        // 将这些已分配但是未订阅的 topic 添加到 group 集合中\n        allSubscribedTopics.addAll(assignedTopics);\n        this.subscriptions.groupSubscribe(allSubscribedTopics);\n        metadata.setTopics(this.subscriptions.groupSubscription());\n        client.ensureFreshMetadata(); // 更新元数据信息\n    }\n\n    // 更新本地缓存的元数据信息快照\n    assignmentSnapshot = metadataSnapshot;\n\n    log.debug(\"Finished assignment for group {}: {}\", groupId, assignment);\n\n    // 对分区分配结果进行序列化，后续需要反馈给集群\n    Map<String, ByteBuffer> groupAssignment = new HashMap<>();\n    for (Map.Entry<String, Assignment> assignmentEntry : assignment.entrySet()) {\n        ByteBuffer buffer = ConsumerProtocol.serializeAssignment(assignmentEntry.getValue());\n        groupAssignment.put(assignmentEntry.getKey(), buffer);\n    }\n\n    return groupAssignment;\n}\n```\n\n整个分区分配的执行流程可以概括为：\n\n1. 校验服务端确定的最终分区策略，获取对应的分区分配器 PartitionAssignor 对象；\n2. 反序列化解析并封装服务端返回的当前 group 名下所有消费者的 topic 订阅信息；\n3. 更新消费者本地缓存的状态信息，包括 group 名下所有消费者订阅的 topic 集合，Leader 角色自己订阅的 topic 集合等；\n4. 检查是否需要更新本地集群元数据信息，如果需要则立即执行更新；\n5. 依据具体的分区分配策略执行分区分配操作；\n6. 校验分区分配结果，如果 group 已经订阅的一些 topic 并未被分配，则记录到日志；\n7. 校验分配结果，如果分配了一些并未订阅的 topic，则将其加入到 group 集合中，并更新本地集群元数据信息；\n8. 序列化封装并返回分区分配结果，后续需要反馈给集群。\n\nKafka 目前主流的分区分配策略分为 2 种（默认是 range，可以通过 `partition.assignment.strategy` 参数指定）：\n\n- __range__ ：在保证均衡的前提下，将连续的分区分配给消费者，对应的实现是 RangeAssignor。\n- __round-robin__ ：在保证均衡的前提下，轮询分配，对应的实现是 RoundRobinAssignor。\n\n在 0.11.0.0 版本引入了一种新的分区分配策略 StickyAssignor，相对于上面两种分区分配策略的优势在于能够在保证分区均衡的前提下尽量保持原有的分区分配结果，从而避免许多冗余的分区分配操作，减少分区再分配的执行时间。不过据反映 StickyAssignor 目前还存在一些小 bug，所以在你的应用中具体是否采用还需要斟酌。\n\n说到这里我们插点题外话，聊聊分区再分配机制的缺点。我们知道分区再分配机制设计的出发点是好的，也确实解决了实际面临的一些问题，但是缺点在于执行过程效率太低，究其根本可以概括为以下 2 方面的原因：\n\n1. 在执行分区再分配过程中，对应 group 名下的所有消费者都需要暂停手头上的工作加入到分区再分配过程中来，外在的表现就是整个 group 在此期间不消费新的消息，会出现一段时间的消息堆积，有点 Stop The World 的意思。\n2. 基于 RangeAssignor 或 RoundRobinAssignor 分区分配策略会对 group 名下所有消费者的分区分配方案重新洗牌，实际上较好的策略是尽量复用原有的分区分配结果，并在此基础上进行微调，从而最大利用原有的状态信息，避免一些冗余的工作量。\n\n实际中因为订阅的 topic 数目发生变更，或者 topic 分区数目的变化导致触发的分区再分配操作我们无法避免，但是此类情况发生的概率较小，大部分的分区再分配都是由于消费者上下线导致的，而且是被 Kafka 误判为下线。Kafka 基于心跳机制来对具体的一个消费者进行判活，如果对应的参数设置不当会极大增加误判率，所以在这一块的参数配置上需要仔细斟酌。\n\n继续接着分析分区再分配机制的实现，步骤 5 会依据具体的分区分配策略对分区执行分配操作，即执行 `PartitionAssignor#assign` 方法，我们已经知晓了每种分配算法的思想，具体分配细节这里不再深入。\n\n完成了分配分区之后，消费者（不管是 Leader，还是 Follower）会构建 SyncGroupRequest 请求，将分区分配结果信息发送给对应的 GroupCoordinator 实例所在节点，并最终保存在服务端。如果请求异常，则会调用 `AbstractCoordinator#requestRejoin` 方法标记需要再次执行分区再分配操作。\n\n下面继续回到 `AbstractCoordinator#joinGroupIfNeeded` 方法，如果分区分配操作失败，则消费者会依据异常类型决定是否继续重试。如果分区分配成功，则接下来需要对本地记录的相关信息重新初始化，因为分配给当前消费者的分区很可能已经变化，消费者需要知晓上一任消费者对当前分区的消费情况，从而找到合适的 offset 位置继续消费，相关实现位于 `ConsumerCoordinator#onJoinComplete` 方法中：\n\n```java\nprotected void onJoinComplete(int generation, String memberId, String assignmentStrategy, ByteBuffer assignmentBuffer) {\n    // only the leader is responsible for monitoring for metadata changes (i.e. partition changes)\n    if (!isLeader) {\n        assignmentSnapshot = null;\n    }\n\n    // 获取最终确定的分区分配策略对应的分区分配器\n    PartitionAssignor assignor = this.lookupAssignor(assignmentStrategy);\n    if (assignor == null) {\n        throw new IllegalStateException(\"Coordinator selected invalid assignment protocol: \" + assignmentStrategy);\n    }\n\n    // 反序列化获取分区分配信息\n    Assignment assignment = ConsumerProtocol.deserializeAssignment(assignmentBuffer);\n    // 标记需要从 GroupCoordinator 节点获取最近提交的 offset 值\n    subscriptions.needRefreshCommits();\n    // 设置每个 topic 分区对应的消费状态\n    subscriptions.assignFromSubscribed(assignment.partitions());\n\n    // 遍历获取新分配的 topic，并更新本地记录的订阅信息\n    Set<String> addedTopics = new HashSet<>();\n    for (TopicPartition tp : subscriptions.assignedPartitions()) {\n        if (!joinedSubscription.contains(tp.topic())) {\n            addedTopics.add(tp.topic()); // 新分配的分区\n        }\n    }\n    if (!addedTopics.isEmpty()) {\n        Set<String> newSubscription = new HashSet<>(subscriptions.subscription());\n        Set<String> newJoinedSubscription = new HashSet<>(joinedSubscription);\n        newSubscription.addAll(addedTopics);\n        newJoinedSubscription.addAll(addedTopics);\n\n        // 使用 AUTO_PATTERN 模式进行订阅\n        subscriptions.subscribeFromPattern(newSubscription);\n        joinedSubscription = newJoinedSubscription;\n    }\n\n    // 更新本地缓存的集群元数据信息\n    metadata.setTopics(subscriptions.groupSubscription());\n    client.ensureFreshMetadata();\n\n    // give the assignor a chance to update internal state based on the received assignment\n    assignor.onAssignment(assignment);\n\n    // 重置下次自动提交 offset 的截止时间\n    nextAutoCommitDeadline = time.milliseconds() + autoCommitIntervalMs;\n\n    // 应用监听分区再分配操作完成的监听器\n    ConsumerRebalanceListener listener = subscriptions.listener();\n    log.info(\"Setting newly assigned partitions {} for group {}\", subscriptions.assignedPartitions(), groupId);\n    try {\n        Set<TopicPartition> assigned = new HashSet<>(subscriptions.assignedPartitions());\n        listener.onPartitionsAssigned(assigned);\n    } catch (WakeupException | InterruptException e) {\n        throw e;\n    } catch (Exception e) {\n        log.error(\"User provided listener {} for group {} failed on partition assignment\", listener.getClass().getName(), groupId, e);\n    }\n}\n```\n\n上述方法主要做了以下 4 件事情：\n\n1. 标记需要重新从集群获取最近一次提交的 offset 值。\n2. 重置本地记录的每个分区的消费状态，并更新本地记录的 topic 订阅信息。\n3. 条件性更新本地记录的集群元数据信息。\n4. 激活 ConsumerRebalanceListener 监听器的 onPartitionsAssigned 方法。\n\n前面我们介绍了 ConsumerRebalanceListener 接口的定义，在分区再分配操作执行之前会调用 `ConsumerRebalanceListener#onPartitionsRevoked` 方法，而另外一个方法 `ConsumerRebalanceListener#onPartitionsAssigned` 的调用时机则是位于这里。\n\n#### 分区消费 offset 提交策略\n\n提交已经消费完成的消息对应的 offset 是保证消息不重复消费和遗漏消费的最重要的措施。这里提交的 offset 是下一条待消费消息的 offset，而非当前已经消费的最后一条消息的 offset。Kafka 默认会按照指定时间间隔自动提交消费者消费完成的 offset 值，同时也允许开发者手动控制 offset 的提交时机。提交操作分为同步（阻塞）和异步（非阻塞）两种，Kafka 为手动提交分别提供了对应 `KafkaConsumer#commitSync` 和 `KafkaConsumer#commitAsync` 方法实现，这些方法都存在多个重载版本，相应的实现均位于 ConsumerCoordinator 类中。\n\nConsumerCoordinator 类提供了多个提交 offset 的方法，区分同步和异步，这些方法之间的调用关系如下所示：\n\n- 同步 offset 提交\n\n```text\n+ maybeAutoCommitOffsetsSync\n| ---- + commitOffsetsSync\n```\n\n- 异步 offset 提交\n\n```text\n+ maybeAutoCommitOffsetsNow / maybeAutoCommitOffsetsAsync\n| ---- + doAutoCommitOffsetsAsync\n| ---- | ---- + commitOffsetsAsync\n| ---- | ---- | ---- + doCommitOffsetsAsync\n```\n\n整个方法调用链路按照同步和异步提交方式分为两条独立的路线，自动提交和手动提交在底层实现上其实是复用的，下面的篇幅中我们分别分析同步提交和异步提交的具体实现细节。\n\n##### 同步 offset 提交策略\n\n我们从 `ConsumerCoordinator#maybeAutoCommitOffsetsSync` 方法切入，该方法的调用时机有两个地方：\n\n1. 执行分区再分配操作的准备阶段（`ConsumerCoordinator#onJoinPrepare` 方法）。\n2. 关闭消费者的时候（`ConsumerCoordinator#close` 方法，`KafkaConsumer#close` 方法在执行时会调用该方法）。\n\n前面曾提到过，当分区再分配操作完成之后，分区与消费者之间的订阅关系可能会发生变化，而 Kafka 又依赖于消费者自己去记录分区的消费状态，所以在执行分区再分配操作之前需要让每个消费者将自己维护的分区消费状态信息上报给集群，这样在完成分区重新分配之后，消费者可以通过请求就集群以知晓新分配的分区的消费 offset 位置，消费者关闭的过程本质上也是如此。这些场景下提交 offset 的过程必须是同步的，否则存在丢失消费状态的可能，最终将导致消息被重复消费。\n\n方法 `ConsumerCoordinator#maybeAutoCommitOffsetsSync` 的实现如下：\n\n```java\nprivate void maybeAutoCommitOffsetsSync(long timeoutMs) {\n    if (autoCommitEnabled) {\n        // 获取当前消费者订阅的所有 topic 分区，以及分区对应的消费状态信息\n        Map<TopicPartition, OffsetAndMetadata> allConsumedOffsets = subscriptions.allConsumed();\n        try {\n            log.debug(\"Sending synchronous auto-commit of offsets {} for group {}\", allConsumedOffsets, groupId);\n            // 执行同步 offset 提交\n            if (!this.commitOffsetsSync(allConsumedOffsets, timeoutMs)) {\n                log.debug(\"Auto-commit of offsets {} for group {} timed out before completion\", allConsumedOffsets, groupId);\n            }\n        }\n        // ... 省略异常处理\n    }\n}\n```\n\n如果允许自动提交 offset，则上述方法首先会从本地获取当前消费者被分配的分区的消费状态，然后调用 `ConsumerCoordinator#commitOffsetsSync` 方法向集群提交 offset 值，方法 `KafkaConsumer#commitSync` 本质上也是调用了该方法实现对 offset 的提交操作。方法 `ConsumerCoordinator#commitOffsetsSync` 的实现如下：\n\n```java\npublic boolean commitOffsetsSync(Map<TopicPartition, OffsetAndMetadata> offsets, long timeoutMs) {\n    // 触发注册的监听 offset 提交完成的方法\n    this.invokeCompletedOffsetCommitCallbacks();\n    // 如果提交的 offset 数据为空，则直接返回\n    if (offsets.isEmpty()) {\n        return true;\n    }\n\n    long now = time.milliseconds();\n    long startMs = now;\n    long remainingMs = timeoutMs;\n    do {\n        // 如果目标 GroupCoordinator 节点不可用\n        if (this.coordinatorUnknown()) {\n            // 尝试寻找负载最小且可用的 GroupCoordinator 节点\n            if (!this.ensureCoordinatorReady(now, remainingMs)) {\n                // 如果目标 GroupCoordinator 节点未准备好接收请求\n                return false;\n            }\n            remainingMs = timeoutMs - (time.milliseconds() - startMs);\n        }\n\n        // 创建并发送 OffsetCommitRequest 请求，提交 offset 值\n        RequestFuture<Void> future = this.sendOffsetCommitRequest(offsets);\n        client.poll(future, remainingMs);\n\n        // 提交成功\n        if (future.succeeded()) {\n            if (interceptors != null) {\n                interceptors.onCommit(offsets);\n            }\n            return true;\n        }\n        // 提交失败，且不可重试，则抛出异常\n        if (!future.isRetriable()) {\n            throw future.exception();\n        }\n\n        time.sleep(retryBackoffMs);\n\n        now = time.milliseconds();\n        remainingMs = timeoutMs - (now - startMs);\n    } while (remainingMs > 0);\n\n    return false;\n}\n```\n\n同步 offset 提交的执行流程可以概括为：\n\n1. 触发注册的监听 offset 提交完成的回调方法；\n2. 校验待提交的 offset 数据是否为空，如果为空则直接返回；\n3. 校验目标 GroupCoordinator 实例所在节点是否可用，如果不可用则尝试寻找负载最小且可用的节点；\n4. 创建并发送提交 offset 的 OffsetCommitRequest 请求；\n5. 处理请求的响应结果。\n\n所有的监听 offset 提交操作的 OffsetCommitCallback 都会被封装成 OffsetCommitCompletion 对象，记录到 `ConsumerCoordinator#completedOffsetCommits` 字段中，并在每次提交 offset 时触发调用。下面来看一下创建并发送 OffsetCommitRequest 请求的逻辑，实现位于 `ConsumerCoordinator#sendOffsetCommitRequest` 方法中：\n\n```java\nprivate RequestFuture<Void> sendOffsetCommitRequest(final Map<TopicPartition, OffsetAndMetadata> offsets) {\n    if (offsets.isEmpty()) {\n        // 如果没有请求的数据，则直接返回\n        return RequestFuture.voidSuccess();\n    }\n\n    // 获取 GroupCoordinator 节点，并检查其可达性\n    Node coordinator = this.coordinator();\n    if (coordinator == null) {\n        return RequestFuture.coordinatorNotAvailable();\n    }\n\n    // 封装每个分区对应提交的 offset 数据\n    Map<TopicPartition, OffsetCommitRequest.PartitionData> offsetData = new HashMap<>(offsets.size());\n    for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {\n        OffsetAndMetadata offsetAndMetadata = entry.getValue();\n        if (offsetAndMetadata.offset() < 0) {\n            // 非法的 offset 值\n            return RequestFuture.failure(new IllegalArgumentException(\"Invalid offset: \" + offsetAndMetadata.offset()));\n        }\n        // key 是分区，value 是分区对应的请求数据\n        offsetData.put(entry.getKey(),\n                new OffsetCommitRequest.PartitionData(offsetAndMetadata.offset(), offsetAndMetadata.metadata()));\n    }\n\n    // 获取当前消费者所属 group 的年代信息\n    final Generation generation;\n    if (subscriptions.partitionsAutoAssigned()) {\n        // 如果是 AUTO_TOPICS 或 AUTO_PATTERN 订阅模式，则获取年代信息\n        generation = this.generation();\n    } else {\n        // 对于 USER_ASSIGNED 模式，因为不涉及到分区再分配操作，所以没有年代信息\n        generation = Generation.NO_GENERATION;\n    }\n    if (generation == null) {\n        // 如果获取 group 年代信息失败，则说明当前消费者并不属于该 group，抛出异常，需要执行分区再分配\n        return RequestFuture.failure(new CommitFailedException());\n    }\n\n    // 创建 OffsetCommitRequest 请求\n    OffsetCommitRequest.Builder builder =\n            new OffsetCommitRequest.Builder(groupId, offsetData)\n                    .setGenerationId(generation.generationId)\n                    .setMemberId(generation.memberId)\n                    .setRetentionTime(OffsetCommitRequest.DEFAULT_RETENTION_TIME);\n\n    log.trace(\"Sending OffsetCommit request with {} to coordinator {} for group {}\", offsets, coordinator, groupId);\n\n    // 发送 OffsetCommitRequest 请求，并注册响应处理器\n    return client.send(coordinator, builder).compose(new OffsetCommitResponseHandler(offsets));\n}\n```\n\n上述方法的执行流程如下：\n\n1. 校验待发送的请求数据是否为空，如果为空则直接返回成功；\n2. 获取目标 GroupCoordinator 实例所在 broker 节点，并校验其可用性；\n3. 封装每个目标分区的待提交 offset 数据；\n4. 获取并校验当前 group 的年代信息，防止提交一些已经离开 group 的消费者的 offset 数据；\n5. 创建并缓存 OffsetCommitRequest 请求，同时注册响应结果处理器。\n\n整体流程都比较简单和直观，集群 GroupCoordinator 实例在收到 OffsetCommitRequest 请求之后，会依据请求指定的版本号决定将 offset 消费信息记录到 ZK 还是最新实现的 offset topic，我们将在后面分析 GroupCoordinator 组件的篇章中针对 OffsetCommitRequest 请求的处理过程进行深入分析。下面来看一下对于响应结果的处理过程，实现位于 `OffsetCommitResponseHandler#handle` 方法中：\n\n```java\npublic void handle(OffsetCommitResponse commitResponse, RequestFuture<Void> future) {\n    sensors.commitLatency.record(response.requestLatencyMs());\n    Set<String> unauthorizedTopics = new HashSet<>();\n\n    // 遍历对所有 topic 分区的响应\n    for (Map.Entry<TopicPartition, Short> entry : commitResponse.responseData().entrySet()) {\n        TopicPartition tp = entry.getKey();\n        OffsetAndMetadata offsetAndMetadata = offsets.get(tp);\n        long offset = offsetAndMetadata.offset();\n\n        // 获取当前分区对应的响应错误码\n        Errors error = Errors.forCode(entry.getValue());\n        // 正常响应\n        if (error == Errors.NONE) {\n            log.debug(\"Group {} committed offset {} for partition {}\", groupId, offset, tp);\n            if (subscriptions.isAssigned(tp)) {\n                // 更新分区对应的消费状态\n                subscriptions.committed(tp, offsetAndMetadata);\n            }\n        }\n        //  ... 省略异常响应处理的过程\n    }\n\n    if (!unauthorizedTopics.isEmpty()) {\n        log.error(\"Not authorized to commit to topics {} for group {}\", unauthorizedTopics, groupId);\n        future.raise(new TopicAuthorizationException(unauthorizedTopics));\n    } else {\n        future.complete(null);\n    }\n}\n```\n\n这里主要看一下对于正常响应的处理过程，一个消费者可能同时消费多个 topic 分区，前面我们已经说过对于每个 topic 分区的消费状态都是独立维护和提交的，所以对于响应的处理也需要针对每个 topic 分区进行单独处理。如果是正常响应，方法首先会确认对应 topic 分区是否分配给当前消费者，如果是的话则会更新对应的分区消费状态的 `TopicPartitionState#committed` 字段，本质上也就是将 `TopicPartitionState#position` 字段记录的消费 offset 值封装成 OffsetAndMetadata 对象进行赋值。\n\n##### 异步 offset 提交策略\n\n下面继续看一下异步 offset 提交的过程，我们从 `ConsumerCoordinator#maybeAutoCommitOffsetsAsync` 方法切入。前面我们在分析 `ConsumerCoordinator#poll` 方法时曾提到了对于该方法的调用，方法的实现比较简单（如下），即判断是否启用了自动提交，如果启用了的话则首先判断对应的 GroupCoordinator 实例所在节点是否可用，如果不可用则修改下一次自动提交的时间戳，延迟到下一次执行，如果目标 GroupCoordinator 节点是可用的，同时自动提交的时间已到，则执行异步提交操作。\n\n```java\nprivate void maybeAutoCommitOffsetsAsync(long now) {\n    if (autoCommitEnabled) {\n        if (this.coordinatorUnknown()) {\n            // 目标 GroupCoordinator 节点不可达，稍后再试\n            this.nextAutoCommitDeadline = now + retryBackoffMs;\n        } else if (now >= nextAutoCommitDeadline) {\n            // 时间已到，执行异步自动提交\n            this.nextAutoCommitDeadline = now + autoCommitIntervalMs;\n            this.doAutoCommitOffsetsAsync();\n        }\n    }\n}\n```\n\n其中，方法 `ConsumerCoordinator#doAutoCommitOffsetsAsync` 除了在这里被调用之外，也会在 `ConsumerCoordinator#maybeAutoCommitOffsetsNow` 方法中被调用，用于立即发起一次异步提交 offset 请求，实现比较简单。方法 `ConsumerCoordinator#doAutoCommitOffsetsAsync` 的实现也比较简单，核心逻辑就是获取当前消费者消费的所有 topic 分区对应的消费状态信息，然后调用 `ConsumerCoordinator#commitOffsetsAsync` 方法执行异步提交操作。该方法首先会触发注册的监听 offset 提交完成的监听器，然后判断目标 GroupCoordinator 实例所在节点是否可用。如果可用则继续执行异步提交操作，如果不可用则会尝试寻找可用且负载最小的节点，并在找到的前提下继续执行异步提交，否则返回异常。\n\n执行异步提交的核心实现位于 `ConsumerCoordinator#doCommitOffsetsAsync` 方法中：\n\n```java\nprivate void doCommitOffsetsAsync(final Map<TopicPartition, OffsetAndMetadata> offsets, final OffsetCommitCallback callback) {\n    // 标记需要从 GroupCoordinator 节点获取最近提交的 offset 值\n    subscriptions.needRefreshCommits();\n    // 创建并发送 OffsetCommitRequest 请求\n    RequestFuture<Void> future = this.sendOffsetCommitRequest(offsets);\n    // 封装 callback，用于监听 offset 提交结果\n    final OffsetCommitCallback cb = callback == null ? defaultOffsetCommitCallback : callback;\n    future.addListener(new RequestFutureListener<Void>() {\n        @Override\n        public void onSuccess(Void value) {\n            if (interceptors != null) {\n                interceptors.onCommit(offsets);\n            }\n            completedOffsetCommits.add(new OffsetCommitCompletion(cb, offsets, null));\n        }\n\n        @Override\n        public void onFailure(RuntimeException e) {\n            Exception commitException = e;\n            if (e instanceof RetriableException) {\n                commitException = new RetriableCommitFailedException(e);\n            }\n            completedOffsetCommits.add(new OffsetCommitCompletion(cb, offsets, commitException));\n        }\n    });\n}\n```\n\n执行提交 OffsetCommitRequest 请求之前，方法首先会标记需要从 GroupCoordinator 实例所在节点获取最近提交的 offset 值，这里的标记主要用于通知那些本地未有效记录分区消费状态的消费者。然后构造并缓存 OffsetCommitRequest 请求对象，等待下次 poll 操作时一并发送，方法 `ConsumerCoordinator#sendOffsetCommitRequest` 的执行逻辑在前面已经分析过。\n\n异步发送和同步发送主要的区别在于是否立即调用 `ConsumerNetworkClient#poll` 方法阻塞发送请求，并处理响应结果。前面在介绍同步提交（`ConsumerCoordinator#commitOffsetsSync` 方法）时可以看到在构建完 OffsetCommitRequest 请求之后会立即执行 poll 方法，而在异步提交时，构建完 OffsetCommitRequest 请求之后并不会立即发送请求，而是会等到下一次执行 poll 方法时一并发送，并通过回调的方式处理响应结果。\n\n### 总结\n\n本文我们介绍了 java 版本的 KafkaConsumer 的使用，并深入分析了相关设计和实现，了解一个 group 名下的所有消费者区分 Leader 和 Follower 角色，其中 Leader 角色除了肩负普通消费者的职责外，还需要负责管理整个 group 的运行状态。此外，消费者在拉取消息时的预取策略虽然在设计上很简单，却很好的利用了消息拉取和消费这两者之间能够并行执行的特点，极大提升了消费者的运行性能。而分区再分配机制则为 Kafka 提供了良好的扩展性，保证在 topic 分区数据发生变化，以及消费者上下线时能够不停服，继续正常对外提供服务。\n\n到此为止，关于 Kafka SDK 的相关实现已经基本介绍完了，从下一篇开始我们将转战服务端，分析 Kafka 集群各个组件的设计与实现。\n","tags":["Kafka"],"categories":["kafka"]},{"title":"Kafka 源码解析：生产者运行机制","url":"/2019/06/18/kafka/kafka-producer/","content":"\nKafka 生产者 KafkaProducer 是 Kafka 与开发者交互的媒介之一，肩负接收用户自定义消息（这里的消息指代往 Kafka 发送的各类数据），并投递给目标 topic 分区的职责。在设计上为了提升消息吞吐量，考量降低与服务端交互的压力等，每次发送消息的请求并非是直接与 Kafka 集群进行交互，而是一个异步的过程。\n\n当调用 `KafkaProducer#send` 方法发送消息时，实际上只是将消息缓存到了本地的消息收集器中，Kafka 定义了一个 RecordAccumulator 收集器用于收集用户提交的消息数据，同时又在后台维护了一个 Sender 线程，以异步的方式不断将收集器中缓存的消息定期定量地投递给 Kafka 集群。<!-- more -->\n\n在本篇文章中，我们首先回忆一下 KafkaProducer 的使用方式，然后重点分析消息的收集、缓存、投递，以及响应的过程。\n\n### KafkaProducer 使用示例\n\nKafkaProducer 往 Kafka 发送消息需要依赖于客户端 SDK，Kafka 提供了 [多种语言的客户端](https://cwiki.apache.org/confluence/display/KAFKA/Clients) 供开发者选择，这里我们以 Kafka 内置的 java 客户端为例，介绍如何向 Kafka 集群发送消息。示例：\n\n```java\nProperties properties = new Properties();\nproperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nproperties.put(ProducerConfig.CLIENT_ID_CONFIG, \"producer-demo\");\nproperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class.getName());\nproperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\nKafkaProducer<Integer, String> producer = new KafkaProducer<>(properties);\n\nboolean isAsync = true;\n\nfor (int i = 0; i < 10; i++) {\n    if (isAsync) {\n        // 异步发送消息\n        producer.send(new ProducerRecord<>(DEFAULT_TOPIC, i, \"zhenchao\"), (metadata, e) -> {\n            if (null != e) {\n                // ... 处理错误\n                return;\n            }\n            printResult(metadata); // 打印结果信息\n        });\n    } else {\n        // 同步发送消息，指定 topic 和消息内容\n        Future<RecordMetadata> future = producer.send(new ProducerRecord<>(DEFAULT_TOPIC, i, \"zhenchao\"));\n        RecordMetadata metadata = future.get(10, TimeUnit.SECONDS);\n        this.printResult(metadata); // 打印结果信息\n\n    }\n}\n```\n\n示例中发送消息依赖于 KafkaProducer 对象，KafkaProducer 类也是我们分析生产者运行机制的入口。创建该对象时我们需要指定 Kafka 集群地址，以及消息 key 和 value 的序列化器，但是客户端 ID 不是必须指定的，后面在分析源码时会看到如果未明确指定客户端 ID，Kafka 会自动为当前客户端创建一个。\n\n接着我们可以调用 `KafkaProducer#send` 方法向 Kafka 集群指定的 topic 投递消息。消息在被投递之前需要封装成 ProducerRecord 对象，该对象封装了当前消息的目标 topic、目标分区，key、value，以及时间戳等信息。ProducerRecord 的字段定义如下，其中 `ProducerRecord#headers` 字段在 0.11 版本引入：\n\n```java\npublic class ProducerRecord<K, V> {\n\n    /** 主题 */\n    private final String topic;\n    /** 分区 */\n    private final Integer partition;\n    /** 消息头 */\n    private final Headers headers;\n    /** 消息对应的 key */\n    private final K key;\n    /** 消息内容 */\n    private final V value;\n    /** 时间戳 */\n    private final Long timestamp;\n\n    // ... 省略方法定义\n\n}\n```\n\n示例中我们定义了 isAsync 参数，需要说明的一点是，isAsync 参数虽然表面意思是指以异步的方式发送消息，但是本质上不管该参数如何设置，Kafka 当下的版本都只有一种消息发送的方式，即异步发送。参数 isAsync 设置为 true 或者 false 的意义在于指定如何获取消息发送的响应结果，区别在于：\n\n- `isAsync=false`：以异步方式发送消息，但是通过 Future 模式阻塞等待消息的发送的响应结果。\n- `isAsync=true`：以异步方式发送消息，但是通过 Callback 模式异步获取消息发送的响应结果，即不管消息发送成功还是失败，都会以回调的方式通知客户端，客户端期间不需要阻塞等待。\n\n### 消息收集与发送过程分析\n\n在具体开始分析消息的发送过程之前，我们需要明确 __消息发送是一个异步的过程__ ，该过程涉及到 2 个线程的协同工作，其中 1 个线程将待发送的消息写入缓冲区（即收集待发送消息），另外 1 个线程（Sender 线程）负责定期定量将缓冲区中的数据投递给 Kafka 集群，并反馈投递结果。\n\n![image](/images/2019/kafka-producer.png)\n\n如上图描绘了生产者运行的基本结构。我们将业务线程称为主线程，业务在调用 `KafkaProducer#send` 方法向 Kafka 投递消息时，对应的消息会经过拦截器、序列化器，以及分区器等一系列处理，最终被缓存到消息收集器 RecordAccumulator 中。消息收集器为每个 topic 分区设置了一个双端队列用于记录待发往目标 topic 分区的消息集合。Sender 线程异步循环轮询消费消息收集器中的各个队列，将消息按照目标 broker 节点（即分区 Leader 副本所在的 broker 节点）进行分组，并封装成 RPC 请求发往目标节点。\n\n这里我们只是简单概括了 KafkaProducer 的基本运行机制，下面将对各个环节展开进行深入分析。\n\n#### 收集待发送的消息\n\n##### KafkaProducer 的字段定义与构造方法\n\n首先来看一下 KafkaProducer 类的字段定义，如下：\n\n```java\npublic class KafkaProducer<K, V> implements Producer<K, V> {\n\n    /** clientId 生成器，如果没有明确指定客户端 ID，则使用该字段顺序生成一个 */\n    private static final AtomicInteger PRODUCER_CLIENT_ID_SEQUENCE = new AtomicInteger(1);\n    /** 生产者唯一标识（对应 client.id 属性配置 ） */\n    private String clientId;\n    /** 分区选择器（对应 partitioner.class 属性配置），如果未明确指定分区，则基于一定的策略为消息选择合适的分区 */\n    private final Partitioner partitioner;\n    /** 消息的最大长度（对应 max.request.size 配置，包含消息头、序列化之后的 key 和 value） */\n    private final int maxRequestSize;\n    /** 发送单条消息的缓冲区大小（对应 buffer.memory 配置） */\n    private final long totalMemorySize;\n    /** kafka 集群元数据 */\n    private final Metadata metadata;\n    /** 消息收集器，用于收集并缓存消息，等待 Sender 线程的发送 */\n    private final RecordAccumulator accumulator;\n    /** 消息发送线程对象 */\n    private final Sender sender;\n    /** 消息发送线程 */\n    private final Thread ioThread;\n    /** 压缩算法（对应 compression.type 配置） */\n    private final CompressionType compressionType;\n    /** 时间戳工具 */\n    private final Time time;\n    /** key 序列化器（对应 key.serializer 配置） */\n    private final Serializer<K> keySerializer;\n    /** value 序列化器（对应 value.serializer 配置） */\n    private final Serializer<V> valueSerializer;\n    /** 封装配置信息 */\n    private final ProducerConfig producerConfig;\n    /** 等待更新 kafka 集群元数据的最大时长 */\n    private final long maxBlockTimeMs;\n    /** 消息发送的超时时间（从发送到收到 ACK 响应） */\n    private final int requestTimeoutMs;\n    /** 发送拦截器（对应 interceptor.classes 配置），用于待发送的消息进行拦截并修改，也可以对 ACK 响应进行拦截处理 */\n    private final ProducerInterceptors<K, V> interceptors;\n\n    // ... 省略方法定义\n\n}\n```\n\n接下来继续看一下 KafkaProducer 类对象的构造过程，KafkaProducer 提供了多个重载版本的构造方法实现，其中最底层的构造方法实现如下：\n\n```java\nprivate KafkaProducer(ProducerConfig config, Serializer<K> keySerializer, Serializer<V> valueSerializer) {\n    try {\n        log.trace(\"Starting the Kafka producer\");\n        // 获取用户配置信息\n        Map<String, Object> userProvidedConfigs = config.originals();\n        this.producerConfig = config;\n        this.time = Time.SYSTEM;\n\n        // 尝试获取用户配置的 clientId，如果未配置则基于 PRODUCER_CLIENT_ID_SEQUENCE 顺序生成一个\n        this.clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG);\n        if (clientId.length() <= 0) {\n            // 用户未指定 clientId，基于 PRODUCER_CLIENT_ID_SEQUENCE 顺序生成一个\n            clientId = \"producer-\" + PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement();\n        }\n\n        // ... 省略打点相关注册逻辑\n\n        // 获取配置的分区器对象（反射创建）\n        this.partitioner = config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG, Partitioner.class);\n        // 获取生产者重试间隔\n        long retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);\n\n        // 如果参数未指定 key 序列化器，则尝试从配置中获取 key 序列化器对象（反射创建）\n        if (keySerializer == null) {\n            this.keySerializer = config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, Serializer.class);\n            this.keySerializer.configure(config.originals(), true);\n        } else {\n            config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n            this.keySerializer = keySerializer;\n        }\n\n        // 如果参数未指定 value 序列化器，则尝试从配置中获取 value 序列化器对象（反射创建）\n        if (valueSerializer == null) {\n            this.valueSerializer = config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, Serializer.class);\n            this.valueSerializer.configure(config.originals(), false);\n        } else {\n            config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n            this.valueSerializer = valueSerializer;\n        }\n\n        // load interceptors and make sure they get clientId\n        userProvidedConfigs.put(ProducerConfig.CLIENT_ID_CONFIG, clientId);\n\n        // 获取注册的拦截器列表\n        List<ProducerInterceptor<K, V>> interceptorList = (List) (new ProducerConfig(userProvidedConfigs, false))\n                .getConfiguredInstances(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ProducerInterceptor.class);\n        this.interceptors = interceptorList.isEmpty() ? null : new ProducerInterceptors<>(interceptorList);\n\n        ClusterResourceListeners clusterResourceListeners =\n                this.configureClusterResourceListeners(keySerializer, valueSerializer, interceptorList, reporters);\n\n        // 创建并更新 kafka 集群的元数据信息\n        this.metadata = new Metadata(retryBackoffMs, config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG), true, clusterResourceListeners);\n        // 获取并设置生产者发送请求的大小\n        this.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG);\n        // 获取并设置生产者内存缓冲区大小，用于缓存要发送到服务器的消息\n        this.totalMemorySize = config.getLong(ProducerConfig.BUFFER_MEMORY_CONFIG);\n        // 获取并设置消息压缩算法，可以设置为 snappy、gzip 或 lz4，默认不压缩。\n        this.compressionType = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG));\n\n        // ... 基于用户配置设置 maxBlockTimeMs 和 requestTimeoutMs，省略\n\n        // 创建消息收集器，用于异步发送消息\n        this.accumulator = new RecordAccumulator(\n                config.getInt(ProducerConfig.BATCH_SIZE_CONFIG), // 指定每个批次的大小（单位：字节）\n                this.totalMemorySize,\n                this.compressionType,\n                config.getLong(ProducerConfig.LINGER_MS_CONFIG), // 消息缓存超时发送时间\n                retryBackoffMs,\n                metrics,\n                time);\n\n        // 获取 kafka 集群主机列表\n        List<InetSocketAddress> addresses = ClientUtils.parseAndValidateAddresses(config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG));\n        // 更新 kafka 集群元数据信息\n        this.metadata.update(Cluster.bootstrap(addresses), Collections.<String>emptySet(), time.milliseconds());\n        ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(config.values());\n        // 创建 NetworkClient 对象，NetworkClient 是 producer 网络 I/O 的核心\n        NetworkClient client = new NetworkClient(\n                new Selector(config.getLong(ProducerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG), metrics, time, \"producer\", channelBuilder),\n                metadata,\n                clientId,\n                config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION),\n                config.getLong(ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG),\n                config.getInt(ProducerConfig.SEND_BUFFER_CONFIG),\n                config.getInt(ProducerConfig.RECEIVE_BUFFER_CONFIG),\n                requestTimeoutMs,\n                time,\n                true);\n\n        // 创建并启动 Sender 线程\n        this.sender = new Sender(\n                client,\n                metadata,\n                accumulator,\n                config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION) == 1,\n                config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG),\n                (short) parseAcks(config.getString(ProducerConfig.ACKS_CONFIG)),\n                config.getInt(ProducerConfig.RETRIES_CONFIG),\n                metrics,\n                Time.SYSTEM,\n                requestTimeoutMs);\n        String ioThreadName = \"kafka-producer-network-thread\" + (clientId.length() > 0 ? \" | \" + clientId : \"\");\n        this.ioThread = new KafkaThread(ioThreadName, this.sender, true);\n        this.ioThread.start();\n\n        // 打印未使用的配置\n        config.logUnused();\n        AppInfoParser.registerAppInfo(JMX_PREFIX, clientId);\n        log.debug(\"Kafka producer started\");\n    } catch (Throwable t) {\n        // ... 省略异常处理\n    }\n}\n```\n\n具体实现如上述代码注释，一条消息的发送需要经过拦截器、序列化器、分区器，最后缓存到消息收集器中，并由 Sender 线程在后台异步往 Kafka 集群投递消息，所以在构造 KafkaProducer 对象时主要就是初始化这些组件。\n\n##### 消息收集的过程\n\n了解了 KafkaProducer 的字段定义和对象的构造过程之后，下面正式开始对消息收集的过程进行分析，相关实现位于 `KafkaProducer#send` 方法中：\n\n```java\npublic Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback) {\n    // 遍历注册的拦截器对待发送的消息执行拦截修改\n    ProducerRecord<K, V> interceptedRecord = this.interceptors == null ? record : this.interceptors.onSend(record);\n    // 调用 doSend 方法开始发送消息\n    return this.doSend(interceptedRecord, callback);\n}\n```\n\n该方法只是简单应用了注册的 Producer 拦截器对发送的消息进行拦截修改，而具体消息收集的过程则封装在 `KafkaProducer#doSend` 方法中。先来看一下 Producer 拦截器，我们可以基于该拦截器机制实现对消息的剔除、修改，以及在响应回调之前增加一些定制化的需求等。拦截器 ProducerInterceptor 接口的定义如下：\n\n```java\npublic interface ProducerInterceptor<K, V> extends Configurable {\n    ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);\n    void onAcknowledgement(RecordMetadata metadata, Exception exception);\n    void close();\n}\n```\n\n其中，方法 `ProducerInterceptor#onSend` 用于对待发送的消息进行前置拦截，具体的拦截时机是在消息被序列化和分配分区（如果未手动指定分区）之前，如上述 `KafkaProducer#send` 方法所示。方法 `ProducerInterceptor#onAcknowledgement` 用于对已发送到 Kafka 集群并得到确认的消息，以及发送失败的消息进行后置拦截，具体的拦截时机是在回调用户自定义的 Callback 逻辑之前。需要注意的一点是，方法 `ProducerInterceptor#onAcknowledgement` 在 Producer 的 I/O 线程中被调用，所以不建议在其中实现一些比较耗时的逻辑，以便影响整体消息发送的性能。\n\n下面继续来看一下收集消息的过程，实现位于 `KafkaProducer#doSend` 方法中：\n\n```java\nprivate Future<RecordMetadata> doSend(ProducerRecord<K, V> record, Callback callback) {\n    TopicPartition tp = null;\n    try {\n        // 1. 获取 kafka 集群元数据信息，如果当前请求的是新 topic，或者指定的分区超过已知的分区范围，则会触发更新集群元数据信息\n        ClusterAndWaitTime clusterAndWaitTime = this.waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);\n        long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);\n        Cluster cluster = clusterAndWaitTime.cluster;\n\n        // 2 基于注册的序列化器对 key 执行序列化\n        byte[] serializedKey;\n        try {\n            serializedKey = keySerializer.serialize(record.topic(), record.key());\n        } catch (ClassCastException cce) {\n            throw new SerializationException(\"Can't convert key of class \" + record.key().getClass().getName() +\n                    \" to class \" + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() + \" specified in key.serializer\");\n        }\n\n        // 3. 基于注册的序列化器对 value 执行序列化\n        byte[] serializedValue;\n        try {\n            serializedValue = valueSerializer.serialize(record.topic(), record.value());\n        } catch (ClassCastException cce) {\n            throw new SerializationException(\"Can't convert value of class \" + record.value().getClass().getName() +\n                    \" to class \" + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() + \" specified in value.serializer\");\n        }\n\n        // 4. 为当前消息选择合适的分区，如果未明确指定的话，则基于注册的分区器为当前消息计算分区\n        int partition = this.partition(record, serializedKey, serializedValue, cluster);\n\n        /* 5. 将消息追加到消息收集器（RecordAccumulator）中 */\n\n        // 计算当前消息大小，并校验消息是否过大\n        int serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);\n        this.ensureValidRecordSize(serializedSize);\n        tp = new TopicPartition(record.topic(), partition); // 消息投递的目标 topic 分区\n        // 如果未明确为当前消息指定时间戳，则设置为当前时间戳\n        long timestamp = record.timestamp() == null ? time.milliseconds() : record.timestamp();\n        log.trace(\"Sending record {} with callback {} to topic {} partition {}\", record, callback, record.topic(), partition);\n        // producer callback will make sure to call both 'callback' and interceptor callback\n        Callback interceptCallback = this.interceptors == null ? callback : new InterceptorCallback<>(callback, this.interceptors, tp);\n        // 追加消息到收集器中\n        RecordAccumulator.RecordAppendResult result = accumulator.append(\n                tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);\n\n        /* 6. 条件性唤醒消息发送线程 */\n\n        // 如果队列中不止一个 RecordBatch，或者最后一个 RecordBatch 满了，或者有创建新的 RecordBatch，则唤醒 Sender 线程发送消息\n        if (result.batchIsFull || result.newBatchCreated) {\n            log.trace(\"Waking up the sender since topic {} partition {} is either full or getting a new batch\", record.topic(), partition);\n            // 唤醒 sender 线程，发送消息\n            this.sender.wakeup();\n        }\n        return result.future;\n    }\n    // ... 省略异常处理\n}\n```\n\n我们可以将消息的发送过程概括为以下 6 个步骤：\n\n1. 获取集群的元数据（Metadata）信息，如果请求的是新 topic，或者指定的分区 ID 超过了已知的合法区间，则触发更新本地缓存的集群元数据信息；\n2. 基于注册的 key 序列化器对消息的 key 执行序列化；\n3. 基于注册的 value 序列化器对消息的 value 执行序列化；\n4. 如果未指定目标 topic 分区，则基于注册的分区器为当前消息计算目标分区；\n5. 缓存消息到消息收集器 RecordAccumulator 中；\n6. 条件性唤醒消息发送 Sender 线程。\n\n下面逐一对上述过程中的 6 个步骤展开分析。首先来看一下获取集群元数据信息的过程（ __步骤 1__ ），KafkaProducer 本地会缓存集群的元数据信息，包括集群的 topic 列表、每个 topic 的分区列表、分区 Leader 和 Follower 副本所在节点、分区 AR 和 ISR 集合，以及集群节点信息等，详细信息参考下面的 Metadata 类定义。\n\n当客户端向集群投递消息时实际上是投递到了目标 topic 指定分区的 Leader 副本上。因为集群状态是动态变化的，Leader 副本所在的网络位置也会发生迁移，所以客户端在投递消息之前，需要确保本地所缓存的集群信息是最新的，否则需要标记当前集群信息需要更新，具体的更新操作由 Sender 线程完成。\n\nKafkaProducer 在发送消息之前会先调用 `KafkaProducer#waitOnMetadata` 方法获取集群元数据信息，如果感知到本地缓存的集群元数据信息已经过期，则会通知 Sender 线程进行更新。首先来看一下保存集群元数据信息的 Metadata 类的字段定义：\n\n```java\npublic final class Metadata {\n\n    /** 元数据最小更新时间间隔，默认是 100 毫秒，防止更新太频繁 */\n    private final long refreshBackoffMs;\n    /** 元数据更新时间间隔，默认为 5 分钟 */\n    private final long metadataExpireMs;\n    /** 元数据版本号，每更新成功一次则版本号加 1 */\n    private int version;\n    /** 上一次更新元数据的时间戳，不管成功还是失败 */\n    private long lastRefreshMs;\n    /** 上一次成功更新元数据的时间戳 */\n    private long lastSuccessfulRefreshMs;\n    /** 集群信息 */\n    private Cluster cluster;\n    /** 标记是否需要更新集群元数据信息 */\n    private boolean needUpdate;\n    /** 记录集群中所有的 topic 信息，key 是 topic，value 是 topic 过期的时间戳 */\n    private final Map<String, Long> topics;\n    /** 元数据更新监听器 */\n    private final List<Listener> listeners;\n    /** 标记是否需要更新所有 topic 的元数据信息，一般只更新当前用到的 topic 的元数据信息 */\n    private boolean needMetadataForAllTopics;\n    /** 是否允许 topic 过期 */\n    private final boolean topicExpiryEnabled;\n\n    // ... 省略方法定义\n\n}\n```\n\n下面继续来看一下 `KafkaProducer#waitOnMetadata` 方法的实现：\n\n```java\nprivate ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long maxWaitMs) throws InterruptedException {\n    // 添加 topic 到集合中，如果是新 topic，标记需要更新集群元数据信息\n    metadata.add(topic);\n    // 获取当前集群信息\n    Cluster cluster = metadata.fetch();\n    // 获取指定 topic 的分区数目\n    Integer partitionsCount = cluster.partitionCountForTopic(topic);\n\n    // 如果参数未指定分区，或指定的分区在当前记录的分区范围之内，则返回历史集群信息\n    if (partitionsCount != null && (partition == null || partition < partitionsCount)) {\n        return new ClusterAndWaitTime(cluster, 0);\n    }\n\n    /* 否则，当前缓存的集群元数据信息可能已经过期，需要进行更新 */\n\n    long begin = time.milliseconds();\n    long remainingWaitMs = maxWaitMs; // 剩余等待时间\n    long elapsed;\n\n    /* 请求集群的元数据信息，直到获取到信息或者超时 */\n    do {\n        log.trace(\"Requesting metadata update for topic {}.\", topic);\n        // 更新 Metadata 的 needUpdate 字段，并获取当前元数据的版本号\n        int version = metadata.requestUpdate();\n        // 唤醒 sender 线程，由 sender 线程负责更新元数据信息\n        sender.wakeup();\n        try {\n            // 等待元数据更新完成\n            metadata.awaitUpdate(version, remainingWaitMs);\n        } catch (TimeoutException ex) {\n            // 等待超时\n            throw new TimeoutException(\"Failed to update metadata after \" + maxWaitMs + \" ms.\");\n        }\n\n        // 获取更新后的集群信息\n        cluster = metadata.fetch();\n        elapsed = time.milliseconds() - begin;\n        if (elapsed >= maxWaitMs) {\n            // 等待超时\n            throw new TimeoutException(\"Failed to update metadata after \" + maxWaitMs + \" ms.\");\n        }\n        // 权限检测\n        if (cluster.unauthorizedTopics().contains(topic)) {\n            throw new TopicAuthorizationException(topic);\n        }\n        remainingWaitMs = maxWaitMs - elapsed; // 更新剩余等待时间\n        partitionsCount = cluster.partitionCountForTopic(topic); // 获取指定 topic 的分区数目\n    } while (partitionsCount == null); // 更新集群信息失败，继续重试\n\n    /* 更新集群信息成功 */\n\n    // 参数指定的分区非法\n    if (partition != null && partition >= partitionsCount) {\n        throw new KafkaException(String.format(\"Invalid partition given with record: %d is not in the range [0...%d).\", partition, partitionsCount));\n    }\n\n    return new ClusterAndWaitTime(cluster, elapsed);\n}\n```\n\n上述方法首先会尝试将当前 topic 加入到本地缓存的 topic 集合中，因为客户端对于 topic 会有一个过期机制，对于长时间未使用的 topic 会从本地缓存中移除。这里一开始调用 `Metadata#add` 方法除了标记当前 topic 是活跃的之外，另外一个目的在于判断本地是否有该 topic 的缓存信息，如果没有则需要通知 Sender 线程更新集群元数据信息。通知的过程实际上只是简单将 `Metadata#needUpdate` 字段设置为 true，Sender 线程会检查该字段以更新集群元数据信息。\n\n接下来会调用 `Metadata#fetch` 方法获取集群信息 Cluster 对象，Cluster 类是对集群节点、topic、分区等信息的一个封装，其字段定义如下：\n\n```java\npublic final class Cluster {\n\n    /** kafka 集群中的节点信息列表（包括 id、host、port 等信息） */\n    private final List<Node> nodes;\n    /** 未授权的 topic 集合 */\n    private final Set<String> unauthorizedTopics;\n    /** 内部 topic 集合 */\n    private final Set<String> internalTopics;\n    /** 记录 topic 分区与分区详细信息的映射关系 */\n    private final Map<TopicPartition, PartitionInfo> partitionsByTopicPartition;\n    /** 记录 topic 及其分区信息的映射关系 */\n    private final Map<String, List<PartitionInfo>> partitionsByTopic;\n    /** 记录 topic 及其分区信息的映射关系（必须包含 leader 副本） */\n    private final Map<String, List<PartitionInfo>> availablePartitionsByTopic;\n    /** 记录节点 ID 与分区信息的映射关系 */\n    private final Map<Integer, List<PartitionInfo>> partitionsByNode;\n    /** key 是 brokerId，value 是 broker 节点信息，方便基于 brokerId 获取对应的节点信息 */\n    private final Map<Integer, Node> nodesById;\n\n    // ... 省略方法定义\n\n}\n```\n\n其中 Node、TopicPartition 和 PartitionInfo 类定义比较简单，其作用分别为：\n\n- __Node__ ：封装 Kafka 节点信息，包括 ID、主机名，以及端口号等信息。\n- __TopicPartition__ ：封装分区摘要信息，包含分区所属 topic 和分区编号。\n- __PartitionInfo__ ：封装分区详细信息，包括分区所属 topic、分区编号、Leader 副本所在节点、全部副本所在节点列表，以及 ISR 副本所在节点列表。\n\n继续回到 `KafkaProducer#waitOnMetadata` 方法。接下来方法会判断是否需要更新集群元数据信息，判断的依据是当前本地缓存的目标 topic 的分区数目不为空，同时如果发送消息时明确指定了分区编号，则此编号必须在本地认为合法的分区编号区间范围内。如果能够满足这些条件，则认为本地缓存的集群信息是合法的，可以直接拿来使用，否则就会触发更新集群元数据的逻辑。如果需要更新集群元数据，则会调用 `Metadata#requestUpdate` 方法设置标记位，同时唤醒 Sender 线程进行处理，并等待集群元数据更新完成。判定更新完成的策略就是判定本地缓存的集群元数据的版本号（`Metadata#version` 字段）是否被更新，因为集群元数据每更新成功一次，版本号会加 1。如果等待过程超时则会抛出 TimeoutException 异常。\n\n此外，客户端也会定期触发元数据更新操作，默认元数据有效时间为 5 分钟，可以通过 `metadata.max.age.ms` 参数进行设定。\n\n回到 `KafkaProducer#doSend` 方法，在拿到集群信息之后，方法会基于配置的 key 和 value 序列化器分别对消息 ID 和消息内容进行序列化（ __步骤 2__ 和 __步骤 3__ ），这一过程比较简单。 __步骤 4__ 会为当前消息选择合适的分区，相关实现位于 `KafkaProducer#partition` 方法中：\n\n```java\nprivate int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) {\n    // 获取当前待发送消息所指定的分区\n    Integer partition = record.partition();\n    // 如果未指定分区，则为当前消息计算一个分区编号\n    return partition != null ?\n            partition :\n            partitioner.partition(record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n}\n```\n\n如果我们在发送消息时明确指定了分区编号，那么这里只是简单的返回该编号，否则就需要基于注册的分区器计算当前消息对应的分区编号。Partitioner 接口是分区器的抽象，我们可以实现该接口自定义分区器，Kafka 也提供了默认的分区器实现 DefaultPartitioner，分区算法实现如下：\n\n```java\npublic int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n    // 获取当前 topic 的分区详细信息\n    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\n    // 获取当前 topic 对应的分区数\n    int numPartitions = partitions.size();\n    // 如果没有设置 key，则基于轮询算法\n    if (keyBytes == null) {\n        // 获取当前 topic 对应的上次位置值加 1，如果是第一次则随机生成一个\n        int nextValue = this.nextValue(topic);\n        // 获取当前 topic 包含 leader 副本的分区详细信息\n        List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);\n        if (availablePartitions.size() > 0) {\n            int part = Utils.toPositive(nextValue) % availablePartitions.size();\n            return availablePartitions.get(part).partition();\n        } else {\n            // no partitions are available, give a non-available partition\n            return Utils.toPositive(nextValue) % numPartitions;\n        }\n    }\n    // 如果指定了 key，则使用 murmur2 算法对 key 做哈希取模\n    else {\n        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;\n    }\n}\n```\n\n默认分区器 DefaultPartitioner 依据消息的 key 计算分区，如果在发送消息时未指定 key，则默认分区器会基于 [Round-Robin](https://en.wikipedia.org/wiki/Round-robin_scheduling) 算法计算分区编号，以保证目标 topic 分区的负载均衡。否则会基于 32 位的 [murmur2](https://en.wikipedia.org/wiki/MurmurHash) 哈希算法计算 key 的哈希值，并与分区数取模得到最后的分区编号。\n\n__步骤 5__ 会计算并校验当前消息的大小，同时为消息附加时间戳，并最终调用 `RecordAccumulator#append` 方法将消息缓存到收集器 RecordAccumulator 中，等待 Sender 线程投递给 Kafka 集群。RecordAccumulator 是生产者 SDK 中非常重要的一个类，可以将其看做是一个本地缓存消息的队列，消息收集线程将消息最终记录到收集器中，而 Sender 线程会定期定量从收集器中取出缓存的消息，并投递给 Kafka 集群。RecordAccumulator 类字段定义如下：\n\n```java\npublic final class RecordAccumulator {\n\n    /** 标识当前收集器是否被关闭，对应 producer 被关闭 */\n    private volatile boolean closed;\n    /** 记录正在执行 flush 操作的线程数 */\n    private final AtomicInteger flushesInProgress;\n    /** 记录正在执行 append 操作的线程数 */\n    private final AtomicInteger appendsInProgress;\n    /** 指定每个 RecordBatch 中 ByteBuffer 的大小 */\n    private final int batchSize;\n    /** 消息压缩类型 */\n    private final CompressionType compression;\n    /** 通过参数 linger.ms 指定，当本地消息缓存时间超过该值时，即使消息量未达到阈值也会进行投递 */\n    private final long lingerMs;\n    /** 生产者重试时间间隔 */\n    private final long retryBackoffMs;\n    /** 缓存（ByteBuffer）管理工具 */\n    private final BufferPool free;\n    /** 时间戳工具 */\n    private final Time time;\n    /** 记录 topic 分区与 RecordBatch 的映射关系，对应的消息都是发往对应的 topic 分区 */\n    private final ConcurrentMap<TopicPartition, Deque<RecordBatch>> batches;\n    /** 记录未发送完成（即未收到服务端响应）的消息集合 */\n    private final IncompleteRecordBatches incomplete;\n    /**\n     * 消息顺序性保证，\n     * 缓存当前待发送消息的目标 topic 分区，防止对于同一个 topic 分区同时存在多个未完成的消息，可能导致消息顺序性错乱\n     */\n    private final Set<TopicPartition> muted;\n    /** 记录 drain 方法批量导出消息时上次的偏移量 */\n    private int drainIndex;\n\n    // ... 省略方法定义\n\n}\n```\n\n既然 RecordAccumulator 可以看做是一个消息缓存队列，那么这里先了解一下其消息存储的模式。这其中涉及到 RecordAccumulator、RecordBatch、MemoryRecords 和 MemoryRecordsBuilder 4 个类。从上面 RecordAccumulator 类的字段列表中我们看到有一个 `ConcurrentMap<TopicPartition, Deque<RecordBatch>>` 类型的 batches 字段，这里的 key 对应 topic 的某个分区，而 value 是一个 Deque 类型，其中封装了一批 RecordBatch 对象，这些对象中记录了待发送的消息集合，而这些消息的一个共同点就是都是发往相同的 topic 分区。RecordBatch 类字段定义如下：\n\n```java\npublic final class RecordBatch {\n\n    /** 当前 RecordBatch 创建的时间戳 */\n    final long createdMs;\n    /** 当前缓存的消息的目标 topic 分区 */\n    final TopicPartition topicPartition;\n    /** 标识当前 RecordBatch 发送之后的状态 */\n    final ProduceRequestResult produceFuture;\n    /** 消息的 Callback 队列，每个消息都对应一个 Callback 对象 */\n    private final List<Thunk> thunks = new ArrayList<>();\n    /** 用来存储数据的 {@link MemoryRecords} 对应的 builder 对象 */\n    private final MemoryRecordsBuilder recordsBuilder;\n    /** 发送当前 RecordBatch 的重试次数 */\n    volatile int attempts;\n    /** 最后一次重试发送的时间戳` */\n    long lastAttemptMs;\n    /** 记录保存的 record 个数 */\n    int recordCount;\n    /** 记录最大的 record 字节数 */\n    int maxRecordSize;\n    /** 记录上次投递当前 BatchRecord 的时间戳 */\n    long drainedMs;\n    /** 追后一次向当前 RecordBatch 追加消息的时间戳 */\n    long lastAppendTime;\n    /** 标记是否正在重试 */\n    private boolean retry;\n\n    // ... 省略方法定义\n\n}\n```\n\n我们可以从字段定义中看到 RecordBatch 持有一个 MemoryRecordsBuilder 类型的字段，MemoryRecordsBuilder 是 MemoryRecords 的构造和管理器，也就是说 RecordBatch 本质上是以 MemoryRecords 作为存储介质。\n\n了解了 RecordAccumulator 类在存储模式上的设计之后，我们接下来分析 `RecordAccumulator#append` 方法的实现：\n\n```java\npublic RecordAppendResult append(TopicPartition tp,\n                                 long timestamp,\n                                 byte[] key,\n                                 byte[] value,\n                                 Callback callback,\n                                 long maxTimeToBlock) throws InterruptedException {\n    // 记录正在向收集器中追加消息的线程数\n    appendsInProgress.incrementAndGet();\n    try {\n        // 获取当前 topic 分区对应的 Deque，如果不存在则创建一个\n        Deque<RecordBatch> dq = this.getOrCreateDeque(tp);\n        synchronized (dq) {\n            if (closed) {\n                // producer 已经被关闭了，抛出异常\n                throw new IllegalStateException(\"Cannot send after the producer is closed.\");\n            }\n            // 向 Deque 中最后一个 RecordBatch 追加 Record，并返回对应的 RecordAppendResult 对象\n            RecordAppendResult appendResult = this.tryAppend(timestamp, key, value, callback, dq);\n            if (appendResult != null) {\n                // 追加成功，直接返回\n                return appendResult;\n            }\n        }\n\n        /* 追加 Record 失败，尝试申请新的 buffer */\n\n        int size = Math.max(this.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));\n        log.trace(\"Allocating a new {} byte message buffer for topic {} partition {}\", size, tp.topic(), tp.partition());\n        // 申请新的 buffer\n        ByteBuffer buffer = free.allocate(size, maxTimeToBlock);\n        synchronized (dq) {\n            if (closed) {\n                // 再次校验 producer 状态，如果已经被关闭了，抛出异常\n                throw new IllegalStateException(\"Cannot send after the producer is closed.\");\n            }\n\n            // 再次尝试向 Deque 中最后一个 RecordBatch 追加 Record\n            RecordAppendResult appendResult = this.tryAppend(timestamp, key, value, callback, dq);\n            if (appendResult != null) {\n                // 追加成功则返回，同时归还之前申请的 buffer\n                free.deallocate(buffer);\n                return appendResult;\n            }\n\n            /* 仍然追加失败，创建一个新的 RecordBatch 进行追加 */\n\n            MemoryRecordsBuilder recordsBuilder = MemoryRecords.builder(buffer, compression, TimestampType.CREATE_TIME, this.batchSize);\n            RecordBatch batch = new RecordBatch(tp, recordsBuilder, time.milliseconds());\n            // 在新创建的 RecordBatch 中追加 Record\n            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));\n            dq.addLast(batch);\n            // 追加到未完成的集合中\n            incomplete.add(batch);\n            // 封装成 RecordAppendResult 对象返回\n            return new RecordAppendResult(future, dq.size() > 1 || batch.isFull(), true);\n        }\n    } finally {\n        appendsInProgress.decrementAndGet();\n    }\n}\n```\n\n追加消息到收集器的过程首先会获取指定 topic 分区对应的发送队列，如果不存在则会创建一个。然后同步往该队列的最后一个 RecordBatch 对象中追加数据，追加的过程位于 `RecordAccumulator#tryAppend` 方法中。如果追加失败，一般都是因为该 RecordBatch 没有足够的空间足以容纳，则方法会尝试申请新的空间，然后继续尝试追加。如果还是失败，则方法会创建一个新的 RecordBatch 对象进行追加。\n\nKafka 定义了 BufferPool 类以实现对 ByteBuffer 的复用，避免频繁创建和释放所带来的性能开销。不过需要注意的一点是，并不是所有的 ByteBuffer 对象都会被复用，BufferPool 对所管理的 ByteBuffer 对象的大小是有限制的（默认大小为 16KB，可以依据具体的应用场景适当调整 `batch.size` 配置进行修改），只有大小等于该值的 ByteBuffer 对象才会被 BufferPool 管理。\n\n上述过程多次调用到 `RecordAccumulator#tryAppend` 方法，下面来看一下该方法的实现：\n\n```java\nprivate RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Callback callback, Deque<RecordBatch> deque) {\n    // 获取 deque 的最后一个 RecordBatch\n    RecordBatch last = deque.peekLast();\n    if (last != null) {\n        // 尝试往该 RecordBatch 末尾追加消息\n        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, callback, time.milliseconds());\n        if (future == null) {\n            // 追加失败\n            last.close();\n        } else {\n            // 追加成功，将结果封装成 RecordAppendResult 对象返回\n            return new RecordAppendResult(future, deque.size() > 1 || last.isFull(), false);\n        }\n    }\n    return null;\n}\n\n// org.apache.kafka.clients.producer.internals.RecordBatch#tryAppend\npublic FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Callback callback, long now) {\n    // 检测是否还有多余的空间容纳该消息\n    if (!recordsBuilder.hasRoomFor(key, value)) {\n        // 没有多余的空间则直接返回，后面会尝试申请新的空间\n        return null;\n    }\n    // 添加当前消息到 MemoryRecords，并返回消息对应的 CRC32 校验码\n    long checksum = this.recordsBuilder.append(timestamp, key, value);\n    // 更新最大 record 字节数\n    this.maxRecordSize = Math.max(this.maxRecordSize, Record.recordSize(key, value));\n    // 更新最后一次追加记录时间戳\n    this.lastAppendTime = now;\n    FutureRecordMetadata future = new FutureRecordMetadata(\n            produceFuture, recordCount,\n            timestamp, checksum,\n            key == null ? -1 : key.length,\n            value == null ? -1 : value.length);\n    if (callback != null) {\n        // 如果指定了 Callback，将 Callback 和 FutureRecordMetadata 封装到 Trunk 中\n        thunks.add(new Thunk(callback, future));\n    }\n    this.recordCount++;\n    return future;\n}\n```\n\n上面过程最终调用 `MemoryRecordsBuilder#append` 方法将消息追加到 MemoryRecords 相应的位置进行存储，并返回消息的 CRC32 校验码，至于 MemoryRecords 存储消息的细节这里不再继续深入。消息追加成功之后，如果在发送消息时指定了 Callback 函数，那么这里会将其封装成 Thunk 类对象，至于其作用这里先不展开分析，等到后面分析 Sender 线程的执行过程时再一探究竟，这里初步猜测 Sender 线程在向集群投递完消息并收到来自集群的响应时会循环遍历 thunks 集合，并应用 Callback 对应的回调方法。\n\n回到 `KafkaProducer#doSend` 方法，来看最后一步（ __步骤 6__ ）。上面追加的过程会返回一个 RecordAppendResult 对象，该对象通过 `RecordAppendResult#batchIsFull` 和 `RecordAppendResult#newBatchCreated` 两个字段分别标记了追加过程中末端的 RecordBatch 是否已满，以及追加过程中是否有创建新的 RecordBatch 对象，如果这两个条件满足其中之一，则会唤醒 Sender 线程尝试向集群投递收集的消息数据。\n\n最后提一点，RecordAccumulator 作为消息的收集器，其内存容量是有上限的，默认为 32MB（可以通过 `buffer.memory` 参数配置），当容量已满时调用 `KafkaProducer#send` 方法发送消息会被阻塞，当阻塞超过一定时间（默认为 60 秒，可以通过 `max.block.ms` 参数配置）则抛出异常。\n\n#### 投递待发送的消息\n\n前面曾提出一个概念，即客户端发送消息的过程实际上是一个异步的过程，由 2 个线程协同执行，其中 1 个线程将待发送的消息写入缓冲区，另外 1 个线程（Sender 线程）负责定期定量将缓冲区中的数据投递给远端 Kafka 集群，并反馈投递结果。上面我们分析了过程 1，下面我们继续分析过程 2，即将缓存的消息发送给 Kafka 集群。\n\n这一过程由 Sender 线程负责执行，前面的分析中曾多次唤醒过该线程，下面来看一下其实现，位于 Sender 类中，该类实现了 `java.lang.Runnable` 接口，其 `Sender#run` 方法实现如下：\n\n```java\npublic void run() {\n\n    // 主循环，一直运行直到 KafkaProducer 被关闭\n    while (running) {\n        try {\n            this.run(time.milliseconds());\n        } catch (Exception e) {\n            log.error(\"Uncaught error in kafka producer I/O thread: \", e);\n        }\n    }\n\n    /* 如果 KafkaProducer 被关闭，尝试发送剩余的消息 */\n    while (!forceClose // 不是强制关闭\n            // 存在未发送或已发送待响应的请求\n            && (this.accumulator.hasUnsent() || this.client.inFlightRequestCount() > 0)) {\n        try {\n            this.run(time.milliseconds());\n        } catch (Exception e) {\n            log.error(\"Uncaught error in kafka producer I/O thread: \", e);\n        }\n    }\n\n    // 如果是强制关闭，忽略所有未发送和已发送待响应的请求\n    if (forceClose) {\n        // 丢弃所有未发送完成的消息\n        this.accumulator.abortIncompleteBatches();\n    }\n    try {\n        // 关闭网络连接\n        this.client.close();\n    } catch (Exception e) {\n        log.error(\"Failed to close network client\", e);\n    }\n}\n```\n\n由上述方法实现可知，Sender 线程在启动后会一直循环执行另外一个重载版本的 `Sender#run` 方法，其中包含了 Sender 线程的主要逻辑。如果客户端被关闭（一般都是调用 `KafkaProducer#close` 方法），在不是强制关闭的前提下，Sender 线程会继续处理本地未发送和已发送但未收到服务端确认的消息，如果是强制关闭（在调用 `KafkaProducer#close` 方法时允许指定超时等待时间，如果在既定时间内客户端仍未完成对缓存消息的处理，则会触发强制关闭机制），则会丢弃本地缓存的所有未发送的消息，最后关闭到 Kafka 集群的网络连接。\n\n下面来看一下 Sender 线程的核心实现，即重载版本的 `Sender#run` 方法：\n\n```java\nvoid run(long now) {\n\n    // 1. 计算需要以及可以向哪些节点发送请求\n    Cluster cluster = metadata.fetch(); // 获取 kafka 集群信息\n    RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now); // 计算需要向哪些节点发送请求\n\n    // 2. 如果存在未知的 leader 副本对应的节点（对应的 topic 分区正在执行 leader 选举，或者对应的 topic 已经失效），标记需要更新缓存的集群元数据信息\n    if (!result.unknownLeaderTopics.isEmpty()) {\n        for (String topic : result.unknownLeaderTopics) this.metadata.add(topic);\n        this.metadata.requestUpdate();\n    }\n\n    // 3. 遍历处理待发送请求的目标节点，基于网络 IO 检查对应节点是否可用，对于不可用的节点则剔除\n    Iterator<Node> iter = result.readyNodes.iterator();\n    long notReadyTimeout = Long.MAX_VALUE;\n    while (iter.hasNext()) {\n        Node node = iter.next();\n        // 检查目标节点是否准备好接收请求，如果未准备好但目标节点允许创建连接，则创建到目标节点的连接\n        if (!this.client.ready(node, now)) {\n            // 对于未准备好的节点，则从 ready 集合中删除\n            iter.remove();\n            notReadyTimeout = Math.min(notReadyTimeout, this.client.connectionDelay(node, now));\n        }\n    }\n\n    // 4. 获取每个节点待发送消息集合，其中 key 是目标 leader 副本所在节点 ID\n    Map<Integer, List<RecordBatch>> batches =\n            this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now);\n\n    // 5. 如果需要保证消息的强顺序性，则缓存对应 topic 分区对象，防止同一时间往同一个 topic 分区发送多条处于未完成状态的消息\n    if (guaranteeMessageOrder) {\n        // 将所有 RecordBatch 的 topic 分区对象加入到 muted 集合中\n        // 防止同一时间往同一个 topic 分区发送多条处于未完成状态的消息\n        for (List<RecordBatch> batchList : batches.values()) {\n            for (RecordBatch batch : batchList)\n                this.accumulator.mutePartition(batch.topicPartition);\n        }\n    }\n\n    // 6. 处理本地过期的消息，返回 TimeoutException，并释放空间\n    List<RecordBatch> expiredBatches = this.accumulator.abortExpiredBatches(this.requestTimeout, now);\n\n    // 如果存在待发送的消息，则设置 pollTimeout 等于 0，这样可以立即发送请求，从而能够缩短剩余消息的缓存时间，避免堆积\n    long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);\n    if (!result.readyNodes.isEmpty()) {\n        log.trace(\"Nodes with data ready to send: {}\", result.readyNodes);\n        pollTimeout = 0;\n    }\n\n    // 7. 发送请求到服务端，并处理服务端响应\n    this.sendProduceRequests(batches, now);\n    this.client.poll(pollTimeout, now);\n}\n```\n\n发送收集器 RecordAccumulator 中缓存的消息到 Kafka 集群的整体执行流程可以概括为如下 7 个步骤：\n\n1. 计算需要向哪些 broker 节点投递消息；\n2. 如果步骤 1 中发现一些 topic 分区的 Leader 副本所在 broker 节点失效，则需要标记更新本地缓存的集群元数据信息；\n3. 遍历处理步骤 1 中获取到的 broker 节点集合，基于 I/O 检测对应节点是否可用，如果不可用则剔除；\n4. 以 broker 节点 ID 为键，获取发往目标节点的消息集合；\n5. 如果需要对消息顺序进行强一致性保证，则需要缓存当前目标 topic 分区对象，防止同一时间往同一个 topic 分区发送多条处于未完成状态的消息；\n6. 处理本地已过期的消息，返回超时异常，并释放占据的空间；\n7. 发送消息到服务端，并处理服务端的响应。\n\n下面就各个步骤展开说明，首先来看 __步骤 1__ ，该步骤用于计算需要向哪些节点投递消息，实现位于 `RecordAccumulator#ready` 方法中：\n\n```java\npublic ReadyCheckResult ready(Cluster cluster, long nowMs) {\n    // 用于记录接收请求的节点\n    Set<Node> readyNodes = new HashSet<>();\n    // 记录下次执行 ready 判断的时间间隔\n    long nextReadyCheckDelayMs = Long.MAX_VALUE;\n    // 记录找不到 leader 副本的分区对应的 topic 集合\n    Set<String> unknownLeaderTopics = new HashSet<>();\n\n    // 是否有线程在等待 BufferPool 分配空间\n    boolean exhausted = this.free.queued() > 0;\n    // 遍历每个 topic 分区及其 RecordBatch 队列，对每个分区的 leader 副本所在的节点执行判定\n    for (Map.Entry<TopicPartition, Deque<RecordBatch>> entry : this.batches.entrySet()) {\n        TopicPartition part = entry.getKey();\n        Deque<RecordBatch> deque = entry.getValue();\n\n        // 获取当前 topic 分区 leader 副本所在的节点\n        Node leader = cluster.leaderFor(part);\n        synchronized (deque) {\n            // 当前分区 leader 副本未知，但存在发往该分区的消息\n            if (leader == null && !deque.isEmpty()) {\n                unknownLeaderTopics.add(part.topic());\n            }\n            // 如果需要保证消息顺序性，则不应该存在多个发往该 leader 副本节点且未完成的消息\n            else if (!readyNodes.contains(leader) && !muted.contains(part)) {\n                RecordBatch batch = deque.peekFirst();\n                if (batch != null) {\n                    // 当前为重试操作，且重试时间间隔未达到阈值时间\n                    boolean backingOff = batch.attempts > 0 && batch.lastAttemptMs + retryBackoffMs > nowMs;\n                    long waitedTimeMs = nowMs - batch.lastAttemptMs; // 重试等待的时间\n                    long timeToWaitMs = backingOff ? retryBackoffMs : lingerMs;\n                    long timeLeftMs = Math.max(timeToWaitMs - waitedTimeMs, 0);\n                    boolean full = deque.size() > 1 || batch.isFull();\n                    boolean expired = waitedTimeMs >= timeToWaitMs;\n\n                    // 标记当前节点是否可以接收请求\n                    boolean sendable = full // 1. 队列中有多个 RecordBatch，或第一个 RecordBatch 已满\n                            || expired // 2. 当前等待重试的时间过长\n                            || exhausted // 3. 有其他线程在等待 BufferPool 分配空间，即本地消息缓存已满\n                            || closed // 4. producer 已经关闭\n                            || flushInProgress(); // 5. 有线程正在等待 flush 操作完成\n                    if (sendable && !backingOff) {\n                        // 允许发送消息，且当前为首次发送，或者重试等待时间已经较长，则记录目标 leader 副本所在节点\n                        readyNodes.add(leader);\n                    } else {\n                        // 更新下次执行 ready 判定的时间间隔\n                        nextReadyCheckDelayMs = Math.min(timeLeftMs, nextReadyCheckDelayMs);\n                    }\n                }\n            }\n        }\n    }\n\n    // 封装结果返回\n    return new ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeaderTopics);\n}\n```\n\n整个计算的逻辑就是遍历我们之前缓存到收集器 RecordAccumulator 中的消息集合，并按照下面 5 个条件进行判定，如果满足其中一个则认为需要往目标节点投递消息：\n\n1. 当前 topic 名下的消息队列持有多个 RecordBatch，或者第 1 个 RecordBatch 已满。\n2. 当前 topic 分区等待重试的时间过长，如果是首次发送则无需校验重试等待时间。\n3. 当前 topic 分区下有其他线程在等待 BufferPool 分配空间，即本地缓存已满。\n4. Producer 被关闭，需要立即投递剩余未完成的消息。\n5. 有线程正在等待 flush 操作完成，则需要立即投递消息，避免线程等待时间过长。\n\n如果遍历过程中发现某个 topic 分区对应的 Leader 副本所在节点失效（对应的 topic 分区正在执行 Leader 副本选举，或者对应的 topic 已经失效），但是本地又缓存了发往该分区的消息，则需要标记当前本地缓存的集群元数据需要更新（ __步骤 2__ ）。上面获取目标 broker 节点的过程是站在收集器 RecordAccumulator 的角度看的，对于一个节点是否可用，还需要从网络 I/O 的角度检查其连通性，这也是 __步骤 3__ 所要做的工作，这一步基于 `KafkaClient#ready` 方法检查目标节点的是否连通，如果目标节点并未准备好接收请求，则需要从待请求节点集合中剔除。\n\n知道了需要向哪些节点投递消息，接下来自然而然就需要获取发往每个节点的数据， __步骤 4__ 的实现位于 `RecordAccumulator#drain` 方法中：\n\n```java\npublic Map<Integer, List<RecordBatch>> drain(Cluster cluster, Set<Node> nodes, int maxSize, long now) {\n    if (nodes.isEmpty()) {\n        return Collections.emptyMap();\n    }\n\n    // 记录转换后的结果，key 是目标节点 ID\n    Map<Integer, List<RecordBatch>> batches = new HashMap<>();\n    for (Node node : nodes) {\n        int size = 0;\n        // 获取当前节点上的分区信息\n        List<PartitionInfo> parts = cluster.partitionsForNode(node.id());\n        // 记录待发往当前节点的 RecordBatch 集合\n        List<RecordBatch> ready = new ArrayList<>();\n        /*\n         * drainIndex 用于记录上次发送停止的位置，本次继续从当前位置开始发送，\n         * 如果每次都是从 0 位置开始，可能会导致排在后面的分区饿死，可以看做是一个简单的负载均衡策略\n         */\n        int start = drainIndex = drainIndex % parts.size();\n        do {\n            PartitionInfo part = parts.get(drainIndex);\n            TopicPartition tp = new TopicPartition(part.topic(), part.partition());\n            // 如果需要保证消息强顺序性，则不应该同时存在多个发往目标分区的消息\n            if (!muted.contains(tp)) {\n                // 获取当前分区对应的 RecordBatch 集合\n                Deque<RecordBatch> deque = this.getDeque(new TopicPartition(part.topic(), part.partition()));\n                if (deque != null) {\n                    synchronized (deque) {\n                        RecordBatch first = deque.peekFirst();\n                        if (first != null) {\n                            // 重试 && 重试时间间隔未达到阈值时间\n                            boolean backoff = first.attempts > 0 && first.lastAttemptMs + retryBackoffMs > now;\n                            // 仅发送第一次发送，或重试等待时间较长的消息\n                            if (!backoff) {\n                                if (size + first.sizeInBytes() > maxSize && !ready.isEmpty()) {\n                                    // 单次消息数据量已达到上限，结束循环，一般对应一个请求的大小，防止请求消息过大\n                                    break;\n                                } else {\n                                    // 每次仅获取第一个 RecordBatch，并放入 read 列表中，这样给每个分区一个机会，保证公平，防止饥饿\n                                    RecordBatch batch = deque.pollFirst();\n                                    // 将当前 RecordBatch 设置为只读\n                                    batch.close();\n                                    size += batch.sizeInBytes();\n                                    ready.add(batch);\n                                    batch.drainedMs = now;\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n            // 更新 drainIndex\n            this.drainIndex = (this.drainIndex + 1) % parts.size();\n        } while (start != drainIndex);\n        batches.put(node.id(), ready);\n    }\n    return batches;\n}\n```\n\n上述方法的返回类型是 `Map<Integer, List<RecordBatch>>`，其中 key 是目标节点的 ID，value 是本次待发往该节点的消息集合。为了防止饥饿，方法会轮询从当前 topic 的每个分区队列对头取数据，并记录每次轮询的偏移量，下次轮询即从该偏移量位置开始，以保证尽量的公平。\n\n下面来看一下 __步骤 5__ ，这是客户端保证消息绝对有序的逻辑。在具体分析之前，我们先来看一个导致消息顺序错乱的场景。假设生产者发送了 2 条指向同一个目标 topic 分区的消息 A 和 B，但是 A 发送失败，B 却成功了，此时生产者会重发消息 A，结果就变成了 B 消息排在了 A 消息的前面。解决该问题的方法就是将参数 `max.in.flight.requests.per.connection` 参数设置为 1，以禁止生产者往同一个分区一次发送多条消息，不过这样会严重降低系统吞吐量，只有在对消息顺序有严格要求时才推荐这样做。步骤 5 的参数 `guaranteeMessageOrder=true` 对应着 `max.in.flight.requests.per.connection=1`，客户端解决上述问题的实现方式也很简单，就是在本地缓存有处于发送中消息对应的目标 topic 分区对象，保证该分区上的消息在被正确响应之前不会再投递第 2 条消息。\n\n下面继续来看 __步骤 6__ ，这一步会遍历收集器 RecordAccumulator 中缓存的 RecordBatch，并调用 `RecordBatch#maybeExpire` 方法检测当前 RecordBatch 是否过期，对于已经过期的 RecordBatch 会执行相应的 `RecordBatch#done` 方法（下一步中会对该方法展开说明），并释放占用的内存空间。\n\n最后我们来看一下消息发送的过程（ __步骤 7__ ），位于 `Sender#sendProduceRequests` 方法中：\n\n```java\nprivate void sendProduceRequests(Map<Integer, List<RecordBatch>> collated, long now) {\n    // 遍历处理待发送消息集合，key 是目标节点 ID\n    for (Map.Entry<Integer, List<RecordBatch>> entry : collated.entrySet())\n        this.sendProduceRequest(now, entry.getKey(), acks, requestTimeout, entry.getValue());\n}\n\nprivate void sendProduceRequest(long now, int destination, short acks, int timeout, List<RecordBatch> batches) {\n    // 遍历 RecordBatch 集合，整理成 produceRecordsByPartition 和 recordsByPartition\n    Map<TopicPartition, MemoryRecords> produceRecordsByPartition = new HashMap<>(batches.size());\n    final Map<TopicPartition, RecordBatch> recordsByPartition = new HashMap<>(batches.size());\n    for (RecordBatch batch : batches) {\n        TopicPartition tp = batch.topicPartition;\n        produceRecordsByPartition.put(tp, batch.records());\n        recordsByPartition.put(tp, batch);\n    }\n\n    // 创建 ProduceRequest 请求构造器\n    ProduceRequest.Builder requestBuilder = new ProduceRequest.Builder(acks, timeout, produceRecordsByPartition);\n\n    // 创建回调对象，用于处理响应\n    RequestCompletionHandler callback = new RequestCompletionHandler() {\n        @Override\n        public void onComplete(ClientResponse response) {\n            handleProduceResponse(response, recordsByPartition, time.milliseconds());\n        }\n    };\n\n    String nodeId = Integer.toString(destination);\n\n    // 创建 ClientRequest 请求对象，如果 acks 不等于 0 则表示期望获取服务端响应\n    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0, callback);\n    // 缓存 ClientRequest 请求对象到 InFlightRequests 中\n    client.send(clientRequest, now);\n    log.trace(\"Sent produce request to {}: {}\", nodeId, requestBuilder);\n}\n```\n\n这一步主要逻辑就是创建客户端请求 ClientRequest 对象，并通过 `NetworkClient#send` 方法将请求加入到网络 I/O 通道（KafkaChannel）中。同时将该对象缓存到 InFlightRequests 中，等接收到服务端响应时会通过缓存的 ClientRequest 对象调用对应的 callback 方法。最后调用 `NetworkClient#poll` 方法执行具体的网络请求和响应。\n\nInFlightRequests 类的主要作用是缓存那些已经发送出去但是还未收到响应的请求，并支持控制对单个节点的最大未完成请求数（默认值为 5，可以通过 `max.in.flight.requests.per.connection` 参数进行配置，但是上限不允许超过 5 个）。\n\n下面来看一下 `NetworkClient#poll` 方法的具体实现：\n\n```java\npublic List<ClientResponse> poll(long timeout, long now) {\n    /*\n     * 如果距离上次更新超过指定时间，且存在负载小的目标节点，\n     * 则创建 MetadataRequest 请求更新本地缓存的集群元数据信息，并在下次执行 poll 操作时一并送出\n     */\n    long metadataTimeout = metadataUpdater.maybeUpdate(now);\n\n    /* 发送网络请求 */\n    try {\n        this.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs));\n    } catch (IOException e) {\n        log.error(\"Unexpected error during I/O\", e);\n    }\n\n    /* 处理服务端响应 */\n\n    long updatedNow = this.time.milliseconds();\n    List<ClientResponse> responses = new ArrayList<>(); // 响应队列\n    // 添加需要被丢弃的请求对应的响应到 responses 队列中，都是一些版本不匹配的请求\n    this.handleAbortedSends(responses);\n    // 对于发送成功且不期望服务端响应的请求，创建本地的响应对象添加到 responses 队列中\n    this.handleCompletedSends(responses, updatedNow);\n    /*\n     * 获取并解析服务端响应\n     * - 如果是更新集群元数据对应的响应，则更新本地缓存的集群元数据信息\n     * - 如果是更新 API 版本的响应，则更新本地缓存的目标节点支持的 API 版本信息\n     * - 否则，获取 ClientResponse 添加到 responses 队列中\n     */\n    this.handleCompletedReceives(responses, updatedNow);\n    // 处理连接断开的请求，构建对应的 ClientResponse 添加到 responses 列表中，并标记需要更新集群元数据信息\n    this.handleDisconnections(responses, updatedNow);\n    // 处理 connections 列表，更新相应节点的连接状态\n    this.handleConnections();\n    // 如果需要更新本地的 API 版本信息，则创建对应的 ApiVersionsRequest 请求，并在下次执行 poll 操作时一并送出\n    this.handleInitiateApiVersionRequests(updatedNow);\n    // 遍历获取 inFlightRequests 中的超时请求，构建对应的 ClientResponse 添加到 responses 列表中，并标记需要更新集群元数据信息\n    this.handleTimedOutRequests(responses, updatedNow);\n\n    // 遍历处理响应对应的 onComplete 方法\n    for (ClientResponse response : responses) {\n        try {\n            // 本质上就是在调用注册的 RequestCompletionHandler#onComplete 方法\n            response.onComplete();\n        } catch (Exception e) {\n            log.error(\"Uncaught error in request completion:\", e);\n        }\n    }\n\n    return responses;\n}\n```\n\n整个方法的执行流程可以概括为 4 个步骤：\n\n1. 检测是否需要更新本地缓存的集群元数据信息，如果需要则创建对应的 MetadataRequest 请求，并在下次 `Selector#poll` 操作时一并送出；\n2. 执行 `Selector#poll` 操作，向服务端发送网络请求；\n3. 处理服务端响应；\n4. 遍历应用注册的 `RequestCompletionHandler#onComplete` 方法。\n\n首先来看更新本地缓存的集群元数据信息的过程（ __步骤 1__ ），前面曾多次提及到更新集群元数据的场景，而这些更新操作实际上都是标记集群元数据需要更新，真正执行更新的操作则发生在这里。实现位于 `DefaultMetadataUpdater#maybeUpdate` 方法中：\n\n```java\npublic long maybeUpdate(long now) {\n    // 获取下次更新集群信息的时间戳\n    long timeToNextMetadataUpdate = metadata.timeToNextUpdate(now);\n    // 检查是否已经发送了 MetadataRequest 请求\n    long waitForMetadataFetch = this.metadataFetchInProgress ? requestTimeoutMs : 0;\n    // 计算当前距离下次发送 MetadataRequest 请求的时间差\n    long metadataTimeout = Math.max(timeToNextMetadataUpdate, waitForMetadataFetch);\n    if (metadataTimeout > 0) {\n        // 如果时间还未到，则暂时不更新\n        return metadataTimeout;\n    }\n\n    // 寻找负载最小的可用节点，如果没有可用的节点则返回 null\n    Node node = leastLoadedNode(now);\n    if (node == null) {\n        log.debug(\"Give up sending metadata request since no node is available\");\n        return reconnectBackoffMs;\n    }\n\n    // 检查是否允许向目标节点发送请求，如果允许则创建 MetadataRequest 请求，并在下次执行 poll 操作时一并送出\n    return this.maybeUpdate(now, node);\n}\n\nprivate long maybeUpdate(long now, Node node) {\n    String nodeConnectionId = node.idString();\n\n    // 如果允许向该节点发送请求\n    if (canSendRequest(nodeConnectionId)) {\n        // 标识正在请求更新集群元数据信息\n        this.metadataFetchInProgress = true;\n        // 创建集群元数据请求 MetadataRequest 对象\n        MetadataRequest.Builder metadataRequest;\n        if (metadata.needMetadataForAllTopics()) {\n            // 需要更新所有 topic 的元数据信息\n            metadataRequest = MetadataRequest.Builder.allTopics();\n        } else {\n            // 仅需更新指定 topic 的元数据信息\n            metadataRequest = new MetadataRequest.Builder(new ArrayList<>(metadata.topics()));\n        }\n\n        // 将 MetadataRequest 包装成 ClientRequest 进行发送，在下次执行 poll 操作时一并发送\n        log.debug(\"Sending metadata request {} to node {}\", metadataRequest, node.id());\n        sendInternalMetadataRequest(metadataRequest, nodeConnectionId, now);\n        return requestTimeoutMs;\n    }\n\n    /* 不允许向目标节点发送请求 */\n\n    // 如果存在到目标节点的连接，则等待一会，无需再次尝试创建新的连接\n    if (isAnyNodeConnecting()) {\n        return reconnectBackoffMs;\n    }\n\n    /* 如果不存在到目标节点连接 */\n\n    // 如果允许创建到目标节点的连接，则初始化连接\n    if (connectionStates.canConnect(nodeConnectionId, now)) {\n        log.debug(\"Initialize connection to node {} for sending metadata request\", node.id());\n        initiateConnect(node, now); // 初始化连接\n        return reconnectBackoffMs;\n    }\n\n    return Long.MAX_VALUE;\n}\n```\n\n方法首先会依据之前设置的标记，以及上次的更新时间决定是否需要更新集群元数据信息，如果需要则依据本地记录的已发往服务端的请求数目寻找集群中负载最小且可用的节点，并创建对应的 MetadataRequest 请求，但是这里的请求不是立即发出的，而是将请求包装成 ClientRequest 对象，并在下次 `Selector#poll` 操作时一并送出，也就是接下去即将执行的步骤 2。\n\n__步骤 2__ 是真正发送网络请求的地方，这里的请求是异步的，客户端在发出请求之后继续执行步骤 3。 __步骤 3__ 的逻辑主要是为每一个 ClientRequest 请求构造对应的 ClientResponse 响应对象，这些响应对象有的是依据服务端的响应进行构造，有的则是在本地伪造，因为不是所有的请求都需要等待服务端的响应，也不是所有的请求都能得到服务端的响应。这一步的实现对应了一系列的 `handle*` 方法：\n\n> - handleAbortedSends\n> - handleCompletedSends\n> - handleCompletedReceives\n> - handleDisconnections\n> - handleConnections\n> - handleInitiateApiVersionRequests\n> - handleTimedOutRequests\n\n下面逐一来看一下相应方法的实现。\n\n- __handleAbortedSends__\n\n该方法的实现就是简单的将 `NetworkClient#abortedSends` 字段中记录的 ClientResponse 响应对象添加到结果集合中，并清空该字段。这些 ClientResponse 对象是在 `NetworkClient#doSend` 时添加的，添加的原因是本地请求与目标节点所支持的 API 版本不匹配。\n\n- __handleCompletedSends__\n\n该方法会遍历客户端已经发送成功的请求，对于那些不期望服务端响应的请求可以直接创建对应的 ClientResponse 响应对象，并添加到结果集合中。实现如下：\n\n```java\nprivate void handleCompletedSends(List<ClientResponse> responses, long now) {\n    for (Send send : this.selector.completedSends()) {\n        // 获取缓存到 inFlightRequests 集合中的请求对象\n        InFlightRequest request = this.inFlightRequests.lastSent(send.destination());\n        // 检测请求是否期望响应\n        if (!request.expectResponse) {\n            // 当前请求不期望服务端响应，则从 inFlightRequests 集合中删除\n            this.inFlightRequests.completeLastSent(send.destination());\n            // 为当前请求生成 ClientResponse 对象\n            responses.add(request.completed(null, now));\n        }\n    }\n}\n```\n\n- __handleCompletedReceives__\n\n该方法会获取并解析服务端的响应结果，并依据响应类型分别处理。实现如下：\n\n```java\nprivate void handleCompletedReceives(List<ClientResponse> responses, long now) {\n    for (NetworkReceive receive : this.selector.completedReceives()) {\n        // 获取返回响应的节点 ID\n        String source = receive.source();\n        // 从 inFlightRequests 集合中获取缓存的 ClientRequest 对象\n        InFlightRequest req = inFlightRequests.completeNext(source);\n        // 解析响应\n        AbstractResponse body = parseResponse(receive.payload(), req.header);\n        log.trace(\"Completed receive from node {}, for key {}, received {}\", req.destination, req.header.apiKey(), body);\n        if (req.isInternalRequest && body instanceof MetadataResponse) {\n            // 如果是更新集群元数据对应的响应，则更新本地的缓存的集群元数据信息\n            metadataUpdater.handleCompletedMetadataResponse(req.header, now, (MetadataResponse) body);\n        } else if (req.isInternalRequest && body instanceof ApiVersionsResponse) {\n            // 如果是更新 API 版本的响应，则更新本地缓存的目标节点支持的 API 版本信息\n            this.handleApiVersionsResponse(responses, req, now, (ApiVersionsResponse) body);\n        } else {\n            // 否则，获取 ClientResponse 响应对象添加到队列中\n            responses.add(req.completed(body, now));\n        }\n    }\n}\n```\n\n如果当前是针对之前请求更新集群元数据信息的响应，则会调用 `DefaultMetadataUpdater#handleCompletedMetadataResponse` 方法解析响应内容，如果响应正常则会调用 `Metadata#update` 方法更新本地缓存的集群元数据信息。如果当前是针对请求更新本地 API 版本信息的响应，则会调用 `NetworkClient#handleApiVersionsResponse` 方法更新本地缓存的目标节点支持的 API 版本信息。对于其它类型的响应，则直接封装成 ClientResponse 对象添加到结果集合中。\n\n- __handleDisconnections__\n\n该方法会调用 `Selector#disconnected` 方法获取断开连接的节点 ID 集合，并更新相应节点的连接状态为 `DISCONNECTED`，同时会清空本地缓存的与该节点相关的数据，最终创建一个 disconnected 类型的 ClientResponse 对象添加到结果集合中。如果这一步确实发现了已断开的连接，则标记需要更新本地缓存的节点元数据信息。\n\n- __handleConnections__\n\n该方法会调用 `Selector#connected` 方法获取连接正常的节点 ID 集合，如果当前节点是第一次建立连接，则需要获取节点支持的 API 版本信息，方法会将当前节点的连接状态设置为 `CHECKING_API_VERSIONS`，并将节点 ID 添加到 `NetworkClient#nodesNeedingApiVersionsFetch` 集合中，对于其它节点，则更新相应连接状态为 `READY`。\n\n- __handleInitiateApiVersionRequests__\n\n该方法用于处理 `NetworkClient#handleConnections` 方法中标记的需要获取支持的 API 版本信息的节点，即记录到 `NetworkClient#nodesNeedingApiVersionsFetch` 集合中的节点。方法会遍历处理集合中的节点，并在判断目标节点允许接收请求的情况下，构建 ApiVersionsRequest 请求以获取目标节点支持的 API 版本信息，该请求会被包装成 ClientRequest 对象，并在下次 `Selector#poll` 操作时一并送出。\n\n- __handleTimedOutRequests__\n\n该方法会遍历缓存在 inFlightRequests 中已经超时的相关请求对应的节点集合，针对此类节点将其视作断开连接进行处理。方法会创建一个 disconnected 类型的 ClientResponse 对象添加到结果集合中，并标记需要更新本地缓存的集群元数据信息。\n\n在完成了将各种类型请求对应的响应对象 ClientResponse 添加到结果集合中之后，会继续遍历该集合并应用 `ClientResponse#onComplete` 方法，该方法最终调用的是我们注册的 RequestCompletionHandler 对应的 `RequestCompletionHandler#onComplete` 方法。我们在分析 `Sender#sendProduceRequest` 方法时曾遇到过下面这一段代码：\n\n```java\nRequestCompletionHandler callback = new RequestCompletionHandler() {\n    @Override\n    public void onComplete(ClientResponse response) {\n        handleProduceResponse(response, recordsByPartition, time.milliseconds());\n    }\n};\n```\n\n实际上在调用 `ClientResponse#onComplete` 方法时本质上也就是在调用 `Sender#handleProduceResponse` 方法，该方法所做的工作就是区分当前的响应类型，并针对每一种响应类型设置对应的参数并回调 `Sender#completeBatch` 方法，区别仅在于方法的 response 参数设置：\n\n- 如果是 disconnected 类型的响应，则设置 `response=new ProduceResponse.PartitionResponse(Errors.NETWORK_EXCEPTION)`。\n- 如果是 API 版本不匹配的响应，则设置 `response=new ProduceResponse.PartitionResponse(Errors.INVALID_REQUEST)`。\n- 对于其它响应类型，如果存在响应体则以响应体作为 response 参数；如果不存在响应体则设置 `response=new ProduceResponse.PartitionResponse(Errors.NONE)`。\n\n下面来看一下 `Sender#completeBatch` 方法的具体实现：\n\n```java\nprivate void completeBatch(RecordBatch batch, ProduceResponse.PartitionResponse response, long correlationId, long now) {\n    Errors error = response.error;\n    // 异常响应，但是允许重试\n    if (error != Errors.NONE && this.canRetry(batch, error)) {\n        log.warn(\"Got error produce response with correlation id {} on topic-partition {}, retrying ({} attempts left). Error: {}\", correlationId, batch.topicPartition, retries - batch.attempts - 1, error);\n        // 将消息重新添加到收集器中，等待再次发送\n        this.accumulator.reenqueue(batch, now);\n    }\n    // 正常响应，或不允许重试的异常\n    else {\n        RuntimeException exception;\n        if (error == Errors.TOPIC_AUTHORIZATION_FAILED) {\n            // 权限认证失败\n            exception = new TopicAuthorizationException(batch.topicPartition.topic());\n        } else {\n            // 其他异常，如果是正常响应，则为 null\n            exception = error.exception();\n        }\n        // 将响应信息传递给用户，并释放 RecordBatch 占用的空间\n        batch.done(response.baseOffset, response.logAppendTime, exception);\n        this.accumulator.deallocate(batch);\n    }\n\n    // 如果是集群元数据异常，则标记需要更新集群元数据信息\n    if (error.exception() instanceof InvalidMetadataException) {\n        metadata.requestUpdate();\n    }\n\n    // 释放已经处理完成的 topic 分区，对于需要保证消息强顺序性，以允许接收下一条消息\n    if (guaranteeMessageOrder) {\n        this.accumulator.unmutePartition(batch.topicPartition);\n    }\n}\n```\n\n上述方法会判断当前响应是否异常且可以需要重试，如果是则将 RecordBatch 重新添加到收集器 RecordAccumulator 中，等待再次发送。如果是正常响应或不允许重试，则调用 `RecordBatch#done` 方法结束本次发送消息的过程，并将响应结果传递给用户，同时释放 RecordBatch 占用的空间。下面来看一下方法 `RecordBatch#done` 的实现：\n\n```java\npublic void done(long baseOffset, long logAppendTime, RuntimeException exception) {\n    log.trace(\"Produced messages to topic-partition {} with base offset offset {} and error: {}.\", topicPartition, baseOffset, exception);\n\n    // 标识当前 RecordBatch 已经处理完成\n    if (completed.getAndSet(true)) {\n        throw new IllegalStateException(\"Batch has already been completed\");\n    }\n\n    // 设置当前 RecordBatch 发送之后的状态\n    produceFuture.set(baseOffset, logAppendTime, exception);\n\n    // 循环执行每个消息的 Callback 回调\n    for (Thunk thunk : thunks) {\n        try {\n            // 消息处理正常\n            if (exception == null) {\n                // RecordMetadata 是服务端返回的\n                RecordMetadata metadata = thunk.future.value();\n                thunk.callback.onCompletion(metadata, null);\n            }\n            // 消息处理异常\n            else {\n                thunk.callback.onCompletion(null, exception);\n            }\n        } catch (Exception e) {\n            log.error(\"Error executing user-provided callback on message for topic-partition '{}'\", topicPartition, e);\n        }\n    }\n\n    // 标记本次请求已经完成（正常响应、超时，以及关闭生产者）\n    produceFuture.done();\n}\n```\n\n前面我们曾分析过在消息追加成功之后，如果在发送消息时指定了 Callback 回调函数，会将其封装成 Thunk 类对象，当时我们猜测 Sender 线程在向集群投递完消息并收到来自集群的响应时会循环遍历 thunks 集合，并应用 Callback 相应的回调方法，而上述方法的实现证实了我们的猜想。\n\n方法中的变量 produceFuture 是一个 ProduceRequestResult 类型的对象，用于表示一次消息生产过程是否完成，该类基于 CountDownLatch 实现了类似 Future 的功能，在构造 ProduceRequestResult 对象时会创建一个大小为 1 的 CountDownLatch 对象，并在调用 `ProduceRequestResult#done` 方法时执行 `CountDownLatch#countDown` 操作，而 `ProduceRequestResult#completed` 方法判定消息发送是否完成的依据就是判定 CountDownLatch 对象值是否等于 0。\n\n### 总结\n\n本文我们介绍了 java 版本的 KafkaProducer 的使用，并深入分析了相关设计和实现。从执行流程上来说，Kafka 生产者运行机制在整体设计上还是比较简单和直观的，但不可否认在实现上也有很多需要注意的细节。Kafka 在老版本的 SDK 中默认使用同步的方式往服务端投递消息，因为采用异步的方式存在消息丢失的问题，直到 0.8.2.0 版本以后才修复了这一问题，并将异步提交设置为默认方式。\n\n了解 KafkaProducer 的设计和实现能够帮助我们在实际开发中更好的使用 Kafka 生产者客户端，知晓如何能够保证消息的强顺序性，以及如何保证消息不丢失，甚至是利用其它编程语言自定义 SDK。下一篇，我们将继续分析消费者的运行机制。\n","tags":["Kafka"],"categories":["kafka"]},{"title":"Kafka 源码解析：架构与核心概念","url":"/2019/06/17/kafka/kafka-architecture/","content":"\n[Apache Kafka](https://kafka.apache.org) 作为分布式消息引擎系统，已经被各大互联网公司广泛引入到生产环境中，主要用于消息的发布订阅、日志数据的采集等，以充当一个公司的数据总线角色。因其具备优良的性能和近乎实时的消息投递能力，并且能够保证消息的顺序性、持久性和完整性（不丢消息），同时引入 topic、partition，以及 group 等精妙的设计理念，所以自开源以来社区一直非常活跃。大厂在引入 Kafka 时，一般会结合公司自身的业务特点在具体落地形式上有所区别（包括在 Kafka 原有基础上扩展和优化，或沿用 Kafka 的设计思想重新设计实现等），但是在思想上仍然是相通的，所以了解 Kafka 的核心设计与实现可以对这些系统举一反三。<!-- more -->\n\n不过发展至今，Kafka 已经不再单纯的只是一个分布式消息引擎系统，今天的 Kafka 已经将自己定位于一个分布式流计算平台（distributed streaming platform）。这主要源自大数据时代以来，流式计算引擎（eg. [Apache Storm](https://storm.apache.org/)、[Apache Spark-Streaming](https://spark.apache.org/streaming/)、[Apache Flink](https://flink.apache.org/)）在企业的技术平台中扮演着越来越重要的角色，提供了将大数据实时变现的能力。考虑到大部分流式计算平台数据源均取自数据总线，所以 Kafka 自然而然也就充当了这些流式计算引擎的上游系统。此外，Kafka 的流式计算模块（Kafka Streams）相对于这些流式计算引擎能够实现端到端的 Exactly-Once 语义，而其它流式计算引擎宣称的 Exactly-Once 语义仅限于引擎内部，所以 Kafka Streams 未来有机会在流式计算领域占有一席之地。\n\n本系列文章主要还是分析 Kafka 消息引擎部分的设计和实现，针对 Kafka Streams 模块，考虑到目前还不够稳定，且具体的落地场景还不是很多，先略过不作分析。\n\n### 架构设计\n\nKafka 在架构设计上可以分为 Producer、Consumer 和 Cluster 三大模块，下图展示了 Producer、Consumer 和 Cluster 模块的交互模式：\n\n![image](/images/2019/kafka-architecture.png)\n\n__Producer__ 模块的实现位于 kafka-clients 中，主要用于接收用户提交的消息数据并投递给 Cluster。在老版本的实现中，Producer 默认采用同步的方式向 Cluster 提交消息数据，所以吞吐量不高。新版本（0.8.2.0 以后）的 Producer 修复了异步提交导致消息数据丢失的问题，并默认采用异步的方式向 Cluster 提交消息数据。新版本的 Producer 对于接收到来自用户的消息数据会先缓存到消息收集器中，同时在后台维护了一个消息发送线程，该线程定期定量的向 Cluster 批量投递消息数据。\n\n__Consumer__ 模块的实现同样位于 kafka-clients 中，主要用于从 Cluster 基于 pull 模式拉取消息进行消费（相对于 push 模式而言，pull 模式虽然在实时性上要差一些，但是因为状态信息由客户端进行维护，所以服务端的压力要小很多），并维护自己消费的 offset。Consumer 具备 group 的概念，一个 group 由多个 Consumer 组成，并订阅一个或多个 topic 进行消费。Kafka 能够保证位于同一个 group 中的消费者在消费同一个 topic 中的消息数据时不重复。此外，一个 group 名下的消费者区分 Leader 和 Follower 角色，并由 1 个 Leader 和多个 Follower 构成。其中 Leader 消费者除了肩负同 Follower 消费者一样从 Cluster 拉取消息进行消费的职责外，还需要管理整个 group 名下所有消费者的状态信息，并在需要时对分配给这些消费者的分区（partition）实施再分配，以保证 1 个消费者消费尽可能少的 topic 分区，同时保证 1 个 topic 分区至多被 1 个消费者消费。\n\n__Cluster__ 即 Kafka 的服务端，主要用于接收并持久化 Producer 发来的消息数据、响应 Consumer 的消息消费请求，以及控制整个集群中各个 broker 节点（可以理解为单台服务器，上面运行着一个 Kafka 服务）的协同运行，下图展示了 Cluster 的主要构成组件：\n\n![image](/images/2019/kafka-cluster.png)\n\n一个 Cluster 一般由多个 broker 节点构成，Kafka 会从中选举一个 broker 节点作为 Leader 角色，并通过节点上运行的 KafkaController 组件控制整个集群中各个 broker 节点的协同运行，以统一对外提供服务。就单个 broker 节点而言，Kafka 会为节点上的每张网卡绑定一个 Acceptor，用于接收来自客户端和其它 broker 节点的连接，Processor 组件会从这些连接中获取请求并交由 Handler 线程进行处理。Handler 基于 KafkaApis 组件解析具体的请求类型并分发给具体的组件，同时负责构造和发送响应结果。\n\n除了上面提及的 KafkaController 组件，Kafka 主要还包括 LogManager、ReplicaManager 和 GroupCoordinator 几大组件。\n\n__LogManager__ 组件主要提供了对日志数据的加载、创建、删除，以及查询等功能，是 Kafka 日志数据管理的核心组件。Kafka 依赖于本地文件系统对日志数据进行存储，为了保证日志数据的可靠性和读写的高性能，引入了副本机制、顺序读写、零拷贝，以及索引等策略，同时在后台维护定时任务对过期或过大的日志数据执行清理操作，并在允许的情况下对 key 相同的消息实施压缩。\n\n__ReplicaManager__ 组件主要负责管理 topic 分区的多个副本。为了避免单点问题导致的日志数据丢失，Kafka 会为每个 topic 分区设置多个副本（包含一个 Leader 角色和多个 Follower 角色），并将这些副本均匀分布在不同的 broker 节点上，理论上这些副本上保存的消息数据应该是一致的。ReplicaManager 提供了对这些副本的管理功能，包括副本角色切换、副本之间的消息数据同步，以及从指定 topic 分区读写日志数据等。\n\n__GroupCoordinator__ 组件主要用于对一个 group 名下的消费者进行协调。在服务运行过程中难免会出现消费者的上下线，以及分区数目的变更，GroupCoordinator 主要负责在必要时对 group 名下的消费者执行分区再分配操作，以保证消费者与 topic 分区之间分配关系的均衡性。\n\n除了上面介绍的这些组件，Kafka 还提供了 Purgatory 组件用于管理延时任务，利用 Authorizer 组件执行权限控制，以及基于 AdminManager 组件对集群进行手动管理等。此外，Kafka 还需要依赖于 ZK 对整个集群中节点的运行达成共识。\n\n后续的文章中会逐一对上面提及的组件进行针对性分析。\n\n### 核心概念\n\n本小节我们介绍一些 Kafka 核心概念，了解这些概念有助于理解 Kafka 的整体设计，也是为后续的文章做铺垫。考虑阅读本系列文章的读者一定对 Kafka 有或多或少的了解，所以对于一些基础的概念（比如 Producer、Consumer，以及 Topic 等）不多做说明。\n\n#### 分区多副本机制\n\nKafka 使用 topic 对消息数据进行组织，每个 topic 可以设置若干个分区，一个 topic 中的消息按照具体的分区策略分布在分区集合中。之所以 Kafka 需要引入分区的概念，主要是希望利用分布式系统中的多节点来提升 Kafka 集群的性能和可扩展性。因为一个 topic 的各个分区可以分布在不同的 broker 节点上，进而就能将 topic 的消息数据分散在这些 broker 节点上存储，对于消息的读写压力就可以由这些节点进行分摊。当我们感知到一个 topic 的消息读写量较大时，我们可以适当增加分区的数目来实现扩容的目的。设想如果我们不引入分区策略，而是由一个 broker 节点完整负责一个 topic，考虑每个 topic 之间的消息数据量和读写量可能存在较大差别，那么各个 broker 节点在负载均衡性上也会有较大的差异，最终影响的是集群整体的可用性。\n\n考虑到分区内消息数据的单点问题，Kafka 为每个分区依据配置会分配多个副本，这些副本数据分散保存在不同的 broker 节点上，一个 broker 节点可以保存成百上千个属于不同 topic 分区的副本。副本分为 Leader 角色和 Follower 角色两类，每个 topic 分区都有一个 Leader 副本，所有生产者和消费者的消息推送和拉取请求都由该副本进行响应。除 Leader 副本以外的副本均为 Follower 副本，Follower 副本不直接处理来自生产者和消费者的请求，其唯一的任务就是从 Leader 副本那里同步消息，以保持与 Leader 副本的数据一致性，并在 Leader 副本失效时竞争成为新的 Leader 角色，以保证对应 topic 的正常运行。\n\n理论上来说，一个 topic 分区各个副本之间的数据应该是一致的，但是考虑到网络的延迟、broker 节点的负载，以及副本角色的切换等因素，Follower 副本中存储的消息数据一般滞后于 Leader 副本中存储的消息数据。但是在一些场景下（一般都是因为副本角色切换），Follower 副本中存储的消息数据甚至会超前于 Leader 副本中存储的消息数据。\n\n__思考__ ：为什么 Kafka 在设计上仅允许 Leader 副本对外提供服务，而不采用经典的读写分离策略（即允许消费者从 Follower 副本读取消息）？\n\n读写分离策略在 MySQL 等数据库领域被广泛应用，能够有效的解决数据库集群的负载压力，但是我们也不能忽略一个前提，即读写分离一般适用于读多写少的场景。如果是读少写多的话，那么主从复制会存在较大的延迟，并且数据库的主要压力集中在 master 节点，读写分离并不能分摊这部分负载。回到 Kafka 本身，作为消息引擎，Kafka 采用发布订阅的模式运行，大部分场景下读和写是几乎是对等的，所以引入读写分离策略并不会带来较大的收益，反而会增加系统设计的复杂度。\n\n此外，Kafka 可以为一个 topic 设置多个分区，这些分区的 Leader 副本一般均匀分散在集群的多个 broker 节点上，所以对于同一个 topic 来说，这一设计已经做到了负载均衡。但是我们仍然不能忽视一种场景，就是一个 topic 的某个分区相对于其它分区的消息量要大很多，这在无意间增加了该分区 Leader 副本所在 broker 节点的压力。此时，我们能够做的就是重新设置合理的分区数目或修改分区选择策略。不过我们也不能否认读写分离策略在一些场景下仍然具备适用性，也许 Kafka 的未来版本会酌情支持。\n\n#### AR & ISR\n\n为了保证在 broker 节点宕机时，由该节点管理的 topic 分区仍然可用，Kafka 一般会为 topic 分区分配多个副本，这些副本称为该 topic 分区的 Assigned Replicas，简称 AR 副本集合。\n\nISR 副本集合是指由一个 topic 分区名下的 In-Sync Replica 副本构成的集合。ISR 集合是 AR 集合的一个子集，如果 AR 集合中的副本能够同时满足以下 2 个条件则有资格加入到 ISR 集合中：\n\n1. 副本所在 broker 节点与 ZK 连接正常，即对应 broker 节点是活跃的。\n2. 副本持有的最新一条消息的 offset 与 Leader 副本最新一条消息的 offset 之间的差值在设定阈值范围内，即 Follower 副本与 Leader 副本之间持有的消息数据差别不大。\n\nISR 集合由每个 topic 分区的 Leader 副本进行维护，Follower 副本在启动之后会从 Leader 副本同步消息数据，当数据之间的差异逐渐变小，直到小于设定的阈值时，该 Follower 副本即有资格被加入到 topic 分区的 ISR 集合中。相反，当 Follower 副本因为某些原因（比如，所在 broker 节点宕机、网络异常等） 逐渐滞后于 Leader 副本时，会被 Leader 副本从 ISR 集合中移除，所以说 ISR 集合中的副本是一个动态变化的过程。\n\n上一小节我们介绍了一个分区的副本由 Leader 和 Follower 角色之分，当 Leader 副本失效时会从 Follower 副本集合中竞选出一个成为新的 Leader，但不是所有的 Follower 副本都适合当 Leader，如果某个 Follower 副本与 Leader 副本之间的消息同步延迟较大，那么该 Follower 副本成为 Leader 之后就会丢失相当一部分消息数据，而 ISR 集合中的 Follower 副本就能够避免这样的问题，这主要得益于下一小节介绍的 HW 值。\n\n__思考__ ：为什么采取 ISR 机制而非一致性协议来保证数据的一致性？\n\n当面临需要维护多个副本的数据一致性时，我们往往会考虑引入 Paxos、Raft 一类的一致性协议，那为什么 Kafka 在设计时不走寻常路呢？个人分析主要包含两方面的原因：\n\n1. Kafka 不需要保持所有副本的数据一致性，因为 Follower 副本在这里仅仅是当 Leader 副本失效时竞选成为新的 Leader 副本以继续提供服务，平时不响应读请求，如果维持所有副本的数据一致性势必会增加对客户端投递消息请求的响应时间（尤其是当一些 broker 节点负载较高的时候），收益不大。\n2. 一致性协议一般采用投票机制，如果允许 n 个副本失效，那么为了保证副本对应的 topic 分区能够继续正常运行，则至少需要设置 2n+1 个副本，也就是说我们至少需要为每个 topic 分区设置 3 个副本才允许有 1 个副本失效，副本数越多对集群的压力也就越大。对于 ISR 机制而言，如果允许 n 个副本失效，则最少只需要设置 n+1 个副本。\n\n#### HW & LEO\n\nHW 和 LEO 是一个副本上两个特殊的 offset 位置，其中 HW 是 High Watermark 的简写，LEO 是 Log End Offset 的简写。\n\nLEO 的概念比较简单，每个副本都有一个 LEO 值，表示当前副本已完成追加的消息的最大 offset 值加 1，即下一条待追加消息的 offset 值。当消费者完成往 Leader 副本追加消息时，Leader 副本的 LEO 值会递增，而当 Follower 副本完成从 Leader 副本拉取消息时，Follower 副本的 LEO 值会递增。\n\nHW 值由 topic 分区的 Leader 副本进行维护，是一个关键的位置值， __消费者在消费当前 topic 分区时只能看见 HW 位置之前的消息（不包括 HW 位置本身）__ 。消费者在将消息提交给 Leader 副本时一般会携带一个 acks 参数，用于指定是否需要服务端对本次请求进行确认，以及在什么情况下进行确认。如果 acks 参数设置为 -1，则表示需要 ISR 集合中的所有 Follower 副本完成对当前消息的同步时，Leader 副本才认为此消息被成功记录到集群，此时 Leader 副本会递增 HW 值。\n\n如果 Leader 副本失效，当从 ISR 集合中选举出新的 Leader 副本时，因为该副本一定保存着 HW 之前的消息数据，所以对消费者来说即使新的 Leader 副本的 LEO 值小于前任 Leader 副本的 LEO 值，消费者也感知不到其中的差别，因为消费者只能看见 HW 之前的消息数据。\n\n#### Offset Topic\n\n在之前版本的 Kafka 设计中依赖 ZK 记录每个 topic 分区的消费 offset 位置，这是一个比较直观的思路，但在实际应用中这一设计因为需要与 ZK 频繁交互，所以在性能和可用性上都受制于 ZK，对于规模较大的集群而言，ZK 面临着巨大的压力。在 0.8.2.2 版本中，Kafka 引入了 native offset storage 机制，使用内建的 topic 替代 ZK 对 offset 信息进行存储，对应的 topic 名称为 `__consumer_offsets`（后续的文章如果不多做说明，均使用 offset topic 进行指代）。Kafka 默认为该 topic 设置了 50 个分区，并为每个分区分配了 3 个副本。为了保证数据不丢失，该 topic 的 acks 参数默认为 -1，即要求所有 ISR 集合中的 Follower 副本对追加的 offset 消息进行确认。\n\n### 总结\n\n本文我们站在整体的角度分析了 Kafka 的架构设计，并对 Kafka 中的一些核心概念和术语进行了介绍，后续的文章中将直接引用这些概念。考虑 0.10 版本之后的 Kafka 在各大功能组件上已经基本稳定（Kafka Streams 除外，1.0 之后的版本主要也是对 Kafka Streams 组件的逐步完善），作为消息引擎已经能够满足生产环境的高可用性和稳定性，并且与 0.11 版本一起作为目前应用最为广泛的版本，所以本系列文章基于 0.10.2.2 版本开始对 Kafka 的整体设计和细节实现进行分析，同时也会在后续对新版本（0.11 之后的版本）中引入的特性逐一进行补充。\n\n### 参考\n\n1. [Apache Kafka从 0.7 到 1.0：那些年我们踩过的坑](https://www.infoq.cn/article/MLMyoWNxqs*MzQX7lvzO)\n","tags":["Kafka"],"categories":["kafka"]},{"title":"基于 CAS 机制的 ConcurrentHashMap 实现内幕","url":"/2019/01/31/java/cas-based-concurrent-hashmap/","content":"\n曾经写过一篇《[基于锁分段机制的 ConcurrentHashMap 实现内幕](/2016/08/16/java/segment-based-concurrent-hashmap/)》的文章，介绍了在 JDK 1.7 之前 ConcurrentHashMap 的实现机制。文章的结尾我们提及到在 JDK 1.8 之后，ConcurrentHashMap 在实现上抛弃了锁分段机制，转而采用 CAS（Compare-And-Swap） 策略，并和 HashMap 一样引入了红黑树的支持。本文我们将基于 JDK 1.8 源码，分析基于 CAS 机制的 ConcurrentHashMap 实现。<!-- more -->\n\n### CAS 机制简述\n\nCAS 属于原子操作的一种，能够保证一次读写操作是原子的。CAS 通过将内存中的值与期望值进行比较，只有在两者相等时才会对内存中的值进行修改。一个 CAS 操作的伪代码实现如下（引用自 [WIKI](https://en.wikipedia.org/wiki/Compare-and-swap)）:\n\n```text\nfunction cas(p : pointer to int, old : int, new : int) returns bool {\n    if *p ≠ old {\n        return false\n    }\n    *p <- new\n    return true\n}\n```\n\nJava 中的 CAS 实现位于 `sun.misc.Unsafe` 类中，该类中定义了大量的 native 方法，CAS 的实现也不例外：\n\n```java\npublic final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x);\npublic final native boolean compareAndSwapInt(Object o, long offset, int expected, int x);\npublic final native boolean compareAndSwapLong(Object o, long offset, long expected, long x);\n```\n\n仅仅从 java 源码层面我们只能看到对应的 native 定义，而具体实现需要依赖于操作系统，这里对方法的参数进行说明：\n\n- __o__ ：目标操作对象。\n- __offset__ ：目标操作数内存偏移地址。\n- __expected__ ：期望值。\n- __x__ ：更新值。\n\nCAS 是支撑 JUC 的基础，除了本文介绍的 ConcurrentHashMap 实现外，典型的应用场景就是 java 中的原子类，例如 AtomicInteger，其中运用了大量的 CAS 操作。CAS 能够在保证性能的同时提供并发场景下的线程安全性，以 `AtomicInteger#getAndSet` 方法为例：\n\n```java\npublic final int getAndSet(int newValue) {\n    return unsafe.getAndSetInt(this, valueOffset, newValue);\n}\n```\n\n该方法原子性的将当前 AtomicInteger 类型的变量值设置为 newValue，并返回修改之前的值。整个过程无需加锁，实现上依赖于 `Unsafe#getAndSetInt` 方法，其中 valueOffset 变量是当前 AtomicInteger 类型变量值的内存偏移地址：\n\n```java\npublic final int getAndSetInt(Object var1, long var2, int var4) {\n    int var5;\n    do {\n        var5 = this.getIntVolatile(var1, var2);\n    } while(!this.compareAndSwapInt(var1, var2, var5, var4));\n    return var5;\n}\n```\n\n方法 `Unsafe#getAndSetInt` 首先会获取当前 AtomicInteger 类型变量的值，然后基于 CAS 更新变量值为 newValue。\n\nCAS 机制虽然无需加锁、安全且高效，但也存在一些缺点，概括如下：\n\n1. 循环检查的时间可能较长，不过可以限制循环检查的次数。\n2. 只能对一个共享变量执行原子操作。\n3. 存在 ABA 问题。\n\n所谓 ABA 问题是指在 CAS 两次检查操作期间，目标变量的值由 A 变为 B，又变回 A，但是 CAS 看不到这中间的变换，对它来说目标变量的值并没有发生变化，一直是 A，所以 CAS 操作会继续更新目标变量的值。大部分时候该问题并不会对结果产生实质性影响，如果确实需要关心该问题（例如 lock-free 算法），可以为目标变量引入版本特性，例如 AtomicStampedReference 工具类通过为引用建立类似版本号（stamp）的方式，来解决 ABA 问题。\n\n### ConcurrentHashMap 实现内幕\n\nJDK 1.7 之前，ConcurrentHashMap 通过加锁保证线程安全，并引入锁分段机制以减小加锁的粒度，从而提升性能。JDK 1.8 中的 ConcurrentHashMap 实现则引入了 CAS 机制以尽量避免加锁操作，虽然仍然有部分同步代码，不过锁的粒度相对于分段锁而言更加细。另外一个重要的设计就是在结点个数达到阈值时会自动将链表转换成红黑树，从而进一步提升性能。\n\n#### 存储结构设计\n\n在存储结构设计上，新的 ConcurrentHashMap 相对于之前看起来更加的简洁。如下图，在一个 Node 类型的数组（下文如不做特殊说明，均使用 table 指代该数组）上挂载着多个链表和红黑树（下文如不做特殊说明，均使用 bin 指代一个完整的链表或红黑树）：\n\n![image](/images/2019/concurrent_hashmap.png)\n\n在结点类型上主要包含：\n\n- `Node<K, V>`：基本结点数据结构，用于存储 key、value，以及结点的哈希值。\n- `ForwardingNode<K, V>`：扩容节点，哈希值始终为 -1，在扩容过程中作为一个占位符表示当前结点为 null，或正在迁移。\n- `ReservationNode<K, V>`：同样是一个占位符结点，哈希值始终为 -3，用于 `computeIfAbsent` 和 `compute` 操作。\n- `TreeNode<K, V>`：红黑树结点，除了包含基本的 key、value，以及结点哈希值外，还定义了红黑树结点特有的指针，以及结点颜色标记。\n- `TreeBin<K, V>`：封装红黑树相关的操作。\n\nConcurrentHashMap 针对 ForwardingNode、ReservationNode，以及树根结点都定义了特定的哈希值：\n\n```java\n/** ForwardingNode 结点的 hash 值 */\nstatic final int MOVED = -1; // hash for forwarding nodes\n\n/** 树根结点的 hash 值 */\nstatic final int TREEBIN = -2; // hash for roots of trees\n\n/** ReservationNode 结点的 hash 值 */\nstatic final int RESERVED = -3; // hash for transient reservations\n```\n\n#### 基本方法实现\n\n##### 工具方法\n\nConcurrentHashMap 主要定义了 3 个工具方法：tabAt、casTabAt 和 setTabAt。\n\n- __tabAt__ ：用于获取 table 上下标为 i 的头结点，实现上依赖 Unsafe 类。\n\n```java\nstatic final <K, V> Node<K, V> tabAt(Node<K, V>[] tab, int i) {\n    return (Node<K, V>) U.getObjectVolatile(tab, ((long) i << ASHIFT) + ABASE);\n}\n```\n\n- __casTabAt__ ：基于 CAS 尝试更新 table 上下标为 i 的结点的值为 v。\n\n```java\nstatic final <K, V> boolean casTabAt(Node<K, V>[] tab, int i, Node<K, V> c, Node<K, V> v) {\n    return U.compareAndSwapObject(tab, ((long) i << ASHIFT) + ABASE, c, v);\n}\n```\n\n- __setTabAt__ ：用于设置 table 上下标为 i 的结点为 v，相对于 casTabAt 方法的区别在于不关注历史值。\n\n```java\nstatic final <K, V> void setTabAt(Node<K, V>[] tab, int i, Node<K, V> v) {\n    U.putObjectVolatile(tab, ((long) i << ASHIFT) + ABASE, v);\n}\n```\n\n##### 构造方法\n\nConcurrentHashMap 的构造方法存在多个重载版本，对应的最底层版本实现如下：\n\n```java\npublic ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) {\n    if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0) {\n        throw new IllegalArgumentException();\n    }\n    // Use at least as many bins\n    if (initialCapacity < concurrencyLevel) {\n        // 如果指定初始化容量小于并行度，则修正初始化容量设置\n        initialCapacity = concurrencyLevel;   // as estimated threads\n    }\n    // 计算大于当前指定初始容量的最小 2 次幂\n    long size = (long) (1.0 + (long) initialCapacity / loadFactor);\n    int cap = (size >= (long) MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int) size);\n    this.sizeCtl = cap;\n}\n```\n\n该构造方法允许我们指定初始化容量（initialCapacity）、负载因子（loadFactor），以及并行度（concurrencyLevel），并依据这些参数计算 sizeCtl 值。类实例变量 sizeCtl 是一个核心变量，用于控制 table 的初始化和扩容策略，该变量的值定义了几种不同的语义：\n\n- -1：表示正在初始化。\n- -N：表示有 N-1 个线程正在执行扩容操作。\n- 0：表示还未执行初始化。\n- N：表示初始化或下次扩容的大小。\n\n##### 添加或更新键值对\n\n方法 put 用于往 ConcurrentHashMap 中添加或更新键值对，这是 map 集合的基础操作，实现如下：\n\n```java\npublic V put(K key, V value) {\n    return this.putVal(key, value, false);\n}\n\nfinal V putVal(K key, V value, boolean onlyIfAbsent) {\n    // key 或 value 不允许为 null\n    if (key == null || value == null) {\n        throw new NullPointerException();\n    }\n    // 计算 key 的哈希码\n    int hash = spread(key.hashCode());\n    int binCount = 0;\n    for (Node<K, V>[] tab = table; ; ) {\n        Node<K, V> f;\n        int n, i, fh;\n        // 1. 如果 table 数组为空，则进行初始化\n        if (tab == null || (n = tab.length) == 0) {\n            // 基于 CAS 策略初始化 table，初始化大小为 16\n            tab = this.initTable();\n        }\n        // 2. 否则，计算 hash 值对应的下标，获取 table 上对应下标的头结点\n        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {\n            /*\n             * table 对应下标的头结点为 null\n             * 基于 CAS 设置结点，如果成功则本次 put 操作完成，\n             * 如果失败则说明期间有存在竞争，需要进入一轮新的循环\n             */\n            if (casTabAt(tab, i, null, new Node<>(hash, key, value, null))) {\n                // 设置结点成功，put 操作完成\n                break; // no lock when adding to empty bin\n            }\n        }\n        // 3. 否则，如果 Map 正在执行扩容操作（MOVED 哈希值表示正在扩容），则帮助扩容\n        else if ((fh = f.hash) == MOVED) {\n            tab = this.helpTransfer(tab, f);\n        }\n        // 4. 否则，获取到 hash 值对应下标的头结点，且结点不为 null\n        else {\n            V oldVal = null;\n            // 同一个槽位内的操作仍然需要通过加锁保证线程安全\n            synchronized (f) {\n                // 保证头结点 f 未发生变更\n                if (tabAt(tab, i) == f) {\n                    // 头结点的哈希值大于等于 0，说明是链表，如果是树的话应该是 -2\n                    if (fh >= 0) {\n                        binCount = 1;\n                        for (Node<K, V> e = f; ; ++binCount) {\n                            K ek;\n                            // 如果是已经存在的 key，则在允许覆盖的前提下直接覆盖已有的值\n                            if (e.hash == hash &&\n                                    ((ek = e.key) == key || (ek != null && key.equals(ek)))) {\n                                oldVal = e.val;\n                                if (!onlyIfAbsent) {\n                                    e.val = value;\n                                }\n                                break;\n                            }\n                            // 如果是不存在的 key，则直接在链表尾部插入一个新的结点\n                            Node<K, V> pred = e;\n                            if ((e = e.next) == null) {\n                                pred.next = new Node<>(hash, key, value, null);\n                                break;\n                            }\n                        }\n                    }\n                    // 红黑树\n                    else if (f instanceof TreeBin) {\n                        Node<K, V> p;\n                        binCount = 2;\n                        // 调用红黑树的方法获取到修改的结点，并插入或更新结点（如果允许）\n                        if ((p = ((TreeBin<K, V>) f).putTreeVal(hash, key, value)) != null) {\n                            oldVal = p.val;\n                            if (!onlyIfAbsent) {\n                                p.val = value;\n                            }\n                        }\n                    }\n                }\n            }\n            if (binCount != 0) {\n                if (binCount >= TREEIFY_THRESHOLD) {\n                    /*\n                     * 结点数目大于等于 8，对链表执行转换操作\n                     * - 如果 table 长度小于 64，则执行扩容\n                     * - 如果 table 长度大于等于 64，则转换成红黑树\n                     */\n                    this.treeifyBin(tab, i);\n                }\n                if (oldVal != null) {\n                    return oldVal;\n                }\n                break;\n            }\n        }\n    }\n    // size 加 1\n    this.addCount(1L, binCount);\n    return null;\n}\n```\n\n上述方法的执行流程可以概括为：\n\n1. 计算 key 的哈希值；\n2. 如果 table 为空，则执行初始化；\n3. 否则，计算 key 哈希值对应的下标，并获取 table 中对应下标的头结点；\n4. 如果头结点为 null，则基于 CAS 尝试添加头结点；\n5. 否则，如果头结点不为 null，但是头结点的哈希值为 MOVED，说明目前正在执行扩容 table 的操作，则帮助扩容；\n6. 否则，如果头结点不为 null，且未处于扩容状态，则尝试添加或更新结点；\n7. 判断当前 bin 范围内结点数目是否大于阈值，如果大于阈值则执行扩容 table 的操作。\n\n下面就流程中的一些关键点展开作进一步分析。\n\n###### 初始化 table\n\nTable 的初始化采用延迟策略，在我们构造 ConcurrentHashMap 对象时只是初始化了一些参数值，并没有对 table 进行构造，而 table 的初始化发生在第一次使用 table 时，例如这里 put 方法。\n\n初始化 table 的过程位于 `ConcurrentHashMap#initTable` 方法中，实现如下：\n\n```java\nprivate final Node<K, V>[] initTable() {\n    Node<K, V>[] tab;\n    int sc;\n    while ((tab = table) == null || tab.length == 0) {\n        // sizeCtl 为负数表示正在初始化或扩容，等待\n        if ((sc = sizeCtl) < 0) {\n            Thread.yield(); // lost initialization race; just spin\n        }\n        // 执行 CAS 操作，期望将 sizeCtl 设置为 -1，-1 表示正在初始化\n        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {\n            try {\n                // 对 table 进行初始化，初始化长度为指定值，默认为 16\n                if ((tab = table) == null || tab.length == 0) {\n                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;\n                    @SuppressWarnings(\"unchecked\")\n                    Node<K, V>[] nt = (Node<K, V>[]) new Node<?, ?>[n];\n                    table = tab = nt;\n                    // 指定下次扩容的长度，相当于 0.75 × n\n                    sc = n - (n >>> 2);\n                }\n            } finally {\n                sizeCtl = sc;\n            }\n            break;\n        }\n    }\n    return tab;\n}\n```\n\nTable 本质上就是一个 Node 数组，其初始化过程也就是对 Node 数组的初始化过程，方法中使用了 CAS 策略控制线程初始化操作之间的竞争。初始化 table 的执行流程可以概括为：\n\n1. 判断 sizeCtl 值是否小于 0，如果小于 0 则表示 ConcurrentHashMap 正在执行初始化操作，所以需要先等待一会，如果其它线程初始化失败还可以顶替上去；\n2. 如果 sizeCtl 值大于等于 0，则基于 CAS 策略抢占标记 sizeCtl 为 -1，表示 ConcurrentHashMap 正在执行初始化，然后构造 table，并更新 sizeCtl 的值。\n\n###### 协助扩容\n\n在 put 过程中，如果当前头结点的哈希值为 MOVED，则说明 ConcurrentHashMap 正在对结点执行扩容操作，此时可以让当前线程加入到扩容工作中协助扩容。该过程由 `ConcurrentHashMap#helpTransfer` 方法实现：\n\n```java\nfinal Node<K, V>[] helpTransfer(Node<K, V>[] tab, Node<K, V> f) {\n    Node<K, V>[] nextTab;\n    int sc;\n    // 当前结点是 ForwardingNode 类型，表示正在迁移中\n    if (tab != null && (f instanceof ForwardingNode) &&\n            (nextTab = ((ForwardingNode<K, V>) f).nextTable) != null) {\n        int rs = resizeStamp(tab.length);\n        // 有 sc-1 个线程正在执行扩容操作\n        while (nextTab == nextTable && table == tab && (sc = sizeCtl) < 0) {\n            if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                    sc == rs + MAX_RESIZERS || transferIndex <= 0) {\n                break;\n            }\n            // 添加一个线程执行 transfer 任务\n            if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {\n                this.transfer(tab, nextTab);\n                break;\n            }\n        }\n        return nextTab;\n    }\n    return table;\n}\n```\n\n该方法的主要作用是基于 CAS 尝试添加一个线程去协助扩容操作，如果能够成功加入则将 sizeCtl 值加 1。方法 `ConcurrentHashMap#transfer` 是真正执行扩容操作的地方，并在多个步骤中被触发，这里先了解一下该方法的参数，后文再对具体实现展开分析。\n\n该方法接收 2 个参数，其中第一个参数 tab 是当前需要被扩容的 table，而第二个参数 nextTab 则表示扩容之后的 table，容量上是之前的两倍。上述方法传递的 nextTab 是一个非 null 值，因为触发 helpTransfer 的前提就是当前已经处于扩容阶段。\n\n###### 链表转红黑树\n\nConcurrentHashMap 在设计上并不是一上来就在 table 上建立红黑树数据结构作为 bin，而是先建立一个链表，并在链表长度与 table 长度均达到一定的阈值时才执行转换，即将链表转换成红黑树：\n\n```java\nprivate final void treeifyBin(Node<K, V>[] tab, int index) {\n    Node<K, V> b;\n    int n, sc;\n    if (tab != null) {\n        // 1. 如果 table 长度小于 64，先对 table 执行扩容操作\n        if ((n = tab.length) < MIN_TREEIFY_CAPACITY) {\n            this.tryPresize(n << 1);\n        }\n        // 2. 否则，将指定位置的链表转换成红黑树，头结点 hash 大于 0，说明是链表\n        else if ((b = tabAt(tab, index)) != null && b.hash >= 0) {\n            synchronized (b) {\n                if (tabAt(tab, index) == b) {\n                    TreeNode<K, V> hd = null, tl = null;\n                    // 将链表转换成一棵红黑树\n                    for (Node<K, V> e = b; e != null; e = e.next) {\n                        TreeNode<K, V> p = new TreeNode<>(e.hash, e.key, e.val, null, null);\n                        if ((p.prev = tl) == null) {\n                            hd = p;\n                        } else {\n                            tl.next = p;\n                        }\n                        tl = p;\n                    }\n                    // 将红黑树设置到 table 对应的位置\n                    setTabAt(tab, index, new TreeBin<>(hd));\n                }\n            }\n        }\n    }\n}\n```\n\n上述方法默认会在链表长度大于等于 8 时触发，此时并没有直接执行转换操作，而是先判断当前 table 的长度是否小于 64，如果小于则先尝试扩容操作，否则才会将链表转换成红黑树。如果是扩容的话会基于 CAS 尝试将 sizeCtl 的值设置为 `(rs << RESIZE_STAMP_SHIFT) + 2`，然后调用 `ConcurrentHashMap#transfer` 方法执行扩容，该过程由 `ConcurrentHashMap#tryPresize` 方法实现：\n\n```java\nprivate final void tryPresize(int size) {\n    // 如果当前期望的大小（size）小于最大允许容量的一半，则扩容大小为 size 的 1.5 倍加 1，在向上取最小的 2 次幂\n    int c = (size >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size >>> 1) + 1);\n    int sc;\n    // 检查当前未处于扩容阶段\n    while ((sc = sizeCtl) >= 0) {\n        Node<K, V>[] tab = table;\n        int n;\n        // 初始化 nextTable\n        if (tab == null || (n = tab.length) == 0) {\n            n = (sc > c) ? sc : c;\n            if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {\n                try {\n                    if (table == tab) {\n                        @SuppressWarnings(\"unchecked\")\n                        Node<K, V>[] nt = (Node<K, V>[]) new Node<?, ?>[n];\n                        table = nt;\n                        sc = n - (n >>> 2);\n                    }\n                } finally {\n                    sizeCtl = sc;\n                }\n            }\n        } else if (c <= sc || n >= MAXIMUM_CAPACITY) {\n            break;\n        } else if (tab == table) {\n            int rs = resizeStamp(n);\n            // 2. 基于 CAS 将 sc 的值加 1，然后执行 transfer 方法\n            if (sc < 0) {\n                Node<K, V>[] nt;\n                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                        sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||\n                        transferIndex <= 0) {\n                    break;\n                }\n                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {\n                    // 执行 transfer 方法\n                    this.transfer(tab, nt);\n                }\n            }\n            // 1. 基于 CAS 将 sizeCtl 的值设置为 (rs << RESIZE_STAMP_SHIFT) + 2\n            else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)) {\n                // 执行 transfer 方法，此时 nextTable 是 null\n                this.transfer(tab, null);\n            }\n        }\n    }\n}\n```\n\n上述方法的核心操作在于添加 transfer 任务，并设置 sizeCtl 值。该方法第一次调用 transfer 方法时 sizeCtl 一定是大于等于 0 的，所以会尝试将 sizeCtl 设置为 `(rs << RESIZE_STAMP_SHIFT) + 2`，这是一个大负数，并执行 `transfer(tab, null)` 操作。后面的循环 sizeCtl 均小于 0，所以会执行 `transfer(tab, nt)`，并将 sizeCtl 加 1。注意整个过程中 sizeCtl 值的变化，在一次扩容操作中第一次调用 transfer 方法时将 sizeCtl 设置为 `(rs << RESIZE_STAMP_SHIFT) + 2`，并在扩容过程再次调用 transfer 方法时将 sizeCtl 加 1，这对于下一节理解扩容操作什么时候结束至关重要。\n\n###### 扩容操作\n\n扩容操作简单地说就是新建一个长度翻倍的 nextTable，然后将之前 table 上的结点重新哈希迁移到新的 nextTable 上，并在迁移完成之后使用 nextTable 替换原先的 table。对于一个 table 而言，上面分布着 n 个 bin 结点，而结点迁移的过程可以是并发的，这样可以提升迁移的效率。ConcurrentHashMap 使用了一个 stride 变量用于指定将 stride 个 bin 结点组成一个任务单元由一个线程负责处理，在单核 CPU 下 stride 的值为 table 的长度 n，在多核 CPU 下为 `(n >>> 3) / NCPU`，最小值为 16。\n\nConcurrentHashMap 定义了一个类实例变量 transferIndex，用于指定任务的边界。任务划分的过程在 table 上是从后往前进行的，例如现在有 n 个结点，则编号 `（n-1-stride, ..., n-1）` 的任务交给第 1 个线程进行处理，编号 `（n-1-2*stride, ..., n-1-stride）` 的任务交给第 2 个线程进行处理，以此类推。当有新的线程加入时可以依据 transferIndex 值知道接下去应该分配哪一块的 bin 结点给当前线程。\n\n整个扩容的核心实现位于 `ConcurrentHashMap#transfer` 方法中，我们在前面的分析中多次提及到该方法，实现如下：\n\n```java\nprivate final void transfer(Node<K, V>[] tab, Node<K, V>[] nextTab) {\n    int n = tab.length, stride;\n    // stride 即步进，在单核下为 table 的长度 n，在多核模式下为 (n >>> 3) / NCPU，最小值为 16\n    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE) {\n        stride = MIN_TRANSFER_STRIDE; // subdivide range\n    }\n\n    // 1. 如果 nextTable 未初始化，则先进行初始化，容量是之前的两倍\n    if (nextTab == null) {            // initiating\n        try {\n            @SuppressWarnings(\"unchecked\")\n            Node<K, V>[] nt = (Node<K, V>[]) new Node<?, ?>[n << 1];\n            nextTab = nt;\n        } catch (Throwable ex) {      // try to cope with OOME\n            sizeCtl = Integer.MAX_VALUE;\n            return;\n        }\n        nextTable = nextTab;\n        transferIndex = n;\n    }\n\n    // 2. 执行迁移工作\n\n    int nextn = nextTab.length;\n    // ForwardingNode 表示一个正在被迁移的结点，对应的 hash 值是 MOVED\n    ForwardingNode<K, V> fwd = new ForwardingNode<>(nextTab);\n    // 标记一个结点是否迁移完成\n    boolean advance = true;\n    // 标记扩容任务是否完成\n    boolean finishing = false; // to ensure sweep before committing nextTab\n    // i 是索引，bound 是边界值，从后往前迁移\n    for (int i = 0, bound = 0; ; ) {\n        Node<K, V> f;\n        int fh;\n        /*\n         * 2.1 基于 CAS 计算本次任务的边界值，即 i 和 bound 值，\n         *     将 i 指向 transferIndex，将 bound 指向 transferIndex - stride\n         */\n        while (advance) {\n            int nextIndex, nextBound;\n            // 标记当前结点迁移完成\n            if (--i >= bound || finishing) {\n                advance = false;\n            }\n            // 一旦 transferIndex <= 0，表示所有任务已经分配给相应的线程进行处理\n            else if ((nextIndex = transferIndex) <= 0) {\n                i = -1;\n                advance = false;\n            }\n            // 基于 CAS 计算 transferIndex 值（即 transferIndex - stride），nextBound 是本次任务的边界\n            else if (U.compareAndSwapInt(\n                    this,\n                    TRANSFERINDEX,\n                    nextIndex,\n                    nextBound = (nextIndex > stride ? nextIndex - stride : 0))) {\n                bound = nextBound;\n                i = nextIndex - 1;\n                advance = false;\n            }\n        }\n\n        // 2.2 执行迁移任务\n\n        if (i < 0 || i >= n || i + n >= nextn) {\n            int sc;\n            // 完成了所有结点的迁移\n            if (finishing) {\n                nextTable = null;\n                // 更新 table 为 nextTable\n                table = nextTab;\n                // sizeCtl 值更新为 table 长度的 1.5 倍\n                sizeCtl = (n << 1) - (n >>> 1);\n                return;\n            }\n\n            // 任务继续\n\n            /*\n             * 基于 CAS 将 sizeCtl 减 1\n             * 在迁移操作开始前会将 sizeCtl 设置为 (rs << RESIZE_STAMP_SHIFT) + 2，每一个线程加入迁移任务就会将 sizeCtl 加 1，\n             * 所以这里执行 sizeCtl 减 1，代表当前任务完成\n             */\n            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {\n                // 当前任务结束，但是整体任务还未完成\n                if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT) {\n                    return;\n                }\n                // 此时 sizeCtl == (rs << RESIZE_STAMP_SHIFT) + 2，说明所有的任务都执行完了\n                finishing = advance = true;\n                i = n; // recheck before commit\n            }\n        }\n        // 否则，获取 table 中位置为 i 的头结点，且为 null\n        else if ((f = tabAt(tab, i)) == null) {\n            // 在当前位置设置一个空的 ForwardingNode 节点\n            advance = casTabAt(tab, i, null, fwd);\n        }\n        // 否则，当前位置已经是一个 ForwardingNode，代表正在执行迁移工作\n        else if ((fh = f.hash) == MOVED) {\n            advance = true; // already processed\n        }\n        // 否则，开始对当前结点执行迁移工作\n        else {\n            synchronized (f) {\n                // 再次校验结点\n                if (tabAt(tab, i) == f) {\n                    Node<K, V> ln, hn;\n                    // 当前 bin 是一个链表\n                    if (fh >= 0) {\n                        int runBit = fh & n; // n 为老 table 的长度\n                        Node<K, V> lastRun = f;\n                        // 遍历当前链表，找到最后 p.hash & n 值相同的第一个结点\n                        for (Node<K, V> p = f.next; p != null; p = p.next) {\n                            int b = p.hash & n;\n                            if (b != runBit) {\n                                runBit = b;\n                                lastRun = p;\n                            }\n                        }\n\n                        // runBit == 0 表示还在老 table 原先的位置\n                        if (runBit == 0) {\n                            ln = lastRun;\n                            hn = null;\n                        }\n                        // 此处 runBit 等于老 table 的长度，即 n\n                        else {\n                            hn = lastRun;\n                            ln = null;\n                        }\n                        // 以 lastRun 为界\n                        for (Node<K, V> p = f; p != lastRun; p = p.next) {\n                            int ph = p.hash;\n                            K pk = p.key;\n                            V pv = p.val;\n                            if ((ph & n) == 0) {\n                                ln = new Node<>(ph, pk, pv, ln);\n                            } else {\n                                hn = new Node<>(ph, pk, pv, hn);\n                            }\n                        }\n                        // 将其中一个链表放置在 nextTable 的 i 位置\n                        setTabAt(nextTab, i, ln);\n                        // 将另外一个链表放置在 nextTable 的 i+n 位置\n                        setTabAt(nextTab, i + n, hn);\n                        // 设置当前 table 的 i 位置为 ForwardingNode 空结点，代表已经处理完\n                        setTabAt(tab, i, fwd);\n                        advance = true;\n                    }\n                    // 当前 bin 是一颗红黑树\n                    else if (f instanceof TreeBin) {\n                        TreeBin<K, V> t = (TreeBin<K, V>) f;\n                        TreeNode<K, V> lo = null, loTail = null;\n                        TreeNode<K, V> hi = null, hiTail = null;\n                        int lc = 0, hc = 0;\n                        for (Node<K, V> e = t.first; e != null; e = e.next) {\n                            int h = e.hash;\n                            TreeNode<K, V> p = new TreeNode<>(h, e.key, e.val, null, null);\n                            if ((h & n) == 0) {\n                                if ((p.prev = loTail) == null) {\n                                    lo = p;\n                                } else {\n                                    loTail.next = p;\n                                }\n                                loTail = p;\n                                ++lc;\n                            } else {\n                                if ((p.prev = hiTail) == null) {\n                                    hi = p;\n                                } else {\n                                    hiTail.next = p;\n                                }\n                                hiTail = p;\n                                ++hc;\n                            }\n                        }\n\n                        /* 如果将红黑树一分为二后，结点数目小于 6，则将红黑树转换成链表 */\n\n                        ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin<>(lo) : t;\n                        hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin<>(hi) : t;\n\n                        // 将其中一个红黑树（或链表）放置在 nextTable 的 i 位置\n                        setTabAt(nextTab, i, ln);\n                        // 将另外一个红黑树（或链表）放置在 nextTable 的 i+n 位置\n                        setTabAt(nextTab, i + n, hn);\n                        // 设置当前 table 的 i 位置为 ForwardingNode 空结点，代表已经处理完\n                        setTabAt(tab, i, fwd);\n                        advance = true;\n                    }\n                }\n            }\n        }\n    }\n}\n```\n\n方法的实现很复杂，不过整体流程可以概括为 2 大步骤：\n\n1. 如果 nextTable 未初始化，则先执行初始化操作，新的 table 容量翻倍；\n2. 执行迁移任务。\n\n其中步骤 1 比较简单，不过需要注意的是并不是所有触发 transfer 方法都需要执行初始化 table 的操作，只有主动触发扩容的线程需要执行该操作，对于后来加入“帮忙”的线程会跳过步骤 1，直接进入步骤 2。\n\n步骤 2 通过 transferIndex 实例变量协调任务的分配，并为每个线程分配 stride 个结点进行迁移，任务分配的过程实际上就是确定当前线程迁移结点的上下界的过程，该过程位于 while 循环中（即代码注释 2.1）。该循环整体上就是一个 CAS 操作，如果迁移任务已经完成，或者没有剩余的结点可以迁移（实例变量 transferIndex 小于等于 0），则退出 CAS，否则尝试为本次任务分配新的上下界，同时更新 transferIndex 值。\n\n接下来正式开始迁移工作，整体流程可以概括为：\n\n1. 检查整体迁移任务是否完成，如果完成则更新 table 和 sizeCtl 值；\n2. 否则，检查当前任务是否已经完成，如果完成则退出本次任务；\n3. 对于仍在进行中的任务会继续执行迁移操作，如果当前结点是一个空结点，则在该位置设置一个空的 ForwardingNode 结点，用于标记当前结点正在迁移中；\n4. 否则，如果当前结点是一个 ForwardingNode 结点，即当前结点正在迁移中，进入下一轮任务分配；\n5. 否则，对当前结点执行迁移操作。\n\n下面针对流程中的一些关键点进行说明，首先来看一下步骤 2 相关的代码：\n\n```java\n/*\n * 基于 CAS 将 sizeCtl 减 1\n * 在迁移操作开始前会将 sizeCtl 设置为 (rs << RESIZE_STAMP_SHIFT) + 2，每一个线程加入迁移任务就会将 sizeCtl 加 1，\n * 所以这里执行 sizeCtl 减 1，代表当前任务完成\n */\nif (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {\n    // 当前任务结束，但是整体任务还未完成\n    if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT) {\n        return;\n    }\n    // 此时 sizeCtl == (rs << RESIZE_STAMP_SHIFT) + 2，说明所有的任务都执行完了\n    finishing = advance = true;\n    i = n; // recheck before commit\n}\n```\n\n前面我们曾提到当新增一个线程支持迁移任务时会执行 `U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)` 操作，并且在扩容操作开始前会设置 sizeCtl 的值为 `(rs << RESIZE_STAMP_SHIFT) + 2`，而这里在完成一个任务的时候会执行 `U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)` 操作将 sizeCtl 的值减 1。上面的代码会判定当前 sizeCtl 值是否等于 `(rs << RESIZE_STAMP_SHIFT) + 2`，如果相等则说明整体扩容任务完成，否则仅说明当前任务完成，将线程任务数减 1。\n\n接下来我们继续来看一个结点迁移的过程，迁移区分链表和红黑树，不过基本思想是想通的，这里以链表为例进行说明，相关实现如下：\n\n```java\n// 当前 bin 是一个链表\nif (fh >= 0) {\n    int runBit = fh & n; // n 为老 table 的长度\n    Node<K, V> lastRun = f;\n    // 遍历当前链表，找到最后 p.hash & n 值相同的第一个结点\n    for (Node<K, V> p = f.next; p != null; p = p.next) {\n        int b = p.hash & n;\n        if (b != runBit) {\n            runBit = b;\n            lastRun = p;\n        }\n    }\n\n    // runBit == 0 表示还在老 table 原先的位置\n    if (runBit == 0) {\n        ln = lastRun;\n        hn = null;\n    }\n    // 此处 runBit 等于老 table 的长度，即 n\n    else {\n        hn = lastRun;\n        ln = null;\n    }\n    // 以 lastRun 为界\n    for (Node<K, V> p = f; p != lastRun; p = p.next) {\n        int ph = p.hash;\n        K pk = p.key;\n        V pv = p.val;\n        if ((ph & n) == 0) {\n            ln = new Node<>(ph, pk, pv, ln);\n        } else {\n            hn = new Node<>(ph, pk, pv, hn);\n        }\n    }\n    // 将其中一个链表放置在 nextTable 的 i 位置\n    setTabAt(nextTab, i, ln);\n    // 将另外一个链表放置在 nextTable 的 i+n 位置\n    setTabAt(nextTab, i + n, hn);\n    // 设置当前 table 的 i 位置为 ForwardingNode 空结点，代表已经处理完\n    setTabAt(tab, i, fwd);\n    advance = true;\n}\n```\n\n这一段代码如果希望更好的理解，建议自己模拟一个 table，并 debug 一下执行流程。其实也不难，这段代码的工作就是将一个链表拆分成两个链表，并将它们插入到新 table 适当的位置。假设老的 table 长度为 16，那么上面的实现有一个巧妙的地方在于对链表中所有结点的哈希值执行 `p.hash & n` 操作，其结果不是 0 就是 16（老 table 的长度）。所以我们可以依据 `p.hash & n` 的值将一个链表拆分成两个链表，其中值均为 0 的结点构成的链表仍然放置在新 table 的当前位置 i，而值均为 16 的结点构成的链表则放置在新的位置，即 i + 16。变量 lastRun 所表示的结点实际上是最后几个具备相同 `p.hash & n` 值的连续结点的最左边结点，因为这样可以减少该结点右边几个结点的迁移工作，因为它们具备相同的 `p.hash & n` 值，自然也就位于同一个链表上。\n\n##### 获取指定键值\n\n方法 put 的执行流程可以加深我们对于 ConcurrentHashMap 存储结构的理解，而理解了 ConcurrentHashMap 的存储结构，那么分析 get 方法的运行机制也是水到渠成的事情，实现如下：\n\n```java\npublic V get(Object key) {\n    Node<K, V>[] tab;\n    Node<K, V> e, p;\n    int n, eh;\n    K ek;\n    // 计算 key 的 hash 值\n    int h = spread(key.hashCode());\n    // table 表不为空，且 key 对应的 table 头结点存在\n    if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) {\n        if ((eh = e.hash) == h) {\n            // 找到对应的 key，返回 value\n            if ((ek = e.key) == key || (ek != null && key.equals(ek))) {\n                return e.val;\n            }\n        }\n        // 当前 bin 为红黑树，执行 find 方法检索\n        else if (eh < 0) {\n            return (p = e.find(h, key)) != null ? p.val : null;\n        }\n        // 当前 bin 是链表，直接遍历检索\n        while ((e = e.next) != null) {\n            if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek)))) {\n                return e.val;\n            }\n        }\n    }\n    return null;\n}\n```\n\n上述方法首先依据相同的实现计算 key 的哈希值，然后定位 key 在 table 中的 bin 位置。如果 bin 结点存在，则依据当前 bin 类型（链表或红黑树）检索目标值。\n\n### 参考\n\n1. JDK 1.8 源码\n2. [Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析](https://javadoop.com/post/hashmap)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"JMockit：单元测试利器","url":"/2019/01/14/java/jmockit/","content":"\n单元测试（UT: Unit Test）是保证服务质量的基础。在实际项目的 UT 开发中，我们通常需要执行第三方服务调用、连接数据库等操作，为了让 UT 能够正常运行起来，我们需要执行大量的环境准备工作，这些工作有时比 UT 本身还要费时费力很多，而 mock 机制则能够帮助我们绕开这些必要但不一定要真正需要去做的事情，隔离 UT 与服务的依赖，模拟我们期望的行为和数据。<!-- more -->\n\n在 java 生态系统中，有多种 mock 组件可供选择，包括：[EasyMock](http://easymock.org/)、[JMock](http://jmock.org/)、[mockito](https://site.mockito.org/)、[unitils](http://www.unitils.org/summary.html)、[PowerMock](http://www.powermock.org)，以及 [JMockit](http://jmockit.github.io/)等。本文将要介绍的 JMockit 组件是众多 mock 组件中最为强大的一个。\n\n> - jmockit version: 1.44\n> - junit version: 4.12\n\n### 录制 & 重放 & 验证\n\n录制（record）、重放（replay）和验证（verify）是 JMockit 的设计哲学（下文如果不做特殊说明，均使用 RRV 进行指代），这三个步骤各自所担负的责任如下：\n\n- __录制__ ：录制目标方法的期望行为，依据条件返回期望的数据，或者抛出异常。\n- __重放__ ：当执行测试逻辑时，之前录制的行为会被触发，所谓的重放是应用之前录制的行为。\n- __验证__ ：验证被测试逻辑的实际表现，例如期望的方法是否被调用，实际被调用了几次等。\n\n实际在日常使用 JUnit 进行 UT 开发时，我们通常也是按照录制、重放、验证这样一个步骤进行的，只不过我们称之为 \"Arrange-Act-Assert\"，3A 理论与 RRV 本质上是一样的。\n\n下面的代码展示了 RRV 在编写 UT 时的具体框架：\n\n```java\n@Test\npublic void test() {\n    // 1. 录制\n    new Expectations() {\n        {\n            // 录制我们期望的目标方法行为\n        }\n    };\n\n    // 2. 重放：执行测试逻辑\n\n    // 3. 验证\n    new Verifications() {\n        {\n            // 验证目标方法的执行状态\n        }\n    };\n}\n```\n\n使用 JMockit 进行实际 UT 开发时，并不要求同时提供这 3 个步骤实现，一般我们常用的是录制和重放，而业务相关的验证逻辑可以使用断言。\n\n#### 录制：Expectations\n\nExpectations 代码块用于放置录制行为，录制主要分为两种方式：\n\n1. 引用外部 mock 类或接口实例进行录制。\n2. 通过构造方法注入类或对象实例进行录制。\n\n##### 引用外部 mock 类或接口实例进行录制\n\n```java\n@Mocked\nprivate UserService userService;\n\n@Test\npublic void recordByMockedInstance() {\n    new Expectations() {\n        {\n            userService.getUserName(anyLong);\n            result = \"zhenchao\";\n\n            userService.getUserAge(anyLong);\n            result = 28;\n        }\n    };\n\n    Assert.assertEquals(\"zhenchao\", userService.getUserName(1001L));\n    Assert.assertEquals(28, userService.getUserAge(1002L));\n}\n```\n\n##### 通过构造方法注入类或对象实例进行录制\n\nExpectations 提供了带参数的构造方法（定义如下），我们可以将一个类的 Class 对象，或者类实例对象作为参数构造 Expectations 对象，区别在于如果传递的是类 Class 对象则录制会对该类的所有实例生效，如果传递的是类实例对象则仅对当前实例生效。\n\n```java\nprotected Expectations(@Nonnull Object... classesOrObjectsToBePartiallyMocked) {\n  execution = new RecordAndReplayExecution(this, classesOrObjectsToBePartiallyMocked);\n}\n```\n\n- 以类 Class 对象构造 Expectations\n\n```java\n@Test\npublic void recordByClass() {\n    User user = new User(1001L);\n    new Expectations(User.class) {\n        {\n            user.getName();\n            result = \"zhenchao\";\n\n            user.getAge();\n            result = 28;\n        }\n    };\n\n    Assert.assertEquals(\"zhenchao\", user.getName());\n    Assert.assertEquals(28, user.getAge());\n\n    // 对其它实例同样生效\n    User user2 = new User(1002L, \"zhangsan\", 18);\n    Assert.assertEquals(\"zhenchao\", user2.getName());\n    Assert.assertEquals(28, user2.getAge());\n}\n```\n\n- 以类对象实例构造 Expectations\n\n```java\n@Test\npublic void recordByInstance() {\n    User user = new User(1001L);\n    new Expectations(user) {\n        {\n            user.getName();\n            result = \"zhenchao\";\n\n            user.getAge();\n            result = 28;\n        }\n    };\n\n    Assert.assertEquals(\"zhenchao\", user.getName());\n    Assert.assertEquals(28, user.getAge());\n\n    // 对其它实例不生效\n    User user2 = new User(1002L, \"zhangsan\", 18);\n    Assert.assertEquals(\"zhangsan\", user2.getName());\n    Assert.assertEquals(18, user2.getAge());\n}\n```\n\n##### 录制多个期望时序结果\n\n如果我们希望目标方法在被调用时，每次返回的期望结果都不一样，那么可以在录制时指定返回一个结果值数组（或列表），数组（或列表）的每个值都对应该方法被调用时期望返回的结果。示例：\n\n```java\n@Test\npublic void recordSequenceResult() {\n    User user = new User(1001L);\n    new Expectations(user) {\n        {\n            user.getName();\n            result = new String[] {\"zhangsan\", \"lisi\", \"wanger\"};\n\n            user.getAge();\n            result = new int[] {16, 17, 18};\n        }\n    };\n\n    // 第一次调用\n    Assert.assertEquals(\"zhangsan\", user.getName());\n    Assert.assertEquals(16, user.getAge());\n\n    // 第二次调用\n    Assert.assertEquals(\"lisi\", user.getName());\n    Assert.assertEquals(17, user.getAge());\n\n    // 第三次调用\n    Assert.assertEquals(\"wanger\", user.getName());\n    Assert.assertEquals(18, user.getAge());\n\n    // 第四次调用，因为没有录制结果，所以返回最后一次录制的期望值\n    Assert.assertEquals(\"wanger\", user.getName());\n    Assert.assertEquals(18, user.getAge());\n}\n```\n\n示例中我们为方法 `User#getName` 和 `User#getAge` 录制了一组返回值，然后在相应方法依次被调用时会返回对应下标的返回值，可以看到当第 4 次调用时仍然返回第 3 组值，这是因为没有为第 4 次调用录制期望值，所以继续沿用最后一组期望值。我们也可以使用 `returns(v1, v2, ...)` 方法来代替 `result = (...)` 的语法，即 `returns(\"zhangsan\", \"lisi\", \"wanger\")` 等价于 `result = new String[] {\"zhangsan\", \"lisi\", \"wanger\"}` 语法。\n\n##### 条件性录制\n\n上面的示例在录制期望返回值时只设定了一个具体的值，如果期望依据入参条件性设置返回值，可以使用 Delegate 接口。例如下面的示例中我们依据入参 userId 的值，条件性返回具体的用户名称：\n\n```java\n@Test\npublic void delegate() {\n    UserService userService = new UserServiceImpl();\n    new Expectations(userService) {\n        {\n            userService.getUserName(anyLong);\n            result = new Delegate() {\n                // 方法名可以任意\n                public String delegate(long userId) {\n                    return userId > 1003L ? \"unknown\" : \"zhenchao\";\n                }\n\n            };\n        }\n    };\n\n    Assert.assertEquals(\"zhenchao\", userService.getUserName(1001L));\n    Assert.assertEquals(\"zhenchao\", userService.getUserName(1002L));\n    Assert.assertEquals(\"unknown\", userService.getUserName(1004L));\n}\n```\n\n另外一个比较经典的应用场景就是依据入参条件性的选择录制还是委托给目标方法，此时我们需要引入 Invocation 对象。示例：\n\n```java\n@Test\npublic void delegate() {\n    UserService userService = new UserServiceImpl();\n    new Expectations(userService) {\n        {\n            userService.getUserInfo(anyLong);\n            result = new Delegate() {\n                // 方法名可以任意\n                public User delegate(Invocation inv, long userId) {\n                    if (userId > 1003) {\n                        return new User(userId, \"u_\" + userId, (int) (userId % 100));\n                    }\n                    // 对于 userId 小于等于 1003 的全部交由目标方法处理\n                    return inv.proceed(userId);\n                }\n\n            };\n        }\n    };\n\n    Assert.assertEquals(UserServiceImpl.REGISTRY.get(1001L), userService.getUserInfo(1001L));\n    Assert.assertEquals(UserServiceImpl.REGISTRY.get(1002L), userService.getUserInfo(1002L));\n    Assert.assertEquals(UserServiceImpl.REGISTRY.get(1003L), userService.getUserInfo(1003L));\n    User user = userService.getUserInfo(1004L);\n    Assert.assertEquals(1004L, user.getId());\n    Assert.assertEquals(\"u_1004\", user.getName());\n    Assert.assertEquals(4, user.getAge());\n}\n```\n\n示例中我们对于 userId 小于等于 1003 的请求全部委托给目标方法执行。\n\n##### 灵活的参数匹配策略\n\n当我们在录制期望时，对于方法的参数设置如果指定了具体的值，那么在重放测试逻辑时只能匹配对应的值，但是很多时候我们并不希望这样精确的匹配。幸运的是 JMockit 对于参数提供了灵活的匹配策略，即 any 语法和 with 语法。\n\n- Any 语法\n\n通过 any 语法，我们可以匹配任意类型的参数值，示例：\n\n```java\n@Test\npublic void any() throws Exception {\n    UserService userService = new UserServiceImpl();\n    new Expectations(userService) {\n        {\n            // 匹配任意类型为 long 的参数值\n            userService.getUserName(anyLong);\n            result = \"zhenchao\";\n        }\n    };\n    Assert.assertEquals(\"zhenchao\", userService.getUserName(RandomUtils.nextLong()));\n}\n```\n\n示例中我们使用 anyLong 录制方法匹配任意 long 类型的参数值。此外，JMockit 还提供了以下 any 语法：\n\n```java\nprotected final Object any = null;\nprotected final String anyString = new String();\nprotected final Long anyLong = 0L;\nprotected final Integer anyInt = 0;\nprotected final Short anyShort = 0;\nprotected final Byte anyByte = 0;\nprotected final Boolean anyBoolean = false;\nprotected final Character anyChar = '\\0';\nprotected final Double anyDouble = 0.0;\nprotected final Float anyFloat = 0.0F;\n```\n\n- With 语法\n\nWith 语法相对于 any 语法提供了更加灵活的匹配策略，当 any 无法满足我们的需求时，可以尝试从 with 语法中寻找解决方案。示例：\n\n```java\n@Test\npublic void with() throws Exception {\n    UserService userService = new UserServiceImpl();\n    new Expectations(userService) {\n        {\n            userService.batchUpdateUserInfo(this.withNotNull());\n            result = 10;\n        }\n    };\n    Assert.assertEquals(10, userService.batchUpdateUserInfo(new ArrayList<>()));\n    // 错误，参数值不允许为 null\n    // Assert.assertEquals(10, userService.batchUpdateUserInfo(null));\n}\n```\n\n示例中 `UserService#batchUpdateUserInfo` 方法接收一个 `List<User>` 类型的参数，这里我们使用了 withNotNull 方法，期望匹配任何不为 null 入参。此外，JMockit 还提供了以下类型的 with 语法：\n\n```java\nprotected final <T> T with(@Nonnull Delegate<? super T> objectWithDelegateMethod);\nprotected final <T> T withAny(@Nonnull T arg);\nprotected final <T> T withEqual(@Nonnull T arg);\nprotected final double withEqual(double value, double delta);\nprotected final float withEqual(float value, double delta);\nprotected final <T> T withInstanceLike(@Nonnull T object);\nprotected final <T> T withInstanceOf(@Nonnull Class<T> argClass);\nprotected final <T> T withNotEqual(@Nonnull T arg);\nprotected final <T> T withNull();\nprotected final <T> T withNotNull();\nprotected final <T> T withSameInstance(@Nonnull T object);\nprotected final <T extends CharSequence> T withSubstring(@Nonnull T text);\nprotected final <T extends CharSequence> T withPrefix(@Nonnull T text);\nprotected final <T extends CharSequence> T withSuffix(@Nonnull T text);\nprotected final <T extends CharSequence> T withMatch(@Nonnull T regex);\n```\n\n##### 录制方法调用次数限制\n\nJMockit 在录制期望时提供了 `times`、`minTimes` 和 `maxTimes` 语法，用于限制当前方法被调用的次数。示例：\n\n```java\n@Test\npublic void times() throws Exception {\n    UserService userService = new UserServiceImpl();\n    new Expectations(userService) {\n        {\n            userService.getUserName(anyLong);\n            result = \"zhenchao\";\n            times = 1; // 限制当前方法仅允许被调用 1 次\n        }\n    };\n    Assert.assertEquals(\"zhenchao\", userService.getUserName(RandomUtils.nextLong()));\n    // 错误，方法限制仅允许调用 1 次\n    // Assert.assertEquals(\"zhenchao\", userService.getUserName(RandomUtils.nextLong()));\n}\n```\n\n#### 验证：Verifications\n\nVerifications 用于验证被测试方法调用的状态，即方法是否被调用过，调用了多少次等。Verifications 同样提供了 `times`、`minTimes` 和 `maxTimes` 语法，这与 Expectations 中的设置相同。示例：\n\n```java\n@Mocked\nprivate UserService userService;\n\n@Test\npublic void verifyForMockedInstance() {\n    Assert.assertNull(userService.getUserName(1001L));\n    Assert.assertNull(userService.getUserName(1001L));\n    Assert.assertEquals(0, userService.getUserAge(1001L));\n\n    new Verifications() {\n        {\n            // 限定 getUserName 方法只能被调用 2 次\n            userService.getUserName(anyLong);\n            times = 2;\n\n            // 限定 getUserAge 方法只能被调用 1 次\n            userService.getUserAge(anyLong);\n            times = 1;\n        }\n    };\n}\n\n@Test\npublic void verifyForInstance() {\n    User user = new User(1001L, \"zhenchao\", 28);\n    Assert.assertEquals(\"zhenchao\", user.getName());\n    Assert.assertEquals(28, user.getAge());\n    Assert.assertEquals(28, user.getAge());\n\n    new Verifications() {\n        {\n            // 限定 getName 方法只能被调用 1 次\n            user.getName();\n            times = 1;\n\n            // 限定 getAge 方法只能被调用 2 次\n            user.getAge();\n            times = 2;\n        }\n    };\n}\n```\n\n##### 限制方法的调用顺序\n\n如果期望目标方法按照一定的顺序执行，可以使用 VerificationsInOrder 代替 Verifications。示例：\n\n```java\n@Mocked\nprivate UserService userService;\n\n@Test\npublic void verifyInOrder() {\n    // 错误，方法执行顺序不满足期望\n    Assert.assertNull(userService.getUserName(1001L));\n    Assert.assertEquals(0, userService.getUserAge(1001L));\n\n    new VerificationsInOrder() {\n        {\n            // 限定 getUserName 方法在 getUserAge 方法前执行\n            userService.getUserName(anyLong);\n            userService.getUserAge(anyLong);\n        }\n    };\n}\n```\n\n需要注意的是，VerificationsInOrder 对于局部实例不生效。\n\n##### 强制验证所有测试方法\n\n如果期望所有在重放阶段调用的测试方法都需要被验证，可以使用 FullVerifications 代替 Verifications。示例：\n\n```java\n@Mocked\nprivate UserService userService;\n\n@Test\npublic void fullVerify() {\n    // 错误，因为 getUserAge 方法并未被验证\n    Assert.assertNull(userService.getUserName(1001L));\n    Assert.assertEquals(0, userService.getUserAge(1001L));\n\n    new FullVerifications() {\n        {\n            userService.getUserName(anyLong);\n        }\n    };\n}\n```\n\n需要注意的是，FullVerifications 对于局部实例不生效。\n\n##### 捕获重放阶段的方法参数\n\nJMockit 允许在 Verifications 代码块中通过 withCapture 方法捕获重放阶段传递的方法参数，分为 3 种情况：\n\n1. 捕获单次方法调用的参数。\n2. 捕获多次方法调用的参数集合。\n3. 捕获方法调用时新创建的对象。\n\n具体示例如下：\n\n```java\n@Test\npublic void capturingSingle() {\n    userService.checkPassword(1001L, \"aaa\");\n\n    new Verifications() {\n        {\n            // 捕获单次方法调用的参数\n            long uid;\n            String pwd;\n            userService.checkPassword(uid = this.withCapture(), pwd = this.withCapture());\n            Assert.assertEquals(1001L, uid);\n            Assert.assertEquals(\"aaa\", pwd);\n        }\n    };\n}\n\n@Test\npublic void capturingMultiple() {\n    userService.getUserInfo(1001L);\n    userService.getUserInfo(1002L);\n    userService.getUserInfo(1003L);\n\n    new Verifications() {\n        {\n            // 捕获多次方法调用的参数集合\n            List<Long> userIds = new ArrayList<>();\n            userService.getUserInfo(this.withCapture(userIds));\n            Assert.assertEquals(3, userIds.size());\n            Assert.assertEquals(Arrays.asList(1001L, 1002L, 1003L), userIds);\n        }\n    };\n}\n\n@Test\npublic void capturingNewInstances(@Mocked User user) { // 不要忘了 @Mocked User\n    userService.updateUserInfo(new User(1001L, \"zhangsan\", 16));\n    userService.updateUserInfo(new User(1002L, \"lisi\", 17));\n    userService.updateUserInfo(new User(1003L, \"wanger\", 18));\n\n    new Verifications() {\n        {\n            // 捕获方法调用时新创建的对象\n            List<User> users = this.withCapture(new User(anyLong, anyString, anyInt));\n            Assert.assertEquals(3, users.size());\n\n            List<User> userInfos = new ArrayList<>();\n            userService.updateUserInfo(this.withCapture(userInfos));\n\n            Assert.assertEquals(users, userInfos);\n        }\n    };\n}\n```\n\n### Mocking：模拟测试所依赖的运行环境\n\n#### Mock 注解的特点与使用场景\n\nJMockit 提供了多个 mock 注解，用于模拟被测试对象所依赖的运行环境，包括 `@Mocked`、`@Tested`、`@Injectabe`、以及 `@Capturing`。这些注解可以修饰我们在测试类中声明的 __mock 属性__ 和测试方法的 __mock 参数__ 。被这些注解修饰的属性和参数（类型包括接口、普通类、抽象类、final 类、注解，以及枚举），JMockit 会依据相应注解的语义对其进行实例化。这几个注解的基本语义如下：\n\n- `@Mocked`：委托 JMockit 创建目标接口或者类的实例，所有实例都会被托管（不管是不是 JMockit 创建的），所有方法（包括静态方法、构造方法）均返回对应类型的初始值，如果是引用类型则递归初始化。\n- `@Injectabe`：委托 JMockit 创建目标接口或者类的实例，仅 JMcokit 创建的实例会被托管，类实例方法（不包括静态方法、构造方法）均返回对应类型的初始值，如果是引用类型则递归初始化。\n- `@Tested`：标记一个实例是被测试实例，如果能够依据类型推断出用于具体实例化的类，则 JMockit 会自动执行实例化操作，否则需要手动实例化，当我们调用实例的方法时，相应方法并不会被 JMockit 托管，但是配合 `@Injectabe` 注解，可以注入方法中使用到的依赖实例。\n- `@Capturing`：委托 JMockit 代理目标接口或者父类，被代理的接口或父类不管子类如何实现（可以是人工编写、匿名类，甚至是动态代理类），其相应的方法都将被 JMockit 托管，适用于代理子类的行为，并且子类是不易描述的。\n\n##### 注解：Mocked\n\n注解 `@Mocked` 可以修饰类和接口，其语义是告诉 JMockit 生成当前被 mock 类或接口的对象，该对象的方法（包括静态方法、构造方法）均返回对应类型的初始值，例如对于 int 类型则返回 0，String 类型返回 null，如果返回类型是一个引用类型，则 JMockit 会递归创建该类型的对象，同样该对象的属性都会被设置为相应的初始值。\n\n###### 修饰接口类型\n\n```java\n@Mocked\nprivate UserService userService;\n\n@Test\npublic void mockedInterface() {\n    // String 类型方法直接返回 null\n    Assert.assertNull(userService.getUserName(1001L));\n\n    // int 类型方法直接返回 0\n    Assert.assertEquals(0, userService.getUserAge(1001L));\n\n    // 引用类型方法返回一个新的 User 对象，但是对象的属性值都是初始值\n    User user = userService.getUserInfo(1001L);\n    Assert.assertNotNull(user);\n    Assert.assertEquals(0L, user.getId());\n    Assert.assertNull(user.getName());\n    Assert.assertEquals(0, user.getAge());\n}\n```\n\n总结：\n\n1. 注解会创建一个接口的实现类对象。\n2. 返回值为基本类型的方法直接返回初始值。\n3. 返回值为 String 类型的方法直接返回 null。\n4. 返回值为引用类型的方法会递归初始化。\n\n###### 修饰类类型\n\n```java\n@Mocked\nprivate UserServiceImpl userServiceImpl;\n\n@Test\npublic void mockedClass() {\n    // String 类型实例方法直接返回 null\n    Assert.assertNull(userService.getUserName(1001L));\n\n    // int 类型实例方法直接返回 0\n    Assert.assertEquals(0, userService.getUserAge(1001L));\n\n    // 引用类型方法返回一个新的 User 对象，但是对象的属性值都是初始值\n    User user = userService.getUserInfo(1001L);\n    Assert.assertNotNull(user);\n    Assert.assertEquals(0L, user.getId());\n    Assert.assertNull(user.getName());\n    Assert.assertEquals(0, user.getAge());\n\n    // 类的静态方法也会被托管\n    User newUser = UserServiceImpl.newUserInfo(\"zhenchao\", 28);\n    Assert.assertEquals(0L, newUser.getId());\n    Assert.assertNull(newUser.getName());\n    Assert.assertEquals(0, newUser.getAge());\n\n    // 自己 new 一个被 mock 类型对象也会被托管\n    UserService localService = new UserServiceImpl();\n    Assert.assertNull(localService.getUserName(1001L));\n    Assert.assertEquals(0, localService.getUserAge(1001L));\n}\n```\n\n总结：\n\n1. 满足接口类型所有的特点。\n2. 静态方法同样会被托管，效果与实例方法一样。\n3. 即使自己 new 出来的实例也会被托管。\n\n##### 注解：Injectabe\n\n注解 `@Injectable` 同样可以修饰类和接口，其语义是告诉 JMockit 生成当前被 mock 类或接口的对象。相对于 `@Mocked` 的区别在于，`@Injectable` 仅托管修饰类或接口的当前实例，而不是所有实例。此外，`@Injectable` 对类的静态方法、构造方法没有影响。修饰类的示例如下：\n\n```java\n@Injectable\nprivate UserServiceImpl userServiceImpl;\n\n@Test\npublic void injectableClass() {\n    // String 类型实例方法直接返回 null\n    Assert.assertNull(userService.getUserName(1001L));\n\n    // int 类型实例方法直接返回 0\n    Assert.assertEquals(0, userService.getUserAge(1001L));\n\n    // 引用类型方法返回一个新的 User 对象，但是对象的属性值都是初始值\n    User user = userService.getUserInfo(1001L);\n    Assert.assertNotNull(user);\n    Assert.assertEquals(0L, user.getId());\n    Assert.assertNull(user.getName());\n    Assert.assertEquals(0, user.getAge());\n\n    // 类的静态方法不会被托管\n    User newUser = UserServiceImpl.newUserInfo(1004L, \"zhenchao\", 28);\n    Assert.assertEquals(1004L, newUser.getId());\n    Assert.assertEquals(\"zhenchao\", newUser.getName());\n    Assert.assertEquals(28, newUser.getAge());\n\n    // 自己 new 一个被 mock 类型对象也不会被托管\n    UserService localService = new UserServiceImpl();\n    Assert.assertEquals(\"zhangsan\", localService.getUserName(1001L));\n    Assert.assertEquals(18, localService.getUserAge(1001L));\n}\n```\n\n总结：\n\n1. 注解会创建一个接口的实现类对象，并且仅托管当前创建的实例。\n2. 返回值为基本类型的方法直接返回初始值。\n3. 返回值为 String 类型的方法直接返回 null。\n4. 返回值为引用类型的方法会递归初始化。\n5. 构造方法、静态方法不会被托管。\n\n##### 注解：Tested\n\n注解 `@Tested` 一般和 `@Injectable` 配合使用以 mock 被测试类或接口的对象，如果该对象没有被赋值，则 JMockit 会对该对象进行实例化。实例化过程中如果被测试类具备带参数的构造方法，则 JMockit 会尝试在 mock 属性和 mock 参数中寻找被 `@Injectable` 修饰的 mock 对象进行注入，否则使用无参构造方法进行实例化，并尝试属性注入。\n\n下面以一个订单示例说明注解 `@Tested` 和 `@Injectable` 的配合使用。假设有一个订单服务 OrderService，当调用该服务的 `OrderService#submitOrder` 方法提交订单时需要调用用户服务 UserService 验证当前提交订单用户的密码，只有在密码验证通过的情况下才会处理订单，并在订单处理成功之后调用邮件服务 EmailService 发送邮件通知用户。订单服务实现如下：\n\n```java\npublic class OrderService {\n\n    /** 用户服务 */\n    private UserService userService;\n\n    /** 邮件服务 */\n    @Resource\n    private EmailService emailService;\n\n    public OrderService(UserService userService) {\n        this.userService = userService;\n    }\n\n    /**\n     * 提交订单\n     *\n     * @param userId 用户 ID\n     * @param orderId 订单 ID\n     * @param password 用户密码\n     * @return 如果订单提交成功则返回 true，否则返回 false\n     */\n    public boolean submitOrder(long userId, long orderId, String password) {\n        // 校验用户密码\n        if (userService.checkPassword(userId, password)) {\n\n            // 密码验证通过，处理订单，省略 ...\n\n            // 发送通知邮件\n            User user = userService.getUserInfo(userId);\n            emailService.send(user.getEmail(), \"submit order success\", \"submit order success, orderId: \" + orderId);\n            System.out.println(\"user submit order success, userId: \" + userId + \", orderId: \" + orderId);\n            return true;\n        }\n        System.out.println(\"invalid password, userId: \" + userId);\n        return false;\n    }\n\n    public OrderService setEmailService(EmailService emailService) {\n        this.emailService = emailService;\n        return this;\n    }\n}\n```\n\n在订单服务 OrderService 中，我们设定了通过构造方法注入 UserService 实例，通过属性注入 EmailService 实例，相应的测试方法实现如下：\n\n```java\n@Tested\nprivate OrderService orderService;\n\n@Injectable\nprivate UserService userService;\n\n@Test\npublic void submitOrder(@Injectable EmailService emailService) {\n    User zhangsan = new User(1001L, \"zhangsan\", 18).setEmail(\"zhangsan@gmail.com\").setPassword(\"aaa\");\n    new Expectations() {\n        {\n            userService.getUserInfo(zhangsan.getId());\n            result = zhangsan;\n\n            userService.checkPassword(zhangsan.getId(), zhangsan.getPassword());\n            result = true;\n\n            emailService.send(zhangsan.getEmail(), anyString, anyString);\n            result = true;\n        }\n    };\n\n    Assert.assertTrue(orderService.submitOrder(zhangsan.getId(), RandomUtils.nextLong(), zhangsan.getPassword()));\n    Assert.assertFalse(orderService.submitOrder(zhangsan.getId(), RandomUtils.nextLong(), \"\"));\n    Assert.assertFalse(orderService.submitOrder(1002L, RandomUtils.nextLong(), zhangsan.getPassword()));\n}\n```\n\n我们在测试方法中同时使用了 mock 属性和 mock 参数，并录制了相应服务方法的期望行为，借助 JMockit 可以将这些录制在执行具体测试逻辑时重放。\n\n##### 注解：Capturing\n\n有时候我们只知道父类或接口，但是希望控制它所有的子类（包括人工编写、匿名类，以及动态代理生成等）的行为，这时可以使用 `@Capturing` 注解。该注解平时虽然较少用到，但在一些场景下还非它不可，尤其是动态代理相关应用场景。\n\n假设我们现在有一个密码校验服务接口 PasswordService，我们并不知道该接口的实现类有哪些，以及如何实现，可能是匿名类，也可能是动态代理，如下：\n\n```java\npublic interface PasswordService {\n    boolean check(long userId, String password);\n}\n\n/**\n * 匿名类\n */\nPasswordService passwordService1 = new PasswordService() {\n    @Override\n    public boolean check(long userId, String password) {\n        return 1001L != userId && StringUtils.isNotBlank(password);\n    }\n};\n\n/**\n * 动态代理类\n */\nPasswordService passwordService2 = (PasswordService) Proxy.newProxyInstance(\n        Thread.currentThread().getContextClassLoader(),\n        new Class[] {PasswordService.class},\n        new InvocationHandler() {\n            @Override\n            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n                return args.length == 2\n                        && (Long) args[0] != 1001L && StringUtils.isNotBlank(String.valueOf(args[1]));\n            }\n        });\n```\n\n假设我们现在想托管所有 PasswordService 接口的实现类，不管是匿名类还是动态生成的，这个时候就可以使用 `@Capturing` 注解：\n\n```java\n@Test\npublic void withCapturing(@Capturing PasswordService passwordService) {\n    final long UID = 1001L;\n    new Expectations() {\n        {\n            passwordService.check(UID, anyString);\n            result = true;\n        }\n    };\n    // 不管子类实现如何，全部应用录制的行为\n    Assert.assertTrue(passwordService1.check(UID, \"aaa\"));\n    Assert.assertTrue(passwordService2.check(UID, \"bbb\"));\n}\n\n@Test\npublic void withoutCapturing() {\n    final long UID = 1001L;\n    Assert.assertFalse(passwordService1.check(UID, \"aaa\"));\n    Assert.assertFalse(passwordService2.check(UID, \"bbb\"));\n}\n```\n\n由示例可以看出，如果目标接口使用 `@Capturing` 注解修饰，则不管子类如何实现，都不再生效。\n\n__注__ ：1.38 版本存在 bug，对于动态代理生成的类无法代理。\n\n上面的示例也可以使用 MockUp 实现，我们会在后面对 MockUp 的使用进行详细介绍，这里先给出一个示例：\n\n```java\n@Test\npublic <T extends PasswordService> void mockup() {\n    final long UID = 1001L;\n    new MockUp<T>() {\n        @Mock\n        public boolean check(long userId, String password) {\n            return true;\n        }\n    };\n\n    PasswordService passwordService1 = new PasswordService() {\n        @Override\n        public boolean check(long userId, String password) {\n            return false;\n        }\n    };\n    Assert.assertTrue(passwordService1.check(UID, \"aaa\"));\n\n    PasswordService passwordService2 = (PasswordService) Proxy.newProxyInstance(\n            Thread.currentThread().getContextClassLoader(),\n            new Class[] {PasswordService.class},\n            new InvocationHandler() {\n                @Override\n                public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n                    return false;\n                }\n            });\n    Assert.assertTrue(passwordService2.check(UID, \"aaa\"));\n}\n```\n\n### Faking：替换目标方法的实现\n\nMockUp 可以伪造目标方法的实现，以返回我们期望的数据或者行为，其语义与 Expectations 相似，但是更加直观和简单。MockUp 适用于一个项目中对一些通用类的 mock 操作，以减少大量重复的 Exceptations 录制代码。示例：\n\n```java\n@Test\npublic void mockup() {\n    new MockUp<UserService>(UserServiceImpl.class) {\n\n        @Mock\n        public int getUserAge(long userId) {\n            if (1001L == userId) {\n                return 1;\n            } else if (1002L == userId) {\n                return 2;\n            } else if (1003L == userId) {\n                return 3;\n            } else {\n                return -1;\n            }\n        }\n\n    };\n\n    UserService userService = new UserServiceImpl();\n    Assert.assertEquals(1, userService.getUserAge(1001L));\n    Assert.assertEquals(2, userService.getUserAge(1002L));\n    Assert.assertEquals(3, userService.getUserAge(1003L));\n    Assert.assertEquals(-1, userService.getUserAge(1004L));\n}\n```\n\n示例中我们通过组合 MockUp 和 `@Mock` 注解对 `UserServiceImpl#getUserAge` 方法进行录制。\n\n如果我们希望像 Expectations 那样对目标方法进行条件性 mock，例如依据参数选择是 mock 还是直接调用原始方法，可以引入 Invocation 对象，实现如下：\n\n```java\n@Test\npublic void mockup() {\n    new MockUp<UserService>(UserServiceImpl.class) {\n\n        @Mock\n        public User getUserInfo(Invocation inv, long userId) {\n            if (userId > 1003L) {\n                return new User(userId, \"u_\" + userId, (int) userId % 100);\n            }\n            // 当 userId 小于等于 1003 时直接调用原始方法\n            return inv.proceed(userId);\n        }\n\n    };\n\n    UserService userService = new UserServiceImpl();\n    Assert.assertEquals(UserServiceImpl.REGISTRY.get(1001L), userService.getUserInfo(1001L));\n    Assert.assertEquals(UserServiceImpl.REGISTRY.get(1002L), userService.getUserInfo(1002L));\n    Assert.assertEquals(UserServiceImpl.REGISTRY.get(1003L), userService.getUserInfo(1003L));\n    User user = userService.getUserInfo(1004L);\n    Assert.assertEquals(1004L, user.getId());\n    Assert.assertEquals(\"u_1004\", user.getName());\n    Assert.assertEquals(4, user.getAge());\n}\n```\n\n可以看到相对于 Expectations 而言，MockUp 的条件性 mock 更加简单。\n\nMockUp 使用简单、直观，与 Expectations 形成互补，从而极大增强了 JMockit 的功能，下面将对 MockUp 的常见应用场景进行举例说明，不过在开始之前我们还是先概括一下 MockUp 在使用上的一些限制：\n\n1. 无法对单个实例进行 mock。\n2. 无法对动态代理类进行 mock。\n3. 当需要对类的所有方法进行 mock 时，开发效率较低。\n\n#### Mock 私有方法和 native 方法\n\nExpectations 在 mock 目标类的私有方法和 native 方法时有些力不从心，这个时候可以使用 MockUp 代替，示例：\n\n```java\npublic class MyClass {\n    // native 方法\n    public native int nativeMethod();\n    // 私有方法\n    private int privateMethod() {\n        return 1;\n    }\n}\n\n@Test\npublic void recordByMockUp() throws Exception {\n    new MockUp<MyClass>(MyClass.class) {\n        @Mock\n        public int privateMethod() {\n            return 2019;\n        }\n        @Mock\n        public int nativeMethod() {\n            return 2019;\n        }\n    };\n\n    MyClass mc = new MyClass();\n    Method privateMethod = MyClass.class.getDeclaredMethod(\"privateMethod\");\n    privateMethod.setAccessible(true);\n    Assert.assertEquals(2019, privateMethod.invoke(mc));\n    Assert.assertEquals(2019, mc.nativeMethod());\n}\n```\n\n#### Mock 构造方法和静态代码块\n\n前面介绍的 mock 方式，即使目标类被 JMockit 托管，但是在实例化时还是会调用我们自定义的构造方法对类进行实例化，当遇到一些实现复杂或者不规范的类时，可能会在类实例化的过程中执行大量的操作，比如创建数据库连接等，这个时候我们可能希望将构造方法、静态代码块都 mock 调用，以简化 UT 的开发。这个时候我们就可以使用 MockUp 来达到目的：\n\n```java\npublic class UserServiceImpl implements UserService {\n\n    private static Connection connection;\n\n    static {\n        try {\n            // 创建数据库连接\n            connection = DBSource.getConnection();\n        } catch (SQLException e) {\n            System.exit(-1);\n        }\n    }\n\n    private int port;\n\n    public UserServiceImpl() {\n    }\n\n    public UserServiceImpl(int port) {\n        this.port = port;\n    }\n\n}\n\n@Test\npublic void mockupInitialization() {\n    new MockUp<UserService>(UserServiceImpl.class) {\n        @Mock\n        public void $clinit() {\n            // mock 静态代码块\n        }\n\n        @Mock\n        public void $init(int port) {\n            // mock 构造方法\n        }\n    };\n\n    UserServiceImpl userService = new UserServiceImpl(8080);\n    Assert.assertEquals(0, userService.getPort());\n    Assert.assertNull(UserServiceImpl.getConnection());\n}\n```\n\n示例中目标类 UserServiceImpl 在初始化时需要创建数据库连接，这是一个耗时且易出错的操作，所以我们将其 mock 掉以简化 UT 的编写。在 MockUp 中使用 `$clinit` 表示类初始化方法，使用 `$init` 表示类构造方法，之所以这样命名是因为我们的静态代码块在编译成字节码时会组织在一个名为 `$clinit` 的方法中，而构造方法在编译成字节码时则使用 `$init` 作为方法名。\n\n#### 织入切面增强\n\nMockUp 还允许定义另外一类名为 `$advice` 的方法，用于实现切面增强的目的，示例：\n\n```java\n@Test\npublic void advice() {\n    new MockUp<UserService>(UserServiceImpl.class) {\n\n        @Mock\n        public Object $advice(Invocation inv) {\n            long start = System.nanoTime();\n            Object result = inv.proceed();\n            System.out.println(\"time elapse: \" + (System.nanoTime() - start));\n            return result;\n        }\n\n    };\n\n    UserService userService = new UserServiceImpl();\n    Assert.assertEquals(UserServiceImpl.REGISTRY.get(1002L), userService.getUserInfo(1002L));\n}\n```\n\n示例中我们在目标方法前后添加了时间打点，用于记录目标方法的执行时间。\n\n### 集成 Spring 框架\n\n对于 java 服务端应用来说，Spring 基本上算是必备框架，如果我们希望 mock 被 spring 创建的 bean，可以实现如下：\n\n```java\n@RunWith(SpringJUnit4ClassRunner.class)\n@ContextConfiguration(locations = \"classpath:spring.xml\")\npublic class SpringMockTest {\n\n    @Resource\n    private UserService userService;\n\n    @Test\n    public void recordByExpectations() {\n        new Expectations(userService) {\n            {\n                userService.getUserName(anyLong);\n                result = \"zhenchao\";\n\n                userService.getUserAge(anyLong);\n                result = 28;\n            }\n        };\n\n        Assert.assertEquals(\"zhenchao\", userService.getUserName(1001L));\n        Assert.assertEquals(28, userService.getUserAge(1001L));\n    }\n\n    @Test\n    public void recordByMockup() {\n        new MockUp<UserService>(UserServiceImpl.class) {\n            @Mock\n            public String getUserName(long userId) {\n                return \"zhenchao\";\n            }\n\n            @Mock\n            public int getUserAge(long userId) {\n                return 28;\n            }\n        };\n\n        Assert.assertEquals(\"zhenchao\", userService.getUserName(1001L));\n        Assert.assertEquals(28, userService.getUserAge(1001L));\n    }\n}\n```\n\n示例中分别实现了基于 Expectations 的录制和基于 MockUp 的录制。\n\n### 参考\n\n- [JMockit 官网文档](http://jmockit.github.io/)\n- [JMockit 中文网](http://jmockit.cn/index.htm)\n","tags":["JMockit"],"categories":["java"]},{"title":"CGLib：The Missing Guide","url":"/2019/01/01/java/cglib-guide/","content":"\nCGLib(Code Generation Library) 是一个强大、高效，以及高质量的字节码生成库，能够在运行时动态生成字节码，从而实现一些比较极客的功能。CGLib 被许多开源软件采用，我们在写一些基础库时也很青睐，但是官方给到的文档比较简单，所以本文参考 [CGLib: The missing manual](http://mydailyjava.blogspot.com/2013/11/cglib-missing-manual.html)，并结合自己的使用经验，总结了一个中文版本。<!-- more -->\n\n在正式开始之前，先给出 CGLib 在使用上的一些限制：\n\n1. 无法代理 final 类（受制于继承机制，final 类不允许继承）。\n2. 无法代理非静态（non-static）内部类。\n3. 创建代理类对象时，需要被代理类提供相应参数签名的构造方法。\n4. 创建代理相对于 java 原生动态代理性能较低，但是运行性能更高。\n\n> 本文示例运行版本：3.2.x\n\n### 动态代理：Enhancer\n\n本小节所有示例都基于 SampleClass 进行，以该类作为被代理类，定义如下：\n\n```java\npublic class SampleClass {\n\n    public SampleClass() {\n        System.out.println(this.getClass().getSimpleName() + \": default construct method\");\n    }\n\n    public SampleClass(String name) {\n        System.out.println(this.getClass().getSimpleName() + \": construct method : \" + name);\n    }\n\n    public String hello(String name) {\n        System.out.println(this.getClass().getSimpleName() + \": hello method\");\n        return \"Hello, \" + name;\n    }\n\n    public final String finalMethod(String input) {\n        System.out.println(this.getClass().getSimpleName() + \": final method\");\n        return \"final method: \" + input;\n    }\n\n    public static String staticMethod(String input) {\n        System.out.println(SampleClass.class.getName() + \": static method\");\n        return \"static method: \" + input;\n    }\n\n    private String privateMethod(String input) {\n        System.out.println(this.getClass().getSimpleName() + \": private method\");\n        return \"private method: \" + input;\n    }\n\n}\n```\n\n#### FixedValue：替换实例方法返回值\n\nFixedValue 用于替换被代理类方法的返回值（final/static 方法除外），假设我们希望替换 `SampleClass#hello` 方法的返回值，基于 CGLib 的 FixedValue 可以实现如下：\n\n```java\nEnhancer enhancer = new Enhancer();\nenhancer.setSuperclass(SampleClass.class);\nenhancer.setCallback(new FixedValue() {\n    @Override\n    public Object loadObject() throws Exception {\n        // 替换方法的返回值\n        return \"Hello, cglib!\";\n    }\n});\n// 这里要求被代理类必须具备默认构造方法\nSampleClass proxy = (SampleClass) enhancer.create();\nAssert.assertEquals(\"Hello, cglib!\", proxy.hello(null)); // 不管我们传递任何参数值，返回值始终是我们指定的返回值\n```\n\n如果我们在创建代理对象时指定了参数（如下），则要求 SampleClass 必须具备相同参数签名的构造方法，这里要求 SampleClass 必须具备仅有一个 String 类型参数的构造方法：\n\n```java\nSampleClass proxy = (SampleClass) enhancer.create(new Class[] {String.class}, new Object[] {\"zhenchao\"});\n```\n\n__注意__ ：代理对象的 toString 方法也会被代理，所以 toString 返回的也是 `Hello, cglib!`。同理 hashCode 方法也会被代理，所以也会返回 `Hello, cglib!` 字符串，但是因为 hashCode 方法的返回类型是 int，所以会抛出 ClassCastException 异常。\n\n此外，final 方法和 static 方法不会被代理。\n\n#### InvocationHandler：拦截方法时提供获取方法的相关信息\n\nFixedValue 仅允许我们修改实例方法的返回值，但是对于当前调用方法的相关信息我们无从了解，InvocationHandler 则以参数的方式将这些信息传递给我们，几乎等同于 jdk 自带的 `java.lang.reflect.InvocationHandler`，两者都定义了 invoke 方法，且在方法签名上是一致的，使用示例：\n\n```java\nEnhancer enhancer = new Enhancer();\nenhancer.setSuperclass(SampleClass.class);\nenhancer.setCallback(new InvocationHandler() {\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        System.out.println(\"proxy: \" + proxy.getClass().getSimpleName());\n        System.out.println(\"method: \" + method.getName());\n        System.out.println(\"args: \" + Arrays.toString(args));\n        // proxy.toString(); 会导致无穷循环\n        System.out.println(\"invoke method: \" + method.getName());\n        return \"Hello, cglib!\";\n    }\n});\nSampleClass proxy = (SampleClass) enhancer.create();\nAssert.assertEquals(\"Hello, cglib!\", proxy.hello(\"zhenchao\"));\n```\n\nInvocationHandler 接口的定义如下，参数 proxy 是 CGLib 生成的代理类对象，method 即为我们当前调用的方法签名，args 是我们传递给方法的参数列表。\n\n```java\npublic interface InvocationHandler extends Callback {\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;\n}\n```\n\n对于本次调用来说这三个参数值如下，其中代理对象对应的类名是 CGLib 在 SampleClass 类型的基础上随机生成的，以防止与系统中已有的类重名：\n\n```text\nproxy: SampleClass$$EnhancerByCGLIB$$a01c21b9\nmethod: hello\nargs: [zhenchao]\n```\n\n__注意__ ：我们在 invoke 中调用 proxy 的一般方法会循环触发 invoke 方法（包括执行 `method.invoke(proxy, args)`），导致无穷循环，最终导致栈溢出，为了解决这一问题我们可以使用 MethodInterceptor 代替。\n\n#### MethodInterceptor：InvocationHandler 的增强版本\n\n```java\nEnhancer enhancer = new Enhancer();\nenhancer.setSuperclass(SampleClass.class);\nenhancer.setCallback(new MethodInterceptor() {\n    @Override\n    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {\n        System.out.println(\"obj: \" + obj.getClass().getSimpleName());\n        System.out.println(\"method: \" + method.getName());\n        System.out.println(\"args: \" + Arrays.toString(args));\n        System.out.println(\"proxy: \" + proxy.getSuperName());\n        // 执行被代理类的方法\n        return proxy.invokeSuper(obj, args);\n    }\n});\nSampleClass proxy = (SampleClass) enhancer.create();\nAssert.assertEquals(\"Hello, zhenchao\", proxy.hello(\"zhenchao\"));\n```\n\nMethodInterceptor 接口的定义如下，其中 obj 是 CGLib 生成的代理类对象，等价于 InvocationHandler 中的 proxy，而 MethodInterceptor 中的 proxy 则是用来触发被代理类对应的方法（即被代理方法），我们可以触发任意次，而不会造成无穷循环。\n\n```java\npublic interface MethodInterceptor extends Callback {\n    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable;\n}\n```\n\n#### LazyLoader：仅在第一次调用方法时创建代理对象\n\nLazyLoader 在方法签名上与 FixedValue 一致，但是在方法返回上却大相径庭，前面介绍了 FixedValue 用于替换方法的返回值，而 LazyLoader 则是返回一个代理对象，该代理对象由开发者自己指定和创建，并且 __仅在第一次调用被代理方法时创建代理对象__ ，后面的使用都会复用该对象：\n\n```java\nEnhancer enhancer = new Enhancer();\nenhancer.setSuperclass(SampleClass.class);\nenhancer.setCallback(new LazyLoader() {\n    @Override\n    public Object loadObject() throws Exception {\n        return new SampleClass();\n    }\n});\nSampleClass proxy = (SampleClass) enhancer.create();\nfor (int i = 0; i < 3; i++) {\n    Assert.assertEquals(\"Hello, zhenchao\", proxy.hello(\"zhenchao\"));\n}\n```\n\n上面的示例我们循环调用了 3 次被代理方法，由下面的输出可以看到只有在第一次调用被代理方法时触发创建了代理对象，这里需要注意的时被代理对象的构造方法被调用了两次，一次是 CGLib 创建代理对象时调用的，一次是我们 `new SampleClass()` 时调用的。\n\n```text\nSampleClass$$EnhancerByCGLIB$$a6d4c46: default construct method\nSampleClass: default construct method\nSampleClass: hello method\nSampleClass: hello method\nSampleClass: hello method\n```\n\n#### Dispatcher: 每次调用被代理方法时都会创建代理对象\n\nDispatcher 的作用与 LazyLoader 相同，区别在于每次调用被代理方法时都会创建返回新的代理对象：\n\n```java\nEnhancer enhancer = new Enhancer();\nenhancer.setSuperclass(SampleClass.class);\nenhancer.setCallback(new Dispatcher() {\n    @Override\n    public Object loadObject() throws Exception {\n        return new SampleClass();\n    }\n});\nSampleClass proxy = (SampleClass) enhancer.create();\nfor (int i = 0; i < 3; i++) {\n    Assert.assertEquals(\"Hello, zhenchao\", proxy.hello(\"zhenchao\"));\n}\n```\n\n输出如下，由输出可以看到每次调用被代理方法时都会创建代理对象：\n\n```text\nSampleClass$$EnhancerByCGLIB$$21d43ab6: default construct method\nSampleClass: default construct method\nSampleClass: hello method\nSampleClass: default construct method\nSampleClass: hello method\nSampleClass: default construct method\nSampleClass: hello method\n```\n\nProxyRefDispatcher 是 Dispatcher 的增强版本，唯一的区别在于在方法中传递了一个代理对象 proxy 进来：\n\n```java\nEnhancer enhancer = new Enhancer();\nenhancer.setSuperclass(SampleClass.class);\nenhancer.setCallback(new ProxyRefDispatcher() {\n    @Override\n    public Object loadObject(Object proxy) throws Exception {\n        System.out.println(\"proxy: \" + proxy.getClass().getSimpleName());\n        return new SampleClass();\n    }\n});\nSampleClass proxy = (SampleClass) enhancer.create();\nfor (int i = 0; i < 3; i++) {\n    Assert.assertEquals(\"Hello, zhenchao\", proxy.hello(\"zhenchao\"));\n}\n```\n\n输出如下：\n\n```text\nSampleClass$$EnhancerByCGLIB$$f6b27b53: default construct method\nproxy: SampleClass$$EnhancerByCGLIB$$f6b27b53\nSampleClass: default construct method\nSampleClass: hello method\nproxy: SampleClass$$EnhancerByCGLIB$$f6b27b53\nSampleClass: default construct method\nSampleClass: hello method\nproxy: SampleClass$$EnhancerByCGLIB$$f6b27b53\nSampleClass: default construct method\nSampleClass: hello method\n```\n\n#### NoOp：直接委托给被代理类执行\n\nNoOp 接口未声明任何方法，如果将 callback 设置为 NoOp 实例，则每次方法调用都会直接委托给被代理方法执行：\n\n```java\nEnhancer enhancer = new Enhancer();\nenhancer.setSuperclass(SampleClass.class);\nenhancer.setCallback(NoOp.INSTANCE);\nSampleClass proxy = (SampleClass) enhancer.create();\nAssert.assertEquals(\"Hello, zhenchao\", proxy.hello(\"zhenchao\")); // 直接调用被代理的 hello 方法\n```\n\n#### CallbackFilter：组合多种回调\n\nDispatcher 和 NoOp 从上面的示例看起来似乎是多此一举，没有太大的用处，但是在一些场景下可以使用 CallbackFilter 将它们组合起来使用，以应对不同调用分而治之，示例如下：\n\n```java\nEnhancer enhancer = new Enhancer();\nenhancer.setSuperclass(SampleClass.class);\nCallbackHelper callbackHelper = new CallbackHelper(SampleClass.class, new Class[0]) {\n    @Override\n    protected Object getCallback(Method method) {\n        if (method.getDeclaringClass() != Object.class && method.getReturnType() == String.class) {\n            return new FixedValue() {\n                @Override\n                public Object loadObject() throws Exception {\n                    return \"Hello, cglib!\"; // 对于被代理类中的返回类型为 String 的方法统一拦截\n                }\n            };\n        } else {\n            return NoOp.INSTANCE; // 对于其它方法直接委托给被代理类\n        }\n    }\n};\nenhancer.setCallbackFilter(callbackHelper);\nenhancer.setCallbacks(callbackHelper.getCallbacks());\nSampleClass proxy = (SampleClass) enhancer.create();\nAssert.assertEquals(\"Hello, cglib!\", proxy.hello(null));\nAssert.assertNotEquals(\"Hello, cglib!\", proxy.toString());\nSystem.out.println(\"hash code : \" + proxy.hashCode()); // 调用 hashCode 方法也能正常返回哈希值了\n```\n\n上面的示例我们为 SampleClass 创建了多个代理对象，如果当前是定义在被代理类中的 String 方法，则直接修改返回值，否则直接委托给被代理类执行，从而能够避免直接使用 FixedValue 一刀切的问题。这个时候我们调用 toString、hashCode 方法就能够正常返回我们期望的结果。\n\n### 工具类集合\n\n#### Bean 工具类集合\n\n##### ImmutableBean：创建对象的不可变引用\n\nImmutableBean 用来创建一个已有对象的不可变引用（`ImmutableBean#create` 方法），我们可以改变原对象的属性，这会反应在 CGLib 创建出来的不可变引用上，但是不允许通过不可变引用来修改原对象的值，示例如下：\n\n```java\nSampleBean bean = new SampleBean();\nbean.setValue(\"Hello world!\");\n// 创建一个不可变的 bean\nSampleBean immutableBean = (SampleBean) ImmutableBean.create(bean);\nAssert.assertEquals(\"Hello world!\", immutableBean.getValue());\n// 可以通过改变原有对象来改变不变对象\nbean.setValue(\"Hello world, again!\");\nAssert.assertEquals(\"Hello world, again!\", immutableBean.getValue());\n// 不允许在不变对象上进行修改\nimmutableBean.setValue(\"Hello cglib!\"); // 错误，不允许修改不可变对象\n```\n\n上面的示例中我们通过 `ImmutableBean#create` 方法创建了一个 SampleBean 对象的不可变引用，然后我们可以修改原对象的值，相应的修改会反应到不可变引用上，但是如果我们尝试修改不可变引用则会抛出异常。\n\n##### BeanGenerator：动态创建 bean 对象\n\nBeanGenerator 可以在 __运行时__ 动态创建一个 bean 对象，这个对象可以是实际不存在的类，例如下面的示例中就创建了一个包含 name 属性的 bean 对象，并调用了相应的 setter 和 getter 方法，但是我们并没有为该 bean 显式的定义类：\n\n```java\nBeanGenerator generator = new BeanGenerator();\ngenerator.addProperty(\"name\", String.class);\n\n// 动态创建一个 bean\nObject bean = generator.create();\n\n// 执行 setter 和 getter\nMethod setter = bean.getClass().getMethod(\"setName\", String.class);\nsetter.invoke(bean, \"zhenchao\");\nMethod getter = bean.getClass().getMethod(\"getName\");\nAssert.assertEquals(\"zhenchao\", getter.invoke(bean));\n```\n\n##### BeanCopier: 在两个不同类型 bean 对象之间执行属性拷贝\n\nBeanCopier 允许在两个不同类型（也可以是相同类型） bean 对象之间执行属性拷贝（按照属性名称匹配），如果属性名称相同但是类型不同，我们可以指定转换器。示例：\n\n```java\nBeanCopier copier = BeanCopier.create(SampleBean.class, SampleBean2.class, false);\nSampleBean bean = new SampleBean();\nbean.setValue(\"Hello cglib!\");\n\n// SampleBean2 与 SampleBean 具备相同的类型和名称属性定义\nSampleBean2 bean2 = new SampleBean2();\ncopier.copy(bean, bean2, null);\nAssert.assertEquals(\"Hello cglib!\", bean2.getValue());\n\nbean.setValue(\"1103\");\ncopier = BeanCopier.create(SampleBean.class, SampleBean3.class, true);\n// SampleBean3 与 SampleBean 具备同名但不同类型属性定义\nSampleBean3 bean3 = new SampleBean3();\ncopier.copy(bean, bean3, new Converter() {\n    @Override\n    public Object convert(Object value, Class target, Object context) {\n        return NumberUtils.isCreatable(String.valueOf(value)) ? NumberUtils.toInt(String.valueOf(value)) : value;\n    }\n});\nAssert.assertEquals(Integer.valueOf(1103), bean3.getValue());\n```\n\n##### BulkBean：为 bean 创建一个代理\n\nBulkBean 在定义时需要指定 bean 类型、setter 和 getter 方法，以及方法类型，然后我们就可以依据 BulkBean 提供的 property 相关方法来操作被代理 bean 对应的属性。示例：\n\n```java\nBulkBean bulkBean = BulkBean.create(\n        User.class,\n        new String[] {\"getName\", \"getAge\"},\n        new String[] {\"setName\", \"setAge\"},\n        new Class[] {String.class, Integer.class});\n\nUser user = new User().setName(\"zhenchao\").setAge(26);\n\n// 通过 bulk 来获取 bean 属性\nAssert.assertEquals(2, bulkBean.getPropertyValues(user).length);\nAssert.assertEquals(\"zhenchao\", bulkBean.getPropertyValues(user)[0]);\nAssert.assertEquals(26, bulkBean.getPropertyValues(user)[1]);\n\n// 通过 bulk 来设置 bean 属性\nbulkBean.setPropertyValues(user, new Object[] {\"xiaotang\", 26});\nAssert.assertEquals(\"xiaotang\", user.getName());\n```\n\n##### BeanMap：将一个 bean 对象转换成 map 集合\n\n```java\nUser user = new User();\nBeanMap map = BeanMap.create(user);\nuser.setName(\"zhenchao\").setAge(26);\nAssert.assertEquals(\"zhenchao\", map.get(\"name\"));\nAssert.assertEquals(26, map.get(\"age\"));\n```\n\n#### KeyFactory：用来动态生成多个值的键\n\n通常我们的键都是单一元素，而有多个值组成的键称为 multi-valued 键，KeyFactory 就是用来生成这种类型的键。首先我们需要定义一个接口，该接口必须仅包含一个 `Object newInstance(...)` 的方法，即方法名称为 newInstance，返回类型为 Object，示例：\n\n```java\npublic interface SampleKeyFactory {\n    Object newInstance(String... keys);\n}\n```\n\n然后我们就可以使用 KeyFactory 来创建 multi-values 键：\n\n```java\nSampleKeyFactory factory = (SampleKeyFactory) KeyFactory.create(SampleKeyFactory.class);\nObject key = factory.newInstance(\"foo\", \"bar\"); // 创建多值键\nMap<Object, String> map = new HashMap<>();\nmap.put(key, \"Hello, cglib!\");\nAssert.assertEquals(\"Hello, cglib!\", map.get(factory.newInstance(\"foo\", \"bar\")));\nAssert.assertFalse(map.containsKey(map.get(factory.newInstance(\"a\", \"b\"))));\n```\n\nKeyFactory 会为键对象生成正确的 equals 方法和 hashCode 方法，从而保证键能够被正确的使用。KeyFactory 在 CGlib 的内部实现中被大量使用。\n\n#### Mixin：混合多个接口的实现\n\n假设现在有两个接口：Interface1 和 Interface2，类 Class1 和 Class2 分别实现了这两个接口，如下：\n\n```java\npublic interface Interface1 {\n    String first();\n}\n\npublic class Class1 implements Interface1 {\n    @Override\n    public String first() {\n        return \"this is first\";\n    }\n}\n\npublic interface Interface2 {\n    String second();\n}\n\npublic class Class2 implements Interface2 {\n    @Override\n    public String second() {\n        return \"this is second\";\n    }\n}\n```\n\n现在我们希望有一个对象能够包含 Class1 和 Class2 中所有的功能实现，则可以定义一个接口 MixinInterface 继承 Interface1 和 Interface2，实现如下：\n\n```java\npublic interface MixinInterface extends Interface1, Interface2 { }\n```\n\n然后我们就可以使用 Mixin 机制动态创建一个 MixinInterface 接口的实现类对象，同时指定让该对象聚合 Class1 和 Class2 实现类的功能：\n\n```java\nMixin mixin = Mixin.create(\n        new Class[] {Interface1.class, Interface2.class, MixinInterface.class},\n        new Object[] {new Class1(), new Class2()});\nMixinInterface delegate = (MixinInterface) mixin;\nSystem.out.println(delegate.first());\nSystem.out.println(delegate.second());\n```\n\n#### StringSwitcher：建立 String 和 int 之间的映射关系\n\nStringSwitcher 可以建立一个 String 数组中值到 int 数组中值依据下标对应的映射关系，例如下面的示例中 one 对应 20，two 对应 10：\n\n```java\nString[] strings = new String[] {\"one\", \"two\"};\nint[] values = new int[] {20, 10};\nStringSwitcher switcher = StringSwitcher.create(strings, values, true);\nAssert.assertEquals(20, switcher.intValue(\"one\"));\nAssert.assertEquals(10, switcher.intValue(\"two\"));\nAssert.assertEquals(-1, switcher.intValue(\"three\")); // 默认值\n```\n\n这一机制在 java 7 之前可以被应用到 switch 中，因为 java 7 之前 switch 不支持匹配字符串，但是现在如果不是必须则不推荐使用。\n\n#### InterfaceMaker：动态创建接口\n\nInterfaceMaker 用于动态创建一个接口，我们可以使用 Signature 来声明接口中的方法：\n\n```java\n// 方法名称，返回类型，参数类型列表\nSignature signature = new Signature(\"hello\", Type.INT_TYPE, new Type[] {Type.DOUBLE_TYPE});\nInterfaceMaker maker = new InterfaceMaker();\nmaker.add(signature, new Type[0]);\nClass iface = maker.create();\nAssert.assertEquals(1, iface.getMethods().length);\nAssert.assertEquals(\"hello\", iface.getMethods()[0].getName());\nAssert.assertEquals(int.class, iface.getMethods()[0].getReturnType());\n```\n\n#### MethodDelegate：建立方法间的代理关系\n\nMethodDelegate 可以动态生成指定接口的实现类对象，并指定一个 bean 和无参数方法，调用接口的所有方法都会被委托给该 bean 的无参数方法：\n\n```java\nSampleBean bean = new SampleBean().setValue(\"Hello, cglib!\");\nInterface1 delegate = (Interface1) MethodDelegate.create(bean, \"getValue\", Interface1.class);\n// 调用接口的 Interface1#first 方法本质上在调用 SampleBean#getValue 方法\nAssert.assertEquals(\"Hello, cglib!\", delegate.first());\n```\n\n#### MulticastDelegate：广播调用指定接口方法到注册的实现类\n\nMulticastDelegate 允许我们在调用指定接口的某个方法时，会将其广播给所有的注册的实现类实例，即调用所有注册的实现类实例的相应方法。\n\n```java\npublic interface Provider {\n    String setValue(String value);\n}\n\npublic class SampleProvider implements Provider {\n\n    private String name;\n    private String value;\n\n    public SampleProvider(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public String setValue(String value) {\n        this.value = value;\n        return name;\n    }\n\n    public String getValue() {\n        return value;\n    }\n}\n```\n\n上面我们定义了一个 Provider 接口，该接口声明了一个 setValue 方法，类 SampleProvider 实现了该接口。MulticastDelegate 允许我们在调用 `Provider#setValue` 方法时，将其广播应用到实现类 SampleProvider 所有在册的实例上：\n\n```java\nMulticastDelegate delegate = MulticastDelegate.create(Provider.class);\nSampleProvider provider1 = new SampleProvider(\"provider a\");\nSampleProvider provider2 = new SampleProvider(\"provider b\");\ndelegate = delegate.add(provider1);\ndelegate = delegate.add(provider2);\n\nProvider provider = (Provider) delegate;\nSystem.out.println(provider.setValue(\"Hello world!\")); // 仅返回最后一个实例的返回值\n\nAssert.assertEquals(\"Hello world!\", provider1.getValue());\nAssert.assertEquals(\"Hello world!\", provider2.getValue());\n```\n\n__注意__ ：该机制要求对应的接口只能声明一个方法，如果对应的方法有返回值，则只能拿到最后一个注册实例的返回值。\n\n#### ConstructorDelegate：字节码层面的工厂方法\n\nConstructorDelegate 允许调用指定类型的指定构造方法来创建类型对象，首先我们需要声明一个 `Object newInstance(...)` 方法的接口（参数数目和类型没有限制，但只能有一个 newInstance 方法）：\n\n```java\npublic interface UserConstructorDelegate {\n    Object newInstance(String name, int age);\n}\n```\n\n假设我们有一个 User 类，该类刚好有一个构造方法 `User(String name, int age)`，接下来我们就可以使用 ConstructorDelegate 来构造 User 对象：\n\n```java\nUserConstructorDelegate delegate = (UserConstructorDelegate) ConstructorDelegate.create(User.class, UserConstructorDelegate.class);\nUser user = (User) delegate.newInstance(\"zhenchao\", 28);\nAssert.assertTrue(User.class.isAssignableFrom(user.getClass()));\nAssert.assertEquals(\"zhenchao\", user.getName());\nAssert.assertEquals(28, user.getAge().intValue());\n```\n\n#### ParallelSorter：更加快速的多维数组排序器\n\nParallelSorter 声明对于多维数组进行排序具备更加高效的性能，示例：\n\n```java\nInteger[][] value = {\n        {4, 3, 9, 0},\n        {2, 1, 6, 0}\n};\nParallelSorter.create(value).mergeSort(0);\nfor (final Integer[] v : value) {\n    System.out.println(Arrays.toString(v));\n}\n```\n\n#### FastClass：更快的反射方法调用\n\n我们在使用 java 反射时往往会顾忌反射执行的性能开销，而 FastClass 声明相对于 java 原生反射调用而言具备更加高效的性能，所以可以将其作为反射场景下部分 Class 对象功能的替代，使用示例：\n\n```java\nFastClass fastClass = FastClass.create(SampleBean.class);\nSampleBean bean = new SampleBean();\nFastMethod fastMethod = fastClass.getMethod(SampleBean.class.getMethod(\"hello\", String.class));\nAssert.assertEquals(\"hello, zhenchao\", fastMethod.invoke(bean, new Object[] {\"zhenchao\"}));\nfastMethod = fastClass.getMethod(SampleBean.class.getMethod(\"getValue\"));\nbean.setValue(\"Hi, 2019~\");\nAssert.assertEquals(\"Hi, 2019~\", fastMethod.invoke(bean, new Object[0]));\n```\n\n上面的示例中我们使用 FastClass 创建了 SampleBean 的类 Class 对象，并利用该对象反射调用执行 SampleBean 的相关方法。FastClass 主要用于对方法的反射调用（包括构造方法），而对于字段的操作则没有提供相应的实现。\n\nFastClass 是否真的比 java 原生反射调用快这里不做讨论，[CGLib: The missing manual](http://mydailyjava.blogspot.com/2013/11/cglib-missing-manual.html) 给到的观点是，现代 JVM 针对原生反射调用已经进行了优化，所以 FastClass 的优势并不明显。原文如下：\n\n> __How can the FastClass be faster than normal reflection?__\n>\n> Java reflection is executed by JNI where method invocations are executed by some C-code. The FastClass on the other side creates some byte code that calls the method directly from within the JVM. However, the newer versions of the HotSpot JVM (and probably many other modern JVMs) know a concept called inflation where the JVM will [translate reflective method calls](http://www.docjar.com/html/api/sun/reflect/ReflectionFactory.java.html) into [native version](http://www.docjar.com/html/api/sun/reflect/NativeMethodAccessorImpl.java.html)'s of FastClass when a reflective method is executed often enough. You can even control this behavior (at least on a HotSpot JVM) with setting the `sun.reflect.inflationThreshold` property to a lower value. (The default is 15.) This property determines after how many reflective invocations a JNI call should be substituted by a byte code instrumented version. I would therefore recommend to not use FastClass on modern JVMs, it can however fine-tune performance on older Java virtual machines.\n\n### 参考\n\n- [CGLib: The missing manual](http://mydailyjava.blogspot.com/2013/11/cglib-missing-manual.html)\n- [CGLib WIKI](https://github.com/cglib/cglib/wiki)\n","tags":["CGlib"],"categories":["java"]},{"title":"JStorm 源码解析：ACK 机制","url":"/2018/11/21/storm/storm-ack/","content":"\nAck 机制是 Storm 能够保证消息至少被处理一次（at least once）的核心，从而保证消息不丢失。在 topology 有向无环图中，spout 向 bolt 发射消息，上游 bolt 也会向下游 bolt 发射消息。Storm 设置了一类 acker 类型的系统 bolt 组件用于接收所有组件发送的 ack 消息，监控数据在 topology 中的处理情况。如果处理成功则发送 `__acker_ack` 消息给 spout，否则发送 `__acker_fail` 消息给 spout，然后 spout 依据相应的消息类型采取一定的应对措施（例如消息重发等）。<!-- more -->\n\nAck 算法利用了数学上的异或操作来实现对整个 tuple tree 的运行状况的判断。在一个由一条消息构成的 tuple tree 中，所有的消息都有一个 MessageId，本质上就是一个 map：\n\n```java\npublic class MessageId {\n    /* [anchor, anchor_value] */\n    private Map<Long, Long> _anchorsToIds;\n}\n```\n\n字段 `_anchorsToIds` 存储的是 anchor 和 anchor value 的映射，其中 anchor 就是 rootId，它在 spout 中生成并且一路透传到 tuple tree 对应的所有下游 bolt 中，同一个 tuple tree 中的消息都具有相同的 rootId，用以唯一标识 spout 发出来的这条消息（以及从下游 bolt 根据这个 tuple 衍生发出的消息）。\n\n### 算法介绍\n\n示例引用自 [官网](http://jstorm.io/ProgrammingGuide_cn/AdvancedUsage/Theory/Acker.html)，Ack 机制算法执行流程如下：\n\n1. spout 发送消息时生成 root_id。\n2. 同时对每一个目标 bolt task 生成 `<root_id, random_long>`（即为这个 root_id 对应一个随机 long 数值），然后随着消息本身发送到下游 bolt 中。假设有 2 个 bolt，生成的随机数对分别为：`<root_id, r1>` 和 `<root_id, r2>`。\n3. spout 向 acker 发送 ack_init 消息，它的 message_id 为 `<root_id, r1 ^ r2>`（即所有 task 产生的随机数列表的异或值）。\n4. bolt 收到 spout 或上游 bolt 发送过来的 tuple 之后，首先会向 acker 发送 ack 消息，message_id 即为收到的值。如果 bolt 下游还有 bolt，则与步骤 2 类似对每一个 bolt 生成随机数对（root_id 不变，但是值变为与当前值亦或新生成的随机数）。\n5. acker 收到消息后会对 root_id 下所有的值做异或操作，亦或结果为 0 则表示整个 tuple tree 被成功处理，否则就会一直等待直到超时，对应 tuple tree 处理失败。\n6. acker 向 spout 发送最终处理成功或失败的消息。\n\n![image](/images/2018/jstorm-acker-2.png)\n\n我们以一个稍微复杂一点的 topology 为例描述一下它的整个过程。假设 topology 结构为 `spout -> bolt1/bolt2 -> bolt3`，即 spout 同时向 bolt1 和 bolt2 发送消息，它们处理完后都向 bolt3 发送消息，bolt3 没有后续处理节点。对于这样一个 topology 而言，ack 机制的执行流程如下：\n\n1. spout 发射一条消息生成 root_id，由于这个值不变我们就用 root_id 来标识：\n\n> - spout -> bolt1 的 message_id = `<root_id, 1>`\n> - spout -> bolt2 的 message_id = `<root_id, 2>`\n> - spout -> acker 的 message_id = `<root_id, 1^2>`\n\n2. bolt1 收到消息后生成如下消息：\n\n> - bolt1 -> bolt3 的 message_id = `<root_id, 3>`\n> - bolt1 -> acker 的 message_id = `<root_id, 1^3>`\n\n3. bolt2 收到消息后生成如下消息：\n\n> - bolt2 -> bolt3 的 message_id = `<root_id, 4>`\n> - bolt2 -> acker 的 message_id = `<root_id, 2^4>`\n\n4. bolt3 收到消息后生成如下消息：\n\n> - bolt3 -> acker 的 message_id = `<root_id, 3>`\n> - bolt3 -> acker 的 message_id = `<root_id, 4>`\n\n5. acker 总共收到以下消息：\n\n```text\n- <root_id, 1^2>\n- <root_id, 1^3>\n- <root_id, 2^4>\n- <root_id, 3>\n- <root_id, 4>\n```\n\n所有的值进行异或之后即为 `1^2^1^3^2^4^3^4 = 0`。\n\n### 实现分析\n\n下面从源码层面分析对于上面描述的算法的实现，相应逻辑分别位于 SpoutCollector、BoltCollector 和 Acker 中。先来看一下 spout 的逻辑，spout 在 emit 消息的时候顺带会向 acker 发送一条 `ack_init` 消息，相应实现位于 `SpoutCollector#sendMsg` 方法中，实现如下：\n\n```java\npublic List<Integer> sendMsg(\n        String out_stream_id, List<Object> values, Object message_id, Integer out_task_id, ICollectorCallback callback) {\n    final long startTime = emitTotalTimer.getTime();\n    try {\n        boolean needAck = (message_id != null) && (ackerNum > 0);\n        // 生成随机的 rootId (随机 long 数值)，需要确保在当前 spout 唯一，否则无法保证 ack 的准确性\n        Long root_id = this.getRootId(message_id);\n        List<Integer> outTasks;\n        // 获取目标 taskId 列表\n        if (out_task_id != null) {\n            outTasks = sendTargets.get(out_task_id, out_stream_id, values, null, root_id);\n        } else {\n            outTasks = sendTargets.get(out_stream_id, values, null, root_id);\n        }\n\n        List<Long> ackSeq = new ArrayList<>(); // 存放为所有 bolt task 生成的随机数值\n        /*\n         * 遍历所有的目标 task：\n         * 1. 为每个目标 task 生成 messageId： <root_id, 随机数值>\n         * 2. 向所有目标 task 发射 tuple 消息\n         */\n        for (Integer taskId : outTasks) {\n            MessageId msgId;\n            if (needAck) {\n                long as = MessageId.generateId(random); // 生成随机的 long 数值\n                msgId = MessageId.makeRootId(root_id, as); // <root_id, 随机数值>\n                ackSeq.add(as); // 添加到 ackSeq 中，用于后面亦或计算\n            } else {\n                msgId = null;\n            }\n\n            // 获取当前 tuple 对应的目标 task 的传输队列，然后将 tuple 投递给该队列\n            TupleImplExt tuple = new TupleImplExt(topology_context, values, task_id, out_stream_id, msgId);\n            tuple.setTargetTaskId(taskId);\n            transfer_fn.transfer(tuple);\n        }\n        // 向 Acker 发送 ack_init 消息\n        this.sendMsgToAck(out_stream_id, values, message_id, root_id, ackSeq, needAck);\n        if (callback != null) {\n            callback.execute(out_stream_id, outTasks, values);\n        }\n        return outTasks;\n    } finally {\n        emitTotalTimer.updateTime(startTime);\n    }\n}\n```\n\n整个方法的执行步骤可以概括为：\n\n1. 为当前 tuple tree 生成在当前 spout 范围内唯一的 root_id；\n2. 获取下游目标 task 集合，并为每一个 task 生成对应的 message_id；\n3. 向所有下游目标 task 发送 tuple 消息；\n4. 向 acker 发送 ack_init 消息。\n\n上面的步骤中 1 和 2 都是在做准备工作，步骤 3 则是发射 tuple 的主体流程，步骤 4 才是 spout 真正执行 ack 的过程。对于一个 tuple 而言，spout 会向所有下游目标 task 逐一发送该 tuple，同时在发射完成之后向 acker 发送一条 `ack_init` 消息。spout ack 的实现位于 `SpoutCollector#sendMsgToAck` 方法中：\n\n```java\nprotected void sendMsgToAck(\n        String outStreamId, List<Object> values, Object messageId, Long rootId, List<Long> ackSeq, boolean needAck) {\n    if (needAck) {\n        TupleInfo info = TupleInfo.buildTupleInfo(outStreamId, messageId, values, System.currentTimeMillis(), isCacheTuple);\n        pending.putHead(rootId, info);\n        // ackerTuple = <root_id, 所有目标 task 的 messageId 随机数值的异或, task_id>\n        List<Object> ackerTuple = JStormUtils.mk_list((Object) rootId, JStormUtils.bit_xor_vals(ackSeq), task_id);\n        // 向 Acker 发射 ack_init 消息，依据 __ack_init 这个 stream 直接找到目标 task 进行发送\n        this.unanchoredSend(topology_context, sendTargets, transfer_fn, Acker.ACKER_INIT_STREAM_ID, ackerTuple);\n    } else if (messageId != null) {\n        // 不需要 ack 但是仍然实现了 IAckValueSpout 接口，需要为这种 spout 回调 ack 方法\n        TupleInfo info = TupleInfo.buildTupleInfo(outStreamId, messageId, values, 0, isCacheTuple);\n        AckSpoutMsg ack = new AckSpoutMsg(rootId, spout, null, info, task_stats);\n        ack.run();\n    }\n}\n```\n\n对于开启了 ack 机制的 topology 来说，方法会对所有下游目标 task 的 message_id 的随机数值执行亦或运算，将结果与 root_id 和当前 spout 的 task_id 一起封装成 tuple 发送给 acker。\n\n下面再来看一下 bolt 的 ack 执行过程。bolt 将 emit 和 ack 分成两个方法，这主要也是为了方便开发者编程实现对于消息消费执行的控制。先来看一下 emit 过程，位于 `BoltCollector#sendMsg` 方法中：\n\n```java\npublic List<Integer> sendMsg(String out_stream_id, List<Object> values,\n                             Collection<Tuple> anchors, Integer out_task_id, ICollectorCallback callback) {\n    final long start = emitTimer.getTime();\n    List<Integer> outTasks = null;\n    try {\n        // 获取所有目标 task 列表\n        if (out_task_id != null) {\n            outTasks = sendTargets.get(out_task_id, out_stream_id, values, anchors, null);\n        } else {\n            outTasks = sendTargets.get(out_stream_id, values, anchors, null);\n        }\n\n        // 提前删除可能超时的 tuple\n        this.tryRotate();\n\n        /*\n         * 遍历所有的目标 task：\n         * 1. 为每一个 task 生成 messageId：<root_id, 随机数值>\n         * 2. 向所有下游 bolt 发射 tuple 消息\n         */\n        for (Integer taskId : outTasks) {\n            // 计算目标 task 的 messageId\n            MessageId msgId = this.getMessageId(anchors);\n            TupleImplExt tuple = new TupleImplExt(topologyContext, values, this.taskId, out_stream_id, msgId);\n            tuple.setTargetTaskId(taskId);\n            taskTransfer.transfer(tuple);\n        }\n    } catch (Exception e) {\n        LOG.error(\"bolt emit error:\", e);\n    } finally {\n        // 省略 finally 逻辑\n    }\n    return outTasks;\n}\n```\n\n实际上一个 bolt 也可以看做是一个特殊的 spout，因为这个时候它相当于是当前 tuple tree 中一个 sub tuple tree 的消息起始点，所以在执行逻辑上与 spout emit 消息基本上相同。上面的方法实现整体与 `SpoutCollector#sendMsg` 也基本类似，这里我们主要看一下计算下游 task 的 message_id 的逻辑，位于 `BoltCollector#getMessageId` 方法中：\n\n```java\nprotected MessageId getMessageId(Collection<Tuple> anchors) {\n    MessageId ret = null;\n    if (anchors != null && ackerNum > 0) {\n        Map<Long, Long> anchors_to_ids = new HashMap<>();\n        for (Tuple tuple : anchors) {\n            if (tuple.getMessageId() != null) {\n                Long edge_id = MessageId.generateId(random);\n                // 更新当前 inputTuple 的 edge_id 亦或值到 pending_acks\n                put_xor(pendingAcks, tuple, edge_id);\n                MessageId messageId = tuple.getMessageId();\n                if (messageId != null) {\n                    // 这里将每一对 <root_id, edge_id> 放入 anchors_to_ids（一般情况下也只有一对），\n                    // 由于 anchors_to_ids 是一个空 map，因此 put_xor 里面相当于将 <root_id, edge_id> 放入 anchors_to_ids\n                    for (Long root_id : messageId.getAnchorsToIds().keySet()) {\n                        put_xor(anchors_to_ids, root_id, edge_id);\n                    }\n                }\n            }\n        }\n        // new MessageId\n        ret = MessageId.makeId(anchors_to_ids);\n    }\n    return ret;\n}\n```\n\n方法 getMessageId 的入参 anchors 是发送给当前 bolt 的 tuple，大部分时候只有一个，所以上面的方法实现我们可以简化一下：\n\n```java\nprotected MessageId getMessageId(Tuple tuple) {\n    Map<Long, Long> anchors_to_ids = new HashMap<>();\n    if (tuple.getMessageId() != null) {\n        Long edge_id = MessageId.generateId(random);\n        // 放置 <inputTuple, edge_id> 到 pending_acks\n        put_xor(pendingAcks, tuple, edge_id); // <tuple, edge_id>, pendingAcks 会在 bolt 执行 ack 时用到\n        MessageId messageId = tuple.getMessageId();\n        if (messageId != null) {\n            // 这里将每一对 <root_id, edge_id> 放入 anchors_to_ids（一般情况下也只有一对），\n            // 由于 anchors_to_ids 是一个空 map，因此 put_xor 里面相当于将 <root_id, edge_id> 放入 anchors_to_ids\n            for (Long root_id : messageId.getAnchorsToIds().keySet()) {\n                put_xor(anchors_to_ids, root_id, edge_id);\n            }\n        }\n    }\n    return MessageId.makeId(anchors_to_ids); // <root_id, edge_id>\n}\n```\n\n简化之后应该更加清晰一些，实际上逻辑很简单，就是为下游 bolt 生成一个随机 long 数值作为 edge_id，然后将 edge_id 和 root_id 一起生成下游 bolt 的 message_id，也就是 `<root_id, edge_id>`。\n\n下面我们再来看一下 bolt 的 ack 过程，位于 `BoltCollector#ack` 方法中：\n\n```java\npublic void ack(Tuple input) {\n    if (input.getMessageId() != null) {\n        Long ack_val = 0L;\n        // 取出当前 inputTuple 对应的 edge_id 值\n        Object pend_val = pendingAcks.remove(input); // <tuple, edge_id>，getMessageId 时写入的，\n        if (pend_val != null) {\n            ack_val = (Long) (pend_val);\n        }\n\n        // 向 Acker 发送 ack 消息\n        for (Entry<Long, Long> entry : input.getMessageId().getAnchorsToIds().entrySet()) {\n            this.unanchoredSend(topologyContext, sendTargets, taskTransfer, Acker.ACKER_ACK_STREAM_ID, // __ack_ack\n                    // 当前 task 的 egge_id 与目标 task 的 edge_id 进行亦或\n                    JStormUtils.mk_list((Object) entry.getKey(), JStormUtils.bit_xor(entry.getValue(), ack_val)));\n        }\n    }\n\n    // 省略状态统计逻辑\n}\n```\n\n整个方法的逻辑就是拿到当前 task 的 edge_id 与目标 task 的 edge_id 进行亦或运算，然后将结果与 root_id（`<root_id, egde_id1 ^ edge_id2>`）一起发送给 acker。\n\n最后我们来看一下 acker 的执行流程，acker 本质上也是一个 bolt，只不过是由系统创建，所以相应的处理逻辑位于 `Acker#execute` 方法中，实现如下：\n\n```java\npublic void execute(Tuple input) { // root_id, random_long, task_id\n    Object id = input.getValue(0);\n    AckObject curr = pending.get(id);\n    String stream_id = input.getSourceStreamId();\n    // __acker_init 消息，由 spout 发送，直接放入 pending map 中\n    if (Acker.ACKER_INIT_STREAM_ID.equals(stream_id)) {\n        if (curr == null) {\n            curr = new AckObject();\n            curr.val = input.getLong(1);\n            curr.spout_task = input.getInteger(2);\n            pending.put(id, curr);\n        } else {\n            // bolt's ack first come\n            curr.update_ack(input.getValue(1)); // 进行亦或运算\n            curr.spout_task = input.getInteger(2);\n        }\n\n    }\n    // __ack_ack 消息，来自于 Bolt 发送\n    else if (Acker.ACKER_ACK_STREAM_ID.equals(stream_id)) {\n        if (curr != null) {\n            curr.update_ack(input.getValue(1)); // 进行亦或运算\n        } else {\n            // two case\n            // one is timeout\n            // the other is bolt's ack first come\n            curr = new AckObject();\n            curr.val = input.getLong(1);\n            pending.put(id, curr);\n        }\n    }\n    // __ack_fail 消息，来自于 Bolt 发送\n    else if (Acker.ACKER_FAIL_STREAM_ID.equals(stream_id)) {\n        if (curr == null) {\n            // do nothing\n            // already timeout, should go fail\n            return;\n        }\n        curr.failed = true;\n    } else {\n        LOG.info(\"Unknown source stream, \" + stream_id + \" from task-\" + input.getSourceTask());\n        return;\n    }\n\n    // 向 spout 发射 ack/fail 消息\n    Integer task = curr.spout_task;\n    if (task != null) {\n        if (curr.val == 0) {\n            // 消息消费成功\n            pending.remove(id);\n            List values = JStormUtils.mk_list(id);\n            collector.emitDirect(task, Acker.ACKER_ACK_STREAM_ID, values);\n        } else {\n            if (curr.failed) {\n                // 消息消费失败\n                pending.remove(id);\n                List values = JStormUtils.mk_list(id);\n                collector.emitDirect(task, Acker.ACKER_FAIL_STREAM_ID, values);\n            }\n            // 否则表示还未执行完成，不执行操作\n        }\n    }\n\n    // 更新 metrics\n    collector.ack(input);\n\n    // 检测是否已经超时了\n    long now = System.currentTimeMillis();\n    if (now - lastRotate > rotateTime) {\n        lastRotate = now;\n        Map<Object, AckObject> tmp = pending.rotate();\n        if (tmp.size() > 0) {\n            LOG.warn(\"Acker's timeout item size:{}\", tmp.size());\n        }\n    }\n\n}\n```\n\n方法的实现虽然很长，但是逻辑还是比较清晰简单的，acker 会为每一个 spout task 创建一个 AckObject 对象，用于记录对应 tuple tree 的执行状态，并在每次接收到来自 spout 和 bolt 的 ack 消息时对该对象进行相应的更新，如果所有的亦或运算结果为 0 则表示 tuple tree 被执行成功，此时 acker 会向 spout 发送消息消费成功的消息，否则如果有 bolt 明确 ack fail，则向 spout 发送消息消费失败的消息，否则基于超时机制进行判定。\n\nOK，关于 JStorm 的源码分析到这一篇基本上就结束了，我们分析了整个 JStorm 的运行骨架，知道我们编写的 topology 任务在集群上的执行过程，同时也了解了一个大规模分布式系统在实现上需要考虑的一些关键点，后面有时间会继续完善本系列，比如继续分析 trident 的实现机制等。\n","tags":["Storm","JStorm"],"categories":["storm"]},{"title":"JStorm 源码解析：Worker 的启动和运行机制","url":"/2018/11/20/storm/storm-worker/","content":"\n上一篇我们分析了 supervisor 节点的启动和运行过程，提及到 supervisor 的核心工作就是基于 ZK 从 nimbus 节点领取分配给它的任务，并启动 worker 执行。一个 worker 就是一个 JVM 进程，运行在 supervisor 节点上，多个 task 可以同时运行在一个 worker 进程之中，每个 task 都对应一个线程。\n\nWorker 进程的启动位于 Worker 类中，前面我们在分析 supervisor 节点的启动过程时提及到了对于 Worker 类 main 函数的触发，supervisor 在启动相应 worker 进程时会指定 topologyId、supervisorId、workerPort、workerId，以及 classpath 等参数，worker 在拿到这些参数之后会先获取当前机器上端口对应的老进程，并逐一 kill 掉，然后调用 `Worker#mk_worker` 方法创建并启动对应的 worker 实例，<!-- more -->该方法的核心实现如下：\n\n```java\nWorker w = new Worker(conf, context, topologyId, supervisorId, port, workerId, jarPath);\nreturn w.execute();\n```\n\nWorker 类仅包含一个实例属性 WorkerData，它封装了所有与 worker 运行相关的属性，实例化 Worker 对象的过程也是初始化 WorkerData 属性的过程，该过程主要包含以下工作：\n\n1. 初始化基本属性（包括运行基本配置项、消息上下文对象等），同时设置初始状态；\n2. 检查当前运行模式，对于集群模式会在本地创建相应的工作目录 `workers/${worker_id}/pids`；\n3. 从 ZK 获取当前集群的运行状态；\n4. 加载 topology 配置信息，并注册相应的配置动态更新监听器；\n5. 注册一系列 mertics 监控项，用于打点 worker 的运行状态；\n6. 加载当前 topology 对应的序列化对象；\n7. 创建并初始化相关的消息传输队列。\n\n初始化完成之后会调用 `Worker#execute` 方法创建并启动 worker 进程，该方法主要的执行流程可以概括如下：\n\n1. 为当前 worker 创建并启动一个 socket 连接，用于接收消息并分发给名下的 task 线程；\n2. 启动一个线程用于维护当前 worker 状态变更时，更新与其它 worker 之间的连接关系；\n3. 启动一个线程用于定期获取当前 topology 在 ZK 上的基本信息，当 topology 状态发生变更时触发本地相应操作；\n4. 启动一个线程循环消费当前 worker 的 tuple 队列发送给对应的下游 task 线程；\n5. 启动一个线程用于定期更新本地的 worker 心跳信息；\n6. 创建并启动当前 worker 下所有的 task 任务。\n\n方法实现如下：\n\n```java\npublic WorkerShutdown execute() throws Exception {\n    List<AsyncLoopThread> threads = new ArrayList<>();\n\n    // 1. 为 worker 创建一个 socket 连接，接收和分发消息给对应的 task\n    AsyncLoopThread controlRvThread = this.startDispatchThread();\n    threads.add(controlRvThread);\n\n    // 2. 创建线程用于在 worker 关闭或者新启动时更新与其他 worker 之间的连接信息\n    RefreshConnections refreshConn = this.makeRefreshConnections();\n    AsyncLoopThread refreshConnLoopThread = new AsyncLoopThread(refreshConn, false, Thread.MIN_PRIORITY, true);\n    threads.add(refreshConnLoopThread);\n\n    // 3. 获取 topology 在 ZK 上的状态，当状态发生变更时更新本地 task 状态\n    RefreshActive refreshZkActive = new RefreshActive(workerData);\n    AsyncLoopThread refreshZk = new AsyncLoopThread(refreshZkActive, false, Thread.MIN_PRIORITY, true);\n    threads.add(refreshZk);\n\n    // 4. 创建一个线程循环消费 tuple 队列发送给对应的下游 task\n    DrainerCtrlRunnable drainerCtrlRunnable = new DrainerCtrlRunnable(workerData, MetricDef.SEND_THREAD);\n    AsyncLoopThread controlSendThread = new AsyncLoopThread(drainerCtrlRunnable, false, Thread.MAX_PRIORITY, true);\n    threads.add(controlSendThread);\n\n    // Sync heartbeat to Apsara Container\n    AsyncLoopThread syncContainerHbThread = SyncContainerHb.mkWorkerInstance(workerData.getStormConf());\n    if (syncContainerHbThread != null) {\n        threads.add(syncContainerHbThread);\n    }\n\n    JStormMetricsReporter metricReporter = new JStormMetricsReporter(workerData);\n    metricReporter.init();\n    workerData.setMetricsReporter(metricReporter);\n\n    // 5. 更新本地心跳信息\n    RunnableCallback heartbeatFn = new WorkerHeartbeatRunnable(workerData);\n    AsyncLoopThread hb = new AsyncLoopThread(heartbeatFn, false, null, Thread.NORM_PRIORITY, true);\n    threads.add(hb);\n\n    // 6. 创建并启动当前 worker 下所有的 task\n    List<TaskShutdownDaemon> shutdownTasks = this.createTasks();\n    workerData.setShutdownTasks(shutdownTasks);\n\n    List<AsyncLoopThread> serializeThreads = workerData.setSerializeThreads();\n    threads.addAll(serializeThreads);\n    List<AsyncLoopThread> deserializeThreads = workerData.setDeserializeThreads();\n    threads.addAll(deserializeThreads);\n\n    return new WorkerShutdown(workerData, threads);\n}\n```\n\n### 消息接收与分发\n\nStorm 会为 worker 基于 Netty 创建并返回一个 socket 连接用于接收消息，同时 worker 与名下所有 task 之间会维持一个传输队列，并启动一个线程循环消费接收到的消息投递给对应 task 的传输队列中。该过程位于 `Worker#startDispatchThread` 方法中，该方法实现如下（去掉了一些非关键代码）：\n\n```java\nprivate AsyncLoopThread startDispatchThread() {\n    IContext context = workerData.getContext(); // 获取消息上下文：NettyContext\n    String topologyId = workerData.getTopologyId();\n\n    // 1. 创建一个接收消息的消息队列（disruptor）\n    Map stormConf = workerData.getStormConf();\n    long timeout = JStormUtils.parseLong(stormConf.get(Config.TOPOLOGY_DISRUPTOR_WAIT_TIMEOUT), 10); // 默认 10ms\n    WaitStrategy waitStrategy = new TimeoutBlockingWaitStrategy(timeout, TimeUnit.MILLISECONDS); // 10ms\n    int queueSize = JStormUtils.parseInt(stormConf.get(Config.TOPOLOGY_CTRL_BUFFER_SIZE), 256);\n    DisruptorQueue recvControlQueue = DisruptorQueue.mkInstance(\"Dispatch-control\", ProducerType.MULTI, queueSize, waitStrategy, false, 0, 0);\n\n    // 2. 为当前 worker 基于 Netty 创建并返回一个 Socket 连接用于接收消息\n    IConnection recvConnection = context.bind(\n            topologyId, workerData.getPort(), workerData.getDeserializeQueues(), recvControlQueue, false, workerData.getTaskIds());\n    workerData.setRecvConnection(recvConnection);\n\n    // 3. 启动一个线程循环消费 worker 接收到的消息，并应用 DisruptorRunnable.onEvent 方法,\n    //    最终调用的是 VirtualPortCtrlDispatch.handleEvent 方法，将消息投递给指定 task 的消息队列\n    RunnableCallback recvControlDispatcher = new VirtualPortCtrlDispatch(\n            workerData, recvConnection, recvControlQueue, MetricDef.RECV_THREAD);\n    return new AsyncLoopThread(recvControlDispatcher, false, Thread.MAX_PRIORITY, true);\n}\n```\n\n这里的消息队列底层都依赖于 [disruptor](https://github.com/LMAX-Exchange/disruptor) 实现，最终对于接收到的消息都会调用 `VirtualPortCtrlDispatch#handleEvent` 方法进行处理：\n\n```java\npublic void handleEvent(Object event, boolean endOfBatch) throws Exception {\n    TaskMessage message = (TaskMessage) event;\n    int task = message.task(); // 获取当前消息对应的 taskId\n\n    // 消息反序列化\n    Object tuple = null;\n    try {\n        // there might be errors when calling update_topology\n        tuple = this.deserialize(message.message(), task);\n    } catch (Throwable e) {\n        if (Utils.exceptionCauseIsInstanceOf(KryoException.class, e)) {\n            throw new RuntimeException(e);\n        }\n        LOG.warn(\"serialize msg error\", e);\n    }\n\n    // 获取 taskId 对应的消息通道\n    DisruptorQueue queue = controlQueues.get(task);\n    if (queue == null) {\n        LOG.warn(\"Received invalid control message for task-{}, Dropping...{} \", task, tuple);\n        return;\n    }\n    if (tuple != null) {\n        // 将消息投递给对应的 task 传输队列\n        queue.publish(tuple);\n    }\n}\n```\n\n### 创建并启动用于维护 worker 之间连接关系的线程\n\n在这一步会创建一个 RefreshConnections 对象，它继承了 RunnableCallback 类，所以同样是被异步循环线程模型接管（按照指定间隔循环调用其 `RefreshConnections#run` 方法），Storm 会定期检测 ZK 上的 topology 任务分配信息是否有更新，如果有比本地更新的任务分配（依赖于任务分配时间戳进行判定）则会判断新任务分配的类型来相应的更新本地的信息。\n\n如果当前的任务分配类型仅仅是更新集群上已有的 topology，则 Storm 会遍历通知各个 task 执行相应的更新操作，同时会回调已注册的所有更新监听器以更新配置信息，实现如下：\n\n```java\n// 当前任务分配已经更新且是更新 topology 操作，则通知所有的 task\nList<TaskShutdownDaemon> taskShutdowns = workerData.getShutdownTasks();\nMap newConf = StormConfig.read_supervisor_topology_conf(conf, topologyId);\nworkerData.getStormConf().putAll(newConf);\nfor (TaskShutdownDaemon taskSD : taskShutdowns) {\n    // 通知所有的 task\n    taskSD.update(newConf);\n}\n// disable/enable metrics on the fly\nworkerData.getUpdateListener().update(newConf); // 回调更新监听器，更新配置\nworkerData.setAssignmentType(AssignmentType.UpdateTopology);\n```\n\n如果当前是更新以外的任务分配类型（Assign、ScaleTopology），则 Storm 会从新的任务分配信息中分别获取新增的、待删除的，以及需要更新的 taskId 列表，并执行相应的创建、删除，以及更新 task 操作，同时会更新 worker 上所有 task 的下游 task 列表信息。部分代码实现如下：\n\n```java\n// 获取新增的 taskId 列表\nSet<Integer> addedTasks = this.getAddedTasks(assignment);\n// 获取待删除的 taskId 列表\nSet<Integer> removedTasks = this.getRemovedTasks(assignment);\n// 获取待更新的 taskId 列表\nSet<Integer> updatedTasks = this.getUpdatedTasks(assignment);\n\n// 基于新任务分配信息更新 workerData\nworkerData.updateWorkerData(assignment);\nworkerData.updateKryoSerializer();\n\n// 关闭需要移除的 task\nthis.shutdownTasks(removedTasks);\n// 创建新增的 task\nthis.createTasks(addedTasks);\n// 更新已有需要被更新的 task\nthis.updateTasks(updatedTasks);\n\n// 更新当前 worker 上所有 task 的下游 task 列表信息\nSet<Integer> tmpOutboundTasks = Worker.worker_output_tasks(workerData);\nif (!outboundTasks.equals(tmpOutboundTasks)) {\n    for (int taskId : tmpOutboundTasks) {\n        if (!outboundTasks.contains(taskId)) {\n            workerData.addOutboundTaskStatusIfAbsent(taskId);\n        }\n    }\n    for (int taskId : workerData.getOutboundTaskStatus().keySet()) {\n        if (!tmpOutboundTasks.contains(taskId)) {\n            workerData.removeOutboundTaskStatus(taskId);\n        }\n    }\n    workerData.setOutboundTasks(tmpOutboundTasks);\n    outboundTasks = tmpOutboundTasks;\n}\nworkerData.setAssignmentType(AssignmentType.Assign);\n```\n\n### 创建并启动定期获取 topology 基本信息的线程\n\n在这一步会创建一个 RefreshActive 对象，它同样继承了 RunnableCallback 类，所以同样也是被异步循环线程模型接管（按照指定间隔循环调用其 `RefreshActive#run` 方法），Storm 会定期获取当前 topology 在 ZK 上的基本信息，当 topology 状态发生变更时触发本地执行相应的操作。\n\n如果 topology 状态信息变为 active、upgrading，或者 rollback 时，Storm 会依次将本地 task 的状态设置为 `TaskStatus.RUN`，如果当前 task 对应的组件是 spout，则会触发 `ISpout#activate` 方法。如果当前 topology 状态不为 inactive 时，Storm 会依次将本地的 task 状态设置为 `TaskStatus.PAUSE`，如果当前 task 对应的组件是 spout，则会触发 `ISpout#deactivate` 方法。最后更新本地记录的 topology 状态。相关实现如下：\n\n```java\nif (newTopologyStatus.equals(StatusType.active) // 激活\n        || newTopologyStatus.equals(StatusType.upgrading) // 灰度\n        || newTopologyStatus.equals(StatusType.rollback)) { // 回滚\n    for (TaskShutdownDaemon task : tasks) {\n        if (task.getTask().getTaskStatus().isInit()) {\n            task.getTask().getTaskStatus().setStatus(TaskStatus.RUN);\n        } else {\n            task.active();\n        }\n    }\n} else if (oldTopologyStatus == null || !oldTopologyStatus.equals(StatusType.inactive)) {\n    for (TaskShutdownDaemon task : tasks) {\n        if (task.getTask().getTaskStatus().isInit()) {\n            task.getTask().getTaskStatus().setStatus(TaskStatus.PAUSE);\n        } else {\n            task.deactive();\n        }\n    }\n}\nworkerData.setTopologyStatus(newTopologyStatus);\n```\n\n### 创建并启动循环消费 worker tuple 队列的线程\n\n在这一步会创建一个 DrainerCtrlRunnable 对象，它同样继承了 RunnableCallback 类，所以同样也是被异步循环线程模型接管（按照指定间隔循环调用其 `DrainerCtrlRunnable#run` 方法），Storm 会循环消费当前 worker 的 tuple 队列 transferCtrlQueue，并最终调用 `DrainerCtrlRunnable#handleEvent` 方法对拿到的消息进行处理，该方法的实现如下：\n\n```java\npublic void handleEvent(Object event, boolean endOfBatch) throws Exception {\n    if (event == null) {\n        return;\n    }\n    ITupleExt tuple = (ITupleExt) event;\n    int targetTask = tuple.getTargetTaskId();\n\n    // 获取与下游 task 的连接\n    IConnection conn = this.getConnection(targetTask);\n    if (conn != null) {\n        byte[] tupleMessage = null;\n        try {\n            // there might be errors when calling update_topology\n            tupleMessage = this.serialize(tuple); // 序列化数据\n        } catch (Throwable e) {\n            // 省略异常处理\n        }\n        // 基于 netty 发送数据\n        TaskMessage message = new TaskMessage(TaskMessage.CONTROL_MESSAGE, targetTask, tupleMessage);\n        conn.sendDirect(message);\n    }\n}\n```\n\n方法的逻辑比较简单，拿到当前 tuple 对应的下游 taskId，然后与之建立连接（netty）并将 tuple 发送给它。\n\n### 创建并启动当前 worker 下所有的 task 线程\n\n方法 `Worker#createTasks` 用于为当前 worker 下的所有 task 任务创建一个 Task 对象，并为每个 task 启动一个线程执行，同时为每个 task 任务创建一个 TaskShutdownDaemon 对象用于管理对应的 task 线程，方法的实现如下：\n\n```java\nprivate List<TaskShutdownDaemon> createTasks() throws Exception {\n    List<TaskShutdownDaemon> shutdownTasks = new ArrayList<>();\n\n    // 获取当前 worker 下所有的 taskId\n    Set<Integer> taskIds = workerData.getTaskIds();\n\n    Set<Thread> threads = new HashSet<>();\n    List<Task> taskArrayList = new ArrayList<>();\n    for (int taskId : taskIds) {\n        // 创建并启动 task\n        Task task = new Task(workerData, taskId);\n        Thread thread = new Thread(task);\n        threads.add(thread);\n        taskArrayList.add(task);\n        thread.start(); // 启动 task\n    }\n    for (Thread thread : threads) {\n        thread.join();\n    }\n    for (Task t : taskArrayList) {\n        shutdownTasks.add(t.getTaskShutdownDameon());\n    }\n    return shutdownTasks;\n}\n```\n\nTask 类实现了 Runnable 接口，其 run 方法中简单调用了 `Task#execute` 方法，该方法首先会向系统 bolt 发送一条“startup”消息，然后依据当前的组件类型创建对应的任务执行器，创建的过程位于 `Task#mkExecutor` 方法中：\n\n```java\npublic BaseExecutors mkExecutor() {\n    BaseExecutors baseExecutor = null;\n\n    if (taskObj instanceof IBolt) {\n        if (taskId == topologyContext.getTopologyMasterId()) {\n            baseExecutor = new TopologyMasterBoltExecutors(this);\n        } else {\n            baseExecutor = new BoltExecutors(this);\n        }\n    } else if (taskObj instanceof ISpout) {\n        if (this.isSingleThread(stormConf)) {\n            baseExecutor = new SingleThreadSpoutExecutors(this);\n        } else {\n            baseExecutor = new MultipleThreadSpoutExecutors(this);\n        }\n    }\n\n    return baseExecutor;\n}\n```\n\nBaseExecutors 类是一个 RunnableCallback 类，所以其 run 方法会被异步循环调用。继承自 BaseExecutors 类有 5 个（如下），而 `Task#mkExecutor` 方法基于组件类型分别选择了相应的实现类进行实例化。\n\n- BoltExecutors\n- TopologyMasterBoltExecutors\n- SpoutExecutors\n- SingleThreadSpoutExecutors\n- MultipleThreadSpoutExecutors\n\n先来看一下 BoltExecutors 和 TopologyMasterBoltExecutors，这是 bolt 组件的任务执行器，其中 TopologyMasterBoltExecutors 继承自 BoltExecutors，所以接下来我们主要来看一下 BoltExecutors 的实现。BoltExecutors 类的 run 方法实现如下：\n\n```java\npublic void run() {\n    if (!isFinishInit) {\n        // 执行初始化操作，主要是调用了 IBolt.prepare 方法\n        this.initWrapper();\n    }\n    while (!taskStatus.isShutdown()) {\n        try {\n            // 循环消费当前 task 的消息队列\n            this.consumeExecuteQueue();\n        } catch (Throwable e) {\n            // 省略异常处理逻辑\n        }\n    }\n}\n```\n\n方法首先会判定是否完成了初始化操作，如果未完成则会调用 `BaseExecutors#initWrapper` 执行初始化，这期间主要是调用了 `IBolt#prepare` 方法，这也是我们在实现一个 bolt 时执行初始化的方法。如果当前 task 线程没有被销毁，则会一直循环调用 `BoltExecutors#consumeExecuteQueue` 消费当前 task 的消息队列。前面的分析我们知道 worker 会对接收到的消息按照 taskId 投递给对应 task 的消息队列，而消息队列的消费过程就在这里发生。针对接收到消息会逐条进行处理，这里最终调用的是 `BoltExecutors#onEvent` 方法，处理的消息就是我们熟悉的 Tuple 对象，而该方法的核心就是调用 `IBolt#execute` 方法，也就是调用用户自定义的策略对收到的 tuple 进行处理。\n\n再来看一下 SingleThreadSpoutExecutors 和 MultipleThreadSpoutExecutors，这两类都继承自 SpoutExecutors 类，区别仅在于对于消息的附加处理和正常的业务逻辑是否位于同一个线程中，而核心逻辑都是调用 `ISpout#nextTuple` 方法，也就是执行用户自定义的业务逻辑。\n\n针对 worker 的运行机制就分析到这里，但是 Storm 对于消息的处理并没有结束，下一篇我们将一起探寻 ack 机制，看看 Storm 如何保证消息至少被执行一次（at least once）。\n","tags":["Storm","JStorm"],"categories":["storm"]},{"title":"JStorm 源码解析：Supervisor 的启动和运行机制","url":"/2018/11/19/storm/storm-supervisor/","content":"\nSupervisor 节点可以理解为单机任务调度器，它负责监听 nimbus 节点的任务资源分配，启动相应的 worker 进程执行 nimbus 分配给当前节点的任务，同时监测 worker 的运行状态，一旦发现有 worker 运行异常，就会杀死该 worker 进程，并将原先分配给 worker 的任务交还给 nimbus 节点进行重新分配。\n\nSupervisor 节点的启动过程位于 Supervisor 类中，main 方法的实现比较简单，主要就是创建了一个 Supervisor 类对象，并调用实例方法<!-- more --> `Supervisor#run`，该方法的实现如下：\n\n```java\npublic void run() {\n    try {\n        /*\n         * 解析配置文件：\n         * 1. 解析 default.yaml\n         * 2. 解析 storm.yaml\n         * 3. 解析 -Dstorm.options 指定的命令行参数\n         * 4. 替换所有配置项中的 JSTORM_HOME 占位符\n         */\n        Map<Object, Object> conf = Utils.readStormConfig();\n\n        // 确保当前为集群运行模式\n        StormConfig.validate_distributed_mode(conf);\n\n        // 创建进程文件： ${storm.local.dir}/supervisor/pids/${pid}\n        this.createPid(conf);\n\n        // 创建并启动 supervisor\n        SupervisorManger supervisorManager = this.mkSupervisor(conf, null);\n\n        JStormUtils.redirectOutput(\"/dev/null\");\n\n        // 注册 SupervisorManger，当 JVM 进程停止时执行 shutdown 逻辑\n        this.initShutdownHook(supervisorManager);\n\n        // 循环监测 shutdown 方法是否执行完毕\n        while (!supervisorManager.isFinishShutdown()) {\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException ignored) {\n            }\n        }\n    }\n    // 省略 catch 代码块\n}\n```\n\n整个方法的逻辑比较清晰（如代码注释），核心实现位于 `Supervisor#mkSupervisor` 方法中，该方法主要用于创建和启动 supervisor 节点，基本执行流程如下：\n\n1. 创建并清空本地存放临时文件的目录（这些文件是从 nimbus 节点下载而来）；\n2. 创建 ZK 操作对象和 worker 运行错误数据上报器；\n3. 创建 LocalState 对象，并获取（或创建）当前 supervisor 节点对应的 ID；\n4. 启动心跳机制，同步节点信息到 ZK；\n5. 启动并定期执行 `SyncSupervisorEvent#run()` 方法（默认间隔 10 秒），从 nimbus 节点领取分配给当前节点的任务并启动执行；\n6. 启动轻量级 HTTP 服务，主要用于查看和下载当前节点的运行日志数据；\n7. 启动 supervisor 运行状况检查机制和 nimbus 节点配置同步策略。\n\nSupervisor 节点在启动时首先会在本地创建并清空临时目录（路径：`supervisor/tmp`），Supervisor 从 nimbus 节点下载下来的文件会临时存放在这里，包括 stormcode.cer、stormconf.cer、stormjar.jar，以及 lib 目录下面的文件等，经过简单处理之后会将其复制到 `stormdist/${topology_id}` 本地目录中，supervisor 本地文件说明如下：\n\n```text\n+ ${supervisor_local_dir}\n| ---- + supervisor\n| ---- | ---- + stormdist\n| ---- | ---- | ---- + ${topology_id}\n| ---- | ---- | ---- | ---- + resources: 指定 topology 程序包 resources 目录下面的所有文件\n| ---- | ---- | ---- | ---- + stormjar.jar: 包含指定 topology 所有代码的 jar 文件\n| ---- | ---- | ---- | ---- + stormcode.ser: 包含指定 topology 对象的序列化文件\n| ---- | ---- | ---- | ---- + stormconf.ser: 包含指定 topology 的配置信息文件\n| ---- | ---- + localstate: 本地状态信息\n| ---- | ---- + tmp: 临时目录，从 nimbus 下载的文件的临时存储目录，简单处理之后复制到 stormdist/${topology_id}\n| ---- | ---- | ---- + ${uuid}\n| ---- | ---- | ---- | ---- + stormjar.jar: 从 nimbus 节点下载下来的 jar 文件\n| ---- | ---- | ---- + ${topology_id}\n| ---- | ---- | ---- | ---- + stormjar.jar: 包含指定 topology 所有代码的 jar 文件（从 inbox 目录复制过来）\n| ---- | ---- | ---- | ---- + stormcode.ser: 包含指定 topology 对象的序列化文件\n| ---- | ---- | ---- | ---- + stormconf.ser: 包含指定 topology 的配置信息文件\n\n| ---- + workers\n| ---- | ---- + ${worker_id}\n| ---- | ---- | ---- + pids\n| ---- | ---- | ---- | ---- + ${pid}: 指定 worker 进程 ID\n| ---- | ---- | ---- + heartbeats\n| ---- | ---- | ---- | ---- + ${worker_id}: 指定 worker 心跳信息（心跳时间、worker 的进程 ID）\n```\n\n接下来 supervisor 会创建 StormClusterState 对象，用于操作 ZK 集群，同时还会创建一个 WorkerReportError 类对象，用于上报 worker 的运行错误数据到 ZK，该类仅包含一个实例方法 report，用于执行上报逻辑。然后 supervisor 节点会创建一个 LocalState 对象用于存储节点的状态信息，这是一个简单、低效的键值存储数据库，每一次操作都会落盘，在这里对应的落盘目录是 `supervisor/localstate`。Supervisor 的 ID（UUID 字符串） 就存储在该数据库中，supervisor 启动时会先尝试从本地状态信息对象中获取 ID 值，如果不存在的话就会创建一个新的 UUID 字符串作为 ID。\n\nSupervisor 节点在启动的过程中会初始化心跳机制，间隔指定时间将当前节点的相关信息上报给 ZK（路径：`supervisors/${supervisor_id}`），包含当前 supervisor 节点的主机名、ID、最近一次上报时间、截止上次上报节点的运行时间，以及 worker 端口列表信息。相关信息的初始化在 Heartbeat 类对象实例化时进行设置，期间会依据当前机器 CPU 核心数和物理内存大小计算允许的 worker 端口数目，并默认从 6800 端口号开始分配 worker 端口。Supervisor 节点会启动一个线程，默认每间隔 60 秒调用 `Heartbeat#update` 方法同步心跳信息到 ZK，该方法的实现如下：\n\n```java\npublic void update() {\n    // 更新本次上报时间为当前时间（单位：秒）\n    supervisorInfo.setTimeSecs(TimeUtils.current_time_secs());\n    // 更新截止目前节点的运行时间（单位：秒）\n    supervisorInfo.setUptimeSecs(TimeUtils.current_time_secs() - startTime);\n\n    // 依据具体配置和资源占用，调整端口号列表\n    this.updateSupervisorInfo();\n\n    try {\n        // 将 supervisor 信息写入 ZK：supervisors/${supervisor_id}\n        stormClusterState.supervisor_heartbeat(supervisorId, supervisorInfo);\n    } catch (Exception e) {\n        LOG.error(\"Failed to update SupervisorInfo to ZK\", e);\n    }\n}\n```\n\n具体过程如代码注释，下面是一个实际的心跳信息示例：\n\n```json\n{\n  \"hostName\": \"10.38.164.192\",\n  \"supervisorId\": \"980bbcfd-5438-4e25-aee9-bf411304a446\",\n  \"timeSecs\": 1533373753,\n  \"uptimeSecs\": 2879598,\n  \"workerPorts\": [\n    6912, 6900, 6901, 6902, 6903, 6904, 6905, 6906, 6907, 6908, 6909, 6910, 6911\n  ]\n}\n```\n\n下面来重点看一下 supervisor 节点领取分配给当前节点的任务并启动执行的过程。该过程的实现代码块如下：\n\n```java\n/*\n * 5. 启动并定期执行 SyncSupervisorEvent#run() 方法（默认间隔 10 秒），从 nimbus 节点领取分配给当前节点的任务并启动执行\n */\nConcurrentHashMap<String, String> workerThreadPids = new ConcurrentHashMap<>();\nSyncProcessEvent syncProcessEvent = new SyncProcessEvent(\n        supervisorId, conf, localState, workerThreadPids, sharedContext, workerReportError, stormClusterState);\n\nEventManagerImp syncSupEventManager = new EventManagerImp();\nAsyncLoopThread syncSupEventThread = new AsyncLoopThread(syncSupEventManager);\nthreads.add(syncSupEventThread);\n\nSyncSupervisorEvent syncSupervisorEvent = new SyncSupervisorEvent(\n        supervisorId, conf, syncSupEventManager, stormClusterState, localState, syncProcessEvent, hb);\n\n// ${supervisor.monitor.frequency.secs}，默认为 10 秒\nint syncFrequency = JStormUtils.parseInt(conf.get(Config.SUPERVISOR_MONITOR_FREQUENCY_SECS));\nEventManagerPusher syncSupervisorPusher = new EventManagerPusher(syncSupEventManager, syncSupervisorEvent, syncFrequency);\n/*\n * 每间隔一段时间（默认为 10 秒）调用 EventManagerPusher#run()，\n * 本质上是调用 EventManagerImp#add(RunnableCallback) 将 syncSupervisorEvent 记录到自己的阻塞队列中，\n * 同时 EventManagerImp 也会循环消费阻塞队列，取出其中的 syncSupervisorEvent，并应用其 run 方法：SyncSupervisorEvent#run()\n */\nAsyncLoopThread syncSupervisorThread = new AsyncLoopThread(syncSupervisorPusher);\nthreads.add(syncSupervisorThread);\n```\n\n要理解该过程的运行机制，我们应该倒着来看相应的源码实现，首先看一下代码块的倒数第二行：\n\n```java\nAsyncLoopThread syncSupervisorThread = new AsyncLoopThread(syncSupervisorPusher);\n```\n\n由前面我们对 Storm 基本线程模型的分析可以知道，这行代码会启动一个线程去循环执行入参回调的 run 方法，这里也就是 `EventManagerPusher#run` 方法，该方法的实现比较简单：\n\n```java\n@Override\npublic void run() {\n    eventManager.add(event);\n}\n```\n\n也就是不断的调用 `EventManager#add` 方法（默认间隔时间为 10 秒），继续往前看我们知道这里的 EventManager 类实际实现是 EventManagerImp，而不断的调用其 add 方法添加的 event 本质上就是一个 SyncSupervisorEvent 实例对象。EventManagerImp 维护了一个阻塞队列来不断记录加入的 event，它本身也是一个回调，再往前看我们就可以看到它在实例化时也被 AsyncLoopThread 启动，`EventManagerImp#run` 方法实现如下：\n\n```java\npublic void run() {\n    try {\n        RunnableCallback r = queue.take();\n        if (r == null) {\n            return;\n        }\n        r.run();\n        e = r.error();\n        this.processInc();\n    } catch (InterruptedException e) {\n        LOG.info(\"Interrupted when processing event.\");\n    }\n}\n```\n\n该方法就是不断的从阻塞队列中取出相应的回调并应用其 run 方法，也就是不断应用 `SyncSupervisorEvent#run` 方法。\n\n以上就是步骤五的整体逻辑，简单描述就是定期的往阻塞队列中添加 SyncSupervisorEvent 事件，而线程会循环的消费队列，取出事件并应用事件的 run 方法。下面来深入分析一下 SyncSupervisorEvent 的 run 方法，该方法所做的工作也就是 supervisor 的核心逻辑，主要可以概括为 3 点：\n\n1. 从 ZK 上下载任务分配信息，并更新到本地；\n2. 从 nimbus 节点上下载 topology 对应的 jar 和配置文件；\n3. 启动 worker 执行分配给当前 supervisor 的 topology 任务。\n\n`SyncSupervisorEvent#run` 方法的实现比较长，下面按照执行步骤逐步拆分进行分析，首先来看一下从 ZK 上下载任务分配信息，并更新到本地的过程，相应实现如下：\n\n```java\n/*\n * 1.1. 同步所有 topology 的任务分配信息及其版本信息到本地\n */\nif (healthStatus.isMoreSeriousThan(HealthStatus.ERROR)) {\n    // 检查当前 supervisor 的状态信息，如果是 PANIC 或 ERROR，则清除所有本地的任务分配相关信息\n    assignmentVersion.clear();\n    assignments.clear();\n    LOG.warn(\"Supervisor machine check status: \" + healthStatus + \", killing all workers.\");\n} else {\n    // 同步所有 topology 的任务分配信息及其版本（即更新 assignmentVersion 和 assignments 参数）\n    this.getAllAssignments(assignmentVersion, assignments, syncCallback);\n}\nLOG.debug(\"Get all assignments \" + assignments);\n\n/*\n * 1.2. 从 supervisor 本地（supervisor/stormdist/）获取已经下载的所有的 topologyId\n */\nList<String> downloadedTopologyIds = StormConfig.get_supervisor_toplogy_list(conf);\nLOG.debug(\"Downloaded storm ids: \" + downloadedTopologyIds);\n\n/*\n * 1.3. 获取分配给当前 supervisor 的任务信息：<port, LocalAssignments>\n */\nMap<Integer, LocalAssignment> zkAssignment = this.getLocalAssign(stormClusterState, supervisorId, assignments);\n\n/*\n * 1.4. 更新 supervisor 本地的任务分配信息\n */\nMap<Integer, LocalAssignment> localAssignment;\ntry {\n    LOG.debug(\"Writing local assignment \" + zkAssignment);\n    localAssignment = (Map<Integer, LocalAssignment>) localState.get(Common.LS_LOCAL_ASSIGNMENTS); // local-assignments\n    if (localAssignment == null) {\n        localAssignment = new HashMap<>();\n    }\n    localState.put(Common.LS_LOCAL_ASSIGNMENTS, zkAssignment);\n} catch (IOException e) {\n    LOG.error(\"put LS_LOCAL_ASSIGNMENTS \" + zkAssignment + \" to localState failed\");\n    throw e;\n}\n```\n\nSupervisor 节点在本地会缓存任务分配信息，同时会定期从 ZK 同步最新的任务分配信息到本地，从 ZK 上获取任务分配信息的逻辑位于 `SyncSupervisorEvent#getAllAssignments` 方法中，方法会从 ZK 的 assignments 路径下获取所有的 topologyId，并与本地比较对应 topology 的任务分配信息版本，如果版本有更新则更新本地缓存的任务分配信息。\n\n接下来 supervisor 会计算所有需要下载的 topology，包括需要更新的、需要重新下载的（之前下载有失败），以及在当前节点进行灰度的，并从 nimbus 节点下载各个 topology 对应的文件，包括 stormjar.jar、stormcode.ser、stormconf.ser，以及 lib 目录下面的依赖文件（如果存在的话），最后从本地删除那些之前下载过但是本次未分配给当前 supervisor 节点的 topology 文件，相应实现如下：\n\n```java\n/*\n * 2.1. 获取所有需要执行下载操作的 topology_id 集合（包括需要更新的、需要重新下载，以及在当前节点灰度的）\n */\nSet<String> updateTopologies = this.getUpdateTopologies(localAssignment, zkAssignment, assignments);\nSet<String> reDownloadTopologies = this.getNeedReDownloadTopologies(localAssignment);\nif (reDownloadTopologies != null) {\n    updateTopologies.addAll(reDownloadTopologies);\n}\n// 获取灰度发布且指定在当前 supervisor 的 topology：[topology_id, Pair(host, port)]\nMap<String, Set<Pair<String, Integer>>> upgradeTopologyPorts =\n        this.getUpgradeTopologies(stormClusterState, localAssignment, zkAssignment);\nif (upgradeTopologyPorts.size() > 0) {\n    LOG.info(\"upgrade topology ports:{}\", upgradeTopologyPorts);\n    updateTopologies.addAll(upgradeTopologyPorts.keySet());\n}\n\n/*\n * 2.2. 从 nimbus 下载对应的 topology 任务代码\n */\n// 从 ZK 上获取分配给当前 supervisor 的 [topologyId, master-code-dir] 信息\nMap<String, String> topologyCodes = getTopologyCodeLocations(assignments, supervisorId);\n// downloadFailedTopologyIds which can't finished download binary from nimbus\nSet<String> downloadFailedTopologyIds = new HashSet<>(); // 记录所有下载失败的 topologyId\n// 从 nimbus 下载相应的 topology jar 文件到 supervisor 本地\nthis.downloadTopology(topologyCodes, downloadedTopologyIds, updateTopologies, assignments, downloadFailedTopologyIds);\n\n/*\n * 2.3. 删除无用的 topology 相关文件（之前下载过，但是本次未分配给当前 supervisor）\n */\nthis.removeUselessTopology(topologyCodes, downloadedTopologyIds);\n```\n\n文件下载的逻辑位于 `SyncSupervisorEvent#downloadTopology` 方法中，文件下载的过程可以概括为以下 5 个步骤：\n\n1. 从 nimbus 上下载 topology 相关文件到 supervisor 的临时目录：`${storm.local.dir}/supervisor/tmp/${uuid}`；\n2. 抽取 stormjar.jar 的 resources 文件；\n3. 将临时目录下的文件移动到 `${storm.local.dir}/supervisor/stormdist/${topology_id}` 目录；\n4. 清空临时目录；\n5. 添加对应的时间戳文件：`${storm.local.dir}/supervisor/stormdist/${topology_id}/timestamp`。\n\n最后 supervisor 节点会调用 `SyncProcessEvent#run` 方法杀死状态异常的 worker，同时启动新的 worker 执行分配的任务：\n\n```java\n/*\n * 3. kill bad workers, start new workers\n */\nsyncProcesses.run(zkAssignment, downloadFailedTopologyIds, upgradeTopologyPorts);\n\n// SyncProcessEvent#run\npublic void run(Map<Integer, LocalAssignment> localAssignments,\n                Set<String> downloadFailedTopologyIds,\n                Map<String, Set<Pair<String, Integer>>> upgradeTopologyPorts) {\n\n    LOG.debug(\"Syncing processes, interval (sec): \" + TimeUtils.time_delta(lastTime));\n    lastTime = TimeUtils.current_time_secs();\n    try {\n        if (localAssignments == null) {\n            localAssignments = new HashMap<>();\n        }\n        LOG.debug(\"Assigned tasks: \" + localAssignments);\n\n        /*\n         * 3.1 获取本地所有 worker 的状态信息：Map<worker_id [WorkerHeartbeat, state]>\n         */\n        Map<String, StateHeartbeat> localWorkerStats;\n        try {\n            // Map[workerId, [worker heartbeat, state]]\n            localWorkerStats = this.getLocalWorkerStats(conf, localState, localAssignments);\n        } catch (Exception e) {\n            LOG.error(\"Failed to get local worker stats\");\n            throw e;\n        }\n        LOG.debug(\"Allocated: \" + localWorkerStats);\n\n        /*\n         * 3.2 杀死无用的 worker，并从 localWorkerStats 中移除\n         */\n        Map<String, Integer> taskCleanupTimeoutMap;\n        Set<Integer> keepPorts = null;\n        try {\n            // [topology_id, cleanup_second]\n            taskCleanupTimeoutMap = (Map<String, Integer>) localState.get(Common.LS_TASK_CLEANUP_TIMEOUT); // task-cleanup-timeout\n            // 对于一些状态为 disallowed/timedOut 的 worker 进行 kill，并清空相应的数据，同时返可用的 worker port\n            keepPorts = this.killUselessWorkers(localWorkerStats, localAssignments, taskCleanupTimeoutMap);\n            localState.put(Common.LS_TASK_CLEANUP_TIMEOUT, taskCleanupTimeoutMap);\n        } catch (IOException e) {\n            LOG.error(\"Failed to kill workers\", e);\n        }\n\n        // 3.3 检测 worker 是否正在启动中，清空处于运行态和启动失败 worker 的相应数据（workerIdToStartTimeAndPort 和 portToWorkerId）\n        this.checkNewWorkers(conf);\n\n        // 3.4 标记需要重新下载的 topology（没有启动成功，同时下载时间已经超过 2 分钟）\n        this.checkNeedUpdateTopologies(localWorkerStats, localAssignments);\n\n        // 3.5 启动新的 worker 执行 topology 任务\n        this.startNewWorkers(keepPorts, localAssignments, downloadFailedTopologyIds);\n\n        // 3.6 启动相应的 worker 执行在当前节点 灰度的 topology 任务\n        this.restartUpgradingWorkers(localAssignments, localWorkerStats, upgradeTopologyPorts);\n\n    } catch (Exception e) {\n        LOG.error(\"Failed to init SyncProcessEvent\", e);\n    }\n}\n```\n\n无论是新任务分配，还是灰度更新，启动 worker 的过程都是调用了 `SyncProcessEvent#startWorkers` 方法，该方法为每个新的 worker 基于 UUID 创建一个 workerId，以及进程目录 `${storm.local.dir}/workers/${worker_id}/pids`，并调用 `SyncProcessEvent#doLaunchWorker` 方法启动 worker，同时更新 worker 在本地的相应数据。Worker 进程的启动和运行机制将在下一篇中进行详细说明。\n\n在分析 nimbus 节点启动过程中有一步会启动一个 HTTP 服务，用于接收查询 nimbus 节点本地日志和配置等数据的需求，supervisor 节点的启动过程也同样包含这样一个过程。Supervisor 的 HTTP 服务默认会监听在 7622 端口，用于接收来自 UI 的请求。\n\n最后对于集群模式，如果配置了 `supervisor.enable.check=true` 则 supervisor 节点在启动时会创建一个线程用于定期检查 supervisor 的运行状况，另外还会启动一个线程用于同步 nimbus 的配置信息到本地节点。最后会创建并返回一个 SupervisorManger 类对象，用于对于当前 supervisor 节点进行管理。\n\n到此，supervisor 节点基本启动完成了，supervisor 会定期基于 ZK 从 nimbus 节点领取任务，然后启动 worker 去执行任务，而启动 worker 的过程我们将在下一篇中进行详细分析。\n","tags":["Storm","JStorm"],"categories":["storm"]},{"title":"JStorm 源码解析：Nimbus 的启动和运行机制","url":"/2018/11/18/storm/storm-nimbus/","content":"\n本篇我们一起分析一下 nimbus 节点的启动和运行机制。Nimbus 节点是 Storm 集群的调度者和管理者，它是集群与用户交互的窗口，负责 topology 任务的分配、启动和运行，也管理着集群中所有的 supervisor 节点的运行，监控着整个集群的运行状态，并将集群运行信息汇集给 UI 进行展示。\n\nNimbus 节点的启动过程位于 NimbusServer 类中，这是一个驱动类，main 方法中会加载集群配置文件，包括 default.yaml 和 storm.yaml，并将配置文件内容与启动时的命令行参数一起封装成 map 对象便于后续使用，真正的启动逻辑位于 `NimbusServer#launchServer` 方法中：<!-- more -->\n\n```java\nprivate void launchServer(final Map conf, INimbus inimbus) {\n    LOG.info(\"Begin to start nimbus with conf \" + conf);\n    try {\n        // 1. 验证当前为分布式运行模式，不允许以本地模式运行\n        StormConfig.validate_distributed_mode(conf);\n\n        // 2. 创建当前 JVM 进程对应的目录：${storm.local.dir}/nimbus/pids/${pid}，如果存在历史运行记录，则会进行清除\n        this.createPid(conf);\n\n        // 3. 注册 shutdown hook 方法，用于在 JVM 进程终止时执行清理逻辑\n        this.initShutdownHook();\n\n        // 4. 模板方法\n        inimbus.prepare(conf, StormConfig.masterInimbus(conf));\n\n        // 5. 基于 conf 创建 NimbusData 对象\n        data = this.createNimbusData(conf, inimbus);\n\n        // 6. 注册一个 follower 线程\n        this.initFollowerThread(conf);\n\n        // 7. 创建并启动一个后端 HTTP 服务（默认端口为 7621，主要用于查看和下载 nimbus 的日志数据）\n        int port = ConfigExtension.getNimbusDeamonHttpserverPort(conf);\n        hs = new Httpserver(port, conf);\n        hs.start();\n\n        // 8. 如果集群运行在 YARN 上，则初始化容器心跳线程\n        this.initContainerHBThread(conf);\n\n        // 9. 创建 ServiceHandler（实现了 Nimbus.Iface），并启动 Thrift 服务，用于处理 Nimbus 请求\n        serviceHandler = new ServiceHandler(data);\n        this.initThrift(conf);\n    } catch (Throwable e) {\n        if (e instanceof OutOfMemoryError) {\n            LOG.error(\"Halting due to out of memory error...\");\n        }\n        LOG.error(\"Fail to run nimbus \", e);\n    } finally {\n        this.cleanup();\n    }\n    LOG.info(\"Quit nimbus\");\n}\n```\n\n整个启动过程可以概括如下：\n\n1. 检测运行模式是否为集群模式，不允许以本地模式运行；\n2. 在本地创建对应的进程目录：`${storm.local.dir}/nimbus/pids/${pid}`；\n3. 注册 shutdown hook 方法，用于在集群销毁时执行相应的清理逻辑；\n4. 模板方法，如果用户实现了 `INimbus#prepare` 方法，则会在这里被调度；\n5. 创建并初始化封装 nimbus 运行数据的 NimbusData 对象；\n6. 注册一个 follower 线程，用于支持 HA 机制；\n7. 启动一个 HTTP 服务，主要用于查看和下载 nimbus 节点的运行日志数据；\n8. 如果集群运行在 YARN 上，则初始化容器的心跳线程；\n9. 启动 nimbus thrift 服务。\n\n整个方法的运行逻辑还是相当清晰的，下面就其中一些关键步骤深入分析，主要包含 NimbusData 的实例化过程、HA 机制，以及 thrift 服务的初始化启动过程。\n\n### NimbusData 的实例化过程\n\n首先来看一下 NimbusData 的实例化过程，位于 `NimbusServer#createNimbusData` 方法中，该方法基于前面加载的集群配置信息创建 NimbusData 类实例，并在构造方法中执行了一系列的初始化逻辑。NimbusData 是 nimbus 端非常重要的一个类，封装了 nimbus 节点所有的运行数据，这里挑重点分析一下其构造的初始化过程：\n\n1. 创建上传和下载传输通道处理器；\n2. 创建并初始化对应的 blobstore 实例；\n3. 创建 StormZkClusterState 对象，并设置本地缓存。\n\n创建上传和下载传输通道处理器位于 `NimbusData#createFileHandler` 方法中，前面我们在分析 topology 构建和提交过程时曾分析过 jar 文件的上传过程，在开始上传之前客户端会先通知 nimbus 节点做一些准备工作，其中就包含创建文件上传通道，对于创建完成的通道会记录到一个 TimeCacheMap 类型的 uploaders 字段中等待后续取用。在 supervisor 从 nimbus 节点下载对应 topology 的 jar 文件时会创建相应的下载传输通道，并记录到 TimeCacheMap 类型的 downloaders 字段中。本方法就是对这两个字段执行初始化的过程，实现如下：\n\n```java\npublic void createFileHandler() {\n    // 注册一个 callback 方法，基于回调的方式关闭管道或输入流\n    ExpiredCallback<Object, Object> expiredCallback = new ExpiredCallback<Object, Object>() {\n        @Override\n        public void expire(Object key, Object val) {\n            try {\n                LOG.info(\"Close file \" + String.valueOf(key));\n                if (val != null) {\n                    if (val instanceof Channel) {\n                        Channel channel = (Channel) val;\n                        channel.close();\n                    } else if (val instanceof BufferFileInputStream) {\n                        BufferFileInputStream is = (BufferFileInputStream) val;\n                        is.close();\n                    }\n                }\n            } catch (IOException e) {\n                LOG.error(e.getMessage(), e);\n            }\n\n        }\n    };\n\n    /*\n     * 获取文件上传和下载的超时时间，默认为 30 秒\n     *\n     * During upload/download with the master,\n     * how long an upload or download connection is idle before nimbus considers it dead and drops the connection.\n     */\n    int file_copy_expiration_secs = JStormUtils.parseInt(conf.get(Config.NIMBUS_FILE_COPY_EXPIRATION_SECS), 30);\n\n    /*\n     * TimeCacheMap 在实例化时会启动一个守护线程，\n     * 并依据超时时间循环从 buckets 中去除对象，并应用执行 callback 的 expire 方法\n     * 这里的 expire 逻辑是执行关闭管道或输入流\n     */\n    uploaders = new TimeCacheMap<>(file_copy_expiration_secs, expiredCallback);\n    downloaders = new TimeCacheMap<>(file_copy_expiration_secs, expiredCallback);\n}\n```\n\n该方法主要完成了 3 件事情，其中 1 和 2 比较直观，而 3 则在 TimeCacheMap 类实例化时完成，3 件事情分别如下：\n\n1. 为通道或流创建回调策略，用于关闭通道或流；\n2. 实例化 uploaders 和 downloaders 属性；\n3. 启动一个守护线程，该线程会定期对过期的通道应用注册的回调策略。\n\n我们来看一下步骤 3 的逻辑，TimeCacheMap 是一个自定义的 map 类型，包含 map 类型常用的方法，同时具备超时机制，在实例化对象时会创建并启动一个后台线程，用于定时的应用超时回调策略：\n\n```java\npublic TimeCacheMap(int expirationSecs, int numBuckets, ExpiredCallback<K, V> callback) {\n    if (numBuckets < 2) {\n        throw new IllegalArgumentException(\"numBuckets must be >= 2\");\n    }\n    buckets = new LinkedList<>();\n    for (int i = 0; i < numBuckets; i++) {\n        buckets.add(new HashMap<K, V>());\n    }\n\n    // 注册回调策略\n    this.callback = callback;\n    final long expirationMillis = expirationSecs * 1000L;\n    final long sleepTime = expirationMillis / (numBuckets - 1);\n\n    /*\n     * cleaner 线程会一直循环的执行，\n     * 间隔指定时间从缓冲区尾部获取对象，并为该对象应用 callback 的 expire 方法\n     */\n    this.cleaner = new Thread(new Runnable() {\n\n        @Override\n        public void run() {\n            while (!AsyncLoopRunnable.getShutdown().get()) {\n                Map<K, V> dead;\n                JStormUtils.sleepMs(sleepTime);\n                synchronized (lock) {\n                    // 从缓冲区队尾获取对象\n                    dead = buckets.removeLast();\n                    // 添加一个空的 map 到缓冲区，从而保证线程的正常运行\n                    buckets.addFirst(new HashMap<K, V>());\n                }\n                if (TimeCacheMap.this.callback != null) {\n                    for (Entry<K, V> entry : dead.entrySet()) {\n                        TimeCacheMap.this.callback.expire(entry.getKey(), entry.getValue());\n                    }\n                }\n            }\n        }\n    });\n    cleaner.setDaemon(true);\n    cleaner.start();\n}\n```\n\n这里我们以 uploaders 为例，当客户端请求 nimbus 执行文件上传准备时，nimbus 会为本次请求创建一个上传通道，同时记录到 uploaders 中，本质上是记录到了 TimeCacheMap 的 buckets 字段头部。在实例化 uploaders 时，方法会创建相应的守护线程，每间隔指定时间（默认是 30 秒）从 buckets 尾部移除超时的通道，并应用回调策略，这里也就是在 createFileHandler 方法开始时创建的关闭通道回调策略。`NimbusData#mkBlobCacheMap` 方法的逻辑与 createFileHandler 基本相同。\n\n下面来看一下 BlobStore 实例的创建和初始化过程，BlobStore 是一个键值存储对象，用于存储 topology 对象，以及 topology 配置信息等。Storm 默认提供了两类存储实现：本地文件存储（LocalFsBlobStore）和 HDFS 文件存储（HdfsBlobStore）。如果是本地存储则需要 ZK 的介入来保证数据一致性，而采用 HDFS 存储则会使用 HDFS 自带的备份和一致性保证。在 NimbusData 实例化过程中会调用 `BlobStoreUtils#getNimbusBlobStore` 方法创建并初始化 BlobStore 实例，方法会检查 `nimbus.blobstore.class` 配置，该配置用于指定具体的 BlobStore 实现类全称类名（包括 HdfsBlobStore），如果没有指定则默认采用 LocalFsBlobStore 实现，并在实例化后调用对应的 prepare 方法执行初始化，这里以 `LocalFsBlobStore#prepare` 进行说明。对于本地模式而言，会采用 `${storm.local.dir}/blobs/` 作为存储的基础路径，并以 FileBlobStoreImpl 类实例操作本地文件，同时会创建对应的 ZK 客户端用于操作 ZK，以维护数据的一致性。\n\n最后来看一下 StormZkClusterState 类对象的创建。StormZkClusterState 类也是一个非常重要的类，它实现了 StormClusterState 接口。Storm 可以看做是基于 ZK 的分布式实时任务调度系统，基于 ZK 实现对整个集群中任务和节点的协调和调度，而集群与 ZK 之间的通信都依赖于 StormZkClusterState 类对象，其实例化过程中所做的主要工作就是在 ZK 上创建相应的一级目录，并注册一个数据变更回调策略，用于触发监听相应路径数据变更时的回调处理器。创建的路径包括：\n\n```text\n- supervisors\n- topology\n- assignments\n- assignments_bak\n- tasks\n- taskbeats\n- taskerrors\n- metrics\n- blobstore\n- gray_upgrade\n```\n\n这里我们对上面的路径进行一个简单的说明：\n\n```text\n+ ${zk_root_dir}\n| ---- + topology: 记录集群中所有正在运行的 topology 数据\n| ---- | ---- + ${topology_id}: 指定 topology 的相关信息（名称、开始运行时间、运行状态等）\n\n| ---- + supervisors: 记录集群中所有 supervisor 节点的心跳信息\n| ---- | ---- + ${supervivor_id}: 指定 supervisor 的心跳信息（心跳时间、主机名称、所有 worker 的端口号、运行时间等）\n\n| ---- + assignments: 记录提交给集群的 topology 任务分配信息\n| ---- | ---- + ${topology_id}: 指定 topology 的任务分配信息（对应 nimbus 上的代码目录、所有 task 的启动时间、每个 task 与节点和端口的映射关系等）\n\n| ---- + assignments_bak: 记录提交给集群的 topology 任务分配信息的备份\n\n| ---- + tasks: 记录集群中所有 topology 的 task 信息\n| ---- | ---- + ${topology_id}: 指定 topology 的所有 task 信息\n| ---- | ---- | ---- + ${task_id}: 指定 task 所属的组件 ID 和类型（spout/bolt）\n\n| ---- + taskbeats: 记录集群中所有 task 的心跳信息\n| ---- | ---- + ${topology_id}: 记录指定 topology 下所有 task 的心跳信息、topologyId，以及 topologyMasterId 等\n| ---- | ---- | ---- + ${task_id}: 指定 task 的心跳信息（最近一次心跳时间、运行时长、统计信息等）\n\n| ---- + taskerrors: 记录集群中所有 topology 的 task 运行错误信息\n| ---- | ---- + ${topology_id}: 指定 topology 下所有 task 的运行错误信息\n| ---- | ---- | ---- + ${task_id}: 指定 task 的运行错误信息\n\n| ---- + metrics: 记录集群中所有 topology 的 metricsId\n\n| ---- + blobstore: 记录集群对应的 blobstore 信息，用于协调数据一致性\n\n| ---- + gray_upgrade: 记录灰度发布中的 topologyId\n```\n\nStorm 集群的运行严重依赖于 ZK 进行协调，所以在集群较大的时候 ZK 有可能成为瓶颈，JStorm 在这一块引入了缓存进行优化，因为 ZK 中的数据有相当一部分是很少变更的，采用缓存策略可以提升访问速度，又减小对于 ZK 的读压力。缓存实例的创建也在 NimbusData 实例化期间完成，相应逻辑位于 `NimbusData#createCache` 方法中，该方法会创建一个 NimbusCache 缓存类对象，并将其记录到 StormZkClusterState 的相应属性中。NimbusCache 采用了两级缓存设计，即内存和文件，构造方法实现如下：\n\n```java\npublic NimbusCache(Map conf, StormClusterState zkCluster) {\n    super();\n\n    // 获取本地缓存的具体实现类\n    String dbCacheClass = this.getNimbusCacheClass(conf);\n    LOG.info(\"NimbusCache db cache will use {}\", dbCacheClass);\n\n    try {\n        dbCache = (JStormCache) Utils.newInstance(dbCacheClass);\n\n        String dbDir = StormConfig.masterDbDir(conf);\n        // 设置本地缓存数据存放目录\n        conf.put(RocksDBCache.ROCKSDB_ROOT_DIR, dbDir); // ${storm.local.dir}/nimbus/rocksdb\n        // 是否在 nimbus 启动时清空数据，默认为 true\n        conf.put(RocksDBCache.ROCKSDB_RESET, ConfigExtension.getNimbusCacheReset(conf));\n        dbCache.init(conf);\n        if (dbCache instanceof TimeoutMemCache) {\n            memCache = dbCache;\n        } else {\n            memCache = new TimeoutMemCache();\n            memCache.init(conf);\n        }\n    }\n    // 省略 catch 代码块\n    this.zkCluster = zkCluster;\n}\n```\n\nJStormCache 接口声明了缓存的基本操作，针对该接口 Storm 主要提供了两类实现：TimeoutMemCache 和 RocksDBCache。对于文件存储而言，如果是本地模式，或者 linux 和 mac 以外的平台均采用 TimeoutMemCache，否则会检查 `nimbus.cache.class` 配置是否有指定相应的缓存实现类，如果没有指定的话，Storm 会采用 RocksDBCache 作为文件存储。RocksDBCache 的存储实现基于 [rocksdb](https://rocksdb.org/)，这是一个由 Facebook 开发和维护的嵌入式键值数据库，借用了 [leveldb](https://github.com/google/leveldb) 项目的核心代码，以及来自 HBase 的设计思想，可以简单将其理解为本地版本的 [HBase](https://hbase.apache.org/)。\n\n### Nimbus 节点的 HA 机制\n\nNimbus 节点在整个 Storm 集群中地位无可厚非，但是单点的设计对于目前大环境下的高可用来说是欠缺的，虽然 nimbus 本身的运行数据是无状态的，但是当 nimbus 节点宕机后，我们还是希望有其它 nimbus 节点能够快速顶替上来，以保证业务 topology 的正常运行。早期的 Storm 实现存在单点的问题，所以 JStorm 在改写的时候引入了 HA 机制来解决这一问题，对于 JStorm 来说一个集群运行过程中只能有一个 nimbus leader 节点，但是可以启动多个 nimbus follower 节点，当 leader 节点宕机之后，follower 节点们可以依据优先级竞选成为 leader 节点。实际上集群刚刚启动时所有的 nimbus 节点都是 follower，不过在短时间内就会依赖于 HA 机制从中选出一个 leader 节点。\n\nJStorm HA 机制依赖于 ZK 实现，会在 ZK 根节点下创建 nimbus_master 和 nimbus_slave 两个临时节点，顾名思义，nimbus_master 用于存储 nimbus leader 的相关信息，其实就是节点对应的 IP 和端口，而 nimbus_slave 主要存储 nimbus follower 的相关信息。简单的说，nimbus 在启动时会抢占式在 ZK 上创建临时节点（EPHEMERAL 类型），先创建成功者成为 leader，余下的成为 follower，这些 follower 会定期检查 nimbus_master 节点是否存在，因为是 EPHEMERAL 类型，所以当 leader 宕机之后对应的节点会被 ZK 主动删除，此时余下的 follower 感知到 leader 不存在会立即抢占式顶替上来，这也算是 ZK 的典型应用场景。\n\n HA 机制的启动过程位于 `NimbusServer#initFollowerThread` 方法中：\n\n```java\nprivate void initFollowerThread(Map conf) {\n    // 如果当前 nimbus 成为 leader，则会触发此回调执行初始化操作\n    Callback leaderCallback = new Callback() {\n        @Override\n        public <T> Object execute(T... args) {\n            try {\n                init(data.getConf());\n            } catch (Exception e) {\n                LOG.error(\"Nimbus init error after becoming a leader\", e);\n                JStormUtils.halt_process(0, \"Failed to init nimbus\");\n            }\n            return null;\n        }\n    };\n    // 创建并启动 follower 线程\n    follower = new FollowerRunnable(data, 5000, leaderCallback);\n    Thread thread = new Thread(follower);\n    thread.setDaemon(true);\n    thread.start();\n    LOG.info(\"Successfully init Follower thread\");\n}\n```\n\n方法的主要逻辑就是为当前 nimbus 节点创建并启动一个 follower 线程，相应的实现位于 FollowerRunnable 类中，该类实例化的过程中会执行以下几件事情：\n\n1. 判断当前是否是以集群模式运行，对于本地模式不适用于 HA 机制；\n2. 将当前节点的 IP 和端口号信息注册到 ZK 的 nimbus_slave 和 nimbus_slave_detail 目录下，表示当前节点是一个 nimbus follower 节点；\n3. 检查当前节点是否存在 leader，如果不存在则尝试成为 leader 节点；\n4. 如果使用本地存储 blobstore 数据则记录状态信息到 ZK，以保证数据的一致性。\n\n当 follower 线程启动之后，follower 默认会每间隔 5 秒钟检查一次当前集群是否存在 nimbus leader 节点，如果不存在则会尝试成为 leader，该过程位于 `FollowerRunnable#tryToBeLeader` 方法中：\n\n```java\nprivate void tryToBeLeader(final Map conf) throws Exception {\n    // 依据候选 nimbus 从节点的优先级来决定当前 nimbus 从节点是否有资格尝试成为 leader\n    boolean allowed = this.check_nimbus_priority();\n    if (allowed) {\n        // 回调策略再次尝试\n        RunnableCallback masterCallback = new RunnableCallback() {\n            @Override\n            public void run() {\n                try {\n                    tryToBeLeader(conf);\n                } catch (Exception e) {\n                    LOG.error(\"tryToBeLeader error\", e);\n                    JStormUtils.halt_process(30, \"Cant't be master\" + e.getMessage());\n                }\n            }\n        };\n        // 尝试成为 leader 节点\n        LOG.info(\"This nimbus can be leader\");\n        data.getStormClusterState().try_to_be_leader(Cluster.MASTER_SUBTREE, hostPort, masterCallback);\n    } else {\n        LOG.info(\"This nimbus can't be leader\");\n    }\n}\n```\n\n方法首先会基于所有 follower 的优先级来决定当前 follower 节点是否有资格尝试成为 leader，对于有资格的 follower 会调用 `StormZkClusterState#try_to_be_leader` 方法尝试在 ZK 上创建 nimbus_master 临时节点并写入自己的 IP 和端口号。如果对应 nimbus_master 节点已经存在，则说明已经有 leader 选举出来，则当前尝试失败，否则如果不存在 NodeExistsException 异常则表示竞选成功。\n\n如果集群已经存在 leader，则方法会判断对应的 leader 是否是当前 follower 自身，如果是的话且上一次的 leader 不存在或是其它 follower 节点，则会触发之前在 `NimbusServer#initFollowerThread` 方法中定义的回调策略，本质上是调用了 `NimbusServer#init` 方法，该方法主要执行以下初始化逻辑：\n\n1. 执行 `NimbusData#init` 方法；\n2. 清除一些老的 topology（在 ZK 上有记录但是在本地没有对应的 topology 文件）；\n3. 启动 topology 任务分配后台线程，也就是 TopologyAssign 线程（之前在分析 topology 任务分配过程的篇章中有专门介绍）；\n4. 更新集群中 topology 的状态信息（设置为 startup）和心跳信息；\n5. 启动定时清理任务，默认每隔 10 分钟会清理上传到本地的 topology 文件（inbox 目录，更多本地目录说明如下）；\n6. 启动 metrics 监控任务。\n\n```text\n+ ${nimbus_local_dir}\n| ---- + nimbus\n| ---- | ---- + inbox: 存放客户端上传的 jar 包\n| ---- | ---- | ---- + stormjar-{uuid}.jar: 对应一个具体的 jar 包\n| ---- | ---- + stormdist\n| ---- | ---- | ---- + ${topology_id}\n| ---- | ---- | ---- | ---- + stormjar.jar: 包含当前拓扑所有代码的 jar 包（从 inbox 那复制过来的）\n| ---- | ---- | ---- | ---- + stormcode.ser: 当前拓扑对象的序列化文件\n| ---- | ---- | ---- | ---- + stormconf.ser: 当前拓扑的配置信息文件\n```\n\n### Thrift 服务的初始化启动过程\n\n最后我们来看一下 nimbus 服务的启动过程。[Thrift](https://zh.wikipedia.org/wiki/Thrift) 是一种接口描述语言和二进制通讯协议，同时也是一个强大的 RPC 中间件，跨语言高效通讯是其主要卖点。Nimbus 启动起来本质上就是一个 thrift 服务，在介绍 topology 任务提交过程时我们就已经接触到与 nimbus 节点通信的过程，本质上也是 RPC 服务调用的过程。所有 RPC 接口的实现均位于 ServiceHandler 类中，该类实现了 `Nimbus.Iface` 接口，NimbusServer 主要调用 `NimbusServer#initThrift` 方法来启动 thrift 服务，过程如下：\n\n```java\nprivate void initThrift(Map conf) throws TTransportException {\n    // 获取 thrift 端口，默认为 8627\n    Integer thrift_port = JStormUtils.parseInt(conf.get(Config.NIMBUS_THRIFT_PORT)); // ${nimbus.thrift.port}\n    TNonblockingServerSocket socket = new TNonblockingServerSocket(thrift_port);\n\n    // ${nimbus.thrift.max_buffer_size}\n    Integer maxReadBufSize = JStormUtils.parseInt(conf.get(Config.NIMBUS_THRIFT_MAX_BUFFER_SIZE));\n    // 设置服务运行参数\n    THsHaServer.Args args = new THsHaServer.Args(socket);\n    args.workerThreads(ServiceHandler.THREAD_NUM); // 64\n    args.protocolFactory(new TBinaryProtocol.Factory(false, true, maxReadBufSize, -1));\n    args.processor(new Nimbus.Processor<Iface>(serviceHandler));\n    args.maxReadBufferBytes = maxReadBufSize;\n\n    thriftServer = new THsHaServer(args);\n\n    LOG.info(\"Successfully started nimbus: started Thrift server...\");\n    thriftServer.serve();\n}\n```\n\n方法实现了一个标准的 thrift 服务启动过程，如果对于 thrift 不熟悉可以参考 [Thrift: The Missing Guide](https://diwakergupta.github.io/thrift-missing-guide/)。Nimbus 节点启动后默认监听 8627 端口，然后等待客户端的请求。到此，一个 nimbus 节点启动的主要流程就基本完成了。\n","tags":["Storm","JStorm"],"categories":["storm"]},{"title":"JStorm 源码解析：基础线程模型","url":"/2018/11/17/storm/storm-async-loop/","content":"\n在具体开始分析 Storm 集群的启动和运行机制之前，我们先来看一下基础的线程模型，在整个 Storm 的实现中有很多地方用到它，所以将其单独拎出来先分析说明一下，后面看到相应的类就大致知道其内在的运行过程啦。\n\n在 Storm 的实现中，有很多实现了 RunnableCallback 类的子类，这些类实例化之后都被传递给了 AsyncLoopThread 对象，<!-- more -->示例如下：\n\n```java\npublic class MyRunnableCallback extends RunnableCallback {\n\n    private static AtomicInteger count = new AtomicInteger();\n\n    @Override\n    public void run() {\n        System.out.println(\"[\" + count.incrementAndGet() + \"] thread-\" + Thread.currentThread().getId() + \" is running.\");\n    }\n\n    @Override\n    public Object getResult() {\n        return 1;\n    }\n\n    public static void main(String[] args) {\n        MyRunnableCallback callback = new MyRunnableCallback();\n        new AsyncLoopThread(callback);\n    }\n}\n```\n\n上面的例子的执行效果是每间隔 1 秒会执行一遍 run 方法，输出如下：\n\n```text\n[1] thread-11 is running.\n[2] thread-11 is running.\n[3] thread-11 is running.\n```\n\n所以我们可以简单的理解其作用是简单方便的创建一个线程用于循环执行自定义的业务逻辑，接下来看一下相应的源码实现。\n\nRunnableCallback 类实现了 Runnable、Callback，以及 Shutdownable 三个接口，其中 Runnable 是 jdk 自带的接口，后两个接口定义如下：\n\n```java\npublic interface Callback {\n    <T> Object execute(T... args);\n}\n\npublic interface Shutdownable {\n    void shutdown();\n}\n```\n\nRunnableCallback 类的完整定义如下：\n\n```java\npublic class RunnableCallback implements Runnable, Callback, Shutdownable {\n\n    @Override\n    public void run() { }\n\n    @Override\n    public <T> Object execute(T... args) {\n        return null;\n    }\n\n    @Override\n    public void shutdown() { }\n\n    public void preRun() { }\n\n    public void postRun() { }\n\n    public Exception error() {\n        return null;\n    }\n\n    public Object getResult() {\n        return null;\n    }\n\n    public String getThreadName() {\n        return null;\n    }\n}\n```\n\n- __run__ ：用于实现自定义的需要异步循环执行的逻辑，该方法会依据条件被循环调度\n- __execute__ ：当线程异常退出时该方法会被调用，用于执行自定义的异常处理逻辑\n- __shutdown__ ：当任务被销毁或者正常退出时该方法被调用，用于执行一定的销毁策略\n- __preRun__ ：执行 run 方法之前的前置模板方法\n- __postRun__ ：执行 run 方法之后的后置模板方法\n- __error__ ：用于获取当前任务的错误运行信息，如果存在错误则会中断当前 run 方法的继续调度\n- __getResult__ ：该方法用于控制 run 方法的调度，如果返回值为 null 或者 0 则任务会一直循环调度，如果返回值小于 0 则会在执行一次 run 之后退出，如果返回值大于 0 则表示每次调度间隔睡眠的时间（单位：秒）\n- __getThreadName__ ：设置当前线程的名称\n\n当我们完成实例化自定义的 RunnableCallback 对象之后，我们需要将其传递给 AsyncLoopThread 类对象用于启动执行。AsyncLoopThread 类提供了多个重载版本的构造函数，但最终调用的都是 `AsyncLoopThread#init` 方法，该方法的实现如下：\n\n```java\nprivate void init(RunnableCallback afn, boolean daemon, RunnableCallback kill_fn, int priority, boolean start) {\n    if (kill_fn == null) {\n        // 如果没有设置，则默认创建一个\n        kill_fn = new AsyncLoopDefaultKill();\n    }\n\n    // 采用 AsyncLoopRunnable 对于 afn 和 kfn 进行包装\n    Runnable runnable = new AsyncLoopRunnable(afn, kill_fn);\n    thread = new Thread(runnable);\n    String threadName = afn.getThreadName();\n    if (threadName == null) {\n        // 以 afn 的 simpleName 作为线程名称\n        threadName = afn.getClass().getSimpleName();\n    }\n    // 配置线程\n    thread.setName(threadName);\n    thread.setDaemon(daemon);\n    thread.setPriority(priority);\n    thread.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {\n        @Override\n        public void uncaughtException(Thread t, Throwable e) {\n            LOG.error(\"UncaughtException\", e);\n            ThreadUtils.haltProcess(1);\n        }\n    });\n\n    this.afn = afn;\n\n    if (start) {\n        // 启动线程\n        thread.start();\n    }\n}\n```\n\n该方法的第一个参数 afn 就是我们传递的自定义的 RunnableCallback 对象；第二个参数 daemon 用于指定当前线程是否以守护线程的模式运行；第三个参数 kill_fn 也是一个 RunnableCallback 类型，当任务异常退出时会调用其 execute 方法；第四个参数 priority 用于指定线程的优先级；第五个参数 start 用于指定是否立即启动任务。\n\n上面的方法中有一个名为 AsyncLoopRunnable 的类，实现了 Runnable 接口，并封装了 afn 和 kill_fn 两个 RunnableCallback 对象，该类的 run 方法实现了整个线程模型的调度机制：\n\n```java\npublic void run() {\n    if (fn == null) {\n        LOG.error(\"fn==null\");\n        throw new RuntimeException(\"AsyncLoopRunnable no core function \");\n    }\n\n    // 模板方法\n    fn.preRun();\n\n    try {\n        while (!shutdown.get()) {\n            // 执行自定义 callback 逻辑\n            fn.run();\n\n            if (shutdown.get()) {\n                this.shutdown();\n                return;\n            }\n\n            Exception e = fn.error();\n            if (e != null) {\n                throw e;\n            }\n\n            // 获取睡眠时间（单位：秒）\n            Object rtn = fn.getResult();\n            if (this.needQuit(rtn)) {\n                this.shutdown();\n                return;\n            }\n        }\n    } catch (Throwable e) {\n        if (shutdown.get()) {\n            this.shutdown();\n        } else {\n            LOG.error(\"Async loop died!!!\" + e.getMessage(), e);\n            killFn.execute(e);\n        }\n    }\n}\n```\n\nAsyncLoopRunnable 的 run 方法会循环调度 RunnableCallback 的 run 方法，并在每次执行完成之后检测当前任务是否被 shutdown、是否存在错误运行信息，如果都没有的话则会继续调用 `AsyncLoopRunnable#needQuit` 方法检查是否需要退出当前任务，该方法会依据 `RunnableCallback#getResult` 的返回结果决策接下去的运行方式，具体决策过程如下：\n\n```java\nprivate boolean needQuit(Object rtn) {\n    if (rtn != null) {\n        long sleepTime = Long.parseLong(String.valueOf(rtn));\n        if (sleepTime < 0) {\n            // 小于 0 则退出执行\n            return true;\n        } else if (sleepTime > 0) {\n            // 大于 0 表示要求每次执行中间休息相应的时间（单位：秒）\n            long now = System.currentTimeMillis();\n            long cost = now - lastTime;\n            long sleepMs = sleepTime * 1000 - cost; // 期望睡眠时间 - 中间消耗的时间\n            if (sleepMs > 0) {\n                // 还没有达到期望睡眠时间，继续睡眠\n                JStormUtils.sleepMs(sleepMs);\n                lastTime = System.currentTimeMillis();\n            } else {\n                lastTime = now;\n            }\n        }\n    }\n    // 为 null 或者 0 都继续执行\n    return false;\n}\n```\n\n整个线程模型的设计和实现比较简单，但是却很实用，推荐大家将其纳入自己的工具箱。对于 Storm 基础线程模型的分析就到此结束，从下一篇开始我们将分三篇分别介绍 nimbus、supervisor，以及 worker 的启动和运行机制。\n","tags":["Storm","JStorm"],"categories":["storm"]},{"title":"JStorm 源码解析：拓扑任务的资源分配过程","url":"/2018/11/16/storm/storm-topology-assignment/","content":"\n上一篇我们分析了 topology 构建和提交过程在客户端的逻辑，并最终通过 `submitTopology` 方法向 Storm 集群的 nimbus 节点提交任务。Nimbus 以 Thrift RPC 服务的方式运行，相应 thrift 接口方法实现位于 ServiceHandler 类中，下面我们从 `ServiceHandler#submitTopology` 方法切入，分析 nimbus 节点之于客户端提交任务的资源分配过程，该方法包装了 `ServiceHandler#submitTopologyWithOpts` 方法。\n\nStorm 集群的任务提交主要分为三种类型：新任务提交、热部署，以及灰度发布。`ServiceHandler#submitTopologyWithOpts` 方法统一处理这三种情况，但是不管哪种提交方式都会首先验证 topology 名称和配置的合法性，然后基于具体提交类型分而治之。<!-- more -->\n\n### 灰度发布 & 热部署\n\n首先来看灰度发布的情况，当客户端请求灰度发布时，nimbus 节点会检查对应 topology 在服务端的运行情况，只有状态为 ACTIVE 时才允许执行灰度发布。灰度发布的相关实现如下：\n\n```java\n// 获取指定 topology 的运行数据\nTopologyInfo topologyInfo = this.getTopologyInfo(topologyId);\nif (topologyInfo == null) {\n    throw new TException(\"Failed to get topology info\");\n}\n\n// 获取指定的 worker 数目：${topology.upgrade.worker.num}\nint workerNum = ConfigExtension.getUpgradeWorkerNum(serializedConf);\n// 获取指定的组件名称：${topology.upgrade.component}\nString component = ConfigExtension.getUpgradeComponent(serializedConf);\n// 获取指定的 worker 列表：${topology.upgrade.workers}\nSet<String> workers = ConfigExtension.getUpgradeWorkers(serializedConf);\n\n// 判定 topology master 是不是使用独立的 worker\nif (!ConfigExtension.isTmSingleWorker(serializedConf, topologyInfo.get_topology().get_numWorkers())) {\n    throw new TException(\"Gray upgrade requires that topology master to be a single worker, cannot perform the upgrade!\");\n}\n\n// 灰度发布\nreturn this.grayUpgrade(topologyId, uploadedJarLocation, topology, serializedConf, component, workers, workerNum);\n```\n\n对于允许灰度发布的场景，Storm 会基于当前提交 topology 的配置首先会尝试获取以下 3 个参数用于挑选 worker 进行发布：\n\n- topology.upgrade.worker.num\n- topology.upgrade.component\n- topology.upgrade.workers\n\n如果同时指定了多个参数，方法会基于一定的优先级进行决策，具体如下：\n\n1. 如果参数 `topology.upgrade.workers` 不为空则忽略其他参数，挑选指定的 worker 进行发布，需要注意的是这些 worker 发布完之后，这个参数就自动置空；\n2. 否则查看参数 `topology.upgrade.component` 是否为空，如果不为空还需要查看参数 `topology.upgrade.worker.num` 是否为 0， 如果不为 0 则挑选指定工作组件下 `topology.upgrade.worker.num` 指定数目的 worker 进行发布，否则对这些工作组件下所有 worker 进行发布；\n3. 如果上面两个都为空，则随机挑选 `topology.upgrade.worker.num` 个 worker 进行发布。\n\n灰度发布的具体执行流程位于 `ServiceHandler#grayUpgrade` 方法中，该方法实现比较冗长，故不在此贴出，下面参考源码和官网文档对发布的过程进行说明：\n\n1. 方法首先尝试从 ZK 获取当前 topology 对应的基本信息（路径：`/topology/${topology_id}`）和灰度发布信息（路径：`/gray_upgrade/${topology_id}`），以及任务分配信息（路径：`assignments/${topology_id}`）；\n2. 如果存在灰度发布信息，则判断对应的灰度状态（已过期 / 已完成 / 进行中），如果正在灰度中则拒绝本次灰度请求，否则（包含不存在灰度发布信息的情况）继续执行灰度发布；\n3. 方法利用 GrayUpgradeConfig 对象封装灰度发布信息，并写入到 ZK 的 `/gray_upgrade/${topology_id}` 路径下，同时设置 `config.continueUpgrading=true`；\n4. Topology Master 有一个线程 GrayUpgradeHandler 会定时读取该节点的配置，检测到有灰度发布配置且 `continueUpgrading=true` 时，将分配指定数目的 worker，添加到 ZK 的 `/gray_upgrade/${topology_id}/upgrading_workers` 路径下，并设置 `continueUpgrading=false`（防止自动进行后续的灰度发布）；\n5. SyncSupervisorEvent 会定时检查每个拓扑的 upgrading_workers 节点，一旦有数据就和自身的 IP 和端口列表进行对比，如果有属于该 supervisor 节点的灰度发布就下载最新的 storm-code 和 storm-jar，然后重启 worker，同时将 worker 添加到 ZK 的 upgraded_workers 节点下；\n6. GrayUpgradeHandler 检测 ZK，如果 upgraded_workers 的 worker 数大于等于当前总 worker 数减 1（topology master 组件占用），则认为此次灰度发布已经完成，删除 ZK 上的灰度发布配置、upgrading_workers，以及 upgraded_workers。\n\n如果只想升级部分 worker 或特定组件，可以用 complete_upgrade 强制完成升级。灰度发布过程中使用单独的 upgrading_workers 和 upgraded_workers 的设计主要是为了避免同步问题。如果将这些信息写在 GrayUpgradeConfig 类中可能会涉及到多个 supervisor 节点同时更新 workers 的情况，而使用单独的节点则只需要在这个节点下添加和删除子节点，不会有同步问题。\n\n热部署和灰度发布从形式上来看都是对运行中 topology 的更新替换操作，但是对于 nimbus 来说，在处理上却是两条不同的分支，实际上热部署与新任务提交在处理过程上更加形似，毕竟热部署的过程就是杀死处于运行中的 topology 然后执行新任务提交的过程，所以接下来我们主要分析新任务的调度细节。\n\n### 新任务提交\n\n对于新提交的任务来说，Storm 会为该 topology 执行一些准备和验证工作，并在 ZK 上创建相应的结点记录该 topology 的元数据和任务分配信息，然后为该 topology 生成一个事件提交给任务分配队列等待 nimbus 节点为当前 topology 制定运行方案，并在执行成功后发送相应的通知事件。相关实现如下：\n\n```java\n// 对当前 topology 配置进行规范化，并附加一些必要的配置\nMap<Object, Object> stormConf = NimbusUtils.normalizeConf(conf, serializedConf, topology);\nLOG.info(\"Normalized configuration:\" + stormConf);\n\n// 合并集群配置和拓扑配置\nMap<Object, Object> totalStormConf = new HashMap<>(conf);\ntotalStormConf.putAll(stormConf);\n\n// 确定 topology 中各个组件的并行度，保证不超过当前 topology 允许的最大值\nStormTopology normalizedTopology = NimbusUtils.normalizeTopology(stormConf, topology, true);\n\n/*\n * 验证 topology 的基本结构信息：\n * 1. 验证 topologyName，组件 ID 是否合法\n * 2. 验证是否存在缺失 input 声明的 spout\n * 3. 验证 woker 和 acker 数目参数配置\n */\nCommon.validate_basic(normalizedTopology, totalStormConf, topologyId);\n\nStormClusterState stormClusterState = data.getStormClusterState();\n\n// 创建 /local-dir/nimbus/${topology_id}/xxxx 文件，并将元数据同步到 ZK\nthis.setupStormCode(topologyId, uploadedJarLocation, stormConf, normalizedTopology, false);\n\n// wait for blob replication before activate topology\nthis.waitForDesiredCodeReplication(conf, topologyId);\n\n// generate TaskInfo for every bolt or spout in ZK : /ZK/tasks/topoologyId/xxx\n// 为当前 topology 在 ZK 上生成 task 信息：/tasks/${topology_id}\nthis.setupZkTaskInfo(conf, topologyId, stormClusterState);\n\n// mkdir topology error directory : taskerrors/${topology_id}\nString path = Cluster.taskerror_storm_root(topologyId);\nstormClusterState.mkdir(path);\n\nString grayUpgradeBasePath = Cluster.gray_upgrade_base_path(topologyId); // gray_upgrade/${topology_id}\nstormClusterState.mkdir(grayUpgradeBasePath);\n// gray_upgrade/${topology_id}/upgraded_workers\nstormClusterState.mkdir(Cluster.gray_upgrade_upgraded_workers_path(topologyId));\n// gray_upgrade/${topology_id}/upgrading_workers\nstormClusterState.mkdir(Cluster.gray_upgrade_upgrading_workers_path(topologyId));\n\n// 为当前 topology 执行任务分配\nLOG.info(\"Submit topology {} with conf {}\", topologyName, serializedConf);\nthis.makeAssignment(topologyName, topologyId, options.get_initial_status());\n\n// push start event after startup\ndouble metricsSampleRate = ConfigExtension.getMetricSampleRate(stormConf); // ${topology.metric.sample.rate}，默认是 0.05\nStartTopologyEvent.pushEvent(topologyId, metricsSampleRate);\n\nthis.notifyTopologyActionListener(topologyName, \"submitTopology\");\n```\n\n下面对源码中涉及到的相关流程进行进一步分析。对于新提交的任务首先会执行一些准备工作，包括：\n\n1. 规范化 topology 的配置信息；\n2. 确定 topology 各个组件的并行度，保证不超过允许的最大值；\n3. 验证 topology 的基本结构信息（topology 名称和组件 ID 的合法性、spout 是否缺失 input 声明，以及验证 worker 和 acker 的参数配置等）。\n\n然后 Storm 会创建或更新当前 topology 对象的序列化文件（stormcode.ser）和配置信息文件(stormconf.ser)到 blobstore 中，如果是采用 nimbus 本地模式存储，还需要将对应的元数据写入 ZK 来保证数据一致性。\n\n接下来会为当前 topology 生成 task 信息，并记录到 ZK 上（路径：`/tasks/${topology_id}`），对于一个 topology 的同一个组件来说，如果并行度大于 1，那么 Storm 会为其创建对应数量的 task，并保证 taskId 是连续的，相应实现位于 `ServiceHandler#setupZkTaskInfo` 方法中：\n\n```java\npublic void setupZkTaskInfo(Map<Object, Object> conf, String topologyId, StormClusterState stormClusterState) throws Exception {\n    // 为当前 topology 追加系统组件，同时基于并行度创建组件对应的 task 信息，同一个组件的多个 task 信息具备连续的 ID\n    Map<Integer, TaskInfo> taskToTaskInfo = this.mkTaskComponentAssignments(conf, topologyId);\n\n    // 获取 topology master 的 ID (这里使用的是其对应的 task ID)\n    int masterId = NimbusUtils.getTopologyMasterId(taskToTaskInfo);\n    TopologyTaskHbInfo topoTaskHbInfo = new TopologyTaskHbInfo(topologyId, masterId);\n    data.getTasksHeartbeat().put(topologyId, topoTaskHbInfo);\n    // 创建 /ZK/taskbeats/${topology_id}，并写入 topologyId 和 topologyMasterId\n    stormClusterState.topology_heartbeat(topologyId, topoTaskHbInfo);\n\n    if (taskToTaskInfo == null || taskToTaskInfo.size() == 0) {\n        throw new InvalidTopologyException(\"Failed to generate TaskIDs map\");\n    }\n    // key is task id, value is task info\n    // 记录 task 信息到 ZK : /ZK/tasks/${topology_id}\n    stormClusterState.set_task(topologyId, taskToTaskInfo);\n}\n```\n\n该方法主要做了 3 件事情：\n\n1. 为当前 topology 追加系统组件（acker-bolt、master-bolt，以及 system-bolt）。\n2. 为当前 topology 生成 task 分配信息，并记录到 ZK 相应节点。\n3. 为当前 topology 在 ZK 上创建对应的 task 心跳记录文件。\n\n其中 1 和 2 位于 `ServiceHandler#mkTaskComponentAssignments` 方法中：\n\n```java\npublic Map<Integer, TaskInfo> mkTaskComponentAssignments(Map<Object, Object> conf, String topologyId)\n        throws IOException, InvalidTopologyException, KeyNotFoundException {\n    // 从 blobstore 中获取当前 topology 的配置信息\n    Map<Object, Object> stormConf = StormConfig.read_nimbus_topology_conf(topologyId, data.getBlobStore());\n    // 从 blobstore 中获取当前 topology 的 StormTopology 对象\n    StormTopology rawTopology = StormConfig.read_nimbus_topology_code(topologyId, data.getBlobStore());\n    // 追加一些系统组件到当前 topology 中\n    StormTopology topology = Common.system_topology(stormConf, rawTopology);\n    // 为当前 topology 生成 task 信息，key 是 taskId\n    return Common.mkTaskInfo(stormConf, topology, topologyId);\n}\n```\n\n方法首先会从 blobstore 中获取 topology 的配置信息和 StormTopology 对象，然后调用 `Common#system_topology` 方法添加一些系统组件，包括 acker-bolt、master-bolt，以及 system-bolt 等。\n\n然后调用 `Common#mkTaskInfo` 方法为当前 topology 中的各个组件生成 task 分配信息。方法实现比较简单，返回的结果是一个 map 类型，其中 key 是 taskId，对于同一个组件来说为其分配的 taskId 是连续的，value 是对应的 TaskInfo 对象，包含两个字段：componentId 和 componentType。前者对应系统组件 ID 和用户自定义组件 ID，后者对应组件类型，也就是 bolt 和 spout。\n\n完成了 topology 组件 task 分配信息的创建，接下来方法为当前任务创建对应的 TopologyAssignEvent 事件对象，并将事件添加到队列中，等待集群为其分配资源。这一过程位于 `ServiceHandler#makeAssignment` 方法中，等待的过程采用了 CountDownLatch 机制，count 值设置为 1，并设置 5 分钟上限等待集群分配资源，超时则返回 false 表示本次任务提交失败。\n\n队列的维护和消费过程位于 TopologyAssign 类中，该类实现了 Runnable 接口，并以单例的形式对外提供服务。Nimbus 节点在启动的时候会创建并初始化 TopologyAssign 对象，并以守护线程的方式启动队列的消费过程。线程的 run 方法会循环的从队列头部以阻塞的方式获取对应的 TopologyAssignEvent 事件对象，并调用 `TopologyAssign#doTopologyAssignment` 方法为相应的 topology 创建任务分配信息（Assignment 对象）和基本运行信息（StormBase 对象），并将任务分配信息和基本运行信息写入 ZK，其中关键的资源分配过程位于 `TopologyAssign#mkAssignment` 方法中，实现如下：\n\n```java\npublic Assignment mkAssignment(TopologyAssignEvent event) throws Exception {\n    String topologyId = event.getTopologyId();\n    LOG.info(\"Determining assignment for \" + topologyId);\n\n    // 1. 基于配置和当前集群运行状态创建 topology 任务分配的上下文信息\n    TopologyAssignContext context = this.prepareTopologyAssign(event);\n\n    // 2. 依据当前的运行模式基于对应节点负载为当前 topology 中的 task 分配 worker\n    Set<ResourceWorkerSlot> assignments;\n    if (!StormConfig.local_mode(nimbusData.getConf())) {\n        // 集群模式，获取模式的调度器\n        ITopologyScheduler scheduler = schedulers.get(DEFAULT_SCHEDULER_NAME); // DefaultTopologyScheduler\n        // 为当前 topology 中的 task 分配 worker\n        assignments = scheduler.assignTasks(context);\n    } else {\n        // 本地模式\n        assignments = mkLocalAssignment(context);\n    }\n\n    // 3. 记录任务分配信息到 ZK: assignments/${topology_id}\n    Assignment assignment = null;\n    if (assignments != null && assignments.size() > 0) {\n        // 获取服务中的 supervisorId 及其 hostname 映射信息\n        Map<String, String> nodeHost = getTopologyNodeHost(context.getCluster(), context.getOldAssignment(), assignments);\n        // 获取 task 的启动时间：<taskId, start_second>\n        Map<Integer, Integer> startTimes = getTaskStartTimes(\n                context, nimbusData, topologyId, context.getOldAssignment(), assignments);\n\n        String codeDir = (String) nimbusData.getConf().get(Config.STORM_LOCAL_DIR);\n\n        assignment = new Assignment(codeDir, assignments, nodeHost, startTimes);\n\n        //  the topology binary changed.\n        if (event.isScaleTopology()) {\n            assignment.setAssignmentType(Assignment.AssignmentType.ScaleTopology);\n        }\n        StormClusterState stormClusterState = nimbusData.getStormClusterState();\n        // 写入 assignment 信息到 ZK: assignments/${topology_id}\n        stormClusterState.set_assignment(topologyId, assignment);\n\n        // update task heartbeat's start time\n        NimbusUtils.updateTaskHbStartTime(nimbusData, assignment, topologyId);\n        NimbusUtils.updateTopologyTaskTimeout(nimbusData, topologyId);\n\n        LOG.info(\"Successfully make assignment for topology id \" + topologyId + \": \" + assignment);\n    }\n    return assignment;\n}\n```\n\n`TopologyAssign#mkAssignment` 方法主要做了下面三件事情：\n\n1. 基于配置和当前集群运行状态为当前 topology 创建任务分配的上下文信息。\n2. 依据当前的运行模式基于对应节点负载为当前 topology 中的 task 分配 worker。\n3. 将 topology 的任务分配信息 Assignment 对象记录到 ZK 相应节点上。\n\n方法一开始会为当前 topology 创建任务分配的上下文信息 TopologyAssignContext 对象，该对象主要包含一下信息：\n\n- 当前 topology 的 topologyId 和 topologyMasterId。\n- 当前 topology 对应的 StormTopology 对象。\n- 配置信息，包括 nimbus 节点配置和 topology 配置。\n- 当前集群可用的 supervisor 节点信息（不包含位于黑名单中的和已经死亡的）。\n- 当前 topology 范围内所有 taskId 与其对应的组件 ID 之间的映射关系。\n- 当前 topology 范围内所有 task 的状态信息。\n- 其他信息，包括任务分配类型、老的任务分配信息、是否是 reassign，以及未停止的 worker 列表等。\n\n完成任务分配的上下文信息创建之后，Storm 会基于该信息为当前 topology 分配 worker，集群模式下该过程的实现位于 `DefaultTopologyScheduler#assignTasks` 方法中，该方法会先计算需要分配的 worker 数目，然后分别为每个 worker 分配对应的 supervisor 节点，最后为 topology 范围内所有组件（包括系统组件）的 task 分配对应的 worker 进程。下面先来看一下 为 worker 分配 supervisor 节点的过程：\n\n```java\npublic List<ResourceWorkerSlot> getAvailableWorkers(\n        DefaultTopologyAssignContext context, Set<Integer> needAssign, int allocWorkerNum) {\n\n    // 1. 计算需要分配的 worker 数目\n    int reserveWorkers = context.getReserveWorkerNum(); // 需要保留的 worker 数目\n    int workersNum = this.getAvailableWorkersNum(context); // 当前集群总的可用的 worker 数目\n    if ((workersNum - reserveWorkers) < allocWorkerNum) {\n        // 没有足够的 worker 可以分配：可用 worker 数目 - 保留的 worker 数目 < 需要分配的数目\n        throw new FailedAssignTopologyException(\"there's no enough worker. allocWorkerNum=\"\n                + allocWorkerNum + \", availableWorkerNum=\" + workersNum + \",reserveWorkerNum=\" + reserveWorkers);\n    }\n    workersNum = allocWorkerNum;\n\n    // 记录分配到的 worker\n    List<ResourceWorkerSlot> assignedWorkers = new ArrayList<>();\n\n    // 2. 分配 worker\n\n    // 2.1 处理用户自定义分配的情况\n    // 从 needAssign 中移除已经分配的 task，并记录分配的 worker 到 assignedWorkers 中\n    this.getRightWorkers(context, needAssign, assignedWorkers, workersNum,\n            // 获取用户自定义分配 worker slot 信息，排除状态为 unstopped 的 worker\n            this.getUserDefineWorkers(context, ConfigExtension.getUserDefineAssignment(context.getStormConf())));\n\n    if (ConfigExtension.isUseOldAssignment(context.getStormConf())) {\n        // 2.2 如果配置指定要复用旧的分配，则优先从旧的分配中选出合适的 worker\n        this.getRightWorkers(context, needAssign, assignedWorkers, workersNum, context.getOldWorkers());\n    } else if (context.getAssignType() == TopologyAssignContext.ASSIGN_TYPE_REBALANCE && !context.isReassign()) {\n        // 2.3 如果是 rebalance 任务分配类型，且可以复用原来的 worker 则将原来分配的 worker 记录下来\n        int cnt = 0;\n        for (ResourceWorkerSlot worker : context.getOldWorkers()) {\n            if (cnt < workersNum) {\n                ResourceWorkerSlot resFreeWorker = new ResourceWorkerSlot();\n                resFreeWorker.setPort(worker.getPort());\n                resFreeWorker.setHostname(worker.getHostname());\n                resFreeWorker.setNodeId(worker.getNodeId());\n                assignedWorkers.add(resFreeWorker);\n                cnt++;\n            } else {\n                break;\n            }\n        }\n    }\n\n    LOG.info(\"Get workers from user define and old assignments: \" + assignedWorkers);\n\n    int restWorkerNum = workersNum - assignedWorkers.size(); // 还需要分配的 worker 数目\n    if (restWorkerNum < 0) {\n        throw new FailedAssignTopologyException(\n                \"Too many workers are required for user define or old assignments. \" +\n                        \"workersNum=\" + workersNum + \", assignedWorkersNum=\" + assignedWorkers.size());\n    }\n\n    // 2.4 对于剩下需要的 worker，直接添加 ResourceWorkerSlot 实例对象\n    for (int i = 0; i < restWorkerNum; i++) {\n        assignedWorkers.add(new ResourceWorkerSlot());\n    }\n\n    /*\n     * 3. 遍历将 worker 分配给相应的 supervisor\n     * - 如果 worker 指定了 supervisor，则优先分配给指定 supervisor\n     * - 依据 supervisor 的负载情况优先选择负载较低的进行分配\n     */\n    List<SupervisorInfo> isolationSupervisors = this.getIsolationSupervisors(context);\n    if (isolationSupervisors.size() != 0) {\n        this.putAllWorkerToSupervisor(assignedWorkers, this.getResAvailSupervisors(isolationSupervisors));\n    } else {\n        // 为 worker 分配对应的 supervisor\n        this.putAllWorkerToSupervisor(assignedWorkers, this.getResAvailSupervisors(context.getCluster()));\n    }\n    this.setAllWorkerMemAndCpu(context.getStormConf(), assignedWorkers);\n    LOG.info(\"Assigned workers=\" + assignedWorkers);\n    return assignedWorkers;\n}\n```\n\n为 worker 分配 supervisor 节点的过程可以概括为：\n\n1. 计算需要分配的 worker 数目，如果可用的 worker 数目不满足要求则会抛出异常；\n2. 为需要分配的 worker 创建 ResourceWorkerSlot 分配单元信息，主要分为四种情况：\n  - 用户自定义 worker slot 分配；\n  - 配置指定复用旧的分配信息则优先从旧的分配中选出合适的 worker slot；\n  - 对于 rebalance 任务分配类型，如果允许则复用原来的 worker slot；\n  - 剩余情况，创建新的 work slot；\n3. 为 worker 分配相应的 supervisor 节点。\n\n下面主要来看一下步骤 3，相应实现位于 `WorkerScheduler#putAllWorkerToSupervisor` 方法中：\n\n```java\nprivate void putAllWorkerToSupervisor(List<ResourceWorkerSlot> assignedWorkers, List<SupervisorInfo> supervisors) {\n\n    // 遍历处理 worker，如果指定了 supervisor，且 supervisor 存在空闲端口，则将其分配给该 supervisor\n    for (ResourceWorkerSlot worker : assignedWorkers) {\n        if (worker.getHostname() != null) {\n            for (SupervisorInfo supervisor : supervisors) {\n                // 如果当前 worker 对应的 hostname 是该 supervisor，且 supervisor 存在空闲的 worker\n                if (NetWorkUtils.equals(supervisor.getHostName(), worker.getHostname())\n                        && supervisor.getAvailableWorkerPorts().size() > 0) {\n                    /*\n                     * 基于当前 supervisor 信息更新对应的 worker 信息：\n                     *  1. 保证 worker 对应的端口号是当前 supervisor 空闲的，否则选一个 supervisor 空闲的给 worker\n                     *  2. 设置 worker 对应的 nodeId 为当前 supervisor 的 ID\n                     */\n                    this.putWorkerToSupervisor(supervisor, worker);\n                    break;\n                }\n            }\n        }\n    }\n\n    // 更新 supervisor 列表，移除没有空闲端口的 supervisor\n    supervisors = this.getResAvailSupervisors(supervisors);\n\n    // 对 supervisor 按照空闲端口数由大到小排序\n    Collections.sort(supervisors, new Comparator<SupervisorInfo>() {\n\n        @Override\n        public int compare(SupervisorInfo o1, SupervisorInfo o2) {\n            return -NumberUtils.compare(o1.getAvailableWorkerPorts().size(), o2.getAvailableWorkerPorts().size());\n        }\n\n    });\n\n    /*\n     * 按照 supervisor 的负载对 worker 进行分配：\n     * 1. 优先选择负载较低的 supervisor 进分配\n     * 2. 如果 supervisor 都已经过载但还有未分配的 worker，则从过载 supervisor 优先选择空闲端口较多的进行分配\n     */\n    this.putWorkerToSupervisor(assignedWorkers, supervisors);\n}\n```\n\n如果 worker 指定了 supervisor 节点，则会将其分配给对应的 supervisor，对于剩余的 worker 来说会考虑 supervisor 节点的负载进行分配，以保证集群中 supervisor 负载的均衡性。Storm 依据集群中 supervisor 节点的平均空闲端口数作为标准来衡量 supervisor 节点的负载，如果一个 supervisor 节点的空闲端口数小于该值则认为该 supervisor 过载。集群负载均衡性的保证主要参考以下两个规则：\n\n1. 优先选择负载较低的 supervisor 节点进分配。\n2. 如果 supervisor 节点都处于过载状态，但还有未分配的 worker，则从过载 supervisor 节点中优先选择空闲端口较多的节点进行分配。\n\n再来看一下为 task 分配 worker 进程的过程，实现位于 `TaskScheduler#assign` 方法中，该方法按照组件的类别分先后对 task 进行 worker 分配，顺序如下：\n\n1. 优先为设置了 `task.on.differ.node=true` 的组件的 task 进行分配；\n2. 接着为剩余的用户自定义组件的 task 分配 worker；\n3. 最后为系统组件分配 worker。\n\n方法实现如下：\n\n```java\npublic List<ResourceWorkerSlot> assign() {\n    if (tasks.size() == 0) { // 没有需要再分配的任务\n        assignments.addAll(this.getRestAssignedWorkers());\n        return assignments;\n    }\n\n    // 1. 处理设置了 task.on.differ.node=true 的组件，为其在不同 supervisor 节点上分配 worker\n    Set<Integer> assignedTasks = this.assignForDifferNodeTask();\n\n    // 2. 为剩余 task 分配 worker，不包含系统组件\n    tasks.removeAll(assignedTasks);\n    Map<Integer, String> systemTasks = new HashMap<>();\n    for (Integer task : tasks) {\n        String name = context.getTaskToComponent().get(task);\n        if (Common.isSystemComponent(name)) {\n            systemTasks.put(task, name);\n            continue;\n        }\n        this.assignForTask(name, task);\n    }\n\n    // 3. 为系统组件 task 分配 worker, e.g. acker, topology master...\n    for (Entry<Integer, String> entry : systemTasks.entrySet()) {\n        this.assignForTask(entry.getValue(), entry.getKey());\n    }\n\n    // 记录所有分配了 task 的 worker 集合\n    assignments.addAll(this.getRestAssignedWorkers());\n    return assignments;\n}\n```\n\n对于设置了 `task.on.differ.node=true` 的组件，要求名下的 task 需要运行在不同的 supervisor 节点上，所以需要优先进行分配，否则如果一些 supervisor 因为配额已满从资源池移除之后，很可能导致没有足够多的 supervisor 节点来满足此类组件的 task 分配需求。\n\n对于这三类组件的 task 分配过程基本过程类似，基本流程可以概括如下：\n\n1. 基于多重选择器为当前 task 选择最优 worker 进行分配；\n2. 将 task 加入到被分配 worker 的 task 列表，并更新 worker 持有的 task 数目；\n3. 检查当前 worker 分配的 task 数目，如果配额已满则将其从资源池移除，不再分配新的 task；\n4. 更新 task 所属组件分配在指定 worker 上的 task 数目。\n\n完成了 task 到 worker，以及 worker 到 supervisor 的配置关系，也就相当于完成了对当前 topology 的任务分配过程，紧接着 Storm 会将任务分配信息记录到 ZK 对应的任务分配路径下面。需要清楚的一点是当前的分配还只是一个方案，Storm 集群并没有开始真正执行当前 topology，如果需要真正启动方案的执行，Storm 还需要调度各个 supervisor 节点按照方案启动相应的 worker 进程，并在每个 worker 进程上启动相应数量的线程来执行 task，相应过程我们后面会逐一进行分析。\n","tags":["Storm","JStorm"],"categories":["storm"]},{"title":"JStorm 源码解析：拓扑的构建和提交过程","url":"/2018/11/15/storm/storm-topology-build/","content":"\n我们按照 Storm 规范开发的 spout 和 bolt 需要使用 TopologyBuilder 构建成有向无环图（拓扑），并指定消息的分组方式，然后提交给 Storm 集群执行，本篇我们将分析 topology 的构建和提交过程。前面分析 Storm 的编程接口时曾介绍过 StormTopology 这个 thrift 类，topology 在构建完成之后会封装成一个 StormTopology 对象，并通过 RPC 方法提交给 Storm 集群的 nimbus 节点。<!-- more -->\n\n### 拓扑的构建过程\n\n拓扑结构在 Storm 集群中以 StormTopology 对象的形式表示，这是一个 thrift 类，其定义如下：\n\n```thrift\nstruct StormTopology {\n  1: required map<string, SpoutSpec> spouts; // topology 中的 spout 集合\n  2: required map<string, Bolt> bolts; // topology 中的 bolt 集合\n  3: required map<string, StateSpoutSpec> state_spouts; // topology 中的 state spout 集合\n}\n```\n\n属性 spouts 的 key 是 spout 对应的 ID，value 是 SpoutSpec 类型对象，这也是一个 thrift 类，封装了 spout 的序列化 ComponentObject 对象和通用组件 ComponentCommon 对象。属性 bolts 的 key 是 bolt 对应的 ID，value 是 Bolt 类型对象，Bolt 同样是一个 thrfit 类，封装了 bolt 的序列化 ComponentObject 对象和通用组件 ComponentCommon 对象。\n\nComponentObject 是一个 thrift 联合类型（union），在这里主要使用了 serialized_java 字段记录组件的序列化值：\n\n```thrift\nunion ComponentObject {\n    1: binary serialized_java;  // 序列化后的 java 对象\n    2: ShellComponent shell;  // ShellComponent 对象\n    3: JavaObject java_object;  // java 对象\n}\n```\n\nComponentCommon 是对组件的抽象表示，spout 和 bolt 在 topology 中统称为组件，topology 构建过程中会将 spout 和 bolt 都封装成为 ComponentCommon 对象：\n\n```thrift\nstruct ComponentCommon {\n  // 组件将从哪些 GlobalStreamId 以何种分组方式接收数据\n  1: required map<GlobalStreamId, Grouping> inputs;\n  // 组件要输出的所有流，key 是 streamId\n  2: required map<string, StreamInfo> streams;\n  // 组件并行度（即多少个线程），这些线程可能分布在不同的机器或进程空间中\n  3: optional i32 parallelism_hint;\n  // 组件相关配置项\n  4: optional string json_conf;\n}\n```\n\nStormTopology 作为 thrift 类在编译成 java 实现时比较冗长，所以 Storm 提供了 TopologyBuilder 构造器类来简化 topology 的构造，其使用形式一般如下：\n\n```java\npublic class WordCountTopology implements ComponentId, FieldName {\n\n    private static final String TOPOLOGY_NAME = \"wordcount-topology\";\n\n    public static void main(String[] args) throws Exception {\n        SentenceSpout sentenceSpout = new SentenceSpout();\n        SentenceSplitBolt sentenceSplitBolt = new SentenceSplitBolt();\n        WordCountBolt wordCountBolt = new WordCountBolt();\n        ReportBolt reportBolt = new ReportBolt();\n\n        TopologyBuilder builder = new TopologyBuilder();\n        builder.setSpout(SENTENCE_SPOUT_ID, sentenceSpout);\n        builder.setBolt(SENTENCE_SPLIT_BOLT_ID, sentenceSplitBolt).shuffleGrouping(SENTENCE_SPOUT_ID);\n        builder.setBolt(WORD_COUNT_BOLT_ID, wordCountBolt).fieldsGrouping(SENTENCE_SPLIT_BOLT_ID, new Fields(WORD));\n        builder.setBolt(REPORT_BOLT_ID, reportBolt).globalGrouping(WORD_COUNT_BOLT_ID);\n\n        Config config = new Config();\n        LocalCluster localCluster = new LocalCluster();\n        localCluster.submitTopology(TOPOLOGY_NAME, config, builder.createTopology());\n\n        TimeUnit.MINUTES.sleep(10);\n\n        localCluster.killTopology(TOPOLOGY_NAME);\n        localCluster.shutdown();\n    }\n\n}\n```\n\n创建完 TopologyBuilder 实例之后，我们可以调用 `setSpout` 方法往 topology 中添加并设置 spout 组件，调用 `setBolt` 方法往 topology 中添加并设置 bolt 组件，并最后通过调用 `createTopology` 方法来完成 topology 的构建，该方法会返回一个 StormTopology 对象。TopologyBuilder 类中主要关注 3 个属性：\n\n```java\n/** 记录拓扑范围内所有的 Bolt 对象 */\nprotected Map<String, IRichBolt> _bolts = new HashMap<>();\n/** 记录拓扑范围内所有的 Spout 对象 */\nprotected Map<String, IRichSpout> _spouts = new HashMap<>();\n/** 记录拓扑范围内封装所有的 Spout 和 Bolt 的 ComponentCommon 组件对象 */\nprotected Map<String, ComponentCommon> _commons = new HashMap<>();\n```\n\n下面来看一下 spout 和 bolt 的构造过程，即 `setSpout` 和 `setBolt` 方法，针对这两类方法，TopologyBuilder 都提供了多种重载版本，其中 `setSpout` 对应的底层实现如下：\n\n```java\npublic SpoutDeclarer setSpout(String id, IRichSpout spout, Number parallelism_hint) throws IllegalArgumentException {\n// 保证 id 在 topology 范围内的全局唯一\nthis.validateUnusedId(id);\n// 以 ComponentCommon 的形式封装组件，并记录到 _commons 属性中\nthis.initCommon(id, spout, parallelism_hint);\n// 记录组件到 _spout 集合中\n_spouts.put(id, spout);\nreturn new SpoutGetter(id);\n}\n```\n\n方法首先会验证 spoutId 在 topology 范围内的全局唯一性，即没有被已有的 spout 和 bolt 占用，否则会抛出 IllegalArgumentException 异常。`initCommon` 方法会构造 spout 对应的 ComponentCommon 对象并记录到 `_commons` 属性中：\n\n```java\nprotected void initCommon(String id, IComponent component, Number parallelism) throws IllegalArgumentException {\n    ComponentCommon common = new ComponentCommon();\n    common.set_inputs(new HashMap<GlobalStreamId, Grouping>());\n\n    // 设置并行度\n    if (parallelism != null) {\n        int dop = parallelism.intValue();\n        if (dop < 1) {\n            throw new IllegalArgumentException(\"Parallelism must be positive.\");\n        }\n        common.set_parallelism_hint(dop); // 设置组件并行度\n    } else {\n        // 如果没有设置的话，默认设置并行度为 1\n        common.set_parallelism_hint(1);\n    }\n\n    // 获取组件相关的配置并以 json 的形式记录到 ComponentCommon 对象中\n    Map conf = component.getComponentConfiguration();\n    if (conf != null) common.set_json_conf(JSONValue.toJSONString(conf));\n    _commons.put(id, common);\n}\n```\n\n最后将 spout 对象记录到 `_spouts` 属性中，并构造当前 spout 对应的 SpoutGetter 对象。\n\nSpoutGetter 可以理解为 spout 对应的属性配置器，用于为当前 spout 加载通用的配置和设置私有的属性值，并最终将所有的配置项序列化为 json 格式记录到封装当前 spout 的 ComponentCommon 对象中（json_conf 属性）。\n\n```java\nprotected class SpoutGetter extends ConfigGetter<SpoutDeclarer> implements SpoutDeclarer {\n    public SpoutGetter(String id) {\n        super(id);\n    }\n}\n```\n\nSpoutGetter 类继承了 ConfigGetter 类，并实现了 SpoutDeclarer 接口，该接口主要是声明了一些 spout 组件相关的配置方法，具体的实现都在 ConfigGetter 的父类 BaseConfigurationDeclarer 中，实现比较简单，不展开说明。ConfigGetter 覆盖实现了父类的 `addConfigurations` 方法，并在该方法中将当前 spout 所有相关的配置项序列化成 json 记录到对应的 ComponentCommon 对象中：\n\n```java\n@Override\npublic T addConfigurations(Map conf) {\n    if (conf != null && conf.containsKey(Config.TOPOLOGY_KRYO_REGISTER)) { // ${topology.kryo.register}\n        // 在通常的非事务流处理中，不允许设置组件的序列化方式\n        throw new IllegalArgumentException(\"Cannot set serializations for a component using fluent API\");\n    }\n    String currConf = _commons.get(_id).get_json_conf();\n    // 将 currConf 与 conf 的配置项合并，并以 json string 的形式记录到对应组件的 json_conf 字段中\n    _commons.get(_id).set_json_conf(JStormUtils.mergeIntoJson(JStormUtils.parseJson(currConf), conf));\n    return (T) this;\n}\n```\n\n下面继续分析 `setBolt` 方法，上一篇在介绍 Bolt 组件接口时我们知道 Storm 提供了三种基础的 Bolt 组件类型，即 IBolt(or IRichBolt)、IBasicBolt，以及 IBatchBolt。针对每种 Bolt 类型，TopologyBuilder 都有提供相应版本的 `setBolt` 方法实现，下面以最常见的 IBolt 类型为例，对应的方法实现如下：\n\n```java\npublic BoltDeclarer setBolt(String id, IRichBolt bolt, Number parallelism_hint) throws IllegalArgumentException {\n    // 保证 id 在 topology 范围内的全局唯一\n    this.validateUnusedId(id);\n    // 以 ComponentCommon 形式封装组件，并记录到 _commons 属性中\n    this.initCommon(id, bolt, parallelism_hint);\n    // 记录 bolt 到 _bolt 集合中\n    _bolts.put(id, bolt);\n    return new BoltGetter(id);\n}\n```\n\n流程上与 `setSpout` 大同小异，不再重复撰述，方法最终会将 bolt 对象记录到 `_bolts` 属性中，并构造当前 bolt 对应的 BoltGetter 对象。\n\n前面我们分析了 SpoutGetter，知道其作用主要是为 spout 配置相关属性，BoltGetter 的作用同样如此，不过相对于 SpoutGetter 增加了消息分组方式的配置入口，最后同样将属性序列化为 json 格式记录到与组件相对应的 ComponentCommon 对象中。\n\n在完成调用 `setSpout` 和 `setBolt` 往 topology 中添加 spout 和 bolt 组件之后，我们需要调用 `createTopology` 方法创建相应的 StormTopology 对象，该方法的实现如下：\n\n```java\npublic StormTopology createTopology() {\n    Map<String, Bolt> boltSpecs = new HashMap<>();\n    Map<String, SpoutSpec> spoutSpecs = new HashMap<>();\n\n    // 如果当前 topology 中含有 stateful-bolt，就为 topology 自动添加一个 CheckpointSpout\n    this.maybeAddCheckpointSpout();\n\n    // 遍历处理 bolt，封装 bolt 的序列化形式和 ComponentCommon 形式为 Bolt 对象，并记录到 boltSpecs 中\n    for (String boltId : _bolts.keySet()) {\n        IRichBolt bolt = _bolts.get(boltId);\n        // 如果当前 topology 中含有 stateful-bolt，那么针对 non-stateful bolt 都采用 CheckpointTupleForwarder 进行包装\n        bolt = this.maybeAddCheckpointTupleForwarder(bolt);\n        ComponentCommon common = this.getComponentCommon(boltId, bolt);\n        try {\n            this.maybeAddCheckpointInputs(common);\n            this.maybeAddWatermarkInputs(common, bolt);\n            // 封装 bolt 的序列化形式和 ComponentCommon 形式为 Bolt 对象，并记录到 boltSpecs 中\n            boltSpecs.put(boltId, new Bolt(ComponentObject.serialized_java(Utils.javaSerialize(bolt)), common));\n        } catch (RuntimeException wrapperCause) {\n            // 省略异常处理逻辑\n            throw wrapperCause;\n        }\n    }\n\n    // 遍历处理 spout，封装 spout 的序列化形式和 ComponentCommon 形式为 SpoutSpec 对象，并记录到 spoutSpecs 中\n    for (String spoutId : _spouts.keySet()) {\n        IRichSpout spout = _spouts.get(spoutId);\n        ComponentCommon common = this.getComponentCommon(spoutId, spout);\n        try {\n            // 封装 spout 的序列化形式和 ComponentCommon 形式为 SpoutSpec 对象，并记录到 spoutSpecs 中\n            spoutSpecs.put(spoutId, new SpoutSpec(ComponentObject.serialized_java(Utils.javaSerialize(spout)), common));\n        } catch (RuntimeException wrapperCause) {\n            // 省略异常处理逻辑\n            throw wrapperCause;\n        }\n    }\n\n    // 封装成为 stormTopology 对象返回\n    return new StormTopology(spoutSpecs, boltSpecs, new HashMap<String, StateSpoutSpec>());\n}\n```\n\n整个方法的执行流程可以概括为：\n\n1. 如果 topology 中存在有状态的 bolt，则为当前 topology 自动添加一个 CheckpointSpout 组件；\n2. 遍历处理之前添加到 topology 中的 bolt，采用 Bolt 封装其序列化对象和 ComponentCommon 组件对象；\n3. 遍历处理之前添加到 topology 中的 spout，采用 SpoutSpec 封装其序列化对象和 ComponentCommon 组件对象；\n4. 构造 StormTopology 对象并返回。\n\n### 集群环境下拓扑的提交过程\n\n当构建完 topology 之后，我们需要以任务的形式将其提交到 Storm 集群运行。此外，为了方便调试，Storm 也支持通过 LocalCluster 在本地提交运行任务，本节我们主要介绍如何向 Storm 集群提交任务。\n\nStorm 提供了 StormSubmitter 类用于向 Storm 集群提交任务，并提供了两类方法：`submitTopology` 和 `submitTopologyWithProgressBar`。后者是对前者的封装，在原版 Storm 中用于支持显示任务的提交进度，但是这一设计在 JStorm 中被移除，所以两类方法实际上是等价的。接下来我们对 `submitTopology` 方法的实现进行分析，Storm 为该方法提供了多个重载版本，对应的底层实现如下：\n\n```java\npublic static void submitTopology(String name, Map stormConf, StormTopology topology, SubmitOptions opts)\n        throws AlreadyAliveException, InvalidTopologyException {\n\n    // 验证配置是否为 json 格式\n    if (!Utils.isValidConf(stormConf)) {\n        throw new IllegalArgumentException(\"Storm conf is not valid. Must be json-serializable\");\n    }\n\n    // 封装配置（构建 topology 期间添加的、提交 topology 时传入的，以及命令行参数）\n    Map userTotalConf = new HashMap();\n    userTotalConf.putAll(TopologyBuilder.getStormConf()); // add the configuration generated during topology building\n    userTotalConf.putAll(stormConf);\n    userTotalConf.putAll(Utils.readCommandLineOpts());\n\n    // 加载配置文件配置\n    Map conf = Utils.readStormConfig();\n    conf.putAll(stormConf);\n    putUserInfo(conf, stormConf);\n\n    try {\n        String serConf = Utils.to_json(userTotalConf); // 转换成 json 形式\n        if (localNimbus != null) {\n            // 本地模式\n            LOG.info(\"Submitting topology \" + name + \" in local mode\");\n            localNimbus.submitTopology(name, null, serConf, topology);\n        } else {\n            // 集群模式\n            // 创建 Thrift 客户端\n            NimbusClient client = NimbusClient.getConfiguredClient(conf);\n            try {\n                // 是否允许热部署 ${topology.hot.deploy.enable}\n                boolean enableDeploy = ConfigExtension.getTopologyHotDeplogyEnable(userTotalConf);\n                // 是否是灰度发布 ${topology.upgrade}\n                boolean isUpgrade = ConfigExtension.isUpgradeTopology(userTotalConf);\n                // 是否允许动态更新\n                boolean dynamicUpdate = enableDeploy || isUpgrade;\n\n                if (topologyNameExists(client, conf, name) != dynamicUpdate) {\n                    if (dynamicUpdate) {\n                        // 动态更新，但是对应的 topology 不存在\n                        throw new RuntimeException(\"Topology with name `\" + name + \"` does not exist on cluster\");\n                    } else {\n                        // 提交新任务，但是对应的 topology 已经存在\n                        throw new RuntimeException(\"Topology with name `\" + name + \"` already exists on cluster\");\n                    }\n                }\n\n                // 上传 jar 包\n                submitJar(client, conf);\n                LOG.info(\"Submitting topology \" + name + \" in distributed mode with conf \" + serConf);\n\n                // 提交任务\n                if (opts != null) {\n                    client.getClient().submitTopologyWithOpts(name, path, serConf, topology, opts);\n                } else {\n                    // for backward compatibility\n                    client.getClient().submitTopology(name, path, serConf, topology);\n                }\n            } finally {\n                client.close();\n            }\n        }\n        LOG.info(\"Finished submitting topology: \" + name);\n    }\n    // 省略 catch 代码块\n}\n```\n\nStorm 任务提交的过程本质上是一个与 nimbus 节点进行 RPC 通信的过程，整体流程可以概括为：\n\n1. 加载与封装配置；\n2. 验证当前 topology 的远程状态；\n3. 上传 topology 的 jar 文件到 nimbus 节点；\n4. 提交 topology 任务。\n\n配置的加载与封装过程会验证配置是否为 json 格式，并聚合多个来源的配置封装成 map 集合。在任务提交之前会验证当前 topology 在远程集群的状态，如果当前操作是热部署或灰度发布，则必须保证对应的 topology 在远程集群已经存在，而对于新提交的 topology 来说，如果远程集群存在同名的 topology 则会禁止提交。\n\nStorm 任务的提交分为两个步骤，首先上传 topology 对应的 jar 文件到 nimbus 服务器，上传成功之后才会调用远程方法通知 nimbus 有新任务加入，需要开始为该 topology 制定运行方案。下面先来看一下 jar 报上传的过程，该过程位于 `submitJar` 方法中：\n\n```java\nprivate static void submitJar(NimbusClient client, Map conf) {\n    if (submittedJar == null) {\n        try {\n            LOG.info(\"Jar not uploaded to master yet. Submitting jar...\");\n            // 获取对应的 client jar 名称，例如 jstorm-1.0.0-SNAPSHOT.jar\n            String localJar = System.getProperty(\"storm.jar\");\n            // 为待上传的 jar 包创建存储路径和 Channel，并返回路径值\n            // ${storm.local.dir}/nimbus/inbox/${key}\n            path = client.getClient().beginFileUpload();\n            String[] pathCache = path.split(\"/\");\n            // ${storm.local.dir}/nimbus/inbox/${key}/stormjar-${key}.jar\n            String uploadLocation = path + \"/stormjar-\" + pathCache[pathCache.length - 1] + \".jar\";\n\n            // 如果设置了 lib jar 则先上传 lib jar\n            List<String> lib = (List<String>) conf.get(GenericOptionsParser.TOPOLOGY_LIB_NAME); // topology.lib.name\n            Map<String, String> libPath = (Map<String, String>) conf.get(GenericOptionsParser.TOPOLOGY_LIB_PATH); // topology.lib.path\n            if (lib != null && lib.size() != 0) {\n                for (String libName : lib) {\n                    String jarPath = path + \"/lib/\" + libName;\n                    client.getClient().beginLibUpload(jarPath);\n                    submitJar(conf, libPath.get(libName), jarPath, client);\n                }\n            } else {\n                if (localJar == null) {\n                    // no lib, no client jar\n                    throw new RuntimeException(\"No client app jar found, please upload it\");\n                }\n            }\n\n            // 上传 client jar\n            if (localJar != null) {\n                submittedJar = submitJar(conf, localJar, uploadLocation, client);\n            } else {\n                // no client jar, but with lib jar\n                client.getClient().finishFileUpload(uploadLocation);\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    } else {\n        LOG.info(\"Jar has already been uploaded to master. Will not submit again.\");\n    }\n}\n```\n\n方法首先会获取 topology 对应的 jar 文件名称（项目打包后对应的 jar 文件），然后调用 thrift 方法 `beginFileUpload` 为待上传的 jar 文件创建存储路径和传输通道，并返回对应的路径值。在 `storm.thrift` 文件中定义了一个 service 类型的 Nimbus 类，如果你对 thrift 熟悉就应该知道这是一个 service 接口声明，Nimbus 类声明了一些能够与 nimbus 节点进行远程通信的方法，相应方法实现位于 ServiceHandler 类中，可以在该类中找到 `beginFileUpload` 方法的实现：\n\n```java\npublic String beginFileUpload() throws TException {\n    String fileLoc = null;\n    try {\n        String key = UUID.randomUUID().toString();\n        String path = StormConfig.masterInbox(conf) + \"/\" + key; // ${storm.local.dir}/nimbus/inbox/${key}\n        FileUtils.forceMkdir(new File(path));\n        FileUtils.cleanDirectory(new File(path));\n        fileLoc = path + \"/stormjar-\" + key + \".jar\"; // ${storm.local.dir}/nimbus/inbox/${key}/stormjar-${key}.jar\n        data.getUploaders().put(fileLoc, Channels.newChannel(new FileOutputStream(fileLoc)));\n        LOG.info(\"Begin upload file from client to \" + fileLoc);\n        return path;\n    }\n    // 省略 catch 代码块\n}\n```\n\n方法首先会基于 UUID 为本次需要上传的 jar 文件创建一个唯一的名称标识，然后在 nimbus 本地对应的目录下创建 jar 文件存储路径（如下），同时为该路径创建一个传输通道，并返回该路径（不包含文件名称）：\n\n> ${storm.local.dir}/nimbus/inbox/${key}/stormjar-${key}.jar\n\n接下来就开始执行 jar 文件的上传逻辑，如果我们在自己的代码中提交 topology 时指定了一些依赖包，那么这里首先会上传这些依赖包，然后再上传主程序包。所有的文件上传都位于一个重载版本的 `submitJar` 方法中，该重载方法会调用远程 `uploadChunk` 方法执行具体的文件上传操作，并在上传完成之后调用远程 `finishFileUpload` 方法关闭对应的上传通道。整个过程就是将我们发布机上本地的 topology jar 文件上传到 nimbus 节点对应的本地路径 `nimbus/inbox/${key}/stormjar-${key}.jar` 下面，其中 key 是一个 UUID 唯一标识。\n\n接下来方法会调用 `submitTopology` 方法提交 topology 任务，默认会设置 topology 的初始化状态为 ACTIVE。Nimbus 在接收到 RPC 请求之后开始对提交的任务制定运行方案，主要是依据 topology 配置和集群的运行状态为提交的任务分配 task、worker，以及 supervisor。如果成功则返回对应的 topologyId，否则会抛出相应的异常，我们将在下一篇中对整个 topology 任务分配过程进行深入分析。\n","tags":["Storm","JStorm"],"categories":["storm"]},{"title":"JStorm 源码解析：编程接口","url":"/2018/11/14/storm/storm-api/","content":"\nStorm Topology 是由 spout 和 bolt 构建的有向无环图，其中 spout 是图的起始节点，用于发送数据，而 bolt 是图的中间节点和末端节点，用于对数据进行处理。下面我们先用一个简单的 wordcount 示例来回忆一下 Storm 的基本使用，然后对示例中涉及到的 Storm 编程接口从源码层面分析其内在实现。<!-- more -->\n\n### Word Count 示例\n\n本节中我们将实现一个 wordcount 程序，其中 spout 用于发送句子，bolt 负责对句子进行切分、单词统计，以及最终打印等工作。\n\n#### 实现 Spout\n\n实现一个 spout 最常见的方式是继承 `BaseRichSpout` 抽象类，我们的句子发送 spout 实现如下：\n\n```java\npublic class SentenceSpout extends BaseRichSpout implements FieldName {\n\n    private static final long serialVersionUID = -2075595983328401544L;\n\n    private static final Logger log = LoggerFactory.getLogger(SentenceSpout.class);\n\n    private static final String[] SENTENCES = {\n            \"It was getting dark, and we weren’t there yet.\",\n            \"Don't step on the broken glass.\",\n            \"The book is in front of the table.\",\n            \"Yeah, I think it's a good environment for learning English.\",\n            \"I will never be this young again. Ever. Oh damn… I just got older.\",\n            \"Joe made the sugar cookies; Susan decorated them.\",\n            \"I really want to go to work, but I am too sick to drive.\",\n            \"There was no ice cream in the freezer, nor did they have money to go to the store.\",\n            \"I want to buy a onesie, but know it won’t suit me.\"\n    };\n\n    private SpoutOutputCollector collector;\n\n    private int index;\n\n    @Override\n    public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {\n        /*\n         * conf: storm 配置信息\n         * context: topology 中组件信息\n         */\n        this.collector = collector;\n    }\n\n    @Override\n    public void nextTuple() {\n        String sentence = SENTENCES[index++ % SENTENCES.length];\n        collector.emit(new Values(sentence));\n        log.info(\"spout emit sentence[{}]\", sentence);\n    }\n\n    @Override\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(SENTENCE));\n    }\n}\n```\n\n#### 实现 Bolt\n\n实现一个 bolt 最常见的方式是继承 `BaseRichBolt` 抽象类，我们的句子切分、单词统计、结果打印三个 bolt 的实现分别如下：\n\n- __句子切分：SentenceSplitBolt__\n\n```java\npublic class SentenceSplitBolt extends BaseRichBolt implements FieldName {\n\n    private static final long serialVersionUID = -8048664019619422801L;\n\n    private static final Logger log = LoggerFactory.getLogger(SentenceSplitBolt.class);\n\n    private OutputCollector collector;\n\n    @Override\n    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) {\n        this.collector = collector;\n    }\n\n    @Override\n    public void execute(Tuple input) {\n        String sentence = input.getStringByField(SENTENCE);\n        if (StringUtils.isBlank(sentence)) {\n            collector.ack(input);\n            return;\n        }\n        String[] words = sentence.split(\"\\\\s*\");\n        log.info(\"sentence split bolt emit words[{}]\", Arrays.toString(words));\n        Arrays.stream(words).forEach(word -> collector.emit(new Values(word)));\n    }\n\n    @Override\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(WORD));\n    }\n}\n```\n\n- __单词统计：WordCountBolt__\n\n```java\npublic class WordCountBolt extends BaseRichBolt implements FieldName {\n\n    private static final long serialVersionUID = -1872418993716384947L;\n\n    private OutputCollector collector;\n    private Map<String, Integer> countMap = new HashMap<>();\n\n    @Override\n    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) {\n        this.collector = collector;\n    }\n\n    @Override\n    public void execute(Tuple input) {\n        String world = input.getStringByField(WORD);\n        countMap.put(world, countMap.getOrDefault(world, 0) + 1);\n        collector.emit(new Values(world, countMap.get(world)));\n    }\n\n    @Override\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(COUNT));\n    }\n}\n```\n\n- __结果打印：ReportBolt__\n\n```java\npublic class ReportBolt extends BaseRichBolt implements FieldName {\n\n    private static final long serialVersionUID = -4646679841956175658L;\n\n    private static final Logger log = LoggerFactory.getLogger(ReportBolt.class);\n\n    private OutputCollector collector;\n\n    @Override\n    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) {\n        this.collector = collector;\n    }\n\n    @Override\n    public void execute(Tuple input) {\n        String word = input.getStringByField(WORD);\n        int count = input.getIntegerByField(COUNT);\n        log.info(\"report bolt, word[{}], count[{}]\", word, count);\n    }\n\n    @Override\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        // emit nothing\n    }\n}\n```\n\n#### 构建 Topology\n\n```java\npublic class WordCountTopology implements ComponentId, FieldName {\n\n    private static final String TOPOLOGY_NAME = \"wordcount-topology\";\n\n    public static void main(String[] args) throws Exception {\n        SentenceSpout sentenceSpout = new SentenceSpout();\n        SentenceSplitBolt sentenceSplitBolt = new SentenceSplitBolt();\n        WordCountBolt wordCountBolt = new WordCountBolt();\n        ReportBolt reportBolt = new ReportBolt();\n\n        TopologyBuilder builder = new TopologyBuilder();\n        builder.setSpout(SENTENCE_SPOUT_ID, sentenceSpout);\n        builder.setBolt(SENTENCE_SPLIT_BOLT_ID, sentenceSplitBolt).shuffleGrouping(SENTENCE_SPOUT_ID);\n        builder.setBolt(WORD_COUNT_BOLT_ID, wordCountBolt).fieldsGrouping(SENTENCE_SPLIT_BOLT_ID, new Fields(WORD));\n        builder.setBolt(REPORT_BOLT_ID, reportBolt).globalGrouping(WORD_COUNT_BOLT_ID);\n\n        Config config = new Config();\n        LocalCluster localCluster = new LocalCluster();\n        localCluster.submitTopology(TOPOLOGY_NAME, config, builder.createTopology());\n\n        TimeUnit.MINUTES.sleep(10);\n\n        localCluster.killTopology(TOPOLOGY_NAME);\n        localCluster.shutdown();\n    }\n\n}\n```\n\n### 编程接口实现分析\n\n#### 基础实现类\n\n- __Fields__\n\nFields 类用于指定消息的输出字段名称，它本质上是对 List 的包装，同时定义了一个 `Map<String, Integer>` 类型的 `_index` 属性用于记录字段及其索引之间的映射关系，同时提供了一些方法方便查询、获取指定字段下标，以及判断字段是否存在等操作。\n\n- __Values__\n\nValues 类与 Fields 相对应，后者用于指定输出字段的名称列表，而字段对应的值则由 Values 进行存储，它继承自 ArrayList。\n\n- __Tuple__\n\nTuple 是对 topology 中传输数据的封装，提供了对于 Fields 和 Values 中数据获取（包括按类型获取）的接口。除此之外还提供了以下接口用于获取当前 tuple 的关联信息：\n\n```java\npublic interface Tuple extends ITuple {\n    /**\n     * 获取与该 tuple 对应的 GlobalStreamId 对象\n     */\n    GlobalStreamId getSourceGlobalStreamId();\n    /**\n     * 获取创建当前 tuple 的组件 ID\n     */\n    String getSourceComponent();\n    /**\n     * 获取创建当前 tuple 的 taskId\n     */\n    int getSourceTask();\n    /**\n     * 获取当前 tuple 被 emit 的目标 streamId\n     */\n    String getSourceStreamId();\n    /**\n     * 获取当前 tuple 的消息序号，用来追踪消息是否被成功处理\n     */\n    MessageId getMessageId();\n}\n```\n\n相对于原生 Storm，在 JStorm 中还定义了 ITupleExt 接口，补充了一些额外的方法用于获取当前 tuple 的目标 taskId、创建时间、是否是 batch 类型，以及设置 batchId 等操作。\n\n#### Thrift 数据结构\n\n- __GlobalStreamId__\n\n```thrift\nstruct GlobalStreamId {\n  1: required string componentId; // 标识当前流所属组件\n  2: required string streamId; // 流的标识\n}\n```\n\n流（stream）是 Storm 中十分重要的一个概念，是消息传输的渠道，一个组件可以向多个流发送消息，也可以接收来自多个流的消息。\n\n- __StreamInfo__\n\n```thrift\nstruct StreamInfo {\n  1: required list<string> output_fields; // 输出的字段名称列表\n  2: required bool direct; // 标识是否是直接流\n}\n```\n\n- __Grouping__\n\n```thrift\nunion Grouping {\n  1: list<string> fields; // empty list means global grouping\n  2: NullStruct shuffle; // tuple is sent to random task\n  3: NullStruct all; // tuple is sent to every task\n  4: NullStruct none; // tuple is sent to a single task (storm's choice) -> allows storm to optimize the topology by bundling tasks into a single process\n  5: NullStruct direct; // this bolt expects the source bolt to send tuples directly to it\n  6: JavaObject custom_object;\n  7: binary custom_serialized;\n  8: NullStruct local_or_shuffle; // prefer sending to tasks in the same worker process, otherwise shuffle\n  9: NullStruct localFirst; //  local worker shuffle > local node shuffle > other node shuffle\n}\n```\n\nGrouping 表示消息的分组方式，被定义为 union 类型，意味着每个组件只能选择一种消息分组方式。各分组类型示意如下：\n\n序号 | 分组方式 | 说明\n--- | --- | ---\n1 | global | 将所有的 tuple 发送给目标组件的第一个 task\n2 | fields | 依据指定字段的值进行分组， 保证指定字段具有相同的值时会发送给同一个 task， 原理是对某个或几个字段值做哈希，然后对哈希值求模得出目标 task\n3 | shuffle | 轮询方式，随机平均发送 tuple 给下游组件\n4 | all | 将 tuple 复制后发送给所有目标组件的所有 task\n5 | none | 随机发送 tuple 到目标组件，相对于 shuffle 而言无法保证平均\n6 | direct | 调用 emitDirect 方法将 tuple 发送给指定的下游 task\n7 | custom | 使用用户接口 CustomStreamGrouping 选择目标 task\n8 | localOrShuffle | 本地 worker 优先，如果本地有目标组件的 task，则随机从本地内部的目标组件 task 列表中进行选择，否则就和 shuffle 分组方式一样，用于减少网络传输\n9 | localFirst | 本地 worker 优先级最高，如果本地有目标组件的 task，则随机从本地内部的目标组件的 task 列表中进行选择；本节点优先级其次，当本地 worker 不能满足条件时，如果本地 supervisor 节点下其他 worker 有目标组件的 task，则随机从中选择一个 task 进行发送；当这两种情况都不满足时，则从其他 supervisor 节点的目标 task 中随机选择一个 task 进行发送\n\n- __ComponentCommon__\n\n```thrift\nstruct ComponentCommon {\n  // 组件将从哪些 GlobalStreamId 以何种分组方式接收数据\n  1: required map<GlobalStreamId, Grouping> inputs;\n  // 组件要输出的所有流，key 是 streamId\n  2: required map<string, StreamInfo> streams;\n  // 组件并行度（即多少个线程），这些线程可能分布在不同的机器或进程空间中\n  3: optional i32 parallelism_hint;\n  // 组件相关配置项\n  4: optional string json_conf;\n}\n```\n\nComponentCommon 是 topology 的基础对象，用于描述一个组件。在 Storm 中将 spout 和 bolt 统称为组件，TopologyBuilder 在构建 topology 时会将我们定义的 spout 和 bolt 封装成 ComponentCommon 对象进行存储。\n\n- __SpoutSpec__\n\n```thrift\nstruct SpoutSpec {\n  // 存储 spout 的序列化对象\n  1: required ComponentObject spout_object;\n  // 描述 spout 输入输出的 ComponentCommon 对象\n  2: required ComponentCommon common;\n}\n```\n\n- __Bolt__\n\n```thrift\nstruct Bolt {\n  // 存储 bolt 的序列化对象\n  1: required ComponentObject bolt_object;\n  // 描述 bolt 输入输出的 ComponentCommon 对象\n  2: required ComponentCommon common;\n}\n```\n\n- __StormTopology__\n\n```thrift\nstruct StormTopology {\n  1: required map<string, SpoutSpec> spouts; // topology 中的 spout 集合\n  2: required map<string, Bolt> bolts; // topology 中的 bolt 集合\n  3: required map<string, StateSpoutSpec> state_spouts; // topology 中的 state spout 集合\n}\n```\n\nStormTopology 用于描述 topology 的组成，包含 spout 和 bolt 组件，我们在使用 TopologyBuilder 类编程构建 topology 时，最终都是为了创建 StormTopology 对象。\n\n- __TopologySummary__\n\n```thrift\nstruct TopologySummary {\n  1: required string id;\n  2: required string name;\n  3: required string status; // 状态信息\n  4: required i32 uptimeSecs; // 运行时长\n  5: required i32 numTasks; // task 数目\n  6: required i32 numWorkers; // worker 数目\n  7: optional string errorInfo;\n}\n```\n\n当我们提交一个任务给 Storm 集群时，nimbus 节点会生成当前任务对应 topology 的状态信息（TopologySummary），用于在 UI 上进行显示。\n\n- __NimbusSummary__\n\n```thrift\nstruct NimbusStat {\n  1: required string host;\n  2: required string uptimeSecs; // 运行时间\n}\n\nstruct NimbusSummary {\n  1: required NimbusStat nimbusMaster; // master 节点信息\n  2: required list<NimbusStat> nimbusSlaves; // slave 节点信息\n  3: required i32 supervisorNum;\n  4: required i32 totalPortNum;\n  5: required i32 usedPortNum;\n  6: required i32 freePortNum;\n  7: required string version;\n}\n```\n\nNimbusSummary 用于描述一个 nimbus 节点的基本信息。\n\n- __SupervisorSummary__\n\n```thrift\nstruct SupervisorSummary {\n  1: required string host; // 所属主机名\n  2: required string supervisorId;\n  3: required i32 uptimeSecs; // 运行时间\n  4: required i32 numWorkers; // 可以使用的 worker 数目\n  5: required i32 numUsedWorkers; // 已经使用的 worker 数目\n  6: optional string version;\n  7: optional string buildTs;\n  8: optional i32 port;\n  9: optional string errorMessage;\n}\n```\n\nSupervisorSummary 用于描述一个 supervisor 节点的基本信息。\n\n- __ClusterSummary__\n\n```thrift\nstruct ClusterSummary {\n  1: required NimbusSummary nimbus;\n  2: required list<SupervisorSummary> supervisors;\n  3: required list<TopologySummary> topologies;\n}\n```\n\nClusterSummary 用于描述整个集群的运行信息，包含 nimbus 节点、supervisor 节点，以及在整个集群上运行着的 topology 的摘要信息。\n\n#### 组件接口\n\n##### IComponent 接口\n\nSpout 和 bolt 在 Storm 中统称为组件，IComponent 接口是对组件的顶层抽象，实现如下：\n\n```java\npublic interface IComponent extends Serializable {\n    /**\n     * 定义组件输出的 Schema，包括输出的 streamId、输出的字段名称列表，以及标识是否是直接流\n     */\n    void declareOutputFields(OutputFieldsDeclarer declarer);\n    /**\n     * 获取与组件相关的配置\n     */\n    Map<String, Object> getComponentConfiguration();\n}\n```\n\n##### ISpout 接口\n\nISpout 是对 spout 组件的顶层抽象，声明了一个 spout 应该具备的基本操作，实现如下：\n\n```java\npublic interface ISpout extends Serializable {\n    void open(Map conf, TopologyContext context, SpoutOutputCollector collector);\n    void close();\n    void activate();\n    void deactivate();\n    void nextTuple();\n    void ack(Object msgId);\n    void fail(Object msgId);\n}\n```\n\nopen 方法会在 spout 组件所属 task 被所在 worker 初始化时进行调用。我们一般在该方法中实现一些初始化逻辑，而不是在 spout 类的构造方法中进行，因为相应节点通过反序列化的方式获取 spout 对象，其构造方法不一定会被调用。\n\nclose 方法会在 spout 被销毁时调用，但是 Storm 并不保证该方法一定会被执行。\n\nactivate 方法和 deactivate 方法会在 spout 被置为活跃和非活跃状态时分别被调用，用户可以在其中实现相应的感知逻辑。\n\nack 和 fail 方法用于实现计算的可靠性，保证消息至少被消费一次（at least once）。\n\nnextTuple 是 spout 的核心方法，用户可以实现该方法来向下游 bolt 发送消息，Storm 会循环调用该方法从数据源拉取数据，并传递给业务执行。在原生 Storm 中 ack、fail，以及 nextTuple 三个方法在同一个线程中被循环调用，所以三个方法都不应该是阻塞的，而 JStorm 则做了针对性的优化，将 nextTuple 和 ack/fail 逻辑分离开。\n\n##### IBolt 接口\n\nIBolt 是常见的对 bolt 组件的顶层抽象，声明了 bolt 应该具备的基本功能，实现如下：\n\n```java\npublic interface IBolt extends Serializable {\n    void prepare(Map stormConf, TopologyContext context, OutputCollector collector);\n    void execute(Tuple input);\n    void cleanup();\n}\n```\n\nprepare 方法类似于 ISpout 的 open 方法，会在 bolt 组件被反序列化时被调用，用于实现一些初始化逻辑，同样我们不应该将初始化逻辑实现在构造方法中。\n\ncleanup 方法类似于 ISpout 的 close 方法，会在 bolt 对象被销毁时调用，Storm 同样不保证该方法一定会被执行。\n\nexecute 方法是 bolt 的核心方法，用户可以在该方法中实现对数据的处理和发送给下游 bolt，如果开启了 ack 机制，那么对消息的 ack 和 fail 也同样在该方法中进行，以保证消息被正确不丢失的处理。\n\n```java\npublic interface IRichBolt extends IBolt, IComponent { }\n```\n\nIRichBolt 接口继承自 IBolt 和 IComponent，组合了这两个接口所定义的功能，所以它并不是一种新的 bolt 接口。\n\n##### IBasicBolt 接口\n\nIBasicBolt 也是一个顶层的 bolt 组件抽象，区别 IBolt 的地方在于使用了 BasicOutputCollector 作为输出收集器，并且是在 execute 方法中传入的，接口定义如下：\n\n```java\npublic interface IBasicBolt extends IComponent {\n    void prepare(Map stormConf, TopologyContext context);\n    void execute(Tuple input, BasicOutputCollector collector);\n    void cleanup();\n}\n```\n\nIBasicBolt 接口存在的意义在于为用户提供一种更加简单的方式实现 bolt，用户不需要考虑消息的 ack 和 fail 等操作，而是由 Storm 自动完成。在利用 TopologyBuilder 构建 topology 时，如果输入的是 IBasicBolt 类型，那么 TopologyBuilder 会自动用 BasicBoltExecutor 对用户自定义的 bolt 进行包装：\n\n```java\npublic BoltDeclarer setBolt(String id, IBasicBolt bolt, Number parallelism_hint) throws IllegalArgumentException {\n    return this.setBolt(id, new BasicBoltExecutor(bolt), parallelism_hint);\n}\n```\n\n而 `BasicBoltExecutor#execute` 方法在执行的时候自动处理了 ack 和 fail 逻辑，用到的输出收集器就是 BasicOutputCollector，实现如下：\n\n```java\npublic void execute(Tuple input) {\n    _collector.setContext(input);\n    try {\n        _bolt.execute(input, _collector);\n        _collector.getOutputter().ack(input);\n    } catch (FailedException e) {\n        if (e instanceof ReportedFailedException) {\n            _collector.reportError(e);\n        }\n        _collector.getOutputter().fail(input);\n    }\n}\n```\n\n##### IBatchBolt 接口\n\nIBatchBolt 接口主要用于定义支持批处理的 bolt，例如 trident、事务处理等。接口定义如下：\n\n```java\npublic interface IBatchBolt<T> extends Serializable, IComponent {\n    void prepare(Map conf, TopologyContext context, BatchOutputCollector collector, T id);\n    void execute(Tuple tuple);\n    void finishBatch();\n}\n```\n\n相对于 IBolt 和 IBasicBolt 而言，IBatchBolt 去掉了 cleanup 方法，取而代之的是 finishBatch，该方法会在当前 batch 之前的所有 batch 都被处理成功时被调用。有一点与 IBasicBolt 相同，IBatchBolt 的用户也无需关心 ack 和 fail 逻辑，Storm 会自动进行处理，相关实现位于 `BatchBoltExecutor#execute` 方法中：\n\n```java\npublic void execute(Tuple input) {\n    Object id = input.getValue(0);\n    IBatchBolt bolt = this.getBatchBolt(id);\n    try {\n        bolt.execute(input);\n        _collector.ack(input);\n    } catch (FailedException e) {\n        LOG.error(\"Failed to process tuple in batch\", e);\n        _collector.fail(input);\n    }\n}\n```\n\n这里的输出收集器是 BatchOutputCollector 的实现。\n\n#### 输出收集器\n\n在 spout 和 bolt 的初始化方法中都有一个输出收集器参数 OutputCollector，输出收集器主要用于对当前组件收到的消息进行进一步的处理，包括 emit、ack，以及 fail 等操作。\n\n##### Spout 输出收集器\n\nISpoutOutputCollector 接口定义了 spout 的输出收集器，用于 spout 对于消息的进一步控制。该接口定义如下：\n\n```java\npublic interface ISpoutOutputCollector {\n    List<Integer> emit(String streamId, List<Object> tuple, Object messageId);\n    void emitDirect(int taskId, String streamId, List<Object> tuple, Object messageId);\n    void reportError(Throwable error);\n}\n```\n\nemit 和 emitDirect 都用于向下游发送数据，区别在于 emitDirect 发出的消息只会被 taskId 参数所指定的 Task 接收到，同时方法要求 streamId 对应的流必须被定义为直接流，接收端的 task 也必须以直接分组（Direct Grouping）的方式来接收消息。\n\n后面在分析 worker 的启动与运行机制的时候将会看到 worker 在启动 task 时会调用 `SpoutExecutors#init` 方法，其中会调用 `ISpout#open` 方法将 SpoutOutputCollector 对象传递给对应的 spout。\n\n##### Bolt 输出收集器\n\n在介绍 Bolt 接口时我们知道围绕 bolt 定义了三种类型的接口：IBolt(or IRichBolt)、IBasicBolt，以及 IBatchBolt。针对每一种 bolt 接口类型也有对应的输出收集器，分别是 OutputCollector、BasicOutputCollector 和 BatchOutputCollector。\n\n- __OutputCollector__\n\nOutputCollector 实现了 IOutputCollector 接口，JStorm 又在此接口的基础上提供了抽象类 OutputCollectorCb，所以 OutputCollector 最终是继承自 OutputCollectorCb。IOutputCollector 接口定义如下：\n\n```java\npublic interface IOutputCollector extends IErrorReporter {\n    List<Integer> emit(String streamId, Collection<Tuple> anchors, List<Object> tuple);\n    void emitDirect(int taskId, String streamId, Collection<Tuple> anchors, List<Object> tuple);\n    void ack(Tuple input);\n    void fail(Tuple input);\n}\n```\n\n- __BasicOutputCollector__\n\nBasicOutputCollector 实现了 IBasicOutputCollector 接口，由于不需要手动去调用 ack 和 fail，所以略去了相关方法。IBasicOutputCollector 接口定义如下：\n\n```java\npublic interface IBasicOutputCollector {\n    List<Integer> emit(String streamId, List<Object> tuple);\n    void emitDirect(int taskId, String streamId, List<Object> tuple);\n    void reportError(Throwable t);\n}\n```\n\n- __BatchOutputCollector__\n\nBatchOutputCollector 是一个抽象类，并提供了 BatchOutputCollectorImpl 实现，BatchOutputCollectorImpl 本质上包装了 OutputCollector。BatchOutputCollector 抽象类定义如下：\n\n```java\npublic abstract class BatchOutputCollector {\n    public List<Integer> emit(List<Object> tuple) {\n        return emit(Utils.DEFAULT_STREAM_ID, tuple);\n    }\n    public abstract List<Integer> emit(String streamId, List<Object> tuple);\n    public void emitDirect(int taskId, List<Object> tuple) {\n        emitDirect(taskId, Utils.DEFAULT_STREAM_ID, tuple);\n    }\n    public abstract void emitDirect(int taskId, String streamId, List<Object> tuple);\n    public abstract void reportError(Throwable error);\n}\n```\n\n本篇主要是对我们编程中直接接触到的 Storm api 实现进行了简单的分析，从下一篇开始，我们将深入到 Storm 的内部，一探这个流式计算引擎的运行机制。\n","tags":["Storm","JStorm"],"categories":["storm"]},{"title":"JStorm 源码解析：整体架构","url":"/2018/11/13/storm/storm-architecture/","content":"\n[Apache Storm](http://storm.apache.org/) 是一个基于 ZK 协调的分布式任务实时调度系统，属于流式（实时）计算引擎的一类。在目前的大数据和人工智能背景下流式计算是公司大部分业务的刚性需求，能够实现在百十毫秒内完成对用户行为的计算并执行具体的策略，例如依据用户的行为对其实施风控等。\n\n当下市面上已有很多流式计算引擎产品，但是 Storm 的出现基本上统一了这一领域，不过近几年也出现了一些新的产品可以撼动 Storm 的地位，比如 [Apache Flink](https://flink.apache.org/)、[Apache Spark-Streaming](https://spark.apache.org/streaming/) 等。不可否认的是，现阶段还是有很多公司的业务运行在 Storm 集群上，这样一个毫秒级延迟的分布式实时计算引擎还是有很多地方值得我们一起去探寻其设计与实现原理。<!-- more -->\n\n### JStorm 架构设计\n\nJStorm 是在 Storm 的基础上基于 java 语言重写而来（Storm 采用 java 和 clojure 混合开发），并在原来的基础上进行了多项改进，主要包括：\n\n- __简化模型设计__ ：将 Task 映射为一个线程，而不仅仅是一个逻辑执行单元。\n- __多维度资源调度__ ：包括 CPU、内存、网络，以及存储等维度。\n- __网络通信层改造__ ：采用更高性能的 netty + disruptor 替换原来的 zmq + blockingQueue。\n- __采样重构__ ：滚动时间窗口、优化缓存性能、增量采样时间，以及减少无谓数据等。\n- __异步化处理__ ：将 nextTuple 和 ack/fail 逻辑分离开，并在 Worker 中采用单独线程负责进出数据的反序列化和序列化工作。\n- __HA 机制__ ：解决 Storm Nimbus 节点的单点问题。\n\nJStorm 的整体架构图如下：\n\n![image](/images/2018/jstorm.png)\n\n其中 W 表示 Worker，T 表示 Task。\n\n从图中我们可以看到 JStorm 在设计上将集群中的节点分为 Nimbus 和 Supervisor 两类。其中 Nimbus 节点相当于整个集群的调度者，基于 ZK 对整个集群进行调度；Supervisor 节点则是整个集群中实际运行 Topology 的节点。在一个 Supervisor 节点中一般会启动多个 Worker 进程，每个 Worker 进程又包含多个 Task 线程。我们提交的 Topology 任务一般会包含多个组件（spout 和 bolt），每个组件依据其并行度配置会分配到相应数量的 Task 任务，而每一个 Task 任务都运行在对应的 Task 线程上面。JStorm 是一个重度依赖于 ZK 的分布式调度系统，所有的工作组件（Nimbus、Supervisor、Worker，以及 Task）都会与 ZK 进行交互上报和更新自己的运行状态，同时获取其他工作组件的运行状态来指导自己接下去的运行。\n\n### Topology 任务提交和运行的基本过程\n\n下面我们简单陈述一下一个 Topology 任务从提交到运行的基本执行过程。\n\n当我们按照 JStorm 的开发规范实现好自己的 Topology 之后，我们需要将其打成 jar 包并执行相应的命令将其发布到集群，这期间我们主要是和 Nimbus 节点进行通信，Nimbus 会启动一个 thrift 服务，而提交任务的过程实际上就是一次 RPC 请求的过程。\n\nNimbus 节点会为本次任务提交请求创建对应的传输通道，然后等待用户上传 Topology 的 jar 文件到本地。上传完成之后，Nimbus 节点会依据用户的配置，以及集群的运行状态开始为当前 Topology 制定运行方案，包括需要分配多少 Task，这些 Task 需要多少 Worker 进行执行，对应的 Worker 需要落地到哪些 Supervisor 节点才能保证集群的均衡等。当方案制定完成之后，Nimbus 会将运行方案写入 ZK 对应的路径下面，并告知用户本次任务提交成功。\n\nSupervisor 节点会定期检查 ZK 的任务分配路径以确定是否有新的任务需要执行，如果正好任务是被分配给当前 Supervisor 节点，则 Supervisor 会从 Nimbus 节点下载当前 Topology 对应的 jar 文件，并按照 Nimbus 制定的运行方案在本地启动相应的 Worker 去执行 Topology 任务。同时 Supervisor 会监控本地 Worker 的运行状态，如果存在运行异常的 Worker，则将其 kill 掉并通知 Nimbus 重新分配。\n\nNimbus 节点作为调度者在实际中以单节点的形式运行，早期的 Storm 在设计上没有引入 HA 机制，所以对于 Nimbus 节点而言存在单点的隐患。虽然 Nimbus 上的数据都是无状态的，但是当 Nimbus 节点宕机之后，还是会在一定程度上影响整个集群的正常运行。JStorm 在改造时引入了 HA 机制，在 JStorm 中可以同时启动多个 Nimbus 节点，这些节点在初始时都是 Follower 角色，它们会将自身的节点信息上报给 ZK，然后依据优先级竞选成为 Leader，期间需要 ZK 的介入来保证竞选结果的一致，当 Nimbus Leader 宕机之后，候选的 Follower 会马上顶替一个上来，以保证集群的正常运行。\n\n### 后记\n\n对于 JStorm 的架构我们先从整体上介绍这么多，在后续的篇章中将会逐一展开来进行深入的分析，包括：\n\n1. 编程接口。\n2. 拓扑的构建和提交过程。\n3. 拓扑任务的资源分配过程。\n4. 基础线程模型。\n5. Nimbus 的启动和运行机制。\n6. Supervisor 的启动和运行机制。\n7. Workers 的启动和运行机制。\n8. ACK 机制。\n\n最后约定一下，后续的篇章中如果不作特殊说明，均用 Storm 指代 JStorm。\n","tags":["Storm","JStorm"],"categories":["storm"]},{"title":"深入理解 JUC：ThreadPoolExecutor","url":"/2018/09/30/java/juc-thread-pool-executor/","content":"\n线程池是 JUC 中的核心组件之一，在并发编程中我们一般都会引入线程池，一方面考虑是为了减少线程创建、销毁，以及频繁上下文切换所带来的性能开销，另一方面也是为了简化对线程创建、复用，以及消亡等过程的管理。ThreadPoolExecutor 是 JUC 线程池的核心实现，但在实际编码时我们可能很少直接使用该类，而是通过工具类 Executors 来创建线程池实例。<!-- more -->\n\nExecutors 类提供了多种静态方法以简化线程池的创建，典型的应用场景如下：\n\n```java\nint nCpu = Runtime.getRuntime().availableProcessors();\nExecutorService es = Executors.newFixedThreadPool(nCpu + 1);\n```\n\n上述示例中通过调用 `Executors#newFixedThreadPool` 方法，我们创建了一个大小为 CPU 核心数加 1 的线程池。此外，Executors 还定义了 `Executors#newSingleThreadExecutor` 和 `Executors#newCachedThreadPool` 方法分别创建固定大小为 1 和非固定大小的线程池。这些方法本质上都是对 ThreadPoolExecutor 类的封装，以简化线程池的使用，例如 `Executors#newCachedThreadPool` 方法的内部实现如下：\n\n```java\npublic static ExecutorService newCachedThreadPool() {\n    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                  60L, TimeUnit.SECONDS,\n                                  new SynchronousQueue<Runnable>());\n}\n```\n\n可以看到方法 `Executors#newCachedThreadPool` 封装了一个大小在 `[0, Integer.MAX_VALUE]` 之间，线程最大存活为时间为 60 秒的 ThreadPoolExecutor 实例，并以 SynchronousQueue 作为工作队列。\n\n所以 ThreadPoolExecutor 可以视为 java 线程池的核心实现类，下面我们将一起来分析 ThreadPoolExecutor 的实现机制。\n\n__注意__ ：实际开发中一般不推荐使用 Executors 创建线程池，而应该通过 ThreadPoolExecutor 显式创建，这样能够让开发人员更加明确线程池的运行规则，规避资源耗尽的风险。Executors 返回的线程池对象主要存在以下弊端：\n\n- FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 `Integer.MAX_VALUE`，可能会堆积大量的请求，从而导致 OOM。\n- CachedThreadPool：允许的创建线程数量为 `Integer.MAX_VALUE`，可能会创建大量的线程，从而导致 OOM。\n\n### 基础组件\n\n在 ThreadPoolExecutor 类实现的开头有几个特殊的常量字段定义和相应的位运算（如下），而这正是整个线程池运行的基础支撑，理解这几个常量的含义是理解整个 ThreadPoolExecutor 实现的关键所在。\n\n```java\n// control，高 3 位表示线程池的运行状态 runState，低 29 位表示线程池内工作线程数 workerCount\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\nprivate static final int COUNT_BITS = Integer.SIZE - 3; // 29\nprivate static final int CAPACITY   = (1 << COUNT_BITS) - 1;  // 00011111111111111111111111111111\n\n// 线程池的五种运行状态\nprivate static final int RUNNING    = -1 << COUNT_BITS; // 11100000000000000000000000000000\nprivate static final int SHUTDOWN   =  0 << COUNT_BITS; // 00000000000000000000000000000000\nprivate static final int STOP       =  1 << COUNT_BITS; // 00100000000000000000000000000000\nprivate static final int TIDYING    =  2 << COUNT_BITS; // 01000000000000000000000000000000\nprivate static final int TERMINATED =  3 << COUNT_BITS; // 01100000000000000000000000000000\n```\n\n首先来看一下 `ThreadPoolExecutor#ctl` 常量，对应 AtomicInteger 类型。第一眼看到这个变量可能会一头雾水，但是随着对源码的深入阅读，逐渐能够理解其命名的灵感来源。作者应该是希望通过该变量来表达控制（control）的意思，因为整个线程池的运行状态和工作线程数量都通过该变量进行记录。这是一个 32 位的整型变量，其中 __高 3 位用表示线程的运行状态（runState）__ ，而 __低 29 位则用来记录当前工作线程的数量（workerCount）__ ，也就是说按照现有的能力，ThreadPoolExecutor 最多允许创建 2<sup>29</sup> - 1 个工作线程，约 5 亿多。这里我们将 workerCount 翻译为工作线程数量可能不太恰当，但是线程池会为每个 Worker 对象绑定一个线程（下文会进一步说明），所以 workerCount 理解为工作线程数量也不无道理。\n\n```java\n// 获取 ctl 中的 runState 值\nprivate static int runStateOf(int c)     { return c & ~CAPACITY; }  // ～CAPACITY=11100000000000000000000000000000\n// 获取 ctl 中的 workerCount 值\nprivate static int workerCountOf(int c)  { return c & CAPACITY; }\n// 由 runState 和 workerCount 计算得到 ctl\nprivate static int ctlOf(int rs, int wc) { return rs | wc; }\n```\n\n类中定义了上述 3 个方法分别用来从 `ThreadPoolExecutor#ctl` 中获取线程池的运行状态 runState、工作线程数 workerCount，以及由 runState 和 workerCount 计算得到 ctl 值。ThreadPoolExecutor 中针对这 3 个变量的变量命名有个规律，一般 c 表示 ctl，rs 表示 runState，而 wc 则表示 workerCount，所以在阅读源码时如果遇到相应变量名，不妨联想一下，或许能够茅塞顿开。\n\n![image](/images/2018/thread-pool-executor.png)\n\n线程池定义了 5 种运行状态（状态转移关系如上图所示），即 RUNNING、SHUTDOWN、STOP、TIDYING，以及 TERMINATED，各状态的释义如下：\n\n- __RUNNING__ ：该状态下线程池允许接收新的任务，并执行工作队列中的任务。\n- __SHUTDOWN__ ：该状态下线程池不接受新的任务，但是会继续执行工作队列中的任务。\n- __STOP__ ：该状态下线程池不接受新的任务，不执行工作队列中的任务，同时会中断正在运行中的任务。\n- __TIDYING__ ：当所有的任务执行完，且工作线程数目为 0，线程池进入该状态后会调用 `ThreadPoolExecutor#terminated` 方法。\n- __TERMINATED__ ：当执行完 `ThreadPoolExecutor#terminated` 方法后，线程池进入该状态。\n\n线程池状态转换关系如下表：\n\n前置状态 | 后置状态 | 转换条件\n--- | --- | ---\nRUNNING | SHUTDOWN | 显式调用了 shutdown 方法，或在线程池的 finalize 方法中调用了 shutdown 方法\nRUNNING or SHUTDOWN | STOP | 调用了线程池的 shutdownNow 方法\nSHUTDOWN | TIDYING | 当工作队列和线程池都为空的时候\nSTOP | TIDYING | 当线程池为空的时候\nTIDYING | TERMINATED | 当方法 terminated 执行完毕的时候\n\nThreadPoolExecutor 利用 `ThreadPoolExecutor#ctl` 的高 3 位记录线程池的运行状态，并利用整型数值对每个状态进行标识，所以可以通过对整型数值的比较运算来判定当前的线程状态。ThreadPoolExecutor 提供了如下 3 个方法以对线程状态进行判定：\n\n```java\nprivate static boolean runStateLessThan(int c, int s) {\n    return c < s;\n}\n\nprivate static boolean runStateAtLeast(int c, int s) {\n    return c >= s;\n}\n\nprivate static boolean isRunning(int c) {\n    return c < SHUTDOWN;\n}\n```\n\n各方法的作用可以通过方法名直观理解。\n\n### 核心字段\n\nThreadPoolExecutor 中主要定义了如下基本字段，用于控制工作队列和线程池大小，以及线程池的运行，下面逐个解释说明。\n\n```java\nprivate final BlockingQueue<Runnable> workQueue;\nprivate final HashSet<Worker> workers = new HashSet<Worker>();\nprivate volatile ThreadFactory threadFactory;\nprivate volatile RejectedExecutionHandler handler;\nprivate volatile long keepAliveTime;\nprivate volatile boolean allowCoreThreadTimeOut;\nprivate volatile int corePoolSize;\nprivate volatile int maximumPoolSize;\n```\n\n- __workQueue__ ：直译为工作队列，用于存放已提交待执行的任务，这是线程池需要具备的一个基础组件。ThreadPoolExecutor 采用阻塞队列 BlockingQueue 作为工作队列的类型，当队列已满时后续提交任务的操作将会被阻塞，当队列为空时，从队列中取任务执行的操作也将被阻塞。\n- __workers__ ：工作线程集合，用于记录当前线程池中所有的工作线程，便于线程池对池中的线程数量、运行状态信息等进行管理。\n- __threadFactory__ ：线程工厂，用于创建新的线程，默认采用 DefaultThreadFactory 实现类，当然我们也可以在创建线程池时自定义线程工厂。\n- __handler__ ：用于指定饱和策略，我们往线程池中提交的任务不一定能够全部被线程池所接受，当线程池处于 SHUTDOWN 状态，或者线程池中的线程都处于运行状态但阻塞队列已满时，如果此时不能够再创建新的工作线程，则线程池可以基于饱和策略对任务提交操作进行反馈。JDK 为饱和策略定义了 RejectedExecutionHandler 接口，并提供了多种不同的策略实现，包括：AbortPolicy、CallerRunsPolicy、DiscardPolicy，以及 DiscardOldestPolicy 等，其中 AbortPolicy 是默认的饱和策略。\n- __keepAliveTime__ ：线程池中的线程往往具备一定的生命周期，当一个线程长时间处于空闲状态时线程池可以将其灭亡，以减少系统资源占用。属性 keepAliveTime 定义了一个线程的最大生命周期，以微妙为单位（我们在创建线程池时可以指定最大生命周期的时间单位，但最终都将转换成微秒记录到 keepAliveTime 中）。一般来说线程池都会定义线程数量的下限，当线程数量减少到该下限值时，余下的线程将会一直存活，ThreadPoolExecutor 定义了 allowCoreThreadTimeOut 变量来控制这部分线程是否受 keepAliveTime 变量值所影响，该变量默认为 false，如果 `allowCoreThreadTimeOut=true` 则任何线程到达生命周期时间时都会死亡。\n- __corePoolSize__ ：核心线程数，可以理解为一个线程池所持有的最小线程数，默认当线程池空闲时这部分线程也会一直存活，不受 keepAliveTime 时间影响。在一开始提交任务且线程池中持有的线程数量还未达到该变量值时，线程池不会复用已有的空闲线程，而是会直接创建新的线程并执行任务。\n- __maximumPoolSize__ ：最大线程数，用于控制线程池中线程数量上限，防止系统运行过程中创建大量的线程，从而浪费系统资源，频繁切换线程上下文。ThreadPoolExecutor 能够持有的线程数量不是无上限的，因为通过 int 类型记录线程池的工作状态，并且利用其中的低 29 位来记录线程数，所以一个线程池最多持有 2<sup>29</sup> - 1 个线程，该值记录在 CAPACITY 静态常量中，我们可以理解一个线程池的线程数量上限是 `min(CAPACITY, maximumPoolSize)`。需要注意的一点是， __当采用无界队列记录提交的任务时该变量将不起作用__ ，具体原因在后面分析线程创建策略时再进行说明。\n\n继续来看一下 ThreadPoolExecutor 的构造方法定义，ThreadPoolExecutor 提供了多种构造方法的重载版本，但都是对如下构造方法的各种定制：\n\n```java\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,\n                          long keepAliveTime, TimeUnit unit,\n                          BlockingQueue<Runnable> workQueue,\n                          ThreadFactory threadFactory,\n                          RejectedExecutionHandler handler) {\n    if (corePoolSize < 0 ||\n        maximumPoolSize <= 0 ||\n        maximumPoolSize < corePoolSize ||\n        keepAliveTime < 0)\n        throw new IllegalArgumentException();\n    if (workQueue == null || threadFactory == null || handler == null)\n        throw new NullPointerException();\n    this.corePoolSize = corePoolSize;\n    this.maximumPoolSize = maximumPoolSize;\n    this.workQueue = workQueue;\n    this.keepAliveTime = unit.toNanos(keepAliveTime);\n    this.threadFactory = threadFactory;\n    this.handler = handler;\n}\n```\n\n方法中所有的参数已在上面进行了专门的说明，需要注意的一点就是参数中的 keepAliveTime 是有单位的，但最终还是将其转换成了微秒记录在 keepAliveTime 字段中。此外，构造方法还允许我们自定义工作队列的实现类型、线程工厂，以及饱和策略等。\n\n### 任务调度\n\n本小节来分析一下 ThreadPoolExecutor 的任务调度过程。下面的代码块展示了 ThreadPoolExecutor 的基本使用方式，通常我们会调用 `ThreadPoolExecutor#submit` 或 `ThreadPoolExecutor#execute` 方法往线程池提交任务。方法 submit 本质上还是对 execute 的封装，该方法的实现位于 AbstractExecutorService 类中，ThreadPoolExecutor 继承了该抽象类。对于我们提交的任务，线程池会基于当前线程池的负载决定是否执行饱和策略，如果我们提交的任务被线程池接受，那么何时调度执行该任务则完全由线程池来控制，这其中的运行原理（调度策略）就是接下来我们主要分析的对象。\n\n```java\nThreadPoolExecutor executor = new ThreadPoolExecutor(1, 8, 60L, TimeUnit.SECONDS, new SynchronousQueue<>());\nexecutor.submit(new Callable<Boolean>() {\n    @Override\n    public Boolean call() throws Exception {\n        // do something here\n        return null;\n    }\n});\nexecutor.shutdown();\n```\n\nAbstractExecutorService 为 `AbstractExecutorService#submit` 方法提供了多种重载版本，这里我们以 `AbstractExecutorService#submit(Callable<T> task)` 方法为例进行说明：\n\n```java\npublic <T> Future<T> submit(Callable<T> task) {\n    if (task == null) throw new NullPointerException();\n    RunnableFuture<T> ftask = newTaskFor(task);\n    execute(ftask);\n    return ftask;\n}\n```\n\n该方法首先通过 FutureTask 对 task 进行了封装，然后交给 `ThreadPoolExecutor#execute` 进行调度。方法 `ThreadPoolExecutor#execute` 的实现如下：\n\n```java\npublic void execute(Runnable command) {\n    if (command == null) {\n        throw new NullPointerException();\n    }\n    /*\n     * Proceed in 3 steps:\n     *\n     * 1. If fewer than corePoolSize threads are running, try to\n     * start a new thread with the given command as its first\n     * task. The call to addWorker atomically checks runState and\n     * workerCount, and so prevents false alarms that would add\n     * threads when it shouldn't, by returning false.\n     *\n     * 2. If a task can be successfully queued, then we still need\n     * to double-check whether we should have added a thread\n     * (because existing ones died since last checking) or that\n     * the pool shut down since entry into this method. So we\n     * recheck state and if necessary roll back the enqueuing if\n     * stopped, or start a new thread if there are none.\n     *\n     * 3. If we cannot queue task, then we try to add a new\n     * thread.  If it fails, we know we are shut down or saturated\n     * and so reject the task.\n     */\n\n    // 获取 ctl 变量\n    int c = ctl.get();\n    // 1. 当前工作线程数小于 corePoolSize，正常情况下会新建一个线程，并将当前 command 绑定为该线程的第一个任务\n    if (workerCountOf(c) < corePoolSize) {\n        if (addWorker(command, true)) {\n            return;\n        }\n        c = ctl.get();\n    }\n\n    /* 工作线程数量大于等于 corePoolSize */\n\n    // 2. 当前线程池处于运行态，且工作队列能够容纳当前任务\n    if (isRunning(c) && workQueue.offer(command)) {\n        int recheck = ctl.get();\n        // 如果当前线程池处于非运行态，移除之前提交的任务\n        if (!isRunning(recheck) && remove(command)) {\n            // 触发饱和策略\n            reject(command);\n        }\n        // 当前工作线程数量为 0，新建线程执行之前累积的任务（包括刚刚提交的任务）\n        else if (workerCountOf(recheck) == 0) {\n            addWorker(null, false);\n        }\n        // 工作线程数量大于 0，不会新建线程，会先将任务记录到 workQueue 中由这些工作线程进行调度\n    }\n    // 3. 线程池处于非运行态，或工作队列已满\n    else if (!addWorker(command, false)) {\n        // 尝试创建新的线程失败，触发饱和策略\n        reject(command);\n    }\n}\n```\n\n上述方法所执行的逻辑可以分为 3 部分，每一部分都会调用 `ThreadPoolExecutor#addWorker` 方法，如下（注意调用参数设置）：\n\n1. 线程池工作线程数小于 corePoolSize，则执行 `addWorker(command, true)` 尝试新建工作线程执行提交的任务。\n2. 线程池工作线程数大于或等于 corePoolSize，且 workQueue 未满，则将提交的任务先记录到 workQueue 中。此时会再次检查工作线程数目，如果为 0 则执行 `addWorker(null, false)` 新建工作线程。\n3. 线程池工作线程数大于或等于 corePoolSize，且 workQueue 已满，则执行 `addWorker(command, false)` 尝试新建工作线程。\n\n下面先对 `ThreadPoolExecutor#addWorker` 方法进行分析，理解了该方法的作用和实现细节，我们再回过头来看 `ThreadPoolExecutor#execute` 方法会显得比较直观。\n\n```java\nprivate boolean addWorker(Runnable firstTask, boolean core) {\n\n    /* 1. 判断是否允许创建新的线程 */\n\n    retry:\n    for (; ; ) {\n        // 获取 ctl 变量\n        int c = ctl.get();\n        // 获取线程池的工作状态\n        int rs = runStateOf(c);\n\n        // Check if queue empty only if necessary.\n        /*\n         * 如果线程池满足下列状态之一，则立即返回 false：\n         * 1. 当前为除 SHUTDOWN 以外的其它非运行态\n         * 2. 当前为 SHUTDOWN，但是 firstTask != null，即尝试往线程池提交新任务\n         * 3. 当前为 SHUTDOWN，但是工作队列为空，累积的任务已被执行完\n         */\n        if (rs >= SHUTDOWN &&\n                !(rs == SHUTDOWN && firstTask == null && !workQueue.isEmpty())) {\n            return false;\n        }\n\n        /*\n         * 1. 当前线程池处于运行状态\n         * 2. 当前线程池处于 SHUTDOWN 状态，但是还有累积的任务未执行完\n         */\n\n        for (; ; ) {\n            // 获取工作线程数\n            int wc = workerCountOf(c);\n            // 如果当前工作线程数已经达到实际允许的最大工作线程上限，则直接返回 false\n            if (wc >= CAPACITY ||\n                    // core = true 表明调用 addWorker 方法时工作线程数小于 corePoolSize\n                    wc >= (core ? corePoolSize : maximumPoolSize)) {\n                return false;\n            }\n            // 工作线程数加 1，退出多重循环\n            if (compareAndIncrementWorkerCount(c)) {\n                break retry;\n            }\n            // 如果过程中工作线程数已变更，则再次尝试\n            c = ctl.get();  // Re-read ctl\n            // 线程池的工作状态已改变\n            if (runStateOf(c) != rs) {\n                continue retry;\n            }\n            // else CAS failed due to workerCount change; retry inner loop\n        }\n    }\n\n    /* 2. 创建 Worker 对象，并启动与之绑定的线程 */\n\n    boolean workerStarted = false;\n    boolean workerAdded = false;\n    Worker w = null;\n    try {\n        // 新建一个 Worker 对象，每个 Worker 绑定一个线程\n        w = new Worker(firstTask);\n        final Thread t = w.thread;\n        if (t != null) {\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                // Recheck while holding lock.\n                // Back out on ThreadFactory failure or if shut down before lock acquired.\n                int rs = runStateOf(ctl.get());\n\n                // 再次检测线程池工作状态\n                if (rs < SHUTDOWN || // 线程池处于运行态\n                        // 线程池处于 SHUTDOWN 状态，但是还有累积未完成的任务\n                        (rs == SHUTDOWN && firstTask == null)) {\n                    // 绑定的线程已被启动，这显然不符合逻辑\n                    if (t.isAlive()) {\n                        // precheck that t is startable\n                        throw new IllegalThreadStateException();\n                    }\n                    // 记录新建的 Worker 对象\n                    workers.add(w);\n                    int s = workers.size();\n                    if (s > largestPoolSize) {\n                        largestPoolSize = s;\n                    }\n                    workerAdded = true;\n                }\n            } finally {\n                mainLock.unlock();\n            }\n            // 启动线程\n            if (workerAdded) {\n                t.start();\n                workerStarted = true;\n            }\n        }\n    } finally {\n        if (!workerStarted) {\n            addWorkerFailed(w);\n        }\n    }\n    return workerStarted;\n}\n```\n\n整个 `ThreadPoolExecutor#addWorker` 方法的执行逻辑可以分为两个步骤：\n\n1. 判断当前线程池是否允许创建新的线程，如果不能则直接返回 false；\n2. 如果允许则创建 Worker 对象，并启动与之绑定的线程。\n\n首先来看 __步骤 1__ ，实现层面通过一个忙循环来执行判定的过程，第一次返回 false 的条件如下：\n\n```java\nif (rs >= SHUTDOWN &&\n        !(rs == SHUTDOWN && firstTask == null && !workQueue.isEmpty())) {\n    return false;\n}\n```\n\n满足这一行语句的所有条件可以概括为：\n\n1. 当前线程池处于除 SHUTDOWN 以外的其它非运行态。\n2. 当前线程池处于 SHUTDOWN 状态，但是 firstTask 不为 null，即尝试提交新的任务。\n3. 当前线程池处于 SHUTDOWN 状态，但是工作队列为空，即之前累积的任务已被执行完成。\n\n回忆一下我们在最开始总结线程池的运行态时，在哪些情况下线程池会继续执行我们提交的任务？实际上可以分为 RUNNING 和 SHUTDOWN 两类运行态，这两类运行态的含义分别如下：\n\n- RUNNING：该状态下线程池接收新的任务，并执行工作队列中的任务。\n- SHUTDOWN：该状态下线程池不接受新的任务，但是会继续执行工作队列中的任务。\n\n如果当前线程池的状态是 RUNNING，那么这时候是可以接受新提交的任务的，并且可以执行工作队列中堆积的任务，此时是不满足这里列举的 3 种情况的。如果当前是 SHUTDOWN 状态，那么线程池不会再接受新的任务，但是会继续执行工作队列中堆积的任务。所以说如果这个时候我们有提交新任务，那么就满足条件 2，当然是不允许创建新的线程执行的。此外，如果这个时候我们工作队列已没有待执行的任务，即满足条件 3，那么线程池也不会再允许创建新的线程。\n\n第二次返回 false 的条件如下：\n\n```java\nif (wc >= CAPACITY ||\n        wc >= (core ? corePoolSize : maximumPoolSize)) {\n    return false;\n}\n```\n\n这里的条件比较容易理解，如果当前线程池持有的线程数量已经达到理论上限 CAPACITY，当然不允许再创建新的线程，因为继续创建就溢出了。除了理论上限以外，线程池一般还存在实际容量上限，当达到该上限时同样不允许创建新的线程。这里的 core 参数是一个 boolean 类型，只有在当前工作线程数量小于 corePoolSize 时才为 true。对于线程池来说，如果当前工作线程数量小于 corePoolSize，则会直接创建新的工作线程去执行提交的任务，而不会将任务记录到工作队列中等待调度，所以在工作线程数量小于 corePoolSize 时是否创建新的线程应该以 corePoolSize 作为上限进行判断。因为过程中工作线程的数量是在变化的，如果走到这里说明工作线程的数量已经大于 corePoolSize，则不能直接创建新的线程，而是要先检查一下是否有空闲的工作线程可以复用。\n\n再来看一下 __步骤 2__ ，这一部分涉及到 ThreadPoolExecutor 中定义的一个核心内部类 Worker：\n\n```java\nprivate final class Worker extends AbstractQueuedSynchronizer implements Runnable {\n    private static final long serialVersionUID = 6138294804551838833L;\n\n    /** Thread this worker is running in.  Null if factory fails. */\n    final Thread thread;\n    /** Initial task to run.  Possibly null. */\n    Runnable firstTask;\n    /** Per-thread task counter */\n    volatile long completedTasks;\n\n    Worker(Runnable firstTask) {\n        setState(-1); // inhibit interrupts until runWorker\n        this.firstTask = firstTask;\n        this.thread = getThreadFactory().newThread(this);\n    }\n\n    /** Delegates main run loop to outer runWorker  */\n    public void run() {\n        runWorker(this);\n    }\n\n    // 省略加锁相关方法\n}\n```\n\nWorker 继承自 AbstractQueuedSynchronizer 抽象类，基于 AQS 实现了一个简单的不可重入独占锁，并复用 AQS 的 state 字段以表示锁的状态，其中 `state=0` 表示锁未被获取的状态，而 `state=1` 表示锁已经被获取的状态。初始时，state 值为 -1，以防止在运行 `ThreadPoolExecutor#runWorker` 方法之前被中断。\n\n此外，Worker 类还实现了 Runnable 接口。当我们新建一个 Worker 对象时，线程池会为其绑定一个新的线程对象。当我们启动该线程时，实际上调用的是 `Worker#run` 方法，该方法实现如下：\n\n```java\npublic void run() {\n    runWorker(this);\n}\n\n// ThreadPoolExecutor#runWorker\nfinal void runWorker(Worker w) {\n    // 获取当前线程对象\n    Thread wt = Thread.currentThread();\n    // 获取与当前 Worker 对象绑定的任务\n    Runnable task = w.firstTask;\n    w.firstTask = null;\n    w.unlock(); // allow interrupts\n    boolean completedAbruptly = true;\n    try {\n        // 尝试先执行与当前 Worker 对象绑定的任务，如果没有则尝试从工作队列中获取待执行的任务\n        while (task != null || (task = getTask()) != null) {\n            w.lock();\n            // If pool is stopping, ensure thread is interrupted; if not, ensure thread is not interrupted.\n            // This requires a recheck in second case to deal with shutdownNow race while clearing interrupt\n            if ((runStateAtLeast(ctl.get(), STOP) ||\n                    (Thread.interrupted() && runStateAtLeast(ctl.get(), STOP))) &&\n                    !wt.isInterrupted()) {\n                wt.interrupt();\n            }\n            try {\n                // 模板方法\n                beforeExecute(wt, task);\n                Throwable thrown = null;\n                try {\n                    // 执行任务\n                    task.run();\n                } catch (RuntimeException x) {\n                    thrown = x;\n                    throw x;\n                } catch (Error x) {\n                    thrown = x;\n                    throw x;\n                } catch (Throwable x) {\n                    thrown = x;\n                    throw new Error(x);\n                } finally {\n                    // 模板方法\n                    afterExecute(task, thrown);\n                }\n            } finally {\n                // 防止任务被重复执行\n                task = null;\n                w.completedTasks++;\n                w.unlock();\n            }\n        }\n        completedAbruptly = false;\n    } finally {\n        processWorkerExit(w, completedAbruptly);\n    }\n}\n```\n\n方法 `ThreadPoolExecutor#runWorker` 描述了一个 Worker 不断执行任务的过程，任务可以是我们创建该 Worker 对象时绑定的，也可以是从工作队列中获取的。只要是存在待执行的任务，且当前线程池运行状态允许执行提交的任务，同时线程没有被中断，就可以循环的处理已提交的任务。当一个任务被执行完毕或因异常而退出，那么该任务会被标记为 null，从而防止任务被重复执行，同时可以让垃圾收集器回收任务对象，方法中在线程执行前后分别提供了模板方法方便扩展。\n\n继续回到 `ThreadPoolExecutor#addWorker` 方法，当我们创建完 Worker 对象之后，线程并没有马上启动工作，而是会再次检测一下线程池的运行状态确保允许启动当前线程。如果允许则会记录当前 Worker 对象到 workers 全局集合中，该集合主要用来让线程池管理池中的线程对象，比如当前线程池的大小、检查各个线程的状态等等。如果一个 Worker 对象被成功注册，那么接下去就会启动与之绑定的线程对象，开始处理提交的任务。\n\n介绍完了 `ThreadPoolExecutor#addWorker` 方法的作用和实现， 我们回过头来继续分析最开始的 `ThreadPoolExecutor#execute` 方法，有了对 Worker 对象的创建，以及任务调度过程的理解，再回过头来看该方法的运行逻辑会清晰许多。前面我们说了 `ThreadPoolExecutor#execute` 方法主要分为 3 个部分，更准确来说是 4 种场景，先简单概括一下：\n\n1. 如果线程池工作线程数小于 corePoolSize，则直接创建新的线程并执行提交的任务；\n2. 如果线程池工作线程数大于或等于 corePoolSize，且工作队列未满，则将提交的任务先缓存到工作队列中，此时会判断是否有工作线程，如果没有则会创建新的线程以继续调度执行缓存的任务；\n3. 如果线程池工作线程数大于或等于 corePoolSize，且工作队列已满，但是工作线程数还未达到线程池实际容量上限，则创建新的线程；\n4. 如果线程池工作线程数大于或等于 corePoolSize，且工作队列已满，同时工作线程数达到线程池实际容量上限，则触发饱和策略。\n\n![image](/images/2018/thread-pool-executor-schedule.png)\n\n如上图描绘了线程池的任务调度执行流程。\n\n先来看一下 __步骤 1__ ，这一步描述第 1 种场景（实现如下）。线程池判断当前工作线程数小于 corePoolSize，则执行 `ThreadPoolExecutor#addWorker(command, true)`。由于第 2 个参数为 true，所以会依据 corePoolSize 判断是否直接创建新的线程并执行提交的任务，因为这中间工作线程数量可能会发生变化，一旦工作线程数达到 corePoolSize，则需要执行其它的策略。\n\n```java\n// 1. 当前工作线程数小于 corePoolSize，正常情况下会新建一个线程，并将当前 command 绑定为该线程的第一个任务\nif (workerCountOf(c) < corePoolSize) {\n    if (addWorker(command, true)) {\n        return;\n    }\n    c = ctl.get();\n}\n```\n\n再来看 __步骤 2__ ，这一步描述了第 2 种场景（实现如下）。能够执行到这里说明工作线程数量已经大于或等于 corePoolSize，同时线程池处于运行态。此时，会尝试先将提交的任务记录到工作队列中，如果过程中线程池的状态发生变更，切换为非运行态，则会从工作队列中移除刚刚提交的任务，并触发饱和策略；否则判断当前的工作线程数，如果为 0 则需要新建工作线程，因为工作队列中还有累积待执行的任务。\n\n```java\n// 2. 当前线程池处于运行态，且工作队列能够容纳当前任务\nif (isRunning(c) && workQueue.offer(command)) {\n    int recheck = ctl.get();\n    // 如果当前线程池处于非运行态，移除之前提交的任务\n    if (!isRunning(recheck) && remove(command)) {\n        // 触发饱和策略\n        reject(command);\n    }\n    // 当前工作线程数量为 0，新建线程执行之前累积的任务（包括刚刚提交的任务）\n    else if (workerCountOf(recheck) == 0) {\n        addWorker(null, false);\n    }\n    // 工作线程数量大于 0，不会新建线程，会先将任务记录到 workQueue 中由这些工作线程进行调度\n}\n```\n\n最后来看一下 __步骤 3__ ，这一步描述了第 3 和第 4 两种场景（实现如下）。能够运行到这一步需要满足两种情况之一：\n\n1. 当前线程池处于非运行状态；\n2. 工作队列已满。\n\n如果线程池当前处于非运行状态，按照之前对于 `ThreadPoolExecutor#addWorker` 方法的分析可知，如果提交的任务不为 null，势必触发饱和策略。如果是因为工作队列已满的原因，则需要依据当前线程池是否还允许创建新的线程来决定是否触发饱和策略。\n\n```java\n// 3. 线程池处于非运行态，或工作队列已满\nelse if (!addWorker(command, false)) {\n    // 尝试创建新的线程失败，触发饱和策略\n    reject(command);\n}\n```\n\n本小节的最后，我们来思考两个问题：\n\n1. 为什么当工作线程数达到核心线程数时，线程池选择将任务先缓存到队列，而不是继续创建线程以执行当前提交的任务呢？\n2. 如果希望改变线程池的调度策略，即当工作线程数达到核心线程数时继续创建线程执行提交的任务，只有当工作线程数达到上限时才选择将任务缓存到队列，应该如何实现呢？\n\n首先来看 __问题 1__ ，ThreadPoolExecutor 采取的策略有点反直觉，直观的我们会认为线程池会在线程数达到上限时才会将后续的任务缓存到队列，那么为什么 ThreadPoolExecutor 要这么做呢？\n\n应用程序广义上可以分为 CPU 密集型和 IO 密集型两大类。对于 CPU 密集型应用而言应该控制线程数尽量接近 CPU 核心数，以避免频繁切换线程上下文所带来的开销；对于 IO 密集型应用而言可以多创建一些线程，因为这一类应用大部分时间都在等待 IO 时间，CPU 相对较空闲。ThreadPoolExecutor 所采取的策略更加适用于 CPU 密集型应用，这应该也是考虑大部分的 java 应用程序都是 CPU 密集型。然而，对于 IO 密集型应用，如果直接使用 ThreadPoolExecutor 就显得有些呆滞，这也是像 Tomcat、Jetty，以及 Dubbo 一类应用需要自己实现线程池的动因。\n\n再来看 __问题 2__ ，既然有应用场景，那么如何实现呢？\n\n直观的思路就是将核心线程数与最大线程数设置相同，实现如下：\n\n```java\nThreadPoolExecutor executor = new ThreadPoolExecutor(\n        8, 8,\n        60, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<>(32),\n        Executors.defaultThreadFactory(),\n        new ThreadPoolExecutor.AbortPolicy());\n\n// 允许核心线程空闲时被回收\nexecutor.allowCoreThreadTimeOut(true);\n```\n\n这是一种比较讨巧的做法，即所有的线程都是核心线程，虽然从表象上能够满足需求，但并不完全符合题意。\n\n换一种思路，我们可以继承 ThreadPoolExecutor 类，重写 `ThreadPoolExecutor#execute` 方法，这也是面向对象编程比较直观的思路。不过，很可惜这条路走不通，因为 ThreadPoolExecutor 中一些状态属性的访问权限是 private，无法被继承。\n\n既然无法通过继承访问 ThreadPoolExecutor 中的 private 状态属性，另外一种思路就是拷贝一份 ThreadPoolExecutor 类，然后修改 `ThreadPoolExecutor#execute` 方法。这条路确实能够走通，但是缺点也是显而易见的，因为自定义的 ThreadPoolExecutor 类只能在自己的应用程序内部使用，无法输出给其它第三方依赖库。\n\n最后，我们来看看开源厂商的做法，这里以 Dubbo 为例。Dubbo 内部通过继承 ThreadPoolExecutor 实现了一个叫 EagerThreadPoolExecutor 的线程池类，其 __解决思路的核心在于在工作队列的 offer 方法上做文章__ 。我们知道 ThreadPoolExecutor 在工作队列已满时会创建新的工作线程，而判断工作队列已满的方式就是调用工作队列的 offer 方法，如果该方法返回 false 则认为工作队列已满。\n\nDubbo 在实现层面继承 LinkedBlockingQueue 自定义实现了 TaskQueue 队列，其 `TaskQueue#offer` 方法实现如下：\n\n```java\npublic boolean offer(Runnable runnable) {\n    if (executor == null) {\n        throw new RejectedExecutionException(\"The task queue does not have executor!\");\n    }\n\n    int currentPoolThreadSize = executor.getPoolSize();\n    // have free worker. put task into queue to let the worker deal with task.\n    // 当前还有空闲的工作线程，缓存任务到工作队列\n    if (executor.getSubmittedTaskCount() < currentPoolThreadSize) {\n        return super.offer(runnable);\n    }\n\n    // return false to let executor create new worker.\n    // 当前没有空闲的工作线程，且工作线程数未达到上限，返回 false 迫使线程池创建新的工作线程\n    if (currentPoolThreadSize < executor.getMaximumPoolSize()) {\n        return false;\n    }\n\n    // currentPoolThreadSize >= max\n    // 工作线程数达到上限，将任务缓存到队列\n    return super.offer(runnable);\n}\n```\n\n上述方法也诠释了 Dubbo 解决问题 2 的核心思想。关于 EagerThreadPoolExecutor 的实现这里不再展开，有兴趣的读者可继续阅读 Dubbo 源码。\n\n### 饱和策略\n\n上面我们多次提及到“饱和策略”一词，所谓饱和策略是指线程池无法容纳新任务的一种拒绝手段。JUC 定义了 RejectedExecutionHandler 接口用于描述饱和策略，当执行 `ThreadPoolExecutor#reject` 方法时，线程池会应用具体的饱和策略，如下：\n\n```java\nfinal void reject(Runnable command) {\n    handler.rejectedExecution(command, this);\n}\n```\n\nJUC 针对 RejectedExecutionHandler 接口定义了 4 个实现类，包括：AbortPolicy、DiscardPolicy、DiscardOldestPolicy，以及 CallerRunsPolicy。其中，AbortPolicy 是 ThreadPoolExecutor 的默认饱和策略。关于这 4 种饱和策略的释义如下：\n\n- __AbortPolicy__ ：抛出 RejectedExecutionException 异常。\n- __DiscardPolicy__ ：简单的丢弃当前提交的任务，而不抛出任何异常。\n- __DiscardOldestPolicy__ ：从工作队列中移除等待时间最久的任务，并尝试提交当前任务。\n- __CallerRunsPolicy__ ：尝试在调用线程中直接执行当前提交的任务。\n\n上述策略执行当前提交的任务的前提是线程池处于运行态，否则仍然会静默忽略当前提交的任务。\n\n### 总结\n\n本文我们分析了线程池 ThreadPoolExecutor 设计与实现，总的说来线程池对于新任务的接受或拒绝，以及对于已接受任务的调度过程还是比较容易理解的。整个 ThreadPoolExecutor 的实现上，最令人敬佩的是 [Doug Lea](https://en.wikipedia.org/wiki/Doug_Lea) 大师在线程池状态和工作线程数量记录上的设计，以一个 int 型，通过位运算来实现所有的基础逻辑，简洁、高效，值得借鉴。\n\n### 参考\n\n1. JDK 1.8 源码\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：关于线程安全队列的若干总结","url":"/2018/09/22/java/juc-queue-overview/","content":"\n前面的几篇文章中，我们对于 JUC 包中提供的线程安全队列的设计与实现进行了全面的分析。JUC 包为 java 开发人员提供了丰富的线程安全队列实现，以满足不同的性能和应用场景需求。然而，不知道你是否与我一样，在学习了各个线程安全队列的实现机制之后，反而有点犯迷糊，这些线程安全队列我们在具体编码时该如何选择呢？于是我打算写一篇总结性的文章，对各个线程安全队列的特性进行总结。<!-- more -->\n\n![image](/images/2018/juc-queue.png)\n\n上面这幅图展示了 JUC 线程安全队列的类继承关系，总的来说线程安全队列分为 Queue 和 Deque 两大类，本文主要关注 Queue。在 Queue 的范围内可以进一步将线程安全队列分为阻塞队列和非阻塞队列，目前只有 ConcurrentLinkedQueue 是非阻塞队列，其它都是阻塞队列。\n\n### 接口说明\n\n由上面的类继承关系图可知，在整个 Queue 的继承关系中包含 3 个接口，即 Queue 接口、BlockingQueue 接口，以及 TransferQueue 接口，这 3 个接口依次成继承关系。\n\n#### Queue 接口\n\nQueue 接口继承自 Collection 接口，增加了队列相关的操作，定义如下：\n\n```java\npublic interface Queue<E> extends Collection<E> {\n\n    boolean add(E e);\n    boolean offer(E e);\n\n    E poll();\n    E peek();\n    E element();\n\n    E remove();\n\n}\n```\n\n针对该接口各方法的含义说明如下：\n\n- `add`：往队列中添加元素，如果成功则返回 true，对于有界队列来说，如果队列已满则抛出 IllegalStateException 异常。\n- `offer`：往队列中添加元素，如果成功则返回 true，对于有界队列来说，如果队列已满则返回 false，而不是抛出异常。\n- `poll`：移除队列头结点，并返回结点元素值，如果队列为空则返回 null。\n- `peek`：仅获取头结点元素值而不删除结点，如果队列为空则返回 null。\n- `element`：仅获取头结点元素值而不删除结点，如果队列为空则抛出 NoSuchElementException 异常。\n- `remove`：移除队列头结点，并返回结点元素值，如果队列为空则抛出 NoSuchElementException 异常。\n\n#### BlockingQueue 接口\n\nBlockingQueue 接口继承自 Queue 接口，用于描述阻塞队列。当队列无法及时响应用户请求时，例如当我们尝试从空队列中获取元素，或者继续往已满的有界队列中添加元素，BlockingQueue 定义了以下 4 种响应形式：\n\n1. 抛出异常。\n2. 立即返回特殊值，例如 null 或 false。\n3. 无限期阻塞当前请求，直到队列状态变为可用。\n4. 超时阻塞当前请求，直到队列状态变为可用。\n\nBlockingQueue 接口的定义如下：\n\n```java\npublic interface BlockingQueue<E> extends Queue<E> {\n\n    boolean offer(E e);\n    boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException;\n    boolean add(E e);\n    void put(E e) throws InterruptedException;\n\n    E poll(long timeout, TimeUnit unit) throws InterruptedException;\n    E take() throws InterruptedException;\n\n    boolean remove(Object o);\n\n    boolean contains(Object o);\n    int remainingCapacity();\n\n    int drainTo(Collection<? super E> c);\n    int drainTo(Collection<? super E> c, int maxElements);\n\n}\n```\n\n针对该接口各方法的含义说明如下：\n\n- `offer`：往队列中添加元素，如果成功则返回 true，对于有界队列来说，如果队列已满则返回 false，而不是抛出异常。BlockingQueue 同时还声明了超时版本的 offer 方法。\n- `add`：往队列中添加元素，如果成功则返回 true，对于有界队列来说，如果队列已满则抛出 IllegalStateException 异常。\n- `put`：往队列中添加元素，对于有界队列来说，如果队列已满则阻塞当前请求，期间支持响应中断。\n- `poll`：移除队列头结点，并返回结点元素值，如果队列为空则等待指定时间，并在超时时返回 null，期间支持响应中断。\n- `take`：仅获取头结点元素值而不删除结点，如果队列为空则阻塞等待，期间支持响应中断。\n- `remove`：接收一个参数，从队列中删除值等于该参数的结点，如果存在多个结点满足要求，则删除第一个。\n- `contains`：接收一个参数，判断队列中是否存在值等于该参数的结点。\n- `remainingCapacity`：返回队列的剩余容量，如果是无界队列，则返回 `Integer.MAX_VALUE`。\n- `drainTo`：从队列中移除所有（或指定个数）结点，并将结点元素放入参数指定的集合中返回，相对于逐个移除更加高效。\n\n#### TransferQueue 接口\n\nTransferQueue 接口在 JDK 1.7 被引入，用于描述一种全新的阻塞队列。LinkedTransferQueue 实现自 TransferQueue 接口，并且是目前（JDK 1.8）该接口的唯一实现类。TransferQueue 接口继承自 BlockingQueue 接口，由 BlockingQueue 描述的阻塞队列在队列为空或者已满时，相应的出队列线程或入队列线程会阻塞等待，而 TransferQueue 则更进一步。以入队列操作为例，当线程成功将元素添加到由 TransferQueue 描述的阻塞队列中后，该线程通常会一直阻塞直到某个出队列线程从队列中取走该入队列线程添加的元素。\n\nTransferQueue 在 BlockingQueue 接口的基础上增加了以下方法：\n\n```java\npublic interface TransferQueue<E> extends BlockingQueue<E> {\n\n    void transfer(E e) throws InterruptedException;\n\n    boolean tryTransfer(E e);\n    boolean tryTransfer(E e, long timeout, TimeUnit unit) throws InterruptedException;\n\n    boolean hasWaitingConsumer();\n    int getWaitingConsumerCount();\n\n}\n```\n\n针对各方法的含义说明如下：\n\n- `transfer`：生产者将元素直接传递给正在等待的消费者，而不执行入队列操作，如果没有正在等待的消费者则无限期等待，期间支持响应中断。\n- `tryTransfer`：生产者将元素直接传递给正在等待的消费者，而不执行入队列操作，如果没有正在等待的消费者则返回 false，提供相应的超时版本。\n- `hasWaitingConsumer`：检查是否存在正在等待的消费者。\n- `getWaitingConsumerCount`：返回当前正在等待的消费者数目（近似值）。\n\n由上述接口方法释义我们可以了解到，TransferQueue 系的队列支持在两个线程之间直接交换数据，而无需先将数据落地存储到队列中，如果确实需要落地，则线程可以随数据一起在队列上等待。\n\n### 特性总结\n\n了解了线程安全队列接口的相关定义，下面对实现了这些接口的具体线程安全队列各自的特性做一个总结。\n\n#### 基本属性\n\n队列 | 数据结构 | 是否阻塞 | 是否有界 | 是否允许 NULL 值 | 安全机制 | 备注\n--- | --- | --- | --- | --- | --- | ---\nConcurrentLinkedQueue | 链表 | 否 | 否 | 否 | CAS |\nArrayBlockingQueue | 数组 | 是 | 是 | 否 | ReentrantLock |\nLinkedBlockingQueue | 链表 | 是 | 是 | 否 | ReentrantLock |\nPriorityBlockingQueue | 最小堆（数组） | 是 | 几乎无界，但受制于底层数组长度限制  | 否 | ReentrantLock | 线程安全的优先级队列\nDelayQueue | PriorityQueue | 是 | 否 | 否 | ReentrantLock | 队列元素需要实现 Delayed 接口，即所有的元素都具备过期属性，并按照过期的先后顺序在队列中进行组织\nSynchronousQueue | Dual Stack / Dual Queue | 是 | 否 | 否 | CAS | 不同于一般线程安全队列，主要应用于线程之间的协同，类比“生产者-消费者”模式\nLinkedTransferQueue | Dual Queue | 是 | 否 | 否 | CAS | 可以看作是 ConcurrentLinkedQueue、SynchronousQueue（公平模式）和 LinkedBlockingQueue 的超集，并且更加实用和高效\n\n#### API 说明\n\n队列 | add | offer | offert(timeout) | put | poll | poll(timeout) | take | peek | element | remove | size\n--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---\nConcurrentLinkedQueue | 委托给 offer 接口 | 往队尾追加元素，无容量限制，始终返回 true | 不支持 | 不支持 | 移除并返回队头元素，如果队列为空则返回 null | 不支持 | 不支持 | 仅返回队头元素，如果队列为空则返回 null | 仅返回队头元素，如果队列为空则抛 NoSuchElementException 异常 | 移除并返回队头元素，如果队列为空则抛 NoSuchElementException 异常 | 近似值\nArrayBlockingQueue | 往队尾追加元素，成功则返回 true，失败则抛出 IllegalStateException 异常 | 往队尾追加元素，成功则返回 true，失败则返回 false | 往队尾追加元素，成功则返回 true，失败则先等待一段时间，而不是立即返回 false | 往队尾追加元素，成功则立即返回，失败则持续等待，直到队列有空闲容量 | 移除并返回队头元素，如果队列为空则立即返回 null | 移除并返回队头元素，如果队列为空则先等待一段时间，而不是立即返回 null | 移除并返回队头元素，如果队列为空则等待直到有新的元素可以返回 | 仅返回队头元素，如果队列为空则返回 null | 仅返回队头元素，如果队列为空则抛 NoSuchElementException 异常 | 移除并返回队头元素，如果队列为空则抛 NoSuchElementException 异常 | 精确值\nLinkedBlockingQueue | 往队尾追加元素，成功则返回 true，失败则抛出 IllegalStateException 异常 | 往队尾追加元素，成功则返回 true，失败则返回 false | 往队尾追加元素，成功则返回 true，失败则先等待一段时间，而不是立即返回 false | 往队尾追加元素，成功则立即返回，失败则持续等待，直到队列有空闲容量 | 移除并返回队头元素，如果队列为空则立即返回 null | 移除并返回队头元素，如果队列为空则先等待一段时间，而不是立即返回 null | 移除并返回队头元素，如果队列为空则等待直到有新的元素可以返回 | 仅返回队头元素，如果队列为空则返回 null | 仅返回队头元素，如果队列为空则抛 NoSuchElementException 异常 | 移除并返回队头元素，如果队列为空则抛 NoSuchElementException 异常 | 精确值\nPriorityBlockingQueue | 委托给 offer 接口 | 往队尾追加元素，因为是无界队列所以一般都会成功，期间可能会执行扩容操作，如果容量到达上限则 OOM | 委托给 offer 接口 | 委托给 offer 接口 | 移除并返回队头（最高优先级）元素，如果队列为空则立即返回 null | 移除并返回队头（最高优先级）元素，如果队列为空则先等待一段时间，而不是立即返回 null | 移除并返回队头（最高优先级）元素，如果队列为空则等待直到有新的元素可以返回 | 仅返回队头（最高优先级）元素，如果队列为空则返回 null | 仅返回队头元素，如果队列为空则抛 NoSuchElementException 异常 | 移除并返回队头元素，如果队列为空则抛 NoSuchElementException 异常 | 精确值\nDelayQueue | 委托给 offer 接口 | 往队尾追加元素，因为是无界队列所以一般都会成功，期间可能会执行扩容操作，如果容量到达上限则 OOM | 委托给 offer 接口 | 委托给 offer 接口 | 移除并返回队头（已到期）元素，如果队列为空或没有到期的元素则立即返回 null | 移除并返回队头（已到期）元素，如果队列为空或没有到期的元素则先等待一段时间，而不是立即返回 null | 移除并返回队头（已到期）元素，如果队列为空或没有到期的元素则等待直到有新的元素到期 | 仅返回队头（最先到期，此时可能还未到期）元素，如果队列为空则返回 null | 仅返回队头（最先到期，此时可能还未到期）元素，如果队列为空则抛 NoSuchElementException 异常 | 移除并返回队头（已到期）元素，如果队列为空或没有到期的元素则抛 NoSuchElementException 异常 | 精确值\nSynchronousQueue | 委托给 offer 接口，入队列失败则抛出 IllegalStateException 异常 | 往队尾追加元素，成功（说明队列中存在待匹配的元素）则返回 true，失败（说明队列中不存在待匹配的元素）则返回 false | 往队尾追加元素，如果队列中存在待匹配的元素则入队列成功，返回 true，否则等待指定时间，如果仍然没有可以匹配的元素则入队列失败，返回 false | 往队尾追加元素，并一直等待直到被匹配 | 移除并返回队列中第一个与之匹配的结点元素，如果不存在则立即返回 null | 移除并返回队列中第一个与之匹配的结点元素，如果不存在则先等待一段时间，而不是立即返回 null | 移除并返回队列中第一个与之匹配的结点元素，如果不存在则等待直到有匹配的元素可以返回 | 始终返回 null | 始终抛 NoSuchElementException 异常 | 移除并返回队列中第一个数据结点元素，如果不存在则抛 NoSuchElementException 异常 | 始终返回 0\nLinkedTransferQueue | 往队尾追加元素，因为是无界队列，所以始终返回 true | 往队尾追加元素，因为是无界队列，所以始终返回 true | 往队尾追加元素，因为是无界队列，所以始终返回 true，并且不会因为队列已满而阻塞等待 | 往队尾追加元素，因为是无界队列，所以不会因为队列已满而阻塞等待 | 移除并返回队列中第一个数据结点元素，如果不存在则立即返回 null | 移除并返回队列中第一个数据结点元素，如果不存在则先等待一段时间，而不是立即返回 null | 移除并返回队列中第一个数据结点元素，如果不存在则等待直到有新的元素可以返回 | 仅返回队列中的第一个数据节点元素，如果不存在则返回 null | 仅返回队列中的第一个数据节点元素，如果不存在则抛 NoSuchElementException 异常 | 移除并返回队列中的第一个数据节点元素，如果不存在则抛 NoSuchElementException 异常 | 精确值（`O(n)`）\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：LinkedTransferQueue","url":"/2018/09/21/java/juc-linked-transfer-queue/","content":"\n上一篇我们分析了 SynchronousQueue 队列的设计与实现。在 SynchronousQueue 内部定义了一个 Transferer 抽象类，并继承该类基于 Dual Queue 和 Dual Stack 数据结构分别实现了 SynchronousQueue 的公平模式和非公平模式。本篇我们将要介绍的 LinkedTransferQueue 队列在设计思路上与 SynchronousQueue 的公平模式十分相似，二者在底层存储结构选型上都引入了 Dual Queue 数据结构。\n\nLinkedTransferQueue 在 jdk 1.7 被引入，是一个基于 Dual Queue 数据结构实现的无界线程安全队列，其作者 [Doug Lea](https://en.wikipedia.org/wiki/Doug_Lea) 描述 LinkedTransferQueue 从功能上来说是 ConcurrentLinkedQueue、SynchronousQueue（公平模式），以及 LinkedBlockingQueue 的超集，并且更加实用和高效。<!-- more -->\n\n下面的章节我们将一起来分析 LinkedTransferQueue 的设计与实现，不过在开始之前还是需要先对两个名词做一下解释，即匹配和松弛度。\n\n我们在上一篇介绍 SynchronousQueue 队列时已经解释了 __匹配__ 的概念，这里再重复介绍一下。LinkedTransferQueue 在内部基于队列实现线程间的交互，以“生产者-消费者”为例，当生产者往 LinkedTransferQueue 中插入一个元素时，通常情况下该生产者线程在插入成功之后并不会立即返回，而是等待消费者前来消费。当消费者执行消费时发现队列上正好有生产者在等待，于是执行消费逻辑，也称为开始执行匹配进程，将当前消费者与生产者匹配成一对儿纷纷出队列。\n\n匹配描述的是 Dual Queue 的运行机制，而 __松弛度（slack）__ 则是一种优化策略。为了避免频繁移动队列的 head 和 tail 指针，作者引入了松弛度的概念，以度量 head 结点（或 tail 结点）与最近一个未匹配结点之间的距离。当一个结点被匹配（或取消，或插入）时，LinkedTransferQueue 并不会立即更新相应的 head 或 tail 指针，而是当松弛度大于指定阈值时才触发更新。这个阈值的取值范围一般设置在 1 到 3 之间，如果太大会降低有效结点命中率，增加遍历的长度，太小则会增加 CAS 的竞争和开销。\n\n### TransferQueue 接口\n\nTransferQueue 接口在 JDK 1.7 被引入，用于描述一种全新的阻塞队列。LinkedTransferQueue 实现自 TransferQueue 接口，并且是目前（JDK 1.8）该接口的唯一实现类。TransferQueue 接口继承自 BlockingQueue 接口，由 BlockingQueue 描述的阻塞队列在队列为空或者已满时，相应的出队列线程或入队列线程会阻塞等待，而 TransferQueue 则更进一步。以入队列操作为例，当线程成功将元素添加到由 TransferQueue 描述的阻塞队列中后，该线程通常会一直阻塞直到某个出队列线程从队列中取走该入队列线程添加的元素。\n\nTransferQueue 在 BlockingQueue 接口的基础上增加了以下方法：\n\n```java\npublic interface TransferQueue<E> extends BlockingQueue<E> {\n\n    void transfer(E e) throws InterruptedException;\n\n    boolean tryTransfer(E e);\n    boolean tryTransfer(E e, long timeout, TimeUnit unit) throws InterruptedException;\n\n    boolean hasWaitingConsumer();\n    int getWaitingConsumerCount();\n\n}\n```\n\n针对各方法的含义说明如下：\n\n- `transfer`：生产者将元素直接传递给正在等待的消费者，而不执行入队列操作，如果没有正在等待的消费者则无限期等待，期间支持响应中断。\n- `tryTransfer`：生产者将元素直接传递给正在等待的消费者，而不执行入队列操作，如果没有正在等待的消费者则返回 false，提供相应的超时版本。\n- `hasWaitingConsumer`：检查是否存在正在等待的消费者。\n- `getWaitingConsumerCount`：返回当前正在等待的消费者数目（近似值）。\n\n由上述接口方法释义我们可以了解到，TransferQueue 系的队列支持在两个线程之间直接交换数据，而无需先将数据落地存储到队列中，如果确实需要落地，则线程可以随数据一起在队列上等待。\n\n### 核心方法实现\n\nLinkedTransferQueue 针对 BlockingQueue 和 TransferQueue 接口中声明的方法，在实现上均委托给 `LinkedTransferQueue#xfer` 方法执行，该方法也是本小节将要重点分析的方法。\n\n在开始分析 `LinkedTransferQueue#xfer` 方法的实现之前，我们先介绍一下 LinkedTransferQueue 的基本字段定义。LinkedTransferQueue 基于 Dual Queue 作为底层存储结构，并定义了 Node 类描述 Dual Queue 上的结点，字段 `LinkedTransferQueue#head` 和 `LinkedTransferQueue#tail` 分别指向底层队列的头结点和尾结点。\n\nNode 类的字段定义如下：\n\n```java\nstatic final class Node {\n\n    /** 标识当前结点是一个数据结点，还是一个请求结点 */\n    final boolean isData;   // false if this is a request node\n    /**\n     * 存放数据，并标识匹配状态：\n     * - 对于请求结点初始为 null，匹配之后指向自己\n     * - 对于数据结点初始为 data，匹配之后为 null\n     */\n    volatile Object item;   // initially non-null if isData; CASed to match\n    /** 后继指针 */\n    volatile Node next;\n    /** 记录在当前结点上等待的线程对象 */\n    volatile Thread waiter; // null until waiting\n\n    // ... 省略方法定义\n\n}\n```\n\nLinkedTransferQueue 中的结点分为 __数据结点__ 和 __请求结点__ 两类，可以简单将数据结点理解为生产者结点，将请求结点理解为消费者结点。Node 类通过 `Node#isData` 字段标记一个结点是数据结点还是请求结点，并通过 `Node#item` 字段承载数据和标识对应结点的匹配状态。下表展示了数据结点和请求结点在匹配前后，字段 `Node#item` 的变化：\n\n结点类型 | 数据结点 | 请求结点\n--- | --- | ---\n匹配前 | isData = true; item != null | isData = false; item = null\n匹配后 | isData = true; item = null | isData = false; item = this\n\n注意：当一个结点被取消后，该结点的 `Node#item` 字段同样指向结点自己。\n\n由上述表格我们可以设计一个判断结点是否已经匹配的方法，如下：\n\n```java\n// Node#isMatched\nfinal boolean isMatched() {\n    Object x = item;\n    return (x == this) || ((x == null) == isData);\n}\n```\n\n如果一个结点的 item 字段指向自己（即 `x == this`），说明该结点被取消，或者对于请求结点而言，该结点已经被匹配，否则我们就可以继续执行 `(x == null) == isData` 进行判断，具体如下：\n\n1. 如果当前结点是数据结点（即 `isData = true`），如果该结点被匹配则结点的 item 应该为 null，所以满足 `(x == null) == isData` 。\n2. 如果当前结点是请求结点（即 `isData = false`），如果该结点被匹配则结点的 item 应该不为 null，所以满足 `(x == null) == isData`。\n\n接下来我们开始分析 `LinkedTransferQueue#xfer` 方法的实现，首先来看一下方法的参数定义，如下：\n\n```java\nprivate E xfer(E e, boolean haveData, int how, long nanos) {\n    // ... 省略方法实现\n}\n```\n\n其中参数 e 表示待添加的元素值，如果是出队列操作，则为 null；参数 haveData 用于指定当前是入队列操作还是出队列操作，如果是入队列则 haveData 为 true，否则为 false；参数 how 对应当前的操作模式，分为：NOW、ASYNC、SYNC，以及 TIMED，如果是 TIMED 模式，则参数 nanos 用于指定当前等待的纳秒值。\n\n下面进一步介绍一下 how 参数，我们知道 LinkedTransferQueue 的队列操作方法基本上都是直接委托给 `LinkedTransferQueue#xfer` 方法执行，而参数 how 则用于控制在不同调用场景下该方法的运行逻辑。LinkedTransferQueue 定义了 4 个 int 类型常量，分别表示不同的操作模式，如下：\n\n```java\nprivate static final int NOW = 0;   // for untimed poll, tryTransfer\nprivate static final int ASYNC = 1; // for offer, put, add\nprivate static final int SYNC = 2;  // for transfer, take\nprivate static final int TIMED = 3; // for timed poll, tryTransfer\n```\n\n针对各个模式的含义说明如下：\n\n- __NOW__ ：当队列中没有匹配的结点时立即返回而不等待，例如当生产者执行入队列操作时，如果队列中没有正在等待的消费者则立即返回。\n- __ASYNC__ ：当队列中没有匹配的结点时将元素入队列，但是当前线程本身并不等待而是立即返回，主要用于入队列操作。\n- __SYNC__ ：当队列中没有匹配的结点时将元素入队列，并且当前线程会依附在对应结点上无限期等待。\n- __TIMED__ ：当队列中没有匹配的结点时将元素入队列，并且当前线程会依附在对应结点上超时等待。\n\nLinkedTransferQueue 实现的主要入队列和出队列方法在委托执行 `LinkedTransferQueue#xfer` 方法时的参数值设置如下表：\n\n方法 | e | haveData | how | nanos\n--- | --- | --- | --- | ---\n`LinkedTransferQueue#put` | e | true | ASYNC | 0\n`LinkedTransferQueue#add` |e | true | ASYNC | 0\n`LinkedTransferQueue#offer(E)` | e | true | ASYNC | 0\n`LinkedTransferQueue#offer(E, long, TimeUnit)` | e | true | ASYNC | 0\n`LinkedTransferQueue#take` | null | false | SYNC | 0\n`LinkedTransferQueue#poll()` | null | false | NOW | 0\n`LinkedTransferQueue#poll(long, TimeUnit)` | null | false | TIMED | timeout\n`LinkedTransferQueue#transfer` | e | true | SYNC | 0\n`LinkedTransferQueue#tryTransfer(E)` | e | true | NOW | 0\n`LinkedTransferQueue#tryTransfer(E, long, TimeUnit)` | e | true | TIMED | timeout\n\n下面开始分析方法 `LinkedTransferQueue#xfer` 的实现，如下：\n\n```java\nprivate E xfer(E e, boolean haveData, int how, long nanos) {\n    // 如果是入队列操作，则不允许待添加元素值为 null\n    if (haveData && (e == null)) {\n        throw new NullPointerException();\n    }\n\n    // the node to append, if needed\n    Node s = null;\n\n    retry:\n    for (; ; ) {                                  // restart on append race\n\n        /* 1. Try to match an existing node */\n\n        // 从头开始遍历队列，对第一个未匹配的结点执行匹配操作\n        for (Node h = head, p = h; p != null; ) { // find & match first node\n            boolean isData = p.isData;\n            Object item = p.item;\n            // 找到第一个未匹配且未被取消的结点\n            if (item != p && (item != null) == isData) { // unmatched\n                // 结点模式与本次操作模式一致，无法匹配，退出循环并进入下一步\n                if (isData == haveData) {  // can't match\n                    break;\n                }\n                // 模式互补，执行匹配操作，将匹配结点 p 的 item 值修改为 e\n                // 如果 item 为 null，则 e 为 data，如果 item 为 data，则 e 为 null\n                if (p.casItem(item, e)) { // 匹配成功\n                    // 如果当前被匹配的结点不是 head 结点，需要更新 head 指针，保证松弛度小于 2\n                    for (Node q = p; q != h; ) {\n                        Node n = q.next;  // update by 2 unless singleton\n                        // 更新 head 为匹配结点 p 的 next 结点，如果 next 结点为 null 则更新为当前匹配结点\n                        if (head == h && this.casHead(h, n == null ? q : n)) {\n                            // 将之前的 head 结点自引用，等待 GC\n                            h.forgetNext();\n                            break;\n                        }\n                        // 如果松弛度（slack）小于 2，则退出循环，否则继续循环后移 head 指针\n                        if ((h = head) == null || (q = h.next) == null || !q.isMatched()) {\n                            break;        // unless slack < 2\n                        }\n                    }\n                    // 唤醒在刚刚完成匹配结点上等待的线程\n                    LockSupport.unpark(p.waiter);\n                    return cast(item);\n                }\n            }\n            // 结点已被其它线程匹配，继续往后遍历寻找下一个可匹配结点\n            Node n = p.next;\n            p = (p != n) ? n : (h = head); // 如果 p 已经脱离队列，则从 head 开始寻找\n        } // end of for\n\n        // 未找到可以匹配的结点，将当前结点添加到队列末端\n        if (how != NOW) {      // 上游函数不期望立即返回\n            if (s == null) {\n                s = new Node(e, haveData);\n            }\n\n            /* 2. Try to append a new node */\n\n            // 将结点 s 添加到队列末端，如果成功则返回 s 的前驱结点\n            Node pred = this.tryAppend(s, haveData);\n            // 返回 null 说明结点 s 入队列失败，重试\n            if (pred == null) {\n                continue retry; // lost race vs opposite mode\n            }\n            // 阻塞（或自旋）等待匹配\n            if (how != ASYNC) {\n\n                /* 3. Await match or cancellation */\n\n                return this.awaitMatch(s, pred, e, (how == TIMED), nanos);\n            }\n        }\n        return e;              // not waiting\n    }\n}\n```\n\n由上述实现可以看出，整个 `LinkedTransferQueue#xfer` 方法的执行分为 3 个阶段（已在代码中标出），针对各个阶段的说明作者在文档中已经给出了概述，这里直接摘录作者的原话：\n\n1. Try to match an existing node;\n2. Try to append a new node;\n3. Await match or cancellation.\n\n也就是说当一个线程进入 `LinkedTransferQueue#xfer` 方法时，第 1 步会尝试在队列中寻找可以匹配的结点，如果存在则执行匹配操作；否则如果上游方法不期望立即返回（即不为 NOW 操作模式）则执行第 2 步，将当前元素添加到队列中；如果上游方法允许当前线程等待（即不为 ASYNC 操作模式），则进入等待状态，也就是第 3 步。\n\n下面我们分步骤对这 3 个阶段逐一进行分析，首先来看 __步骤 1__ ，作者对这一步的详细概述摘录如下：\n\n> __Try to match an existing node__\n>\n> Starting at head, skip already-matched nodes until finding an unmatched node of opposite mode, if one exists, in which case matching it and returning, also if necessary updating head to one past the matched node (or the node itself if the list has no other unmatched nodes). If the CAS misses, then a loop retries advancing head by two steps until either success or the slack is at most two. By requiring that each attempt advances head by two (if applicable), we ensure that the slack does not grow without bound. Traversals also check if the initial head is now off-list, in which case they start at the new head.\n>\n> If no candidates are found and the call was untimed poll/offer, (argument \"how\" is NOW) return.\n\n这一步的核心逻辑在于从队列中寻找可以匹配的结点，并执行匹配操作，具体执行流程概括为：\n\n1. 从队列头部开始遍历队列，寻找第一个未被取消且未被匹配的结点 p，如果存在则进入匹配进程；\n2. 校验结点 p 的模式是否与当前操作模式互补，如果相同则无法匹配，需要转而执行步骤 2，将当前结点添加到队列末端；\n3. 否则，基于 CAS 修改结点 p 的 item 值（如果是请求结点，则更新 item 为元素值 e；如果是数据结点，则更新 item 为 null），即执行匹配操作；\n4. 如果匹配失败，则说明存在其它线程先于完成了匹配操作，继续往后寻找下一个可以匹配的结点；\n5. 如果匹配成功，则尝试后移 head 指针，保证 head 结点的松弛度小于 2，并唤醒在匹配结点上阻塞的线程，最后返回本次匹配结点的 item 值。\n\n下面利用图示演示上述执行流程，其中黄色表示消费者结点，青色表示生产者结点（M 表示已匹配，U 表示未匹配），红色表示当前匹配结点。假设当前操作是一个消费者线程，则从队列头部开始往后寻找第一个未被取消且未被匹配的结点，此时各指针的指向如下图 1 所示。在执行完几轮循环之后，当前线程在队列上找到了第一个可以匹配的结点 p，如下图 2 所示。然后执行匹配操作，基于 CAS 尝试将待匹配结点 p 的 item 值修改为 null，如下图 3 所示。\n\n![image](/images/2018/juc-linked-transfer-queue-xfer-1.png)\n\n接下来线程会进入最内侧 for 循环，尝试后移 head 指针，以保证 head 结点的松弛度小于 2，如果期间正好有另外一个线程更新了 head 指针的指向，此时各指针的指向如上图 4 所示。此时 head 指针与 h 指针指向不同，所以继续执行最内侧 for 循环的第二个 if 判断，执行完后各个指针的指向如上图 5 所示。此时因为指针 q 所指向的结点已经完成匹配，所以继续进入下一轮最内侧 for 循环，此时满足最内侧 for 循环的第一个 if 判断，基于 CAS 更新 head 指针，并将之前 head 结点的 next 指针指向自己（自引用），等待 GC 回收，如上图 6 所示。最后唤醒在本次匹配结点上等待的线程，并返回。\n\n如果上述步骤没有找到可以匹配的结点，则尝试为当前元素构造一个新的结点并插入到队列中，即执行 __步骤 2__ ，作者对这一步的详细概述摘录如下：\n\n> __Try to append a new node__\n>\n> Starting at current tail pointer, find the actual last node and try to append a new node (or if head was null, establish the first node). Nodes can be appended only if their predecessors are either already matched or are of the same mode. If we detect otherwise, then a new node with opposite mode must have been appended during traversal, so we must restart at phase 1. The traversal and update steps are otherwise similar to phase 1: Retrying upon CAS misses and checking for staleness. In particular, if a self-link is encountered, then we can safely jump to a node on the list by continuing the traversal at current head.\n>\n> On successful append, if the call was ASYNC, return.\n\n如果当前操作模式为 NOW，则说明上游方法要求当队列中不存在可以匹配的结点时立即返回，则不执行本步骤，否则执行 `LinkedTransferQueue#tryAppend` 方法尝试将当前结点 s 入队列。该方法在执行失败的情况下会返回 null，否则返回新添加结点 s 的前驱结点，如果没有前驱结点则返回结点 s 自己。\n\n方法 `LinkedTransferQueue#tryAppend` 的实现如下：\n\n```java\nprivate Node tryAppend(Node s, boolean haveData) {\n    // 尝试将结点 s 入队列\n    for (Node t = tail, p = t; ; ) {           // move p to last node and append\n        Node n, u;                             // temps for reads of next & tail\n        // 当前队列为空\n        if (p == null && (p = head) == null) { // 1\n            // 直接将结点 s 设置为 head，并返回 s 结点\n            if (this.casHead(null, s)) {\n                return s;                      // initialize\n            }\n        }\n        // 结点 s 不能作为结点 p 的后继结点，因为 p 和 s 的模式互补，且 p 未匹配\n        else if (p.cannotPrecede(haveData)) {  // 2\n            return null;                       // lost race vs opposite mode\n        }\n        // p 已经不是最新的尾结点，更新\n        else if ((n = p.next) != null) {       // 3\n            // not last; keep traversing\n            p = p != t && t != (u = tail) ?\n                    (t = u)                    // stale tail\n                    :\n                    (p != n) ? n : null;       // restart if off list\n        }\n        // 结点 s 入队列失败，说明 p 未指向最新的尾结点\n        else if (!p.casNext(null, s)) {        // 4\n            p = p.next;                        // re-read on CAS failure\n        }\n        // 将结点 s 入队列成功，后移 tail 指针，保证松弛度小于 2\n        else {                                 // 5\n            if (p != t) {                      // update if slack now >= 2\n                while ((tail != t || !this.casTail(t, s)) // 后移 tail 指针\n                        && (t = tail) != null\n                        && (s = t.next) != null // advance and retry\n                        && (s = s.next) != null && s != t) {\n                }\n            }\n            return p;\n        }\n    }\n}\n```\n\n这一步的核心逻辑在于将结点 s 入队列，并在 tail 结点松弛度较大时后移 tail 指针。具体执行流程概括为：\n\n1. 如果队列为空，则直接将结点 s 入队列，并返回结点 s 对象；\n2. 否则，校验结点 s 能否入队列，如果前驱结点与结点 s 模式互补且未匹配，则不能入队列，此时直接返回 null 并退回步骤 1 开始执行；\n3. 如果结点 s 可以入队列，则寻找队列当前真正的 tail 结点，并将结点 s 作为后继结点入队列；\n4. 如果入队列失败，则说明前驱结点不是最新的队列 tail 结点，继续进入下一轮循环重试；\n5. 如果入队列成功，则判断 tail 结点的松弛度是否较大，如果较大则后移 tail 指针，以降低 tail 结点的松弛度。\n\n下面利用图示演示上述执行流程。假设当前操作是一个生产者线程，期望向队列插入一个元素值为 5 的结点，并且队列中存在的都是未匹配的生产者结点，如下图 1 所示。此时队列不为空，且结点 s 可以入队列，此时各指针指向如下图 2 所示。因为结点 p 的 next 结点不为 null，说明 p 未指向最新的 tail 结点，需要后移 p、t 和 n 指针，直到 p 指向 tail 结点，如下图 3、4 和 5 所示。\n\n![image](/images/2018/juc-linked-transfer-queue-xfer-2.png)\n\n接下来执行代码 4，基于 CAS 尝试将 p 结点的 next 结点由 null 更新为 s，即将结点 s 入队列，如上图 6 所示。如果入队列成功，则继续执行代码 5，后移 tail 指针，保证 tail 结点的松弛度小于 2，最后返回结点 s 的前驱结点，如上图 7 和 8 所示。\n\n最后来看 __步骤 3__ ，作者对这一步的详细概述摘录如下：\n\n> __Await match or cancellation__\n>\n> Wait for another thread to match node; instead cancelling if the current thread was interrupted or the wait timed out. On multiprocessors, we use front-of-queue spinning: If a node appears to be the first unmatched node in the queue, it spins a bit before blocking. In either case, before blocking it tries to unsplice any nodes between the current \"head\" and the first unmatched node.\n>\n> Front-of-queue spinning vastly improves performance of heavily contended queues. And so long as it is relatively brief and \"quiet\", spinning does not much impact performance of less-contended queues. During spins threads check their interrupt status and generate a thread-local random number to decide to occasionally perform a Thread.yield. While yield has underdefined specs, we assume that it might help, and will not hurt, in limiting impact of spinning on busy systems. We also use smaller (1/2) spins for nodes that are not known to be front but whose predecessors have not blocked -- these \"chained\" spins avoid artifacts of front-of-queue rules which otherwise lead to alternating nodes spinning vs blocking. Further, front threads that represent phase changes (from data to request node or vice versa) compared to their predecessors receive additional chained spins, reflecting longer paths typically required to unblock threads during phase changes.\n\n如果当前操作模式为 ASYNC，则说明上游方法要求线程在完成入队列操作之后不阻塞等待，而是立即返回。对于其它操作模式（除 NOW 和 ASYNC 以外）则需要执行 `LinkedTransferQueue#awaitMatch` 方法让当前线程依附在刚刚入队列的结点上等待。如果是 TIMED 操作模式，则执行超时等待，否则执行无限期等待，期间支持响应中断。\n\n方法 `LinkedTransferQueue#awaitMatch` 实现如下：\n\n```java\nprivate E awaitMatch(Node s, Node pred, E e, boolean timed, long nanos) {\n    // 如果设置超时，则计算到期时间戳\n    final long deadline = timed ? System.nanoTime() + nanos : 0L;\n    Thread w = Thread.currentThread();\n    int spins = -1; // initialized after first item and cancel checks\n    ThreadLocalRandom randomYields = null; // bound if needed\n\n    for (; ; ) {\n        Object item = s.item;\n        // 当前结点已匹配\n        if (item != e) {                  // matched\n            s.forgetContents();           // avoid garbage\n            return cast(item);\n        }\n        // 线程被中断，或者等待超时，则取消\n        if ((w.isInterrupted() || (timed && nanos <= 0))\n                && s.casItem(e, s)) {     // 将结点的 item 指向结点自己，表示取消\n            // 移除结点 s\n            this.unsplice(pred, s);\n            return e;\n        }\n\n        // 初始化自旋次数\n        if (spins < 0) {                  // establish spins at/near front\n            // 依据前驱结点的状态计算当前结点的自旋次数\n            if ((spins = spinsFor(pred, s.isData)) > 0) {\n                randomYields = ThreadLocalRandom.current();\n            }\n        }\n        // 在阻塞之前先自旋几次\n        else if (spins > 0) {             // spin\n            --spins;\n            if (randomYields.nextInt(CHAINED_SPINS) == 0) {\n                // 随机让步\n                Thread.yield();           // occasionally yield\n            }\n        }\n        // 将当前线程对象绑定到 s 结点上\n        else if (s.waiter == null) {\n            s.waiter = w;                 // request unpark then recheck\n        }\n        // 如果设置了超时，则超时等待\n        else if (timed) {\n            nanos = deadline - System.nanoTime();\n            if (nanos > 0L) {\n                LockSupport.parkNanos(this, nanos);\n            }\n        }\n        // 如果未设置超时，则无限期等待\n        else {\n            LockSupport.park(this);\n        }\n    }\n}\n```\n\n可以看到在线程进入阻塞状态之前会先自旋几次，这样主要是为了提升 LinkedTransferQueue 在多核 CPU 上的性能，在入队列和出队列比较频繁的场景下避免线程不必要的阻塞和唤醒操作。上述方法的实现与上一篇介绍 SynchronousQueue 中的 `TransferStack#awaitFulfill` 方法的执行过程基本一致。\n\n### 总结\n\n本文我们分析了 LinkedTransferQueue 的设计与实现，LinkedTransferQueue 本质上是一个阻塞队列，但是相对于阻塞队列而言在阻塞语义上更进了一步，不仅仅在队列为空或已满时会触发线程阻塞，线程甚至会阻塞直到有其它线程取走或填充当前线程的元素值。此外，不同于一般的线程安全队列，LinkedTransferQueue 能够实现线程间的数据传递而无需先将数据入队列。\n\nLinkedTransferQueue 在实现上基于 Dual Queue 数据结构，并基于 CAS 保证线程安全性。作者 [Doug Lea](https://en.wikipedia.org/wiki/Doug_Lea) 描述 LinkedTransferQueue 从功能上来说是 ConcurrentLinkedQueue、SynchronousQueue（公平模式）和 LinkedBlockingQueue 的超集，并且更加实用和高效。\n\n不过尽管如此优秀，网上还是有人质疑 LinkedTransferQueue 存在数据暂失和导致 CPU 爆满的 [bug](http://ifeve.com/buglinkedtransferqueue-bug/)，有兴趣的读者可以进一步研究一下。\n\n### 参考\n\n1. JDK 1.8 源码\n2. [TransferQueue motivation](http://cs.oswego.edu/pipermail/concurrency-interest/2009-February/005888.html)\n3. [Java 7 中的 TransferQueue](http://ifeve.com/java-transfer-queue/)\n4. [LinkedTransferQueue 的数据暂失和 CPU 爆满以及修复](http://ifeve.com/buglinkedtransferqueue-bug/)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：SynchronousQueue","url":"/2018/09/18/java/juc-synchronous-queue/","content":"\n本文我们一起来分析一下 SynchronousQueue 的设计与实现。不同于前面介绍的一系列线程安全队列，SynchronousQueue 从真正意义上来说并不能算是一个队列，而将其理解为一个用于线程之间通信的组件更为恰当。SynchronousQueue 没有容量的概念，一个线程在执行完入队列操作之后，必须等待另外一个线程与之匹配完成出队列后方可继续再次入队列，反之亦然。此外，有别于我们通常理解的队列中的结点只承载元素，SynchronousQueue 中的结点还需要附着对应的操作线程，这些线程在对应的结点上等待被匹配（fulfill）。<!-- more -->\n\nSynchronousQueue 实现自 BlockingQueue 接口，底层基于 [LockSupport 工具类](/2018/08/24/java/juc-aqs/) 实现线程的阻塞和唤醒操作，并依赖 CAS 保证线程安全。在构造 SynchronousQueue 对象时，允许通过参数指定是否启用公平模式。SynchronousQueue 基于 __Dual Stack__ 数据结构实现非公平的线程通信，基于 __Dual Queue__ 数据结构实现公平的线程通信。SynchronousQueue 的公平模式因为减少了线程之间的冲突，在竞争频繁的场景下反而具备更高的性能，而非公平模式能够更好的维持线程局部性（thread locality），减少线程上下文切换的开销。\n\n### SynchronousQueue 示例\n\n本小节我们以“生产者-消费者”示例演示 SynchronousQueue 的基本使用，在示例中我们设置了一个生产者和两个消费者，以展示 SynchronousQueue 公平性特征。示例实现如下（省略了异常处理）：\n\n```java\nprivate static BlockingQueue<Integer> queue = new SynchronousQueue<>(true);\n\nprivate static class Producer implements Runnable {\n\n    @Override\n    public void run() {\n        int count = 0;\n        while (count < 10) {\n            int val = count++;\n            System.out.println(\"Producer produce: \" + val);\n            queue.put(val);\n            TimeUnit.SECONDS.sleep(1);\n        }\n    }\n}\n\nprivate static class Consumer implements Runnable {\n\n    @Override\n    public void run() {\n        while (!Thread.currentThread().isInterrupted()) {\n            System.out.println(\"Consumer \" + Thread.currentThread().getName() + \" consume: \" + queue.take());\n        }\n    }\n}\n\npublic static void main(String[] args) {\n    Thread producer = new Thread(new Producer());\n    Thread consumer1 = new Thread(new Consumer());\n    Thread consumer2 = new Thread(new Consumer());\n    consumer1.setName(\"A\");\n    consumer2.setName(\"B\");\n\n    producer.start();\n    consumer1.start();\n    consumer2.start();\n}\n```\n\n运行输出如下：\n\n```text\nProducer produce: 0\nConsumer A consume: 0\nProducer produce: 1\nConsumer A consume: 1\nProducer produce: 2\nConsumer B consume: 2\nProducer produce: 3\nConsumer A consume: 3\nProducer produce: 4\nConsumer B consume: 4\nProducer produce: 5\nConsumer A consume: 5\nProducer produce: 6\nConsumer B consume: 6\nProducer produce: 7\nConsumer A consume: 7\nProducer produce: 8\nConsumer B consume: 8\nProducer produce: 9\nConsumer A consume: 9\n```\n\n可以看到，当生产者往 SynchronousQueue 中插入一个元素之后，生产者线程会等待消费者完成消费，而消费者线程在完成消费之后会等待生产者生产。SynchronousQueue 的公平性特性尽可能保证了消费者 A 和 B 能够交替执行消费操作。\n\n在上述示例中，如果我们将 Producer 入队列的方法由 put 改为 offer，那么在 Consumer 入队列成功之前，Producer 始终不能入队列成功，这对于一般的队列而言显得有些奇怪。实际上，这里说的不能成功入队列不够准确，要知道 offer 是一类带有超时机制的方法，也就是说当 Producer 在将某个元素执行入队列之后，它希望有一个 Consumer 能够在自己期望的时间内与该元素进行匹配，否则就只能返回 false，从表象上来看就是没有入队列成功。实际应用中我们需要考虑此类表象是否符合自己的业务场景，如果不满足则可以考虑使用 put 方法执行入队列操作。\n\n### 核心方法实现\n\nSynchronousQueue 实现自 BlockingQueue 接口，但并未对接口中声明的方法全部支持，例如 SynchronousQueue 的 `SynchronousQueue#peek` 方法就始终返回 null，在使用时推荐先阅读 API 文档，避免影响程序的正确性。本文主要分析 SynchronousQueue 的实现机制，所以下面重点来看一下 SynchronousQueue 已实现的出队列和入队列操作。\n\n前面我们提及到 SynchronousQueue 内部基于 Dual Stack 和 Dual Queue 数据结构实现，在 SynchronousQueue 中定义了一个 Transferer 抽象类，该类抽象了 Dual Stack 和 Dual Queue 数据结构的实现，定义如下：\n\n```java\nabstract static class Transferer<E> {\n    abstract E transfer(E e, boolean timed, long nanos);\n}\n```\n\nSynchronousQueue 的出队列和入队列操作均委托给 `Transferer#transfer` 方法执行（如下），该方法接收 3 个参数，其中参数 e 表示待添加到队列中的元素值，对于出队列操作来说，e 始终等于 null；参数 timed 用于设置当前操作是否具备超时策略，如果是则需要使用参数 nanos 参数指定超时时间。\n\n- `SynchronousQueue#put(E e)` -> `transferer.transfer(e, false, 0)`\n- `SynchronousQueue#offer(E)` -> `transferer.transfer(e, true, 0)`\n- `SynchronousQueue#offer(E, long, TimeUnit)` -> `transferer.transfer(e, true, unit.toNanos(timeout))`\n- `SynchronousQueue#take` -> `transferer.transfer(null, false, 0)`\n- `SynchronousQueue#poll()` -> `transferer.transfer(null, true, 0)`\n- `SynchronousQueue#poll(long, TimeUnit)` -> `transferer.transfer(null, true, unit.toNanos(timeout))`\n\n针对 Dual Stack 和 Dual Queue 数据结构，SynchronousQueue 分别定义了 TransferStack 和 TransferQueue 实现类，下面的小节将针对这两个类的实现机制展开分析。\n\n在开始之前，我们先对 __匹配__ 一词在 SynchronousQueue 中的含义进行解释，在下面的章节中将多次提及匹配的概念。我们大致已经了解到 SynchronousQueue 在内部基于栈或队列实现线程间的交互，以“生产者-消费者”为例，如果使用的是栈结构（队列亦如此），当生产者往 SynchronousQueue 中插入一个元素时，该生产者线程在插入成功之后并不会立即返回，而是等待消费者前来消费。当消费者执行消费时发现栈上正好有生产者在等待，于是执行消费逻辑，也称为开始执行匹配（fulfill）进程，将当前消费者与生产者匹配成一对儿纷纷出栈。\n\n#### Dual Stack\n\n针对 Dual Stack 数据结构，SynchronousQueue 实现了 TransferStack 类。TransferStack 继承自 Transferer 抽象类，并定义了 SNode 类描述栈上的结点。针对结点的运行模式，TransferStack 定义了 3 个 int 类型的常量字段予以描述，如下：\n\n1. REQUEST：标识未匹配的消费者结点。\n2. DATA：标识未匹配的生产者结点。\n3. FULFILLING：标识结点正在执行匹配操作。\n\n栈在运行期间要么为空，要么存放着一个或多个未匹配的消费者结点或生产者结点，对应的消费者或生产者线程依附在具体的结点上等待。一个栈上不可能同时共存未匹配的消费者结点和未匹配的生产者结点，也就是说同一时间栈上所有结点的运行模式（即 `SNode#mode` 字段值）都应该是一致的，除了栈顶结点可能会因为正在执行匹配进程而附加 FULFILLING 状态。\n\nSNode 类的字段定义如下：\n\n```java\nstatic final class SNode {\n    /** 后继指针 */\n    volatile SNode next;        // next node in stack\n    /** 记录匹配的结点，如果当前结点被取消，则指向自己 */\n    volatile SNode match;       // the node matched to this\n    /** 在当前结点上等待的线程对象 */\n    volatile Thread waiter;     // to control park/unpark\n    /** 结点元素值，如果是消费者结点则为 null */\n    Object item;                // data; or null for REQUESTs\n    /**\n     * 结点运行模式：\n     * - 0：代表消费者结点\n     * - 1：代表生产者结点\n     * - (2 | 0) or (2 | 1)：代表结点正在或已被匹配\n     */\n    int mode;\n\n    // ... 省略方法实现\n\n}\n```\n\n各字段的含义如代码注释，我们将在下面分析 `TransferStack#transfer` 方法实现时一并分析 SNode 中定义的方法，并对各个字段的含义结合具体场景做进一步介绍。\n\n前面在介绍 Transferer 抽象类时，我们知道该抽象类仅声明了一个方法，即 `Transferer#transfer` 方法，该方法也是整个 SynchronousQueue 中最核心的实现。在开始分析 TransferStack 之于该方法的实现之前，我们先从整体出发，感知一下 TransferStack 的运行流程。\n\n以“生产者-消费者”为例，假设当前有 3 个生产者依次执行往 SynchronousQueue 中插入元素，执行的顺序为 `1 -> 2 -> 3`，则入栈之后得到的栈结构如下：\n\n```text\n 3 -> 2 -> 1 -> null\n ↓\nhead\n```\n\n入栈后的 3 个生产者线程将在栈对应结点上等待。如果来了一个消费者执行出队列操作，此时消费者将与 head 结点上的生产者进行匹配，匹配成功之后得到的栈结构如下：\n\n```text\n 2 -> 1 -> null\n ↓\nhead\n```\n\n此时剩下的生产者线程将继续等待，期间可以允许新的消费者出队列，也可以允许新的生产者入队列。\n\n上述过程就是 `TransferStack#transfer` 方法的核心执行逻辑，对此有了一个大概的感知之后，下面来深入分析 `TransferStack#transfer` 方法的具体实现。实际上在 `TransferStack#transfer` 方法的开头，作者已经对整个方法的运行流程给出了直观的概括，摘录如下：\n\n> 1. If apparently empty or already containing nodes of same mode, try to push node on stack and wait for a match, returning it, or null if cancelled.\n>\n> 2. If apparently containing node of complementary mode, try to push a fulfilling node on to stack, match with corresponding waiting node, pop both from stack, and return matched item. The matching or unlinking might not actually be necessary because of other threads performing action 3:\n>\n> 3. If top of stack already holds another fulfilling node, help it out by doing its match and/or pop operations, and then continue. The code for helping is essentially the same as for fulfilling, except that it doesn't return the item.\n\n方法 `TransferStack#transfer` 实现如下：\n\n```java\nE transfer(E e, boolean timed, long nanos) {\n    SNode s = null; // constructed/reused as needed\n\n    // 操作模式判定，如果为 null 则说明当前是出队列操作，否则说明是入队列操作\n    int mode = (e == null) ? REQUEST : DATA;\n\n    for (; ; ) {\n        SNode h = head;\n        // 1. 如果栈为空，或者包含相同模式的结点，将结点入栈等待匹配\n        if (h == null || h.mode == mode) {   // empty or same-mode\n            // 如果设置超时且到期\n            if (timed && nanos <= 0) {       // can't wait\n                // 如果 head 结点被取消，则后移 head 指针\n                if (h != null && h.isCancelled()) {\n                    this.casHead(h, h.next); // pop cancelled node\n                } else {\n                    // 否则返回 null\n                    return null;\n                }\n            }\n            // 否则，说明当前线程需要在栈上等待，先创建一个结点入栈，之后对应的线程会在该结点上等待\n            else if (this.casHead(h, s = snode(s, e, h, mode))) {\n                // 等待结点被匹配或取消，返回的是与当前结点匹配的结点，或者结点自己（即结点被取消）\n                SNode m = this.awaitFulfill(s, timed, nanos);\n                // 如果返回的是结点自己，则说明是被取消了\n                if (m == s) {               // wait was cancelled\n                    // 清理无效结点\n                    this.clean(s);\n                    return null;\n                }\n\n                /* 当前结点被匹配了 */\n\n                // 与 s 匹配的结点就是 head 结点，将 s 和 m 出栈，这里只是一个优化，不影响程序执行的正确性\n                if ((h = head) != null && h.next == s) {\n                    this.casHead(h, s.next); // help s's fulfiller\n                }\n\n                // 如果是出队列则返回匹配结点的元素值，如果是入队列则返回新添加的结点元素值\n                return (E) ((mode == REQUEST) ? m.item : s.item);\n            }\n        }\n        // 2. 栈中包含互补模式的结点，且 head 结点不处于 FULFILLING 状态，执行匹配操作\n        else if (!isFulfilling(h.mode)) {  // try to fulfill\n            // 头结点已经被取消，则后移 head 指针后重试\n            if (h.isCancelled()) {         // already cancelled\n                this.casHead(h, h.next);   // pop and retry\n            }\n            // 入队一个带有 FULFILLING 标志的新结点 s，同一时间栈中最多只有一个带有 FULFILLING 标志的结点，且该结点一定是 head 结点\n            else if (this.casHead(h, s = snode(s, e, h, FULFILLING | mode))) {\n                for (; ; ) {               // loop until matched or waiters disappear\n                    // 获取本次与 s 结点执行匹配的结点，也就是 s 的 next 结点\n                    SNode m = s.next;      // m is s's match\n                    // 如果待匹配的结点为 null，说明已经被其它线程取消\n                    if (m == null) {       // all waiters are gone\n                        // 将结点 s 出队列，并退出循环\n                        this.casHead(s, null);   // pop fulfill node\n                        s = null;                // use new node next time\n                        break;                   // restart main loop\n                    }\n                    // 如果待匹配的结点不为 null，则尝试执行匹配\n                    SNode mn = m.next;\n                    if (m.tryMatch(s)) { // 尝试将结点 m 的 match 指针指向结点 s\n                        // 匹配成功，修改头结点为已匹配结点 m 的 next 结点\n                        this.casHead(s, mn);     // pop both s and m\n                        // 如果是出队列则返回已匹配结点的元素值，如果是入队列则返回新添加的结点元素值\n                        return (E) ((mode == REQUEST) ? m.item : s.item);\n                    } else {                // lost match\n                        // 匹配失败，说明结点 m 被取消，继续尝试匹配 m 的 next 结点\n                        s.casNext(m, mn);   // help unlink\n                    }\n                }\n            }\n        }\n        // 3. 栈中包含互补模式的结点，且 head 结点处于 FULFILLING 状态\n        else {                            // help a fulfiller\n            SNode m = h.next;             // m is h's match\n            if (m == null) {              // waiter is gone\n                this.casHead(h, null);    // pop fulfilling node\n            } else {\n                SNode mn = m.next;\n                if (m.tryMatch(h)) {      // help match\n                    this.casHead(h, mn);  // pop both h and m\n                } else {                  // lost match\n                    h.casNext(m, mn);     // help unlink\n                }\n            }\n        }\n    }\n}\n```\n\n上述实现中 for 循环内部的 `if ... else if ... else` 控制结构分别对应作者给出的 3 段注释（已在代码中标出），其中场景 3 主要是对场景 2 的辅助，下面重点分析场景 1 和场景 2 的实现和执行流程。\n\n首先来看一下 __场景 1__ ，此时栈为空，或者栈中等待的线程运行模式与当前线程的运行模式相同，此时需要将结点入栈，并让当前线程在结点上等待。执行流程可以概括为：\n\n1. 如果设置了超时且已经到期，则顺带判断 head 结点是否被取消，如果是则后移 head 指针并进入下一轮循环，否则返回 null；\n2. 否则新建一个包含待添加元素 e 的结点入栈，并执行 `TransferStack#awaitFulfill` 方法让当前线程在该结点上等待匹配（或被取消）；\n3. 如果在等待期间被取消，则清理栈上的无效结点，并返回 null；\n4. 否则说明结点被成功匹配，如果当前线程是消费者线程则返回匹配结点的元素值，如果当前线程是生产者线程则返回刚刚添加的元素值。\n\n下面利用图示演示上述执行流程。假设当前操作线程是一个生产者，期望将元素 3 插入到 SynchronousQueue 中，并且当前栈中已经包含两个处于等待状态的生产者（如下图 1 所示）。因为当前线程与栈中等待的线程模式相同（均为 DATA），所以新建一个元素值为 3 的结点入栈（如下图 2 所示），并让当前线程在结点上等待。\n\n![image](/images/2018/juc-synchronous-queue-ds-transfer-1.png)\n\n继续分析让线程等待的 `TransferStack#awaitFulfill` 方法，线程会阻塞（或自旋）在该方法上等待被匹配，实现如下：\n\n```java\nSNode awaitFulfill(SNode s, boolean timed, long nanos) {\n    // 如果设置了超时，则计算到期时间\n    final long deadline = timed ? System.nanoTime() + nanos : 0L;\n    Thread w = Thread.currentThread();\n    // 计算自旋的次数\n    int spins = (this.shouldSpin(s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0);\n    for (; ; ) {\n        // 从阻塞中醒来，先检查期间是否被中断\n        if (w.isInterrupted()) {\n            // 如果被中断，则将结点的 match 指针指向自己，表示结点被取消\n            s.tryCancel();\n        }\n\n        // 获取与当前结点匹配的结点，要么是结点自己，要么就是某个与之匹配的结点，只要不为 null 就返回\n        SNode m = s.match;\n        if (m != null) {\n            return m;\n        }\n\n        /* 结点未被匹配或取消 */\n\n        // 如果设置了超时且已经到期，则取消结点\n        if (timed) {\n            nanos = deadline - System.nanoTime();\n            if (nanos <= 0L) {\n                s.tryCancel();\n                continue;\n            }\n        }\n\n        // 在阻塞之前先自旋几次，如果 Producer 和 Consumer 之间交互频繁，自旋相对于阻塞性能更高\n        if (spins > 0) {\n            spins = this.shouldSpin(s) ? (spins - 1) : 0;\n        }\n        // 如果结点的 waiter 为空，则设置为当前线程对象\n        else if (s.waiter == null) {\n            s.waiter = w; // establish waiter so can park next iter\n        }\n        // 未设置超时，则无限期等待\n        else if (!timed) {\n            LockSupport.park(this);\n        }\n        // 设置了超时，则超时等待\n        else if (nanos > spinForTimeoutThreshold) {\n            LockSupport.parkNanos(this, nanos);\n        }\n    }\n}\n```\n\n上述方法首先会依据是否设置超时来计算剩余的到期时间和自旋次数，然后执行：\n\n1. 判断等待期间是否被中断，如果是则取消当前结点，即将结点的 match 指针指向自己；\n2. 判断结点的 match 指针是否指向 null，只要不为 null 就说明当前结点被成功匹配或取消（此时 match 指针指向结点自己），返回 match 指针指向的结点；\n3. 否则，说明结点未被匹配或取消，如果设置了超时且已经到期，则取消当前结点，并在下一轮循环中返回；\n4. 在进入阻塞之前，先尝试自旋几次；\n5. 如果自旋几次之后仍然未完成匹配则阻塞等待，依据是否设置超时来决定是无限期等待还是超时等待，并在等待之前判断当前结点上是否有绑定线程，如果未绑定则将当前线程绑定到该结点上。\n\n由上述实现可以看到，等待的线程并没有立即阻塞，而是先尝试自旋了几次，这主要是考虑生产者和消费者频繁交互的情况。这类场景下当生产者执行入队列操作之后马上会有消费者前来执行出队列，此时生产者线程无需被阻塞，只需要自旋几次即被匹配成功，从而避免线程阻塞和唤醒所带来的性能开销。如果生产者和消费者交互并不频繁，因为自旋的次数并不多，所以不会造成太多的 CPU 开销，几乎可以忽略。\n\n如果结点在等待期间被取消，则上述方法会将结点的 match 指针指向自己，后续流程会基于该特征识别被取消的结点，并调用 `TransferStack#clean` 方法执行清理工作，该方法实现如下：\n\n```java\nvoid clean(SNode s) {\n    s.item = null;   // forget item\n    s.waiter = null; // forget thread\n\n    // 寻找 s 的最近一个后继有效（未被取消）结点，作为本次遍历的哨兵（sentinel）结点\n    SNode past = s.next;\n    if (past != null && past.isCancelled()) {\n        past = past.next;\n    }\n\n    // 从头开始遍历，将 head 指针指向第一个有效（未被取消）结点\n    SNode p;\n    while ((p = head) != null && p != past && p.isCancelled()) {\n        this.casHead(p, p.next);\n    }\n\n    // 从当前有效的头结点开始遍历，直到遇到哨兵结点，移除期间遇到的无效结点\n    while (p != null && p != past) {\n        SNode n = p.next;\n        if (n != null && n.isCancelled()) {\n            p.casNext(n, n.next);\n        } else {\n            p = n;\n        }\n    }\n}\n```\n\n清理的过程首先会确立一个哨兵（sentinel）结点，该结点是位于结点 s 之后最近一个有效（未被取消）的结点，然后从栈顶开始遍历清除那些已经被取消的结点。至于为什么需要设置一个哨兵结点，考虑在并发场景下结点 s 可能已经被其它线程移除，设置哨兵结点能够避免对整个栈进行遍历。\n\n接着来看一下 __场景 2__ ，此时栈中正在等待的线程运行模式与当前线程互补（可以简单理解为栈中等待的线程都是生产者，而当前线程是消费者），并且此时没有线程正在执行匹配操作，所以进入匹配进程。本次与当前线程匹配的是 head 结点上的线程，所以首先需要从上至下在栈上找到第一个有效（未被取消）的 head 结点，然后执行：\n\n1. 创建一个结点元素为 e，附加 FULFILLING 标志的结点 s，并将结点入栈；\n2. 获取本次待与 s 匹配的结点 m，如果 m 为 null 则说明栈上已经没有处于等待的结点，需要退出匹配进程并继续判定接下去进入哪个场景；\n3. 否则，调用 `SNode#tryMatch` 方法执行匹配操作；\n4. 如果匹配成功则后移 head 指针，并返回（如果当前线程是消费者线程则返回匹配结点的元素值，如果当前线程是生产者线程则返回刚刚添加的元素值）；\n5. 如果匹配失败，说明结点 m 已经被取消，尝试继续匹配 m 的后继结点。\n\n下面利用图示演示上述执行流程。如下图 1 所示，假设当前操作线程是一个消费者（图中黄色结点），期望对 SynchronousQueue 执行出队列操作，并且当前栈中已经包含两个处于等待状态的生产者（图中青色结点）。因为当前线程与栈中等待的线程模式互补，所以新建一个元素值为 null 的结点入栈（如下图 2 所示），并附加 FULFILLING 标志（图中红色结点）。\n\n![image](/images/2018/juc-synchronous-queue-ds-transfer-2.png)\n\n然后开始执行匹配进程，设置 m 和 mn 指针，如上图 3 所示。在成功执行完 `SNode#tryMatch` 方法之后会将结点 m 的 match 指针指向结点 s，表示结点 m 和 s 匹配成功，如上图 4 所示。\n\n继续来分析一下执行匹配进程的 `SNode#tryMatch` 方法，实现如下：\n\n```java\nboolean tryMatch(SNode s) {\n    // 基于 CAS 将当前结点的 match 字段设置为 s 结点\n    if (match == null && UNSAFE.compareAndSwapObject(this, matchOffset, null, s)) {\n        Thread w = waiter;\n        if (w != null) {    // waiters need at most one unpark\n            waiter = null;\n            // 唤醒阻塞在当前结点上的线程\n            LockSupport.unpark(w);\n        }\n        return true;\n    }\n    return match == s;\n}\n```\n\n匹配的过程核心在于将待匹配结点的 match 指针指向当前操作线程对应的结点。\n\n关于 Dual Stack 的运行机制就介绍这么多，受栈 FILO 特性的约束，基于 Dual Stack 的 SynchronousQueue 始终在栈顶执行入队列和出队列操作，后入队的线程会先被匹配，这也解释了为什么基于 Dual Stack 的 SynchronousQueue 是非公平的。基于 Dual Stack 的 SynchronousQueue 潜在的一个问题是可能导致先入队的线程长期得不到匹配而饥饿，而优点在于能够更好的维持线程局部性（thread locality），减少线程上下文切换的开销。\n\n#### Dual Queue\n\n针对 Dual Queue 数据结构，SynchronousQueue 实现了 TransferQueue 类，TransferQueue 同样继承自 Transferer 抽象类，并定义了 QNode 类描述队列上的结点。TransferQueue 定义了 `TransferQueue#head` 和 `TransferQueue#tail` 指针字段，分别指向队列的头结点和尾结点。\n\nQNode 类的字段定义如下：\n\n```java\nstatic final class QNode {\n    /** 后继指针 */\n    volatile QNode next;          // next node in queue\n    /** 结点元素值，如果等于结点自己则说明被取消 */\n    volatile Object item;         // CAS'ed to or from null\n    /** 在当前结点上等待的线程对象 */\n    volatile Thread waiter;       // to control park/unpark\n    /** 标识当前是消费者结点，还是生产者结点 */\n    final boolean isData;\n\n    // ... 省略方法定义\n\n}\n```\n\n各字段的含义如代码注释，其中 `QNode#isData` 字段用于标识对应结点是生产者结点还是消费者结点。不同于 TransferStack 的 SNode 需要使用 `SNode#mode` 字段描述结点是未匹配的生产者、未匹配的消费者，或者是正在匹配中等状态，TransferQueue 因为出队列和入队列分别在 head 和 tail 结点上执行，所以无需定义专门的字段描述结点的运行模式。我们将在下面分析 `TransferQueue#transfer` 方法实现时一并分析 QNode 中定义的方法，并对各个字段的含义结合具体场景做进一步介绍。\n\n在开始分析 TransferQueue 之于 `Transferer#transfer` 方法的实现之前，我们还是先从整体出发，感知一下 TransferQueue 的运行流程。同样以“生产者-消费者”为例，假设当前有 3 个生产者依次执行往 SynchronousQueue 中插入元素，执行的顺序为 `1 -> 2 -> 3`，则入队列之后得到的队列结构如下：\n\n```text\n 1 -> 2 -> 3 -> null\n ↓         ↓\nhead      tail\n```\n\n入队列后的 3 个生产者线程将在队列对应结点上等待。如果来了一个消费者执行出队列操作，此时消费者将与 head 结点上的生产者进行匹配，匹配成功之后得到的队列结构如下：\n\n```text\n 2 -> 3 -> null\n ↓    ↓\nhead tail\n```\n\n此时剩下的生产者线程将继续等待，期间可以允许新的消费者出队列，也可以允许新的生产者入队列。\n\n上述过程就是 `TransferQueue#transfer` 方法的核心执行逻辑，对此有了一个大概的感知之后，下面来深入分析 `TransferQueue#transfer` 方法的具体实现。实际上在 `TransferQueue#transfer` 方法的开头，作者同样已经对整个方法的运行流程给出了直观的概括，摘录如下：\n\n> 1. If queue apparently empty or holding same-mode nodes, try to add node to queue of waiters, wait to be fulfilled (or cancelled) and return matching item.\n>\n> 2. If queue apparently contains waiting items, and this call is of complementary mode, try to fulfill by CAS'ing item field of waiting node and dequeuing it, and then returning matching item.\n\n方法 `TransferQueue#transfer` 实现如下：\n\n```java\nE transfer(E e, boolean timed, long nanos) {\n    QNode s = null;                         // constructed/reused as needed\n    // 标识当前是生产模式还是消费模式\n    boolean isData = (e != null);\n\n    for (; ; ) {\n        QNode t = tail;\n        QNode h = head;\n        if (t == null || h == null) {       // saw uninitialized value\n            continue;                       // spin\n        }\n\n        // 1. 队列为空，或者包含相同模式的结点，将结点入队列等待匹配\n        if (h == t || t.isData == isData) { // empty or same-mode\n            QNode tn = t.next;\n            // 期间有其它线程入队列，进入下一轮循环重新获取 tail\n            if (t != tail) {                // inconsistent read\n                continue;\n            }\n            // t 不是队列尾结点，尝试后移 tail 指针\n            if (tn != null) {               // lagging tail\n                this.advanceTail(t, tn);\n                continue;\n            }\n            // 设置超时且已到期，则返回 null\n            if (timed && nanos <= 0) {      // can't wait\n                return null;\n            }\n            if (s == null) {\n                s = new QNode(e, isData);\n            }\n            // 基于 CAS 将结点 s 添加到队列末端\n            if (!t.casNext(null, s)) {      // failed to link in\n                // 添加失败则重试\n                continue;\n            }\n\n            /* 将 s 结点入队列成功 */\n\n            // 后移 tail 指针\n            this.advanceTail(t, s);         // swing tail and wait\n            // 等待结点被匹配或取消，返回已匹配的结点元素值，或者结点自己（表示已取消）\n            Object x = this.awaitFulfill(s, e, timed, nanos);\n            // 结点已经被取消\n            if (x == s) {                   // wait was cancelled\n                // 执行清理工作\n                this.clean(t, s);\n                return null;\n            }\n\n            /* 结点被匹配 */\n\n            // 结点 s 的 next 指针未指向自己，表示结点 s 未出队列\n            if (!s.isOffList()) {           // not already unlinked\n                // t 当前是 s 的前驱结点，也是当前的 head 结点，\n                // 因为 s 已经匹配，说明 s 前面的结点都已经被匹配\n                this.advanceHead(t, s);     // unlink if head\n                // 将 s 的 item 指向自己，说明结点被取消\n                if (x != null) {            // and forget fields\n                    s.item = s;\n                }\n                s.waiter = null;\n            }\n            // 如果是出队列则返回匹配结点的元素值，如果是入队列则返回新添加的结点元素值\n            return (x != null) ? (E) x : e;\n        }\n        // 2. 队列中存在互补模式的结点\n        else {                             // complementary-mode\n            QNode m = h.next;              // node to fulfill\n            // 期间有入队或出队操作，或者待匹配的结点 m 为 null，则进入下一轮循环\n            if (t != tail || m == null || h != head) {\n                continue;                  // inconsistent read\n            }\n\n            // 获取结点 m 的元素值\n            Object x = m.item;\n            // 如果 isData = true，则说明当前操作线程为生产者，期望 m 为消费者，即 x == null\n            // 如果 isData = false，则说明当前操作线程为消费者，期望 m 为生产者，即 x != null\n            if (isData == (x != null)      // m already fulfilled\n                    // 结点 m 已经被取消\n                    || x == m              // m cancelled\n                    // 尝试修改结点 m 的元素值为 e 失败\n                    || !m.casItem(x, e)) { // lost CAS\n                // 结点 m 已经被匹配，或被取消，或已经被其它线程匹配，则后移 head 指针继续\n                this.advanceHead(h, m);    // dequeue and retry\n                continue;\n            }\n\n            // 匹配成功，后移 head 指针\n            this.advanceHead(h, m);        // successfully fulfilled\n            // 唤醒阻塞在匹配结点 m 上的线程\n            LockSupport.unpark(m.waiter);\n            // 如果是出队列则返回匹配结点的元素值，如果是入队列则返回新添加的结点元素值\n            return (x != null) ? (E) x : e;\n        }\n    }\n}\n```\n\n上述实现中 for 循环内部的 `if ... else` 控制结构分别对应作者给出的 2 段注释（已在代码中标出），在 for 循环的一开始会判断 head 或 tail 指针是否为 null，但是在 SynchronousQueue 运行期间正常是不会出现 head 或 tail 指针为 null 的情况，作者在注释中给出的解释如下：\n\n> The loop starts off with a null check guarding against seeing uninitialized head or tail values. This never happens in current SynchronousQueue, but could if callers held non-volatile/final ref to the transferer. The check is here anyway because it places null checks at top of loop, which is usually faster than having them implicitly interspersed.\n\n下面展开分析场景 1 和场景 2 的实现和执行流程。首先来看一下 __场景 1__ ，此时队列为空，或者队列中等待的线程运行模式与当前线程的运行模式相同，此时需要将结点入队列，并让当前线程在结点上等待。执行流程可以概括为：\n\n1. 因为要入队列操作，所以要保证 tail 指向队列真正的尾结点；\n2. 如果设置了超时且已到期，则返回 null；\n3. 否则新建一个包含待添加元素 e 的结点入队列，如果失败进入下一轮循环重试，否则后移 tail 指针并调用 `TransferQueue#awaitFulfill` 方法让当前线程在该结点上等待匹配（或被取消）；\n4. 如果在等待期间被取消，则清理队列上的无效结点，并返回 null；\n5. 否则说明结点被成功匹配，更新 head 指针，如果当前线程是消费者线程则返回匹配结点的元素值，如果当前线程是生产者线程则返回刚刚添加的元素值。\n\n下面利用图示演示上述执行流程。假设当前操作线程是一个生产者，期望将元素 3 插入到 SynchronousQueue 中，并且当前栈中已经包含了两个处于等待状态的生产者（如下图 1 所示）。因为当前线程与队列中等待的线程模式相同（即 `isData=true`），所以新建一个元素值为 3 的结点入队列（如下图 2 所示），并让当前线程在结点上等待。\n\n![image](/images/2018/juc-synchronous-queue-dq-transfer-1.png)\n\nTransferQueue 实现的让线程等待的方法 `TransferQueue#awaitFulfill` 与 TransferStack 中实现的 `TransferStack#awaitFulfill` 方法在设计和实现思路上相同，这里不再重复介绍。下面来分析一下执行清理工作的 `TransferQueue#clean` 方法，实现如下（其中 s 是待清理的结点，pred 是 s 的前驱结点）：\n\n```java\nvoid clean(QNode pred, QNode s) {\n    s.waiter = null; // forget thread\n    while (pred.next == s) { // Return early if already unlinked\n        QNode h = head;\n        QNode hn = h.next;   // Absorb cancelled first node as head\n        // 从头开始，将 head 指针指向有效（未被取消）的头结点\n        if (hn != null && hn.isCancelled()) {\n            this.advanceHead(h, hn);\n            continue;\n        }\n        QNode t = tail;      // Ensure consistent read for tail\n        // 队列已经为空，返回\n        if (t == h) {\n            return;\n        }\n        QNode tn = t.next;\n        // t 不是最新的 tail 结点\n        if (t != tail) {\n            continue;\n        }\n        // tail 指针未指向最新的尾结点\n        if (tn != null) {\n            this.advanceTail(t, tn);\n            continue;\n        }\n        // 如果待删除的 s 结点不是 tail 结点，直接清理\n        if (s != t) {        // If not tail, try to unsplice\n            QNode sn = s.next;\n            if (sn == s || pred.casNext(s, sn)) {\n                return;\n            }\n        }\n\n        /* 当前待删除的 s 结点是 tail 结点 */\n\n        QNode dp = cleanMe;\n        // cleanMe 非空，此时该 cleanMe 的 next 指针一定不是 tail 结点，清理 cleanMe.next\n        if (dp != null) {      // Try unlinking previous cancelled node\n            QNode d = dp.next; // d 是需要清理的结点\n            QNode dn;          // d 的 next 结点\n            if (d == null      // d is gone or\n                    || d == dp // d is off list or\n                    || !d.isCancelled() // d not cancelled or\n                    || (d != t // d not tail and\n                    && (dn = d.next) != null  //   has successor\n                    && dn != d // that is on list\n                    && dp.casNext(d, dn))) { // d unspliced\n                // 将 cleanMe 设置为 null\n                this.casCleanMe(dp, null);\n            }\n            if (dp == pred) {\n                return;      // s is already saved node\n            }\n        }\n        // cleanMe 为空，需要将 s 结点的 pred 标记为 cleanMe，以后再清理 s 结点\n        else if (this.casCleanMe(null, pred)) {\n            return;          // Postpone cleaning s\n        }\n    }\n}\n```\n\n如果待删除结点 s 不是 tail 结点，则只需要简单移除 s 即可，否则暂时不能移除 s 结点，会导致 tail 为 null，影响后续入队列操作。针对这种场景，作者设计了一个 cleanMe 结点，该结点的 next 指针指向需要被移除的 s 结点（此时 s 为 tail 结点），当结点 s 后续不再是 tail 结点时，延后删除。\n\n接着来看一下 __场景 2__ ，此时队列中正在等待的线程运行模式与当前线程互补，所以进入匹配进程。本次与当前线程匹配的是 head 结点的后继结点上的线程，所以首先需要从前往后在队列上找到第一个有效（未被取消）的 head 后继结点，然后执行：\n\n1. 获取 head 结点的后继结点 m；\n2. 如果结点 m 已经被匹配，或被取消，则后移 head 指针后进入下一轮循环重试；\n3. 否则，基于 CAS 尝试将结点 m 的元素值替换为 e，如果失败则说明结点 m 已经被其它线程匹配，继续后移 head 指针后进入下一轮循环重试；\n4. 否则，说明匹配成功，后移 head 指针，并唤醒在匹配结点 m 上等待的线程，如果当前线程是消费者线程则返回匹配结点的元素值，如果当前线程是生产者线程则返回刚刚添加的元素值。\n\n下面利用图示演示上述执行流程。如下图 1 所示，假设当前操作线程是一个消费者（图中黄色结点），期望对 SynchronousQueue 执行出队列操作，并且当前队列中已经包含两个处于等待状态的生产者（图中青色结点）。因为当前线程与队列中等待的线程模式互补，所以获取 head 结点的 next 结点 m 作为待匹配结点（如下图 2 所示）。基于 CAS 尝试将结点 m 的元素值修改为 null，如下图 3 所示，然后后移 head 指针指向 m 结点，并唤醒在结点 m 上等待的线程，如下图 4 所示。\n\n![image](/images/2018/juc-synchronous-queue-dq-transfer-2.png)\n\n关于 Dual Queue 的运行机制就介绍这么多，受队列 FIFO 特性的约束，基于 Dual Queue 的 SynchronousQueue 在队头执行出队列操作，并在队尾执行入队列操作，先入队的线程通常会先被匹配，这也解释了为什么基于 Dual Queue 的 SynchronousQueue 是公平的。基于 Dual Queue 的 SynchronousQueue 因为入队和出队的冲突相对较小，所以在竞争频繁的场景下相对于非公平模式反而具有更好的性能。\n\n### 总结\n\n本文我们分析了 SynchronousQueue 的设计与实现，相对于之前文章中介绍的一系列线程安全队列而言，SynchronousQueue 在实现和使用上有其特别之处。SynchronousQueue 没有容量的概念，入队列的线程在完成入队列操作之后会在队列上等待出队列的线程前来执行出队列操作，反之亦然。SynchronousQueue 中的结点除了承载结点元素之外，还附着着相应的操作线程，这些线程在对应的结点上等待被匹配。此外，SynchronousQueue 区分公平和非公平模式，其中公平模式基于 Dual Queue 数据结构实现，非公平模式基于 Dual Stack 数据结构实现。理解 SynchronousQueue 的核心在于理解 Dual Stack 和 Dual Queue 的设计思想。\n\n### 参考\n\n1. JDK 1.8 源码\n2. [Nonblocking Concurrent Data Structureswith Condition Synchronization](http://www.it.uu.se/katalog/aleji304/ConcurrentDS/Non-blocking-Concurrent-Data-Structures-with-Condition-Synchronization)\n3. [SynchronousQueue 的一些理解](https://gist.github.com/ylgrgyq/95782a0c0dbabf54d9999acfa079fe4b)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：DelayQueue","url":"/2018/09/14/java/juc-delay-queue/","content":"\n延迟队列 DelayQueue 用于存放具有过期属性的元素，被添加到 DelayQueue 中的元素只有在到达过期时间之后才会出队列，常用于延迟任务调度。DelayQueue 本质上是一个无界的阻塞队列，底层依赖于优先级队列 PriorityQueue 作为存储结构，并使用 ReentrantLock 锁保证线程安全。<!-- more -->\n\nDelayQueue 的字段定义如下：\n\n```java\npublic class DelayQueue<E extends Delayed> extends AbstractQueue<E> implements BlockingQueue<E> {\n\n    /** 保证线程安全的可重入独占锁 */\n    private final transient ReentrantLock lock = new ReentrantLock();\n\n    /** 底层存储结构，优先级队列 */\n    private final PriorityQueue<E> q = new PriorityQueue<E>();\n\n    /** Leader-Follower 模式，用于记录角色为 leader 的线程对象 */\n    private Thread leader = null;\n\n    /** 因为队列为空，或元素未到期而阻塞的线程 */\n    private final Condition available = lock.newCondition();\n\n    // ... 省略方法定义\n\n}\n```\n\n重点分析一下 `DelayQueue#leader` 字段设置的意图，该字段用于记录当前角色为 leader 的线程对象。当执行出队列操作（`DelayQueue#take` 和 `DelayQueue#poll(long, TimeUnit)` 方法）时，如果 `DelayQueue#leader` 字段为 null，即不存在 leader 线程，且有未到期的延迟元素，则会将当前线程设置成 leader 角色，并等待该元素到期，以减少不必要的等待时间，保证延迟元素能够在到期时及时被响应。\n\n设想如果不这样设计，那么线程在遇到队列中没有到期的延迟元素时应该怎么办呢？可以采取以下 3 种策略：\n\n1. 进入忙循环轮询。\n2. 进入条件队列等待，并稍后由其它线程唤醒。\n3. 先退出当前方法，等待后续再次执行出队列操作。\n\n可以看出，这些策略要么是消耗 CPU 资源，要么就是无法对队列中的元素在到期时及时出队列，而引入 leader 角色正好能够避免了这些问题。在某个线程以 leader 的身份等待优先级最高的延迟元素到期时，其它线程在发现队列中没有到期的元素时会以 follower 角色无限期等待。而在 leader 线程从等待状态退出时，它会主动放弃自己的 leader 角色，并唤醒一个正在处于等待状态的 follower 线程，该线程将有机会晋升成为新的 leader。\n\n在 leader 线程等待期间，有可能会插入优先级更高的元素，这个时候就需要剥夺该线程的 leader 角色，以提供其它线程成为 leader 的机会，继而保证刚刚新插入的元素能够在到期时及时被响应。否则就需要等到当前 leader 线程退出等待状态之后或者有新的线程请求获取元素时才有机会出队列，这样可能存在较大的延迟。\n\n### 核心方法实现\n\nDelayQueue 实现自 BlockingQueue 接口，下面针对核心方法的实现逐一进行分析。不过在开始分析之前，我们先来介绍一下 `java.util.concurrent.Delayed` 接口，DelayQueue 要求添加到其中的元素必须实现该接口。Delayed 接口定义如下：\n\n```java\npublic interface Delayed extends Comparable<Delayed> {\n    long getDelay(TimeUnit unit);\n}\n```\n\n该接口继承自 Comparable 接口，所以添加到 DelayQueue 中的元素都是可比较的。方法 `Delayed#getDelay` 接收一个 TimeUnit 类型的单位值，用于返回当前延迟元素的剩余到期时间，如果小于等于 0 则说明该元素已经到期。\n\n#### 添加元素：offer & add & put\n\n针对添加元素的操作，DelayQueue 实现了 `DelayQueue#offer`、`DelayQueue#add` 和 `DelayQueue#put` 方法，不过后两者都是直接调用了 `DelayQueue#offer` 方法。\n\n此外，该方法的超时版本 `DelayQueue#offer(E, long, TimeUnit)` 也是直接委托给 `DelayQueue#offer` 方法执行，并没有真正实现超时等待机制。这主要是因为 DelayQueue 是无界的，所有的添加操作都能够被立即响应，而不会阻塞。\n\n下面展开分析一下 `DelayQueue#offer` 方法的实现，如下：\n\n```java\npublic boolean offer(E e) {\n    final ReentrantLock lock = this.lock;\n    // 加锁\n    lock.lock();\n    try {\n        // 往队列中添加元素\n        q.offer(e);\n        // 当前添加的元素是队列中最先过期的\n        if (q.peek() == e) {\n            // 清空 leader，保证该元素能够及时出队列\n            leader = null;\n            // 唤醒因元素均为到期或队列为空而等待的线程\n            available.signal();\n        }\n        return true;\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n}\n```\n\nDelayQueue 不允许向其中添加值为 null 的元素，这主要由优先级队列 PriorityQueue 保证。如果待添加的元素值合法，则执行：\n\n1. 加锁，保证同一时间只有一个线程在操作队列；\n2. 将待添加元素插入到 DelayQueue 中；\n3. 检查 DelayQueue 中优先级最高的的元素是否是刚刚新加入的元素；\n4. 如果是则剥夺当前 leader 线程的 leader 角色，并唤醒一个之前因为队列中的元素均未到期或队列为空而等待的线程；\n5. 释放锁并返回。\n\n为什么当队列中插入了一个优先级最高的元素时需要剥夺当前 leader 线程的 leader 角色，并唤醒一个处于等待的 follower 线程呢？\n\n其实在前面也有所提及，假设现在 DelayQueue 中最先过期的元素还有 10 秒到期，则 leader 线程会等待 10 秒后再次尝试出队列，其它 follower 线程因为检测到当前已有线程成为 leader，所以在发现没有已到期的元素时会等待。假设现在有一个还有 5 秒到期的元素插入了进来，如果在该元素到期之后没有新的线程来请求出队列，则该元素将不能及时被响应，直到 leader 线程退出等待，即使此时有相当数量的 follower 线程在等待元素到期。\n\n#### 获取元素：poll & peek & take\n\n针对获取元素的操作，DelayQueue 实现了 `DelayQueue#poll`、`DelayQueue#peek` 和 `DelayQueue#take` 方法。其中 `DelayQueue#peek` 方法在获取到锁的基础上直接调用了 `PriorityQueue#peek` 方法，仅获取 DelayQueue 中最先到期的元素（获取时可能还未到期），而不移除该元素，实现上比较简单。\n\n方法 `DelayQueue#take` 相对于 `DelayQueue#poll` 的区别在于，当队列为空或没有到期的元素时该方法会无限期阻塞，直到有元素到期或该线程被中断，而 `DelayQueue#poll` 方法在相同场景下则会立即返回 null。\n\n下面分别展开分析这两个方法的实现，首先来看一下 `DelayQueue#poll` 方法，实现如下：\n\n```java\npublic E poll() {\n    final ReentrantLock lock = this.lock;\n    // 获取锁\n    lock.lock();\n    try {\n        // 获取队列中最先过期的元素\n        E first = q.peek();\n        // 队列为空，或者元素还未到期，立即返回 null\n        if (first == null || first.getDelay(NANOSECONDS) > 0) {\n            return null;\n        }\n        // 当前元素已过期，移除并返回\n        else {\n            return q.poll();\n        }\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n}\n```\n\n上述方法会检查 DelayQueue 中是否有已经到期的元素，如果有则将该元素出队列并返回，否则，如果队列为空或没有已经到期的元素，则立即返回 null。针对 `DelayQueue#poll` 方法，DelayQueue 还提供了超时版本 `DelayQueue#poll(long, TimeUnit)`，当队列为空或没有已经到期的元素时等待指定时间。\n\n再来看一下 `DelayQueue#take` 方法的实现，如下：\n\n```java\npublic E take() throws InterruptedException {\n    final ReentrantLock lock = this.lock;\n    // 获取锁，支持响应中断\n    lock.lockInterruptibly();\n    try {\n        for (; ; ) {\n            // 获取最先过期的元素\n            E first = q.peek();\n            // 队列为空，则等待\n            if (first == null) {\n                available.await();\n            }\n            // 队列非空\n            else {\n                // 如果当前元素已经过期，则出队列\n                long delay = first.getDelay(NANOSECONDS);\n                if (delay <= 0) {\n                    return q.poll();\n                }\n\n                /* 当前元素还未过期 */\n\n                first = null; // don't retain ref while waiting\n\n                // 已经有其它线程成为 leader，则等待\n                if (leader != null) {\n                    available.await();\n                }\n                // 没有 leader 线程，将自己设置为 leader 角色\n                else {\n                    Thread thisThread = Thread.currentThread();\n                    leader = thisThread;\n                    try {\n                        // 等待 delay 纳秒\n                        available.awaitNanos(delay);\n                    } finally {\n                        // 如果等待期间自己的 leader 角色未被剥夺，则在等待完成之后主动放弃\n                        if (leader == thisThread) {\n                            leader = null;\n                        }\n                    }\n                }\n            }\n        }\n    } finally {\n        // 如果队列不为空，则唤醒一个之前因为队列为空而等待的线程\n        if (leader == null && q.peek() != null) {\n            available.signal();\n        }\n        // 释放锁\n        lock.unlock();\n    }\n}\n```\n\n方法 `DelayQueue#take` 在获取到锁之后会先检查队列是否为空，如果为空则等待，否则执行：\n\n1. 如果 DelayQueue 中优先级最高的元素已经到期，则出队列并返回该元素；\n2. 否则，如果当前已经有 leader 线程，则等待；\n3. 如果当前没有 leader 线程，则将自己设置为 leader 角色，并等待队列中优先级最高的元素到期。\n\n如果 DelayQueue 中优先级最高的元素到期，或者等待期间被中断，则当前 leader 线程会主动放弃自己的 leader 角色，以给其它 follower 线程机会。当然在等待期间，当前线程的 leader 角色也可能会被剥夺，前面我们在分析 `DelayQueue#offer` 方法时已经介绍过，当等待期间有其它优先级更高的元素插入进来时，执行插入的线程会剥夺当前 leader 线程的 leader 角色，以便让刚刚插入的优先级更高的元素能够在到期时及时出队列。\n\n在整个 `DelayQueue#take` 方法执行的最后，如果 DelayQueue 非空，且当前没有线程成为 leader，则会唤醒一个之前因为队列为空而阻塞的 follower 线程。这里限制 `leader == null` 主要是防止在有 leader 存在的前提下，被唤醒的线程会因为队列中没有到期的元素而再次等待。\n\n#### 移除元素：remove\n\n针对移除元素的操作，DelayQueue 实现了 `DelayQueue#remove` 方法，并提供了有参和无参的版本，其中无参版本实际上是委托给 `DelayQueue#poll` 方法执行的。下面来分析一下有参版本的实现，如下：\n\n```java\npublic boolean remove(Object o) {\n    final ReentrantLock lock = this.lock;\n    // 加锁\n    lock.lock();\n    try {\n        // 从优先级队列中移除元素\n        return q.remove(o);\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n}\n```\n\nDelayQueue 移除指定元素的操作在获取到锁的前提下，交由 PriorityQueue 执行，实现上比较简单。\n\nDelayQueue 的 `DelayQueue#size` 方法在实现上与 `DelayQueue#remove` 方法思路相同，不再展开。但需要注意的一点是，方法 `DelayQueue#size` 所返回的值并不仅仅包含那些未到期的元素，也可能包含一些已经到期而未被从队列中移除的元素，一种可能是这些元素未被及时响应，另外一种可能就是线程仅获取了元素值，而没有移除对应的结点，例如调用了 `DelayQueue#peek` 方法。\n\n### 总结\n\n本文分析了 DelayQueue 的设计与实现。DelayQueue 相对于前面介绍的队列的特别之处在于引入了时间属性，只有在元素到期时才会被出队列。在实现上，DelayQueue 底层依赖于优先级队列 PriorityQueue 作为存储结构，并基于 ReentrantLock 锁保证线程安全，同时巧妙设计了 Leader-Follower 模式来保证延迟元素在到期时能够及时被响应。\n\n### 参考\n\n1. JDK 1.8 源码\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：PriorityBlockingQueue","url":"/2018/09/13/java/juc-priority-blocking-queue/","content":"\n优先级队列 PriorityQueue 应该是大家都比较熟悉的一个集合组件，本文将要介绍的 PriorityBlockingQueue 是 PriorityQueue 的线程安全版本。PriorityBlockingQueue 底层依赖于数组作为存储结构，最大容量上限是 `Integer.MAX_VALUE - 8`，所以几乎可以将其视为无界的。同 PriorityQueue 一样，PriorityBlockingQueue 同样引入了堆数据结构来编排队列元素的优先级，默认使用最小堆结构。<!-- more -->\n\n此外，由 Blocking 字样我们可以推断出 PriorityBlockingQueue 是一个阻塞队列。PriorityBlockingQueue 实现自 BlockingQueue 接口，并基于 ReentrantLock 锁保证线程安全。不过需要注意的一点是，PriorityBlockingQueue 的阻塞仅针对出队列操作而言，当队列为空时出队列的线程会阻塞等待其它线程往队列中添加新的元素。对于入队列操作来说，因为 PriorityBlockingQueue 定义为无界，所以执行入队列的线程会立即得到响应，如果队列底层数组已满则该线程会尝试对底层数组进行扩容，当底层数据达到容量上限而无法继续扩容时会抛出 OOM 异常。\n\n下面先来了解一下 PriorityBlockingQueue 的字段定义，如下：\n\n```java\npublic class PriorityBlockingQueue<E> extends AbstractQueue<E> implements BlockingQueue<E>, Serializable {\n\n    /** 队列默认初始容量 */\n    private static final int DEFAULT_INITIAL_CAPACITY = 11;\n\n    /**\n     * 队列容量上限\n     *\n     * Some VMs reserve some header words in an array.\n     * Attempts to allocate larger arrays may result in OutOfMemoryError: Requested array size exceeds VM limit\n     */\n    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;\n\n    /**\n     * 存储队列元素的数组，按照最小堆组织\n     *\n     * Priority queue represented as a balanced binary heap:\n     * the two children of queue[n] are queue[2*n+1] and queue[2*(n+1)].\n     * The priority queue is ordered by comparator, or by the elements' natural ordering,\n     * if comparator is null: For each node n in the heap and each descendant d of n, n <= d.\n     * The element with the lowest value is in queue[0], assuming the queue is nonempty.\n     */\n    private transient Object[] queue;\n\n    /** 队列中元素个数 */\n    private transient int size;\n\n    /** 队列元素比较器，如果为 null 则使用元素自带的比较器 */\n    private transient Comparator<? super E> comparator;\n\n    /** 保证队列操作线程安全的可重入独占锁 */\n    private final ReentrantLock lock;\n\n    /** 记录因为队列为空而阻塞的线程 */\n    private final Condition notEmpty;\n\n    /**\n     * 扩容标记位，保证同一时间只有一个线程在扩容队列，状态为 0 或 1：\n     * - 0： 表示当前没有在执行扩容操作\n     * - 1： 表示当前正在执行扩容操作\n     */\n    private transient volatile int allocationSpinLock;\n\n    /** 辅助支持序列化和反序列化 */\n    private PriorityQueue<E> q;\n\n    // ... 省略方法实现\n\n}\n```\n\nPriorityBlockingQueue 默认初始时的底层数组大小设置为 11，并在元素已满时触发扩容操作，字段 `PriorityBlockingQueue#allocationSpinLock` 用于控制同一时间只有一个线程在执行扩容。当某个线程检测到当前底层数组已满时会基于 CAS 操作尝试将该字段值由 0 改为 1，然后开始执行扩容，并在完成之后重置该标记字段。\n\n字段 `PriorityBlockingQueue#comparator` 用于指定元素比较器以判定队列元素的优先级，如果该字段为 null，则 PriorityBlockingQueue 会基于元素自带的比较器排列优先级。对于基本类型而言则参考元素的自然顺序，对于自定义对象来说，需要保证这些对象实现了 `java.lang.Comparable` 接口，否则会抛出 ClassCastException 异常。\n\n### 核心方法实现\n\nPriorityBlockingQueue 实现自 BlockingQueue 接口，下面针对核心方法的实现逐一进行分析。\n\n#### 添加元素：offer & add & put\n\n针对添加元素的操作，PriorityBlockingQueue 实现了 `PriorityBlockingQueue#offer`、`PriorityBlockingQueue#add` 和 `PriorityBlockingQueue#put` 方法，不过后两者都是直接调用了 `PriorityBlockingQueue#offer` 方法。\n\n此外，该方法的超时版本 `PriorityBlockingQueue#offer(E, long, TimeUnit)` 也是直接委托给 `PriorityBlockingQueue#offer` 方法执行，并没有真正实现超时等待机制，这主要是因为 PriorityBlockingQueue 是无界的，所有的添加操作都能够被立即响应，而不会阻塞。\n\n下面展开分析一下 `PriorityBlockingQueue#offer` 方法的实现，如下：\n\n```java\npublic boolean offer(E e) {\n    // 待添加元素不能为 null\n    if (e == null) {\n        throw new NullPointerException();\n    }\n    final ReentrantLock lock = this.lock;\n    // 加锁\n    lock.lock();\n    int n, cap;\n    Object[] array;\n    // 如果队列中的元素个数大于等于队列的容量，则执行扩容操作\n    while ((n = size) >= (cap = (array = queue).length)) {\n        this.tryGrow(array, cap); // 扩容\n    }\n    try {\n        // 将待添加元素插入到堆的合适位置（最小堆）\n        Comparator<? super E> cmp = comparator;\n        if (cmp == null) {\n            siftUpComparable(n, e, array);\n        } else {\n            // 自定义比较器\n            siftUpUsingComparator(n, e, array, cmp);\n        }\n        // 结点计数加 1\n        size = n + 1;\n        // 唤醒一个之前因为队列为空而阻塞的线程\n        notEmpty.signal();\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n    return true;\n}\n```\n\nPriorityBlockingQueue 同样不允许往其中添加 null 元素，如果待添加的元素值合法则执行：\n\n1. 加锁，保证同一时间只有一个线程在操作队列；\n2. 判断队列是否已满，如果是则执行扩容操作；\n3. 将元素基于最小堆数据结构的约束插入到底层数据的合适位置；\n4. 队列结点计数加 1；\n5. 因为当前队列至少包含一个元素，所以尝试唤醒一个之前因为队列为空而阻塞的线程；\n6. 释放锁并返回。\n\n继续来看一下上述步骤中的扩容过程，实现位于 `PriorityBlockingQueue#tryGrow` 方法中，如下：\n\n```java\nprivate void tryGrow(Object[] array, int oldCap) {\n    // 扩容之前，先释放锁，避免扩容期间阻塞其它线程的出队列、入队列操作\n    lock.unlock(); // must release and then re-acquire main lock\n    Object[] newArray = null;\n    if (allocationSpinLock == 0 &&\n            // 基于 CAS 操作将扩容标记位由 0 改为 1\n            UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset, 0, 1)) {\n        try {\n            // 如果当前队列长度小于 64，则扩容为 2(n + 1)，否则扩容为 (1 + 1/2)n\n            int newCap = oldCap + ((oldCap < 64) ? (oldCap + 2) : (oldCap >> 1)); // grow faster if small\n            // 避免队列容量超过允许上限\n            if (newCap - MAX_ARRAY_SIZE > 0) {    // possible overflow\n                int minCap = oldCap + 1;\n                if (minCap < 0 || minCap > MAX_ARRAY_SIZE) {\n                    throw new OutOfMemoryError();\n                }\n                newCap = MAX_ARRAY_SIZE;\n            }\n            if (newCap > oldCap && queue == array) {\n                newArray = new Object[newCap];\n            }\n        } finally {\n            // 重置扩容标记\n            allocationSpinLock = 0;\n        }\n    }\n\n    // 当前线程扩容失败，则让渡其它线程获取锁\n    if (newArray == null) {\n        Thread.yield();\n    }\n\n    // 加锁\n    lock.lock();\n\n    // 替换底层存储为扩容后的数组，并复制元素\n    if (newArray != null && queue == array) {\n        queue = newArray;\n        System.arraycopy(array, 0, newArray, 0, oldCap);\n    }\n}\n```\n\n在开始执行扩容之前，当前线程会释放持有的锁，以避免在扩容期间阻塞其它线程的出队列操作，然后基于 CAS 操作修改扩容标记位 `PriorityBlockingQueue#allocationSpinLock`，保证同一时间只有一个线程在执行扩容。一开始数组较小（长度小于 64）时，线程将对底层数组成倍扩容（即 `2(n + 1)`），然后再按照 50% 的比例进行扩容（即 `(1 + 1/2) * n`），如果底层数组已经到达容量上限，则会抛出 OOM 异常。\n\n线程在完成扩容操作之后会重置扩容标记，如果有线程在竞争 CAS 时失败则会尝试让渡其它线程获取锁。这里主要是让渡给成功完成扩容操作的线程，因为此时扩容操作还未真正完成，该线程需要尝试获取锁以继续用扩容后的数组替换当前底层数组。\n\n继续回到 `PriorityBlockingQueue#offer` 方法，如果扩容操作完成或者本次入队列操作无需触发扩容，则接下去线程会将待添加的元素按照最小堆的约束插入到底层数据的合适位置。此时需要区分两种情况，如果在构造 PriorityBlockingQueue 对象时指定了比较器 Comparator，则会调用 `PriorityBlockingQueue#siftUpUsingComparator` 方法基于该比较器执行最小堆插入操作，否则调用 `PriorityBlockingQueue#siftUpComparable` 方法按照元素的自然顺序将当前元素插入到最小堆中。\n\n基于数组实现的堆结构，在操作上是比较简单的，读者可以自行参考源码，本文不对最小堆 `siftUp*` 和 `siftDown*` 操作展开分析。\n\n#### 获取元素：poll & peek & take\n\n前面几篇介绍的队列都满足 FIFO 的特性，在执行出队列时返回的都是在队列中存活时间最长的元素。对于 PriorityBlockingQueue 而言，结点的顺序则按照优先级进行编排，所以这里获取元素的操作返回的是队列中优先级最高的结点。\n\n针对获取元素的操作，PriorityBlockingQueue 实现了 `PriorityBlockingQueue#poll`、`PriorityBlockingQueue#peek` 和 `PriorityBlockingQueue#take` 方法。其中 `PriorityBlockingQueue#peek` 方法仅获取最小堆堆顶结点元素值，而不移除该结点，实现上比较简单。方法 `PriorityBlockingQueue#take` 相对于 `PriorityBlockingQueue#poll` 的区别在于，当队列为空时该方法会无限期阻塞，直到有其它线程往队列中插入新的元素，或者该线程被中断。实现层面，二者大同小异，所以下面以 `PriorityBlockingQueue#poll` 方法为例展开分析从 PriorityBlockingQueue 中获取元素操作的具体实现。\n\nPriorityBlockingQueue 针对 `PriorityBlockingQueue#poll` 方法定义了两个版本，区别在于当队列为空时是立即返回还是阻塞等待一段时间，而在实现思路上是一致的。这里以不带超时参数的版本为例展开分析，实现如下：\n\n```java\npublic E poll() {\n    final ReentrantLock lock = this.lock;\n    // 加锁\n    lock.lock();\n    try {\n        // 出队列，获取最小堆堆顶元素值，并移除堆顶结点，调整最小堆\n        return this.dequeue();\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n}\n\nprivate E dequeue() {\n    int n = size - 1;\n    if (n < 0) {\n        // 当前队列为空，直接返回 null\n        return null;\n    } else {\n        Object[] array = queue;\n        // 获取堆顶元素值\n        E result = (E) array[0];\n        // 调整堆的结构，以便再次满足最小堆定义\n        E x = (E) array[n];\n        array[n] = null;\n        Comparator<? super E> cmp = comparator;\n        if (cmp == null) {\n            siftDownComparable(0, x, array, n);\n        } else {\n            // 自定义比较器\n            siftDownUsingComparator(0, x, array, n, cmp);\n        }\n        // 队列结点计数减 1\n        size = n;\n        return result;\n    }\n}\n```\n\n对于优先级队列而言，出队列操作获取到的是队列中优先级最高的元素，因为底层依赖于最小堆实现，所以只需要移除最小堆堆顶结点，并返回结点元素即可。但是因为这样破坏了堆的结构，所以需要调用 `shiftDown*` 方法从上往下进行调整，以再次满足最小堆结构的约束。\n\n#### 移除元素：remove\n\n针对移除元素的操作，PriorityBlockingQueue 实现了 `PriorityBlockingQueue#remove` 方法，并提供了有参和无参的版本，其中无参版本实际上是委托给 `PriorityBlockingQueue#poll` 方法执行的。下面来分析一下有参版本的实现，如下：\n\n```java\npublic boolean remove(Object o) {\n    final ReentrantLock lock = this.lock;\n    // 加锁\n    lock.lock();\n    try {\n        // 获取待删除元素的数组下标\n        int i = this.indexOf(o);\n        if (i == -1) {\n            // 不存在\n            return false;\n        }\n        // 移除元素\n        this.removeAt(i);\n        return true;\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n}\n\nprivate void removeAt(int i) {\n    Object[] array = queue;\n    int n = size - 1;\n    // 当前移除的是最后一个元素\n    if (n == i) { // removed last element\n        array[i] = null;\n    }\n    // 当前移除的是中间元素\n    else {\n        // 将数组最后一个位置置为 null，并调整堆的结构以满足最小堆定义\n        E moved = (E) array[n];\n        array[n] = null;\n        Comparator<? super E> cmp = comparator;\n        // 自上而下调整堆结构以满足最小堆定义\n        if (cmp == null) {\n            siftDownComparable(i, moved, array, n);\n        } else {\n            siftDownUsingComparator(i, moved, array, n, cmp);\n        }\n        // 自下而上调整堆结构以满足最小堆定义\n        if (array[i] == moved) {\n            if (cmp == null) {\n                siftUpComparable(i, moved, array);\n            } else {\n                siftUpUsingComparator(i, moved, array, cmp);\n            }\n        }\n    }\n    // 队列结点计数减 1\n    size = n;\n}\n```\n\n如果待删除的元素是优先级最低的元素，则只需要将底层数组末尾结点置为 null 即可，否则，对于其它优先级的元素来说，在执行删除之后需要调整堆结构以满足最小堆定义。\n\n#### 其它操作：size & contains\n\n方法 `PriorityBlockingQueue#contains` 接收一个参数，用于判断队列中是否包含值等于参数的结点。\n\n方法 `PriorityBlockingQueue#size` 用于返回当前队列中包含的结点个数，因为 PriorityBlockingQueue 已经定义了 `PriorityBlockingQueue#size` 字段，用于对队列中的结点进行计数，所以该方法只需要返回字段值即可。\n\n### 总结\n\n本文分析了 PriorityBlockingQueue 的设计与实现。PriorityBlockingQueue 是优先级队列 PriorityQueue 的线程安全版本，基于最小堆实现元素的优先级排列。不同于前面几篇我们介绍的队列的 FIFO 特性，PriorityBlockingQueue 出队列的元素并非是在队列中存活时间最长的元素，而是优先级最高的元素。\n\nPriorityBlockingQueue 的底层虽然依赖于数组作为存储结构，但因为容量上限足够大，所以几乎可以视为无界的。当底层数组存满时，PriorityBlockingQueue 并不会让入队列的线程阻塞等待，而是转去扩容底层数组，以继续容纳新的元素。当然，如果容量到达上限，无法继续扩容时，入队列操作会触发 OOM 异常。\n\n### 参考\n\n1. JDK 1.8 源码\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：LinkedBlockingQueue","url":"/2018/09/12/java/juc-linked-blocking-queue/","content":"\n上一篇我们分析了无界非阻塞线程安全队列 ConcurrentLinkedQueue 的设计与实现，本篇我们继续分析线程安全队列 LinkedBlockingQueue 的实现机制。由 Blocking 字样可以推断出 LinkedBlockingQueue 是阻塞队列，前面我们介绍过阻塞队列和非阻塞队列在实现上的区别，知道阻塞队列一般是基于锁机制来保证线程安全，本文我们就一起来分析一下 LinkedBlockingQueue 是如何基于锁构建线程安全队列的。<!-- more -->\n\n同样由 Linked 关键字我们可以推断出 LinkedBlockingQueue 底层依赖于链表实现，在 LinkedBlockingQueue 的内部实现了一个单链表，用以存放队列元素。其中，结点 Node 类定义如下：\n\n```java\nstatic class Node<E> {\n\n    E item;\n    Node<E> next;\n\n    Node(E x) {\n        item = x;\n    }\n}\n```\n\n其中 next 指针的指向分为 3 种情况：\n\n1. 指向某个具体的后继结点。\n2. 指向自己，意味着后继结点为 `head.next`。\n3. 指向 null，说明当前结点是队列的尾结点，没有后继结点。\n\nLinkedBlockingQueue 定义了 head 和 last 指针分别指向队列的头结点和尾结点。此外，LinkedBlockingQueue 还定义了如下字段：\n\n```java\npublic class LinkedBlockingQueue<E> extends AbstractQueue<E> implements BlockingQueue<E>, Serializable {\n\n    /** 当前队列的容量上限 */\n    private final int capacity;\n    /** 记录当前队列的元素个数 */\n    private final AtomicInteger count = new AtomicInteger();\n\n    /** 队列头结点 */\n    transient Node<E> head;\n    /** 队列尾结点 */\n    private transient Node<E> last;\n\n    /** 用于控制 take、poll 等操作，保证同一时间只有一个线程从队列获取元素 */\n    private final ReentrantLock takeLock = new ReentrantLock();\n    /** 条件队列，记录出队列时因为队列为空而等待的线程 */\n    private final Condition notEmpty = takeLock.newCondition();\n\n    /** 用户控制 put、offer 等操作，保证同一时间只有一个线程往队列添加元素 */\n    private final ReentrantLock putLock = new ReentrantLock();\n    /** 条件队列，记录入队列时因为队列已满而等待的线程 */\n    private final Condition notFull = putLock.newCondition();\n\n    // ... 省略方法定义\n\n}\n```\n\n由上述字段定义可以看出，LinkedBlockingQueue 限制了队列的容量上限，并使用 AtomicInteger 类型字段对队列中的元素个数进行计数。虽然 LinkedBlockingQueue 底层依赖于链表实现，理论上是无界的，但是 LinkedBlockingQueue 在实现上却限制了队列的容量上限（默认为 `Integer.MAX_VALUE`）。\n\n此外，针对出队列和入队列操作，LinkedBlockingQueue 分别设置了一把独占可重入锁，即 takeLock 和 putLock，从而保证同一时间只有一个线程执行出队列操作，只有一个线程执行入队列操作，且出队列的线程与入队列的线程彼此之间不相互影响。针对一些阻塞版本的出队列入队列方法，如果队列为空，则出队列线程会被记录到条件队列 notEmpty 中进行等待，如果队列已满，则入队列线程会被记录到条件队列 notFull 中进行等待。\n\n### BlockingQueue 接口\n\nBlockingQueue 接口继承自 Queue 接口，用于描述阻塞队列。当队列无法及时响应用户请求时，例如当我们尝试从空队列中获取元素，或者继续往已满的有界队列中添加元素，BlockingQueue 定义了以下 4 种响应形式：\n\n1. 抛出异常。\n2. 立即返回特殊值，例如 null 或 false。\n3. 无限期阻塞当前请求，直到队列状态变为可用。\n4. 超时阻塞当前请求，直到队列状态变为可用。\n\nBlockingQueue 接口的定义如下：\n\n```java\npublic interface BlockingQueue<E> extends Queue<E> {\n\n    boolean offer(E e);\n    boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException;\n    boolean add(E e);\n    void put(E e) throws InterruptedException;\n\n    E poll(long timeout, TimeUnit unit) throws InterruptedException;\n    E take() throws InterruptedException;\n\n    boolean remove(Object o);\n\n    boolean contains(Object o);\n    int remainingCapacity();\n\n    int drainTo(Collection<? super E> c);\n    int drainTo(Collection<? super E> c, int maxElements);\n\n}\n```\n\n针对各方法的含义说明如下：\n\n- `offer`：往队列中添加元素，如果成功则返回 true，对于有界队列来说，如果队列已满则返回 false，而不是抛出异常。BlockingQueue 同时还声明了超时版本的 offer 方法。\n- `add`：往队列中添加元素，如果成功则返回 true，对于有界队列来说，如果队列已满则抛出 IllegalStateException 异常。\n- `put`：往队列中添加元素，对于有界队列来说，如果队列已满则阻塞当前请求，期间支持响应中断。\n- `poll`：移除队列头结点，并返回结点元素值，如果队列为空则等待指定时间，并在超时时返回 null，期间支持响应中断。\n- `take`：仅获取头结点元素值而不删除结点，如果队列为空则阻塞等待，期间支持响应中断。\n- `remove`：接收一个参数，从队列中删除值等于该参数的结点，如果存在多个结点满足要求，则删除第一个。\n- `contains`：接收一个参数，判断队列中是否存在值等于该参数的结点。\n- `remainingCapacity`：返回队列的剩余容量，如果是无界队列，则返回 `Integer.MAX_VALUE`。\n- `drainTo`：从队列中移除所有（或指定个数）结点，并将结点元素放入参数指定的集合中返回，相对于逐个移除更加高效。\n\n### 核心方法实现\n\nLinkedBlockingQueue 实现自 BlockingQueue 接口，下面针对核心方法的实现逐一进行分析。\n\n#### 添加元素：offer & add & put\n\n针对添加元素的操作，LinkedBlockingQueue 实现了 `LinkedBlockingQueue#offer`、`LinkedBlockingQueue#add` 和 `LinkedBlockingQueue#put` 方法，其中 `LinkedBlockingQueue#add` 是对 `LinkedBlockingQueue#offer` 的封装，并在队列已满时抛出 IllegalStateException 异常。\n\n下面主要展开分析 `LinkedBlockingQueue#offer` 和 `LinkedBlockingQueue#put` 方法的实现。首先来看一下 `LinkedBlockingQueue#offer` 方法，实现如下：\n\n```java\npublic boolean offer(E e) {\n    // 不允许添加 null 元素\n    if (e == null) {\n        throw new NullPointerException();\n    }\n    final AtomicInteger count = this.count;\n    // 当前队列已满，直接返回 false\n    if (count.get() == capacity) {\n        return false;\n    }\n    int c = -1;\n    // 创建待添加元素对应的结点对象\n    Node<E> node = new Node<>(e);\n    final ReentrantLock putLock = this.putLock;\n    // 加锁\n    putLock.lock();\n    try {\n        // 再次校验队列是否已满\n        if (count.get() < capacity) {\n            // 往队列末端追加结点\n            this.enqueue(node);\n            // 队列元素个数计数加 1，并返回添加之前队列的大小\n            c = count.getAndIncrement();\n            // 当前队列在执行添加操作之后仍然存在空闲位置，尝试唤醒一个之前因为队列已满而等待的线程\n            if (c + 1 < capacity) {\n                notFull.signal();\n            }\n        }\n    } finally {\n        // 释放锁\n        putLock.unlock();\n    }\n    // c == 0 说明队列中至少存在一个元素（当前添加的），尝试唤醒一个之前因为队列为空而等待的线程\n    if (c == 0) {\n        this.signalNotEmpty();\n    }\n    return c >= 0;\n}\n```\n\n与 ConcurrentLinkedQueue 一样，LinkedBlockingQueue 同样不允许往其中添加 null 元素。如果队列已满，则上述方法会直接返回 false，表示添加失败，否则创建待添加元素对应的结点对象，并继续执行：\n\n1. 加锁，保证同一时间只有一个线程在执行添加操作；\n2. 再次校验队列是否已满，如果已满则跳转至步骤 5，否则执行 `LinkedBlockingQueue#enqueue` 方法往队列末端插入结点；\n3. 结点个数计数加 1；\n4. 如果在完成本次添加操作之后，队列仍然未满，则尝试唤醒一个之前因为队列已满而等待的线程；\n5. 释放锁；\n6. 如果本次成功添加了一个元素，则调用 `LinkedBlockingQueue#signalNotEmpty` 方法尝试唤醒一个之前因为队列为空而等待的线程；\n7. 返回。\n\n其中 `LinkedBlockingQueue#signalNotEmpty` 方法的实现比较简单，读者可以参考源码实现。这里简单提一下 `LinkedBlockingQueue#enqueue` 方法，实现如下：\n\n```java\nprivate void enqueue(Node<E> node) {\n    last = last.next = node;\n}\n```\n\n在 LinkedBlockingQueue 对象被构造出来时，head 和 last 指针均指向一个元素值为 null 的标记结点。由上述方法的实现可以看出当执行入队列操作时，是将结点赋值给 last 结点的 next 指针，并没有移除队列头部的 null 结点，下文在介绍出队列操作时返回的都是 `head.next` 结点元素值，理解了上述插入操作的执行过程也就不会疑惑为什么出队列时不是直接返回 head 结点的元素值。\n\nLinkedBlockingQueue 还定义了超时版本的 `LinkedBlockingQueue#offer(E, long, TimeUnit)` 方法，当队列已满时，该方法会阻塞等待指定的时间。\n\n下面再来看一下 `LinkedBlockingQueue#put` 方法，相对于上面介绍的 `LinkedBlockingQueue#offer` 方法，对于有界队列而言，如果队列已满则该方法将无限期阻塞，方法实现如下：\n\n```java\npublic void put(E e) throws InterruptedException {\n    // 不允许添加 null 元素\n    if (e == null) {\n        throw new NullPointerException();\n    }\n    // Note: convention in all put/take/etc is to preset local var\n    // holding count negative to indicate failure unless set.\n    int c = -1;\n    Node<E> node = new Node<>(e);\n    final ReentrantLock putLock = this.putLock;\n    final AtomicInteger count = this.count;\n    // 加锁，期间支持响应中断\n    putLock.lockInterruptibly();\n    try {\n        /*\n         * Note that count is used in wait guard even though it is not protected by lock.\n         * This works because count can only decrease at this point (all other puts are shut out by lock),\n         * and we (or some other waiting put) are signalled if it ever changes from capacity.\n         * Similarly for all other uses of count in other wait guards.\n         */\n\n        // 队列已满，则等待\n        while (count.get() == capacity) {\n            notFull.await();\n        }\n        // 执行入队列操作\n        this.enqueue(node);\n        // 队列元素个数计数加 1，并返回添加之前队列的大小\n        c = count.getAndIncrement();\n        // 当前队列在执行添加操作之后仍然存在空闲位置，尝试唤醒一个之前因为队列已满而等待的线程\n        if (c + 1 < capacity) {\n            notFull.signal();\n        }\n    } finally {\n        // 释放锁\n        putLock.unlock();\n    }\n    // c == 0 说明队列中至少存在一个元素（当前添加的），尝试唤醒一个之前因为队列为空而等待的线程\n    if (c == 0) {\n        this.signalNotEmpty();\n    }\n}\n```\n\n由上述实现可以看出，相对于 `LinkedBlockingQueue#offer` 方法在队列已满时的直接返回，方法 `LinkedBlockingQueue#put` 会将当前线程添加到条件队列中等待其它线程释放队列空间。\n\n#### 获取元素：poll & peek & take\n\n针对获取元素的操作，LinkedBlockingQueue 实现了 `LinkedBlockingQueue#poll`、`LinkedBlockingQueue#peek` 和 `LinkedBlockingQueue#take` 方法，其中 `LinkedBlockingQueue#peek` 方法仅获取队列头结点元素值，而不移除头结点，实现上比较简单。下面展开分析 `LinkedBlockingQueue#poll` 和 `LinkedBlockingQueue#take` 方法的实现机制。\n\n首先来看一下 `LinkedBlockingQueue#poll` 方法，LinkedBlockingQueue 针对该方法定义了两个版本，区别在于当队列为空时是立即返回还是阻塞等待一段时间，而在实现思路上是一致的。这里以不带超时参数的版本为例展开分析，实现如下：\n\n```java\npublic E poll() {\n    final AtomicInteger count = this.count;\n    // 当前队列为空，直接返回 null\n    if (count.get() == 0) {\n        return null;\n    }\n    E x = null;\n    int c = -1;\n    final ReentrantLock takeLock = this.takeLock;\n    // 加锁\n    takeLock.lock();\n    try {\n        // 如果当前队列不为空\n        if (count.get() > 0) {\n            // 获取队列头结点元素，并移除头结点\n            x = this.dequeue();\n            // 队列元素计数值减 1，这里返回的是减 1 之前的值\n            c = count.getAndDecrement();\n            // 队列在执行移除操作后至少还存在一个元素，尝试唤醒一个之前因为队列为空而阻塞的线程\n            if (c > 1) {\n                notEmpty.signal();\n            }\n        }\n    } finally {\n        // 释放锁\n        takeLock.unlock();\n    }\n    /*\n     * 之前队列已满，但是经过本次 poll 操作之后，至少有一个空闲位置，\n     * 尝试唤醒一个之前因为队列已满而阻塞的线程\n     */\n    if (c == capacity) {\n        this.signalNotFull();\n    }\n    return x;\n}\n```\n\n如果队列为空则上述方法会直接返回 null，否则继续执行：\n\n1. 加锁，保证同一时间只有一个线程在执行获取操作；\n2. 再次校验队列是否为空，如果为空则跳转至步骤 5，否则执行 `LinkedBlockingQueue#dequeue` 方法移除队列头结点，并返回结点元素值；\n3. 结点个数计数减 1；\n4. 如果在完成本次移除操作之后，队列仍然非空，则尝试唤醒一个之前因为队列为空而等待的线程；\n5. 释放锁；\n6. 如果本次成功移除了一个元素，则调用 `LinkedBlockingQueue#signalNotFull` 方法尝试唤醒一个之前因为队列已满而等待的线程；\n7. 返回。\n\n其中 `LinkedBlockingQueue#signalNotFull` 方法的实现比较简单，读者可以参考源码实现。前面我们分析了入队列 `LinkedBlockingQueue#enqueue` 方法，下面来看一下出队列方法，实现如下：\n\n```java\nprivate E dequeue() {\n    Node<E> h = head;\n    Node<E> first = h.next;\n    // 自引用，等待 GC 回收\n    h.next = h; // help GC\n    head = first;\n    // 获取真正队列头结点的元素值\n    E x = first.item;\n    // 将队列头结点元素值置为 null\n    first.item = null;\n    return x;\n}\n```\n\n理解了前面入队列的过程，则上述出队列的实现也就一目了然，只要清楚队列的头结点一直是一个值为 null 的结点，而真正有效的队列头结点是该结点的 next 结点。\n\nLinkedBlockingQueue 还定义了超时版本的 `LinkedBlockingQueue#poll(long, TimeUnit)` 方法，当队列为空时，该方法会阻塞等待指定的时间。\n\n下面再来看一下 `LinkedBlockingQueue#take` 方法，相对于上面介绍的 `LinkedBlockingQueue#poll` 方法，对于有界队列而言，如果队列为空则该方法将无限期阻塞，方法实现如下：\n\n```java\npublic E take() throws InterruptedException {\n    E x;\n    int c = -1;\n    final AtomicInteger count = this.count;\n    final ReentrantLock takeLock = this.takeLock;\n    // 加锁\n    takeLock.lockInterruptibly();\n    try {\n        // 如果队列为空，则等待\n        while (count.get() == 0) {\n            notEmpty.await();\n        }\n        // 获取队列头结点元素，并移除头结点\n        x = this.dequeue();\n        // 队列元素计数值减 1，这里返回的是减 1 之前的值\n        c = count.getAndDecrement();\n        // 队列在执行移除操作后至少还存在一个元素，尝试唤醒一个之前因为队列为空而阻塞的线程\n        if (c > 1) {\n            notEmpty.signal();\n        }\n    } finally {\n        // 释放锁\n        takeLock.unlock();\n    }\n    /*\n     * 之前队列已满，但是经过本次 poll 操作之后，至少有一个空闲位置，\n     * 尝试唤醒一个之前因为队列已满而阻塞的线程\n     */\n    if (c == capacity) {\n        this.signalNotFull();\n    }\n    return x;\n}\n```\n\n由上述实现可以看出，相对于 `LinkedBlockingQueue#poll` 方法在队列为空时的直接返回，方法 `LinkedBlockingQueue#take` 会将当前线程添加到条件队列中等待其它线程添加新的队列元素。\n\n#### 移除元素：remove\n\n针对移除元素的操作，LinkedBlockingQueue 实现了 `LinkedBlockingQueue#remove` 方法，并提供了有参和无参的版本，其中无参版本实际上是委托给 `LinkedBlockingQueue#poll` 方法执行的。下面来分析一下有参版本的实现，如下：\n\n```java\npublic boolean remove(Object o) {\n    if (o == null) {\n        return false;\n    }\n    // 锁定出队列、入队列操作\n    this.fullyLock();\n    try {\n        // 从头开始遍历队列\n        for (Node<E> trail = head, p = trail.next;\n             p != null;\n             trail = p, p = p.next) {\n            // 如果找到第一个目标元素，则移除\n            if (o.equals(p.item)) {\n                // 移除 p 结点，如果执行移除之后队列有空闲位置，\n                // 则尝试唤醒一个之前因为队列已满而阻塞的线程\n                this.unlink(p, trail);\n                return true;\n            }\n        }\n        return false;\n    } finally {\n        // 释放出队列、入队列操作\n        this.fullyUnlock();\n    }\n}\n```\n\n上述方法接收一个参数，并执行删除元素值等于该参数的结点，如果存在多个满足条件的结点，则删除第一个。在执行删除操作之前会获取 putLock 和 takeLock 两把锁，以防止删除期间有其它线程执行出队列或入队列操作。\n\n#### 其它操作：size & contains\n\n最后来看一下 `LinkedBlockingQueue#contains` 和 `LinkedBlockingQueue#size` 方法的实现，前者用于检查队列是否包含值等于参数的结点，实现如下：\n\n```java\npublic boolean contains(Object o) {\n    if (o == null) {\n        return false;\n    }\n    // 锁定出队列、入队列操作\n    this.fullyLock();\n    try {\n        // 从头开始遍历链表，并逐一比对\n        for (Node<E> p = head.next; p != null; p = p.next) {\n            if (o.equals(p.item)) {\n                return true;\n            }\n        }\n        return false;\n    } finally {\n        // 释放出队列、入队列操作\n        this.fullyUnlock();\n    }\n}\n```\n\n方法 `LinkedBlockingQueue#size` 用于返回队列的结点个数，前面已经介绍了 LinkedBlockingQueue 定义了一个 AtomicInteger 类型的字段用于计数队列的结点个数，所以 `LinkedBlockingQueue#size` 方法能够精确的返回，且几乎没有性能开销，同时在实现上非常简单，如下：\n\n```java\npublic int size() {\n    return count.get();\n}\n```\n\n既然定义一个 AtomicInteger 类型的计数变量有这么多优势，那么不禁要思考为什么上一篇介绍的 ConcurrentLinkedQueue 没有这么做呢？这主要还是因为 ConcurrentLinkedQueue 是非阻塞队列，基于 CAS 机制来保证线程安全，但是 CAS 的缺点在于无法像锁一样同时保证多个操作的原子性，所以无法引入计数原子变量。\n\n### 总结\n\n本文分析了 LinkedBlockingQueue 的设计与实现，LinkedBlockingQueue 底层依赖于单链表作为存储结构，并基于可重入锁 ReentrantLock 保证线程安全，同时为入队列和出队列分别设置了一把锁以提升操作性能，减少阻塞开销。\n\n相对于上一篇介绍的 ConcurrentLinkedQueue 而言，LinkedBlockingQueue 与其功能相同，但是底层却是两套不同的设计与实现。此外，JUC 还提供了以数组作为底层存储结构的有界阻塞线程安全队列 ArrayBlockingQueue，该组件与本文介绍的 LinkedBlockingQueue 在设计思路上是一致的，同样基于 ReentrantLock 锁保证线程安全，并支持在构造时使用公平锁策略。\n\n总而言之，在线程安全队列的使用上 JUC 给我们提供了多种选择，具体开发时如何确定使用哪个组件还是要取决于具体的应用场景，甚至有必要进行一些压测，以结果引导决策。\n\n### 参考\n\n1. JDK 1.8 源码\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：ConcurrentLinkedQueue","url":"/2018/09/10/java/juc-concurrent-linked-queue/","content":"\nConcurrentLinkedQueue 是线程安全的无界非阻塞队列。在 JUC 包中，线程安全的队列按照实现方式可以分为阻塞队列和非阻塞队列两大类，前者基于锁来保证线程安全，而后者则基于 CAS 机制保证线程安全，阻塞队列一般在类名中都带有 Blocking 的字样。<!-- more -->\n\n由 Linked 关键字我们可以推断出 ConcurrentLinkedQueue 底层依赖于链表实现，在 ConcurrentLinkedQueue 的内部实现了一个单链表，用以存放队列元素。其中，结点 Node 类定义如下：\n\n```java\nprivate static class Node<E> {\n\n    /** 结点元素值 */\n    volatile E item;\n    /** 指针，指向下一个结点 */\n    volatile Node<E> next;\n\n    // ... 省略方法定义\n\n}\n```\n\nNode 类是一个典型的链表结点定义，此外，Node 类还定义了一些方法用于修改结点的元素值和 next 指针，这些方法均基于 Unsafe 实现。ConcurrentLinkedQueue 的 head 和 tail 字段分别指向队列的头结点和尾结点，如下：\n\n```java\npublic class ConcurrentLinkedQueue<E> extends AbstractQueue<E> implements Queue<E>, Serializable {\n\n    private transient volatile Node<E> head;\n    private transient volatile Node<E> tail;\n\n    public ConcurrentLinkedQueue() {\n        head = tail = new Node<>(null);\n    }\n\n    // ... 省略方法实现\n\n}\n```\n\n当我们构造一个空的 ConcurrentLinkedQueue 对象时，链表的 head 和 tail 均指向一个元素值为 null 的标记结点。在 ConcurrentLinkedQueue 中不允许添加 null 元素，因为值为 null 的结点在 ConcurrentLinkedQueue 中扮演着特殊的角色。\n\n### Queue 接口\n\nQueue 接口继承自 Collection 接口，增加了队列相关的操作，定义如下：\n\n```java\npublic interface Queue<E> extends Collection<E> {\n\n    boolean add(E e);\n    boolean offer(E e);\n\n    E poll();\n    E peek();\n    E element();\n\n    E remove();\n\n}\n```\n\n针对各方法的含义说明如下：\n\n- `add`：往队列中添加元素，如果成功则返回 true，对于有界队列来说，如果队列已满则抛出 IllegalStateException 异常。\n- `offer`：往队列中添加元素，如果成功则返回 true，对于有界队列来说，如果队列已满则返回 false，而不是抛出异常。\n- `poll`：移除队列头结点，并返回结点元素值，如果队列为空则返回 null。\n- `peek`：仅获取头结点元素值而不删除结点，如果队列为空则返回 null。\n- `element`：仅获取头结点元素值而不删除结点，如果队列为空则抛出 NoSuchElementException 异常。\n- `remove`：移除队列头结点，并返回结点元素值，如果队列为空则抛出 NoSuchElementException 异常。\n\n### 核心方法实现\n\nConcurrentLinkedQueue 实现自 Queue 接口，下面来分析一下其针对 Queue 中声明的核心操作方法的实现。\n\n#### 添加元素：add & offer\n\nConcurrentLinkedQueue 实现了 Queue 接口中声明的往队列中添加元素方法，即 `Queue#add` 和 `Queue#offer`。这两个方法都是往队列末端追加元素，因为 ConcurrentLinkedQueue 没有容量上的限制，所以这两个方法也就不存在队列已满的问题。所以，对于 ConcurrentLinkedQueue 而言，这两个方法在实现上并没有区别。\n\n下面来看一下 ConcurrentLinkedQueue 针对 `Queue#offer` 的实现，如下：\n\n```java\npublic boolean offer(E e) {\n    // 待添加元素不能为 null\n    checkNotNull(e);\n    // 创建待添加元素对应的 Node 结点\n    final Node<E> newNode = new Node<>(e);\n\n    // 添加到尾结点\n    for (Node<E> t = tail, p = t; ; ) {\n        Node<E> q = p.next;\n        if (q == null) { // 1\n            // p 已经是尾结点，基于 CAS 设置结点 newNode 为 p 的 next 结点\n            if (p.casNext(null, newNode)) {\n                /*\n                 * Successful CAS is the linearization point for e to become an element of this queue,\n                 * and for newNode to become \"live\".\n                 */\n                if (p != t) { // hop two nodes at a time\n                    // 更新 tail 结点\n                    this.casTail(t, newNode);  // Failure is OK.\n                }\n                return true;\n            }\n            // Lost CAS race to another thread; re-read next\n        } else if (p == q) { // 2\n            /*\n             * We have fallen off list. If tail is unchanged, it will also be off-list,\n             * in which case we need to jump to head, from which all live nodes are always reachable.\n             * Else the new tail is a better bet.\n             */\n            p = (t != (t = tail)) ? t : head;\n        } else { // 3\n            // Check for tail updates after two hops.\n            p = (p != t && t != (t = tail)) ? t : q;\n        }\n    }\n}\n```\n\n对于待添加的元素，上述方法首先会判断是否为 null，前面已经提及过 ConcurrentLinkedQueue 不允许向其中添加 null 元素，这主要是因为元素值为 null 的结点在 ConcurrentLinkedQueue 中是一个特殊的标记结点。如果待添加元素不为 null，则上述方法会将元素包装成 Node 结点（令该结点为 N）添加到队列的末端。\n\n下面通过图示演示各种不同的元素添加场景，本小节中均使用青色表示 head 结点，使用橘黄色表示 tail 结点。假设当前队列的元素构成如下图 (1) 所示，此时 q 结点为 null（说明：本文中所有虚线表示的结点均指代结点本身为 null，而非结点元素值为 null），即运行到上述代码 1 位置。需要基于 CAS 操作将 p 的 next 结点由 null 修改为 N 结点，成功则返回 true。此时 p 不等于 t，操作完成之后队列的元素构成如下图 (2) 所示。\n\n![image](/images/2018/juc-concurrent-linked-queue-offer-1.png)\n\n考虑上述过程存在多个线程竞争，假设现在有两个线程 A 和 B，其中 A 在执行代码 1 中的 `Node#casNext` 时成功将 p 的 next 结点由 null 更新为 node1 结点，如下图 (1) 所示。此时线程 B 再执行 `Node#casNext` 企图将 p 的 next 结点由 null 更新为 node2 结点时将失败，因为 p 的 next 结点此时已经不为 null，所以线程 B 将进入下一轮 for 循环，但此时 q 已经不为 null，且不等于 p，所以进入代码 3，这一步的运行结果就是将 q 赋值给 p，如下图 (2) 所示。接着线程 B 继续进入下一轮 for 循环，执行 `Node<E> q = p.next;`，如下图 (3) 所示。因为此时 q 等于 null，所以继续执行代码 1 将 p 的 next 结点由 null 修改为 node2，如下图 (4) 所示。但此时的 p 不等于 t，所以需要执行 `ConcurrentLinkedQueue#casTail` 更新 tail 结点，如下图 (5) 所示。\n\n![image](/images/2018/juc-concurrent-linked-queue-offer-2.png)\n\n最后再来分析一下什么情况下会执行到代码 2。假设当前队列的元素构成如下图 (1) 所示，此种结构一般由其它线程执行 poll 方法所造成，下一小节会进行分析。此时 tail 结点形成了自引用，开始执行 for 循环时 p 和 t 均指向 tail 结点，当将 p 的 next 结点赋值给 q 时，因为 p 的 next 结点即为 tail 结点自己，所以 q 也指向 tail 结点。此时，q 结点不为 null，且 p 等于 q，所以执行代码 2 将 head 结点赋值给 p，如下图 (2) 所示。所以这一步的目的在于跳出自引用，后续的执行流程参考下图 (3)、(4) 和 (5)，读者可以自行梳理。\n\n![image](/images/2018/juc-concurrent-linked-queue-offer-3.png)\n\n除了上面介绍的 `ConcurrentLinkedQueue#offer` 方法，ConcurrentLinkedQueue 还实现了 `ConcurrentLinkedQueue#add` 方法同样用于往队列末端追加元素，不过因为 ConcurrentLinkedQueue 是无界队列，所以该方法也只是简单的将请求委托给 `ConcurrentLinkedQueue#offer` 方法执行。\n\n#### 获取元素：poll & peek & element\n\n针对获取元素的操作，Queue 接口声明了 3 个方法，包括 `Queue#poll`、`Queue#peek`，以及 `Queue#element`。其中 `Queue#poll` 和 `Queue#peek` 的区别一般都比较熟悉，而 `Queue#element` 方法在功能上与 `Queue#peek` 方法类似，都是获取队列的头结点元素值而不删除结点，区别在于当队列为空时，方法 `Queue#peek` 返回 null，而 `Queue#element` 则抛出异常。ConcurrentLinkedQueue 针对 `Queue#element` 方法的实现实际上也是委托给 `ConcurrentLinkedQueue#peek` 方法执行的，只是对该方法的返回值进行了处理，如果返回值为 null 则抛出 NoSuchElementException 异常。\n\n下面首先来看一下 ConcurrentLinkedQueue 针对方法 `Queue#poll` 的实现，如下：\n\n```java\npublic E poll() {\n    restartFromHead:\n    for (; ; ) {\n        // 从头结点获取元素\n        for (Node<E> h = head, p = h, q; ; ) {\n            E item = p.item;\n\n            // 如果当前头结点不为 null，则尝试基于 CAS 将其修改为 null\n            if (item != null && p.casItem(item, null)) { // 1\n                // CAS 操作成功\n                // Successful CAS is the linearization point for item to be removed from this queue.\n                if (p != h) { // hop two nodes at a time\n                    this.updateHead(h, ((q = p.next) != null) ? q : p);\n                }\n                return item;\n            }\n            // 当前队列为空\n            else if ((q = p.next) == null) { // 2\n                this.updateHead(h, p);\n                return null;\n            } else if (p == q) { // 3\n                continue restartFromHead;\n            } else { // 4\n                p = q;\n            }\n        }\n    }\n}\n\nfinal void updateHead(Node<E> h, Node<E> p) {\n    // 将头结点由 h 更新为 p\n    if (h != p && this.casHead(h, p)) {\n        // 更新 h 的 next 结点为 h 自己\n        h.lazySetNext(h);\n    }\n}\n```\n\n上述方法使用了 continue 标签语法以控制代码的执行逻辑，其中标签名为 restartFromHead，此外，break 关键字同样支持标签语法，与 continue 一起实现类似 goto 关键字的功能。\n\n下面同样通过图示演示各种不同的获取元素场景，本小节中均使用青色表示 head 结点，使用橘黄色表示 tail 结点。假设当前队列的元素构成如下图 (1) 所示，此时 p 和 h 均指向 head 结点，而 q 结点未赋值，所以暂未标出。此时 p 所指向的结点元素值不为 null，所以尝试执行 `Node#casItem` 方法基于 CAS 修改结点元素值为 null，即运行上述代码 1。假设当前线程 CAS 操作成功，如下图 (2) 所示，因为此时 p 等于 h，所以直接返回结点元素值，即出队列成功。\n\n![image](/images/2018/juc-concurrent-linked-queue-poll-1.png)\n\n继续演示一些其它情况，假设现在队列的头结点元素值为 null，所以直接跳转到代码 2 执行，将 q 赋值为 p 的 next 结点，如下图 (1) 所示，但是因为结点不为 null，所以继续往下执行。此时 p 不等于 q，所以执行代码 4 将 q 赋值给 p，如下图 (2) 所示，然后进入下一轮循环。\n\n此时结点 p 的元素值不为 null，所以进入代码 1。考虑存在多个线程竞争的场景，假设现在有两个线程 A 和 B，其中 A 在执行代码 1 中的 `Node#casItem` 时成功将 p 的元素值更新为 null，如下图 (3-1) 所示。因为此时 p 不等于 h，所以执行 `ConcurrentLinkedQueue#updateHead` 方法将头结点由 h 更新为 p，并重定向 h 的 next 指针指向自己，如下图 (4-1) 所示。最后返回结点元素值，即出队列成功。\n\n![image](/images/2018/juc-concurrent-linked-queue-poll-2.png)\n\n因为线程 A 已经操作成功，所以线程 B 在执行 `Node#casItem` 方法时必然失败，于是继续向下执行代码 2，将 q 指向 p 的 next 结点，如上图 (3-2) 所示。因为此时 q 结点为 null，所以执行 `ConcurrentLinkedQueue#updateHead` 方法将头结点由 h 更新为 p，并重定向 h 的 next 指针指向自己，如上图 (4-2) 所示。最后返回 null 值，即出队列成功。\n\n最后再来分析一下什么情况下会执行到代码 3。假设当前队列的元素构成如下图 (1) 所示，并且当前有两个线程（A 和 B）竞争执行出队列操作，线程 A 首先执行代码 1 基于 CAS 将结点 p 元素值修改为 null，如下图 (2) 所示。但在线程 A 继续执行代码 1 中的 `ConcurrentLinkedQueue#updateHead` 方法尝试更新 head 结点之前，B 线程进入了 for 循环，如下图 (3) 所示，此时 B 线程的 h 和 p 指针均指向 head 结点，但是在 B 继续向下执行之前，A 线程执行了 `ConcurrentLinkedQueue#updateHead` 方法，将 head 结点由 h 更新为 p，并修改 h 的 next 指针指向自己，最后返回元素值，如下图 (4) 所示。\n\n![image](/images/2018/juc-concurrent-linked-queue-poll-3.png)\n\n此时，如上图 (5) 所示，B 线程再继续执行时发现 p 结点元素值为 null，所以跳转执行代码 2 将 p 的 next 结点赋值给 q，如上图 (6) 所示。因为此时 p 结点不为 null，且是自引用，所以 p 也就等于 q，继续执行代码 3 跳出本次 for 循环从头再来。再次进入 for 循环时，B 线程看到的队列结构就变成了如上图 (7) 所示。\n\n本小节的最后一起来看一下 `ConcurrentLinkedQueue#peek` 方法的实现，相对于 `ConcurrentLinkedQueue#poll` 方法，该方法的区别在于仅获取队头元素，而不移除头结点。方法实现如下：\n\n```java\npublic E peek() {\n    restartFromHead:\n    for (; ; ) {\n        for (Node<E> h = head, p = h, q; ; ) {\n            E item = p.item;\n            if (item != null || (q = p.next) == null) { // 1\n                this.updateHead(h, p);\n                return item;\n            } else if (p == q) { // 2\n                continue restartFromHead;\n            } else { // 3\n                p = q;\n            }\n        }\n    }\n}\n```\n\n上述实现初看起来似乎不太好理解，但是如果像上面一样结合图示去分析就会一目了然，这里就不再继续演示各个步骤的执行逻辑，感兴趣的读者可以自己动手画一下。\n\n#### 移除元素：remove\n\n针对删除元素操作，Queue 仅声明了 `Queue#remove` 方法，用于删除队列头结点并返回结点元素值，区别于 `Queue#poll` 方法返回 null 值，当队列为空时该方法将抛出异常。ConcurrentLinkedQueue 还实现了带参数的 remove 方法（继承自 Collection 接口），该方法用于从当前队列中删除目标元素值对应的结点，如果存在多个则删除第 1 个。下面主要来看一下带参数版本的 remove 方法实现，如下：\n\n```java\npublic boolean remove(Object o) {\n    if (o != null) {\n        Node<E> next, pred = null;\n        // 遍历队列中的元素\n        for (Node<E> p = this.first(); p != null; pred = p, p = next) {\n            boolean removed = false;\n            E item = p.item;\n            if (item != null) {\n                // 如果当前遍历元素不是期望删除的元素，则继续获取后继结点\n                if (!o.equals(item)) {\n                    next = this.succ(p);\n                    continue;\n                }\n                // 当前遍历元素是期望删除的元素，基于 CAS 将该结点置为 null\n                removed = p.casItem(item, null);\n            }\n\n            /*\n             * 指向到这里分为两种情况：\n             * 1. 当前结点为 null。\n             * 2. 当前结点为待删除结点。\n             */\n\n            // 获取当前结点的后继结点\n            next = this.succ(p);\n            // 更新前驱结点的 next 指针指向当前结点的后继结点\n            if (pred != null && next != null) { // unlink\n                pred.casNext(p, next);\n            }\n            if (removed) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```\n\n删除的过程从队列头部开始遍历，并在遇到待删除元素时基于 CAS 将对应结点元素值更新为 null，在遍历过程中会剔除掉所有元素值为 null 的结点。\n\n#### 其它操作：size & contains\n\nConcurrentLinkedQueue 提供了 `ConcurrentLinkedQueue#size` 方法用于获取队列的长度，该方法在实现上会从头开始对队列进行遍历，并计数元素值不为 null 的结点，并以 `Integer.MAX_VALUE` 作为计数值上界。需要注意的一点是不同于一般的集合，ConcurrentLinkedQueue 整个计算队列大小的过程时间复杂度为 `O(n)`，并且结果是不准确的。如果期间有其它线程对队列执行增删操作，将不会在 `ConcurrentLinkedQueue#size` 方法的返回值中体现。\n\n方法 `ConcurrentLinkedQueue#contains` 用于判断队列中是否包含参数指定的元素值，在实现上与 `ConcurrentLinkedQueue#size` 方法思想想通，都需要从头开始遍历队列并对元素值进行比对。\n\n### 总结\n\n本文分析了 ConcurrentLinkedQueue 的设计与实现，并运用图示梳理了队列元素添加、获取，以及删除的过程。ConcurrentLinkedQueue 底层依赖于单链表作为存储结构，并基于 CAS 对链表的结点进行修改，从而实现在不阻塞的前提下保证线程安全，避免线程阻塞和唤醒所带来的性能开销。ConcurrentLinkedQueue 的设计思路还是比较简单明了的，难点在于访问结点过程中对链表的操作，并不是特别直观，所以本文引入了大量的图示演示相关的操作过程，希望能够简化理解。\n\n### 参考\n\n1. JDK 1.8 源码\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：CopyOnWriteArrayList","url":"/2018/09/05/java/juc-cow-array-list/","content":"\nCopyOnWriteArrayList 是线程安全的 List 实现，底层依赖于数组作为存储结构，并基于 [写时复制（CoW: Copy-on-Write）机制](https://en.wikipedia.org/wiki/Copy-on-write) 保证线程安全性。CopyOnWriteArrayList 在执行修改操作时会将底层数组复制一份，并在副本上实施修改，最后再更新回底层数组。虽然这样的实现比较消耗内存，但却带来了较高的执行效率，属于拿空间换时间。<!-- more -->\n\n除了 CopyOnWriteArrayList，在 JUC 包中还有另外一个基于 CoW 机制实现的线程安全组件，即 CopyOnWriteArraySet，不过 CopyOnWriteArraySet 本质上还是基于 CopyOnWriteArrayList 实现的，所以理解了 CopyOnWriteArrayList 的实现原理，也就同时理解了 CopyOnWriteArraySet 的实现原理。\n\n### CopyOnWriteArrayList 实现内幕\n\nCopyOnWriteArrayList 实现自 List 接口，所以我们可以像使用 ArrayList 一样使用 CopyOnWriteArrayList。CopyOnWriteArrayList 类的字段定义如下：\n\n```java\npublic class CopyOnWriteArrayList<E> implements List<E>, RandomAccess, Cloneable, Serializable {\n\n    /** 支撑同步操作的重入锁 */\n    final transient ReentrantLock lock = new ReentrantLock();\n    /** 底层数组 */\n    private transient volatile Object[] array;\n\n    // ... 省略方法定义\n\n}\n```\n\n其中 `CopyOnWriteArrayList#array` 数组是 CopyOnWriteArrayList 的底层存储结构，CopyOnWriteArrayList 依赖于该数组对数据进行存储。字段 `CopyOnWriteArrayList#lock` 对应 ReentrantLock 类型，用于控制多个线程对底层数组的修改操作，保证同一时间只有一个线程对底层数组进行修改。CopyOnWriteArrayList 提供了相应的 `CopyOnWriteArrayList#getArray` 和 `CopyOnWriteArrayList#setArray` 方法用于访问该字段。\n\nCopyOnWriteArrayList 定义了多个重载的构造方法来初始化构造一个 CopyOnWriteArrayList 对象，实现上比较简单。下面重点看一下 CopyOnWriteArrayList 之于 List 接口中声明的核心方法实现，即增（add）、删（remove）、改（set）、查（get）操作。\n\n首先来看一下 __添加元素__ 的操作，CopyOnWriteArrayList 定义了多个重载版本的 `CopyOnWriteArrayList#add` 的方法实现，包括：\n\n- `CopyOnWriteArrayList#add(E)`\n- `CopyOnWriteArrayList#add(int, E)`\n- `CopyOnWriteArrayList#addIfAbsent(E)`\n- `CopyOnWriteArrayList#addAll(Collection<? extends E>)`\n- `CopyOnWriteArrayList#addAll(int, Collection<? extends E>)`\n- `CopyOnWriteArrayList#addAllAbsent`\n\n这些方法在实现上思想都是相通的，下面以 `CopyOnWriteArrayList#add(E)` 方法为例分析往 CopyOnWriteArrayList 中添加元素的运行机制，方法实现如下：\n\n```java\npublic boolean add(E e) {\n    final ReentrantLock lock = this.lock;\n    // 加锁，保证同一时间只有一个线程修改底层数组\n    lock.lock();\n    try {\n        // 获取底层数组\n        Object[] elements = this.getArray();\n        int len = elements.length;\n        // 复制出一份新的数组，长度加 1，以容纳待添加的元素\n        Object[] newElements = Arrays.copyOf(elements, len + 1);\n        newElements[len] = e;\n        // 更新底层数组\n        this.setArray(newElements);\n        return true;\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n}\n```\n\n前面我们已经提及到 CopyOnWriteArrayList 对于数据的修改都是在副本上进行的，上述方法的实现印证了这一点。当往 CopyOnWriteArrayList 中添加一个元素时，方法的执行流程如下：\n\n1. 获取锁对象，保证同一时间只有一个线程在执行修改操作；\n2. 获取底层数组，基于该数组拷贝出一个新的数组，新数组长度加 1；\n3. 追加待添加元素到新数组的末尾位置，并更新底层数组；\n4. 释放锁对象。\n\n再来看一下 __获取元素__ 的操作，CopyOnWriteArrayList 仅定义了一个 `CopyOnWriteArrayList#get` 方法，用于获取指定下标的元素值，实现如下：\n\n```java\npublic E get(int index) {\n    // 直接返回底层数组 index 下标的元素\n    return this.get(this.getArray(), index);\n}\n\nprivate E get(Object[] a, int index) {\n    return (E) a[index];\n}\n```\n\n实现上比较简单，这里主要强调一下弱一致性问题，也就说 get 操作不一定能够返回最新的值。考虑这样一个场景，假设有线程 A 和 B，其中 A 调用 get 方法获取数据，B 调用 add 方法添加数据，当前数组长度为 5：\n\n1. 线程 B 获取底层数组 x，然后拷贝出一个长度为 6 的新数组 y，并将待追加的元素设置到 `y[5]` 的位置，此时还未更新底层数组；\n2. 因为读操作无需获取锁，如果此时线程 A 尝试获取下标为 5 的元素，则会抛出 IndexOutOfBoundsException，因为此时 A 获取到的底层数组还是 x，还没有更新成 y。\n\n然而，大部分时候这种弱一致性并不会对我们的业务造成影响，但是我们需要知道其存在，以便在发生错误时快速定位问题。\n\n继续来看一下 __修改元素__ 的操作，CopyOnWriteArrayList 同样仅定义了一个 `CopyOnWriteArrayList#set` 方法，用于修改指定下标的元素值，实现如下：\n\n```java\npublic E set(int index, E element) {\n    final ReentrantLock lock = this.lock;\n    // 获取锁\n    lock.lock();\n    try {\n        // 获取底层数组\n        Object[] elements = this.getArray();\n        // 获取数组 index 下标值\n        E oldValue = this.get(elements, index);\n        // 待更新的元素值与数组中指定位置的元素值不同\n        if (oldValue != element) {\n            int len = elements.length;\n            Object[] newElements = Arrays.copyOf(elements, len);\n            // 更新 index 位置的元素值\n            newElements[index] = element;\n            // 更新底层数组\n            this.setArray(newElements);\n        } else {\n            // Not quite a no-op; ensures volatile write semantics\n            // 待更新的元素值与数组中指定位置的元素值相同，无需执行更新操作\n            this.setArray(elements); // 保证 volatile 写语义\n        }\n        return oldValue;\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n}\n```\n\n上述方法的执行逻辑如代码注释，比较简单，但是当修改的目标元素值前后未发生变化时还是会调用 `CopyOnWriteArrayList#setArray` 方法更新一下底层数组，用意何在呢？\n\n代码中给出的理由是 “Not quite a no-op; ensures volatile write semantics”，也就是说这里的更新操作不完全是一个无意义的操作，可以用来保证 volatile 的写语义，因为底层数组 array 是 volatile 类型。要理解其用意，可以参考 《[深入理解 java 内存模型](https://www.infoq.cn/article/java_memory_model)》一书中的示例（稍作修改）：\n\n```java\nprivate int a = 0;\nprivate volatile boolean flag = true;\n\npublic void writer() {\n    a = 1; // 1\n    flag = true; // 2\n}\n\npublic void reader() {\n    if (flag) { // 3\n        int i = a; // 4\n    }\n}\n```\n\n假设线程 A 执行 writer 方法之后，线程 B 执行 reader 方法。根据 happens-before 原则，这个过程建立的 happens-before 关系为：\n\n1. 根据程序次序规则，1 happens before 2; 3 happens before 4。\n2. 根据 volatile 规则，2 happens before 3。\n3. 根据 happens before 的传递性规则，1 happens before 4。\n\n这样就能保证线程 B 在 reader 方法中读取 a 变量时能够看见线程 A 在 writer 方法中对 a 的修改，即使在 writer 方法中对变量 flag 的修改同样看似多余。\n\n最后来看一下 __删除元素__ 的操作，CopyOnWriteArrayList 针对删除操作定义了多个重载版本的 `CopyOnWriteArrayList#remove` 的方法实现，包括：\n\n- `CopyOnWriteArrayList#remove(int)`\n- `CopyOnWriteArrayList#remove(java.lang.Object)`\n- `CopyOnWriteArrayList#removeAll`\n- `CopyOnWriteArrayList#removeIf`\n\n下面以 `CopyOnWriteArrayList#remove(int)` 方法为例分析从 CopyOnWriteArrayList 中删除元素的运行机制，方法实现如下：\n\n```java\npublic E remove(int index) {\n    final ReentrantLock lock = this.lock;\n    // 获取锁\n    lock.lock();\n    try {\n        // 获取底层数组\n        Object[] elements = this.getArray();\n        int len = elements.length;\n        // 获取指定下标元素\n        E oldValue = this.get(elements, index);\n        int numMoved = len - index - 1;\n        // 如果是删除最后一个元素，则直接 copy 即可，无需移动\n        if (numMoved == 0) {\n            this.setArray(Arrays.copyOf(elements, len - 1));\n        } else {\n            // 否则，分两次进行拷贝，去掉原 index 下标的元素\n            Object[] newElements = new Object[len - 1];\n            System.arraycopy(elements, 0, newElements, 0, index);\n            System.arraycopy(elements, index + 1, newElements, index, numMoved);\n            this.setArray(newElements);\n        }\n        return oldValue;\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n}\n```\n\n删除的逻辑本质上还是在副本上进行，如上述代码注释，其过程与前面分析的操作类似。\n\n除了上面分析的核心操作方法，CopyOnWriteArrayList 还实现了 `CopyOnWriteArrayList#iterator` 方法返回一个迭代器，实现如下：\n\n```java\npublic Iterator<E> iterator() {\n    return new COWIterator<E>(this.getArray(), 0);\n}\n```\n\n关于 COWIterator 的实现不再继续深入，但是需要知晓的一点是，COWIterator 不支持在迭代过程中修改 CopyOnWriteArrayList 中的元素，对应的 `COWIterator#remove`、`COWIterator#set` 和 `COWIterator#add` 方法均直接抛出 UnsupportedOperationException 异常。此外，方法 `CopyOnWriteArrayList#iterator` 返回的是一个弱一致性迭代器，即在迭代期间，其它线程对于底层数组的修改并不会被迭代器看见。\n\n### 总结\n\n本文分析了 CopyOnWriteArrayList 的设计与实现，CopyOnWriteArrayList 对于数据的修改操作均在副本上完成，并基于 ReentrantLock 保证同一时间只有一个线程能够对底层数组执行修改操作。线程在读取 CopyOnWriteArrayList 时都是拿到底层数组的一个最新快照，并在快照上执行读取操作，所以期间的修改结果对于读操作是不可见的，这也就导致了读写的弱一致性。但是对于读多写少的场景来说，CopyOnWriteArrayList 能够在保证线程安全的同时媲美 ArrayList 的性能。\n\n### 参考\n\n1. JDK 1.8 源码\n2. [深入理解 java 内存模型](https://www.infoq.cn/article/java_memory_model)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：Semaphore","url":"/2018/09/04/java/juc-semaphore/","content":"\n前面我们分析了同步器 CountDownLatch 和 CyclicBarrier 的设计和实现，这两个同步器在使用上都有一个共同的特点，就是在构造时需要指定参与的线程数目，然后对计数器执行减值操作。本文将要介绍的 Semaphore 信号量同样在构造时需要指定一个 int 类型 permits 参数，不过该参数并不用于指定参与的线程数目，相反，Semaphore 并不限制参与的线程数，该参数用于限制同一时间最大允许执行的线程数目上限。<!-- more -->\n\n参与到 Semaphore 中的线程如果希望继续运行，需要从 Semaphore 那里申请获取一个或多个令牌，只有成功拿到令牌的线程才允许继续执行，否则需要阻塞等待，并在执行完成之后需要归还令牌。参数 permits 可以理解为令牌的总数，只要 Semaphore 手上有可用的令牌，就允许有新的线程过来申请。一个线程一次性可以申请一个或多个令牌，只要令牌的数量足够多，Semaphore 就允许同一个时间有多个线程并行执行。\n\n### Semaphore 示例\n\n下面以一个排队就餐的例子来演示 Semaphore 的基本使用，假设一个餐厅一次性最多只能容纳 5 个人同时就餐，但是因为菜品口味极佳，所以生意非常好，来就餐的人多于餐厅能够同时容纳的人数上限，所以超出的人需要在外面排队等待叫号。假设今天有 20 个人前来就餐，那么叫号的过程可以实现如下：\n\n```java\nprivate static final int MAX_COUNT = 5;\n\nprivate static class Person implements Runnable {\n\n    private Semaphore semaphore;\n\n    public Person(Semaphore semaphore) {\n        this.semaphore = semaphore;\n    }\n\n    @Override\n    public void run() {\n        try {\n            System.out.println(\"Thread \" + Thread.currentThread().getName() + \" is waiting.\");\n            semaphore.acquire();\n            System.out.println(\"Thread \" + Thread.currentThread().getName() + \" is eating.\");\n            TimeUnit.SECONDS.sleep(RandomUtils.nextInt(1, 3));\n            System.out.println(\"Thread \" + Thread.currentThread().getName() + \" ate up.\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            semaphore.release();\n        }\n\n    }\n}\n\npublic static void main(String[] args) {\n    // 使用公平锁，保证叫号尽量的公平\n    Semaphore semaphore = new Semaphore(MAX_COUNT, true);\n    for (int i = 0; i < 20; i++) {\n        new Thread(new Person(semaphore), String.valueOf(i)).start();\n    }\n}\n```\n\n上述示例中当一个顾客到达时需要调用 `Semaphore#acquire` 方法申请获取令牌（即询问是否有空位），如果没有空闲的令牌则需要等待。当一个顾客就餐完毕之后需要归还之前申请到的令牌（执行 `Semaphore#release` 方法），此时允许下一位顾客申请令牌进入餐厅就餐。\n\n### Semaphore 实现内幕\n\n下面来看一下 Semaphore 的设计与实现。Semaphore 同样基于 AQS 实现，其内部类 Sync 继承自 AbstractQueuedSynchronizer，并派生出 FairSync 和 NonfairSync 两个子类，分别表示公平锁和非公平锁，这些设计与前面文章中介绍的基于 AQS 实现的 ReentrantLock 和 ReentrantReadWriteLock 如出一辙。Semaphore 在构造时允许我们通过参数指定是使用公平锁还是非公平锁，默认为非公平锁，如下：\n\n```java\npublic Semaphore(int permits) {\n    sync = new NonfairSync(permits);\n}\n\npublic Semaphore(int permits, boolean fair) {\n    sync = fair ? new FairSync(permits) : new NonfairSync(permits);\n}\n```\n\nSemaphore 中定义的方法在实现上均委托给 Sync 对象执行，并复用 AQS 的 state 字段记录当前剩余可用的令牌数。下面重点来分析一下 Semaphore 申请和归还令牌的方法实现，即 `Semaphore#acquire` 和 `Semaphore#release` 方法。首先来看一下令牌申请的过程，Semaphore 提供了多个版本的 `Semaphore#acquire` 方法实现，包括：\n\n- `Semaphore#acquire()`：申请 1 个令牌，如果成功则立即返回，否则阻塞等待，期间支持响应中断请求。\n- `Semaphore#acquire(int)`：相对于 `Semaphore#acquire()` 的区别在于一次性申请多个令牌。\n- `Semaphore#acquireUninterruptibly()`：申请 1 个令牌，如果成功则立即返回，否则阻塞等待，期间忽略中断请求。\n- `Semaphore#acquireUninterruptibly(int)`：相对于 `Semaphore#acquireUninterruptibly()` 的区别在于一次性申请多个令牌。\n- `Semaphore#tryAcquire()`：尝试申请 1 个令牌，不管成功还是失败都会立即返回，成功则返回 true，失败则返回 false。\n- `Semaphore#tryAcquire(int)`：相对于 `Semaphore#tryAcquire()` 的区别在于一次性申请多个令牌。\n- `Semaphore#tryAcquire(long, TimeUnit)`：尝试申请 1 个令牌，相对于 `Semaphore#tryAcquire()` 引入了超时等待机制。\n- `Semaphore#tryAcquire(int, long, TimeUnit)`：相对于 `Semaphore#tryAcquire(long, TimeUnit)` 的区别在于一次性申请多个令牌。\n\n这些申请令牌的方法在实现上大同小异，下面以 `Semaphore#acquire()` 为例分析一下具体的执行过程。方法实现如下：\n\n```java\npublic void acquire() throws InterruptedException {\n    sync.acquireSharedInterruptibly(1);\n}\n```\n\n上述方法直接委托给 AQS 的 `AbstractQueuedSynchronizer#acquireSharedInterruptibly` 方法执行，申请令牌单位为 1。前面在分析 AQS 时已经介绍了该方法的运行机制，下面重点来看一下 Sync 对于模板方法 `AbstractQueuedSynchronizer#tryAcquireShared` 的实现（以 NonfairSync 为例）：\n\n```java\n// NonfairSync#tryAcquireShared\nprotected int tryAcquireShared(int acquires) {\n    return this.nonfairTryAcquireShared(acquires);\n}\n\n// Sync#nonfairTryAcquireShared\nfinal int nonfairTryAcquireShared(int acquires) {\n    for (; ; ) {\n        // 获取 state 状态值\n        int available = this.getState();\n        // 计算剩余可用的资源数\n        int remaining = available - acquires;\n        if (remaining < 0 // 当前没有可用的资源\n                || this.compareAndSetState(available, remaining)) { // 当前有可用的资源，且获取资源成功\n            return remaining;\n        }\n    }\n}\n```\n\n申请令牌的执行流程可以总结为：\n\n1. 获取当前剩余可用的令牌数，即 state 值；\n2. 如果剩余可用的令牌数小于本次申请的数目，则返回差值（负值）；\n3. 否则，更新 state 值，如果更新成功则说明获取令牌成功，返回差值（非负值）。\n\n由 `AbstractQueuedSynchronizer#acquireSharedInterruptibly` 方法的实现我们知道，如果上述过程返回负值，则会将当前线程添加到同步队列中阻塞等待。\n\n再来看一下令牌归还的过程，Semaphore 同样提供了多个版本的 `Semaphore#release` 方法实现，包括：\n\n- `Semaphore#release()`：归还 1 个令牌。\n- `Semaphore#release(int)`：归还指定数目的令牌。\n\n下面以 `Semaphore#release()` 方法为例分析一下令牌归还的执行过程，实现如下：\n\n```java\npublic void release() {\n    sync.releaseShared(1);\n}\n```\n\n上述方法直接委托给 AQS 的 `AbstractQueuedSynchronizer#releaseShared` 方法执行，归还令牌单位为 1。前面在分析 AQS 时同样已经介绍了该方法的运行机制，下面重点来看一下 Sync 对于模板方法 `AbstractQueuedSynchronizer#tryReleaseShared` 的实现：\n\n```java\nprotected final boolean tryReleaseShared(int releases) {\n    for (; ; ) {\n        // 获取 state 状态值\n        int current = this.getState();\n        // 计算释放之后剩余的资源数\n        int next = current + releases;\n        if (next < current) { // overflow\n            // 溢出\n            throw new Error(\"Maximum permit count exceeded\");\n        }\n        // 更新 state 状态值\n        if (this.compareAndSetState(current, next)) {\n            return true;\n        }\n    }\n}\n```\n\n令牌归还的执行过程如上述代码注释，比较简单，但是有一点疑问的是什么情况下 next 值会溢出？\n\n一般来说线程在归还令牌之前必须先申请令牌，这样就能够保证空闲令牌的数量始终不会大于我们在构造 Semaphore 时指定的初始值，然而在上述方法实现中，我们并没有看到有任何逻辑限定在调用 `Semaphore#release` 方法之前必须调用 `Semaphore#acquire` 方法。实际上 Semaphore 在实现时也的确没有添加这一限制，也就说任何线程都可以调用 `Semaphore#release` 方法归还令牌，即使它之前从来没有申请过令牌，这样就会导致令牌的数量溢出。官方文档中有如下说明：\n\n> There is no requirement that a thread that releases a permit must have acquired that permit by calling {@link #acquire}. Correct usage of a semaphore is established by programming convention in the application.\n\n也就是说，Semaphore 并不要求线程在归还令牌之前一定要先申请获取令牌，具体由应用程序自己决定。\n\n### 总结\n\n本文我们分析了 Semaphore 信号量的设计与实现，了解到 Semaphore 同样是基于 AQS 实现的同步器组件。Semaphore 通过令牌机制以限定参与的线程在同一时间执行的线程数目不能超过令牌的个数，在语义和实现上都比较简单，但功能却很强大。最后还需要注意的一点就是，Semaphore 并不要求在归还令牌之前一定要先申请获取令牌，开发者可以结合自身业务逻辑来灵活应用这一点。\n\n### 参考\n\n1. JDK 1.8 源码\n2. [The java.util.concurrent Synchronizer Framework](https://www.sciencedirect.com/science/article/pii/S0167642305000663)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：CyclicBarrier","url":"/2018/09/03/java/juc-cyclic-barrier/","content":"\n上一篇我们分析了 CountDownLatch 同步器的设计与实现，在日常开发中还有另外一个同步器组件 CyclicBarrier 常常令我们容易混淆。在文章 [理清 CountDownLatch 与 CyclicBarrier 的区别](/2015/11/05/java/latch-and-barrier/) 中我们曾经总结过二者的区别，并通过示例演示了各自的应用场景。上一篇，我们分析了 CountDownLatch 的实现原理，本文我们继续从源码层面来分析 CyclicBarrier 的设计与实现。<!-- more -->\n\n### CyclicBarrier 实现内幕\n\n前面介绍的 CountDownLatch 同步器是基于 AQS 实现的，而本文要介绍的 CyclicBarrier 则没有直接继承 AQS 的 AbstractQueuedSynchronizer 抽象类，而是基于 ReentrantLock 锁进行实现。首先来看一下 CyclicBarrier 的字段定义，如下：\n\n```java\npublic class CyclicBarrier {\n\n    /** 支撑 CyclicBarrier 的重入锁 */\n    private final ReentrantLock lock = new ReentrantLock();\n    /** 条件队列，已经到达屏障的线程会在条件队列中等待其它线程 */\n    private final Condition trip = lock.newCondition();\n    /** 参与的线程数 */\n    private final int parties;\n    /** 当所有线程都到达屏障时的回调函数 */\n    private final Runnable barrierCommand;\n    /** 当前年代对象 */\n    private Generation generation = new Generation();\n    /** 当前剩余未完成的线程数 */\n    private int count;\n\n    // ... 省略方法定义\n\n}\n```\n\n上述各个字段的含义如代码注释，这里我们进一步解释一下 generation 字段，该字段为 Generation 类型，用于表示当前 CyclicBarrier 同步器的年代信息。Generation 内部类定义如下：\n\n```java\nprivate static class Generation {\n    boolean broken = false;\n}\n```\n\n当新建一个 CyclicBarrier 对象时会初始化 `CyclicBarrier#generation` 字段。此外，当所有参与的线程都到达屏障后（也称 tripped），或者 CyclicBarrier 被重置（即调用 `CyclicBarrier#reset` 方法）时，会新建一个 Generation 对象赋值给 `CyclicBarrier#generation` 字段，表示年代的更替。\n\nGeneration 定义的 `Generation#broken` 属性用于标识当前屏障是否被打破。当 CyclicBarrier 被重置，或者参与到该屏障的某个线程被中断、等待超时，亦或是执行回调函数发生异常，都会导致屏障被打破。破损的屏障（即 `broken=true`）会导致当前参与等待的线程，以及已经处于等待状态的线程抛出 BrokenBarrierException 异常，并退出当前屏障进程。\n\n因为 CyclicBarrier 的复用性，导致在程序运行期间可能并存多个年代信息，但是任何时刻只有一个年代对象是活跃的，剩余的年代对象对应的 CyclicBarrier 要么是已经用完的（tripped），要么就是已经破损的。\n\n介绍完了字段定义，下面来分析一下 CyclicBarrier 的方法实现，首先来看一下构造方法。CyclicBarrier 定义了两个构造方法，实现如下：\n\n```java\npublic CyclicBarrier(int parties) {\n    this(parties, null);\n}\n\npublic CyclicBarrier(int parties, Runnable barrierAction) {\n    if (parties <= 0) {\n        throw new IllegalArgumentException();\n    }\n    this.parties = parties;\n    this.count = parties;\n    this.barrierCommand = barrierAction;\n}\n```\n\n其中 parties 参数用于指定当前参与的线程数，参数 barrierAction 用于指定当所有参与的线程都到达屏障时的回调逻辑。你可能有些疑问，既然设置了 parties 字段，为什么还要设置一个 count 字段呢？\n\n考虑 CyclicBarrier 是可重用的，所以需要有一个字段记录参与线程的数目，即 parties 字段，而 count 字段初始值等于 parties 字段值，但是在运行期间其值是会随着参与线程逐一到达屏障而递减的，所以 count 值始终记录的是当前未到达屏障的线程数。当 CyclicBarrier 被重置时，我们需要依据 parties 字段值来重置 count 字段值。\n\n继续来看一下 CyclicBarrier 除构造方法以外的剩余方法实现，主要分析一下 `CyclicBarrier#await` 方法和 `CyclicBarrier#reset` 方法。首先来看一下 `CyclicBarrier#reset` 方法，当我们希望复用 CyclicBarrier 对象时可以调用该方法，用于重置 count 值、年代信息，并唤醒所有位于条件队列中等待的线程。方法实现如下：\n\n```java\npublic void reset() {\n    final ReentrantLock lock = this.lock;\n    lock.lock();\n    try {\n        this.breakBarrier();   // break the current generation\n        this.nextGeneration(); // start a new generation\n    } finally {\n        lock.unlock();\n    }\n}\n\nprivate void breakBarrier() {\n    // 标识当前屏障被打破\n    generation.broken = true;\n    // 重置 count 字段值\n    count = parties;\n    // 唤醒所有等待的线程\n    trip.signalAll();\n}\n\nprivate void nextGeneration() {\n    // 唤醒所有等待的线程\n    trip.signalAll();\n    // 重置 count 值\n    count = parties;\n    generation = new Generation();\n}\n```\n\n再来看一下 `CyclicBarrier#await` 方法，该方法用于阻塞当前线程，以在屏障处等待其它线程到达，CyclicBarrier 还为该方法定义了超时等待版本。当一个线程因调用 `CyclicBarrier#await` 方法进入等待状态时，该线程将会在满足以下条件之一时退出等待状态：\n\n1. 所有参与的线程都已经到达了屏障。\n2. 当前线程被中断，或者其它处于等待状态的线程被中断。\n3. 如果启用了超时机制，并且某个参与的线程等待超时。\n4. CyclicBarrier 被重置。\n\n方法  `CyclicBarrier#await` 的普通版本和超时版本在实现上都是直接委托给 `CyclicBarrier#dowait` 方法执行，所以下面主要来分析一下该方法，实现如下：\n\n```java\nprivate int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException {\n    final ReentrantLock lock = this.lock;\n    // 加锁\n    lock.lock();\n    try {\n        // 获取当前年代信息\n        final Generation g = generation;\n\n        // 当前屏障被打破，抛出异常\n        if (g.broken) {\n            throw new BrokenBarrierException();\n        }\n\n        // 当前线程被中断，打破屏障，并唤醒所有等待的线程\n        if (Thread.interrupted()) {\n            this.breakBarrier();\n            throw new InterruptedException();\n        }\n\n        int index = --count;\n        // 如果 count 值为 0，说明所有的线程都已经到达屏障\n        if (index == 0) {  // tripped\n            boolean ranAction = false;\n            try {\n                // 如果设置了回调，则执行\n                final Runnable command = barrierCommand;\n                if (command != null) {\n                    command.run();\n                }\n                ranAction = true;\n                // 唤醒所有等待的线程，并重置屏障\n                this.nextGeneration();\n                return 0;\n            } finally {\n                // 如果执行回调异常\n                if (!ranAction) {\n                    this.breakBarrier();\n                }\n            }\n        }\n\n        // count 值不为 0，说明存在还未到达屏障的线程，则进入条件队列等待\n\n        // loop until tripped, broken, interrupted, or timed out\n        for (; ; ) {\n            try {\n                if (!timed) {\n                    // 进入条件队列等待\n                    trip.await();\n                } else if (nanos > 0L) {\n                    // 进入条件队列超时等待\n                    nanos = trip.awaitNanos(nanos);\n                }\n            } catch (InterruptedException ie) {\n                // 当前线程被中断，响应中断\n                if (g == generation && !g.broken) {\n                    this.breakBarrier();\n                    throw ie;\n                } else {\n                    // We're about to finish waiting even if we had not been interrupted,\n                    // so this interrupt is deemed to \"belong\" to subsequent execution.\n                    Thread.currentThread().interrupt();\n                }\n            }\n\n            // 屏障被打破\n            if (g.broken) {\n                throw new BrokenBarrierException();\n            }\n\n            // 当前 CyclicBarrier 已经被重置\n            if (g != generation) {\n                return index;\n            }\n\n            // 等待超时\n            if (timed && nanos <= 0L) {\n                this.breakBarrier();\n                throw new TimeoutException();\n            }\n        }\n    } finally {\n        // 释放锁\n        lock.unlock();\n    }\n}\n```\n\n由上述实现我们可以总结线程在调用 `CyclicBarrier#await` 方法时的整体执行流程。如果当前线程不是最后一个到达屏障的线程（递减 count 值之后仍然大于 0），则调用 `Condition#await` 方法（或超时版本）将当前线程添加到条件队列中等待。如果当前线程是最后一个到达屏障的线程（递减 count 值之后为 0），则在线程到达屏障后执行：\n\n1. 如果指定了回调逻辑，则执行该回调，如果期间发生任何异常，则打破屏障、重置 count 值，并唤醒条件队列中所有等待的线程；\n2. 否则，继续调用 `CyclicBarrier#nextGeneration` 方法唤醒条件队列中所有等待的线程，并重置 count 值和年代信息。\n\n在上述过程中如果当前线程或处于等待状态的线程被中断、屏障被打破、年代信息发生变化，或者等待超时（如果允许的话），则线程将会从 `Condition#await` 方法中退出，即当前屏障失效。\n\n### 总结\n\n最后总结一下，CyclicBarrier 在实现上虽然没有直接基于 AQS，但是组合了 ReentrantLock 锁，所以我们仍然可以将其视为基于 AQS 的同步器实现。CyclicBarrier 在被构造时需要指定参与的线程数目，当参与的线程调用 `CyclicBarrier#await` 方法时，如果该线程不是最后一个到达屏障的线程，则会将其打入条件队列进行等待。当参与的最后一个线程到达屏障时，该线程会唤醒所有在屏障前面等待的线程继续往下执行。\n\nCyclicBarrier 和 CountDownLatch 虽然都采用了计数器机制，但是区别在于，CountDownLatch 的计数器是由其它线程操作减值的，这些操作的线程在操作完成之后仍然会继续往下执行，并不会参与等待；而 CyclicBarrier 的计数器是由参与等待的线程操作减值的，这些线程在操作完成之后后在屏障前面阻塞等待。所以最终的表象就是 CountDownLatch 在等待其它线程操作完成，而 CyclicBarrier 在相互等待彼此操作完成。\n\n### 参考\n\n1. JDK 1.8 源码\n2. [The java.util.concurrent Synchronizer Framework](https://www.sciencedirect.com/science/article/pii/S0167642305000663)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：CountDownLatch","url":"/2018/08/31/java/juc-count-down-latch/","content":"\nCountDownLatch 是一个同步辅助工具，用于阻塞当前一个或多个线程以等待其它线程中的操作完成。在构造 CountDownLatch 对象时，我们需要指定一个非负的 count 值，一般情况下，调用 `CountDownLatch#await` 方法的线程需要阻塞等待该 count 值变为 0 时才能够继续往下执行。具体示例可以参考 [理清 CountDownLatch 与 CyclicBarrier 的区别](/2015/11/05/java/latch-and-barrier/)。<!-- more -->\n\n### CountDownLatch 实现内幕\n\nCountDownLatch 在实现上同样依赖于 AQS 组件，在 CountDownLatch 的内部定义了一个 Sync 内部类，该类继承自 AbstractQueuedSynchronizer，并复用 AQS 的 state 字段以记录 count 值的变化。CountDownLatch 的核心方法均委托 Sync 进行处理，实现如下：\n\n```java\npublic class CountDownLatch {\n\n    private final Sync sync;\n\n    public CountDownLatch(int count) {\n        if (count < 0) {\n            throw new IllegalArgumentException(\"count < 0\");\n        }\n        this.sync = new Sync(count);\n    }\n\n    public void await() throws InterruptedException {\n        sync.acquireSharedInterruptibly(1);\n    }\n\n    public boolean await(long timeout, TimeUnit unit) throws InterruptedException {\n        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));\n    }\n\n    public void countDown() {\n        sync.releaseShared(1);\n    }\n\n    public long getCount() {\n        return sync.getCount();\n    }\n\n}\n```\n\n下面我们主要分析一下 `CountDownLatch#await` 和 `CountDownLatch#countDown` 方法的实现。\n\n首先来看一下 `CountDownLatch#await` 方法，该方法用于阻塞当前线程，直到 count 值变为 0，或者被其它线程中断。具体实现上，CountDownLatch 直接将请求委托给 AQS 的 `AbstractQueuedSynchronizer#acquireSharedInterruptibly` 方法进行处理，所以我们下面主要来看一下 CountDownLatch 针对模板方法 `AbstractQueuedSynchronizer#tryAcquireShared` 的实现，如下：\n\n```java\nprotected int tryAcquireShared(int acquires) {\n    return (getState() == 0) ? 1 : -1;\n}\n```\n\n实现上非常简单，获取并判定状态值是否为 0，如果是则说明当前线程获取资源成功，能够继续往下执行，否则说明当前线程获取资源失败，需要被添加到同步队列阻塞等待。CountDownLatch 还为 `CountDownLatch#await` 方法定义了超时版本 `CountDownLatch#await(long, TimeUnit)`。\n\n继续来看一下 `CountDownLatch#countDown` 方法，该方法用于将 count 值减 1，如果发现 count 值变为 0，则唤醒阻塞等待的线程。具体实现上，CountDownLatch 同样直接将请求委托给 AQS 的 `AbstractQueuedSynchronizer#releaseShared` 方法进行处理，所以我们下面主要来看一下 CountDownLatch 针对模板方法 `AbstractQueuedSynchronizer#tryReleaseShared` 的实现，如下：\n\n```java\nprotected boolean tryReleaseShared(int releases) {\n    // Decrement count; signal when transition to zero\n    for (; ; ) {\n        // 获取 state 状态值\n        int c = getState();\n        // 如果已经为 0 则说明没有资源可以释放，直接返回 false，避免 state 变为负值\n        if (c == 0) {\n            return false;\n        }\n        // 资源数减 1\n        int nextc = c - 1;\n        if (compareAndSetState(c, nextc)) {\n            // 如果为 0，则说明资源全部释放完毕，此时需要唤醒等待的线程\n            return nextc == 0;\n        }\n    }\n}\n```\n\n具体实现如代码注释，比较简单。需要注意的一点就是上面步骤中的判 0 操作，刚开始看的时候可能觉得有点多余，但是这一步的主要作用在于保证 state 值不会变为负值。当前 count 值变为 0 时，上述方法会返回 true，接下去 AQS 会执行唤醒之前因为 count 值不为 0 而被打入同步队列的线程。\n\n### 总结\n\nCountDownLatch 的实现机制到此就分析完了，因为依赖于 AQS，所以 CountDownLatch 在实现上变得十分简单，但是功能却很强大。下一篇我们将要分析与 CountDownLatch 极为容易混淆的 CyclicBarrier 组件，从实现层面去理清二者的区别。\n\n### 参考\n\n1. JDK 1.8 源码\n2. [The java.util.concurrent Synchronizer Framework](https://www.sciencedirect.com/science/article/pii/S0167642305000663)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：ReentrantReadWriteLock","url":"/2018/08/31/java/juc-reentrant-read-write-lock/","content":"\n上一篇我们分析了 ReentrantLock 锁的设计与实现，对于大部分并发场景来说已经能够满足同步加锁的需求，但是相对于本文将要介绍的 ReentrantReadWriteLock 锁而言，ReentrantLock 主要存在的不足在于不区分读操作和写操作。考虑读多写少的场景，如果将读操作和写操作一视同仁的对待，那么线程之间读操作是互斥的，同一时间只允许一个线程读取数据，势必会影响系统的吞吐性能，并且读操作并不会导致数据的不一致性，这种情况下应该允许多个线程对同一份数据执行并发读取。<!-- more -->\n\nReentrantReadWriteLock 锁在设计上认识到了 ReentrantLock 锁在读多写少场景下的不足，于是分别设计了读锁和写锁，在满足同步加锁需求的基础上支持读锁能够同时被多个线程持有。ReentrantReadWriteLock 锁的特性包括：\n\n1. 读锁和写锁均是可重入的，并允许多个不同线程同时持有读锁。\n2. 对于不同线程而言，读锁与写锁之间是互斥的，写锁与写锁之间也是互斥的。\n3. 对于相同线程而言，在获取到写锁的前提下，仍然可以获取读锁，反之则不行。\n4. 支持公平锁机制，默认为非公平锁。\n\n关于读写锁不同加锁顺序对应的表现概括如下表：\n\n\\- | 先获取 | 再获取 | 表现\n--- | --- | --- | ---\n相同线程 | read lock | read lock | 重入\n相同线程 | write lock | write lock | 重入\n相同线程 | write lock | read lock | 重入\n相同线程 | read lock | write lock | 死锁\n不同线程 | read lock | read lock | 重入\n不同线程 | write lock | write lock | 互斥\n不同线程 | write lock | read lock | 互斥\n不同线程 | read lock | write lock | 互斥\n\n__思考__ ：对于同一个线程而言，为什么在获取到读锁的前提下再去获取写锁会出现死锁？\n\n我们将这种在获取到读锁的情况下再去获取写锁的操作称为锁升级（不太严谨，需要与 synchronized 关键字中锁升级（膨胀）的过程相区分）。之所以 ReentrantReadWriteLock 不允许锁升级操作，首先我们需要再次明确一下 ReentrantReadWriteLock 的基本特性，即读锁能够被多个线程同时持有，但是写锁在同一时间只能被同一个线程持有，并且读锁和写锁对于不同线程而言是互斥的。设想当前有多个线程持有读锁，如果允许锁升级则这些线程在执行过程中都会尝试去获取写锁，其结果必然只能是其中一个线程获取写锁成功，又对于不同线程而言获取读写锁是互斥的，那么此时这些持有读锁的线程将如何处理自己手中持有的读锁对象呢？所以 ReentrantReadWriteLock 的解决方案是直接禁止锁升级行为。然而，作为 ReentrantReadWriteLock 增强版的 StampedLock 则支持由读锁到写锁的切换，关于 StampedLock 的实现原理我们以后再进行分析。\n\n### ReentrantReadWriteLock 示例\n\n在开始分析 ReentrantReadWriteLock 的实现内幕之前，我们先以官方示例来回忆一下 ReentrantReadWriteLock 的基本使用，具体实现如下（做了一些小小的改动）：\n\n```java\nprivate Object data;\nprivate volatile boolean cacheInvalid = true;\n\nprivate final ReadWriteLock lock = new ReentrantReadWriteLock();\nprivate final Lock readLock = lock.readLock();\nprivate final Lock writeLock = lock.writeLock();\n\nvoid processCachedData() {\n    readLock.lock();\n    if (cacheInvalid) {\n        readLock.unlock(); // 在获取写锁之前必须释放读锁，否则会造成死锁\n        writeLock.lock();\n        try {\n            // 再次校验状态，考虑其它线程可能已经初始化了缓存数据\n            if (cacheInvalid) {\n                // 初始化缓存数据\n                data = new Object();\n                cacheInvalid = false;\n            }\n            // 获取读锁，在持有写锁的情况下，同一个线程仍然可以获取读锁\n            readLock.lock();\n        } finally {\n            // 释放写锁\n            writeLock.unlock();\n        }\n    }\n\n    try {\n        // 使用缓存数据\n        this.use(data);\n    } finally {\n        // 释放读锁\n        readLock.unlock();\n    }\n}\n```\n\n线程在读取缓存数据 data 之前需要获取读锁（ReadLock），如果判断缓存数据 data 未被初始化，则尝试获取写锁（WriteLock）以初始化缓存数据。因为读锁是共享的，所有上述示例允许多个线程并发读取 data 数据，但是一旦某个线程检测到 data 未被初始化，则尝试获取写锁并更新缓存数据，期间其它线程需要阻塞等待初始化过程的完成。\n\n上述示例还暗含了一个 __锁降级__ 的过程，我们将 __在持有写锁的前提下获取到读锁，然后再释放写锁的过程称为锁降级（先释放写锁再获取读锁的过程并不能称为锁降级）__ 。那么锁降级操作的意义何在呢？简单而言，锁降级通过不同线程间获取读写锁的互斥性，实现当前线程在对数据进行修改之后能够读取到修改后的值，保证期间数据不会被其它线程所更改。\n\n以上述示例为例，当线程完成对缓存数据 data 的更新之后，并没有立即释放写锁，而是先获取到了读锁后再释放写锁，这样就能够避免期间其它线程因为获取到写锁而更新缓存数据。下面对上述示例稍作修改以演示锁降级策略，调度程序如下：\n\n```java\nprivate final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();\nprivate final Lock readLock = lock.readLock();\nprivate final Lock writeLock = lock.writeLock();\n\nprivate volatile boolean cacheInvalid = true;\nprivate int value = 0;\n\n@Test\npublic void testDowngrade() throws Exception {\n    CountDownLatch start = new CountDownLatch(1);\n    CountDownLatch stop = new CountDownLatch(2);\n    final Thread ta = new Thread(new DowngradeTask(start, stop, 1L), \"A\");\n    final Thread tb = new Thread(new DowngradeTask(start, stop, 2L), \"B\");\n    ta.start();\n    tb.start();\n    start.countDown();\n    stop.await();\n}\n\nprivate class DowngradeTask implements Runnable {\n\n    private final CountDownLatch start;\n    private final CountDownLatch stop;\n    private final long sleepSecs;\n\n    public DowngradeTask(CountDownLatch start, CountDownLatch stop, long sleepSecs) {\n        this.start = start;\n        this.stop = stop;\n        this.sleepSecs = sleepSecs;\n    }\n\n    @Override\n    public void run() {\n        try {\n            start.await();\n            TimeUnit.SECONDS.sleep(sleepSecs);\n            System.out.println(\"<thread-\" + Thread.currentThread().getName() + \"> start to run after \" + sleepSecs + \" seconds\");\n            cacheInvalid = true;\n            // processCachedDataWithoutDowngrade(RandomUtils.nextInt(1, 100));\n            processCachedDataWithDownGrade(RandomUtils.nextInt(1, 100));\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            stop.countDown();\n        }\n    }\n\n}\n```\n\n如果不使用锁降级策略，即先释放写锁再获取读锁，对应的实现如下：\n\n```java\nprivate void processCachedDataWithoutDowngrade(int newValue) {\n    readLock.lock();\n    if (cacheInvalid) {\n        readLock.unlock();\n        writeLock.lock();\n        try {\n            if (cacheInvalid) {\n                value = newValue;\n                System.out.println(\"<thread-\" + Thread.currentThread().getName() + \"> update value as \" + value);\n                cacheInvalid = true;\n            }\n        } finally {\n            writeLock.unlock();\n        }\n    }\n    try {\n        /*\n         * 模拟处理数据的过程，期间 cacheInvalid 可能会被其它线程修改以期望修改数据，\n         * 没有锁降级保证，其它线程期间可能获取到写锁并更改数据，导致当前线程之前看到的数据发生变化\n         */\n        TimeUnit.SECONDS.sleep(5);\n        System.out.println(\"<thread-\" + Thread.currentThread().getName() + \"> read value is \" + value);\n    } catch (InterruptedException e) {\n        e.printStackTrace();\n    } finally {\n        if (lock.getReadHoldCount() > 0) {\n            readLock.unlock();\n        }\n    }\n}\n```\n\n执行结果如下：\n\n```text\n<thread-A> start to run after 1 seconds\n<thread-A> update value as 11\n<thread-B> start to run after 2 seconds\n<thread-B> update value as 12\n<thread-A> read value is 12\n<thread-B> read value is 12\n```\n\n上述代码因为在处理缓存数据之前释放了写锁，所以期间可能会出现写锁被其它线程持有的情况，进而对数据进行修改，最终导致当前线程看到的数据状态发生了变化。\n\n如果在释放写锁之前先持有写锁，即采用锁降级策略，则能够避免此类问题，实现如下：\n\n```java\nprivate void processCachedDataWithDownGrade(int newValue) {\n    readLock.lock();\n    if (cacheInvalid) {\n        readLock.unlock();\n        writeLock.lock();\n        try {\n            if (cacheInvalid) {\n                value = newValue;\n                System.out.println(\"<thread-\" + Thread.currentThread().getName() + \"> update value as \" + value);\n                cacheInvalid = false;\n                // 锁降级，在释放写锁之前先获取读锁\n                readLock.lock();\n            }\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    try {\n        /*\n         * 模拟处理数据的过程，期间 cacheInvalid 可能会被其它线程修改以期望修改数据，\n         * 因为有锁降级保证，其它线程期间尝试获取写锁的请求会被阻塞，所以当前线程之前看到的数据不会变化\n         */\n        TimeUnit.SECONDS.sleep(5);\n        System.out.println(\"<thread-\" + Thread.currentThread().getName() + \"> read value is \" + value);\n    } catch (InterruptedException e) {\n        e.printStackTrace();\n    } finally {\n        if (lock.getReadHoldCount() > 0) {\n            readLock.unlock();\n        }\n    }\n}\n```\n\n执行结果如下：\n\n```text\n<thread-A> start to run after 1 seconds\n<thread-A> update value as 43\n<thread-B> start to run after 2 seconds\n<thread-A> read value is 43\n<thread-B> update value as 48\n<thread-B> read value is 48\n```\n\n因为对于不同线程来说，获取读锁和写锁是互斥的，所以锁降级能够保证在当前线程处理完缓存数据之前，其它线程尝试获取写锁的请求都会被阻塞，所以当前线程看到的数据状态不会被更改。\n\n### ReentrantReadWriteLock 实现内幕\n\n下面来分析一下 ReentrantReadWriteLock 的设计与实现，ReentrantReadWriteLock 在设计上并没有直接实现 Lock 接口，而是实现了 ReadWriteLock 接口，该接口定义了返回读锁和写锁对象的方法，如下：\n\n```java\npublic interface ReadWriteLock {\n    Lock readLock();\n    Lock writeLock();\n}\n```\n\nReentrantReadWriteLock 在内部定义了 ReadLock 和 WriteLock 两个内部类，用于分别表示读锁和写锁，ReadLock 和 WriteLock 均实现自 Lock 接口。与 ReentrantLock 一样，ReentrantReadWriteLock 也支持公平锁（FairSync）与非公平锁（NonfairSync）机制，并且允许在构造 ReentrantReadWriteLock 对象时通过参数指定是否使用公平锁，默认使用非公平锁。\n\nFairSync 和 NonfairSync 均派生自 Sync 抽象类，该抽象类继承自 AbstractQueuedSynchronizer，这一点设计上与 ReentrantLock 如出一辙。Sync 类的字段定义和部分基础方法实现如下：\n\n```java\nabstract static class Sync extends AbstractQueuedSynchronizer {\n\n    static final int SHARED_SHIFT = 16;\n    /** 共享锁（读锁）单位值 */\n    static final int SHARED_UNIT = (1 << SHARED_SHIFT);\n    /** 共享锁（读锁）最大线程数 */\n    static final int MAX_COUNT = (1 << SHARED_SHIFT) - 1;\n\n    /** 独占锁（写锁）掩码 */\n    static final int EXCLUSIVE_MASK = (1 << SHARED_SHIFT) - 1;\n\n    /** 读锁线程数目 */\n    static int sharedCount(int c) { return c >>> SHARED_SHIFT; }\n\n    /** 写锁重入次数 */\n    static int exclusiveCount(int c) { return c & EXCLUSIVE_MASK; }\n\n    /** 记录各个线程（除第 1 个）获取读锁的重入次数 */\n    private transient ThreadLocalHoldCounter readHolds;\n\n    /** 最近 1 次获取到读锁的线程计数器 */\n    private transient HoldCounter cachedHoldCounter;\n\n    /** 记录第 1 个获取到读锁的线程 */\n    private transient Thread firstReader = null;\n    /** 记录第 1 个获取到读锁的线程重入次数 */\n    private transient int firstReaderHoldCount;\n\n    // ... 省略方法定义\n\n}\n```\n\nReentrantReadWriteLock 复用 AQS 的 state 字段以记录线程的重入次数，区别于 ReentrantLock 锁，因为区分了读锁和写锁，ReentrantReadWriteLock 将 state 字段由中间分割成了两段，其中高位区间（16 位）用于记录持有读锁的线程数（重入则累加），低位区间（16 位）用于记录写锁的重入次数。\n\n前面在分析 AQS 同步队列的 Node 内部类定义时，介绍了结点分为共享（SHARED）和独占（EXCLUSIVE）两种模式。对应到 ReentrantReadWriteLock，我们可以认为读锁是共享的，而写锁是独占的，同一时间读锁能够被多个线程持有，而写锁只能被一个线程持有。Sync 定义了 `Sync#sharedCount` 和 `Sync#exclusiveCount` 方法，分别用于获取读锁线程重入次数和写锁线程重入次数。\n\n属性 `Sync#readHolds` 用于记录除第 1 个获取到读锁的线程外的剩余线程的重入次数，类型为 ThreadLocalHoldCounter。ThreadLocalHoldCounter 类继承自 ThreadLocal，实现如下：\n\n```java\nstatic final class ThreadLocalHoldCounter extends ThreadLocal<HoldCounter> {\n    @Override\n    public HoldCounter initialValue() {\n        return new HoldCounter();\n    }\n}\n\nstatic final class HoldCounter {\n    int count = 0; // 重入次数\n    // Use id, not reference, to avoid garbage retention\n    final long tid = getThreadId(Thread.currentThread()); // 线程 ID\n}\n```\n\nThreadLocalHoldCounter 覆盖实现了 `ThreadLocal#initialValue` 方法，当某个线程第一次访问 `Sync#readHolds` 属性时会为该线程创建一个 HoldCounter 对象（下文简称线程计数器），用于记录当前线程 ID 和重入次数。\n\n属性 `Sync#cachedHoldCounter` 为 HoldCounter 类型，用于记录最近一次获取到读锁的线程计数器对象，其目的是为了提升 ReadLock 的性能，因为大多数时候调用 `ReadLock#unlock` 方法释放锁资源的线程就是刚刚（即最近一次）调用 `ReadLock#lock` 方法获取锁资源的线程，引入 `Sync#cachedHoldCounter` 字段能够快速获取该线程的计数器对象，避免从 `Sync#readHolds` 中查找。\n\n属性 `Sync#firstReader` 和 `Sync#firstReaderHoldCount` 用于记录首次获取到读锁的线程对象和该线程重入读锁的次数。之所以要设计这样两个字段，同样是为了性能的考量，考虑只有一个线程加锁的场景，此时引入这两个字段就能避免为该线程创建一个 HoldCounter 计数器对象，同时也就避免了从 `Sync#readHolds` 中查找\n\n#### 读锁：ReadLock\n\n本小节来分析一下 ReadLock 的实现机制。ReadLock 实现自 Lock 接口，针对接口方法的实现均委托给 Sync 对象执行。下面首先来看一下 `ReadLock#tryLock()` 方法，之前的文章中我们已经介绍过 Lock 接口的 `Lock#tryLock()` 方法用于尝试获取锁资源，不管获取成功与否该方法都会立即返回，如果获取成功则返回 true，否则返回 false。ReadLock 在实现该方法时直接调用了 Sync 的 `Sync#tryReadLock` 方法，实现如下：\n\n```java\n// ReadLock#tryLock()\npublic boolean tryLock() {\n    return sync.tryReadLock();\n}\n\n// Sync#tryReadLock\nfinal boolean tryReadLock() {\n    // 获取当前线程对象\n    Thread current = Thread.currentThread();\n    for (; ; ) {\n        // 获取 state 状态值\n        int c = this.getState();\n        // 如果写锁被其它线程持有，则立即返回 false\n        if (exclusiveCount(c) != 0 && this.getExclusiveOwnerThread() != current) {\n            return false;\n        }\n        // 获取读锁重入次数\n        int r = sharedCount(c);\n        if (r == MAX_COUNT) {\n            // 读锁重入次数已达上限\n            throw new Error(\"Maximum lock count exceeded\");\n        }\n        // 基于 CAS 操作更新 state 状态值\n        if (this.compareAndSetState(c, c + SHARED_UNIT)) {\n            // 读锁被首次被获取\n            if (r == 0) {\n                firstReader = current; // 记录第 1 个获取到读锁的线程\n                firstReaderHoldCount = 1; // 记录第 1 个获取到读锁的线程重入次数\n            }\n            // 首个获取该读锁的线程是当前线程，更新线程的重入次数\n            else if (firstReader == current) {\n                firstReaderHoldCount++;\n            }\n            // 当前线程不是首个获取该读锁的线程，更新计数器\n            else {\n                // 最近 1 次获取到读锁的线程计数器\n                HoldCounter rh = cachedHoldCounter;\n                // 当前记录的最近 1 次获取到读锁的线程不是当前线程，则更新 cachedHoldCounter 计数器\n                if (rh == null || rh.tid != getThreadId(current)) {\n                    cachedHoldCounter = rh = readHolds.get();\n                }\n                // 当前线程是最近 1 次获取到读锁的线程\n                else if (rh.count == 0) {\n                    readHolds.set(rh);\n                }\n                // 线程重入次数加 1\n                rh.count++;\n            }\n            return true;\n        }\n    }\n}\n```\n\n尝试获取读锁资源的操作在拿到当前线程对象之后会基于 CAS 尝试修改 state 的值，具体执行过程可以概括为：\n\n1. 获取 ReentrantReadWriteLock 的 state 状态值；\n2. 如果当前 ReentrantReadWriteLock 的写锁已被其它线程持有，则返回 false，因为不同线程之间读锁与写锁之间是互斥的；\n3. 否则，获取当前 ReentrantReadWriteLock 读锁的线程重入次数，校验是否达到上限值（即 65535），如果是则抛出异常；\n4. 否则，基于 Unsafe 尝试更新 state 状态值，即将读锁重入次数加 1；\n5. 如果更新成功，则修改当前线程对应的计数器，失败则退回到步骤 1 继续重试。\n\n除了上面介绍的 `ReadLock#tryLock()` 方法，ReadLock 针对其它获取读锁资源的方法均委托给 AQS 执行，包括：\n\n- `ReadLock#lock`：直接调用 `AbstractQueuedSynchronizer#acquireShared` 方法，请求资源数为 1。\n- `ReadLock#lockInterruptibly`：直接调用 `AbstractQueuedSynchronizer#acquireSharedInterruptibly` 方法，请求资源数为 1。\n- `ReadLock#tryLock(long, TimeUnit)`：直接调用 `AbstractQueuedSynchronizer#tryAcquireSharedNanos` 方法，请求资源数为 1。\n\nAQS 针对上述方法的实现，我们在前面的文章中已经专门介绍过，这些方法均调用了模板方法 `AbstractQueuedSynchronizer#tryAcquireShared` 尝试获取读锁资源，Sync 类针对该模板方法的实现如下：\n\n```java\nprotected final int tryAcquireShared(int unused) {\n    /*\n     * Walkthrough:\n     * 1. If write lock held by another thread, fail.\n     * 2. Otherwise, this thread is eligible for lock wrt state, so ask if it should block because of queue policy.\n     *    If not, try to grant by CASing state and updating count.\n     *    Note that step does not check for reentrant acquires, which is postponed to full version\n     *    to avoid having to check hold count in the more typical non-reentrant case.\n     * 3. If step 2 fails either because thread apparently not eligible or CAS fails or count saturated,\n     *    chain to version with full retry loop.\n     */\n\n    // 获取当前线程对象\n    Thread current = Thread.currentThread();\n    // 获取 state 状态值\n    int c = this.getState();\n    // 如果写锁被其它线程持有，则立即返回 -1\n    if (exclusiveCount(c) != 0 && this.getExclusiveOwnerThread() != current) {\n        return -1;\n    }\n    // 获取持有读锁的线程数\n    int r = sharedCount(c);\n    if (!this.readerShouldBlock() // 对于公平锁，保证公平性，对于非公平锁，判断写锁是否被占用\n            && r < MAX_COUNT // 重入次数未达上限\n            && this.compareAndSetState(c, c + SHARED_UNIT)) { // 修改 state 状态值成功\n        // 读锁被首次被获取\n        if (r == 0) {\n            firstReader = current; // 记录第 1 个获取到读锁的线程\n            firstReaderHoldCount = 1; // 记录第 1 个获取到读锁的线程重入次数\n        }\n        // 首个获取该读锁的线程是当前线程，更新线程的重入次数\n        else if (firstReader == current) {\n            firstReaderHoldCount++;\n        }\n        // 当前线程不是首个获取该读锁的线程，更新计数器\n        else {\n            // 最近 1 次获取到读锁的线程计数器\n            HoldCounter rh = cachedHoldCounter;\n            // 当前记录的最近 1 次获取到读锁的线程不是当前线程，则更新 cachedHoldCounter 计数器\n            if (rh == null || rh.tid != getThreadId(current)) {\n                cachedHoldCounter = rh = readHolds.get();\n            } else if (rh.count == 0) {\n                readHolds.set(rh);\n            }\n            // 线程重入次数加 1\n            rh.count++;\n        }\n        return 1;\n    }\n\n    /*\n     * 执行到这里，需要满足以下条件之一：\n     * 1. 对于公平锁而言，前面有等待的线程，为了保证公平性，需要让前面的线程优先获取锁；\n     * 2. 对于非公平锁而言，写锁已经被持有；\n     * 3. 读锁重入次数达到上限\n     * 4. 更新 state 字段失败，说明期间有其它线程获取到锁对象（读锁、写锁）\n     */\n\n    // 继续尝试获取读锁，更多考虑一些重入的场景\n    return this.fullTryAcquireShared(current);\n}\n```\n\n上述方法尝试获取读锁资源的执行流程可以概括为：\n\n1. 获取当前线程对象和 state 状态值；\n2. 如果写锁已经被其它线程持有，则获取读锁失败，返回 -1；\n3. 如果写锁未被持有（非公平锁），或者当前没有排队等待获取锁的线程（公平锁），且读锁重入次数未达到上限，则尝试更新 state 字段，即重入次数加 1；\n4. 如果更新成功，则更新线程计数器；\n5. 如果更新不成功，或者 3 中的条件不满足，则继续执行 `Sync#fullTryAcquireShared` 方法尝试获取读锁。\n\n方法 `Sync#fullTryAcquireShared` 的实现逻辑与上述方法大同小易，区别在于引入了重试机制，主要用来处理 CAS 操作失败和线程重入的场景。之所以这样设计，主要还是考虑到性能上的需求，对于非重入的场景来说避免了查询线程计数器的开销。方法 `Sync#fullTryAcquireShared` 实现如下：\n\n```java\nfinal int fullTryAcquireShared(Thread current) {\n    /*\n     * This code is in part redundant with that in tryAcquireShared but is simpler overall by not\n     * complicating tryAcquireShared with interactions between retries and lazily reading hold counts.\n     */\n    HoldCounter rh = null;\n    for (; ; ) {\n        // 获取 state 状态值\n        int c = this.getState();\n        // 当前写锁已被持有\n        if (exclusiveCount(c) != 0) {\n            // 如果持有写锁的线程不是当前线程，则尝试加读锁失败\n            if (this.getExclusiveOwnerThread() != current) {\n                return -1;\n            }\n            // else we hold the exclusive lock; blocking here would cause deadlock.\n        }\n        // 对于公平锁而言，前面存在等待的线程\n        else if (this.readerShouldBlock()) {\n            // Make sure we're not acquiring read lock reentrantly\n            if (firstReader == current) {\n                // assert firstReaderHoldCount > 0;\n            } else {\n                // 更新计数器，如果当前线程未持有读锁，则移除计数器\n                if (rh == null) {\n                    rh = cachedHoldCounter;\n                    if (rh == null || rh.tid != getThreadId(current)) {\n                        rh = readHolds.get();\n                        if (rh.count == 0) {\n                            readHolds.remove();\n                        }\n                    }\n                }\n                if (rh.count == 0) {\n                    return -1;\n                }\n            }\n        }\n\n        /*\n         * 执行到这一步说明：\n         * 1. 写锁未被持有，或者持有写锁的线程是当前线程\n         * 2. 前面没有排队等待的线程，或者当前线程已经持有了读锁\n         */\n\n        // 读锁重入次数达到上限\n        if (sharedCount(c) == MAX_COUNT) {\n            throw new Error(\"Maximum lock count exceeded\");\n        }\n        // 修改读锁重入次数（加 1）\n        if (this.compareAndSetState(c, c + SHARED_UNIT)) {\n            if (sharedCount(c) == 0) {\n                firstReader = current;\n                firstReaderHoldCount = 1;\n            } else if (firstReader == current) {\n                firstReaderHoldCount++;\n            } else {\n                if (rh == null) {\n                    rh = cachedHoldCounter;\n                }\n                if (rh == null || rh.tid != getThreadId(current)) {\n                    rh = readHolds.get();\n                } else if (rh.count == 0) {\n                    readHolds.set(rh);\n                }\n                rh.count++;\n                cachedHoldCounter = rh; // cache for release\n            }\n            return 1;\n        }\n    }\n}\n```\n\n上述方法和前面分析的 `AbstractQueuedSynchronizer#tryAcquireShared` 方法均调用了 `Sync#readerShouldBlock` 方法用于判断当前获取读锁的线程是否应该阻塞。Sync 中仅仅声明了该方法，具体实现交由 FairSync 和 NonfairSync 子类实现，如下：\n\n```java\n// FairSync#readerShouldBlock\nfinal boolean readerShouldBlock() {\n    return this.hasQueuedPredecessors();\n}\n\n// NonfairSync#readerShouldBlock\nfinal boolean readerShouldBlock() {\n    return this.apparentlyFirstQueuedIsExclusive();\n}\nfinal boolean apparentlyFirstQueuedIsExclusive() {\n    Node h, s;\n    return (h = head) != null && (s = h.next) != null && !s.isShared() && s.thread != null;\n}\n```\n\nFairSync 在实现上通过调用 `AbstractQueuedSynchronizer#hasQueuedPredecessors` 方法判断同步队列中是否有排在前面等待获取锁的线程，如果有的话则让渡这些线程以保证锁的公平性。NonfairSync 在实现上则判断当前同步队列队头等待线程节点是否以 EXCLUSIVE 模式在等待，也就是在等待获取写锁，如果是则当前获取读锁的线程应该让渡获取写锁的线程。\n\nReadLock 释放读锁资源的方法 `ReadLock#unlock` 同样是直接委托给 AQS 处理，调用的是 `AbstractQueuedSynchronizer#releaseShared` 方法。AQS 通过调用模板方法 `AbstractQueuedSynchronizer#tryReleaseShared` 尝试释放共享资源，成功则返回 true。Sync 针对该模板方法的实现如下：\n\n```java\nprotected final boolean tryReleaseShared(int unused) {\n    // 获取当前线程对象\n    Thread current = Thread.currentThread();\n    // 如果当前线程是首个获取读锁的线程，则更新对应的重入次数\n    if (firstReader == current) {\n        // assert firstReaderHoldCount > 0;\n        if (firstReaderHoldCount == 1) {\n            firstReader = null;\n        } else {\n            firstReaderHoldCount--;\n        }\n    }\n    // 否则，修改线程计数器\n    else {\n        HoldCounter rh = cachedHoldCounter;\n        if (rh == null || rh.tid != getThreadId(current)) {\n            rh = readHolds.get();\n        }\n        int count = rh.count;\n        if (count <= 1) {\n            readHolds.remove();\n            if (count <= 0) {\n                throw this.unmatchedUnlockException();\n            }\n        }\n        --rh.count;\n    }\n\n    // 基于 CAS 修改 state 状态值\n    for (; ; ) {\n        int c = this.getState();\n        int nextc = c - SHARED_UNIT;\n        if (this.compareAndSetState(c, nextc)) {\n            /*\n             * Releasing the read lock has no effect on readers,\n             * but it may allow waiting writers to proceed if both read and write locks are now free.\n             */\n            return nextc == 0; // 如果 nextc 为 0，则说明当前锁（读锁、写锁）未被任何线程持有\n        }\n    }\n}\n```\n\n整体逻辑比较简单，如代码注释。\n\n#### 写锁：WriteLock\n\n本小节一起来分析一下 WriteLock 的实现机制。WriteLock 同样实现自 Lock 接口，针对接口方法的实现均委托给 Sync 对象执行。下面首先来看一下 `WriteLock#tryLock()` 方法，WriteLock 在实现该方法时直接调用了 `Sync#tryWriteLock` 方法，实现如下：\n\n```java\nfinal boolean tryWriteLock() {\n    // 获取当前线程对象\n    Thread current = Thread.currentThread();\n    // 获取 state 状态值\n    int c = this.getState();\n    // 如果不为 0，则说明当前锁（读锁、写锁）已被线程持有\n    if (c != 0) {\n        // 获取写锁的重入次数\n        int w = exclusiveCount(c);\n        if (w == 0 // 写锁重入次数为 0，说明读锁已被持有，获取写锁失败\n                || current != this.getExclusiveOwnerThread()) { // 写锁已经被其它线程持有，获取写锁失败\n            return false;\n        }\n        // 写锁重入次数达到上限\n        if (w == MAX_COUNT) {\n            throw new Error(\"Maximum lock count exceeded\");\n        }\n    }\n    // 更新写锁重入次数（加 1）\n    if (!this.compareAndSetState(c, c + 1)) {\n        return false;\n    }\n    // 记录当前持有写锁的线程对象\n    this.setExclusiveOwnerThread(current);\n    return true;\n}\n```\n\n尝试获取写锁的具体执行过程可以概括为：\n\n1. 获取当前线程对象和 state 状态值；\n2. 如果 state 状态值不为 0，则说明写锁或读锁已被线程持有；\n3. 如果是读锁被持有，则尝试获取写锁失败；否则，如果持有写锁的线程不是当前线程，则尝试获取写锁失败；\n4. 判断写锁重入次数是否达到上限（即 65535），如果是则抛出异常；\n5. 尝试修改写锁重入次数（加 1），修改成功即加锁成功，如果失败则返回 false，对于成功获取到写锁的线程对象需要予以记录，并返回 true；\n\n除了 `WriteLock#tryLock()` 方法，WriteLock 针对其它获取写锁资源的方法均委托给 AQS 执行，包括：\n\n- `WriteLock#lock`：直接调用 `AbstractQueuedSynchronizer#acquire` 方法，请求资源数为 1。\n- `WriteLock#lockInterruptibly`：直接调用 `AbstractQueuedSynchronizer#acquireInterruptibly` 方法，请求资源数为 1。\n- `WriteLock#tryLock(long, TimeUnit)`：直接调用 `AbstractQueuedSynchronizer#tryAcquireNanos` 方法，请求资源数为 1。\n\nAQS 针对上述方法的实现，我们同样在前面的文章中已经专门分析过，这些方法均调用了模板方法 `AbstractQueuedSynchronizer#tryAcquire` 尝试获取资源，Sync 类针对该模板方法的实现如下：\n\n```java\nprotected final boolean tryAcquire(int acquires) {\n    /*\n     * Walkthrough:\n     * 1. If read count nonzero or write count nonzero and owner is a different thread, fail.\n     * 2. If count would saturate, fail. (This can only happen if count is already nonzero.)\n     * 3. Otherwise, this thread is eligible for lock if it is either a reentrant acquire or\n     *    queue policy allows it. If so, update state and set owner.\n     */\n\n    // 获取当前线程对象\n    Thread current = Thread.currentThread();\n    // 获取 state 状态值\n    int c = this.getState();\n    // 获取写锁的重入次数\n    int w = exclusiveCount(c);\n    // 如果不为 0，则说明当前锁（读锁、写锁）已被线程持有\n    if (c != 0) {\n        // (Note: if c != 0 and w == 0 then shared count != 0)\n        if (w == 0 // 写锁重入次数为 0，说明读锁已被持有，获取写锁失败\n                || current != this.getExclusiveOwnerThread()) { // 写锁已经被其它线程持有，获取写锁失败\n            return false;\n        }\n        // 写锁重入次数达到上限\n        if (w + exclusiveCount(acquires) > MAX_COUNT) {\n            throw new Error(\"Maximum lock count exceeded\");\n        }\n        // 更新 state 状态值\n        this.setState(c + acquires);\n        return true;\n    }\n\n    // 当前锁对象未被线程持有，对于非公平锁则抢占式获取锁对象，对于公平锁则等待前面的线程优先获取锁\n    if (this.writerShouldBlock() || !this.compareAndSetState(c, c + acquires)) {\n        return false;\n    }\n    // 记录当前持有写锁的线程对象\n    this.setExclusiveOwnerThread(current);\n    return true;\n}\n```\n\n上述方法尝试获取写锁资源的执行流程可以概括为：\n\n1. 获取当前线程对象、state 状态值，以及写锁的重入次数；\n2. 如果 state 状态值不为 0，但写锁重入次数为 0，说明当前读锁已被持有，获取写锁失败；\n3. 如果 state 状态值不为 0，且写锁重入次数也不为 0，说明当前写锁已被持有，如果持有该写锁的线程不是当前线程，则获取写锁失败；\n4. 否则，说明当前线程已经持有该写锁资源，本次加锁相当于重入，此时需要校验写锁重入次数是否已达上限，是则抛出异常，否则说明获取写锁成功，更新 state 状态值；\n5. 如果 2 中检测到 state 状态值为 0，说明当前锁对象未被任何线程持有，对于公平锁而言需要考虑公平性，优先让排在前面的线程先获取锁；\n6. 尝试更新 state 状态值，如果成功则说明加锁成功，需要记录当前持有写锁的线程对象并返回 true，否则返回 false。\n\n上述方法通过调用 `Sync#writerShouldBlock` 方法来判断当前获取写锁资源的线程是否应该被阻塞。Sync 中同样仅仅声明了该方法，具体实现交由 FairSync 和 NonfairSync 子类实现，如下：\n\n```java\n// FairSync#writerShouldBlock\nfinal boolean writerShouldBlock() {\n    return this.hasQueuedPredecessors();\n}\n\n// NonfairSync#writerShouldBlock\nfinal boolean writerShouldBlock() {\n    return false; // writers can always barge\n}\n```\n\n由实现可以看出在获取写锁时，对于公平锁需要让渡排在同步队列前面的等待线程，而非公平锁则允许当前线程抢占获取写锁资源。\n\nWriteLock 释放写锁资源的方法 `WriteLock#unlock` 同样是直接委托给 AQS 处理，调用的是 `AbstractQueuedSynchronizer#release` 方法。AQS 通过调用模板方法 `AbstractQueuedSynchronizer#tryRelease` 尝试释放独占资源，成功则返回 true。Sync 针对该模板方法的实现如下：\n\n```java\nprotected final boolean tryRelease(int releases) {\n    // 如果写锁未被当前线程持有，则抛出异常\n    if (!this.isHeldExclusively()) {\n        throw new IllegalMonitorStateException();\n    }\n    // 计算释放之后，剩余的重入次数\n    int nextc = this.getState() - releases;\n    // 如果写锁重入次数为 0，则说明锁被释放\n    boolean free = exclusiveCount(nextc) == 0;\n    if (free) {\n        // 写锁已经被释放，清空持有写锁的线程对象\n        this.setExclusiveOwnerThread(null);\n    }\n    // 更新 state 状态值\n    this.setState(nextc);\n    return free;\n}\n```\n\n整体逻辑比较简单，如代码注释。\n\n### 总结\n\n本文我们通过一个官方示例演示了 ReentrantReadWriteLock 的基本使用，并分析了其内在实现机制。ReentrantReadWriteLock 相对于前面介绍的 ReentrantLock 更加适合读多写少的业务场景，通过将读锁与写锁相分离的设计以提升读操作的吞吐性能。然而，灵活的背后也暗藏着更加容易出错的风险，一些不规范的使用很容易造成死锁，比如在已经持有读锁的基础上仍然尝试获取写锁，使用时需要留心。\n\n### 参考\n\n1. JDK 1.8 源码\n2. [The java.util.concurrent Synchronizer Framework](https://www.sciencedirect.com/science/article/pii/S0167642305000663)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：ReentrantLock","url":"/2018/08/29/java/juc-reentrant-lock/","content":"\n上一遍我们深入分析了 AQS 的设计与实现，了解到 AQS 是 JUC 包实现的基础支撑，本文我们就来分析一个基于 AQS 实现的 JUC 组件，即 ReentrantLock。\n\nReentrantLock 译为可重入锁，我们在使用时总是将其与 synchronized 关键字进行对比，实际上 ReentrantLock 与 synchronized 关键字在使用上具备相同的语义，区别仅在于 ReentrantLock 相对于 synchronized 关键字留给开发者的可操作性更强，所以在使用上更加灵活，当然凡事都有两面，灵活的背后也暗藏着更加容易出错的风险。<!-- more -->\n\n尽管语义相同，但 ReentrantLock 和 synchronized 关键字背后的实现机制却大相径庭。前面的文章中我们分析了 synchronized 关键字的实现内幕，知道了 synchronized 关键字背后依赖于 monitor 技术，而本文所要分析的 ReentrantLock 在实现上则依赖于 AQS 队列同步器，具体如何基于 AQS 进行实现，下面来一探究竟。\n\n### ReentrantLock 示例\n\n本小节使用 ReentrantLock 实现一个 3 线程交替打印的程序，演示基于 ReentrantLock 实现锁的获取、释放，以及线程之间的通知机制。示例实现如下：\n\n```java\nprivate static Lock lock = new ReentrantLock(true);\n\nprivate static Condition ca = lock.newCondition();\nprivate static Condition cb = lock.newCondition();\nprivate static Condition cc = lock.newCondition();\n\nprivate static volatile int idx = 0;\n\nprivate static class A implements Runnable {\n\n    @Override\n    public void run() {\n        try {\n            lock.lock();\n            for (int i = 0; i < 10; i++) {\n                cb.signalAll();\n                System.out.println(\"a: \" + (++idx));\n                ca.await();\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n\nprivate static class B implements Runnable {\n\n    @Override\n    public void run() {\n        try {\n            lock.lock();\n            for (int i = 0; i < 10; i++) {\n                cc.signalAll();\n                System.out.println(\"b: \" + (++idx));\n                cb.await();\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n\nprivate static class C implements Runnable {\n\n    @Override\n    public void run() {\n        try {\n            lock.lock();\n            for (int i = 0; i < 10; i++) {\n                ca.signalAll();\n                System.out.println(\"c: \" + (++idx));\n                cc.await();\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n\npublic static void main(String[] args) {\n    new Thread(new A()).start();\n    new Thread(new B()).start();\n    new Thread(new C()).start();\n}\n```\n\n上述示例定义了 3 个线程类 A、B 和 C，并按照 `A -> B -> C` 的顺序进行组织，各个线程在调用 `Lock#lock` 方法获取到锁之后会先尝试通知后继线程（将对应的线程移入到同步队列），然后对 idx 变量进行累加并打印，接着进入等待状态并释放资源，方法 `Lock#unlock` 接下来会调度位于同步队列队头结点的线程继续执行。\n\n### ReentrantLock 实现内幕\n\n#### Lock 接口\n\nReentrantLock 实现了 Lock 接口，该接口抽象了锁应该具备的基本操作，包括锁资源的获取、释放，以及创建条件对象。除了本文介绍的 ReentrantLock 外，JUC 中直接或间接实现了 Lock 接口的组件还包括 ReentrantReadWriteLock 和 StampedLock，我们将在后面的文章中对这些组件逐一分析。Lock 接口的定义如下：\n\n```java\npublic interface Lock {\n    void lock();\n    void lockInterruptibly() throws InterruptedException;\n    boolean tryLock();\n    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;\n    void unlock();\n    Condition newCondition();\n}\n```\n\n各方法释义如下：\n\n- `lock()`：获取锁资源，如果获取失败则阻塞。\n- `lockInterruptibly()`：获取锁资源，如果获取失败则阻塞，阻塞期间支持响应中断请求。\n- `tryLock()`：尝试获取锁资源，不管是否获取成功都立即返回，如果获取成功则返回 true，否则返回 false。\n- `tryLock(long time, TimeUnit unit)`：尝试获取锁资源，相对于无参版本的 tryLock 方法引入了超时机制，并支持在等待期间响应中断请求。\n- `unlock()`：释放锁资源。\n- `newCondition()`：创建一个绑定到当前 Lock 上的条件对象。\n\n#### 资源的获取与释放\n\n上一小节分析了 Lock 接口的定义，ReentrantLock 实现了该接口，并将接口方法的实现都委托给了 Sync 内部类处理。Sync 是一个抽象类，继承自 AbstractQueuedSynchronizer，并派生出 FairSync 和 NonfairSync 两个子类（继承关系如下图），由命名可以看出 FairSync 实现了公平锁，而 NonfairSync 则实现了非公平锁。\n\n![image](/images/2018/juc-reentrant-lock.png)\n\nReentrantLock 提供了带 boolean 参数的构造方法，依据该参数来决定是创建公平锁还是非公平锁（默认为非公平锁），构造方法定义如下：\n\n```java\npublic ReentrantLock() {\n    // 默认创建非公平锁\n    sync = new NonfairSync();\n}\n\npublic ReentrantLock(boolean fair) {\n    // 依据参数决定创建公平锁还是非公平锁\n    sync = fair ? new FairSync() : new NonfairSync();\n}\n```\n\n下面将区分公平锁和非公平锁分析 ReentrantLock 针对 Lock 接口方法的具体实现，在开始之前先介绍一下 AQS 中的 state 字段在 ReentrantLock 中的作用。\n\n我们知道 ReentrantLock 是可重入的，这里的可重入是指当一个线程获取到 ReentrantLock 锁之后，如果该线程再次尝试获取该 ReentrantLock 锁时仍然可以获取成功，对应的重入次数加 1。ReentrantLock 的重入次数则由 AQS 的 state 字段进行记录。当 state 为 0 时，说明目标 ReentrantLock 锁当前未被任何线程持有，当一个线程释放 ReentrantLock 锁时，对应的 state 值需要减 1。\n\n##### 非公平锁\n\n本小节我们来分析一下非公平锁 NonfairSync 的实现机制，首先来看一下 `NonfairSync#lock` 方法，该方法用于获取资源，如果获取失败则会将当前线程加入到同步队列中阻塞等待。方法实现如下：\n\n```java\nfinal void lock() {\n    // 尝试获取锁，将 state 由 0 设置为 1\n    if (this.compareAndSetState(0, 1)) {\n        // 首次获取锁成功，记录当前锁对象\n        this.setExclusiveOwnerThread(Thread.currentThread());\n    } else {\n        // 目标锁对象已经被占用，或者非首次获取目标锁对象\n        this.acquire(1);\n    }\n}\n```\n\n方法 `NonfairSync#lock` 加锁的过程首先会基于 CAS 操作尝试将 ReentrantLock 的 state 值由 0 改为 1，抢占锁资源，这也是非公平语义的根本所在。如果操作成功，则说明目标 ReentrantLock 锁当前未被任何线程持有，且本次加锁成功。如果操作失败则区分两种情况：\n\n- 目标 ReentrantLock 锁已被当前线程持有。\n- 目标 ReentrantLock 锁已被其它线程持有。\n\n针对这两种情况，接下来会调用 `AbstractQueuedSynchronizer#acquire` 方法尝试获取 1 个单位的资源，该方法由 AQS 实现，我们已经在前面的文章中分析过，其中会执行模板方法 `AbstractQueuedSynchronizer#tryAcquire`。NonfairSync 针对该模板方法的实现如下：\n\n```java\nprotected final boolean tryAcquire(int acquires) {\n    return this.nonfairTryAcquire(acquires);\n}\n```\n\n上述方法将尝试获取资源的逻辑委托给 `Sync#nonfairTryAcquire` 方法执行，ReentrantLock 的 `ReentrantLock#tryLock()` 方法同样基于该方法实现。下面来分析一下该方法的执行逻辑，实现如下：\n\n```java\nfinal boolean nonfairTryAcquire(int acquires) {\n    // 获取当前线程对象\n    final Thread current = Thread.currentThread();\n    // 获取 state 值\n    int c = this.getState();\n    if (c == 0) {\n        // state 为 0，表示目标锁当前未被持有，尝试获取锁\n        if (this.compareAndSetState(0, acquires)) {\n            this.setExclusiveOwnerThread(current);\n            return true;\n        }\n    }\n    // 如果当前已经持有锁的线程已经是当前线程\n    else if (current == this.getExclusiveOwnerThread()) {\n        // 重入次数加 1\n        int nextc = c + acquires;\n        if (nextc < 0) {\n            // 重入次数溢出\n            throw new Error(\"Maximum lock count exceeded\");\n        }\n        // 更新 state 记录的重入次数\n        this.setState(nextc);\n        return true;\n    }\n    // 已经持有锁的线程不是当前线程，尝试加锁失败\n    return false;\n}\n```\n\n方法 `Sync#nonfairTryAcquire` 的执行流程可以概括为;\n\n1. 获取当前 ReentrantLock 锁的 state 值；\n2. 如果 state 值为 0，说明当前 ReentrantLock 锁未被任何线程持有，基于 CAS 尝试将 state 值由 0 改为 1，抢占锁资源，修改成功即为加锁成功；\n3. 否则，如果当前已经持有该 ReentrantLock 锁的线程是自己，则修改重入次数（即将 state 值加 1）；\n4. 否则，目标 ReentrantLock 锁已经被其它线程持有，加锁失败。\n\n如果 `Sync#nonfairTryAcquire` 方法返回 false，则说明当前线程尝试获取目标 ReentrantLock 锁失败，对于 `ReentrantLock#lock` 方法而言，接下去线程会被加入到同步队列阻塞等待，而对于 `ReentrantLock#tryLock()` 方法而言，线程会立即退出，并返回 false。\n\n方法 `ReentrantLock#newCondition` 同样是委托给 `Sync#newCondition` 方法处理，该方法只是简单的创建了一个 ConditionObject 对象，即新建了一个条件队列。非公平锁 NonfairSync 中的以下方法都是直接委托给 AQS 处理，这些方法的实现机制已在前面分析 AQS 时介绍过：\n\n- `ReentrantLock#lockInterruptibly`：直接委托给 `AbstractQueuedSynchronizer#acquireInterruptibly` 方法实现，获取的资源数为 1。\n- `ReentrantLock#tryLock(long, java.util.concurrent.TimeUnit)`：直接委托给 `AbstractQueuedSynchronizer#tryAcquireNanos` 方法实现，获取的资源数为 1。\n- `ReentrantLock#unlock`：直接委托给 `AbstractQueuedSynchronizer#release` 方法实现，释放的资源数为 1。\n\n前面的文章，我们在分析 AQS 的 `AbstractQueuedSynchronizer#release` 方法时，曾介绍过该方法会调用模板方法 `AbstractQueuedSynchronizer#tryRelease` 以尝试释放资源。ReentrantLock 针对该模板方法的实现位于 Sync 抽象类中，所以它是一个由 NonfairSync 和 FairSync 共用的方法，下面来分析一下该方法的实现。\n\n```java\nprotected final boolean tryRelease(int releases) {\n    // 将当前 state 记录的重入次数减 1\n    int c = this.getState() - releases;\n    // 如果当前持有锁的线程对象不是当前线程则抛出异常\n    if (Thread.currentThread() != this.getExclusiveOwnerThread()) {\n        throw new IllegalMonitorStateException();\n    }\n    boolean free = false;\n    // 如果重入次数已经降为 0，则清空持有当前锁的线程对象\n    if (c == 0) {\n        free = true;\n        this.setExclusiveOwnerThread(null);\n    }\n    // 更新当前锁的重入次数\n    this.setState(c);\n    return free;\n}\n```\n\n尝试释放资源的过程本质上就是修改 state 字段值的过程，如果当前操作的线程是持有 ReentrantLock 锁的线程，则上述方法会将 state 值减 1，即将已重入次数减 1。如果修改后的 state 字段值为 0，则说明当前线程已经释放了持有的 ReentrantLock 锁，此时需要清除记录在 ReentrantLock 对象中的线程 Thread 对象。\n\n##### 公平锁\n\n本小节我们来分析一下公平锁 FairSync 的实现机制，这里的公平本质上是指公平的获取锁资源，所以主要的区别体现在加锁的过程，即 `ReentrantLock#lock` 方法。\n\n前面我们在分析 NonfairSync 时看到，NonfairSync 在加锁时首先会基于 CAS 尝试将 state 值由 0 改为 1，失败的情况下才会继续调用 `AbstractQueuedSynchronizer#acquire` 方法等待获取资源，并且在同步队列中等待期间仍然会在 state 为 0 时抢占获取锁资源。\n\nFairSync 相对于 NonfairSync 的区别在于当 state 值为 0 时，即目标 ReentrantLock 锁此时未被任何线程持有的情况下，FairSync 并不会去抢占锁资源，而是检查同步队列中是否有排在前面等待获取锁资源的其它线程，如果有则让渡这些排在前面的线程优先获取锁资源。\n\n下面来看一下 `FairSync#lock` 方法的实现，该方法只是简单的将获取锁资源操作委托给 AQS 的 `AbstractQueuedSynchronizer#acquire` 方法执行，所以我们需要重点关注一下模板方法 `FairSync#tryAcquire` 的实现：\n\n```java\nprotected final boolean tryAcquire(int acquires) {\n        // 获取当前线程对象\n        final Thread current = Thread.currentThread();\n        // 获取当前 state 值\n        int c = this.getState();\n        if (c == 0) {\n            // state 为 0，表示目标锁当前未被持有，先检查是否有阻塞等待当前锁的线程，如果没有再尝试获取锁\n            if (!this.hasQueuedPredecessors() && this.compareAndSetState(0, acquires)) {\n                this.setExclusiveOwnerThread(current);\n                return true;\n            }\n        }\n        // 如果当前已经持有锁的线程已经是当前线程，则修改已重入次数加 1\n        else if (current == this.getExclusiveOwnerThread()) {\n            int nextc = c + acquires;\n            if (nextc < 0) {\n                throw new Error(\"Maximum lock count exceeded\");\n            }\n            this.setState(nextc);\n            return true;\n        }\n        return false;\n    }\n}\n```\n\n上述方法的执行流程与 NonfairSync 中的相关实现大同小异，主要区别在于当 state 值为 0 时，FairSync 会调用 `AbstractQueuedSynchronizer#hasQueuedPredecessors` 检查当前同步队列中是否还有等待获取锁资源的其它线程，如果存在则优先让这些线程获取锁资源，并将自己加入到同步队列中排队等待。\n\n### 总结\n\n本文我们通过一个 3 线程交替打印的程序演示了 ReentrantLock 的基本使用，并一起分析了 ReentrantLock 的实现机制。因为基于 AQS 实现，所以大部分的操作已经由 AQS 完成，ReentrantLock 只需要关注自身定制化逻辑即可，整体实现要简单了很多。\n\n理解了 ReentrantLock 的实现机制，应该会对 AQS 的设计与实现有更进一步的认识。最后留两个小思考题：\n\n1. 示例程序中一共用到了几个队列，线程在运行期间是如何出队列入队列的？\n2. 参考 ReentrantLock 的设计，思考如何实现一个非重入锁 NonReentrantLock？\n\n### 参考\n\n1. JDK 1.8 源码\n2. [The java.util.concurrent Synchronizer Framework](https://www.sciencedirect.com/science/article/pii/S0167642305000663)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：AQS 队列同步器","url":"/2018/08/24/java/juc-aqs/","content":"\nAbstractQueuedSynchronizer 简称 AQS，可能我们几乎不会直接去使用它，但它却是 JUC 的核心基础组件，支撑着 java 锁和同步器的实现，例如 ReentrantLock、ReentrantReadWriteLock、CountDownLatch，以及 Semaphore 等。大神 [Doug Lea](https://en.wikipedia.org/wiki/Doug_Lea) 在设计 JUC 包时希望能够抽象一个基础且通用的组件以支撑上层模块的实现，AQS 应运而生。\n\nAQS 本质上是一个 FIFO 的双向队列，线程被包装成结点的形式，基于自旋机制在队列中等待获取资源（这里的资源可以简单理解为对象锁）。AQS 在设计上实现了两类队列，即 __同步队列__ 和 __条件队列__ ，其中同步队列服务于线程阻塞等待获取资源，而条件队列则服务于线程因某个条件不满足而进入等待状态。条件队列中的线程实际上已经获取到了资源，但是没有能够继续执行下去的条件，所以被打入条件队列并释放持有的资源，以让渡其它线程执行，如果未来某个时刻条件得以满足，则该线程会被从条件队列转移到同步队列，继续参与竞争资源，以继续向下执行。<!-- more -->\n\n本文我们主要分析 AQS 的设计与实现，包括 LockSupport 工具类、同步队列、条件队列，以及 AQS 资源获取和释放的通用过程。AQS 采用模板方法设计模式，具体获取资源和释放资源的过程都交由子类实现，对于这些方法的分析将留到后面分析具体子类的文章中再展开。\n\n### LockSupport 工具类\n\nLockSupport 工具类是 JUC 的基础组件，主要作用是用来阻塞和唤醒线程，底层依赖于 Unsafe 类实现。LockSupport 主要定义类 2 类方法：park 和 unpark，其中 park 方法用于阻塞当前线程，而 unpark 方法用于唤醒处于阻塞状态的指定线程。\n\n下面的示例演示了 park 和 unpark 方法的基本使用：\n\n```java\nThread thread = new Thread(() -> {\n    System.out.println(\"Thread start: \" + Thread.currentThread().getName());\n    LockSupport.park(); // 阻塞自己\n    System.out.println(\"Thread end: \" + Thread.currentThread().getName());\n});\n\nthread.setName(\"A\");\nthread.start();\n\nSystem.out.println(\"Main thread sleep 3 second: \" + Thread.currentThread().getId());\nTimeUnit.SECONDS.sleep(3);\nLockSupport.unpark(thread); // 唤醒线程 A\n```\n\n线程 A 在启动之后调用了 `LockSupport#park` 方法将自己阻塞，主线程在休息 3 秒之后调用 `LockSupport#unpark` 方法线程 A 唤醒。运行结果：\n\n```text\nThread start: A\nMain thread sleep 3 second: 1\nThread end: A\n```\n\nLockSupport 针对 park 方法提供了多种实现，如下：\n\n```java\npublic static void park()\npublic static void park(Object blocker)\npublic static void parkNanos(long nanos)\npublic static void parkNanos(Object blocker, long nanos)\npublic static void parkUntil(long deadline)\npublic static void parkUntil(Object blocker, long deadline)\n```\n\n由方法命名不难看出，parkNanos 和 parkUntil 都属于 park 方法的超时版本，区别在于 parkNanos 方法接收一个纳秒单位的时间值，用于指定阻塞的时间长度，例如当设置 `nanos=3000000000` 时，线程将阻塞 3 秒后苏醒，而 parkUntil 方法则接收一个时间戳，参数 deadline 用于指定阻塞的到期时间。\n\n所有的 park 方法都提供了包含 `Object blocker` 参数的重载版本，参数 blocker 指代导致当前线程阻塞等待的锁对象，方便问题排查和系统监控，而在 LockSupport 最开始被设计时却忽视了这一点，导致在线程 dump 时无法提供阻塞对象的相关信息，这一点在 java 6 中得以改进。实际开发中如果使用到了 LockSupport 工具类，推荐使用带 blocker 参数的版本。\n\n下面以 `LockSupport#park(java.lang.Object)` 方法为例来看一下具体的实现，如下：\n\n```java\npublic static void park(Object blocker) {\n    // 获取当前线程对象\n    Thread t = Thread.currentThread();\n    // 记录当前线程阻塞等待的锁对象（设置线程对象的 parkBlocker 为参数指定的 blocker 对象）\n    setBlocker(t, blocker);\n    // 阻塞线程\n    UNSAFE.park(false, 0L);\n    // 线程恢复运行，清除 parkBlocker 参数记录的锁对象\n    setBlocker(t, null);\n}\n```\n\n具体实现比较简单，阻塞线程的操作依赖于 Unsafe 类实现。上述方法会调用 `LockSupport#setBlocker` 方法基于 Unsafe 类将参数指定的 blocker 对象记录到当前线程对象的 `Thread#parkBlocker` 字段中，然后进入阻塞状态，并在被唤醒之后清空对应的 `Thread#parkBlocker` 字段。\n\n当一个线程调用 park 方法进入阻塞状态之后，会在满足以下 3 个条件之一时从阻塞状态中苏醒：\n\n1. 其它线程调用 unpark 方法唤醒当前线程。\n2. 其它线程中断了当前线程的阻塞状态。\n3. 方法 park 因为一些不合逻辑的原因退出。\n\n线程在从 park 方法中返回时并不会携带具体的返回原因，调用者需要自行检测，例如再次检查之前调用 park 方法的条件是否仍然满足以予以推测。\n\n方法 `LockSupport#unpark` 的实现同样基于 Unsafe 类实现，不同于 park 的多版本实现，LockSupport 针对 unpark 方法仅提供了单一实现，如下：\n\n```java\npublic static void unpark(Thread thread) {\n    if (thread != null) {\n        UNSAFE.unpark(thread);\n    }\n}\n```\n\n需要注意的一点是，如果事先针对某个线程调用了 unpark 方法，则该线程继续调用 park 方法并不会进入阻塞状态，而是会立即返回，并且 park 方法是不可重入的。\n\n### 同步队列\n\n同步队列的作用在于管理竞争资源的线程，当一个线程竞争资源失败会被记录到同步队列的末端，并以自旋的方式循环检查能够成功获取到资源。AQS 的同步队列基于 CLH(Craig, Landin, and Hagersten) 锁思想进行设计和实现。CLH 锁是一种基于链表的可扩展、高性能，且具备公平性的自旋锁。线程以链表结点的形式进行组织，在等待期间相互独立的执行自旋，并不断轮询前驱结点的状态，如果发现前驱结点上的线程释放了资源则尝试获取。\n\nCLH 锁是 AQS 队列同步器实现的基础，AQS 以内部类 Node 的形式定义了同步队列结点，包括下一小节介绍的条件队列，同样以 Node 定义结点。Node 的字段定义如下：\n\n```java\nstatic final class Node {\n\n    /** 模式定义 */\n\n    static final Node SHARED = new Node();\n    static final Node EXCLUSIVE = null;\n\n    /** 线程状态 */\n\n    static final int CANCELLED = 1;\n    static final int SIGNAL = -1;\n    static final int CONDITION = -2;\n    static final int PROPAGATE = -3;\n\n    /** 线程等待状态 */\n    volatile int waitStatus;\n\n    /** 前驱结点 */\n    volatile Node prev;\n    /** 后置结点 */\n    volatile Node next;\n\n    /** 持有的线程对象 */\n    volatile Thread thread;\n\n    /** 对于独占模式而言，指向下一个处于 CONDITION 等待状态的结点；对于共享模式而言，则为 SHARED 结点 */\n    Node nextWaiter;\n\n    // ... 省略方法定义\n}\n```\n\n由上述字段定义可以看出，位于 CLH 链表中的线程以 2 种模式在等待资源，即 SHARED 和 EXCLUSIVE，其中 SHARED 表示共享模式，而 EXCLUSIVE 表示独占模式。共享模式与独占模式的主要区别在于，同一时刻独占模式只能有一个线程获取到资源，而共享模式在同一时刻可以有多个线程获取到资源。典型的场景就是读写锁，读操作可以有多个线程同时获取到读锁资源，而写操作同一时刻只能有一个线程获取到写锁资源，其它线程在尝试获取资源时都会被阻塞。\n\nAQS 的 CLH 锁为处于 CLH 链表中的线程定义了 4 种状态，包括 CANCELLED、SIGNAL、CONDITION，以及 PROPAGATE，并以 `Node#waitStatus` 字段进行记录。这 4 种状态的含义分别为：\n\n- __CANCELLED__ ：表示当前线程处于取消状态，一般是因为等待超时或者被中断，处于取消状态的线程不会再参与到竞争中，并一直保持该状态。\n- __SIGNAL__：表示当前结点后继结点上的线程正在等待被唤醒，如果当前线程释放了持有的资源或者被取消，需要唤醒后继结点上的线程。\n- __CONDITION__ ：表示当前线程正在等待某个条件，当某个线程在调用了 `Condition#signal` 方法后，当前结点将会被从条件队列转移到同步队列中，参与竞争资源。\n- __PROPAGATE__ ：处于该状态的线程在释放共享资源，或接收到释放共享资源的信号时需要通知后继结点，以防止通知丢失。\n\n一个结点在被创建时，字段 `Node#waitStatus` 的初始值为 0，表示结点上的线程不位于上述任何状态。\n\nNode 类在方法定义上除了基本的构造方法外，仅定义了 `Node#isShared` 和 `Node#predecessor` 两个方法，其中前者用于返回当前结点是否以共享模式在等待，后者用于返回当前结点的前驱结点。\n\n介绍完了队列结点的定义，那么同步队列具体如何实现呢？这还需要依赖于 AbstractQueuedSynchronizer 类中的两个字段定义，即：\n\n```java\nprivate transient volatile Node head;\nprivate transient volatile Node tail;\n```\n\n其中 head 表示同步队列的头结点，而 tail 则表示同步队列的尾结点，具体组织形式如下图：\n\n![image](/images/2018/juc-aqs-sync-queue.png)\n\n当调用 AQS 的 acquire 方法获取资源时，如果资源不足则当前线程会被封装成 Node 结点添加到同步队列的末端，头结点 head 用于记录当前正在持有资源的线程结点，而 head 的后继结点就是下一个将要被调度的线程结点，当 release 方法被调用时，该结点上的线程将被唤醒，继续获取资源。\n\n关于同步队列结点入队列、出队列的实现先不展开，留到后面分析 AQS 资源获取与释放的过程时一并分析。\n\n### 条件队列\n\n除了上面介绍的同步队列，在 AQS 中还定义了一个条件队列。内部类 ConditionObject 实现了条件队列的组织形式，包含一个起始结点（firstWaiter）和一个末尾结点（lastWaiter），并同样以上面介绍的 Node 类定义结点，如下：\n\n```java\npublic class ConditionObject implements Condition, Serializable {\n\n        /** 指向条件队列中的起始结点 */\n        private transient Node firstWaiter;\n        /** 指向条件队列的末尾结点 */\n        private transient Node lastWaiter;\n\n        // ... 省略方法定义\n\n}\n```\n\n前面在分析 Node 内部类的时候，可以看到 Node 类还定义了一个 `Node#nextWaiter` 字段，用于指向条件队列中的下一个等待结点。由此我们可以描绘出条件队列的组织形式如下：\n\n![image](/images/2018/juc-aqs-condition-queue.png)\n\nConditionObject 类实现了 Condition 接口，该接口定义了与 Lock 锁相关的线程通信方法，主要分为 await 和 signal 两大类。\n\n当线程调用 await 方法时，该线程会被包装成结点添加到条件队列的末端，并释放持有的资源。当条件得以满足时，方法 signal 可以将条件队列中的一个或全部的线程结点从条件队列转移到同步队列以参与竞争资源。应用可以创建多个 ConditionObject 对象，每个对象都对应一个条件队列，对于同一个条件队列而言，其中的线程所等待的条件是相同的。\n\nCondition 接口的定义如下：\n\n```java\npublic interface Condition {\n\n    void await() throws InterruptedException;\n    void awaitUninterruptibly();\n    long awaitNanos(long nanosTimeout) throws InterruptedException;\n    boolean await(long time, TimeUnit unit) throws InterruptedException;\n    boolean awaitUntil(Date deadline) throws InterruptedException;\n\n    void signal();\n    void signalAll();\n}\n```\n\n#### 等待：await\n\n下面来分析一下 ConditionObject 类针对 Condition 接口方法的实现，首先来看一下 `ConditionObject#await` 方法，该方法用于将当前线程添加到条件队列中进行等待，同时支持响应中断。方法实现如下：\n\n```java\npublic final void await() throws InterruptedException {\n    if (Thread.interrupted()) {\n        // 立即响应中断\n        throw new InterruptedException();\n    }\n    // 将当前线程添加到等待队列末尾，等待状态为 CONDITION\n    Node node = this.addConditionWaiter();\n    // 释放当前线程持有的资源\n    int savedState = fullyRelease(node);\n    int interruptMode = 0;\n    while (!isOnSyncQueue(node)) { // 如果当前结点位于条件队列中，则循环\n        // 阻塞当前线程\n        LockSupport.park(this);\n        // 如果线程在阻塞期间被中断，则退出循环\n        if ((interruptMode = this.checkInterruptWhileWaiting(node)) != 0) {\n            break;\n        }\n    }\n    // 如果在同步队列中等待期间被中断，且之前的中断状态不为 THROW_IE\n    if (acquireQueued(node, savedState) && interruptMode != THROW_IE) {\n        interruptMode = REINTERRUPT;\n    }\n    if (node.nextWaiter != null) {\n        // 清除条件队列中所有状态不为 CONDITION 的结点\n        this.unlinkCancelledWaiters();\n    }\n    // 如果等待期间被中断，则响应中断\n    if (interruptMode != 0) {\n        this.reportInterruptAfterWait(interruptMode);\n    }\n}\n```\n\n因为 `ConditionObject#await` 方法支持响应中断，所以在方法一开始会先检查一下当前线程是否被中断，如果是则抛出 InterruptedException 异常，否则继续将当前线程加入到条件队列中进行等待。整体执行流程可以概括为：\n\n1. 将当前线程加入到条件队列末端，并设置等待状态为 CONDITION；\n2. 释放当前线程所持有的资源，避免饥饿或死锁；\n3. 基于自旋机制在条件队列中等待，直到被其它线程转移到同步队列，或者等待期间被中断；\n4. 如果等待期间被中断，则响应中断。\n\nConditionObject 定义了两种中断响应方式，即：`REINTERRUPT` 和 `THROW_IE`。如果是 `REINTERRUPT`，则线程会调用 `Thread#interrupt` 方法中断自己；如果是 `THROW_IE`，则线程会直接抛出 InterruptedException 异常。\n\n下面继续分析一下支撑 `ConditionObject#await` 运行的其它几个方法，包括 addConditionWaiter、fullyRelease、isOnSyncQueue，以及 unlinkCancelledWaiters。\n\n方法 `ConditionObject#addConditionWaiter` 用于将当前线程包装成 Node 结点对象添加到条件队列的末端，期间会执行清除条件队列中处于取消状态（等待状态不为 CONDITION）的线程结点。方法实现如下：\n\n```java\nprivate Node addConditionWaiter() {\n    // 获取条件队列的末尾结点\n    Node t = lastWaiter;\n    // 如果末尾结点状态不为 CONDITION，表示对应的线程已经取消了等待，需要执行清理操作\n    if (t != null && t.waitStatus != Node.CONDITION) {\n        // 清除条件队列中所有状态不为 CONDITION 的结点\n        this.unlinkCancelledWaiters();\n        t = lastWaiter;\n    }\n    // 构建当前线程对应的 Node 结点，等待状态为 CONDITION，并添加到条件队列末尾\n    Node node = new Node(Thread.currentThread(), Node.CONDITION);\n    if (t == null) {\n        firstWaiter = node;\n    } else {\n        t.nextWaiter = node;\n    }\n    lastWaiter = node;\n    return node;\n}\n```\n\n将当前线程对象添加到条件队列中的过程本质上是一个简单的链表插入操作，在执行插入操作之前，上述方法会先对条件队列执行一遍清理操作，清除那些状态不为 CONDITION 的结点。具体实现位于 `ConditionObject#unlinkCancelledWaiters` 方法中：\n\n```java\nprivate void unlinkCancelledWaiters() {\n    Node t = firstWaiter;\n    Node trail = null; // 记录上一个不被删除的结点\n    while (t != null) {\n        Node next = t.nextWaiter;\n        // 如果结点上的线程等待状态不为 CONDITION，则删除对应结点\n        if (t.waitStatus != Node.CONDITION) {\n            t.nextWaiter = null;\n            if (trail == null) {\n                firstWaiter = next;\n            } else {\n                trail.nextWaiter = next;\n            }\n            if (next == null) {\n                lastWaiter = trail;\n            }\n        } else {\n            trail = t;\n        }\n        t = next;\n    }\n}\n```\n\n方法 `AbstractQueuedSynchronizer#fullyRelease` 用于释放当前线程持有的资源，这也是非常容易理解的，毕竟当前线程即将进入等待状态，如果持有的资源不被释放，将可能导致程序最终被饿死，或者死锁。方法的实现如下：\n\n```java\nfinal int fullyRelease(Node node) {\n    boolean failed = true;\n    try {\n        // 获取当前线程的同步状态，可以理解为持有的资源数量\n        int savedState = this.getState();\n        // 尝试释放当前线程持有的资源\n        if (this.release(savedState)) {\n            failed = false;\n            return savedState;\n        } else {\n            // 释放资源失败\n            throw new IllegalMonitorStateException();\n        }\n    } finally {\n        if (failed) {\n            // 如果释放资源失败，则取消当前线程\n            node.waitStatus = Node.CANCELLED;\n        }\n    }\n}\n```\n\n如果资源释放失败，则上述方法会将当前线程的状态设置为 CANCELLED，以退出等待状态。\n\n方法 `AbstractQueuedSynchronizer#isOnSyncQueue` 用于检测当前结点是否位于同步队列中，方法实现如下：\n\n```java\nfinal boolean isOnSyncQueue(Node node) {\n    // 如果结点位于等待队列，或是头结点则返回 false\n    if (node.waitStatus == Node.CONDITION || node.prev == null) {\n        return false;\n    }\n    // If has successor, it must be on queue\n    if (node.next != null) {\n        return true;\n    }\n\n    /*\n     * node.prev can be non-null, but not yet on queue because the CAS to place it on queue can fail.\n     * So we have to traverse from tail to make sure it actually made it. It will always be near the tail in calls to this method,\n     * and unless the CAS failed (which is unlikely), it will be there, so we hardly ever traverse much.\n     */\n\n    // 从后往前检测目标结点是否位于同步队列中\n    return this.findNodeFromTail(node);\n}\n```\n\n如果一个线程所等待的条件被满足，则触发条件满足的线程会将等待该条件的一个或全部线程结点从条件队列转移到同步队列，此时，这些线程将从 `ConditionObject#await` 方法中退出，以参与竞争资源。\n\n方法 `ConditionObject#awaitNanos`、`ConditionObject#awaitUntil` 和 `ConditionObject#await(long, TimeUnit)` 在上面介绍的 `ConditionObject#await` 方法的基础上引入了超时机制，当一个线程在条件队列中等待的时间超过设定值时，线程结点将被从条件队列转移到同步队列，参与竞争资源。其它执行过程与 `ConditionObject#await` 方法相同，故不再展开。\n\n下面来分析一下 `ConditionObject#awaitUninterruptibly` 方法，由方法命名可以看出该方法相对于 `ConditionObject#await` 方法的区别在于在等待期间不响应中断。方法实现如下：\n\n```java\npublic final void awaitUninterruptibly() {\n    // 将当前线程添加到等待队列末尾，等待状态为 CONDITION\n    Node node = this.addConditionWaiter();\n    // 释放当前线程持有的资源\n    int savedState = fullyRelease(node);\n    boolean interrupted = false;\n    // 如果当前结点位于条件队列中，则循环\n    while (!isOnSyncQueue(node)) {\n        // 阻塞当前线程\n        LockSupport.park(this);\n        if (Thread.interrupted()) {\n            // 标识线程等待期间被中断，但不立即响应\n            interrupted = true;\n        }\n    }\n    // 自旋获取资源，返回 true 则说明等待期间被中断过\n    if (acquireQueued(node, savedState) || interrupted) {\n        // 响应中断\n        selfInterrupt();\n    }\n}\n```\n\n如果线程在等待期间被中断，则上述方法会用一个字段进行记录，并在最后集中处理，而不会因为中断而退出等待状态。\n\n#### 通知：signal\n\n调用 await 方法会将线程对象自身加入到条件队列中进行等待，而 signal 通知方法则用于将一个或全部的等待线程从条件队列转移到同步队列，以参与竞争资源。ConditionObject 定义了两个通知方法：signal 和 signalAll，前者用于将条件队列的头结点（也就是等待时间最长的结点）从条件队列转移到同步队列，后者用于将条件队列中所有处于等待状态的结点从条件队列转移到同步队列。下面分别来分析一下这两个方法的实现。\n\n方法 `ConditionObject#signal` 的实现如下：\n\n```java\npublic final void signal() {\n    // 先检测当前线程是否获取到了锁，否则不允许继续执行\n    if (!isHeldExclusively()) {\n        throw new IllegalMonitorStateException();\n    }\n    // 获取条件队列头结点，即等待时间最长的结点\n    Node first = firstWaiter;\n    if (first != null) {\n        // 将头结点从条件队列转移到同步队列，参与竞争资源\n        this.doSignal(first);\n    }\n}\n```\n\n调用 `ConditionObject#signal` 方法的线程必须位于临界区，也就是必须先持有独占锁，所以上述方法一开始会对这一条件进行校验，方法 `AbstractQueuedSynchronizer#isHeldExclusively` 是一个模板方法，交由子类来实现。如果满足执行条件，则上述方法会调用 `ConditionObject#doSignal` 方法将条件队列的头结点从条件队列转移到同步队列。\n\n```java\nprivate void doSignal(Node first) {\n    // 从前往后遍历，直到遇到第一个不为 null 的结点，并将其从条件队列转移到同步队列\n    do {\n        if ((firstWaiter = first.nextWaiter) == null) {\n            lastWaiter = null;\n        }\n        first.nextWaiter = null;\n    } while (!transferForSignal(first) && (first = firstWaiter) != null);\n}\n\n// AbstractQueuedSynchronizer#transferForSignal\nfinal boolean transferForSignal(Node node) {\n    // 更新当前结点的等待状态：CONDITION -> 0\n    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) {\n        // 更新失败，说明对应的结点上的线程已经被取消\n        return false;\n    }\n\n    /*\n     * Splice onto queue and try to set waitStatus of predecessor to indicate that thread is (probably) waiting.\n     * If cancelled or attempt to set waitStatus fails, wake up to resync (in which case the waitStatus can be transiently and harmlessly wrong).\n     */\n\n    // 将结点添加到同步队列末端，并返回该结点的前驱结点\n    Node p = this.enq(node);\n    int ws = p.waitStatus;\n    // 如果前驱结点被取消，或者设置前驱结点的状态为 SIGNAL 失败，则唤醒当前结点上的线程\n    if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) {\n        LockSupport.unpark(node.thread);\n    }\n    return true;\n}\n```\n\n方法 `ConditionObject#doSignal` 会从前往后遍历条件队列，寻找第一个不为 null 的结点，并应用 `AbstractQueuedSynchronizer#transferForSignal` 方法尝试将其从条件队列转移到同步队列。\n\n在入同步队列之前，方法 `AbstractQueuedSynchronizer#transferForSignal` 会基于 CAS 机制清除结点的 CONDITION 状态，如果清除失败则说明该结点上的线程已被取消，此时 `ConditionObject#doSignal` 方法会继续寻找下一个可以被唤醒的结点。如果清除结点状态成功，则接下来会将该结点添加到同步队列的末端，同时依据前驱结点的状态决定是否唤醒当前结点上的线程。\n\n继续来看 `ConditionObject#signalAll` 方法的实现，相对于上面介绍的 `ConditionObject#signal` 方法，该方法的特点在于它会唤醒条件队列中所有不为 null 的等待结点。方法实现如下：\n\n```java\npublic final void signalAll() {\n    if (!isHeldExclusively()) {\n        // 先检测当前线程是否获取到了锁，否则不允许继续执行\n        throw new IllegalMonitorStateException();\n    }\n    // 获取条件队列头结点\n    Node first = firstWaiter;\n    if (first != null) {\n        // 将所有结点从条件队列转移到同步队列，参与竞争资源\n        this.doSignalAll(first);\n    }\n}\n\nprivate void doSignalAll(Node first) {\n    lastWaiter = firstWaiter = null;\n    do {\n        Node next = first.nextWaiter;\n        first.nextWaiter = null;\n        transferForSignal(first);\n        first = next;\n    } while (first != null);\n}\n```\n\n实际上理解了 `ConditionObject#doSignal` 的运行机制，再理解  `ConditionObject#signalAll` 的运行机制也是水到渠成的事情。\n\n### 资源的获取与释放\n\n前面的小节我们分析了 LockSupport 工具类，以及 AQS 同步队列和条件队列的设计与实现，这些都是支撑 AQS 运行的基础组件，本小节我们将正式开始分析 AQS 的实现机制。\n\nAQS 对应的 AbstractQueuedSynchronizer 实现类，在属性定义上主要包含 4 个字段（如下），其中 exclusiveOwnerThread 由父类 AbstractOwnableSynchronizer 继承而来，用于记录当前持有独占锁的线程对象，而 head 和 tail 字段分别指向同步队列的头结点和尾结点：\n\n```java\nprivate transient Thread exclusiveOwnerThread;\n\nprivate transient volatile Node head;\nprivate transient volatile Node tail;\n\nprivate volatile int state;\n```\n\n字段 state 用于描述同步状态，对于不同的实现类来说具备不同的用途：\n\n- 对于 ReentrantLock 而言，表示当前线程获取锁的重入次数。\n- 对于 ReentrantReadWriteLock 而言，高 16 位表示获取读锁的重入次数，低 16 位表示获取写锁的重入次数。\n- 对于 Semaphore 而言，表示当前可用的信号个数。\n- 对于 CountDownLatch 而言，表示计数器当前的值。\n\n具体细节我们将在后面分析相应组件实现机制的文章中再展开说明。\n\nAbstractQueuedSynchronizer 是一个抽象类，在方法设计上引入了模板方法设计模式，下面的代码块中列出了所有需要子类依据自身运行机制针对性实现的模板方法：\n\n```java\nprotected boolean tryAcquire(int arg)\nprotected boolean tryRelease(int arg)\nprotected int tryAcquireShared(int arg)\nprotected boolean tryReleaseShared(int arg)\nprotected boolean isHeldExclusively()\n```\n\n这里先简单说明一下各个方法的作用，具体实现留到后面分析各个基于 AQS 实现组件的文章中再进一步分析：\n\n- __tryAcquire__ ：尝试以独占模式获取资源，如果获取成功则返回 true，否则返回 false。\n- __tryRelease__ ：尝试以独占模式释放资源，如果释放成功则返回 true，否则返回 false。\n- __tryAcquireShared__ ：尝试以共享模式获取资源，如果返回正数则说明获取成功，且还有可用的剩余资源；如果返回 0 则说明获取成功，但是没有可用的剩余资源；如果返回负数则说明获取资源失败。\n- __tryReleaseShared__ ：尝试以共享模式释放资源，如果释放成功则返回 true，否则返回 false。\n- __isHeldExclusively__ ：判断当前线程是否正在独占资源，如果是则返回 true，否则返回 false。\n\nAbstractQueuedSynchronizer 中的方法实现按照功能划分可以分为两大类，即获取资源（acquire）和释放资源（release），同时区分独占模式和共享模式。下面的小节中主要对获取和释放资源的方法区分独占模式和共享模式进行分析。\n\n#### 独占获取资源\n\n针对独占模式获取资源，AbstractQueuedSynchronizer 定义了多个版本的 acquire 方法实现，包括：acquire、acquireInterruptibly，以及 tryAcquireNanos，其中 acquireInterruptibly 是 acquire 的中断版本，在等待获取资源期间支持响应中断请求，tryAcquireNanos 除了支持响应中断以外，还引入了超时等待机制。\n\n下面主要分析一下 `AbstractQueuedSynchronizer#acquire` 的实现，理解了该方法的实现机制，也就自然而然理解了另外两个版本的实现机制。方法 `AbstractQueuedSynchronizer#acquire` 的实现如下：\n\n```java\npublic final void acquire(int arg) {\n    if (!this.tryAcquire(arg) // 尝试获取资源\n            // 如果获取资源失败，则将当前线程加入到同步队列的末端（独占模式），并基于自旋机制等待获取资源\n            && this.acquireQueued(this.addWaiter(Node.EXCLUSIVE), arg)) {\n        // 等待获取资源期间曾被中断过，在获取资源成功之后再响应中断\n        selfInterrupt();\n    }\n}\n```\n\n方法 `AbstractQueuedSynchronizer#tryAcquire` 的功能在前面已经简单介绍过了，用于尝试获取资源，如果获取资源失败则会将当前线程添加到同步队列中，基于自旋机制等待获取资源。\n\n方法 `AbstractQueuedSynchronizer#addWaiter` 用于将当前线程对象封装成结点添加到同步队列末端，并最终返回线程结点对象：\n\n```java\nprivate Node addWaiter(Node mode) {\n    // 为当前线程创建结点对象\n    Node node = new Node(Thread.currentThread(), mode);\n    // 基于 CAS 机制尝试快速添加结点到同步队列末端\n    Node pred = tail;\n    if (pred != null) {\n        node.prev = pred;\n        if (this.compareAndSetTail(pred, node)) {\n            pred.next = node;\n            return node;\n        }\n    }\n    // 快速添加失败，继续尝试将该结点添加到同步队列末端，如果同步队列未被初始化则执行初始化\n    this.enq(node);\n    // 返回当前线程对应的结点对象\n    return node;\n}\n```\n\n上述方法在添加结点的时候，如果同步队列已经存在，则尝试基于 CAS 操作快速将当前结点添加到同步队列末端。如果添加失败，或者队列不存在，则需要再次调用 `AbstractQueuedSynchronizer#enq` 方法执行添加操作，该方法在判断队列不存在时会初始化同步队列，然后基于 CAS 机制尝试往同步队列末端插入线程结点。方法实现如下：\n\n```java\nprivate Node enq(final Node node) {\n    for (; ; ) {\n        // 获取同步队列末尾结点\n        Node t = tail;\n        // 如果结点不存在，则初始化\n        if (t == null) { // Must initialize\n            if (this.compareAndSetHead(new Node())) {\n                tail = head;\n            }\n        } else {\n            // 往末尾追加\n            node.prev = t;\n            if (this.compareAndSetTail(t, node)) {\n                t.next = node;\n                return t;\n            }\n        }\n    }\n}\n```\n\n完成了结点的入同步队列操作，接下来会调用 `AbstractQueuedSynchronizer#acquireQueued` 方法基于自旋机制等待获取资源，在等待期间并不会响应中断，而是记录中断标志，等待获取资源成功后延迟响应。方法实现如下：\n\n```java\nfinal boolean acquireQueued(final Node node, int arg) {\n    boolean failed = true;\n    try {\n        boolean interrupted = false; // 标记自旋过程中是否被中断\n        // 基于自旋机制等待获取资源\n        for (; ; ) {\n            // 获取前驱结点\n            final Node p = node.predecessor();\n            // 如果前驱结点为头结点，说明当前结点是排在同步队列最前面，可以尝试获取资源\n            if (p == head && this.tryAcquire(arg)) {\n                // 获取资源成功，更新头结点\n                this.setHead(node); // 头结点一般记录持有资源的线程结点\n                p.next = null; // help GC\n                failed = false;\n                return interrupted; // 自旋过程中是否被中断\n            }\n            // 如果还未轮到当前结点，或者获取资源失败\n            if (shouldParkAfterFailedAcquire(p, node) // 判断是否需要阻塞当前线程\n                    && this.parkAndCheckInterrupt()) { // 如果需要，则进入阻塞状态，并在苏醒时检查中断状态\n                // 标识等待期间被中断\n                interrupted = true;\n            }\n        }\n    } finally {\n        // 尝试获取资源失败，说明执行异常，取消当前结点获取资源的进程\n        if (failed) {\n            this.cancelAcquire(node);\n        }\n    }\n}\n```\n\n上述方法会循环检测当前结点是否已经排在同步队列的最前端，如果是则调用 `AbstractQueuedSynchronizer#tryAcquire` 方法尝试获取资源，具体获取资源的过程由子类实现。自旋期间如果还未轮到调度当前线程结点，或者尝试获取资源失败，则会调用 `AbstractQueuedSynchronizer#shouldParkAfterFailedAcquire` 方法检测是否需要阻塞当前线程，具体判定的过程依赖于前驱结点的等待状态，实现如下：\n\n```java\nprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\n    // 获取前驱结点状态\n    int ws = pred.waitStatus;\n    if (ws == Node.SIGNAL) {\n        // 前驱结点状态为 SIGNAL，说明当前结点需要被阻塞\n        return true;\n    }\n    if (ws > 0) {\n        // 前驱结点处于取消状态，则一直往前寻找处于等待状态的结点，并排在其后面\n        do {\n            node.prev = pred = pred.prev;\n        } while (pred.waitStatus > 0);\n        pred.next = node;\n    } else {\n        /*\n         * 前驱结点的状态为 0 或 PROPAGATE，但是当前结点需要一个被唤醒的信号，\n         * 所以基于 CAS 将前驱结点等待状态设置为 SIGNAL，在阻塞之前，调用者需要重试以再次确认不能获取到资源。\n         */\n        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n    }\n    return false;\n}\n```\n\n上述方法首先会获取前驱结点的等待状态，并依据具体的状态值进行决策：\n\n1. 如果前驱结点等待状态为 SIGNAL，则说明当前结点需要被阻塞，所以直接返回 true；\n2. 否则，如果前驱结点的等待状态大于 0（即处于取消状态），则一直往前寻找未被取消的结点，并将当前结点排在其后，这种情况下直接返回 false，再次尝试获取一次资源；\n3. 否则，前驱结点的状态为 0 或 PROPAGATE（不可能为 CONDITION 状态，因为当前处于同步队列），因为当前结点需要一个唤醒信号，所以修改前驱结点的状态为 SIGNAL，这种情况下同样返回 false，以再次确认不能获取到资源。\n\n如果上述检查返回 true，则接下来会调用 `AbstractQueuedSynchronizer#parkAndCheckInterrupt` 方法，基于 LockSupport 工具阻塞当前线程，并在线程苏醒时检查中断状态。如果期间被中断过则记录中断标记，而不立即响应，直到成功获取到资源，或者期间发生异常退出自旋。方法 `AbstractQueuedSynchronizer#acquireQueued` 最终会返回这一中断标记，并在外围进行响应。\n\n如果在自旋期间发生异常，则上述方法会执行 `AbstractQueuedSynchronizer#cancelAcquire` 以取消当前结点等待获取资源的进程，包括设置结点的等待状态为 CANCELLED，唤醒后继结点等。\n\n#### 独占释放资源\n\n针对独占模式释放资源，AbstractQueuedSynchronizer 定义了单一实现，即 `AbstractQueuedSynchronizer#release` 方法，该方法本质上是一个调度的过程，具体释放资源的操作交由 tryRelease 方法完成，由子类实现。方法 `AbstractQueuedSynchronizer#release` 实现如下：\n\n```java\npublic final boolean release(int arg) {\n    // 尝试释放资源\n    if (this.tryRelease(arg)) {\n        Node h = head;\n        // 如果释放资源成功，则尝试唤醒后继结点\n        if (h != null && h.waitStatus != 0) {\n            this.unparkSuccessor(h);\n        }\n        return true;\n    }\n    return false;\n}\n```\n\n如果 tryRelease 释放资源成功，则上述方法会尝试唤醒同步队列中由后往前距离头结点最近的一个结点上的线程。方法 `AbstractQueuedSynchronizer#unparkSuccessor` 的实现如下：\n\n```java\nprivate void unparkSuccessor(Node node) {\n    // 获取当前结点状态\n    int ws = node.waitStatus;\n    if (ws < 0) {\n        // 如果当前结点未被取消，则基于 CAS 更新结点等待状态为 0\n        compareAndSetWaitStatus(node, ws, 0);\n    }\n\n    /*\n     * Thread to unpark is held in successor, which is normally just the next node.\n     * But if cancelled or apparently null, traverse backwards from tail to find the actual non-cancelled successor.\n     */\n    Node s = node.next; // 获取后继结点\n    // 如果后继结点为 null，或者被取消\n    if (s == null || s.waitStatus > 0) {\n        s = null;\n        // 从后往前寻找距离当前结点最近的一个未被取消的线程结点\n        for (Node t = tail; t != null && t != node; t = t.prev) {\n            if (t.waitStatus <= 0) {\n                s = t;\n            }\n        }\n    }\n    // 唤醒结点上的线程\n    if (s != null) {\n        LockSupport.unpark(s.thread);\n    }\n}\n```\n\n选举待唤醒线程结点的过程被设计成从后往前遍历，寻找距离当前结点最近的未被取消的结点，并调用 LockSupport 工具类唤醒结点上的线程。\n\n那 __为什么要设计成从后往前遍历同步队列呢__ ？在 [Doug Lea](https://en.wikipedia.org/wiki/Doug_Lea) 大神的论文 [The java.util.concurrent Synchronizer Framework](https://www.sciencedirect.com/science/article/pii/S0167642305000663) 中给出了答案，摘录如下：\n\n> An `AbstractQueuedSynchronizer` queue node contains a `next` link to its successor. But because there are no applicable techniques for lock-free atomic insertion of double-linked listnodes using compareAndSet, this link is not atomically set as part of insertion; it is simply assigned: `pred.next = node;` after the insertion. This is reflected in all usages. The `next` link is treated only as an optimized path. If a node's successor does not appear to exist (or appears to be cancelled) via its `next` field, it is always possible to start at the tail of the list and traverse backwards using the `pred` field to accurately check if therereally is one.\n\n也就说对于双向链表而言，没有不加锁的原子手段可以保证构造双向指针的线程安全性。回到代码中，我们回顾一下往同步队列中添加结点的执行过程，如下（其中 pred 是末尾结点，而 node 是待插入的结点）：\n\n```java\nnode.prev = pred;\nif (this.compareAndSetTail(pred, node)) {\n    pred.next = node;\n    return node;\n}\n```\n\n上述方法会将 node 结点的 prev 指针指向 pred 结点，而将 pred 的 next 指针指向 node 结点的过程需要建立在基于 CAS 成功将 node 设置为末端结点的基础之上，如果这一过程失败则 next 指针将会断掉，而选择从后往前遍历则始终能够保证遍历到头结点。\n\n#### 共享获取资源\n\n针对共享模式获取资源，AbstractQueuedSynchronizer 同样定义了多个版本的 acquire 方法实现，包括：acquireShared、acquireSharedInterruptibly，以及 tryAcquireSharedNanos，其中 acquireSharedInterruptibly 是 acquireShared 的中断版本，在等待获取资源期间支持响应中断请求，tryAcquireSharedNanos 除了支持响应中断以外，还引入了超时等待机制。下面同样主要分析一下 `AbstractQueuedSynchronizer#acquireShared` 的实现，理解了该方法的实现机制，也就自然而然理解了另外两个版本的实现机制。\n\n方法 `AbstractQueuedSynchronizer#acquireShared` 的实现如下：\n\n```java\npublic final void acquireShared(int arg) {\n    // 返回负数表示获取资源失败\n    if (this.tryAcquireShared(arg) < 0) {\n        // 将当前线程添加到条件队列，基于自旋等待获取资源\n        this.doAcquireShared(arg);\n    }\n}\n\nprivate void doAcquireShared(int arg) {\n    // 将当前线程加入条件队列末端，并标记为共享模式\n    final Node node = this.addWaiter(Node.SHARED);\n    boolean failed = true;\n    try {\n        boolean interrupted = false; // 标记自旋过程中是否被中断\n        for (; ; ) {\n            // 获取前驱结点\n            final Node p = node.predecessor();\n            // 如果前驱结点为头结点，说明当前结点是排在同步队列最前面，可以尝试获取资源\n            if (p == head) {\n                // 尝试获取资源\n                int r = this.tryAcquireShared(arg);\n                if (r >= 0) {\n                    // 获取资源成功，设置自己为头结点，并尝试唤醒后继结点\n                    this.setHeadAndPropagate(node, r);\n                    p.next = null; // help GC\n                    if (interrupted) {\n                        selfInterrupt();\n                    }\n                    failed = false;\n                    return;\n                }\n            }\n            // 如果还未轮到当前结点，或者获取资源失败\n            if (shouldParkAfterFailedAcquire(p, node) // 判断是否需要阻塞当前线程\n                    && this.parkAndCheckInterrupt()) { // 如果需要，则进入阻塞状态，并在苏醒时检查中断状态\n                // 标识等待期间被中断\n                interrupted = true;\n            }\n        }\n    } finally {\n        // 尝试获取资源失败，说明执行异常，取消当前结点获取资源的进程\n        if (failed) {\n            this.cancelAcquire(node);\n        }\n    }\n}\n```\n\n上述方法与 `AbstractQueuedSynchronizer#acquire` 的实现逻辑大同小异，区别在于线程在被封装成结点之后，是以共享（SHARED）模式在同步队列中进行等待。这里我们重点关注一下 `AbstractQueuedSynchronizer#setHeadAndPropagate` 方法的实现，当结点上的线程成功获取到资源会触发执行该方法，以尝试唤醒后继结点。实现如下：\n\n```java\nprivate void setHeadAndPropagate(Node node, int propagate) {\n    Node h = head; // 记录之前的头结点\n    this.setHead(node); // 头结点一般记录持有资源的线程结点\n    /*\n     * 如果满足以下条件，尝试唤醒后继结点：\n     *\n     * 1. 存在剩余可用的资源；\n     * 2. 后继结点处于等待状态，或后继结点为空\n     *\n     * Try to signal next queued node if:\n     *   Propagation was indicated by caller,\n     *   or was recorded (as h.waitStatus either before or after setHead) by a previous operation\n     *   (note: this uses sign-check of waitStatus because PROPAGATE status may transition to SIGNAL.)\n     * and\n     *   The next node is waiting in shared mode,\n     *   or we don't know, because it appears null\n     *\n     * The conservatism in both of these checks may cause unnecessary wake-ups,\n     * but only when there are multiple racing acquires/releases, so most need signals now or soon anyway.\n     */\n    if (propagate > 0 // 存在剩余可用的资源\n            || h == null || h.waitStatus < 0 // 此时 h 是之前的头结点\n            || (h = head) == null || h.waitStatus < 0) { // 此时 h 已经更新为当前头结点\n        Node s = node.next;\n        // 如果后继结点以共享模式在等待，或者后继结点未知，则尝试唤醒后继结点\n        if (s == null || s.isShared()) {\n            this.doReleaseShared();\n        }\n    }\n}\n```\n\n因为当前结点已经获取到资源，所以需要将当前结点记录到头结点中。此外，如果满足以下 2 种情况之一，还需要唤醒后继结点：\n\n1. 参数 `propagate > 0`，即存在可用的剩余资源；\n2. 前任头结点或当前头结点不存在，或指明后继结点需要被唤醒。\n\n如果满足上述条件之一，且后继结点状态未知或以共享模式在等待，则调用 `AbstractQueuedSynchronizer#doReleaseShared` 方法唤醒后继结点，关于该方法的实现留到下一小节进行分析。\n\n#### 共享释放资源\n\n针对共享模式释放资源，AbstractQueuedSynchronizer 同样定义了单一实现，即 `AbstractQueuedSynchronizer#releaseShared` 方法，该方法本质上也是一个调度的过程，具体释放资源的操作交由 tryReleaseShared 方法完成，由子类实现。方法 `AbstractQueuedSynchronizer#releaseShared` 实现如下：\n\n```java\npublic final boolean releaseShared(int arg) {\n    // 尝试释放资源\n    if (this.tryReleaseShared(arg)) {\n        // 释放资源成功，唤醒后继结点\n        this.doReleaseShared();\n        return true;\n    }\n    return false;\n}\n\nprivate void doReleaseShared() {\n    /*\n     * Ensure that a release propagates, even if there are other in-progress acquires/releases.\n     * This proceeds in the usual way of trying to unparkSuccessor of head if it needs signal.\n     * But if it does not, status is set to PROPAGATE to ensure that upon release, propagation continues.\n     * Additionally, we must loop in case a new node is added while we are doing this.\n     * Also, unlike other uses of unparkSuccessor, we need to know if CAS to reset status fails, if so rechecking.\n     */\n    for (; ; ) {\n        Node h = head;\n        if (h != null && h != tail) {\n            int ws = h.waitStatus;\n            // 如果头结点状态为 SIGNAL，则在唤醒后继结点之前尝试清除当前结点的状态\n            if (ws == Node.SIGNAL) {\n                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) {\n                    // loop to recheck cases\n                    continue;\n                }\n                // 唤醒后继结点\n                this.unparkSuccessor(h);\n            }\n            /*\n             * 如果后继结点暂时不需要被唤醒，则基于 CAS 尝试将目标结点的 waitStatus 由 0 修改为 PROPAGATE，\n             * 以保证后续由唤醒通知到来时，能够将通知传递下去\n             */\n            else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) {\n                // loop on failed CAS\n                continue;\n            }\n        }\n        // 如果头结点未变更，则说明期间持有锁的线程未发生变化，能够走到这一步说明前面的操作已经成功完成\n        if (h == head) {\n            break;\n        }\n        // 如果头结点发生变更，则说明期间持有锁的线程发生了变化，需要重试以保证唤醒动作的成功执行\n    }\n}\n```\n\n如果释放资源成功，需要依据头结点当下等待状态分别处理：\n\n1. 如果头结点的等待状态为 SIGNAL，则表明后继结点需要被唤醒，在执行唤醒操作之前需要清除等待状态。\n2. 如果头结点状态为 0，则表示后继结点不需要被唤醒，此时需要将结点状态修改为 PROPAGATE，以保证后续接收到唤醒通知时能够将通知传递下去。\n\n### 总结\n\n本文我们分析了 AQS 的设计与实现。理解了 AQS 的运行机制也就理解了 java 的 Lock 锁是如何实现线程的阻塞、唤醒、等待和通知机制的，所以理解 AQS 也是我们后面分析 Lock 锁和同步器实现的基础。\n\n从下一篇开始，我们将介绍 JUC 中基于 AQS 实现的组件，包括 ReentrantLock、ReentrantReadWriteLock、CountDownLatch，以及 Semaphore 等，去分析 AQS 中定义的模板方法是如何在这些组件中进行实现的。\n\n### 参考\n\n1. JDK 1.8 源码\n2. [The java.util.concurrent Synchronizer Framework](https://www.sciencedirect.com/science/article/pii/S0167642305000663)\n3. [知乎：Java AQS unparkSuccessor 方法中 for 循环从 tail 开始而不是 head 的疑问？](https://www.zhihu.com/question/50724462)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"深入理解 JUC：synchronized 关键字","url":"/2018/08/03/java/juc-synchronized/","content":"\n关键字 synchronized 是 java 程序员在进入并发编程世界时的银弹，只要是遇到有并发访问安全的地方，会无脑的加上一个 synchronized 关键字进行修饰。但是随着对 java 并发编程的逐渐深入，我们也开始慢慢意识到 synchronized 是一个重量级的操作，曾经甚至有一段时间人们倡导使用 Lock 来代替 synchronized 关键字。不过 Lock 虽然灵活但也有其弊端，对开发人员写出线程安全且无死锁的多线程程序要求相对要提高了许多，好在 java 6 对 synchronized 关键字进行了大刀阔斧的优化，并推荐在 Lock 和 synchronized 均满足需求的场景下优先使用 synchronized 关键字。本文我们就一起来深入分析一下 synchronized 关键字的实现内幕。<!-- more -->\n\n### 站在字节码层面看 synchronized 关键字\n\n关键字 synchronized 可以修饰实例方法、静态方法，以及代码块，对应的锁粒度分别为：\n\n1. 修饰实例方法：锁对象是方法所属类对象。\n2. 修饰静态方法：锁对象是方法所属类的 Class 对象。\n3. 修饰代码块：锁对象是 synchronized 关键字括号中指定的对象。\n\n当程序执行 synchronized 关键字修饰的代码之前，需要先获取 synchronized 关键字对应的锁对象，并在执行完成之后释放持有的锁对象。\n\n#### 修饰代码块\n\n在实现层面上，如果 synchronized 关键字修饰的是代码块，那么编译器在将 synchronized 代码块编译成字节码时，会在代码块的前后分别插入 `monitorenter` 和 `monitorexit` 指令，示例：\n\n```java\nprivate int count = 0;\n\npublic void syncMethodBlock() {\n    // ... 省略前置逻辑\n    synchronized (this) {\n        count++;\n    }\n    // ... 省略后置逻辑\n}\n```\n\n使用 `javap -v` 查看上述 java 代码对应的字节码：\n\n```java\n0: aload_0\n1: dup\n2: astore_1\n3: monitorenter // 插入 monitorenter 指令\n4: aload_0\n5: dup\n6: getfield      #2                  // Field count:I\n9: iconst_1\n10: iadd\n11: putfield      #2                  // Field count:I\n14: aload_1\n15: monitorexit // 插入 monitorexit 指令\n16: goto          24\n19: astore_2\n20: aload_1\n21: monitorexit // 插入 monitorexit 指令\n22: aload_2\n23: athrow\n24: return\n```\n\n__为什么会有 2 个 monitorexit 指令？__\n\n这主要是因为在上述实现中，关键字 synchronized 释放锁对象存在两种场景：一种是正常执行完成后释放；另外一种是发生异常后由 JVM 释放。如上述字节码所示，当正常执行时，指令 `monitorexit` 后面紧跟 goto 指令，跳转到第 24 行执行 return 返回；如果发生异常则会进入 goto 语句后面的逻辑，即执行第 2 个 `monitorexit` 指令，以确保异常的情况下锁也能够被释放，防止死锁。\n\n#### 修饰方法\n\n如果 synchronized 关键字修饰的是方法（不管是实例方法，还是静态方法），则编译器在将 java 代码编译成字节码时会给相应的方法添加一个 `ACC_SYNCHRONIZED` 访问标记（记录在运行时常量池中）。运行时线程在执行方法之前会检查该标记以确认是否需要获取相应的监视器（monitor）锁，如果执行完成退出（不管是正常退出，还是异常退出）则会释放持有的监视器锁。如果在执行 synchronized 方法期间发生了异常，并且方法中未捕获相应异常，则在将异常向上层调用方抛出去之前会释放持有的监视器锁。\n\n```java\npublic synchronized void syncMethod() { }\npublic synchronized static void syncStaticMethod() { }\n```\n\n针对上述 synchronized 方法编译得到的字节码示例：\n\n```java\npublic synchronized void syncMethod();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_SYNCHRONIZED\n    Code:\n      stack=0, locals=1, args_size=1\n         0: return\n      LineNumberTable:\n        line 13: 0\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       1     0  this   Lorg/zhenchao/concurrency/SynchronizedMain;\n\npublic static synchronized void syncStaticMethod();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_STATIC, ACC_SYNCHRONIZED\n    Code:\n      stack=0, locals=0, args_size=0\n         0: return\n      LineNumberTable:\n        line 17: 0\n```\n\n上面介绍的 `monitorenter` 和 `monitorexit` 指令，以及 `ACC_SYNCHRONIZED` 访问标记，实际上都是基于 monitor 机制实现的，每个对象都有一个 monitor 与之关联。我们通常说的获取一个对象的锁，本质上就是尝试持有该对象的 monitor。实现层面上，monitor 在 HotSpot 虚拟机中对应 `objectMonitor.cpp` 类，采用 C++ 语言实现。\n\n### Java 对象头与锁优化策略\n\n在 JVM 中，每个 java 对象都有一个对象头（object header），一个 java 对象头由标记字段（Mark Word）和类型指针（Klass Word）所构成。其中，标记字段用以存储对象的运行数据，如哈希码、GC 分代年龄，以及锁信息等，而类型指针则指向该对象所属的类。如下所示（引用自 [https://gist.github.com/arturmkrtchyan/43d6135e8a15798cc46c](https://gist.github.com/arturmkrtchyan/43d6135e8a15798cc46c)）：\n\n```text\n|----------------------------------------------------------------------------------------|--------------------|\n|                                    Object Header (64 bits)                             |        State       |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|                  Mark Word (32 bits)                  |      Klass Word (32 bits)      |                    |\n|-------------------------------------------------------|--------------------------------|--------------------|\n| identity_hashcode:25 | age:4 | biased_lock:1 | lock:2 |      OOP to metadata object    |       Normal       |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|  thread:23 | epoch:2 | age:4 | biased_lock:1 | lock:2 |      OOP to metadata object    |       Biased       |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|               ptr_to_lock_record:30          | lock:2 |      OOP to metadata object    | Lightweight Locked |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|               ptr_to_heavyweight_monitor:30  | lock:2 |      OOP to metadata object    | Heavyweight Locked |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|                                              | lock:2 |      OOP to metadata object    |    Marked for GC   |\n|-------------------------------------------------------|--------------------------------|--------------------|\n```\n\n关键字 synchronized 用到的对象锁就存在于 java 对象头的 Mark Word 中。Mark Word 依据对象所处的状态可以分为无锁状态、偏向锁、轻量级锁、重量级锁，以及 GC 5 种状态，如下图所示（以 32 位 JVM 为例）：\n\n![image](/images/2018/java-mark-word.png)\n\n其中偏向锁的 epoch 字段可以理解为偏向锁的年代信息（或版本信息），具体作用将在下面介绍偏向锁时进行说明。\n\n在 java 6 之前关键字 synchronized 的性能较差，那时候所依赖的 monitor 实现完全依靠操作系统内部的互斥锁，因需要在用户态和内核态之间进行切换，所以同步操作是一个重量级的操作。Java 6 对锁的实现引入了大量的优化措施，包括自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁，以及轻量级锁等技术，从而极大提升了 synchronized 关键字的性能，且相对于 Lock 在使用上更加简单，所以在 synchronized 能够满足需求的前提下更加推荐使用 synchronized 关键字。\n\n关于锁消除和锁粗化的概念比较简单，这里简单说明一下，其它优化技术将在下文展开介绍。\n\n- __锁消除__ 策略简单来说就是将一些实际运行过程中不存在竞争的锁对象予以剔除。基于逃逸分析技术，即时编译器能够明确哪些对象是不会逃逸的，这些非逃逸对象不会在多个线程之间进行共享，也就不存在锁竞争。这种情况下线程自身加锁解锁操作除了影响性能之外，没有任何收益，所以可以将这类锁予以消除，以提升程序性能。\n\n- __锁粗化__ 策略可以理解为将多个连续的小范围锁合并为一个大范围锁，以减少频繁加锁解锁的操作次数。Java 并发编程主张在编写并发程序时尽量缩小临界区的范围，以降低锁定的时间和锁竞争的可能性，从而提升并发程序的性能，但是如果一个线程连续遇到多个小范围的锁，频繁的加锁解锁操作也是一种开销，锁粗化技术适用于优化这一类场景。\n\n#### 偏向锁\n\n偏向锁的设计有这样一个前提，即 __大部分情况下锁不仅不存在多线程竞争，而且总是由同一个线程多次获得__ ，此时偏向锁能够降低线程获取锁的开销。\n\n当线程首次获取一个对象锁时，如果该锁对象支持偏向锁，那么 JVM 会尝试基于 CAS 操作往目标锁对象的 Mark Word 中写入当前线程的线程 ID，同时设置 Mark Word 的偏向锁标记为 1，并将锁标志位设置为 01，标识当前锁类型是一个服务于当前线程的偏向锁。当线程再次尝试获取该对象锁时，只需要做以下检查：\n\n1. 锁对象是否是偏向锁类型，即偏向锁标记为 1，锁标志位为 01；\n2. 锁对象 Mark Word 中记录的线程 ID 是否等于当前线程的 ID；\n3. 锁对象 Mark Word 中记录的 epoch 值是否与锁对象所属 Class 类中记录的 epoch 值相同。\n\n如果上述条件均满足，则可以直接获取该对象锁。\n\n下面继续介绍一下 epoch 字段的含义，我们可以简单将其理解为偏向锁的年代信息（或版本信息）。\n\n如果线程请求的锁对象是一个偏向锁，但其中记录的线程 ID 与当前线程 ID 不匹配，则 JVM 需要撤销该偏向锁（注意，此时 epoch 字段值必须匹配，否则当前线程可以认为该偏向锁已经失效，可以直接将偏向锁指向自己）。\n\n如果一个类的某个实例的偏向锁被撤销次数超过指定阈值（默认为 20，可以通过 `-XX:BiasedLockingBulkRebiasThreshold` 参数指定），则 JVM 会将该偏向锁置为无效，同时将类的 epoch 值加 1，后续遇到小于该 epoch 值的偏向锁均可以视为无效。然而更新 epoch 值可能会导致那些已经获取到该类其它实例偏向锁的线程丢失锁定状态，所以 JVM 会遍历更新这些类实例 Mark Word 中记录的 epoch 值。为了保证线程安全，整个偏向锁撤销过程需要在所有线程处于安全点（SafePoint）时执行。\n\n如果某个类的偏向锁被置为无效的次数过多（默认为 40，可以通过 `-XX:BiasedLockingBulkRevokeThreshold` 参数指定），则 JVM 会认为该类不适合采用偏向锁，因此会撤销所有类实例的偏向锁，并直接膨胀为轻量级锁。\n\n关于偏向锁引入的假设，即“大部分情况下锁不仅不存在多线程竞争，而且总是由同一个线程多次获得”，存在争议，所以一些 JVM 调优建议使用 `-XX:-UseBiasedLocking` 参数关闭偏向锁。因为一旦有第 2 个线程尝试获取这把锁，JVM 就需要执行锁膨胀转变为轻量级锁，通过开启安全点日志可以看到不少 RevokeBiasd 的纪录，像 GC 一样 Stop The World。虽然只是很短暂的停顿，但取消之后对于多线程并应用反而能够提升性能。\n\n#### 轻量级锁\n\n上面介绍的偏向锁适用于同一个线程多次获取同一个对象锁的场景，然而在实际并发应用程序中必然存在多个线程竞争同一个对象锁的情况。JVM 在处理时优先采取轻量级锁机制，以避免重量级锁带来的阻塞和唤醒开销。\n\n当执行 __加锁__ 操作时，JVM 首先会判断目标锁对象是否已经是重量级锁，如果不是则线程会在当前栈帧中创建一块区域用于存储锁记录，并将锁对象的 Mark Word 复制到锁记录中，然后线程会基于 CAS 操作尝试将锁对象中的 Mark Word 替换成指向当前栈帧中锁记录的指针，如果操作成功则当前线程成功获取到锁。在执行 CAS 时需要判断锁标志位是否为 01（即偏向锁标志），如果是则在更新锁记录成功之后会将锁标志位修改为 00（即轻量锁标志），如果不是则分为 2 种情况：\n\n1. 当前线程重复获取该轻量级锁，此时 JVM 会将锁记录清零，以表示该锁被重复获取。\n2. 其它线程持有该锁，此时 JVM 会将该锁膨胀为重量级锁，并阻塞当前线程。\n\n当执行 __解锁__ 操作时，JVM 会从线程的当前栈帧中弹出最顶层的锁记录，如果锁记录值为 0 则表示当前线程重复获取了该轻量锁，此时直接返回即可。如果不为 0，则需要基于 CAS 操作将锁对象 Mark Word 替换成当前锁记录中存储的值。这里比对的是锁对象 Mark Word 中记录的指针是否指向当前锁记录，如果是且替换成功则成功释放锁，否则需要将锁膨胀为重量级锁，并进入重量级锁的释放进程。\n\n#### 重量级锁\n\n重量级锁一般依赖于操作系统的互斥锁机制进行实现，当线程尝试对重量级锁执行加锁操作时，如果目标重量级锁已经被占用，则该线程会被阻塞，并一直等到目标重量级锁执行解锁操作时被唤醒。\n\n因为涉及到在操作系统用户态和内核态之间的切换，所以重量级锁的开销相对要大很多，为此 JVM 引入了自旋机制（ __自旋锁__ ）来减少线程阻塞的可能。所谓自旋是指线程在阻塞之前先执行一段空循环（运行的是无用指令），期间轮询尝试获取目标锁，如果恰好能够成功加锁则无需再进入阻塞状态。\n\n准确来说，自旋锁是在 java 4 中被引入的，不过那时默认是关闭的（可以通过 `-XX:+UseSpinning` 参数开启），直到 java 6 才默认开启。Java 6 中的自旋锁默认自旋次数为 10（可以通过 `-XX:PreBlockSpin` 参数调整），但是这种静态的配置无法预测运行时的需求，为此 java 6 还引入了 __适应性自旋锁__ ，其自旋次数会根据以往自旋等待时能否获取到锁来动态调整自旋的次数。\n\n当然，自旋机制也有其自身的缺点，一方面是浪费 CPU 资源，另一方面就是破坏了公平机制。当一个重量级锁被释放时，处于自旋状态的线程相对于处于阻塞状态的线程能够更早的进行感知，也就间接增加了自旋线程成功获取锁的可能性。\n\n### 总结\n\n本文介绍了 synchronized 关键字的应用场景、实现机制，以及优化技术。相对于与之功能等价的 ReentrantLock 而言，因为在使用上更加简单、不易于出错，且有 JVM 各种锁优化策略的加持，在满足需求的前提下相较于 ReentrantLock 则更加推荐使用 synchronized 关键字。当然，ReentrantLock 的灵活性是 synchronized 关键字所欠缺的，我将在后面的文章中深入分析 ReentrantLock 的实现机制。\n\n### 参考\n\n1. [Java 虚拟机规范（Java SE 8 版）](https://book.douban.com/subject/26418340/)\n2. [Java 并发编程的艺术](https://book.douban.com/subject/26591326/)\n3. [极客时间：深入拆解 java 虚拟机](https://time.geekbang.org/column/intro/108)\n4. [关键系统的 JVM 参数推荐（2018 仲夏版）](https://mp.weixin.qq.com/s/FHY0MelBfmgdRpT4zWF9dQ)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"Scala 集合：Map API","url":"/2018/05/19/scala/scala-collection-map/","content":"\nMap 定义了键值对的特质类型，区分可变与不可变，间接继承了偏函数 PartialFunction 特质，所以一个 Map 本质上也是一个偏函数，其定义如下：\n\n```scala\ntrait Map[K, +V] extends Iterable[(K, V)] with GenMap[K, V] with MapLike[K, V, Map[K, V]]\n```\n\n其伴生对象提供了构造 Map 对象的简单方式，示例：\n\n```scala\nval map1 = Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nval map2 = Map((\"name\", \"zhenchao\"), (\"age\", 28))\n```\n\n<!-- more -->\n\n可变 Map 与不可变 Map 的相互转换：\n\n- __可变 -> 不可变__\n\n将可变 Map 转换成不可变 Map 的最简单方式就是调用 toMap 函数，但是如果希望转换成特定类型的不可变 Map 类型，则需要借助 `++` 函数，示例：\n\n```scala\nval mmap = mutable.Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nval map = mmap.toMap\nmap // 输出：Map(age -> 28, name -> zhenchao)\nval tmap = mutable.TreeMap.empty[String, AnyVal] ++ mmap\ntmap // 输出：TreeMap(age -> 28, name -> zhenchao)\n```\n\n- __不可变 -> 可变__\n\n不可变 Map 转换成可变 Map 也需要借助 `++` 函数实现，示例：\n\n```scala\nval map = Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nval mmap = mutable.Map.empty[String, AnyVal] ++ map\nmmap // 输出：Map(name -> zhenchao, age -> 28)\n```\n\n### 一. 查询操作\n\n#### 1.1 get & getOrElse & apply\n\n函数 get、getOrElse 和 apply 均用于从 Map 对象中获取元素，区别在于 get 操作返回 Option 类型，getOrElse 允许在对应 key 不命中时返回默认的 value，而 apply 同样是返回指定的 key 对应的 value，但是在 key 不命中时默认抛出 NoSuchElementException 异常。示例：\n\n```scala\nval map = Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmap.get(\"name\") // 输出：zhenchao\nmap.getOrElse(\"school\", \"WHU\") // 输出：WHU\nmap.apply(\"age\") // 输出：28\nmap(\"age\") // 输出：28\n```\n\n函数 apply 同样可以使用 `()` 表达式简写。\n\n#### 1.2 withDefault & withDefaultValue\n\n上面在使用 apply 函数时，在 key 不命中的情况下默认会抛出 NoSuchElementException，如果希望改变这种行为，我们可以使用 withDefault 或 withDefaultValue 函数自定义默认行为，其中 withDefault 接收一个函数（入参是 key），而 withDefaultValue 则接收一个默认值。示例：\n\n```scala\nval map = Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nval map1 = map.withDefault(key => \"invalid key: \" + key)\nval map2 = map.withDefaultValue(\"unknown\")\nmap1(\"school\") // 输出：invalid key: school\nmap2(\"school\") // 输出：unknown\n```\n\n#### 1.3 getOrElseUpdate\n\n对于可变集合来说，可以使用 getOrElseUpdate 函数（定义如下），该函数允许提供一个 op 操作，如果对应的 key 存在则返回对应的 value，否则会计算 op 得到一个 value，并更新 Map 对象，同时返回该 value。\n\n```scala\ndef getOrElseUpdate(key: K, op: => V): V\n```\n\n示例：\n\n```scala\nval mmap = mutable.Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmmap.getOrElseUpdate(\"school\", \"WHU\") // 输出：WHU\n```\n\n### 二. 插入操作\n\n插入操作允许 value 为 null，但不允许 key 为 null，此外对于已经存在的 key，插入操作相当于更新操作。\n\n#### 2.1 `+`\n\n函数 `+` 用于往 Map 对象中添加一个或多个键值对，函数定义如下：\n\n```scala\ndef + [V1 >: V](kv: (K, V1)): Map[K, V1]\ndef + [V1 >: V] (elem1: (K, V1), elem2: (K, V1), elems: (K, V1) *): immutable.Map[K, V1]\n```\n\n示例：\n\n```scala\nval map = Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmap + (\"school\" -> \"WHU\") // 输出：Map(name -> zhenchao, age -> 28, school -> WHU)\nmap + (\"school\" -> \"CMU\", \"gender\" -> \"M\") // 输出：Map(name -> zhenchao, age -> 28, school -> CMU, gender -> M)\n```\n\n#### 2.2 `++` & `++:`\n\n函数 `++` 接收一个 GenTraversableOnce 类型的参数，只要是继承 GenTraversableOnce 的集合都可以作为参数，函数会将参数中所包含的元素添加到原 Map 对象中，并创建一个新的 Map 返回。示例：\n\n```scala\nval map = Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmap ++ Seq(\"school\" -> \"CMU\", \"gender\" -> \"M\") // 输出：Map(name -> zhenchao, age -> 28, school -> CMU, gender -> M)\nmap ++: Seq(\"school\" -> \"CMU\", \"gender\" -> \"M\") // 输出：List((name,zhenchao), (age,28), (school,CMU), (gender,M))\n```\n\n函数 `++:` 是 `++` 的右结合版本。\n\n#### 2.3 `+=` & `++=` & put\n\n对于可变集合而言，可以实现原地插入，函数 `+=` 对标 `+`，函数 `++=` 对标 `++`，函数 put 用于插入单个键值对，并返回一个 Option 类型，表示插入操作之前对应的 value。示例：\n\n```scala\nval mmap = mutable.Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmmap += (\"school\" -> \"WHU\")\nmmap += (\"school\" -> \"CMU\", \"gender\" -> \"M\")\nmmap // 输出：Map(school -> CMU, age -> 28, name -> zhenchao, gender -> M)\nmmap ++= Seq(\"age\" -> 29, \"gender\" -> \"M\")\nmmap // 输出：Map(school -> CMU, age -> 29, name -> zhenchao, gender -> M)\nmmap.put(\"country\", \"China\")\nmmap // 输出：Map(school -> CMU, country -> China, age -> 29, name -> zhenchao, gender -> M)\n```\n\n### 三. 更新操作\n\n#### 3.1 updated\n\n函数 updated 用于更新 Map 对象中指定的 key 和 value，如果不存在则添加，示例：\n\n```scala\nval map = Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmap.updated(\"age\", 29) // 输出：Map(name -> zhenchao, age -> 29)\nmap.updated(\"school\", \"WHU\") // 输出：Map(name -> zhenchao, age -> 28, school -> WHU)\n```\n\n#### 3.2 update & put\n\n对于可变集合而言，可以实现原地更新操作，函数 update 用于更新一个可变 Map 中的 key 和 value，如果不存在则会添加，效果上等价于 put，示例：\n\n```scala\nval mmap = mutable.Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmmap.update(\"age\", 29)\nmmap.update(\"school\", \"WHU\")\nmmap(\"school\") = \"CMU\"\nmmap // 输出：Map(school -> CMU, age -> 29, name -> zhenchao)\n```\n\n函数 update 同样可以简写为 `()` 表达式。\n\n### 四. 删除操作\n\n#### 4.1 `-` & `--`\n\n函数 `-` 用于删除指定的一个或多个 key，而函数 `--` 则接收一个 GenTraversableOnce 类型参数，用于批量删除给定集合中包含的所有 key，示例：\n\n```scala\nval map = Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmap - \"name\" // 输出：Map(age -> 28)\nmap -- Set(\"age\", \"school\") // 输出：Map(name -> zhenchao)\n```\n\n#### 4.2 `-=` & `--=` & remove & clear\n\n对于可变集合而言，可以实现原地删除，函数 `-=` 对标 `-`，函数 `--=` 对标 `--`，示例：\n\n```scala\nval mmap = mutable.Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmmap -= \"name\"\nmmap --= Set(\"age\", \"school\")\nmmap // 输出：Map()\n```\n\n函数 remove 用于从可变 Map 对象中删除给定的 key，并返回 key 对应的 value，Option 类型。函数 clear 用于清空整个 Map 对象。\n\n### 五. 包含检查\n\n#### 5.1 contains & isDefinedAt\n\n函数 contains 和 isDefinedAt 均用于检查 Map 对象中是否包含指定的 key，示例：\n\n```scala\nval map = Map(\"name\" -> \"zhenchao\", \"age\" -> 28)\nmap.contains(\"name\") // 输出：true\nmap.isDefinedAt(\"school\") // 输出：false\n```\n\n其中 isDefinedAt 继承自偏函数。\n\n### 六. 获取键或值的集合\n\n#### 6.1 keys & keySet & keysIterator\n\n函数 keys、keySet 和 keysIterator 均用于获取 Map 对象键的集合，区别在于函数 keys 返回的是 `Iterable[K]` 类型对象；函数 keySet 返回的是 `Set[K]` 类型对象；而函数 keysIterator 返回一个 `Iterator[K]` 类型对象。\n\n#### 6.2 values & valuesIterator\n\n函数 values 和 valuesIterator 均用于获取 Map 对象值的集合，区别在于函数 values 返回的是 `Iterable[V]` 类型，而函数 valuesIterator 返回的是 `Iterator[V]` 类型。\n\n### 七. 转换操作\n\nMap 对象考虑其特性，增加了 filterKeys、mapValues 和 transform 函数。\n\n#### 7.1 filterKeys\n\n函数 filterKeys 对 Map 对象中的 key 进行筛选，并保留满足条件的元素，示例：\n\n```scala\nval map = Map(1 -> \"zhangsan\", 2 -> \"lisi\", 3 -> \"wanger\")\nmap.filterKeys(_ % 2 == 0) // 输出：Map(2 -> lisi)\n```\n\n#### 7.2 mapValues & transform\n\n函数 mapValues 和 transform 均用于对 Map 对象的值进行转换，区别在于函数 mapValues 的入参只有 value，而 transform 的入参除了 value，还包含 key，示例：\n\n```scala\nval map = Map(1 -> \"zhangsan\", 2 -> \"lisi\", 3 -> \"wanger\")\nmap.mapValues(_.reverse) // 输出：Map(1 -> nasgnahz, 2 -> isil, 3 -> regnaw)\nmap.transform((k, v) => v + k) // 输出：Map(1 -> zhangsan1, 2 -> lisi2, 3 -> wanger3)\n```\n\n对于可变 Map 而言，因为是原地转换，所以要求 transform 操作输出的 value 类型与输入的类型相同。\n\n### 八. 反转操作\n\n对于给定的 Map 集合，我们可以使用 map 函数很容易将 key 和 value 反转，但是如果 value 存在重复，那么这个时候我们可能希望反转之后的 value 是一个集合类型，这种需求该如何实现？\n\n```scala\n// value 不重复\nval map = Map(1 -> \"zhangsan\", 2 -> \"lisi\", 3 -> \"wanger\")\nmap.map(t => (t._2, t._1)) // 输出：Map(zhangsan -> 1, lisi -> 2, wanger -> 3)\nmap.map { case (x, y) => (y, x) } // 输出：Map(zhangsan -> 1, lisi -> 2, wanger -> 3)\n\n// value 重复\nval map2 = Map(\"a\" -> 1, \"b\" -> 2, \"c\" -> 2, \"d\" -> 3, \"e\" -> 1)\nmap2.groupBy(_._2).mapValues(_.keys.toList) // 输出：Map(2 -> List(b, c), 1 -> List(e, a), 3 -> List(d))\n```\n\n上述示例中重复 value 的反转执行流程如下：\n\n1. 对包含重复 value 的 Map 执行 groupBy 操作：`Map(2 -> Map(b -> 2, c -> 2), 1 -> Map(e -> 1, a -> 1), 3 -> Map(d -> 3))`；\n2. 对步骤 1 的结果执行 mapValues 操作，提取 key，并封装成 List 集合。\n\n### 参考\n\n- [Scala Documentation](https://docs.scala-lang.org/)\n- [Scala 集合技术手册](https://book.douban.com/subject/26819038/)\n","tags":["Scala"],"categories":["scala"]},{"title":"Scala 集合：Set API","url":"/2018/05/18/scala/scala-collection-set/","content":"\nSet 用于表示一个不包含重复元素的集合，不强调元素的顺序性。Set 同样被定义为是一个特质类型，区分可变与不可变，定义如下：\n\n```scala\ntrait Set[A] extends (A => Boolean)\n                with Iterable[A]\n                with GenSet[A]\n                with GenericSetTemplate[A, Set]\n                with SetLike[A, Set[A]]\n```\n\n<!-- more -->\n\n### 一. 插入操作\n\n#### 1.1 `+`\n\n函数 `+` 用于往 Set 对象中添加一个或多个元素，其定义如下：\n\n```scala\ndef + (elem: A): This\ndef + (elem1: A, elem2: A, elems: A*): This = this + elem1 + elem2 ++ elems\n```\n\n示例：\n\n```scala\nval set = Set(1, 2, 3)\nset + 4 // 输出：Set(1, 2, 3, 4)\nset + (4, 5) // 输出：Set(5, 1, 2, 3, 4)\n```\n\n#### 1.2 `++` & `++:`\n\n函数 `++` 接收一个 GenTraversableOnce 类型的参数，只要是继承自 GenTraversableOnce 的集合都可以作为参数，函数会将参数中所包含的元素添加到原 Set 对象中，并创建一个新的 Set 对象返回。示例：\n\n```scala\nval set = Set(1, 2, 3)\nset ++ Seq(4, 5) // 输出：Set(5, 1, 2, 3, 4)\nset ++: Seq(4, 5) // 输出：List(1, 2, 3, 4, 5)\n```\n\n函数 `++:` 相对于 `++` 的区别在于右结合，所以上面的示例对应的结果类型是 List。\n\n#### 1.3 `+=` & `++=` & add\n\n对于可变集合而言，可以实现原地插入，函数 `+=` 对标 `+`，而 `++=` 则对标 `++`，示例：\n\n```scala\nval mset = mutable.Set(1, 2, 3)\nmset += 4\nmset += (5, 6)\nmset // 输出：Set(1, 5, 2, 6, 3, 4)\nmset ++= Set(7, 8)\nmset // 输出：Set(1, 5, 2, 6, 3, 7, 4, 8)\n```\n\n函数 add 同样适用于可变 Set 对象，用于往 Set 对象中添加单个元素，如果 Set 中已经包含该元素则返回 false，否则返回 true。示例：\n\n```scala\nval mset = mutable.Set(1, 2, 3)\nmset.add(3) // 输出：false\nmset.add(4) // 输出：true\n```\n\n### 二. 更新操作\n\n#### 2.1 update\n\n对于可变集合来说，函数 update 用于更新集合中的元素（定义如下），其中参数 elem 对应需要更新的元素值，而参数 included 则用于指定是添加（`included = true`）还是删除（`included = false`）。\n\n```scala\ndef update(elem: A, included: Boolean)\n```\n\n示例：\n\n```scala\nval set = mutable.Set(1, 2, 3)\nset.update(0, included = true)\nset // 输出：Set(0, 1, 2, 3)\nset.update(0, included = false)\nset // 输出：Set(1, 2, 3)\n```\n\n其中 `set.update(0, included = true)` 可以简写为 `set(0) = true`，`set.update(0, included = false)` 可以简写为 `set(0) = false`。\n\n### 三. 删除操作\n\n#### 3.1 `-` & `--`\n\n函数 `-` 用于从 Set 对象中移除一个或多个元素，而函数 `--` 则接收一个 GenTraversableOnce 类型参数，只要是继承自 GenTraversableOnce 的集合都可以作为参数，函数会从原 Set 对象中移除参数集合中所包含的元素。示例：\n\n```scala\nval set = Set(1 to 9: _*)\nset - 1 // 输出：Set(5, 6, 9, 2, 7, 3, 8, 4)\nset - (9, 8) // 输出：Set(5, 1, 6, 2, 7, 3, 4)\nset -- Seq(7, 6) // 输出：Set(5, 1, 9, 2, 3, 8, 4)\n```\n\n#### 3.2 `-=` & `--=`\n\n对于可变集合而言，可以实现原地删除，函数 `-=` 对标 `-`，而 `--=` 则对标 `--`，示例：\n\n```scala\nval mset = mutable.Set(1 to 9: _*)\nmset -= 1\nmset -= (9, 8)\nmset // 输出：Set(5, 2, 6, 3, 7, 4)\nmset --= Seq(7, 6)\nmset // 输出：Set(5, 2, 3, 4)\n```\n\n#### 3.3 remove & retain & clear\n\n函数 remove 用于从 Set 中移除单个元素，如果对应的元素存在则返回 true，否则返回 false；函数 retain 接收一个谓词 `A => Boolean`，用于移除所有不满足条件的元素；函数 clear 则用于清空所有元素。示例：\n\n```scala\nval mset = mutable.Set(1 to 9: _*)\nmset.remove(1) // 输出：true\nmset.remove(1) // 输出：false\nmset.retain(_ % 2 == 0)\nmset // 输出：Set(2, 6, 4, 8)\nmset.clear()\nmset // 输出：Set()\n```\n\n### 四. 包含检查\n\n#### 4.1 contains & apply\n\n函数 contains 用于检查 Set 对象中是否包含指定的元素，这是一个从父特质继承而来的方法，对于 Set 来说，可以使用 apply 函数检查是否包含指定元素，同样，函数 apply 可以使用 `()` 简写。示例：\n\n```scala\nval set = Set(1, 2, 3)\nset.contains(2) // 输出：true\nset.apply(5) // 输出：false\nset(5) // 输出：false\n```\n\n#### 4.2 subsetOf\n\n函数 subsetOf 用于检查当前 Set 对象是否是参数给定的 Set 的子集，示例：\n\n```scala\nval set = Set(1, 2, 3)\nset.subsetOf(Set(1, 2, 3, 4)) // 输出：true\nset.subsetOf(Set(1, 2)) // 输出：false\n```\n\n### 五. 集合操作\n\n#### 5.1 intersect & `&`\n\n函数 intersect 用于对于两个 Set 对象求 __交集__ ，也可以简写为 `&`，示例：\n\n```scala\nval set1 = Set(1, 2, 3)\nval set2 = Set(3, 4, 5)\nset1.intersect(set2) // 输出：Set(3)\nset1 & set2 // 输出：Set(3)\n```\n\n#### 5.2 union & `|`\n\n函数 union 用于对于两个 Set 对象求 __并集__ ，也可以简写为 `|`，示例：\n\n```scala\nval set1 = Set(1, 2, 3)\nval set2 = Set(3, 4, 5)\nset1.union(set2) // 输出：Set(5, 1, 2, 3, 4)\nset1 | set2 // 输出：Set(5, 1, 2, 3, 4)\n```\n\n#### 5.3 diff & `&~`\n\n函数 diff 用于对两个 Set 对象求 __差集__ ，也可以简写为 `&~`，示例：\n\n```scala\nval set1 = Set(1, 2, 3)\nval set2 = Set(3, 4, 5)\nset1.diff(set2) // 输出：Set(1, 2)\nset1 &~ set2 // 输出：Set(1, 2)\n```\n\n### 参考\n\n- [Scala Documentation](https://docs.scala-lang.org/)\n- [Scala 集合技术手册](https://book.douban.com/subject/26819038/)\n","tags":["Scala"],"categories":["scala"]},{"title":"Scala 集合：Seq API","url":"/2018/05/17/scala/scala-collection-seq/","content":"\nSeq 是一个特质类型（定义如下），用于表示按照一定顺序排列的元素序列，Seq 继承了偏函数 PartialFunction 特质，所以一个序列本质上也是一个偏函数，对应的函数类型是 `Int => A`，其中 A 是对应 Seq 的元素类型，而输入参数是 Seq 的下标。\n\n```scala\ntrait Seq[+A] extends PartialFunction[Int, A]\n                      with Iterable[A]\n                      with GenSeq[A]\n                      with GenericTraversableTemplate[A, Seq]\n                      with SeqLike[A, Seq[A]]\n```\n\n<!-- more -->\n\nSeq 同样分为可变和不可变两大类，此外还派生出 IndexedSeq 和 LinearSeq 两个重要的子特质：\n\n- __IndexedSeq__ ：代表索引序列，对于基于索引的操作来说效率较高，一般底层依赖于数组实现。\n- __LinearSeq__ ：代表线性序列，对于 head、tail，以及 isEmpty 一类的方法效率较高，一般底层依赖于链表实现。\n\nIndexedSeq 特质典型的实现类有 ArraySeq、Vector，以及 Range 等，其中 Vector 基于 Trie 树实现，在随机读和随机更新方面进行了权衡，虽然随机读的时间相对于数组略长，但是随机更新性能要优于数组和链表，是 iimmutable IndexedSeq 的默认实现。\n\nLinearSeq 特质的典型实现类就是 List 类型，不过 List 是一个抽象类，默认基于 ListBuffer 构建。ListBuffer 的父特质 Buffer 也是 Seq 派生的一个重要子特质，Buffer 特质声明为 mutable，用于定义可变的 Seq 集合，除了 ListBuffer 实现类，Scala 主要还提供了基于数组的 ArrayBuffer 实现。\n\n本文我们主要介绍 Seq 系的集合，包括 Seq、Buffer、List、Stack，以及 Queue。\n\n### 一. Seq\n\n#### 1.1 获取集合索引\n\n##### 1.1.1 indexOf & lastIndexOf\n\n函数 indexOf 和 lastIndexOf 均用于从给定 Seq 对象中检索指定元素的下标值（如果不存在则返回 -1），区别在于 indexOf 从左至右开始检索，而 lastIndexOf 则从右至左开始检索，同时这两个方法均允许指定检索的起始下标。函数定义如下：\n\n```scala\ndef indexOf[B >: A](elem: B): Int\ndef indexOf[B >: A](elem: B, from: Int): Int\n\ndef lastIndexOf[B >: A](elem: B): Int\ndef lastIndexOf[B >: A](elem: B, end: Int): Int\n```\n\n示例：\n\n```scala\nval seq = Seq('a' to 'z': _*)\nseq.indexOf('c') // 输出：2\nseq.lastIndexOf('h') // 输出：7\n```\n\n##### 1.1.2 indexWhere & lastIndexWhere\n\n函数 indexWhere 和 lastIndexWhere 相对于 indexOf 和 lastIndexOf 更加灵活一些，这两个函数均允许指定谓词 `A => Boolean` 来对集合中的元素进行筛选，并返回满足条件的第 1 个元素对应的下标。函数定义如下：\n\n```scala\ndef indexWhere(p: A => Boolean, from: Int): Int\ndef indexWhere(p: A => Boolean): Int\n\ndef lastIndexWhere(p: A => Boolean): Int\ndef lastIndexWhere(p: A => Boolean, end: Int): Int\n```\n\n示例：\n\n```scala\nval seq = Seq(1 to 9: _*)\nseq.indexWhere(x => x % 2 == 0 && x > 5) // 输出：5\nseq.lastIndexWhere(x => x % 2 == 1 && x < 5) // 输出：2\n```\n\n实际上 indexOf 和 lastIndexOf 底层分别使用 indexWhere 和 lastIndexWhere 进行实现。\n\n##### 1.1.3 indexOfSlice & lastIndexOfSlice\n\n函数 indexOfSlice 和 lastIndexOfSlice 用于检索给定的子序列在 Seq 对象中的位置，并返回子序列第 1 个元素对应的下标，如果不存在则返回 -1。函数定义如下：\n\n```scala\ndef indexOfSlice[B >: A](that: GenSeq[B]): Int\ndef indexOfSlice[B >: A](that: GenSeq[B], from: Int): Int\n\ndef lastIndexOfSlice[B >: A](that: GenSeq[B]): Int\ndef lastIndexOfSlice[B >: A](that: GenSeq[B], end: Int): Int\n```\n\n示例：\n\n```scala\nval seq = Seq(1 to 9: _*)\nseq.indexOfSlice(Seq(7, 8)) // 输出：6\nseq.lastIndexOfSlice(Seq(7, 8)) // 输出：6\nseq.indexOfSlice(Seq(1, 8)) // 输出：-1\nseq.lastIndexOfSlice(Seq(1, 8)) // 输出：-1\n```\n\n##### 1.1.4 indices\n\n函数 indices 用于获取 Seq 对象的索引集合，返回一个 Range 对象，示例：\n\n```scala\nval seq = Seq(\"A\", \"B\", \"C\")\nseq.indices // 输出：Range 0 until 3\n```\n\n#### 1.2 获取集合长度\n\n##### 1.2.1 length & size\n\n函数 length 和 size 都可以返回当前 Seq 对象的长度，区别在于 size 是 Traversable 中定义的方法，而 length 是 Seq 中定义的方法，二者在功能上是等价的。示例：\n\n```scala\nval seq = Seq(1 to 9: _*)\nseq.size // 输出：9\nseq.length // 输出：9\n```\n\n##### 1.2.2 lengthCompare\n\n函数 lengthCompare 接收一个参数 n，用于将当前 Seq 对象的长度 l 与该参数进行比较，如果 `l > n` 则返回 1，如果 `l == n` 则返回 0，如果 `l < n` 则返回 `l - n`。示例：\n\n```scala\nval seq = Seq(1 to 9: _*)\nseq.lengthCompare(8) // 输出：1\nseq.lengthCompare(9) // 输出：0\nseq.lengthCompare(18) // 输出：-1\n```\n\n为什么 `seq.lengthCompare(18)` 的结果是 -1，而不是 -9 呢，这是因为这里实际使用的实现类 List 覆盖实现了该方法，强制返回 -1。\n\n##### 1.2.3 segmentLength & prefixLength\n\n函数 segmentLength 接收一个谓词 `A => Boolean`，用于从指定下标 from 开始往右检索连续满足条件的子序列的最大长度，函数定义如下：\n\n```scala\ndef segmentLength(p: A => Boolean, from: Int): Int\n```\n\n而函数 prefixLength 是 segmentLength 的特殊版本，其 from 参数设置为 0，表示从头开始检索，即检索集合满足给定条件的最长前缀子序列，并返回其长度。示例：\n\n```scala\nval seq = Seq(1 to 9: _*)\nseq.segmentLength(_ < 5, 2) // 输出：2\nseq.prefixLength(_ < 5) // 输出：4\n```\n\n#### 1.3 查询操作\n\n##### 1.3.1 apply\n\n函数 apply 用于从 Seq 对象中获取指定下标的元素，例如 `seq.apply(2)` 用于获取下标为 2 的元素，也可以简写为 `seq(2)`，示例：\n\n```scala\nval seq = Seq(\"A\", \"B\", \"C\")\nseq.apply(2) // 输出：C\nseq(2) // 输出：C\n```\n\n#### 1.4 插入操作\n\n##### 1.4.1 `+:` & `:+`\n\n函数 `+:` 和 `:+` 均用于往 Seq 对象中追加元素，并返回一个新的集合对象，区别在于 `+:` 是前置追加，而 `:+` 是后置追加，示例：\n\n```scala\nval seq = Seq(2, 3, 4)\n1 +: seq // 输出：List(1, 2, 3, 4)\nseq :+ 5 // 输出：List(2, 3, 4, 5)\n```\n\n##### 1.4.2 padTo\n\n函数 padTo 用于将当前 Seq 对象中的前 len 个元素复制到新集合中，并在集合元素不够时使用给定的 elem 默认值填充。函数定义如下：\n\n```scala\ndef padTo[B >: A, That](len: Int, elem: B)(implicit bf: CanBuildFrom[Repr, B, That]): That\n```\n\n示例：\n\n```scala\nval seq = Seq(2, 3, 4)\nseq.padTo(5, 0) // 输出：List(2, 3, 4, 0, 0)\nseq.padTo(2, 0) // 输出：List(2, 3, 4)\n```\n\n#### 1.5 更新操作\n\n##### 1.5.1 updated\n\n函数 updated 用于更新 Seq 对象中指定下标位置的元素值，对于不可变集合的修改会创建出一个新的集合，而对于可变集合来说则是原地修改，所以对于可变集合可以简写为 `()` 操作符。示例：\n\n```scala\nval seq = Seq(1, 2, 3)\nseq.updated(2, 8) // 输出：List(1, 2, 8)\nval mseq = mutable.Seq(1, 2, 3)\nmseq(2) = 8\nmseq // 输出：ArrayBuffer(1, 2, 8)\n```\n\n##### 1.5.2 patch\n\n函数 patch 使用给定的元素序列 patch 替换 Seq 对象中 `[from, from + replaced)` 下标的元素。函数定义如下：\n\n```scala\ndef patch[B >: A, That](from: Int, patch: GenSeq[B], replaced: Int)(implicit bf: CanBuildFrom[Repr, B, That]): That\n```\n\n示例：\n\n```scala\nval seq = Seq(1 to 9: _*)\nseq.patch(3, Seq(8, 8, 8, 8, 8), 2) // 输出：List(1, 2, 3, 8, 8, 8, 8, 8, 6, 7, 8, 9)\n```\n\n#### 1.6 排序操作\n\n##### 1.6.1 sorted & sortBy & sortWith\n\n函数 sorted、sortBy 和 sortWith 均用于对 Seq 对象中的元素进行排序操作，区别在于：\n\n- __sorted__ ：按照元素的值从小到大进行排序。\n- __sortBy__ ：按照指定的因子从小到大对集合中的元素进行排序。\n- __sortWith__ ：接收一个比较函数 `(A, A) => Boolean`，已该函数对集合中的元素进行排序。\n\n示例：\n\n```scala\nval seq = Seq.fill(10)(Random.nextInt(100))\nseq.sorted // 输出：List(28, 36, 42, 43, 63, 66, 69, 84, 85, 88)\nseq.sortBy(_ % 10) // 输出：List(42, 63, 43, 84, 85, 66, 36, 88, 28, 69)\nseq.sortWith((x, y) => y < x) // 输出：List(88, 85, 84, 69, 66, 63, 43, 42, 36, 28)\n```\n\n#### 1.7 反转操作\n\n##### 1.7.1 reverse & reverseIterator & reverseMap\n\n函数 reverse 用于对 Seq 对象中的元素执行反转操作，而函数 reverseIterator 同样执行反转操作，只是返回的是一个迭代器对象，示例：\n\n```scala\nval seq = Seq(1 to 5: _*)\nseq.reverse // 输出：List(5, 4, 3, 2, 1)\nseq.reverseIterator // 输出：<iterator>\n```\n\n函数 reverseMap 相当于 reverse 和 map 的组合，不过执行效率更高，用于对反转的集合执行 map 操作，示例：\n\n```scala\nval seq = Seq(1 to 5: _*)\nseq.reverseMap(_ - 5) // 输出：List(0, -1, -2, -3, -4)\n```\n\n#### 1.8 包含检查\n\n##### 1.8.1 contains & containsSlice\n\n函数 contains 用于检查 Seq 对象是否包含指定单个元素，而函数 containsSlice 用于检查是否包含给定的元素序列，示例：\n\n```scala\nval seq = Seq(1 to 5: _*)\nseq.contains(3) // 输出：true\nseq.containsSlice(Seq(1, 2)) // 输出：true\nseq.containsSlice(Seq(2, 1)) // 输出：false\n```\n\n#### 1.9 转换操作\n\n##### 1.9.1 transform\n\n对于集合来说一般使用 map 函数执行转换操作，但是对于 __可变__ Seq 对象来说，Scala 还提供了 transform 函数，用于原地转换，示例：\n\n```scala\nval seq = mutable.Seq(1, 2, 3)\nseq.transform(_ * 10)\nseq // 输出：ArrayBuffer(10, 20, 30)\n```\n\n#### 1.10 集合运算\n\n##### 1.10.1 intersect\n\n函数 intersect 用于求解两个集合的 __交集__ ，示例：\n\n```scala\nval seq1 = Seq(1, 2, 3, 3)\nval seq2 = Seq(2, 3, 4, 5)\nseq1.intersect(seq2) // 输出：List(2, 3)\n```\n\n__注意__ ：如果两个集合包含重复元素，假设该元素在集合 A 中出现 x 次，在集合 B 中出现 y 次，则该元素在交集结果中出现 `min(x, y)` 次。\n\n##### 1.10.2 union\n\n函数 union 用于求解两个集合的 __并集__ ，示例：\n\n```scala\nval seq1 = Seq(1, 2, 3, 3)\nval seq2 = Seq(2, 3, 4, 5)\nseq1.union(seq2) // 输出：List(1, 2, 3, 3, 2, 3, 4, 5)\n```\n\n并集等价于 `++` 操作。\n\n##### 1.10.3 diff\n\n函数 diff 用于求解两个集合的 __差集__ ，示例：\n\n```scala\nval seq1 = Seq(1, 2, 3, 3)\nval seq2 = Seq(2, 3, 4, 5)\nseq1.diff(seq2) // 输出：List(1, 3)\n```\n\n__注意__ ：如果两个集合包含重复元素，假设该元素在集合 A 中出现 x 次，在集合 B 中出现 y 次，则该元素在差集结果中出现 `max(0, x - y)` 次。\n\n#### 1.11 排列组合\n\n##### 1.11.1 permutations\n\n函数 permutations 用于获取一个 Seq 对象中元素的全排列，示例：\n\n```scala\nval seq = Seq(1, 1, 3)\nseq.permutations.foreach(println)\n```\n\n输出：\n\n```text\nList(1, 1, 3)\nList(1, 3, 1)\nList(3, 1, 1)\n```\n\n__注意__ ：如果输入集合中包含重复元素，则在全排列时会出现重复的排列，函数 permutations 会对结果去重。\n\n##### 1.11.2 combinations\n\n函数 combinations 按照顺序从 Seq 对象中选取指定个数的元素进行组合，下面的示例按照顺序每次选择 3 个元素构建组合：\n\n```scala\nval seq = Seq(1, 2, 3, 4)\nseq.combinations(3).foreach(println)\n```\n\n输出：\n\n```text\nList(1, 2, 3)\nList(1, 2, 4)\nList(1, 3, 4)\nList(2, 3, 4)\n```\n\n#### 1.12 检查两个序列对应的元素是否满足给定条件\n\n##### 1.12.1 corresponds\n\n函数 corresponds 用于接收一个序列 that 作为参数，并接收一个谓词 `(A,B) => Boolean`，函数会按照下标对两个集合中的元素逐一比对是否满足给定条件，如果全部满足则返回 true，函数定义如下：\n\n```scala\ndef corresponds[B](that: GenSeq[B])(p: (A,B) => Boolean): Boolean\n```\n\n示例：\n\n```scala\nval seq1 = Seq(1, 2, 3)\nval seq2 = Seq.range(2, 7, 2)\nseq1.corresponds(seq2)(_ * 2 == _) // 输出：true\n```\n\n### 二. Buffer\n\nBuffer 是一个可变的序列类（继承自 Seq 特质），其定义如下：\n\n```scala\ntrait Buffer[A] extends Seq[A]\n                   with GenericTraversableTemplate[A, Buffer]\n                   with BufferLike[A, Buffer[A]]\n                   with scala.Cloneable {\n  override def companion: GenericCompanion[Buffer] = Buffer\n}\n```\n\nBuffer 的子类中最重要的两个类分别是 ListBuffer 和 ArrayBuffer：\n\n- __ListBuffer__ ：底层依赖于 `immutable.List`，以链表的形式实现，对于头部和尾部的操作的时间复杂度是 `O(1)`，因为内部使用变量保存了长度，所以 length 和 size 操作的时间复杂度也是 `O(1)`，对于其它操作基本上都是 `O(n)` 的时间复杂度。\n- __ArrayBuffer__ ：底层依赖于 ResizableArray 实现，对于尾部操作、更新，以及随机访问操作的时间复杂度都是 `O(1)`，对于头部和移除操作因为涉及到元素的移动，时间复杂度为 `O(n)`。\n\n#### 2.1 查询操作\n\n函数 apply 用于从 Buffer 对象中获取指定下标对应的元素值，示例：\n\n```scala\nval buf = mutable.Buffer(1 to 9: _*)\nbuf.apply(3) // 输出：4\nbuf(3) // 输出：4\n```\n\n函数 apply 可以简写为 `()` 表达式。\n\n#### 2.2 插入操作\n\n##### 2.2.1 `+:` & `:+`\n\n函数 `+:` 和 `:+` 用于往 Buffer 对象中添加单个元素，区别在于一个是前置添加，一个是后置添加，示例：\n\n```scala\nval buf = mutable.Buffer(1, 2, 3)\n0 +: buf // 输出：ArrayBuffer(0, 1, 2, 3)\nbuf :+ 4 // 输出：ArrayBuffer(1, 2, 3, 4)\n```\n\n__注意__ ：虽然 Buffer 本身是可变集合，但是考虑一致性，函数 `+:` 和 `:+` 均会返回一个新的集合，而非原地修改。\n\n##### 2.2.2 `++` & `++:`\n\n函数 `++` 和 `++:` 用于往 Buffer 对象中添加一个集合元素，区别在于一个是前置添加，一个是后置添加，示例：\n\n```scala\nval buf = mutable.Buffer(1, 2, 3)\nbuf ++ Seq(4, 5, 6) // 输出：ArrayBuffer(1, 2, 3, 4, 5, 6)\nSeq(-2, -1, 0) ++: buf // 输出：ArrayBuffer(-2, -1, 0, 1, 2, 3)\n```\n\n__注意__ ：虽然 Buffer 本身是可变集合，但是考虑一致性，函数 `++` 和 `++:` 均会返回一个新的集合，而非原地修改。\n\n##### 2.2.3 `+=` & `+=:` & `++=` & `++=:`\n\n函数 `+=` 和 `+=:` 均用于对 Buffer 对象执行原地修改，其中 `+=` 对标 `+`，而 `+=:` 对标 `+:`；函数 `++=` 和 `++=:` 同样用于对 Buffer 对象执行原地修改，其中 `++=` 对标 `++`，而 `++=:` 对标 `++:`。示例：\n\n```scala\nval buf = mutable.Buffer(1, 2, 3)\nbuf += 4\n0 +=: buf\nbuf // 输出：ArrayBuffer(0, 1, 2, 3, 4)\nbuf ++= Seq(6, 7)\nSeq(-2, -1) ++=: buf\nbuf // 输出：ArrayBuffer(-2, -1, 0, 1, 2, 3, 4, 6, 7)\n```\n\n##### 2.2.4 append & appendAll & prepend & prependAll\n\n函数 append 对标 `+=`，函数 appendAll 对标 `++=`；函数 prepend 对标 `+=:`，函数 prependAll 对标 `++=:`，示例：\n\n```scala\nval buf = mutable.Buffer(1, 2, 3)\nbuf.append(4, 5)\nbuf.appendAll(Seq(7, 8))\nbuf // 输出：ArrayBuffer(1, 2, 3, 4, 5, 7, 8)\nbuf.prepend(-1, 0)\nbuf.prependAll(Seq(-3, -2))\nbuf // 输出：ArrayBuffer(-3, -2, -1, 0, 1, 2, 3, 4, 5, 7, 8)\n```\n\n##### 2.2.5 insert & insertAll\n\n函数 insert 用于将一个或多个元素插入到 Buffer 对象的指定位置，而函数 insertAll 用于将一个集合中的元素插入到 Buffer 的指定位置，示例：\n\n```scala\nval buf = mutable.Buffer(1, 2, 3)\nbuf.insert(0, -1, 0)\nbuf.insertAll(0, mutable.Seq(-3, -2))\nbuf // 输出：ArrayBuffer(-3, -2, -1, 0, 1, 2, 3)\n```\n\n#### 2.3 更新操作\n\n##### 2.3.1 update\n\n函数 update 用于对 Buffer 对象执行原地修改，示例：\n\n```scala\nval buf = mutable.Buffer(1 to 9: _*)\nbuf.update(0, -1)\nbuf // 输出：ArrayBuffer(-1, 2, 3, 4, 5, 6, 7, 8, 9)\nbuf(0) = 1\nbuf // 输出：ArrayBuffer(1, 2, 3, 4, 5, 6, 7, 8, 9)\n```\n\n函数 update 可以使用 `()` 表达式简写。\n\n#### 2.4 删除操作\n\n##### 2.4.1 `-` & `--`\n\n函数 `-` 用于从 Buffer 对象中移除一个或多个元素，而函数 `--` 则接收一个 GenTraversableOnce 类型参数，任何实现了该特质的集合都可以作为参数使用，并从 Buffer 对象中移除集合中给定的所有元素。示例：\n\n```scala\nval buf = mutable.Buffer(1 to 9: _*)\nbuf - 1 // 输出：ArrayBuffer(2, 3, 4, 5, 6, 7, 8, 9)\nbuf - (1, 2) // 输出：ArrayBuffer(3, 4, 5, 6, 7, 8, 9)\nbuf -- Seq(1, 2, 3) // 输出：ArrayBuffer(4, 5, 6, 7, 8, 9)\n```\n\n__注意__ ：\n\n1. 如果 Buffer 包含重复元素，则移除第一个匹配的元素。\n2. 虽然 Buffer 本身是可变集合，但是考虑一致性，函数 `-` 和 `--` 均会返回一个新的集合，而非原地修改。\n\n##### 2.4.2 `-=` & `--=`\n\n函数 `-=` 用于从 Buffer 对象中原地移除一个或多个元素，而函数 `--=` 接收一个 TraversableOnce 类型参数，任何实现了该特质的集合都可以作为参数使用，并从 Buffer 对象中原地移除集合中给定的所有元素。示例：\n\n```scala\nval buf = mutable.Buffer(1 to 9: _*)\nbuf -= 1\nbuf -= (2, 3)\nbuf --= Seq(4, 5, 6)\nbuf // 输出：ArrayBuffer(7, 8, 9)\n```\n\n##### 2.4.3 remove\n\n函数 remove 用于从 Buffer 对象中移除给定下标 n 的元素，相应的重载版本允许指定参数 count，用于对指定下标 n 的位置重复执行 count 次删除操作，函数定义如下：\n\n```scala\ndef remove(n: Int): A\ndef remove(n: Int, count: Int)\n```\n\n示例：\n\n```scala\nval buf = mutable.Buffer(1 to 9: _*)\nbuf.remove(0)\nbuf // 输出：ArrayBuffer(2, 3, 4, 5, 6, 7, 8, 9)\nbuf.remove(0, 3)\nbuf // 输出：ArrayBuffer(5, 6, 7, 8, 9)\n```\n\n#### 2.5 剥离（trim）操作\n\n##### 2.5.1 trimStart & trimEnd\n\n函数 trimStart 和 trimEnd 均接收一个参数 n，分别用于从 Buffer 对象的前部移除 n 个元素和从 Buffer 对象的后部移除 n 个元素，示例：\n\n```scala\nval buf = mutable.Buffer(1 to 9: _*)\nbuf.trimStart(2)\nbuf // 输出：ArrayBuffer(3, 4, 5, 6, 7, 8, 9)\nbuf.trimEnd(2)\nbuf // 输出：ArrayBuffer(3, 4, 5, 6, 7)\n```\n\n### 三. List\n\nList 表示具备固定的 __不可变链表__ 结构，同样继承自 Seq 特质，定义如下：\n\n```scala\nsealed abstract class List[+A] extends AbstractSeq[A]\n                                  with LinearSeq[A]\n                                  with Product\n                                  with GenericTraversableTemplate[A, List]\n                                  with LinearSeqOptimized[A, List[A]]\n                                  with scala.Serializable\n```\n\nList 中定义了两个样例类 Nil 和 `::`，注意不要和 `::` 函数混淆，其中 Nil 表示一个空的 List 对象，而 `::` 类则用来建立一种链表结构。这两个类的定义如下：\n\n```scala\ncase object Nil extends List[Nothing] {\n  override def isEmpty = true\n  override def head: Nothing = throw new NoSuchElementException(\"head of empty list\")\n  override def tail: List[Nothing] = throw new UnsupportedOperationException(\"tail of empty list\")\n  // Removal of equals method here might lead to an infinite recursion similar to IntMap.equals.\n  override def equals(that: Any) = that match {\n    case that1: scala.collection.GenSeq[_] => that1.isEmpty\n    case _ => false\n  }\n}\n\nfinal case class ::[B](override val head: B, private[scala] var tl: List[B]) extends List[B] {\n  override def tail : List[B] = tl\n  override def isEmpty: Boolean = false\n}\n```\n\n之所以定义 `::` 类，是为了支持模式匹配中的中缀操作模式，从而与 `::` 操作符实现统一，示例：\n\n```scala\nval list = List(1, 2, 3, 4, 5)\nlist match {\n    case a :: b :: c :: tails => println(s\"a=$a, b=$b, c=$c, tails=$tails\")\n    case Nil => println(\"empty list\")\n}\n```\n\n输出：\n\n```text\na=1, b=2, c=3, tails=List(4, 5)\n```\n\n#### 3.1 插入操作\n\n##### 3.1.1 `::` & `:::`\n\n函数 `::` 用于往 List 对象的前部追加元素，而函数 `:::` 则用于将两个 List 对象进行连接，示例：\n\n```scala\nval list = List(3, 4, 5)\n1 :: 2 :: list // 输出：List(1, 2, 3, 4, 5)\nval list2 = List(6, 7, 8)\nlist ::: list2 // 输出：List(3, 4, 5, 6, 7, 8)\n```\n\n##### 3.1.2 `reverse_:::`\n\n函数 `reverse_:::` 用于对左边的集合反转之后，再与右边的集合执行连接操作，示例：\n\n```scala\nval list = List(3, 4, 5)\nval list2 = List(6, 7, 8)\nlist reverse_::: list2 // 输出：List(5, 4, 3, 6, 7, 8)\nlist.reverse_:::(list2) // 输出：List(8, 7, 6, 3, 4, 5)\n```\n\n__注意__ ：`list reverse_::: list2` 等价于 `list2.reverse_:::(list)`，而不是 `list.reverse_:::(list2)`。\n\n虽然 `list reverse_::: list2` 在结果上等价于 `list.reverse ::: list2`，但是前者效率更高。\n\n### 四. Stack\n\n栈（stack）是一种后进先出的数据结构，Scala 的 Stack 类在实现上同样继承自 Seq 特质，本质上是一种序列类型，默认采用链表实现。虽然 Stack 也区分可变和不可变，但是常用的还是可变的栈类型（不可变的栈定义已被标记为 `@deprecated`，因为栈的特性需要频繁被修改，而每次都创建一个新对象的设计，效率较低），定义如下：\n\n```scala\nclass Stack[A] private (var elems: List[A]) extends AbstractSeq[A]\n   with Seq[A]\n   with SeqLike[A, Stack[A]]\n   with GenericTraversableTemplate[A, Stack]\n   with Cloneable[Stack[A]]\n   with Serializable\n```\n\n#### 4.1 出栈操作\n\n##### 4.1.1 top & pop\n\n函数 top 和 pop 均可用于获取栈顶操作，区别在于 pop 在获取栈顶元素的同时会移除对应的元素，示例：\n\n```scala\nval stack = mutable.Stack(1, 2, 3)\nstack.top // 输出：1\nstack // 输出：Stack(1, 2, 3)\nstack.pop() // 输出：1\nstack // 输出：Stack(2, 3)\n```\n\n如果栈为空，则会抛出 NoSuchElementException 异常。\n\n#### 4.2 入栈操作\n\n##### 4.2.1 push & pushAll\n\n函数 push 用于将一个或多个元素压入栈顶，而函数 pushAll 接收一个 TraversableOnce 类型的集合参数，用于将集合中的所有元素逐一压栈，示例：\n\n```scala\nval stack = mutable.Stack[Int]()\nstack.push(1)\nstack.push(2, 3)\nstack.pushAll(Seq(4, 5, 6))\nstack // 输出：Stack(6, 5, 4, 3, 2, 1)\n```\n\n#### 4.3 更新操作\n\n##### 4.3.1 update\n\n函数 update 用于更新栈指定位置的元素，下标计数从栈顶开始，示例：\n\n```scala\nval stack = mutable.Stack(1, 2, 3)\nstack.update(0, -1)\nstack // 输出：Stack(-1, 2, 3)\n```\n\n### 五. Queue\n\n队列（queue）是一种先进先出的数据结构，Scala 的 Queue 类在实现上同样继承自 Seq 特质，本质上是一种序列类型。虽然 Queue 也区分可变和不可变，但是常用的还是可变的队列类型（不可变队列虽然没有被标记为 `@deprecated`，但是因为不可变的设计在这种频繁修改的场景下效率较低，所以不建议使用），定义如下：\n\n```scala\nclass Queue[A] extends MutableList[A]\n   with LinearSeqOptimized[A, Queue[A]]\n   with GenericTraversableTemplate[A, Queue]\n   with Cloneable[Queue[A]]\n   with Serializable\n```\n\n#### 5.1 出队列操作\n\n##### 5.1.1 front\n\n函数 front 用于从队列中获取头部元素，但是不移除该元素，示例：\n\n```scala\nval queue = mutable.Queue(1 to 9: _*)\nqueue.front // 输出：1\nqueue // 输出：Queue(1, 2, 3, 4, 5, 6, 7, 8, 9)\n```\n\n##### 5.1.2 dequeue & dequeueFirst & dequeueAll\n\n函数 dequeue、dequeueFirst 和 dequeueAll 均用于从队列中获取并移除满足条件的元素，其中 dequeue 用于获取并移除队头元素，而函数 dequeueFirst 和 dequeueAll 均接收一个谓词 `A => Boolean` 参数，其中 dequeueFirst 用于获取并满足条件的第一个元素，而 dequeueAll 则用于获取并移除满足条件的所有元素。示例：\n\n```scala\nval queue = mutable.Queue(1 to 9: _*)\nqueue.dequeue() // 输出：1\nqueue // 输出：Queue(2, 3, 4, 5, 6, 7, 8, 9)\nqueue.dequeueFirst(_ % 2 == 1) // 输出：Some(3)\nqueue // 输出：Queue(2, 4, 5, 6, 7, 8, 9)\nqueue.dequeueAll(_ % 2 == 0) // 输出：ArrayBuffer(2, 4, 6, 8)\nqueue // 输出：Queue(5, 7, 9)\n```\n\n#### 5.2 入队列操作\n\n##### 5.2.1 enqueue\n\n函数 enqueue 用于执行入队列操作，可以将一个或多个元素追加到队列尾部，示例：\n\n```scala\nval queue = mutable.Queue[Int]()\nqueue.enqueue(1)\nqueue.enqueue(2, 3)\nqueue // 输出：Queue(1, 2, 3)\n```\n\n### 参考\n\n- [Scala Documentation](https://docs.scala-lang.org/)\n- [Scala 集合技术手册](https://book.douban.com/subject/26819038/)\n","tags":["Scala"],"categories":["scala"]},{"title":"Scala 集合：基础 API","url":"/2018/05/16/scala/scala-collection-common/","content":"\nTraversable 和 Iterable 特质定义了 scala 集合的基本操作，后续文章中将要介绍的 Seq、Set，以及 Map 等集合都实现了这两个特质。本文主要对 Traversable 和 Iterable 中定义的方法进行归类和介绍，了解这些方法也就基本知道了 scala 集合的大部分操作。\n\nTraversable 定义为 Trait 类型，包含 2 个直接派生的子特质 `mutable.Traversable` 和 `immutable.Traversable`，分别表示可变集合和不可变集合。其中不可变集合是指集合中的元素一旦初始化完成便不可再被修改，任何对该集合的修改操作都将生成一个新的集合。Traversable 特质的定义如下：\n\n```scala\ntrait Traversable[+A] extends TraversableLike[A, Traversable[A]]\n                         with GenTraversable[A]\n                         with TraversableOnce[A]\n                         with GenericTraversableTemplate[A, Traversable]\n```\n\n<!-- more -->\n\nTraversable 是一个 Trait 类型，所以我们不能直接通过 new 关键字来创建 Traversable 对象，但是 scala 为 Traversable 定义了伴生对象，我们可以通过伴生对象的 apply 方法创建 Traversable 类型对象（eg. `Traversable(1, 2, 3)`）。同时我们可以使用 repr 函数得到这个具体的实现类对象：\n\n```scala\nval t = Traversable(1 until 10: _*)\nt.repr // 返回的是一个 List 对象\n```\n\nIterable 继承自 Traversable，也是一个特质类型，定义如下：\n\n```scala\ntrait Iterable[+A] extends Traversable[A]\n                      with GenIterable[A]\n                      with GenericTraversableTemplate[A, Iterable]\n                      with IterableLike[A, Iterable[A]]\n```\n\nIterable 同样包含 2 个直接派生的子特质 `mutable.Iterable` 和 `immutable.Iterable`。\n\n### 一. 构造 & 填充\n\n#### 1.1 fill\n\n函数 fill 可以生成指定维度的集合，并使用给定的值对集合进行填充。示例：\n\n```scala\nval t1 = Traversable.fill(3)(\"A\")\nt1 // 输出：List(A, A, A)\nval t3 = Traversable.fill(2, 3, 4)(RandomUtils.nextInt(0, 100))\nt3.foreach(println)\n```\n\n集合 t3 内容如下：\n\n```text\nList(List(18, 43, 2, 78), List(7, 78, 52, 20), List(7, 85, 77, 85))\nList(List(82, 15, 36, 29), List(5, 83, 32, 78), List(99, 22, 13, 22))\n```\n\n函数 fill 包含多个重载版本（如下），其中第 1 组参数用于指定目标集合的维度，第 2 个函数是 `elem: => A` 类型，允许我们使用不同的元素对集合进行填充，例如示例中指定的随机数函数。\n\n```scala\ndef fill[A](n: Int)(elem: => A): CC[A]\ndef fill[A](n1: Int, n2: Int)(elem: => A): CC[CC[A]]\ndef fill[A](n1: Int, n2: Int, n3: Int)(elem: => A): CC[CC[CC[A]]]\ndef fill[A](n1: Int, n2: Int, n3: Int, n4: Int)(elem: => A): CC[CC[CC[CC[A]]]]\ndef fill[A](n1: Int, n2: Int, n3: Int, n4: Int, n5: Int)(elem: => A): CC[CC[CC[CC[CC[A]]]]]\n```\n\n#### 1.2 tabulate\n\n函数 tabulate 与 fill 的功能类似，区别在于第 2 个函数，函数 tabulate 会将集合对应的下标值传递给函数 f，我们可以依据下标值生成集合元素值。函数 tabulate 的定义如下：\n\n```scala\ndef tabulate[A](n: Int)(f: Int => A): CC[A]\ndef tabulate[A](n1: Int, n2: Int)(f: (Int, Int) => A): CC[CC[A]]\ndef tabulate[A](n1: Int, n2: Int, n3: Int)(f: (Int, Int, Int) => A): CC[CC[CC[A]]]\ndef tabulate[A](n1: Int, n2: Int, n3: Int, n4: Int)(f: (Int, Int, Int, Int) => A): CC[CC[CC[CC[A]]]]\n def tabulate[A](n1: Int, n2: Int, n3: Int, n4: Int, n5: Int)(f: (Int, Int, Int, Int, Int) => A): CC[CC[CC[CC[CC[A]]]]]\n```\n\n示例（生成乘法口诀表）：\n\n```scala\nval t = Traversable.tabulate(9, 9)((x, y) => (x + 1) * (y + 1))\nt.foreach(h => println(h.mkString(\"\\t\")))\n```\n\n输出：\n\n```text\n1\t2\t3\t4\t5\t6\t7\t8\t9\n2\t4\t6\t8\t10\t12\t14\t16\t18\n3\t6\t9\t12\t15\t18\t21\t24\t27\n4\t8\t12\t16\t20\t24\t28\t32\t36\n5\t10\t15\t20\t25\t30\t35\t40\t45\n6\t12\t18\t24\t30\t36\t42\t48\t54\n7\t14\t21\t28\t35\t42\t49\t56\t63\n8\t16\t24\t32\t40\t48\t56\t64\t72\n9\t18\t27\t36\t45\t54\t63\t72\t81\n```\n\n#### 1.3 iterate\n\n函数 iterate 的定义如下，其中参数 start 用于指定起始值，len 用于限定生成集合的长度，并依据 start 值应用 f 函数生成集合元素，生成算法为 `start, f(start), f(f(start)), ...`：\n\n```scala\ndef iterate[A](start: A, len: Int)(f: A => A): CC[A]\n```\n\n示例：\n\n```scala\nval t = Traversable.iterate(1, 10)(_ + 2)\nt // 输出：List(1, 3, 5, 7, 9, 11, 13, 15, 17, 19)\n```\n\n#### 1.4 range\n\n函数 range 提供了 3 个参数，其中 start 和 end 用于指定结果元素值的上下界，参数 step 用于指定步进值：\n\n```scala\ndef range[T: Integral](start: T, end: T, step: T): CC[T]\n```\n\n示例：\n\n```scala\nval t = Traversable.range(0, 11, 2)\nt // 输出：List(0, 2, 4, 6, 8, 10)\n```\n\n### 二. 平展操作\n\n#### 2.1 flatten\n\n假设我们希望对 `Traversable(Traversable(1, 2), Traversable(2, 3), Traversable(3, 4))` 执行平展操作得到 `(1, 2, 2, 3, 3, 4)`，那么可以使用 flatten 函数实现。示例：\n\n```scala\nval t = Traversable(Traversable(1, 2), Traversable(2, 3), Traversable(3, 4))\nt.flatten // 输出：List(1, 2, 2, 3, 3, 4)\n```\n\n关于 flatten 操作的 3 个问题：\n\n1. 如果 Traversable 对象中包含的元素类型不一致怎么办，平展后的集合类型是什么？\n\n这种情况下 scala 会从类型继承树中寻找这些类型的公共父类型，并以公共类型作为结果类型，最差的结果就是生成 `Traversable[Any]` 类型的集合。示例：\n\n```scala\nval t = Traversable(Traversable(1, 2), Traversable(2L, 3L), Traversable(\"3\", \"4\"))\nt.flatten // 输出：res: Traversable[Any] = List(1, 2, 2, 3, 3, 4)\n```\n\n2. 如果 Traversable 对象中包含的元素，有的是普通类型，有的是集合类型，能否平展？\n\n如果不添加隐式转换，那么这种情况下是不允许平展的，因为 flatten 方法要求集合的元素必须继承或者能够转换成 GenTraversableOnce 类型。但是如果添加隐式转换，将元素类型转换成 Traversable 类型，就可以实现转换。示例：\n\n```scala\n// 隐式转换\nimplicit def asTraversable[T <: Any](x: T): Traversable[T] = x match {\n    case v: Traversable[T] => v\n    case v => Traversable(v)\n}\n\nval t = Traversable(1, 2, Traversable(2, 3), Traversable(3, 4))\nt.flatten(asTraversable) // 输出：List(1, 2, 2, 3, 3, 4)\n```\n\n3. 如果 Traversable 对象中包含的元素是多层嵌套集合，能否平展？\n\n平展只能是浅层的，所以这种情况下并不会执行平展操作。\n\n```scala\nval t = Traversable(Traversable(Traversable(1, 2), Traversable(2, 3)), Traversable(Traversable(3, 4)))\nt.flatten // 不会平展\n```\n\n平展 flatten 操作有一个比较典型的应用就是对包含 Option 类型的 Traversable 执行平展操作，剔除 None 值，返回 Some 所包含的值。示例：\n\n```scala\nval t = Traversable(Some(1), None, Some(2))\nt.flatten // 输出：List(1, 2)\n```\n\n### 三. 转置操作\n\n#### 3.1 transpose\n\n假设我们需要一个矩阵执行转置操作（如下），那么在 scala 中可以使用 transpose 操作完成。\n\n```text\n1  4  7      1  2  3\n2  5  8  ->  4  5  6\n3  6  9      7  8  9\n```\n\n实现：\n\n```scala\nval matrix = Traversable(Traversable(1, 2, 3), Traversable(4, 5, 6), Traversable(7, 8, 9))\nmatrix.transpose // 输出：List(List(1, 4, 7), List(2, 5, 8), List(3, 6, 9))\n```\n\n__注意__ ：每个集合中包含的元素个数必须一致。\n\n### 四. （拉）拉链操作\n\n#### 4.1 zip\n\n函数 zip 用于对两个 Iterable 对象执行拉拉链操作，并 __以较短的集合为准，忽略较长集合中多出来的元素__ ，示例：\n\n```scala\nval itr1 = Iterable(1, 3, 5)\nval itr2 = Iterable(\"A\", \"B\", \"C\", \"D\")\nitr1.zip(itr2) // 输出：List((1,A), (3,B), (5,C))\n```\n\n#### 4.2 zipAll\n\n函数 zipAll 同样用于对两个 Iterable 对象执行拉拉链操作，但是与 zip 相反的是，函数 zipAll __以较长的集合为准，并用提供的默认值对较短的集合进行弥补__ 。示例：\n\n```scala\nval itr1 = Iterable(1, 3, 5)\nval itr2 = Iterable(\"A\", \"B\", \"C\", \"D\")\nitr1.zipAll(itr2, 0, \"X\") // 输出：List((1,A), (3,B), (5,C), (0,D))\n```\n\n函数 zipAll 的定义如下：\n\n```scala\ndef zipAll[B, A1 >: A, That](that: GenIterable[B], thisElem: A1, thatElem: B)(implicit bf: CanBuildFrom[Repr, (A1, B), That]): That\n```\n\n其中参数 thisElem 用于设置左边集合对应的默认值，参数 thatElem 用于设置右边集合对应的默认值。\n\n#### 4.3 zipWithIndex\n\n函数 zipWithIndex 用于将 Iterable 对象中的元素与集合下标进行拉拉链操作，示例：\n\n```scala\nval itr = Iterable(\"A\", \"B\", \"C\", \"D\")\nitr.zipWithIndex // 输出：List((A,0), (B,1), (C,2), (D,3))\n```\n\n如果需要将下标放置在前面，我们可以使用 map 函数进行转换：\n\n```scala\nval itr = Iterable(\"A\", \"B\", \"C\", \"D\")\nitr.zipWithIndex.map(x => (x._2, x._1)) // 输出：List((0,A), (1,B), (2,C), (3,D))\n```\n\n### 五. （解）拉链操作\n\n#### 5.1 unzip\n\n示例：\n\n```scala\nval t = Traversable(\"a\" -> 1, \"b\" -> 2, \"c\" -> 3)\nval tuple = t.unzip\ntuple._1 // 输出：List(a, b, c)\ntuple._2 // 输出：List(1, 2, 3)\n```\n\n函数 unzip 的定义如下：\n\n```scala\ndef unzip[A1, A2](implicit asPair: A => (A1, A2)): (CC[A1], CC[A2])\n```\n\n函数接收一个 `A => (A1, A2)` 类型的 asPair 隐式参数，我们可以自定义该隐式参数，以实现更加复杂的解拉链操作，示例：\n\n```scala\nval t = Traversable(\"a_1\", \"b_2\", \"c_3\")\nval tuple = t.unzip(x => (x(0), x.substring(2).toInt))\ntuple._1 // 输出：List(a, b, c)\ntuple._2) // 输出：List(1, 2, 3)\n```\n\n#### 5.2 unzip3\n\n函数 unzip 用于将 1 个集合分成 2 个集合，而函数 unzip3 则用于将 1 个集合分成 3 个集合，unzip3 的定义如下：\n\n```scala\ndef unzip3[A1, A2, A3](implicit asTriple: A => (A1, A2, A3)): (CC[A1], CC[A2], CC[A3])\n```\n\n函数 unzip3 接收一个 `A => (A1, A2, A3)` 类型的 asTriple 隐式参数。示例：\n\n```scala\nval t = Traversable(\"name, age, school\", \"zhenchao, 28, WHU\", \"guida, 28, HUST\")\nval tuple3 = t.unzip3(x => {\n    val elems = x.split(\", \")\n    (elems(0), elems(1), elems(2))\n})\ntuple3._1 // 输出：List(name, zhenchao, guida)\ntuple3._2 // 输出：List(age, 28, 28)\ntuple3._3 // 输出：List(school, WHU, HUST)\n```\n\n### 六. 连接操作\n\n#### 6.1 ++\n\n如果有 2 个 Traversable 对象，我们希望将这 2 个对象中的元素进行连接，可以使用 `++` 函数，示例：\n\n```scala\nval t1 = Traversable(1, 2, 3)\nval t2 = Traversable(3, 4, 5)\nt1 ++ t2 // 输出：List(1, 2, 3, 3, 4, 5)\n```\n\n需要注意的是，函数 `++` 并不要求这两个 Traversable 对象中的元素类型必须一致，示例：\n\n```scala\nval t1 = Traversable(1, 2, 3)\nval t2 = Traversable(\"3\", \"4\", \"5\")\nt1 ++ t2 // 输出：List(1, 2, 3, 3, 4, 5)\n```\n\n连接操作的结果类型是 `scala.collection.immutable.$colon$colon`，即 `scala.collection.immutable.::`，其中 `::` 类型是 List 的子类型。具体的元素类型是两个 Traversable 对象中元素类型的公共父类型，这里对应的是 Any 类型。\n\n在 Traversable 的实现中，结果类型与左边的集合类型保持一致，示例：\n\n```scala\nval t1 = List(1, 2, 3)\nval t2 = Set(3, 4, 5)\n t1 ++ t2 // 结果类型为 List 类型\n t2 ++ t1 // 结果类型是 Set 类型\n```\n\n另外 Traversable 还提供了 `++:` 方法，该方法也表示连接操作，只是将左边的集合连接到右边的集合，结果类型由右边的集合决定。 __在 scala 中，以 `:` 结尾的函数都是右操作的__ ，即 `A ++ B` 等价于 `B ++: A`。\n\nScala 允许以一些特殊符号对类或方法进行命名，但是这在 JVM 中是不允许，为了保证能够正常编译，Scala 使用 mangled 技术将这些特殊字符编码成 `$name` 的形式以满足 JVM 的要求。对应字符编码之后的值如下：\n\n```text\n~ -> $tilde\n= -> $eq\n< -> $less\n> -> $greater\n! -> $bang\n# -> $hash\n% -> $percent\n^ -> $up\n| -> $bar\n* -> $times\n/ -> $div\n+ -> $plus\n- -> $minus\n: -> $colon\n\\ -> $bslash\n? -> $qmark\n@ -> $at\n```\n\n#### 6.2 concat\n\n如果我们需要对多个 Traversable 对象执行连接操作，一种解决方式就是对所有的对象执行 `++` 操作，即 `A ++ B ++ C ++ ...`，但是这样会在每次执行 `++` 操作时生成一个新的集合，影响性能。\n\n这种情况下可以使用 concat 函数，它会预先计算出所需的结果集合大小，然后生成结果，减少了中间临时集合对象的生成。示例：\n\n```scala\nval t = Traversable.concat(Traversable(0 to 5: _*), Traversable(5 to 10: _*), Traversable(10 to 15: _*))\n// 输出：List(0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15)\n```\n\n### 七. 使用偏函数（PartialFunction）对结果进行收集\n\n#### 7.1 collect & collectFirst\n\n函数 collect 的定义如下，它接收一个偏函数 PartialFunction 类型的参数：\n\n```scala\ndef collect[B, That](pf: PartialFunction[A, B])(implicit bf: CanBuildFrom[Repr, B, That]): That\n```\n\n我们可以自定义偏函数对 Traversable 集合中的元素进行筛选，仅保留满足条件的集合，示例：\n\n```scala\ndef filterEven: PartialFunction[Int, String] = {\n    case x if x % 2 == 0 => x.toString // 输出类型为 String，仅输出偶数\n}\n\nval t = Traversable(1 to 10: _*)\nt.collect(filterEven) // 输出：List(2, 4, 6, 8, 10)\n```\n\n与 filter 函数不同的是，偏函数接收一个集合中的元素 A，并输出一个结果元素 B，元素 B 的类型可以与 A 的类型不同。可以说 collect 函数兼具 filter 和 map 的功能。\n\n函数 collectFirst 是 collect 的特殊版本，它返回满足条件的第 1 个元素，对应 Option 类型，如果不存在满足条件的元素则返回 None。\n\n__偏函数说明：__\n\n包括在花括号内的一组 case 语句组成一个偏函数（partial function），偏函数并非对所有输入值都有定义，常见的 try-catch 语句的 catch 子句就是一个偏函数。偏函数是特质 `PartialFunction[-A, +B]` 的一个实例，其中 A 是入参类型，B 是返回值类型，该类有两个方法，apply 方法从匹配到的模式计算函数值，isDefinedAt 方法校验当前的输入是否有对应匹配的模式，如果有则返回 true，否则返回 false。示例：\n\n```scala\nval f: PartialFunction[Char, Int] = {\n    case '+' => 1\n    case '-' => -1\n}\n```\n\n调用：\n\n```scala\n\"-3+4\".collect(f) // Vector(-1, 1)\nf.apply('+') // 1\nf.isDefinedAt('*') // false\n```\n\n前面说到偏函数并非对所有的输入值都有定义，这里我们的入参为 `-3+4`，而偏函数 f 仅对 `-+` 有定义，所以返回值是 `(-1, 1)`。如果完全覆盖了所有场景则是一个 Function1，而不仅仅是一个 PartialFunction。\n\n我们可以调用 `PartialFunction#lift` 方法将一个偏函数转换成返回 `Option[R]` 类型的常规函数，这样对于偏函数有定义的输入值返回 Some 类型，没有的则返回 None。方法 unlift 可以将一个常规函数转换成一个偏函数。\n\n### 八. 过滤操作\n\n#### 8.1 filter & filterNot\n\n函数 filter 和 filterNot 用于对 Traversable 对象中的元素进行筛选，区别在于前者保留满足筛选条件的元素，而后者保留不满足筛选条件的元素。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.filter(_ % 2 == 0) // 输出：List(2, 4, 6, 8, 10)\nt.filterNot(_ % 2 == 0) // 输出：List(1, 3, 5, 7, 9)\n```\n\n#### 8.2 withFilter\n\n函数 withFilter 同样接收一个谓词 `A => Boolean`，对 Traversable 对象中的元素进行筛选，并保留满足条件的元素。区别于 filter，函数 withFilter 返回的结果类型是 FilterMonadic 特质，定义如下：\n\n```scala\ntrait FilterMonadic[+A, +Repr] extends Any {\n  def map[B, That](f: A => B)(implicit bf: CanBuildFrom[Repr, B, That]): That\n  def flatMap[B, That](f: A => scala.collection.GenTraversableOnce[B])(implicit bf: CanBuildFrom[Repr, B, That]): That\n  def foreach[U](f: A => U): Unit\n  def withFilter(p: A => Boolean): FilterMonadic[A, Repr]\n}\n```\n\n也就是说我们在调用 withFilter 函数之后，接下去只能调用 map、flatMap、foreach，以及 withFilter 这几个函数。这里对应函数式编程的 Monad 概念，表示一个计算序列，可以让程序使用管道式的方式处理数据。在这样的计算模式中可以流式调用多个上述函数，但是只有在调用 foreach 时才会真正执行计算。而 filter 函数在每次调用时都会进行计算并返回一个新的集合，因此 withFilter 在性能上会更加高一些。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.withFilter(_ % 2 == 0).withFilter(_ > 6).foreach(println) // 输出：2 和 8\n```\n\n### 九. 归约操作\n\n#### 9.1 scan & scanLeft\n\n假设我们希望计算 [1, 5] 区间数据的阶乘，最简单的方式就是定义一个计算阶乘的函数，然后遍历应用集合中的每个元素，但是这样每次都需要从 1 开始执行计算，而不能复用之前的计算结果，实际上 `5! = 5 * 4!`，我们计算完 4 的阶乘之后乘以 5 即得到 5 的阶乘，而不需要重 1 开始重新计算。\n\n使用 scan 函数我们可以做到复用，函数 scan 的定义如下，它接收一个初始值 z 和一个操作符 op， __前一次的计算结果会作为初始值传递给下一次计算__ ：\n\n```scala\ndef scan[B >: A, That](z: B)(op: (B, B) => B)(implicit cbf: CanBuildFrom[Repr, B, That]): That\n```\n\n计算阶乘的示例：\n\n```scala\nval t = Traversable(1 to 5: _*)\nt.scan(1)(_ * _) // 输出：List(1, 1, 2, 6, 24, 120)\n```\n\n函数 scan 只是 scanLeft 的别名，本质上就是 scanLeft。\n\n#### 9.2 scanRight\n\n函数 scan 从左往右对集合进行遍历，而 scanRight 则从右往左对集合进行遍历，示例：\n\n```scala\nval t = Traversable(1 to 5: _*)\nt.scanRight(1)(_ * _) // 输出：List(120, 120, 60, 20, 5, 1)\n```\n\n函数 scanRight 会从右往左对集合中的元素进行遍历，并将计算结果按照同样的顺序记录到结果集合中，同时将中间结果传递给下一次计算作为初始值。\n\n#### 9.3 fold & foldLeft\n\n函数 fold 的作用与 scan 有些相似，会将上一次计算得到的中间结果传递给下一次计算，但是区别于 scan，函数 fold 并不会输出中间结果，而只是返回函数最后一次计算得到的最终结果。\n\n示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nval sum = t.fold(0)(_ + _) // 输出：55\n```\n\n上述示例使用 fold 对集合中的元素进行求和，本质上与 sum 函数是一致的，实际上 sum 底层也是依赖于 fold 实现的。\n\n函数 fold 只是 foldLeft 的别名，本质上就是 foldLeft。\n\nScala 为 foldLeft 提供了简写版的 `/:` 函数，上面的示例可以改写如下：\n\n```scala\nval sum = (0 /: t) (_ + _)\n```\n\n#### 9.4 foldRight\n\n函数 foldRight 用于对集合中元素从右往左进行遍历，并应用计算，示例：\n\n```scala\nval t = Traversable(\"a\", \"b\", \"c\")\nt.foldRight(\"x\")(_ + _) // 输出：abcx\n```\n\nScala 也为 foldRight 提供了简写版的 `:\\` 函数，上面的示例可以改写如下：\n\n```scala\nval res = (t :\\ \"x\") (_ + _)\n```\n\n#### 9.5 reduce & reduceOption & reduceLeft & reduceLeftOption\n\n函数 reduce 在功能上与 fold 相同，只是不需要提供初始值，函数 reduce 会以集合的第 1 个元素作为初始值，并提供从左往右的归约计算。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.reduce(_ + _) // 输出：55\nt.reduceLeft(_ + _) // 输出：55\nt.reduceOption(_ + _) // 输出：Some(55)\nt.reduceLeftOption(_ + _) // 输出：Some(55)\n```\n\n其实函数 reduce 和 reduceOption 分别对应函数 reduceLeft 和 reduceLeftOption 的别名，二者的区别在于当集合为空时，reduce 会抛出异常，而 reduceOption 只是返回 None。如果集合中只有 1 个元素，那么两个函数均返回该元素，而不是抛出异常。\n\n#### 9.6 reduceRight & reduceRightOption\n\n函数 reduceRight 对标 reduceLeft，函数 reduceRightOption 对标 reduceLeftOption，区别仅在于是从右往左进行计算，示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.reduceRight(_ * 10 + _) // 输出：460\nt.reduceRightOption(_ * 10 + _) // 输出：Some(460)\n```\n\n### 十. 元素获取与检索\n\n#### 10.1 head & headOption\n\n函数 head 和 headOption 都是用于从 Traversable 对象中获取第一个元素，区别在于前者在元素不存在时抛出 NoSuchElementException 异常，而后者返回 None。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.head // 输出：1\nt.headOption // 输出：Some(1)\n```\n\n#### 10.2 last & lastOption\n\n函数 last 和 lastOption 都是用于从 Traversable 对象中获取最后一个元素，区别在于前者在元素不存在时抛出 NoSuchElementException 异常，而后者返回 None。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.last // 输出：10\nt.lastOption // 输出：Some(10)\n```\n\n__注意__ ：对于 Traversable 来说，默认的 last 实现会遍历整个集合，时间复杂度为 `O(n)`。\n\n#### 10.3 find\n\n函数 find 用于从 Traversable 对象中基于给定的筛选条件 `A => Boolean` 选择第一个满足条件的元素，如果不存在则返回 None。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.find(_ % 2 == 0) // 输出：Some(2)\n```\n\n#### 10.4 tail & tails\n\n前面介绍了 head 函数用于返回 Traversable 对象的第一个元素，而 tail 函数正好与 head 函数互补，用于返回 Traversable 对象除第一个元素以外的剩余元素。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.tail // 输出：List(2, 3, 4, 5, 6, 7, 8, 9, 10)\n```\n\n我们可以说一个集合是由 head 和 tail 组成的：`head :: tail`。\n\n函数 tails 与 tail 的作用类似，但是多了一个 s，所以该函数的返回结果是一个集合，可以将 tails 看做是对集合迭代执行 tail 操作并生成结果集，其中第一个结果是原集合，而最后一个结果是空集合。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.tails.foreach(println)\n```\n\n输出：\n\n```text\nList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\nList(2, 3, 4, 5, 6, 7, 8, 9, 10)\nList(3, 4, 5, 6, 7, 8, 9, 10)\nList(4, 5, 6, 7, 8, 9, 10)\nList(5, 6, 7, 8, 9, 10)\nList(6, 7, 8, 9, 10)\nList(7, 8, 9, 10)\nList(8, 9, 10)\nList(9, 10)\nList(10)\nList()\n```\n\n#### 10.5 init & inits\n\n函数 init 的作用正好与 tail 相反，它与 last 函数正好互补，用于返回 Traversable 对象除最后一个元素以外的剩余元素。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.init // 输出：List(1, 2, 3, 4, 5, 6, 7, 8, 9)\n```\n\n而 inits 函数的作用也正好与 tails 相反，示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.inits.foreach(println)\n```\n\n输出：\n\n```text\nList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\nList(1, 2, 3, 4, 5, 6, 7, 8, 9)\nList(1, 2, 3, 4, 5, 6, 7, 8)\nList(1, 2, 3, 4, 5, 6, 7)\nList(1, 2, 3, 4, 5, 6)\nList(1, 2, 3, 4, 5)\nList(1, 2, 3, 4)\nList(1, 2, 3)\nList(1, 2)\nList(1)\nList()\n```\n\n#### 10.6 take & takeWhile\n\n函数 take 用于从 Traversable 中获取前 n 个元素（如果集合长度小于 n，则返回全部元素），示例：\n\n```scala\nval t = Traversable(1, 2, 3, 4, 5, 4, 3, 2, 1)\nt.take(5) // 输出：List(1, 2, 3, 4, 5)\n```\n\n函数 takeWhile 接收一个谓词 `A => Boolean`，用于从左往右对 Traversable 对象中的元素进行筛选，直到第一个不满足条件的元素为止。示例：\n\n```scala\nval t = Traversable(1, 2, 3, 4, 5, 4, 3, 2, 1)\nt.takeWhile(_ <= 3) // 输出：List(1, 2, 3)\n```\n\n#### 10.7 drop & dropWhile\n\n函数 drop 与 take 刚好相反，用于获取 Traversable 对象中除前 n 个元素之外的元素（如果集合长度小于 n，则返回空集合），示例：\n\n```scala\nval t = Traversable(1, 2, 3, 4, 5, 4, 3, 2, 1)\nt.drop(5) // 输出：List(4, 3, 2, 1)\n```\n\n如果 n 小于等于 0，则返回整个集合。\n\n函数 dropWhile 与 takeWhile 刚好相反，它也接收一个谓词 `A => Boolean`，用于从左往右对 Traversable 对象中的元素进行筛选并跳过开头连续满足谓词的的元素，并返回该元素之后元素组成的集合。示例：\n\n```scala\nval t = Traversable(1, 2, 3, 4, 5, 4, 3, 2, 1)\nt.dropWhile(_ <= 3) // 输出：List(4, 5, 4, 3, 2, 1)\n```\n\n#### 10.8 takeRight & dropRight\n\n函数 takeRight 用于获取 Iterable 集合的后 n 个元素，而函数 dropRight 用于阶段 Iterable 集合的后 n 个元素，示例：\n\n```scala\nval itr = Iterable(1 to 9: _*)\nitr.takeRight(3) // 输出：List(7, 8, 9)\nitr.dropRight(3) // 输出：List(1, 2, 3, 4, 5, 6)\n```\n\n#### 10.9 slice\n\n函数 slice 用于获取原 Traversable 对象的一个子集合，函数的定义为 `slice(from: Int, until: Int)`，第 2 个参数命名为 until，所以我们可以知道截取的是一个 __左闭右开__ 的区间。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.slice(3, 5) // 输出：List(4, 5)\n```\n\n__注意__ ：如果 from 或 until 的参数值超过了集合的上下标，则以集合的上下标为准，不会抛出异常。\n\n### 十一. 分组操作\n\n#### 11.1 splitAt\n\n函数 splitAt 接收一个参数 n，并以位置 n 将 Traversable 集合分割成前后两部分，示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.splitAt(3) // 输出：(List(1, 2, 3),List(4, 5, 6, 7, 8, 9, 10))\n```\n\n功能上类似于 `(t.take(n), t.drop(n))`。\n\n#### 11.2 span\n\n函数 span 接收一个谓词 `A => Boolean`，并且从左往右对 Traversable 集合进行遍历，将开头连续满足条件的元素分为一组，剩下的元素分为一组。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.span(_ < 4) // 输出：(List(1, 2, 3),List(4, 5, 6, 7, 8, 9, 10))\n```\n\n功能上类似于 `(t.takeWhile(n), t.dropWhile(n))`。\n\n#### 11.3 partition\n\n函数 partition 接收一个谓词 `A => Boolean`，相对于 span 的区别在于它会对集合中所有的元素进行筛选，并将满足条件的元素分为一组，不满足条件的元素分为另一组。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.partition(_ % 2 == 0) // 输出：(List(2, 4, 6, 8, 10),List(1, 3, 5, 7, 9))\n```\n\n#### 11.4 groupBy\n\n函数 groupBy 接收一个 `A => K` 类型参数，对 Traversable 对象中的元素进行计算并得到一个 K 类型的值，然后以 K 值作为 key，对应的集合元素作为 value，构建 Map 结果集。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.groupBy(_ % 3).foreach(println)\n```\n\n输出：\n\n```text\n(2,List(2, 5, 8))\n(1,List(1, 4, 7, 10))\n(0,List(3, 6, 9))\n```\n\n#### 11.5 grouped\n\n函数 grouped 用于对 Iterable 对象中的元素进行分组，该函数接收一个 size 参数，用于将原集合分组成长度为指定大小的多个子集合，对于最后一个子集合，其长度可能小于 size。示例：\n\n```scala\nval itr = Iterable(1 to 9: _*)\nval grouped = itr.grouped(4)\ngrouped.foreach(println)\n```\n\n输出：\n\n```text\nList(1, 2, 3, 4)\nList(5, 6, 7, 8)\nList(9)\n```\n\n#### 11.6 sliding\n\n函数 sliding 用于对 Iterable 对象进行窗口操作，该函数定义如下，其中参数 size 用于指定窗口的大小，而参数 step 用于指定每次滑动的步长（默认为 1）：\n\n```scala\ndef sliding(size: Int): Iterator[Repr]\ndef sliding(size: Int, step: Int): Iterator[Repr]\n```\n\n示例：\n\n```scala\nval itr = Iterable(1 to 9: _*)\nitr.sliding(3, 2).foreach(println)\n```\n\n输出：\n\n```text\nList(1, 2, 3)\nList(3, 4, 5)\nList(5, 6, 7)\nList(7, 8, 9)\n```\n\n### 十二. 检查操作\n\n#### 12.1 forall & exist\n\n函数 forall 和 exist 都接收一个谓词 `A => Boolean`，用于对集合中的元素进行检查，区别在于前者会对所有的元素进行校验，并在所有元素都满足条件时返回 true，而后者只需要有一个元素满足条件即返回 true。示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.forall(_ > 0) // 输出：true\nt.exists(_ % 2 == 0) // 输出：true\n```\n\n__注意__ ：对于一个空集合，函数 forall 会返回 true。\n\n#### 12.2 count\n\n函数 count 接收一个谓词 `A => Boolean`，该函数会对 Traversable 对象中所有的元素进行检查，并返回满足条件的元素个数，示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.count(_ % 2 == 0) // 输出：5\n```\n\n__注意__ ：不推荐使用 `t.filter(_ % 2 == 0).size` 进行计算，因为这样会生成一个中间集合，性能较差。\n\n### 十三. 聚合操作\n\n聚合操作对集合中的元素执行计算，并返回单一的值。\n\n#### 13.1 sum & product\n\n函数 sum 和 product 分别用于求解集合中元素的 __和__ 与 __积__ ，示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.sum // 输出：55\nt.product // 输出：3628800\n```\n\n#### 13.2 min & max\n\n函数 min 和 max 分别用于求解集合中元素的最小值和最大值，示例：\n\n```scala\nval t = Traversable(1 to 10: _*)\nt.min // 输出：1\nt.max // 输出：10\n```\n\n其中 min 和 max 函数的定义如下：\n\n```scala\nmin[B >: A](implicit cmp: Ordering[B]): A\nmax[B >: A](implicit cmp: Ordering[B]): A\n```\n\n它们都接受一个隐式参数 cmp，我们可以利用该参数自定义比较器。\n\n#### 13.3 minBy & maxBy\n\n函数 min 和 max 都是依据集合中元素值本身进行比较，而函数 minBy 和 maxBy 则允许我们指定比较的因子，示例：\n\n```scala\nval t = Traversable(\"111\", \"2\", \"33\")\nt.minBy(_.length) // 输出：2\nt.maxBy(_.toInt) // 输出：111\n```\n\n#### 13.4 aggregate\n\n函数 aggregate 是一个比 fold 和 reduce 更加抽象的高阶函数，应用上更加灵活，该函数不要求输出的结果必须是集合元素类型的父类型。函数 aggregate 定义如下：\n\n```scala\naggregate[B](z: =>B)(seqop: (B, A) => B, combop: (B, B) => B): B\n```\n\n其中 z 是初始值，seqop 用于在遍历分区的时候更新结果，combop 用于汇总各个分区的结果。\n\n示例：\n\n```scala\nval t = Traversable(\"111\", \"2\", \"33\")\nt.aggregate(0)(_ + _.toInt, _ + _) // 输出：146\n```\n\n上述示例将集合中的每个元素都转换成 Int 类型，并使用 seqop 执行求和操作，其中初始值 z 设置为 0。这里因为没有启用并行计算，所以只有一个分组在运行，对应的 combop 没有意义，我们可以将所有分区的求和结果置为 0，即 `t.aggregate(0)(_ + _.toInt, (_, _) => 0)`，对应的结果不会变化。但是如果我们启用并行计算，即 `t.par.aggregate(0)(_ + _.toInt, (_, _) => 0)`，那么结果就会是 0，改为 `t.par.aggregate(0)(_ + _.toInt, _ + _)` 即能拿到正确结果。\n\n### 十四. 生成字符串\n\n#### 14.1 mkString & addString\n\n函数 mkString 用于对 Traversable 对象中的元素拼接生成字符串，并且允许指定元素的分隔符，以及前缀和后缀。示例：\n\n```scala\nval t = Traversable(1 until 10: _*)\nt.mkString(\", \") // 输出：1, 2, 3, 4, 5, 6, 7, 8, 9\nt.mkString(\"[\", \", \", \"]\") // 输出：[1, 2, 3, 4, 5, 6, 7, 8, 9]\n```\n\n函数 addString 同样用于对 Traversable 对象中的元素拼接生成字符串， __相对于 mkString 的区别在于需要提供 StringBuilder 对象__ ，同样允许指定分隔符、前缀和后缀。 __事实上 mkString 就是利用 addString 实现的__ 。示例：\n\n```scala\nval t = Traversable(1 until 10: _*)\nt.addString(new StringBuilder()) // 输出：123456789\nt.addString(new StringBuilder(), \", \") // 输出：1, 2, 3, 4, 5, 6, 7, 8, 9\nt.addString(new StringBuilder(), \"[\", \", \", \"]\") // 输出：[1, 2, 3, 4, 5, 6, 7, 8, 9]\n```\n\n#### 14.2 stringPrefix\n\n函数 stringPrefix 用于返回集合对象的实际类型名称，示例：\n\n```scala\nval t = Traversable(1 until 10: _*)\nt.stringPrefix // 输出：List\n```\n\n### 十五. 复制元素到数组\n\n#### 15.1 copyToArray & copyToBuffer\n\n函数 toArray 可以将一个 Traversable 对象转换成一个数组对象，如果我们希望将 Traversable 对象中已有的元素复制到一个已有的数组中，那么可以使用 copyToArray 函数。示例：\n\n```scala\nval t = Traversable(1 until 10: _*)\nval res = new Array[Int](t.size / 2)\nt.copyToArray(res, 0, res.length)\nres.mkString(\", \") // 输出：1, 2, 3, 4\n```\n\n函数 copyToArray 包含 3 个重载版本，如下：\n\n```scala\ncopyToArray[B >: A](xs: Array[B]): Unit\ncopyToArray[B >: A](xs: Array[B], start: Int): Unit\ncopyToArray[B >: A](xs: Array[B], start: Int, len: Int): Unit\n```\n\n其中参数 start 对应目标数组的下标，表示待复制的元素将写入数组的哪个位置，默认为 0，参数 len 表示要复制的元素长度，默认为集合的长度，如果 len 超过了集合的长度，则以集合长度为准。\n\n函数 copyToBuffer 用于将元素复制到所提供的 buffer 对象中，示例：\n\n```scala\nval t = Traversable(1 until 10: _*)\nval buffer = mutable.Buffer[Int]()\nt.copyToBuffer(buffer)\nbuffer // 输出：ArrayBuffer(1, 2, 3, 4, 5, 6, 7, 8, 9)\n```\n\n函数 copyToBuffer 没有提供其它重载版本。\n\n### 十六. 生成视图\n\n#### 16.1 view\n\n函数 view 用于生成 Traversable 对象的视图（相当于对原集合对象的引用），它接收两个参数 from 和 until，用于指定目标视图的生成区间，如果不指定这 2 个参数则创建整个 Traversable 对象中元素的视图。示例：\n\n```scala\nval t = mutable.Seq(1 until 10: _*)\nval v = t.view(0, 3)\nval s = t.slice(0, 3)\nval f = v.force // 严格模式\nt(0) = 10\nv.mkString(\", \") // 输出：10, 2, 3\nf.mkString(\", \") // 输出：1, 2, 3\ns.mkString(\", \") // 输出：1, 2, 3\nt(0) = 8\nv.mkString(\", \") // 输出：8, 2, 3\nf.mkString(\", \") // 输出：1, 2, 3\n```\n\n__函数 view 与 slice 的区别__ ：\n\n函数 view 生成集合的一个非严格模式（non-strict）视图，即 view 是延迟计算的，如果希望转换成严格模式，则可以调用视图的 force 函数，非严格模式的视图可以看做是对原集合区间的一个引用，当原集合区间中的元素发生变更时，会反应到视图上。\n\n### 参考\n\n- [Scala Documentation](https://docs.scala-lang.org/)\n- [Scala 集合技术手册](https://book.douban.com/subject/26819038/)\n","tags":["Scala"],"categories":["scala"]},{"title":"那些年，面试被虐过的红黑树","url":"/2018/03/25/algorithm/rb-tree/","content":"\n- __面试官__ ：小桂子是吧，看你简历上写着精通 java 编程，想必对 java 已经掌握的很好了吧？\n- __小桂子__ ：系呀系呀，一直都用 java 写 bug 呢~\n- __面试官__ ：那你说说 jdk1.7 之前 HashMap 的底层实现原理呗，另外为什么在高并发场景下可能造成较高的 CPU 占用？\n- __小桂子__ ：这个。。。好像是红黑树？\n- __面试官__ ：哦？你说的是 jdk1.8 之后的设计，既然你提到了，那就聊聊红黑树这个数据结构吧，这里是白纸和笔，手写一棵吧！\n- __小桂子__ ：哎呀，哎呀哎呀，老师，突然肚子好疼，我要去一下厕所，一会儿就回来~~~\n\n<!-- more -->\n\n![image](/images/material/liu.png)\n\n面试处处是套路呀。。。不知道你是否有和小桂子一样尴尬的面试经历呢，如果有的话欢迎到评论区留言，说出你的故事～\n\n接下来我们进入正题，开始探究面试官为难小桂子的红黑树。说到红黑树，大部分人应该对他既熟悉又陌生，熟悉是因为我们每天 coding 都会直接或者间接的用到它，但是设计和实现上的复杂性又让很多人对其原理望而却步。红黑树的定义比较简单，无非是在插入和删除的过程中自平衡规则多了一些，不过再多也只是个位数而已，只要静下心来跟随本文，相信你会有所收获，let's moving...\n\n接下去的篇幅小编假设你已经对二叉树、平衡二叉树的结构、作用，以及弊端有一定的了解。\n\n![image](/images/2018/rbt.png)\n\n红黑树（如上图，引用自维基百科）是一种 __自平衡__ 的二叉树，所谓的自平衡是指在插入和删除的过程中，红黑树会采取一定的策略对树的组织形式进行调整，以尽可能的减少树的高度，从而节省查找的时间。红黑树的特性如下：\n\n> 1. 结点是红色或黑色\n> 2. 根结点始终是黑色\n> 3. 叶子结点（NIL 结点）都是黑色\n> 4. 红色结点的两个直接孩子结点都是黑色（即从叶子到根的所有路径上不存在两个连续的红色结点）\n> 5. 从任一结点到每个叶子的所有简单路径都包含相同数目的黑色结点\n\n以上性质保证了红黑树在满足平衡二叉树特征的前提下，还可以做到 __从根到叶子的最长路径最多不会超过最短路径的两倍__ ，这主要是考虑两个极端的情况，由性质 4 和 5 我们可以知道在一棵红黑树上从根到叶子的最短路径全部由黑色结点构成，而最长结点则由红黑结点交错构成（始终按照一红一黑的顺序组织），又因为最短路径和最长路径的黑色结点数目是一致的，所以最长路径上的结点数是最短路径的两倍。\n\n### 自平衡策略\n\n对于一棵红黑树的操作最基本的无外乎增删改查，其中查和改都不会改变树的结构，所以与普通平衡二叉树操作无异。剩下的就是增删操作，插入和删除都会破坏树的结构，不过借助一定的平衡策略能够让树重新满足定义。平衡策略可以简单概括为三种： __左旋转__ 、__右旋转__ ，以及 __变色__ 。在插入或删除结点之后，只要我们沿着结点到根的路径上执行这三种操作，就可以最终让树重新满足定义。\n\n- __左旋转__\n\n对于当前结点而言，如果右子结点为红色，左子结点为黑色，则执行左旋转，如下图：\n\n![image](/images/2018/rbt_1.png)\n\n- __右旋转__\n\n对于当前结点而言，如果左子、左孙子结点均为红色，则执行右旋转，如下图：\n\n![image](/images/2018/rbt_2.png)\n\n- __变色__\n\n对于当前结点而言，如果左、右子结点均为红色，则执行变色，如下图：\n\n![image](/images/2018/rbt_3.png)\n\n### 插入操作\n\n红黑树作为平衡二叉树的一种，同样需要借助于查找操作定位插入点，不过红黑树约定 __新插入的结点一律为红色__ ，这主要也是为了简化树的自平衡过程。对于一棵空树而言，插入结点为红色会增加一次变色操作，但是对于其余的情况，如果插入的结点是一个黑色结点，那么必然会破坏性质 5，而插入一个红色结点有可能会破坏性质 4，但是此时我们可以通过简单的策略对树进行调整以重新满足定义。\n\n我们约定 X 为插入的结点，P 为 X 的父结点，G 为 X 的祖父结点，U 为 X 的叔叔结点。\n\n下面遵从上述策略分场景对插入过程进行探讨：\n\n> 1.新插入结点 X 是根结点\n\n此时新插入结点为红色，违背性质 2，只需将其变为黑色即可。\n\n> 2.新插入结点 X 的父结点 P 是黑色\n\n此时需要依据新插入结点 X 值相对于父结点 P 的大小分为两种情况，如果小于则将 X 简单插入到 P 的左子位置即可（下图左），如果 X 的值大于 P，则需要将 X 插入到 P 的右子结点位置，然后执行一次左旋转即可（下图右）。\n\n![image](/images/2018/rbt_i_1.png)\n\n> 3.父结点 P 为红色，同时存在叔叔结点 U 也为红色\n\n因为 P 为红色，按照性质 4 则 G 必定为黑色，如果 X 的值小于 P，则需要在 P 的左子位置插入（如下图），插入后不满足性质 4，此时只需要执行一次变色操作，将 P、G、U 的颜色反转一下即可，因为 G 变为红色，所以路径长度减 1，但是因为 P 和 U 都变为了黑色，所以路径长度又加 1，最终长度不变，但此时 G 变为了红色，所以需要继续向上递归。\n\n![image](/images/2018/rbt_i_2.png)\n\n如果 X 的值大于 P，则需要在 P 的右子位置插入（如下图），插入后不满足性质 4，此时需要先执行左旋转变为上面这种情况，继续变色即可。\n\n![image](/images/2018/rbt_i_3.png)\n\n> 4.父结点 P 为红色，同时叔叔结点 U 为黑色或不存在\n\n因为 P 为红色，按照性质 4 则 G 必定为黑色，如果 X 的值小于 P，则需要在 P 的左子位置插入（如下图），插入后不满足性质 4，此时需要先执行一次右旋转，旋转之后仍然违背性质 4，同时左子树的高度减 1，这个时候需要再执行一次变色操作即可满足定义。\n\n![image](/images/2018/rbt_i_4.png)\n\n如果 X 的值大于 P，则需要在 P 的右子位置插入（如下图），插入后不满足性质 4，此时我们需要执行一次左旋转，然后就转换成了上面这种情况，继续右旋转、变色即可。\n\n![image](/images/2018/rbt_i_5.png)\n\n### 删除操作\n\n红黑树作为平衡二叉树的一种，同样需要借助于查找操作定位删除点，在执行删除之前我们需要判断待删除结点有几个孩子结点，如果是 2 个的话我们需要从结点的左子树中寻找值最大的结点，或者从右子树中寻找值最小的结点，并用结点值替换掉待删除结点（只要目标结点值从树上消失即可，不要纠结具体删除的是哪个结点）。这两个结点有一个共性，即最多只有一个孩子结点（因为已经是自己所处范围内的最大和最小了嘛，一山不容二虎（鼠）），此时就将需求转变成删除只有一个孩子结点的结点，相对要简单了许多。\n\n我们约定 X 为待删除的结点，P 为 X 的父结点，S 为 X 的孩子结点，B 为 X 的兄弟结点，BL 为 B 的左孩子结点，BR 为 B 的右孩子结点。\n\n1. 如果待删除结点 X 是一个红色结点，则直接删除即可，不会违反定义。\n2. 如果待删除结点 X 是一个黑色结点，且其孩子结点 S 是红色的，那么只需要将 X 替换成 S，同时将 S 由红变黑即可。\n3. 如果需要删除的结点 X 是黑色的，同时它的孩子结点 S 也是黑色的，这种情况需要进一步分场景讨论。\n\n对于第三种情况我们首先将 X 替换成 S，并重命名其为 N，N 沿用 X 对于长辈和晚辈的称呼，需要清楚这里实际删除的是 X 结点，并且删除之后通过 N 的路径长度减 1。\n\n> 1.N 是新的根\n\n这种情况比较简单，不需要再做任何调整。\n\n> 2.N 的父结点、兄弟结点 B，以及 B 的孩子结点均为黑色\n\n如下图，此时只需要将 B 变为红色即可，这样所有通过 B 的路径减 1，与所有通过 N 的路径正好一致，但是此时通过 P 的路径都减少了 1 个长度，所以需要向上递归对结点 P 继续判定。\n\n![image](/images/2018/rbt_d_1.png)\n\n> 3.N 的兄弟结点 B 为红色，其余结点均为黑色\n\n如下图，此时需要执行一次左旋转，然后将 P 和 B 的颜色互换。调整前后各个结点的路径没有变化，但是因为之前经过 N 的路径长度少了一个单位，所以此时仍然不满足定义，需要按照后面的场景继续调整。\n\n![image](/images/2018/rbt_d_2.png)\n\n> 4.N 的父结点 P 为红色，兄弟结点 B，以及 B 的孩子结点均为黑色\n\n如下图，此时我们只需要简单互换 P 和 B 的颜色，这种情况下对于不通过 N 的结点路径没有影响，但是却让通过 N 的结点路径加 1，正好弥补之前删除操作所带来的损失。\n\n![image](/images/2018/rbt_d_3.png)\n\n> 5.N 的兄弟结点 B 为黑色，B 的左孩子为红色，B 的右孩子为黑色\n\n如下图，此时我们需要先执行一次右旋转操作，然后互换 B 与 BL 的颜色，操作之后通过所有结点的路径长度并没有发生变化，却让 N 有了一个新的黑色兄弟结点，并且该兄弟结点的右孩子为红色，从而可以按照接下去介绍的一种场景继续调整。\n\n![image](/images/2018/rbt_d_4.png)\n\n注：白色结点表示该结点既可以是黑色也可以是红色，后续图示亦是如此。\n\n> 6.N 的兄弟结点 B 为黑色，B 的右孩子为红色\n\n如下图，此时我们需要先执行一次左旋转，并互换 P 和 B 的颜色，同时将 B 的右孩子结点变为黑色。变更之后，除 N 外其余结点的路径长度未发生变化，但是经过 N 的路径上却增加了一个黑色结点，这刚好弥补之前删除操作所带来的损失。\n\n![image](/images/2018/rbt_d_5.png)\n\n### 总结\n\n红黑树的主要难点在于插入和删除过程中的自平衡调整，其中插入过程的调整相对简单，删除的过程需要处理的情况要多一些，但不管是插入还是删除，都建议读者将所有的图放置在一起进行观察，能够发现其中承前启后的奥妙，本文鉴于篇幅就不再贴出长图。另外也建议读者按照上述过程自己在白纸上手动去构造一棵红黑树，并逐一将结点删除，以此来加深理解，也可以借助旧金山大学推出的交互网站辅助学习（[点击前往](https://www.cs.usfca.edu/~galles/visualization/RedBlack.html)），相关实现位于 algorithm-design 项目的 `org.zhenchao.classic.search` 包下面，地址：\n\n> [https://github.com/plotor/algorithm-design](https://github.com/plotor/algorithm-design)\n\n[《算法》](https://book.douban.com/subject/10432347/) 红宝书的作者之一 “罗伯特·塞奇威克” 是红黑树的提出者，红黑树是在 2-3 树的基础上改进而成，相对于红黑树而言 2-3 树的自平衡策略要容易理解很多，在此也推荐大家在学习时参阅相关章节。\n\n### 参考文献\n\n1. [红黑树 - 维基百科](https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91)\n2. [算法（第4版）](https://book.douban.com/subject/10432347/)\n","tags":["数据结构","算法"],"categories":["algorithm"]},{"title":"OAuth 2.0 开放授权那些事儿","url":"/2018/03/04/protocol/oauth-v2-protocol/","content":"\n[OAuth 2.0](https://tools.ietf.org/html/rfc6749) 协议是一种三方授权协议，目前大部分的第三方授权场景（例如接入微信第三方登录）均为基于该协议的标准或改进实现。[OAuth 1.0](https://tools.ietf.org/html/rfc5849) 版本于 2007 年发布，2.0 版本则在 2011 年发布，其中 2.0 版本取消了所有 token 的加密过程，并简化了授权流程，但因强制使用 HTTPS 协议，被认为安全性高于之前的版本。\n\n- 项目地址：[https://github.com/plotor/oauth4j](https://github.com/plotor/oauth4j)\n\n<!-- more -->\n\n### 小场景带你感受 OAuth 2.0 的交互过程\n\n为了让你对 OAuth 2.0 协议有一个整体上的感知，这里先设置一个小场景对协议的交互过程进行模拟。话说阿冰在花果山上有几亩果园，种了各种各样的水果，有苹果、荔枝、西瓜等等，并由管理员老王进行看管。\n\n夏天到了，果园里的的水果涨势喜人，阿冰的好朋友小桂子想去果园摘一些西瓜和荔枝解解馋，于是小桂子提着果篮吭哧吭哧就跑到了花果山。结果，被管理员老王一把拦住，呵斥道：“要摘水果，必须经过阿冰的同意，快出示相关凭证”。小桂子当然没有，还纳闷去哪搞什么凭证。这时老王拎着小桂子来到了一个茅草房前，只见上面写着“花果山街道办事处”，并告诉小桂子这里可以开具凭证。\n\n小桂子来到柜台前，业务人员询问了其姓名，并要求出示身份证件。核实身份之后，业务人员询问小桂子要去谁的果园，采摘什么水果？小桂子如实答复，不一会只见业务人员打印出了一张凭证，并将其丢入一个“时光通道”，凭证上写着：\n\n```text\n小桂子请求在您的果园采摘以下水果：\n- 采摘您的西瓜 2 个\n- 采摘您的荔枝 3 斤\n```\n\n通道那头的阿冰收到凭证之后盖上自己的印章以示同意，然后将其投回了“时光通道”。最终小桂子拿到了经过阿冰授权的凭证，跳着奔向果园。管理员老王验证了小桂子出示的凭证，并摘了 2 个西瓜和 3 斤荔枝交到了小桂子手上。\n\n一个星期后，小桂子嘴又馋了，拿着上次的凭证直奔花果山，到了果园门口又被老王拦住了，老王说：“你这凭证已经过期了，必须再次请求阿冰授权”。小桂子满脸委屈，嘟囔着：“不就想吃俩西瓜嘛，怎么就管的这么严”。\n\n小编不才，实在编不下去了，就这样结束吧。。。\n\n在这个故事中，凭证限制了小桂子是否可以获得水果，以及获得哪些水果，每种水果多少斤。此外凭证还具备生命周期，超出凭证范围的请求都会被老王拒绝。通过凭证，小桂子可以获取到自己想要的水果，阿冰也不需要亲临花果山，在做好果园管理的同时，又不影响阿冰的生活。\n\n回到正题，对于 OAuth 2.0 协议（以下简称 OAuth 协议），我相信大部分读者都有所接触，最常见的就是使用微信登录第三方应用。的确，OAuth 协议被广泛应用于第三方授权登录中，借助第三方登录可以让用户免于再次注册之苦，支持第三方登录也对这些网站、APP 起到了积极的作用，免去了复杂的注册过程，用户体验更佳。这样在提高留存率的同时，也更加易于收集用户的一些非敏感信息等，另外还可以借助一些社交类的第三方帐号进行站点推广。\n\n### 基本概念与授权流程\n\n作为第三方登录服务提供方，其核心矛盾点是 __既要让用户在对接服务的 APP 上完成登录，同时还不能让该 APP 拿到用户的密码凭证__ 。解决这一矛盾的利器就是 token（中文译为令牌），而 OAuth 协议的最终目的就是给第三方应用下发 token，它记录了用户的登录或授权状态。通过将 token 下发给第三方应用，既能让 APP 登录并拿到用户许可的数据，也可以将用户的密码凭证牢牢拽在服务自己手里。\n\n上面的论述可能侧重了第三方登录，实际上登录只是一个授权的过程，OAuth 2.0 协设计的目的在于开放授权。对于一个应用，其最终目的还是在于拿到用户存储在资源服务器上的用户数据，所以登录授权还只是第一步，后续 APP 还需要携带 token 去资源服务器请求用户数据，这个时候是一个鉴权的过程。OAuth 协议的主要目的在于授权，至于鉴权，实现上主要还是对请求传递过来的 token 进行解析和验证，这一块相对要简单一些，所以本文主要讲解 OAuth 授权的过程。\n\n#### 角色定义\n\nOAuth 2.0 协议的交互过程主要涉及 4 类角色：\n\n- __资源所有者（resource owner）__ ：受保护资源所属的实体，比如资源的所有人，下文的用户即为资源所有者。\n- __资源服务器（resource server）__ ：托管受保护资源的服务器，能够响应持有访问令牌的资源访问请求，可以与授权服务器是同一台服务器，也可以分开。\n- __客户端（client）__ ：客户端是 OAuth 服务的接入方，其目的是希望请求用户存储在资源服务器上的受保护资源。\n- __授权服务器（authorization server）__ ：授权服务器的主要职责是验证资源所有者的身份，并依据资源所有者的许可向客户端下发访问令牌。\n\n在之前的故事中，果园中的水果就是资源，而资源所有者是阿冰，果园可以看做是资源服务器，小桂子就是客户端，而街道办事处是整个流程的授权中心，也就是上面的授权服务器。\n\n#### 基本概念\n\n##### 访问令牌（access token）\n\n还记得故事中老王问小桂子要的凭证吗？凭证限制了小桂子只能摘 2 个西瓜和 3 斤荔枝，并且凭证还是具备生命周期的，一个星期之后小桂子再拿着过期的凭证老王也不认了。\n\n实际上故事中的凭证对应的是 OAuth 2.0 中的访问令牌，访问令牌是在用户授权许可下，授权服务器下发给客户端的一个授权凭证，该令牌所要表达的意思是 __“用户授予该 APP 在多少时间范围内允许访问哪些与自己相关的服务或数据 ”__ ，所以访问令牌主要在 __时间__ 和 __权限__ 两个维度进行控制。此外，访问令牌对于客户端来说是就是一个字符串，客户端无法知晓字符串背后所隐藏的用户信息，因此不用担心用户的密码凭证会因此泄露。\n\n##### 刷新令牌（refresh token）\n\n故事中小桂子最后之所以觉得委屈是因为意识到自己需要再重复走一次授权过程，这让小桂子觉得很麻烦，专业点说就是用户体验太差，解决之道就是引入刷新令牌。\n\n刷新令牌的作用在于更新访问令牌。访问令牌的生命周期一般较短，这样可以保证在发生访问令牌泄露时，不至于造成太坏的影响。然而，访问令牌有效期设置太短导致的副作用就是用户需要频繁授权，虽然可以通过一定的机制进行静默授权，但是频繁的调用授权接口之于授权服务器也是一种压力。此时可以在下发访问令牌的同时下发一个刷新令牌，刷新令牌的生命周期明显长于访问令牌，这样在访问令牌失效时，可以利用刷新令牌去授权服务器换取新的访问令牌，不过协议对于刷新令牌没有强制规定，是否需要该令牌客户端可以自行选择。\n\n##### 回调地址（redirect uri）\n\nOAuth 2.0 是一类基于回调的授权协议。以授权码模式为例，整个授权需要分为两步进行：第一步下发授权码；第二步根据授权码请求授权服务器下发访问令牌。OAuth 在第一步下发授权码时，是将授权码以参数的形式添加到回调地址后面，并以 302 跳转的形式进行下发，这样简化了客户端的操作，不需要再主动去触发一次请求，即可进入下一步流程。\n\n回调的设计存在一定的安全隐患，坏人可以利用该机制引导用户到一个恶意站点，继而对用户发起攻击。对于授权服务器而言也存在一定的危害，坏人可以利用该机制让授权服务器变成“肉鸡”，以授权服务器为代理请求目标地址，这样在消耗授权服务器资源的同时，也对目标地址服务器产生 DDOS 攻击。\n\n为了避免上述安全隐患，OAuth 协议强制要求客户端在注册时填写自己的回调地址，其目的是为了让回调请求能够到达客户端自己的服务器，从而可以走获取访问令牌的流程。客户端可以同时配置多个回调地址，并在请求授权时携带一个地址，服务器会验证客户端传递上来的回调地址是否与之前注册的回调地址相同，或者前者是后者集合的一个元素，只有在满足这一条件下才允许下发授权码，同时协议还要求两步请求客户端携带的回调地址必须一致，通过这些措施来保证回调过程能够正常到达客户端自己的服务器，并继续后面拿授权码换取访问令牌的过程。\n\n##### 权限范围（scope）\n\n访问令牌自带过期时间，可以在时间维度上对授权进行控制，而在权限维度层面，OAuth 引入了一个叫 scope 的概念。Scope 可以看做是一个对象，包含权限 ID、名称，以及描述信息等，比如“获取您的基本资料（头像、昵称）”。应用在接入 OAuth 服务时必须向服务提供方申请相应的 scope，并在请求授权时指明该参数，这些权限在用户确认授权时必须毫无保留的展示给用户，以让用户知道本次请求需要访问用户的哪些数据或服务。\n\n在之前的故事中凭证允许小桂子只能摘取 2 个西瓜和 3 斤荔枝，这里就对应两个 scope，这些信息是写入到凭证（访问令牌）中的，从而限制凭证的权限范围。\n\n#### 基本授权流程\n\nOAuth 2.0 协议定义了 4 种授权模式，其中最具代表性的是授权码模式，我们将在 3.1 节中详细介绍，这里先简单体会一下 OAuth 2.0 的授权流程，交互时序图如下：\n\n![image](/images/2017/oauth_basic_flow.png)\n\n假设整个流程开始之前，用户已经登录，那么整个授权流程如下：\n\n1. 客户端请求资源所有者（用户）授权，一般都是由授权服务器进行引导；\n2. 资源所有者实施授权（采用 4 种授权模式中的一种），客户端拿到用户的授权凭证；\n3. 客户端携带用户授权凭证请求授权服务器下发访问令牌；\n4. 授权服务器验证客户端出示的授权凭证，并下发访问令牌；\n5. 客户端携带访问令牌请求存储在资源服务器上的用户受保护资源；\n6. 资源服务器验证客户端出示的访问令牌，通过则响应客户端的请求。\n\n整个过程中，客户端都无法接触到用户的密码凭证信息，客户端通过访问令牌请求受保护资源，用户可以通过对授权操作的控制来间接控制客户端对于受保护资源的访问权限范围和周期。\n\n### 四种授权模式\n\nOAuth 2.0 相对于 1.0 版本在授权模式上做了更多的细化，已定义的授权模式分为四种：\n\n- 授权码模式（Authorization Code Grant）。\n- 隐式授权模式（Implicit Grant）。\n- 资源所有者密码凭证模式（Resource Owner Password Credentials Grant）。\n- 客户端凭证模式（Client Credentials Grant）。\n\n#### 授权码授权模式（Authorization Code Grant）\n\n授权码模式在整个授权流程上与 1.0 版本最为贴近，但是流程上还是要简化许多，也是 OAuth 2.0 中最标准、应用最为广泛的授权模式。这类授权模式非常适用于具备服务端的应用，当然现在大多数 APP 都有自己的服务端，所以授权码模式拥有最广泛的应用场景，下图为授权码各个角色之间的交互时序：\n\n![image](/images/2017/oauth-v2-authorization-code.png)\n\n整个授权流程说明如下（具体参数释义见下文）：\n\n1. 客户端携带 `client_id`, `scope`, `redirect_uri`, `state` 等信息请求授权服务器下发 `code`；\n2. 授权服务器验证客户端身份，通过则询问用户是否同意授权（此时会跳转到用户能够直观看到的授权页面，等待用户点击确认授权）；\n3. 假设用户同意授权，此时授权服务器会将 `code` 和 `state` 拼接在 `redirect_uri` 后面，并以 302 形式下发 `code`；\n4. 客户端携带 `code`, `redirect_uri`, 以及 `client_secret` 请求授权服务器下发 `access_token`；\n5. 授权服务器验证客户端身份，同时验证 `code`，以及 `redirect_uri` 是否与第一步相同，通过则下发 `access_token`，并选择性下发 `refresh_token`。\n\n##### 获取授权码\n\n授权码是授权流程的一个中间临时凭证，是对用户确认授权这一操作的一个短暂性表征，其生命周期一般较短，协议建议最大不要超过 10 分钟。在这一有效时间内，客户端可以通过授权码去授权服务器请求换取访问令牌，授权码应该采取防重放措施。\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nresponse_type | 必须 | 对于授权码模式来说 `response_type=code`。\nclient_id | 必须 | 客户端 ID，用于标识一个客户端，在注册应用时生成。\nredirect_uri | 可选 | 授权回调地址，具体参见 2.2.3 小节。\nscope | 可选 | 权限范围，用于对客户端的权限进行控制，如果客户端没有传递该参数，那么服务器则以该应用被许可的所有权限代替。\nstate | 推荐 | 用于维持请求和回调过程中的状态，防止 [CSRF攻击](https://zh.wikipedia.org/wiki/%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0)，服务器不对该参数做任何处理，如果客户端携带了该参数，则服务器在响应时原封不动的进行返回。\n\n__请求参数示例：__\n\n```http\nGET /authorize?response_type=code&client_id=s6BhdRkqt3&state=xyz&redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1\nHost: server.example.com\n```\n\n客户端携带上述参数请求授权服务器，授权服务器会验证客户端的身份以及相关参数，并在确认用户已登录的前提下弹出授权页询问用户是否同意授权，如果用户同意则会将 code 和 state 信息添加到回调地址后面，并以 302 的形式下发。\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\ncode | 必须 | 授权码，授权码代表用户确认授权的暂时性凭证，推荐最大生命周期不超过 10 分钟。\nstate | 可选 | 如果客户端传递了该参数，则必须原封不动返回。\n\n__成功响应示例：__\n\n```http\nHTTP/1.1 302 Found\nLocation: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA&state=xyz\n```\n\n如果请求参数错误，或者服务器端响应错误，那么需要将错误信息添加在回调地址后面，同样以 302 形式下发（回调地址错误，或客户端标识无效除外）。\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码。\nerror_description | 可选 | 具备可读性的错误描述信息。\nerror_uri | 可选 | 错误描述信息页面地址。\nstate | 可选 | 如果客户端传递了该参数，则必须原封不动返回。\n\n__错误响应示例：__\n\n```http\nHTTP/1.1 302 Found\nLocation: https://client.example.com/cb?error=access_denied&state=xyz\n```\n\n##### 下发访问令牌\n\n授权服务器的授权端点在以 302 形式下发 code 之后，用户代理（例如浏览器）将携带对应的 code 回调请求用户指定的 redirect_url，这个地址应该能够保证请求打到应用服务器的对应接口，该接口可以由此拿到 code，并附加相应参数请求授权服务器的令牌端点，授权端点验证 code 和相关参数，验证通过则下发 access_token。\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\ngrant_type | 必须 | 对于授权码模式 `grant_type=authorization_code`。\ncode | 必须 | 上一步骤获取的授权码。\nredirect_uri | 必须 | 授权回调地址，具体参见 2.2.3 小节，如果上一步有设置，则必须相同。\nclient_id | 必须 | 客户端 ID，用于标识一个客户端，在注册应用时生成。\n\n如果在注册应用时有下发客户端凭证信息（client_secret），那么客户端必须携带该参数以让授权服务器验证客户端的真实性。针对客户端凭证需要多说的一点就是不能将其存储或传递到客户端，客户端无法保证 client_secret 的安全，应该始终将其存储在应用的服务器端，当下发授权码回调请求到应用服务器时，在服务器端携带上 client_secret 继续请求下发令牌。\n\n__请求参数示例：__\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=authorization_code&code=SplxlOBeZQQYbYS6WxSbIA&redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb\n```\n\n授权服务器需要验证客户端的真实性，以及是否与之前请求授权码的客户端属同一个（请求授权时的信息可以记录在授权码中，或以授权码为 key 建立缓存），授权服务器还要保证授权码处于生命周期内，且只能被使用一次。验证通过之后，授权服务器生成 access_token，并选择性下发 refresh_token，OAuth 2.0 协议明确了 token 的下发策略，对于 token 的生成策略没有做太多说明，不过相关 RFC 补充文档为生成 token 提供了指导，目前主要的 token 有 BEARER、MAC 等类型。\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\naccess_token | 必须 | 访问令牌\ntoken_type | 必须 | 访问令牌类型，比如 BEARER、MAC 等。\nexpires_in | 推荐 | 访问令牌的生命周期，以秒为单位，表示令牌下发后多久时间过期，如果没有指定该项，则使用默认值。\nrefresh_token | 可选 | 刷新令牌，选择性下发，参见 2.2.2。\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明。\n\n最后访问令牌以 JSON 格式响应，并要求指定响应首部 `Cache-Control: no-store` 和 `Pragma: no-cache`。\n\n__成功响应示例：__\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n{\n    \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n    \"token_type\":\"example\",\n    \"expires_in\":3600,\n    \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n    \"example_parameter\":\"example_value\"\n}\n```\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码。\nerror_description | 可选 | 具备可读性的错误描述信息。\nerror_uri | 可选 | 错误描述信息页面地址。\n\n__错误响应示例：__\n\n```http\nHTTP/1.1 400 Bad Request\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"error\":\"invalid_request\"\n}\n```\n\n##### 一点小感悟\n\n授权码授权模式是 OAuth 2.0 协议已定义 4 种模式中最为严谨的模式，其余 3 中模式都是建立在一些特殊场景下，并对这些场景做了一些妥协和优化。授权码授权流程分为两步走，将用户授权与下发访问令牌分开，这给授权带来了更多的灵活性。正常授权过程中必须经过用户登录这一步骤，在用户已登录的前提下，可以直接询问用户是否同意授权，但是在一些场景下，比如内部走 SSO（单点登录）的应用集成了基于 OAuth 授权的第三方应用，此时在 OAuth 授权登录第三方应用时，用户体验较好的流程是不需要用户再次输入用户名和密码的，这就需要将外围 APP 的登录态传递给嵌套的应用，但是这样是存在安全问题的，用户的登录态必须把握在走 SSO 登录流程的应用手上，这样的场景下授权码授权模式的两步走流程就可以满足在不交出用户登录态的情况下，无需再次登录即可授权。\n\n内部应用可以拿着第三方应用的 client_id 等信息代替第三方应用去请求获取 code，因为自己持有用户的登录态，所以过程中无需用户再次输入用户名和密码，拿到 code 之后将其交给第三方应用。第三方应用利用 code 和自己的 client_secret 信息去请求授权服务器下发 token，整个流程内部应用不需要交出自己持有的用户登录态，第三方应用也无需交出自己的 client_secret 信息，最终却能够实现在保护用户密码凭证的前提下无需再次登录即可完成整个授权流程。\n\n#### 隐式授权模式（Implicit Grant）\n\n对于一些纯客户端应用，往往无法妥善的保管其客户端凭证，同时因为没有服务器端，所以无法向授权服务器传递凭证信息，并且纯客户端应用在请求交互上要弱于有服务器的应用，这时候减少交互可以让应用的稳定性和用户体验更好，隐式授权模式是对这一应用场景的优化。\n\n隐式授权模式在安全性上要弱于授权码模式，因为无法对当前客户端的真实性进行验证，同时对于下发的 access_token 存在被同设备上其它应用窃取的风险，为了降低这类风险，隐式授权模式强制要求不能下发 refresh_token，这一强制要求的另外一个考量是因为 refresh_token 的生命周期较长，而客户端无法安全的对其进行存储和保护。下图为授权码各个角色之间的交互时序：\n\n![image](/images/2017/oauth-v2-implicit-grant.png)\n\n整个授权流程说明如下：\n\n1. 客户端携带 `client_id`, `scope`, `redirect_uri`, `state` 等信息请求授权服务器下发 `access_token`；\n2. 授权服务器验证客户端身份，通过则询问用户是否同意授权（此时会跳转到用户能够直观看到的授权页面，等待用户点击确认授权）；\n3. 假设用户同意授权，此时授权服务器会将 `access_token` 和 `state` 等信息以 URI Fragment 形式拼接在 `redirect_uri` 后面，并以 302 形式下发；\n4. 客户端利用脚本解析获取 `access_token`。\n\n##### 请求获取访问令牌\n\n不同于授权码模式的分两步走，隐式授权码模式一步即可拿到访问令牌。\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nresponse_type | 必须 | 对于授权码模式 `response_type=token`。\nclient_id | 必须 | 客户端 ID，用于标识一个客户端，在注册应用时生成。\nredirect_uri | 可选 | 授权回调地址，具体参见 2.2.3 小节。\nscope | 可选 | 权限范围，用于对客户端的权限进行控制，如果客户端没有传递该参数，那么服务器则以该应用被许可的所有权限代替。\nstate | 推荐 | 用于维持请求和回调过程中的状态，防止 [CSRF攻击](https://zh.wikipedia.org/wiki/%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0)，服务器不对该参数做任何处理，如果客户端携带了该参数，则服务器在响应时原封不动的返回。\n\n__请求参数示例：__\n\n```http\nGET /authorize?response_type=token&client_id=s6BhdRkqt3&state=xyz&redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1\nHost: server.example.com\n```\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\naccess_token | 必须 | 访问令牌。\ntoken_type | 必须 | 访问令牌类型，比如 BEARER，MAC 等。\nexpires_in | 推荐 | 访问令牌的生命周期，以秒为单位，表示令牌下发后多久时间过期，如果没有指定该项，则使用默认值。\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明。\nstate | 可选 | 如果客户端传递了该参数，则必须原封不动返回。\n\n隐式授权模式不下发刷新令牌，访问令牌以 URI Fragment 的形式拼接在授权回调地址后面以 302 形式下发，并要求指定响应首部 `Cache-Control: no-store` 和 `Pragma: no-cache`。\n\n__成功响应示例：__\n\n```http\nHTTP/1.1 302 Found\nLocation: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA&state=xyz&token_type=example&expires_in=3600\n```\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码。\nerror_description | 可选 | 具备可读性的错误描述信息。\nerror_uri | 可选 | 错误描述信息页面地址。\nstate | 可选 | 如果客户端传递了该参数，则必须原封不动返回。\n\n授权服务器将上述元素以 URI Fragment 形式拼接在授权回调地址后面以 302 形式下发（redirect_uri 或 client_id 错误除外）。\n\n__错误响应参数示例：__\n\n```http\nHTTP/1.1 302 Found\nLocation: https://client.example.com/cb#error=access_denied&state=xyz\n```\n\n#### 资源所有者密码凭证授权模式（Resource Owner Password Credentials Grant）\n\n资源所有者密码凭证授权模式建立在资源所有者充分信任客户端的前提下，因为该模式客户端可以拿到用户的登录凭证，从而在用户无感知的情况下完成整个授权流程，毕竟都有用户的登录凭证了，再弹窗让用户确认授权也是多此一举。\n\n这里可能有一个比较疑惑的地方是，既然都已经拿到了用户的登录凭证了，为什么还需要绕一大圈子走 OAuth 授权，拿到访问令牌后再去请求用户的受保护资源呢？以我的个人经验来说，客户端在拿到用户的登录凭证之后确实可以直接请求用户的资源，但是服务端一般不认，因为服务端采用 OAuth 协议进行鉴权。\n\n举个例子，比如有一个 API 是获取某个用户的通讯录，这是用户十分敏感的数据，且一般只能授予内部应用，如果是在服务级别进行控制，那么只要拿到接口访问权限，该应用可以请求获取任何一个用户的通讯录数据，这是一件十分危险的事情。如果基于 OAuth 做鉴权，那么就可以将粒度控制在用户级别。前面讲的两种授权方式在这种场景下都有一个共同的缺点，需要弹出授权页让用户确认授权，要知道这样的场景往往是发生在内部应用中，内部应用是可以持有用户登录态的，这里的确认授权对于一个用户体验好的 APP 来说应该发生在用户登录时，通过用户协议等方式直接告诉用户，从而让用户在一次登录过程中可以让应用拿到用户的登录态和访问令牌。\n\n资源所有者密码凭证授权模式的交互时序如下：\n\n![image](/images/2017/oauth-v2-resource-owner-password-credentials.png)\n\n整个授权流程说明如下：\n\n1. 用于授予客户端登录凭证（比如用户名和密码信息，亦或是 token）；\n2. 客户端携带用户的登录凭证和 `scope` 等信息请求授权服务器下发 `access_token`；\n3. 授权服务器验证用户的登录凭证和客户端信息的真实性，通过则下发 `access_token`，并选择性下发 `refresh_token`。\n\n##### 用户授予登录凭证\n\n用于登录凭证如何传递给客户端这一块协议未做说明，实际中该类授权一般用于内部应用，这类应用的特点就是为用户提供登录功能，当用户登录之后，这类应用也就持有了用户的登录态，可以是用户登录的 session 标识，也可以是走 SSO 下发的 token 信息。\n\n##### 请求获取访问令牌\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\ngrant_type | 必须 | 对于本模式 `grant_type=password`。\nusername | 必须 | 用户名。\npassword | 必须 | 用户密码。\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明。\n\n如果在注册应用时有下发客户端凭证信息（client_secret），那么客户端必须携带该参数以让授权服务器验证客户端的真实性。\n\n__请求参数示例：__\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=password&username=johndoe&password=A3ddj3w\n```\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\naccess_token | 必须 | 访问令牌。\ntoken_type | 必须 | 访问令牌类型，比如 BEARER、MAC 等。\nexpires_in | 推荐 | 访问令牌的生命周期，以秒为单位，表示令牌下发后多久时间过期，如果没有指定该项，则使用默认值。\nrefresh_token | 可选 | 刷新令牌，选择性下发，参见 2.2.2。\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明。\n\n最后访问令牌以 JSON 格式响应，并要求指定响应首部 `Cache-Control: no-store` 和 `Pragma: no-cache`。\n\n__成功响应参数示例：__\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n    \"token_type\":\"example\",\n    \"expires_in\":3600,\n    \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n    \"example_parameter\":\"example_value\"\n}\n```\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码。\nerror_description | 可选 | 具备可读性的错误描述信息。\nerror_uri | 可选 | 错误描述信息页面地址。\n\n__错误响应示例：__\n\n```http\nHTTP/1.1 400 Bad Request\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"error\":\"invalid_request\"\n}\n```\n\n#### 客户端凭证授权模式（Client Credentials Grant）\n\n客户端凭证授权模式基于客户端持有的证书去请求用户的受保护资源，如果把这里的受保护资源定义得更加宽泛一点，比如说是对一个内网接口权限的调用，那么这类授权方式可以被改造为内网权限验证服务。客户端凭证授权模式的交互时序如下：\n\n![image](/images/2017/oauth-v2-client-credentials.png)\n\n整个授权流程说明如下：\n\n1. 客户端携带客户端凭证和 `scope` 等信息请求授权服务器下发 `access_token`；\n2. 授权服务器验证客户端真实性，通过则下发 `access_token`。\n\n##### 请求获取访问令牌：\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\ngrant_type | 必须 | 对于本模式 `grant_type=client_credentials`。\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明。\n\n__请求参数示例：__\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=client_credentials\n```\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\naccess_token | 必须 | 访问令牌。\ntoken_type | 必须 | 访问令牌类型，比如 BEARER、MAC 等。\nexpires_in | 推荐 | 访问令牌的生命周期，以秒为单位，表示令牌下发后多久时间过期，如果没有指定该项，则使用默认值。\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明。\n\n最后访问令牌以 JSON 格式响应，并要求指定响应首部 `Cache-Control: no-store` 和 `Pragma: no-cache`。\n\n__成功响应参数示例：__\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n    \"token_type\":\"example\",\n    \"expires_in\":3600,\n    \"example_parameter\":\"example_value\"\n}\n```\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码。\nerror_description | 可选 | 具备可读性的错误描述信息。\nerror_uri | 可选 | 错误描述信息页面地址。\n\n__错误响应示例：__\n\n```http\nHTTP/1.1 400 Bad Request\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"error\":\"invalid_request\"\n}\n```\n\n### 总结\n\n本文介绍了 OAuth 2.0 授权协议的理论知识，OAuth 2.0 被广泛应用于第三方授权登录，很多其它的协议都可以基于该协议进行改造，比如前面提到的 SSO，作为开发人员，还是建议对该协议或多或少有些了解。如果要自己实现一个授权和鉴权服务，该协议为我们绘制指明了思路，但是还有很多细节实现需要我们再去查阅各种资料和实践。\n\n关于 token 的生成最后再补充一点，OAuth 2.0 协议只是一笔带过的说它是一个字符串，用于表示特定的权限、生命周期等，却没有明确阐述 token 的生成策略，以及如何去验证一个 token。协议不去详细阐述，个人觉得是因为这一块是与具体业务绑定的，无法完全做到抽象，并且在这一块去做详细的规定，意义也不大。\n\nToken 本质上就是对用户授权这一操作在时间和权限范围两个维度上的一个表征，协议可以对 token 的传递和基本验证做相应规定，但是具体的一个 token 包含哪些元素，采用什么样的生成算法还是需要由自己去把握。一些文档，比如参考文献 3 和 4 都为 token 的生成进行了扩展说明，鉴于篇幅，不再展开。\n\n### 参考\n\n1. [RFC5849 - The OAuth 1.0 Protocol](https://tools.ietf.org/html/rfc5849)\n2. [RFC6749 - The OAuth 2.0 Authorization Framework](https://tools.ietf.org/html/rfc6749)\n3. [RFC6750 - The OAuth 2.0 Authorization Framework: Bearer Token Usage](https://tools.ietf.org/html/rfc6750)\n4. [HTTP Authentication: MAC Authentication (draft-hammer-oauth-v2-mac-token-02)](https://tools.ietf.org/html/draft-hammer-oauth-v2-mac-token-02)\n","tags":["OAuth"],"categories":["protocol"]},{"title":"Dubbo 之于 SPI 扩展机制的实现分析","url":"/2017/12/17/rpc/dubbo-spi/","content":"\n[SPI (Service Provider Interfaces)](https://docs.oracle.com/javase/tutorial/sound/SPI-intro.html) 是 JDK 1.5 引入的一种服务扩展内置机制。在面向接口编程的范畴下，SPI 能够基于配置的方式声明应用的具体扩展接口实现。之前在写接口限流器时曾遇到过这样一个场景，针对服务端的限流策略一般需要从多个维度进行控制，比如具体接口、IP、用户、设备，以及调用方等等，假设限流器接口 `org.zhenchao.spi.ApiRateLimiter` 定义为：\n\n```java\npublic interface RateLimiter {\n    boolean reject();\n}\n```\n\n<!-- more -->\n\n针对该接口在各个维度的实现类定义如下：\n\n```text\norg.zhenchao.spi.RateLimiter\n+- org.zhenchao.spi.ApiRateLimiter # 接口维度\n+- org.zhenchao.spi.IpRateLimiter # IP 维度\n+- org.zhenchao.spi.UserRateLimiter # 用户维度\n+- org.zhenchao.spi.DeviceRateLimiter # 设备维度\n+- org.zhenchao.spi.ClientRateLimiter # 调用方维度\n```\n\n现在的问题是，不同业务所需要的限流维度可能不同，一些业务甚至还需要扩展实现属于自身特有维度的限流策略，如何能够对限流策略进行组合、定制，并站在更高的层次上对这些限流策略进行统一调度？这个时候正是 SPI 机制发挥其作用的时候。\n\nSPI 扩展机制虽然早已存在，但是你可能对其并不熟悉，因为其应用场景更多的是用来编写框架、插件，以及基础组件等，比如 commons-logging、JDBC 中都有 SPI 的身影，但是了解这一机制有时候能够让你在 coding 时多一种思路，从而写出更加优雅的代码。\n\n曾经在阅读一个遗留项目源码时，之前的开发者曾将一个接口部分实现类的 simple name 写在配置文件中，并在程序中读取该配置，循环以包名前缀拼接相应实现类 simple name 的方式得到类的限定名，然后反射创建类对象进行调用，这样的实现除了不够优雅，也阉割了程序的可扩展性，是一种程序设计的坏味道。\n\nSPI 扩展机制除了 JDK 内置的实现外，[Dubbo](https://dubbo.apache.org) RPC 框架也提供了相应的实现版本，并在功能上进行了增强，接下来将分别介绍 JDK SPI 和 Dubbo  SPI 的使用方式，并对 Dubbo 之于 SPI 扩展机制的实现内幕进行分析。\n\n### JDK SPI\n\n继续前面给出的例子，如果我们的业务只希望从接口、IP，以及用户 3 个维度实施限流，基于 JDK 内置的 SPI 该如何实现呢？我们首先需要在 `/META-INF/services` 目录下面新建一个与接口同名的名为 `org.zhenchao.spi.RateLimiter` 的文件，内容为：\n\n```text\norg.zhenchao.spi.ApiRateLimiter\norg.zhenchao.spi.IpRateLimiter\norg.zhenchao.spi.UserRateLimiter\n```\n\n然后基于 `java.util.ServiceLoader` 加载 SPI 扩展实现类，具体如下：\n\n```java\nServiceLoader<RateLimiter> rateLimiters = ServiceLoader.load(RateLimiter.class);\nfor (final RateLimiter limiter : rateLimiters) {\n    limiter.reject();\n}\n```\n\n到此，我们就完成了基于 JDK SPI 实现对限流策略的定制化。我们可以在 SPI 配置文件中定义任意维度限流策略的组合，如果已有的策略实现无法满足业务需求，我们也可以实现 RateLimiter 接口定义自己的限流策略，只需要将新增实现类限定名配置到 `META-INF/services/org.zhenchao.spi.RateLimiter` 中即可。\n\n### Dubbo SPI\n\nDubbo RPC 框架在设计和实现上采用“微内核 + 插件”的方式，具备良好的定制性和可扩展性，整体架构非常简单、精美，即使你工作中不使用它，也建议你阅读一下其源码以学习其中的设计思想。Dubbo 的可扩展性基于 SPI 扩展机制实现，不过它并没有采用 JDK 内置的 SPI，而是自己另起炉灶实现了一套，之所以这样“重复造轮子”，官方给出的理由如下：\n\n1. JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。\n2. 如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK 标准的 ScriptEngine，通过 `ScriptEngine#getName` 获取脚本类型的名称，但如果 RubyScriptEngine 因为所依赖的 `jruby.jar` 不存在，导致 RubyScriptEngine 类加载失败，这个失败原因被吃掉了，和 ruby 对应不起来，当用户执行 ruby 脚本时，会报不支持 ruby，而不是真正失败的原因。\n3. 增加了对扩展点 IoC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。\n\n下面继续就前面的例子给出基于 Dubbo SPI 的实现，和 JDK SPI 类似，我们首先需要在 `/META-INF/dubbo` 目录（Dubbo SPI 也兼容 `/META-INF/services` 目录）下新建一个与接口同名的名为 `org.zhenchao.spi.RateLimiter` 的配置文件，内容为：\n\n```properties\napi=org.zhenchao.spi.ApiRateLimiter\nip=org.zhenchao.spi.IpRateLimiter\nuser=org.zhenchao.spi.UserRateLimiter\n```\n\n不同于 JDK SPI，Dubbo 要求被扩展的接口必须采用注解 `@SPI` 进行修饰，所以 RateLimiter 接口需要更改为：\n\n```java\n@SPI\npublic interface RateLimiter {\n    boolean reject();\n}\n```\n\n然后基于 `com.alibaba.dubbo.common.extension.ExtensionLoader` 类进行调度（如下），ExtensionLoader 是整个 Dubbo SPI 最核心的实现，稍后会对其实现进行详细分析：\n\n```java\nExtensionLoader<RateLimiter> extensionLoader = ExtensionLoader.getExtensionLoader(RateLimiter.class);\nfor (final String name : extensionLoader.getSupportedExtensions()) {\n    RateLimiter limiter = extensionLoader.getExtension(name);\n    limiter.reject();\n}\n```\n\n上面的例子仅仅演示了 Dubbo SPI 的基本使用，基本看不出和 JDK SPI 的区别，实际上从例子中我们还是可以初步看出 Dubbo SPI 是按需加载的。Dubbo SPI 基于我们指定的扩展名称加载相应的扩展实现，而 JDK SPI 则是一股脑全部给加载了，这也就是前面列举 Dubbo 为什么 “重复造轮子” 的 __第 1 个原因__ 。相对于 JDK SPI 来说，Dubbo SPI 还是多做了一些，接下来我们继续从源码层面对整个 SPI 扩展机制的设计和实现进行分析。\n\nDubbo 整个 SPI 的实现位于 `com.alibaba.dubbo.common.extension` 包下面，代码总量也就 1000 行左右，可谓是短小而精悍，extension 包中的类组织结构如下：\n\n```text\nextension\n+- factory\n|-- com.alibaba.dubbo.common.extension.factory.AdaptiveExtensionFactory\n|-- com.alibaba.dubbo.common.extension.factory.SpiExtensionFactory\n+- support\n|-- com.alibaba.dubbo.common.extension.support.ActivateComparator\n+- com.alibaba.dubbo.common.extension.Activate\n+- com.alibaba.dubbo.common.extension.Adaptive\n+- com.alibaba.dubbo.common.extension.ExtensionFactory\n+- com.alibaba.dubbo.common.extension.ExtensionLoader\n+- com.alibaba.dubbo.common.extension.SPI\n```\n\n上面的例子中我们已经接触到了 `@SPI` 注解和 ExtensionLoader 类，这也是 Dubbo SPI 最核心的两个实现，接下去的分析过程将从这两个类展开。SPI 扩展机制虽然听起来高大上并且好用，但是说得简单点也就是 __基于配置指定扩展接口的具体一个或多个实现，解析并反射实例化扩展实现类的过程__ ，所以不管实现上怎么添油加醋，也都是围绕着这么一个基本的运行机制展开。\n\n下面首先来看一下注解 `@SPI` 的定义，Dubbo 通过该注解标识接口是一个扩展接口，接口的实现类能够被 Dubbo SPI 托管，`@SPI` 的定义比较简单：\n\n```java\n@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target({ElementType.TYPE})\npublic @interface SPI {\n    /**\n     * 缺省扩展点名。\n     */\n    String value() default \"\";\n}\n```\n\n该注解仅声明了一个属性，用于指定默认扩展名，Dubbo SPI 的配置一般采用 `key=value` 的形式，我们可以在注解接口时指定默认实现类的扩展名称。\n\n接下来分析 ExtensionLoader 实现，前面已经提及过这是 Dubbo SPI 最核心的一个实现类，回忆一下前面的例子对于扩展类的调度实际上也就分为 2 步，第 1 步拿到\nRateLimiter 对应的 ExtensionLoader 对象，第 2 步调用该对象的 getExtension 方法基于扩展名称获取扩展实现类对象：\n\n```text\n1. ExtensionLoader<RateLimiter> extensionLoader = ExtensionLoader.getExtensionLoader(RateLimiter.class);\n2. RateLimiter limiter = extensionLoader.getExtension(name);\n```\n\n针对每一个 SPI 扩展类型，Dubbo 都会为其绑定一个 ExtensionLoader 对象，上面第 1 步调用 `getExtensionLoader(Class<T> type)` 方法就是在获取扩展类型对应的 ExtensionLoader，该方法的实现如下：\n\n```java\npublic static <T> ExtensionLoader<T> getExtensionLoader(Class<T> type) {\n    if (type == null) {\n        throw new IllegalArgumentException(\"Extension type == null\");\n    }\n    // 必须是接口类型\n    if (!type.isInterface()) {\n        throw new IllegalArgumentException(\"Extension type(\" + type + \") is not interface!\");\n    }\n    // 必须被 @SPI 注解\n    if (!withExtensionAnnotation(type)) {\n        throw new IllegalArgumentException(\n                \"Extension type(\" + type + \") is not extension, because WITHOUT @\" + SPI.class.getSimpleName() + \" Annotation!\");\n    }\n\n    // 先尝试从本地缓存中获取\n    ExtensionLoader<T> loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);\n    if (loader == null) {\n        // 本地缓存不命中则创建\n        EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader<T>(type));\n        loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);\n    }\n    return loader;\n}\n```\n\n该方法会限制入参必须是被 `@SPI` 注解的接口类型，这也是 Dubbo 对于扩展类型仅有的约束，在这方面 JDK SPI 则没有相应的限制，扩展类型既可以是类也可以是接口，并且不需要额外注解，不过既然是面向接口编程，所以扩展类型还是推荐设计成接口类型。对于满足约束条件的入参，方法接下去会先尝试从缓存中获取绑定的 ExtensionLoader 实例，这里采用一个线程安全的 ConcurrentHashMap 缓存扩展类型及其绑定的 ExtensionLoader，该属性定义如下：\n\n```java\n/** 缓存扩展类型及其绑定的 ExtensionLoader 对象（每一个扩展类型都拥有属于自己的 ExtensionLoader） */\nprivate static final ConcurrentMap<Class<?>, ExtensionLoader<?>> EXTENSION_LOADERS = new ConcurrentHashMap<Class<?>, ExtensionLoader<?>>();\n```\n\n对于第一次调用该方法的扩展类型会创建一个新的 ExtensionLoader 对象，并记录到 EXTENSION_LOADERS 中。接下来就可以调用 ExtensionLoader 对象的 `getExtension(String name)` 方法获取指定的扩展类型实现类实例：\n\n```java\npublic T getExtension(String name) {\n    if (name == null || name.length() == 0) {\n        throw new IllegalArgumentException(\"Extension name == null\");\n    }\n    if (\"true\".equals(name)) {\n        // 获取默认的实现类\n        return this.getDefaultExtension();\n    }\n\n    // 获取指定名称的扩展类型实例\n    Holder<Object> holder = cachedInstances.get(name); // 先尝试从缓存中获取\n    if (holder == null) {\n        cachedInstances.putIfAbsent(name, new Holder<Object>());\n        holder = cachedInstances.get(name);\n    }\n    Object instance = holder.get();\n    if (instance == null) {\n        synchronized (holder) {\n            instance = holder.get();\n            if (instance == null) {\n                // 创建扩展类型实现\n                instance = this.createExtension(name);\n                holder.set(instance);\n            }\n        }\n    }\n    return (T) instance;\n}\n```\n\n该方法的执行流程可以概括如下 3 步：\n\n1. 如果 `name=true` 则获取注解默认指定的扩展类型实例；\n2. 尝试从缓存中获取之前创建的扩展类型实例；\n3. 如果缓存不命中则说明是第一次获取指定扩展类型，执行创建对应的实例。\n\n依据前面对 `@SPI` 注解实现的介绍，我们知道该注解持有一个 String 类型的属性，允许我们指定当前扩展类型的默认扩展名称，在本方法中如果入参 `name=true` 则 Dubbo 会认为我们希望获取默认的扩展类型实现，接下来会转而走 `getDefaultExtension()` 逻辑，默认扩展名称的获取我们会在稍后的解析过程中提及到，方法 `getDefaultExtension()` 本质上也是调用了 `getExtension(String name)` 方法，所以这里不展开说明。对于其他有效入参来说，方法会首先尝试获取缓存的实例，这些实例记录在 cachedInstances 属性中，这也是一个线程安全的 ConcurrentHashMap 类型：\n\n```java\n/** 记录扩展名称与对应持有扩展类型实例的 {@link Holder} 对象 */\nprivate final ConcurrentMap<String, Holder<Object>> cachedInstances = new ConcurrentHashMap<String, Holder<Object>>();\n```\n\n对于缓存不命中的的扩展名称，接下来会调用 `createExtension(String name)` 方法创建扩展类型实例，该方法所做的工作可以概括为：\n\n1. 基于扩展名称获取对应的扩展实现类 Class 对象；\n2. 如果之前没有访问过该 Class 则会基于反射创建相应的实例，并缓存；\n3. 遍历实例所有的方法，反射调用参数类型为扩展类型的 setter，注入相应的扩展实例属性；\n4. 应用包装类对实例逐层包装。\n\n上述过程中 3 和 4 是 Dubbo SPI 相对于 JDK SPI 进行的增强，在一些较复杂场景下实为一种有用的设计。方法 `createExtension(String name)` 的具体实现如下：\n\n```java\nprivate T createExtension(String name) {\n    // 获取扩展名称对应的实现类 Class 对象\n    Class<?> clazz = this.getExtensionClasses().get(name);\n    if (clazz == null) {\n        throw this.findException(name);\n    }\n    try {\n        // 尝试从缓存中获取对应的实例\n        T instance = (T) EXTENSION_INSTANCES.get(clazz);\n        if (instance == null) {\n            // 反射实例化\n            EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance());\n            instance = (T) EXTENSION_INSTANCES.get(clazz);\n        }\n        // 执行 setter 注入\n        this.injectExtension(instance);\n        Set<Class<?>> wrapperClasses = cachedWrapperClasses;\n        if (wrapperClasses != null && wrapperClasses.size() > 0) {\n            for (Class<?> wrapperClass : wrapperClasses) {\n                // 采用包装类逐层包装\n                instance = this.injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance));\n            }\n        }\n        return instance;\n    } catch (Throwable t) {\n        throw new IllegalStateException(\n                \"Extension instance(name: \" + name + \", class: \" + type + \")  could not be instantiated: \" + t.getMessage(), t);\n    }\n}\n```\n\n在获取扩展名称对应的实现类 Class 对象之前，先是调用了 `getExtensionClasses()` 方法，实际上 ExtensionLoader 在多个方法中都有调用该方法，主要是因为通过该方法能够获取到当前 ExtensionLoader 对象所关联的扩展类型对应配置的所有扩展实现类 Class 对象，并在首次访问时触发 SPI 配置的加载过程。该方法的实现如下：\n\n```java\nprivate Map<String, Class<?>> getExtensionClasses() {\n    Map<String, Class<?>> classes = cachedClasses.get();\n    if (classes == null) {\n        synchronized (cachedClasses) {\n            classes = cachedClasses.get();\n            if (classes == null) {\n                // 加载当前类型的 SPI 配置\n                classes = this.loadExtensionClasses();\n                cachedClasses.set(classes);\n            }\n        }\n    }\n    return classes;\n}\n```\n\n方法利用 cachedClasses 缓存扩展类对应的 SPI 配置，cachedClasses 是一个 Holder 类型的属性，持有 Map 类型的数据，其中 key 为扩展名称，value 为对应的扩展实现类 Class 对象，属性定义如下：\n\n```java\n/** 记录正向映射关系 */\nprivate final Holder<Map<String, Class<?>>> cachedClasses = new Holder<Map<String, Class<?>>>();\n```\n\n对于首次调用而言会触发调用 `loadExtensionClasses()` 方法，该方法的主要作用就是从 `META-INF/dubbo/internal/`、`META-INF/dubbo/`，以及 `META-INF/services/` 目录下检索 SPI 配置，并执行加载和解析过程：\n\n```java\nprivate Map<String, Class<?>> loadExtensionClasses() {\n    final SPI defaultAnnotation = type.getAnnotation(SPI.class);\n    if (defaultAnnotation != null) {\n        String value = defaultAnnotation.value();\n        // 指定默认的扩展名称\n        if ((value = value.trim()).length() > 0) {\n            String[] names = NAME_SEPARATOR.split(value);\n            if (names.length > 1) {\n                // 只能指定一个默认扩展名称\n                throw new IllegalStateException(\n                        \"more than 1 default extension name on extension \" + type.getName() + \": \" + Arrays.toString(names));\n            }\n            if (names.length == 1) {\n                cachedDefaultName = names[0];\n            }\n        }\n    }\n\n    Map<String, Class<?>> extensionClasses = new HashMap<String, Class<?>>();\n    // META-INF/dubbo/internal/\n    this.loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY);\n    // META-INF/dubbo/\n    this.loadFile(extensionClasses, DUBBO_DIRECTORY);\n    // META-INF/services/\n    this.loadFile(extensionClasses, SERVICES_DIRECTORY);\n    return extensionClasses;\n}\n```\n\n方法首先会解析 `@SPI` 注解中配置的默认扩展名称，并记录到属性 cachedDefaultName 中，Dubbo 要求只能指定一个默认的扩展名称。然后会调用 `loadFile(Map<String, Class<?>> extensionClasses, String dir)` 方法从之前所列举的各个目录中检索、加载，以及解析 SPI 配置，最终以扩展名称为 key，对应配置的扩展实现类 Class 对象为 value 记录到 Map 集合中，整个过程这里不展开说明，比较简单。\n\n下面继续来看一下 `injectExtension(T instance)` 方法，前面曾提到过借助该方法，Dubbo SPI 能够调用参数类型同样为扩展类型的 setter 方法注入相应的扩展实现类对象到当前实例中，这是 JDK SPI 所不具备的。该方法的实现如下：\n\n```java\nprivate T injectExtension(T instance) {\n    try {\n        if (objectFactory != null) {\n            for (Method method : instance.getClass().getMethods()) {\n                // 仅处理 setter\n                if (method.getName().startsWith(\"set\")\n                        && method.getParameterTypes().length == 1\n                        && Modifier.isPublic(method.getModifiers())) {\n                    // 获取属性类型\n                    Class<?> pt = method.getParameterTypes()[0];\n                    try {\n                        // 获取属性名称\n                        String property = method.getName().length() > 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : \"\";\n                        Object object = objectFactory.getExtension(pt, property);\n                        if (object != null) {\n                            // 反射调用\n                            method.invoke(instance, object);\n                        }\n                    } catch (Exception e) {\n                        logger.error(\"fail to inject via method \" + method.getName() + \" of interface \" + type.getName() + \": \" + e.getMessage(), e);\n                    }\n                }\n            }\n        }\n    } catch (Exception e) {\n        logger.error(e.getMessage(), e);\n    }\n    return instance;\n}\n```\n\n方法一开始就判断属性 objectFactory 是否为 null，该属性在 ExtensionLoader 的构造函数中被创建（如下），然后方法会依据 java bean 定义规范筛选出 setter 方法，并以此得到 setter 方法的参数类型及其对应的属性名称，然后基于 `ExtensionFactory#getExtension` 方法获取相应的 SPI 扩展实现类实例注入到当前实例中。\n\n```java\nprivate ExtensionLoader(Class<?> type) {\n    this.type = type;\n    this.objectFactory = (type == ExtensionFactory.class ? null :\n            ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());\n}\n```\n\n对于除 ExtensionFactory 以外的其他扩展类型来说，这里本质上返回的是 AdaptiveExtensionFactory 类型，Dubbo 默认对于 ExtensionFactory 的扩展配置如下：\n\n```properties\nadaptive=com.alibaba.dubbo.common.extension.factory.AdaptiveExtensionFactory\nspi=com.alibaba.dubbo.common.extension.factory.SpiExtensionFactory\n```\n\n由于 AdaptiveExtensionFactory 采用注解 `@Adaptive` 修饰，所以在加载扩展配置时会将其 Class 对象记录到类属性 cachedAdaptiveClass 中，这是一个适配器类，其中持有了配置的 ExtensionFactory 扩展实现类实例，当我们调用 `AdaptiveExtensionFactory#getExtension` 方法获取指定扩展类型实例时，实际上是在遍历应用其持有的 ExtensionFactory 实例。\n\n扩展点自适应实际上也是 Dubbo SPI 增强的特性之一（“重复造轮子” 中列举的 __第 3 个原因__ ），这一机制依赖于 `@Adaptive` 注解，上面对于该注解的应用是修饰在类型上，实际上该注解更多的应用场合在于修饰方法。前面我们曾介绍过 Dubbo SPI 在构造扩展类型实例时，针对实例的参数类型同样为扩展类型的 setter 会执行依赖注入，这个时候注入的并不是一个具体的扩展类型，而是一个扩展类型的适配器类实例。例如在对扩展类型 A 实例执行 setter 注入 B 扩展类型时，此时注入的实际上是 B 类型的适配器类型实例（由程序自动生成），而不是具体的 B 类型实现类实例，因为对于一个扩展类型来说我们并不知道当前依赖的具体类型是谁，需要依据 URL 中的入参待到运行时才能决定。\n\n这里以前面的 IpRateLimiter 举例说明，假设 IpRateLimiter 需要依赖于一个 IP 解析器 IpResolver，这是一个接口，围绕该接口有两个具体实现类：LocalIpResolver 和 RemoteIpResolver，接口的定义如下：\n\n```java\n@SPI(\"local\")\npublic interface IpResolver {\n    @Adaptive(\"resolver\")\n    String resolve(URL url);\n}\n```\n\n依赖于 IpResolver 的 IpRateLimiter 定义如下：\n\n```java\npublic class IpRateLimiter implements RateLimiter {\n\n    private IpResolver ipResolver;\n\n    @Override\n    public boolean reject() {\n        ipResolver.resolve(url);\n        return false;\n    }\n\n    public IpRateLimiter setIpResolver(IpResolver ipResolver) {\n        this.ipResolver = ipResolver;\n        return this;\n    }\n}\n```\n\nDubbo SPI 在构造 IpRateLimiter 实例时检测到它有一个参数类型为 SPI 扩展类型的 setter（即 setIpResolver），这个时候就会构造 IpResolver 的适配器类型实例进行注入，相应的适配器实现由程序按照规则自动生成。待到实际执行 `IpResolver#resolve` 方法时，会从入参 URL 中查询 key 为 `resolver` 的参数值，以此决定具体注入的扩展类型实例。\n\n这一自适应机制简单的说就是在依赖注入时先用一个适配器类实例占坑，待到运行时再动态代理到具体的实现类去执行相应的操作。这是一个比较常用且优雅的设计，记得之前在设计动态 IoC 时就采用了类似的实现机制，针对一个 service 类存在多个实现，具体使用哪个实现类需要等到运行时才能依据入参决定，但是 Spring IoC 又是在容器启动时完成 singleton 类型的注入，如果不希望把 Spring IoC 退化成一个大工厂使用，就可以在依赖注入时先注入一个适配器类实例，并在运行时由该实例动态代理具体的 service 实现类。\n\n关于上述扩展点自适应机制，下面一起来看一下相应的源码实现，这里将焦点聚焦到 `ExtensionLoader#getAdaptiveExtension` 方法，ExtensionLoader 利用属性 cachedAdaptiveInstance 记录当前扩展类型对应的适配器类实例，所以该方法的逻辑就是先尝试从 cachedAdaptiveInstance 中获取，如果不存在则会调用 `ExtensionLoader#createAdaptiveExtension` 方法进行创建：\n\n```java\nprivate T createAdaptiveExtension() {\n    try {\n        return this.injectExtension((T) this.getAdaptiveExtensionClass().newInstance());\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Can not create adaptive extension \" + type + \", cause: \" + e.getMessage(), e);\n    }\n}\n\nprivate Class<?> getAdaptiveExtensionClass() {\n    this.getExtensionClasses();\n    if (cachedAdaptiveClass != null) {\n        return cachedAdaptiveClass;\n    }\n    return cachedAdaptiveClass = this.createAdaptiveExtensionClass();\n}\n```\n\n上述方法的逻辑比较简单，前面曾说明过 `@Adaptive` 注解既可以注解类型，也可以注解方法，如果一个扩展类型的某个实现类已经被该注解所修饰，那么此时就没有必要为该扩展类型再自动生成一个适配器，相当于我们已经为其手动创建了一个，前面的 AdaptiveExtensionFactory 就是这样一个手动创建的适配器类。对于其他情况来说，就需要调用 `ExtensionLoader#createAdaptiveExtensionClass` 方法自动生成相应的适配器类，并编译返回对应的 Class 对象，具体实现如下：\n\n```java\nprivate Class<?> createAdaptiveExtensionClass() {\n    // 生产扩展类型的 Adaptive 类 java 代码\n    String code = this.createAdaptiveExtensionClassCode();\n    ClassLoader classLoader = findClassLoader();\n    // 编译机器生成的 Adaptive 类 java 代码\n    Compiler compiler = ExtensionLoader.getExtensionLoader(Compiler.class).getAdaptiveExtension();\n    return compiler.compile(code, classLoader);\n}\n```\n\n方法首先会调用 `ExtensionLoader#createAdaptiveExtensionClassCode` 方法按照规则生成扩展类型的适配器类，相应实现比较冗长，但是逻辑并不复杂。以前面的 IpResolver 接口举例来说，该方法会为其生成一个名为 `IpResolver$Adaptive` 的适配器类，该类会实现被 `@Adaptive` 修饰的方法（其他方法直接抛出 UnsupportedOperationException 异常），其逻辑就是从 URL 中获取注解指定参数对应的参数值，并以该参数值为扩展类型名称获取相应的扩展实例，然后调用具体实现类对应的方法，具体形式如下（为了排版美观，进行了一些微调）：\n\n```java\npublic class IpResolver$Adaptive implements IpResolver {\n\n    public java.lang.String resolve(URL arg0) {\n        if (arg0 == null) throw new IllegalArgumentException(\"url == null\");\n        URL url = arg0;\n        String extName = url.getParameter(\"resolver\", \"local\");\n        if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.zhenchao.spi.IpResolver) name from url(\" + url.toString() + \") use keys([resolver])\");\n        IpResolver extension = ExtensionLoader.getExtensionLoader(IpResolver.class).getExtension(extName);\n        return extension.resolve(arg0);\n    }\n\n}\n```\n\n上面说明了“重复造轮子”的原因 1 和原因 3。针对原因 2，Dubbo SPI 定义了一个 exceptions 属性，这是一个 Map 类型集合，在加载 SPI 配置时，如果某一行配置存在问题导致加载失败，Dubbo SPI 会以该行的具体配置为 key 记录相应的异常信息，并在获取指定扩展名称对应扩展实现类 Class 对象失败时打印相应的异常链，从而方便定位错误。除了这 3 个原因（也可以说是 Dubbo SPI 对于 JDK SPI 进行的增强），Dubbo SPI 还定义了 `@Activate` 注解，我们可以调用 `ExtensionLoader#getActivateExtension` 方法获取被该注解修饰的扩展类型实现，从而简化配置和编码，具体的实现比较简单，不再展开说明。\n\n针对 Dubbo SPI 机制，除了内嵌在 Dubbo 中的实现，Dubbo 的作者也曾将其抽取出来成为一个独立的项目，即 [cooma](https://github.com/alibaba/cooma)。在实现上，comma 对 Dubbo SPI 进行了一些精简和优化，Dubbo 的作者此举是认为 Dubbo SPI 在实现上耦合了微容器之外 RPC 的概念，在功能上划分不够清晰，所以将其独立出来划清与 Dubbo 的界限，方便独立发展和改进，但是二者在设计思想上还是一致的。如果仅仅是希望学习 Dubbo SPI，可以参阅 cooma 的源码，780 行的微容器实现，短小而精悍，并且 SPI 机制（包括适配器机制）有时候并不是我们不需要它，而是不知道它的存在，以致于写了一些不够优雅的代码。\n\n### 总结\n\n本文主要介绍和分析了 JDK SPI 和 Dubbo SPI，关于两种 SPI 机制的选择，个人觉得如果不是写框架、基础组件类代码，大部分时候 JDK SPI 都能够胜任我们的需求，JDK SPI 相对于 Dubbo SPI 虽然在功能上弱化了许多，但是使用简单、不增加学习成本，也不坑后来人，所以 JDK SPI 理应成为我们的首选，当然 Dubbo SPI 的设计思想和实现也值得我们去借鉴。\n","tags":["RPC","Dubbo"],"categories":["rpc"]},{"title":"Reactor：事件驱动的高性能响应模式","url":"/2017/10/23/design-pattern/reactor/","content":"\n[Node.js](https://nodejs.org) 这几年火的不要不要的，借助 js 天生的事件驱动机制和 V8 高性能引擎，让编写高并发的 web 应用门槛降低了许多，当然这背后还要得益于 [Douglas C. Schmidt](https://en.wikipedia.org/wiki/Douglas_C._Schmidt) 在 1995 年提出的基于事件驱动的 Reactor 模式，让本身只支持单线程执行的 js 能够胜任如今高并发环境下的服务端应用。\n\n不过作为一名服务端开发人员，我对 js 的使用程度并不高，所以也一直没有机会去切身体会 Node.js 的魅力，好在 Reactor 只是一个设计模式，与具体语言和平台无关的。前段时间将负责的项目中的一个比较新的服务引入了 [Vert.x](http://vertx.io/) 组件进行改造，也算是与 Reactor 模式有了一次亲密接触。Vert.x 是一个被称为运行在 JVM 上的 Node.js，用于在任何层次上编写非阻塞、响应式的模块或服务，关于 Vert.x 的发展历程还多少有些坎坷，具体可以移步官网。<!-- more -->\n\n### 线程硬抗 or 事件驱动\n\n服务端在响应请求设计方面主要可以分为 __线程驱动__ 和 __事件驱动__ 两条主线，前者是大部分 java 服务端开发人员熟知和常用的模式（不要说你不知道 servlet），而后者则是 Reactor 模式的设计基础。\n\n我们先来看一下 __线程驱动__ 的模式设计，这一模式针对每一个请求都创建一个独立的线程。以 web 应用为例，web 服务器会为每一个客户端连接创建一个独立的线程，该线程用于接受请求参数、响应业务逻辑，并最后将结果进行渲染返回给客户端，如下图是对该模式的描绘。\n\n![image](/images/2017/thread-based-architecture.png)\n\n针对内建多线程支持的语言来说，我们通常认为这样的设计是理所当然的，事实也确实如此。基于该模式衍生出了众多的框架和组件，且有数不清的服务正在基于这样的模式运行着，其中也不乏大型项目。然而我们也不能否认这一模式在高并发场景下的乏力，“thread-per-connection” 势必导致相当一部分线程处于阻塞状态，而每一个线程的存活都需要占用一定的操作系统资源，这部分阻塞线程所持有的资源对于操作系统来说是一笔不小的开销。此外，CPU 也不得不在频繁的线程上下文切换上浪费不少的时间，如果遇上一些 I/O 密集型业务，情况会更加糟糕。下面是针对该模式的简单示例实现：\n\n```java\npublic class Server implements Runnable {\n\n    private int port;\n\n    public Server(int port) {\n        this.port = port;\n    }\n\n    @Override\n    public void run() {\n        try {\n            ServerSocket ss = new ServerSocket(port);\n            System.out.println(\"Server listening on port: \" + this.port);\n            while (!Thread.interrupted())\n                // 针对每一个请求都创建一个新的线程，也可以引入线程池\n                new Thread(new Handler(ss.accept())).start();\n        } catch (IOException ex) {\n            ex.printStackTrace();\n        }\n    }\n\n    private class Handler implements Runnable {\n\n        private final Socket socket;\n\n        public Handler(Socket socket) {\n            this.socket = socket;\n        }\n\n        @Override\n        public void run() {\n            try {\n                System.out.println(\"[thread-\" + Thread.currentThread().getId() + \"] is processing data from client.\");\n                byte[] input = new byte[1024];\n                socket.getInputStream().read(input);\n                byte[] output = this.process(input);\n                socket.getOutputStream().write(output);\n            } catch (IOException ex) {\n                ex.printStackTrace();\n            }\n        }\n\n        private byte[] process(byte[] cmd) {\n            // do something here\n        }\n    }\n}\n```\n\n针对 __事件驱动__ 模式来说，则不会为每一个连接都创建一个相应的处理线程，这里的线程数量是既定的，用于执行当前事件类型绑定的业务逻辑。这一模式有些类似于“观察者模式”的工作机制，事件就是被观察的消息。我们可以设置一个 “event-loop”，以单线程的方式不断的循环检查当前发生的具体事件，一旦有新的事件发生，则基于事件类型回调绑定的业务逻辑，而对于业务逻辑的处理则交由另外的线程（池）执行。\n\n因为事件循环检测这一过程是非常轻量化的（计算量非常小），所以单线程即可以满足高并发的需求，但是这也不是绝对的，我们也可以基于实际情况设置多个“event-loop”，从而发挥 CPU 的最大性能。这里执行业务处理的线程数量可以是单线程也可以是线程池，但是不管怎样其目的都是为了在有限的计算资源前提下尽量提高并发量，不过相对于线程驱动的模式来说，事件驱动的模式可以保证线程数量是可控的。\n\n### Reactor 设计模式与示例实现\n\nReactor 是针对事件驱动这一思想的具体设计模式，该模式自被提出以来在多种语言上都有内建或第三方的实现。该模式主要定义了如下几种角色：\n\n- __Handle__ ：可以理解为操作系统中的句柄，是对资源在操作系统层面上的抽象，例如打开的文件、网络连接(Socket）等。\n- __Synchronous Event Demultiplexer__ ：用于阻塞监听 Handle 中的事件，一般采用操作系统的 select 实现，在 java NIO 中用 Selector 进行封装。\n- __Initiation Dispatcher__ ：用于管理 Event Handler，包括注册、注销等。此外它还是事件的分发器，根据 Synchronous Event Demultiplexer 监听到的事件类型，将其分发给对应的 Event Handler 进行处理。\n- __Event Handler__ ：事件处理器，与具体的事件类型绑定，一般被定义成抽象类或接口，其中声明了钩子方法以让实现类定义具体的处理逻辑。\n- __Concrete Event Handler__ ：Event Handler 实现类。\n\n以上角色交互图如下，所有的 Event Handler 都会注册到 Initiation Dispatcher 上，Synchronous Event Demultiplexer 在应用启动后一直监听操作系统事件，当有新的事件发生时会回调 Initiation Dispatcher 的 `handle_events()` 方法，该方法会判断当前的事件类型，并调用事件绑定的 Event Handler 处理事件。\n\n![image](/images/2017/reactor-pattern-interaction.png)\n\n上述过程是 [Douglas C. Schmidt](https://en.wikipedia.org/wiki/Douglas_C._Schmidt) 在其论文中的描述，参考 [Doug Lea](https://en.wikipedia.org/wiki/Doug_Lea) 的文章来看还可以描述的更加简单一点。实际上该模式主要包含两个角色：reactor 和 handler。其中 reactor 的主要责任就是用来监听事件（event-loop），并回调事件绑定的已注册的 handler，而 handler 则用来执行事件对应的具体业务逻辑。如下图所示，其中 event-loop 和 dispatcher 都是 ractor 的角色，而 handler 和 acceptor 都注册在 dispatcher 上，其中 acceptor 是特殊的 Handler，用于创建和绑定处理事件的 handler。\n\n![image](/images/2017/event-driven-architecture.png)\n\n再生动一点，reactor 可以类比春风十里里面的老鸨，而 handler 就是菇凉们，自己脑补一下吧（邪恶...）。\n\n说完了理论，下面我们编写一个示例程序来演示 reactor 的工作机制。Java NIO 对 reactor 提供了内建的支持，这里我们以 Socket 连接作为 Handle，即 java NIO 中的 Channel。Channel 注册到 Synchronous Event Demultiplexer 中以监听 Handle 事件（对 ServerSocketChannnel 来说可以是 CONNECT 事件，对 SocketChannel 可以是 READ、WRITE、CLOSE 等事件）。Synchronous Event Demultiplexer 监听事件的过程，对应到 java NIO 则采用 Selector 进行封装，当 `Selector.select()` 返回时，可以调用 Selector 的 `selectedKeys()` 方法获取 `Set<SelectionKey>` 集合，一个 SelectionKey 对象表示一个有事件发生的 Channel 以及对应的事件类型。\n\n- __Reactor 实现__\n\n```java\npublic class Reactor implements Runnable {\n\n    private final Selector selector;\n    private final ServerSocketChannel serverSocketChannel;\n\n    public Reactor(int port) throws IOException {\n        this.selector = Selector.open();\n        this.serverSocketChannel = ServerSocketChannel.open();\n        this.serverSocketChannel.socket().bind(new InetSocketAddress(port));\n        this.serverSocketChannel.configureBlocking(false);\n        SelectionKey selectionKey = this.serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n        selectionKey.attach(new Acceptor());\n    }\n\n    @Override\n    public void run() {\n        System.out.println(\"Server listening on port: \" + serverSocketChannel.socket().getLocalPort());\n        try {\n            while (!Thread.interrupted()) {\n                selector.select();\n                Set selected = selector.selectedKeys();\n                Iterator itr = selected.iterator();\n                while (itr.hasNext()) {\n                    this.dispatch((SelectionKey) (itr.next()));\n                }\n                selected.clear();\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    private void dispatch(SelectionKey key) throws Exception {\n        Runnable acceptor = (Runnable) (key.attachment());\n        if (acceptor != null) acceptor.run();\n    }\n\n    private class Acceptor implements Runnable {\n\n        @Override\n        public void run() {\n            try {\n                SocketChannel socketChannel = serverSocketChannel.accept();\n                if (socketChannel != null) new Handler(selector, socketChannel);\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n}\n```\n\n- __Handler 实现__\n\n```java\npublic class Handler implements Runnable {\n\n    private static final int READ = 0, PROCESS = 1, WRITE = 2;\n\n    private final SocketChannel socketChannel;\n    private final SelectionKey selectionKey;\n\n    private static ExecutorService pool = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\n\n    private ByteBuffer input = ByteBuffer.allocate(1024);\n    private boolean isClosed;\n    private int state = READ;\n    private String data;\n\n    public Handler(Selector selector, SocketChannel channel) throws IOException {\n        this.socketChannel = channel;\n        this.socketChannel.configureBlocking(false);\n        this.isClosed = !socketChannel.isConnected();\n        this.selectionKey = this.socketChannel.register(selector, 0);\n        this.selectionKey.attach(this);\n        this.selectionKey.interestOps(SelectionKey.OP_READ);\n        selector.wakeup();\n    }\n\n    @Override\n    public void run() {\n        try {\n            if (isClosed) socketChannel.close();\n            if (READ == state) {\n                this.read();\n            } else if (WRITE == state) {\n                this.write();\n            }\n        } catch (IOException e) {\n            try {\n                socketChannel.close();\n            } catch (IOException e1) {\n                // ignore\n            }\n        }\n    }\n\n    private void read() throws IOException {\n        System.out.println(\"[thread-\" + Thread.currentThread().getId() + \"] read data from client.\");\n        int readCount = socketChannel.read(input);\n        if (readCount > 0) {\n            state = PROCESS;\n            pool.execute(() -> this.process(readCount));\n        } else {\n            this.isClosed = true;\n        }\n        selectionKey.interestOps(SelectionKey.OP_WRITE);\n    }\n\n    private void process(int readCount) {\n        System.out.println(\"[thread-\" + Thread.currentThread().getId() + \"] is processing data.\");\n        StringBuilder sb = new StringBuilder();\n        input.flip();\n        byte[] subStringBytes = new byte[readCount];\n        byte[] array = input.array();\n        System.arraycopy(array, 0, subStringBytes, 0, readCount);\n        sb.append(new String(subStringBytes));\n        input.clear();\n        this.data = sb.toString().trim();\n        state = WRITE;\n    }\n\n    private void write() throws IOException {\n        System.out.println(\"[thread-\" + Thread.currentThread().getId() + \"] write data to client : \" + this.data);\n        ByteBuffer output = ByteBuffer.wrap((\"Hello \" + this.data + \"\\n\").getBytes());\n        socketChannel.write(output);\n        selectionKey.interestOps(SelectionKey.OP_READ);\n        state = READ;\n    }\n\n}\n```\n\n示例程序以 [Doug Lea](https://en.wikipedia.org/wiki/Doug_Lea) 大师在 “[Scalable IO in Java](http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)” 文章中的例子为原型并做了一些更改。该示例采用一个线程不断的监听客户端请求（具体实现时可以依据需要选择实现多个监听器），一旦有新的 socket 连接就会创建一个与之绑定的 Handler，并读取请求数据，至于对数据的处理则交由线程池中的线程进行。这里默认我们设置线程池的大小为当前宿主机核心数，并使用一个单线程不断的监听请求事件，在这样的设计下，不管客户端有多少连接并发量，服务端的线程数始终是 （核心数 + 1），我们甚至可以只用 2 个线程来处理客户端的所有请求（一个负责监听事件，一个用于处理事件）。\n\n对应的客户端测试程序如下，真实环境下客户端的请求是不应该设置上限的，这里我们设置了 1024 个请求线程也只是为了演示：\n\n```java\npublic class Client {\n\n    private String host;\n    private int port;\n\n    public Client(String host, int port) {\n        this.host = host;\n        this.port = port;\n    }\n\n    private void sayHello() throws Exception {\n        ExecutorService es = Executors.newCachedThreadPool();\n        List<Callable<Boolean>> tasks = new ArrayList<>();\n        for (int i = 0; i < 1024; i++) {\n            tasks.add(() -> {\n                Socket socket = null;\n                PrintWriter out = null;\n                BufferedReader in = null;\n                try {\n                    socket = new Socket(host, port);\n                    out = new PrintWriter(socket.getOutputStream(), true);\n                    in = new BufferedReader(new InputStreamReader(socket.getInputStream()));\n                    System.out.println(\"Client[\" + Thread.currentThread().getId() + \"] connect success, host : \" + host + \" port: \" + port);\n                    String hay = RandomStringUtils.randomAlphanumeric(32);\n                    out.println(hay);\n                    String msg = in.readLine().trim();\n                    System.out.println(\"Client[\" + Thread.currentThread().getId() + \"] receive data from server : \" + msg);\n                    if(!(\"Hello \" + hay).equals(msg)) {\n                        System.err.println(\"expect : \" + hay + \", but : \" + msg);\n                        System.exit(-1);\n                    }\n                    return true;\n                } catch (Exception e) {\n                    e.printStackTrace();\n                } finally {\n                    if (null != out) out.close();\n                    if (null != in) in.close();\n                    if (null != socket) socket.close();\n                }\n                return false;\n            });\n        }\n        List<Future<Boolean>> futures = es.invokeAll(tasks);\n        for (final Future<Boolean> future : futures) {\n            future.get();\n        }\n        TimeUnit.SECONDS.sleep(5);\n        es.shutdown();\n    }\n\n}\n```\n\n说了这么多，我们最后再来谈谈 Reactor 模式的不足，毕竟完美的事物是不存在的，Reactor 的不足主要表现在如下几个方面：\n\n1. 相对于传统模型来说，Reactor 在思想上稍显复杂性，因此也增加了实现和使用的门槛，并且不易于调试。\n2. 需要底层 Synchronous Event Demultiplexer 支持，比如 java 中的 Selector，操作系统的 select 等，如果要自己实现可能不会那么高效。\n3. 在 IO 读写数据时仍然在同一个线程中实现的，即使实现了多个 reactor，那些共享同一个 reactor 的 channel 如果执行长时间的数据读写，也会影响这个 reactor 中其他 channel 的响应时间。比如在大文件传输时，IO 操作就会影响其他 client 的响应时间，因而对这种操作，使用传统的 “thread-per-connection” 或许是更好的选择，或者使用 [Proactor](https://en.wikipedia.org/wiki/Proactor_pattern) 模式。\n\n### 参考\n\n1. [Reactor: An Object Behavioral Pattern forDemultiplexing and Dispatching Handles for Synchronous Events](http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf)\n2. [Scalable IO in Java](http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)\n3. [Reactor Pattern Explained](http://jeewanthad.blogspot.hk/2013/02/reactor-pattern-explained-part-1.html)\n4. [Reactor模式详解](http://www.blogjava.net/DLevin/archive/2015/09/02/427045.html)\n","tags":["反应式"],"categories":["design-pattern"]},{"title":"限流技术中的常用算法及其优缺点","url":"/2017/10/18/solution/throttle/","content":"\n我们通常说缓存、降级，以及限流技术是高并发服务的三大利器，本文我们就来聊聊限流技术中常用的算法。为保证服务的可用性，限流往往是服务端接口的必备特性之一，用于对抗大规模恶意或无效请求，保护有限的计算和存储资源。关于接口限流有很多成熟的算法可供使用，包括：计数器、漏桶，以及令牌桶等，这些算法都为实际项目中的限流器设计提供了理论支撑。<!-- more -->\n\n### 计数器算法\n\n计数器应该是最简单、最容易想到的限流策略，毕竟限流的本质就是限制一个接口在某个维度上单位时间内的响应次数。我们可以设置一个计数器对某一时间段内的请求进行计数，当请求量超过某个事先设定的阈值时则触发饱和策略，拒绝用户的请求。比如我们事先设定某个接口单一 IP 维度在 1 分钟内只能正常响应 100 次用户请求，那么如果范围内某个 IP 请求超过该阈值，就会拒绝后续请求。\n\n计数器方法存在的一个缺点是计数不够平滑。考虑一个 10 点开放抢购的场景，如果一个恶意用户在 `09:59:30 ~ 09:59:59` 之间请求了 100 次，然后等到 10 点整时计数器被清空，这个时候该用户在 `10:00:00 ~ 10:00:30` 之间又可以再次请求 100 次，实际上在 `09:59:30 ~ 10:00:30` 这一分钟内该恶意用户请求了 200 次，成功绕过了限流策略。\n\n针对计数器算法存在的上述缺陷，一种典型的解决方法就是采用 __滑动窗口策略__ 。以上述场景为例，我们可以为 1 分钟 100 次的请求上限设置一个大窗口，并对该窗口进一步细分，比如每 10 秒设置一个小窗口，该窗口的频率上限同样设置为 100。这样，大窗口中包含了 6 个小窗口，并且每隔 10 秒大窗口就往前移动一个小窗口长度。这样的设计下，如果一个恶意用户在 `09:59:30 ~ 09:59:59` 之间请求了 100 次，等到 `10:00:00 ~ 10:00:30` 时这 100 次计数仍然是有效的，所以这个时间段该用户新的请求仍然会被拒绝。\n\n### 漏桶算法\n\n漏桶（Leaky Bucket）算法是限流方面比较经典的算法，该算法最早应用于网络拥塞控制方面。要理解该算法可以联想一个具体的漏桶模型，不管进水量有多大，漏桶始终以恒定的速率往外排水，如果桶被装满则后来涌入的水会漫出去。\n\n对应接口限流而言，用户的请求可以看作是这里的水，不管用户的请求量有多大多不均衡，能够被处理的请求速率是恒定的，而且能够被接受的请求数也是有上限的，超出上限的请求会被拒绝，典型的我们可以采用队列作为这里的漏桶实现。\n\n![image](/images/2017/leaky_bucket.jpg)\n\n由上面的解释我们应该能够体会到漏桶算法非常适用于秒杀系统的限流。漏桶在这种应用场景下可以起到一定的削峰填谷的作用，并且漏桶的设计从根本上能够应对集中访问的问题，同时具备平滑策略。然而，始终恒定的处理速率有时候并不一定是好事情，对于突发的请求洪峰，在保证服务安全的前提下，应该尽最大努力去响应，这个时候漏桶算法显得有些呆滞。\n\n### 令牌桶算法\n\n令牌桶（Token Bucket）算法可以看作是计数器算法的逆过程，不过相对于计数器来说更加平滑。该算法要求系统以一定的速率发放访问令牌，用户的请求必须在持有合法令牌的前提下才能够被响应。我们可以按照权重设置一类请求被响应所需持有的令牌数，只有当桶中的令牌数目满足当前请求所需时才授予令牌，对于其它情况则拒绝请求。\n\n![image](/images/2017/token_bucket.jpg)\n\n由于发放令牌的速率是恒定的，所以对于集中请求来说，令牌桶算法能够很好的做平滑。例如前面列举的在 `09:59:30 ~ 09:59:59` 之间有 100 次的突发请求，那么等到 10 点整的时候系统并不会立即容忍 100 次新的请求，这个时候服务的响应受限于当前桶中的令牌数量。实际项目中我们可以基于当前服务能力动态调整令牌的发放速率，此外我们还需要为桶设置大小上限（或者为令牌设置生命周期），以防止大量令牌累积导致的“伪限流失效”现象。\n\n[Guava](https://github.com/google/guava) 库中的 RateLimiter 类是对令牌桶算法的单机版实现，基于 RateLimiter 我们可以设置每秒生成的令牌数，并允许以阻塞、尝试，以及超时等策略获取令牌。\n\n### 总结\n\n总的来说，计数器算法在实现层面比较简单，但是如果要做到平滑需要引入滑动窗口策略；漏洞算法天生具备平滑属性，但是在面对流量突增时调整起来不够方便，显得有些呆滞；令牌桶算法同样具备平滑属性，并且能够通过简单调整令牌的发放频率以应对流量突增，但是如果在流量突增时有大量累积可用的令牌则会导致短暂的限流失效假象。\n\n限流器在实现层面并没有太多复杂的逻辑，不过正如以前听一位长者所说，__限流的难点在于配置__ ，不管是静态配置还是动态配置，如何让限流在不误伤的前提下尽量发挥硬件的最大性能是一个富有经验的问题，而压测是一个基础且行之有效的途径。\n\n### 参考\n\n1. [Leaky bucket](https://en.wikipedia.org/wiki/Leaky_bucket)\n2. [Token bucket](https://en.wikipedia.org/wiki/Token_bucket)\n3. [流量调整和限流技术](http://colobu.com/2014/11/13/rate-limiting/)\n","tags":["限流"],"categories":["solution"]},{"title":"MyBatis 源码解析：SQL 语句的执行机制","url":"/2017/10/15/mybatis/mybatis-execute-sql/","content":"\n通过前面两篇文章，我们完成了对 MyBatis 所有配置文件（包括配置文件和映射文件）解析过程的分析。回忆一下我们最开始给出的小示例（如下），经过前面的跋山涉水，我们终于完成了第一行代码的 99% （手动滑稽），这最后的 1% 就是创建 SqlSessionFactory 对象。所有的配置解析最后都会封装到 Configuration 对象中，接下去就是调用 `SqlSessionFactoryBuilder#build` 方法创建 SqlSessionFactory 对象，实际使用的是 DefaultSqlSessionFactory 实现类进行实例化。<!-- more -->\n\n```java\nSqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder()\n        .build(Resources.getResourceAsStream(\"mybatis-config.xml\"));\ntry (SqlSession sqlSession = sessionFactory.openSession()) {\n    UserMapper mapper = sqlSession.getMapper(UserMapper.class);\n    User user = mapper.selectByName(\"zhenchao\");\n    // ... use user object\n}\n```\n\nSqlSessionFactory 是一个工厂类，用于创建 SqlSession 对象。按照官方文档的说明，SqlSessionFactory 对象一旦被创建就应该在应用的运行期间一直存在，不应该在运行期间对其进行清除或重建。调用该工厂的 `SqlSessionFactory#openSession` 方法可以开启一次会话，即创建一个 SqlSession 对象。SqlSession 封装了面向数据库执行 SQL 的所有 API，它不是线程安全的，因此不能被共享，所以该对象的最佳作用域是请求或方法作用域。在上面的示例中，我们用 SqlSession 拿到相应的 Mapper 接口对象（更准确的说是一个动态代理对象），然后执行指定的数据库操作，最后关闭此次会话。\n\n![image](/images/2017/mybatis-execute-sql.png)\n\n上面这张时序图我们在本系列开篇的文章中已经引用过，描绘了 MyBatis 在一次会话生命周期内执行数据库操作的交互时序。下面对这幅图中所描绘的执行过程中类之间的交互时序关系作进一步说明，稍后我们会对图中涉及到的类和接口从源码层面进行分析，执行时序如下：\n\n1. 调用 `SqlSessionFactory#openSession` 方法创建 SqlSession 对象，开启一次会话；\n2. 调用 `SqlSession#getMapper` 方法获取指定的 Mapper 接口对象，这里实际上将请求委托给 `Configuration#getMapper` 方法执行，由前面分析映射文件解析过程时我们知道所有的 Mapper 接口都会注册到全局唯一的配置对象 Configuration 的 MapperRegistry 类型属性中；\n3. MapperRegistry 在执行 `MapperRegistry#getMapper` 操作时会反射创建 Mapper 接口的动态代理对象并返回；\n4. 执行对应的数据库操作方法（例如 `UserMapper#selectByName`），即调用 Mapper 接口动态代理对象的 `MapperProxy#invoke` 方法，在该方法中会获取封装执行方法的 MapperMethod 对象；\n5. 执行 `MapperMethod#execute` 方法，该方法会判定当前数据库操作类型（例如 SELECT），依据类型选择执行 SqlSession 对应的数据库操作方法；\n6. SqlSession 会将数据库操作委托给具体的 Executor 执行。对于动态 SQL 语句而言，在这里会依据参数执行解析；对于查询语句而言，Executor 在条件允许的情况下会尝试先从缓存中进行查询，缓存不命中才会操作具体的数据库并更新缓存。MyBatis 强大的结果集映射操作也在这里完成；\n7. 返回查询结果；\n8. 调用当前会话的 `SqlSession#close` 方法关闭本次会话。\n\n整个过程围绕一次查询操作展开，虽然不能覆盖 MyBatis 执行 SQL 语句的各个方面，但主线上还是能够说明白 MyBatis 针对一次 SQL 执行的大概过程。在下面的篇幅中，我们将一起分析这一整套时序背后的实现机制。\n\n### SQL 会话管理\n\nSqlSession 接口是 MyBatis 对外提供的数据库操作 API，是 MyBatis 的核心接口之一，用于管理一次数据库会话。围绕 SqlSession 接口的类继承关系如下图所示，其中 DefaultSqlSession 是默认的 SqlSession 实现。SqlSessionFactory 是一个工厂接口，其功能是用来创建 SqlSession 对象，该接口中声明了多个重载版本的 `SqlSessionFactory#openSession` 方法，DefaultSqlSessionFactory 是该接口的默认实现。上述示例程序中 `SqlSessionFactoryBuilder#build` 方法就是基于该实现类创建的 SqlSessionFactory 对象。SqlSessionManager 类实现了这两个接口，所以具备创建、使用，以及管理 SqlSession 对象的能力，后面会详细说明。\n\n![image](/images/2017/mybatis-sqlsession.png)\n\nSqlSession 接口中声明的方法都比较直观，感兴趣的读者可以自行阅读源码。我们来看一下针对该接口的默认实现类 DefaultSqlSession，该类的属性定义如下：\n\n```java\n/** 全局唯一的配置对象 */\nprivate final Configuration configuration;\n/** SQL 语句执行器 */\nprivate final Executor executor;\n/** 是否自动提交事务 */\nprivate final boolean autoCommit;\n/** 标记当前缓存中是否存在脏数据 */\nprivate boolean dirty;\n/** 记录已经打开的游标 */\nprivate List<Cursor<?>> cursorList;\n```\n\nDefaultSqlSession 中的方法实现基本上都是对 Executor 接口方法的封装，实现上都比较简单。这里解释一下 `DefaultSqlSession#cursorList` 这个属性，在 `DefaultSqlSession#selectCursor` 方法中会记录查询返回的游标（Cursor）对象，并在关闭 SqlSession 会话时遍历集合逐一关闭，从而防止打开的游标没有被关闭的现象。\n\nDefaultSqlSessionFactory 是 SqlSessionFactory 接口的默认实现，用于创建 SqlSession 对象。该实现类提供了两种创建 SqlSession 对象的方式，分别是基于当前数据源创建会话和基于当前数据库连接创建会话，对应的实现如下。\n\n- __基于数据源创建会话__\n\n```java\nprivate SqlSession openSessionFromDataSource(\n    ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {\n    Transaction tx = null;\n    try {\n        // 获取当前激活的数据库环境配置\n        final Environment environment = configuration.getEnvironment();\n        // 获取当前数据库环境对应的 TransactionFactory 对象，不存在的话就创建一个\n        final TransactionFactory transactionFactory = this.getTransactionFactoryFromEnvironment(environment);\n        tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);\n        // 依据指定的 Executor 类型创建对应的 Executor 对象\n        final Executor executor = configuration.newExecutor(tx, execType);\n        // 创建 SqlSession 对象\n        return new DefaultSqlSession(configuration, executor, autoCommit);\n    } catch (Exception e) {\n        this.closeTransaction(tx); // may have fetched a connection so lets call close()\n        throw ExceptionFactory.wrapException(\"Error opening session.  Cause: \" + e, e);\n    } finally {\n        ErrorContext.instance().reset();\n    }\n}\n```\n\n- __基于数据库连接创建会话__\n\n```java\nprivate SqlSession openSessionFromConnection(ExecutorType execType, Connection connection) {\n    try {\n        boolean autoCommit;\n        try {\n            autoCommit = connection.getAutoCommit();\n        } catch (SQLException e) {\n            // 考虑到很多驱动或者数据库不支持事务，设置自动提交事务\n            autoCommit = true;\n        }\n        // 获取当前激活的数据库环境配置\n        final Environment environment = configuration.getEnvironment();\n        // 获取当前数据库环境对应的 TransactionFactory 对象，不存在的话就创建一个\n        final TransactionFactory transactionFactory = this.getTransactionFactoryFromEnvironment(environment);\n        final Transaction tx = transactionFactory.newTransaction(connection);\n        // 依据指定的 Executor 类型创建对应的 Executor 对象\n        final Executor executor = configuration.newExecutor(tx, execType);\n        // 创建 SqlSession 对象\n        return new DefaultSqlSession(configuration, executor, autoCommit);\n    } catch (Exception e) {\n        throw ExceptionFactory.wrapException(\"Error opening session.  Cause: \" + e, e);\n    } finally {\n        ErrorContext.instance().reset();\n    }\n}\n```\n\n两种创建会话的方式在执行流程上基本一致，具体细节如上述代码注释。\n\nSqlSessionManager 同时实现了 SqlSessionFactory 和 SqlSession 两个接口，所以具备这两个接口全部的功能。该实现类的属性定义如下：\n\n```java\n/** 封装的 {@link SqlSessionFactory} 对象 */\nprivate final SqlSessionFactory sqlSessionFactory;\n/** 线程私有的 SqlSession 对象的动态代理对象 */\nprivate final SqlSession sqlSessionProxy;\n/** 线程私有的 SqlSession 对象 */\nprivate final ThreadLocal<SqlSession> localSqlSession = new ThreadLocal<SqlSession>();\n```\n\n针对 SqlSessionFactory 接口中声明的方法，SqlSessionManager 均委托给持有的 SqlSessionFactory 对象完成。对于 SqlSession 接口中声明的方法，SqlSessionManager 提供了两种实现方式：如果当前线程已经绑定了一个 SqlSession 对象，那么只要未主动调用 `SqlSessionManager#close` 方法，就会一直复用该线程私有的 SqlSession 对象；否则会在每次执行数据库操作时创建一个新的 SqlSession 对象，并在使用完毕之后关闭会话。相关逻辑位于 SqlSessionInterceptor 类中，这是一个定义在 SqlSessionManager 中的内部类，属性 `SqlSessionManager#sqlSessionProxy` 是基于该类实现的动态代理对象：\n\n```java\nthis.sqlSessionProxy = (SqlSession) Proxy.newProxyInstance(\n            SqlSessionFactory.class.getClassLoader(), new Class[]{SqlSession.class}, new SqlSessionInterceptor());\n```\n\nSqlSessionInterceptor 类实现自 InvocationHandler 接口，对应的 `SqlSessionInterceptor#invoke` 方法实现如下：\n\n```java\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n    // 获取当前线程私有的 SqlSession 对象\n    final SqlSession sqlSession = localSqlSession.get();\n    // 会话未被关闭\n    if (sqlSession != null) {\n        try {\n            // 直接反射调用相应的方法\n            return method.invoke(sqlSession, args);\n        } catch (Throwable t) {\n            throw ExceptionUtil.unwrapThrowable(t);\n        }\n    }\n    // 没有 SqlSession，或已关闭，创建一个，使用完毕之后即关闭会话\n    else {\n        try (SqlSession autoSqlSession = SqlSessionManager.this.openSession()) {\n            try {\n                // 反射调用相应的方法\n                final Object result = method.invoke(autoSqlSession, args);\n                // 提交事务\n                autoSqlSession.commit();\n                return result;\n            } catch (Throwable t) {\n                // 回滚事务\n                autoSqlSession.rollback();\n                throw ExceptionUtil.unwrapThrowable(t);\n            }\n        }\n    }\n}\n```\n\nSqlSessionInterceptor 首先会尝试获取线程私有的 SqlSession 对象，对于未绑定的线程来说会创建一个新的 SqlSession 对象，并在使用完毕之后立刻关闭。\n\n### 动态代理 Mapper 接口\n\nMyBatis 要求所有的 Mapper 都定义成接口的形式，这主要是为了配合 JDK 内置的动态代理机制，JDK 内置的动态代理要求被代理的类必须抽象出一个接口。常用的动态代理除了 JDK 内置的方式，还有基于 CGlib 等第三方组件的方式，MyBatis 采用了 JDK 内置的方式创建 Mapper 接口的动态代理对象。\n\n我们先来复习一下 JDK 内置的动态代理机制，假设现在有一个接口 Mapper 及其实现类如下：\n\n```java\npublic interface Mapper {\n    int select();\n}\n\npublic class MapperImpl implements Mapper {\n    @Override\n    public int select() {\n        System.out.println(\"do select.\");\n        return 0;\n    }\n}\n```\n\n现在我们希望在方法执行之前打印一行调用日志，基于动态代理的实现方式如下。我们需要定义一个实现了 InvocationHandler 接口的代理类，然后在其 `InvocationHandler#invoke` 方法中实现增强逻辑：\n\n```java\npublic class MapperProxy implements InvocationHandler {\n\n    private Mapper mapper;\n\n    public MapperProxy(Mapper mapper) {\n        this.mapper = mapper;\n    }\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        System.out.println(\"before invoke.\");\n        return method.invoke(this.mapper, args);\n    }\n\n}\n```\n\n客户端调用代码：\n\n```java\nMapper mapper = new MapperImpl();\nMapper mapperProxy = (Mapper) Proxy.newProxyInstance(\n        mapper.getClass().getClassLoader(), mapper.getClass().getInterfaces(), new MapperProxy(mapper));\nmapperProxy.select();\n```\n\n回到 MyBatis 框架本身，我们在执行目标数据库操作时，一般会直接调用目标 Mapper 接口的相应方法，这里框架返回给我们的实际上是 Mapper 接口的动态代理类对象。MyBatis 基于 JDK 的动态代理机制实现了 Mapper 接口中声明的方法，这其中包含了 __获取 SQL 语句、参数绑定、缓存操作、数据库操作，以及结果集映射处理__ 等步骤，下面就 Mapper 接口动态代理机制涉及到的相关类和方法进行分析。\n\n上一篇在分析映射文件时我们介绍了在 `MapperRegistry#knownMappers` 属性中记录了 Mapper 接口与 MapperProxyFactory 的映射关系，MapperProxyFactory 顾名思义是 MapperProxy 的工厂类，其中定义了创建 Mapper 接口代理对象的方法，如下：\n\n```java\npublic T newInstance(SqlSession sqlSession) {\n    final MapperProxy<T> mapperProxy = new MapperProxy<>(sqlSession, mapperInterface, methodCache);\n    return this.newInstance(mapperProxy);\n}\n\nprotected T newInstance(MapperProxy<T> mapperProxy) {\n    // 创建 Mapper 接口对应的动态代理对象（基于 JDK 内置的动态代理机制）\n    return (T) Proxy.newProxyInstance(\n        mapperInterface.getClassLoader(),\n        new Class[] {mapperInterface},\n        mapperProxy);\n}\n```\n\n来看一下 MapperProxy 实现，该类实现了 InvocationHandler 接口，对应的 `InvocationHandler#invoke` 实现如下：\n\n```java\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n    try {\n        // 对于 Object 类中声明的方法，直接调用\n        if (Object.class.equals(method.getDeclaringClass())) {\n            return method.invoke(this, args);\n        }\n        // 对于非 Object 类中声明的方法\n        else {\n            // 获取方法关联的 MapperMethodInvoker 对象，并执行数据库操作\n            return this.cachedInvoker(method).invoke(proxy, method, args, sqlSession);\n        }\n    } catch (Throwable t) {\n        throw ExceptionUtil.unwrapThrowable(t);\n    }\n}\n```\n\n上述方法的核心逻辑在于获取当前执行方法 Method 对象对应的 MapperMethodInvoker 方法调用器，并执行 `MapperMethodInvoker#invoke` 方法触发对应的数据库操作。\n\n围绕 MapperMethodInvoker 接口，MyBatis 提供了两种实现，即 DefaultMethodInvoker 和 PlainMethodInvoker，其中前者用于支持 JDK 7 引入的动态类型语言特性，后者则是对 MapperMethod 的封装。MapperMethod 中主要定义两个内部类：\n\n- __SqlCommand__ ：用于封装方法关联的 SQL 语句名称和类型。\n- __MethodSignature__ ：用来封装方法相关的签名信息。\n\n先来看一下 SqlCommand 的具体实现，该类定义了 `SqlCommand#name` 和 `SqlCommand#type` 两个属性，分别用于记录对应 SQL 语句的名称和类型，并在构造方法中实现了相应的解析逻辑和初始化操作，如下：\n\n```java\npublic SqlCommand(Configuration configuration, Class<?> mapperInterface, Method method) {\n    // 获取方法名称\n    final String methodName = method.getName();\n    // 获取方法隶属的类或接口的 Class 对象\n    final Class<?> declaringClass = method.getDeclaringClass();\n    // 解析方法关联的 SQL 语句对应的 MappedStatement 对象（用于封装 SQL 语句）\n    MappedStatement ms = this.resolveMappedStatement(mapperInterface, methodName, declaringClass, configuration);\n    // 未找当前方法对应的 MappedStatement 对象\n    if (ms == null) {\n        // 如果对应方法注解了 @Flush，表示执行缓存的批量更新语句，则进行标记\n        if (method.getAnnotation(Flush.class) != null) {\n            name = null;\n            type = SqlCommandType.FLUSH;\n        } else {\n            throw new BindingException(\n                \"Invalid bound statement (not found): \" + mapperInterface.getName() + \".\" + methodName);\n        }\n    }\n    // 找当前方法对应的 MappedStatement 对象，初始化 SQL 语句名称和类型\n    else {\n        name = ms.getId();\n        type = ms.getSqlCommandType();\n        if (type == SqlCommandType.UNKNOWN) {\n            throw new BindingException(\"Unknown execution method for: \" + name);\n        }\n    }\n}\n\nprivate MappedStatement resolveMappedStatement(\n    Class<?> mapperInterface, String methodName, Class<?> declaringClass, Configuration configuration) {\n    // 接口名称.方法名\n    String statementId = mapperInterface.getName() + \".\" + methodName;\n\n    // 方法存在关联的 SQL 语句，则获取封装该 SQL 语句的 MappedStatement 对象\n    if (configuration.hasStatement(statementId)) {\n        return configuration.getMappedStatement(statementId);\n    }\n    // 已经递归到该方法隶属的最上层类，但是仍然没有找到关联的 MappedStatement 对象\n    else if (mapperInterface.equals(declaringClass)) {\n        return null;\n    }\n\n    // 沿着继承关系向上递归检索\n    for (Class<?> superInterface : mapperInterface.getInterfaces()) {\n        if (declaringClass.isAssignableFrom(superInterface)) {\n            // 递归检索\n            MappedStatement ms = this.resolveMappedStatement(\n                superInterface, methodName, declaringClass, configuration);\n            if (ms != null) {\n                return ms;\n            }\n        }\n    }\n    return null;\n}\n```\n\nSqlCommand 在实例化时所做的主要工作就是解析当前 Mapper 方法关联的 SQL 对应的 MappedStatement 对象，并初始化记录的 SQL 语句名称和类型，整个解析过程如上述代码注释。\n\n再来看一下 MethodSignature 类，该类用于封装一个具体 Mapper 方法的相关签名信息，其中定义的方法实现都比较简单，这里列举一下其属性定义：\n\n```java\n/** 标记返回值是否是 {@link java.util.Collection} 或数组类型 */\nprivate final boolean returnsMany;\n/** 标记返回值是否是 {@link Map} 类型 */\nprivate final boolean returnsMap;\n/** 标记返回值是否是 {@link Void} 类型 */\nprivate final boolean returnsVoid;\n/** 标记返回值是否是 {@link Cursor} 类型 */\nprivate final boolean returnsCursor;\n/** 标记返回值是否是 {@link Optional} 类型 */\nprivate final boolean returnsOptional;\n/** 返回值类型 */\nprivate final Class<?> returnType;\n/** 对于 Map 类型的返回值，用于记录 key 的别名 */\nprivate final String mapKey;\n/** 标记参数列表中 {@link ResultHandler} 的下标 */\nprivate final Integer resultHandlerIndex;\n/** 标记参数列表中 {@link RowBounds} 的下标 */\nprivate final Integer rowBoundsIndex;\n/** 参数名称解析器 */\nprivate final ParamNameResolver paramNameResolver;\n```\n\n上面属性中重点介绍一下 ParamNameResolver 这个类，它的作用在于解析 Mapper 方法的参数列表，以便于在方法实参和方法关联的 SQL 语句的参数之间建立映射关系。其中一个比较重要的属性是 `ParamNameResolver#names`，定义如下：\n\n```java\n/**\n * 记录参数在参数列表中的下标和参数名称之间的对应关系。\n * 参数名称通过 {@link Param} 注解指定，如果没有指定则使用参数下标作为参数名称，\n * 需要注意的是，如果参数列表中包含 {@link RowBounds} 或 {@link ResultHandler} 类型的参数，\n * 这两种功能型参数不会记录到集合中，此时如果用下标表示参数名称，索引值 key 与对应的参数名称（实际索引）可能会不一致。\n *\n * <p>\n * The key is the index and the value is the name of the parameter.<br />\n * The name is obtained from {@link Param} if specified. When {@link Param} is not specified,\n * the parameter index is used. Note that this index could be different from the actual index\n * when the method has special parameters (i.e. {@link RowBounds} or {@link ResultHandler}).\n * </p>\n * <ul>\n * <li>aMethod(@Param(\"M\") int a, @Param(\"N\") int b) -&gt; {{0, \"M\"}, {1, \"N\"}}</li>\n * <li>aMethod(int a, int b) -&gt; {{0, \"0\"}, {1, \"1\"}}</li>\n * <li>aMethod(int a, RowBounds rb, int b) -&gt; {{0, \"0\"}, {2, \"1\"}}</li>\n * </ul>\n */\nprivate final SortedMap<Integer, String> names;\n```\n\n我把它的英文注释和我的理解都写在代码注释中，应该可以清楚理解该属性的作用。至于为什么需要跳过 RowBounds 和 ResultHandler 这两个类型的参数，是因为前者用于设置 LIMIT 参数，后者用于设置结果集处理器，所以都不是真正意义上的参数，按照我的话说这两种类型的参数都是功能型的参数。\n\nParamNameResolver 在构造方法中实现了对参数列表的解析，如下：\n\n```java\npublic ParamNameResolver(Configuration config, Method method) {\n    // 获取参数类型列表\n    final Class<?>[] paramTypes = method.getParameterTypes();\n    // 获取参数列表上的注解列表\n    final Annotation[][] paramAnnotations = method.getParameterAnnotations();\n    final SortedMap<Integer, String> map = new TreeMap<>();\n    int paramCount = paramAnnotations.length;\n\n    // 遍历处理方法所有的参数\n    for (int paramIndex = 0; paramIndex < paramCount; paramIndex++) {\n        // 跳过 RowBounds 和 ResultHandler 类型参数\n        if (isSpecialParameter(paramTypes[paramIndex])) {\n            continue;\n        }\n\n        // 查找当前参数是否有 @Param 注解\n        String name = null;\n        for (Annotation annotation : paramAnnotations[paramIndex]) {\n            // 获取注解指定的参数名称\n            if (annotation instanceof Param) {\n                hasParamAnnotation = true;\n                name = ((Param) annotation).value();\n                break;\n            }\n        }\n\n        // 没有 @Param 注解\n        if (name == null) {\n            // 基于配置开关决定是否获取参数的真实名称\n            if (config.isUseActualParamName()) {\n                name = this.getActualParamName(method, paramIndex);\n            }\n            // 使用下标作为参数名称\n            if (name == null) {\n                // use the parameter index as the name (\"0\", \"1\", ...)\n                // gcode issue #71\n                name = String.valueOf(map.size());\n            }\n        }\n        map.put(paramIndex, name);\n    }\n    names = Collections.unmodifiableSortedMap(map);\n}\n```\n\n整个过程概括来说就是遍历处理指定方法的参数列表，忽略 RowBounds 和 ResultHandler 类型的参数，并判断参数前面是否有 `@Param` 注解，如果有则尝试以注解指定的字符串作为参数名称，否则基于配置决定是否采用参数的真实名称作为这里的参数名，再不济就采用下标值作为参数名称。\n\n考虑到会忽略 RowBounds 和 ResultHandler 两种类型的参数，但是属性 `ParamNameResolver#names` 对应的 key 又是递增的，所以就可能出现在以下标值作为参数名称时，参数名称与对应下标值不一致的情况。例如，假设有一个方法的参数列表为 `(int a, RowBounds rb, int b)`，因为有 RowBounds 类型夹在中间，如果以下标值作为参数名称的最终解析结果就是 `{0, \"0\"}, {2, \"1\"}`，下标与具体的参数名称不一致。\n\nParamNameResolver 中还有一个比较重要的方法 `ParamNameResolver#getNamedParams`，用于关联实参和形参列表，其中 args 参数是用户传递的实参数组，方法基于前面的参数列表解析结果将传递的实现与对应的方法参数进行关联，最终记录到 Object 对象中进行返回，实现如下：\n\n```java\npublic Object getNamedParams(Object[] args) {\n    // names 属性记录参数在参数列表中的下标和参数名称之间的对应关系\n    final int paramCount = names.size();\n    // 无参方法，直接返回\n    if (args == null || paramCount == 0) {\n        return null;\n    }\n    // 没有 @Param 注解，且只有一个参数\n    else if (!hasParamAnnotation && paramCount == 1) {\n        return args[names.firstKey()];\n    }\n    // 有 @Param 注解，或存在多个参数\n    else {\n        final Map<String, Object> param = new ParamMap<>();\n        int i = 0;\n        // 遍历处理参数列表中的非功能性参数\n        for (Map.Entry<Integer, String> entry : names.entrySet()) {\n            // 记录参数名称与参数值之间的映射关系\n            param.put(entry.getValue(), args[entry.getKey()]);\n            // 构造一般参数名称，即 (param1, param2, ...) 形式参数\n            final String genericParamName = GENERIC_NAME_PREFIX + (i + 1);\n            // 以“param + 索引”的形式再记录一次，如果 @Param 指定的参数名称已经是这种形式则不覆盖\n            if (!names.containsValue(genericParamName)) {\n                param.put(genericParamName, args[entry.getKey()]);\n            }\n            i++;\n        }\n        return param;\n    }\n}\n```\n\n做了这么多的铺垫，是时候回来继续分析 MapperMethod 的核心方法 `MapperMethod#execute` 了。该方法的作用在于委托 SqlSession 对象执行方法对应的 SQL 语句，实现如下：\n\n```java\npublic Object execute(SqlSession sqlSession, Object[] args) {\n    Object result;\n    switch (command.getType()) {\n        case INSERT: {\n            // 关联实参与方法参数列表\n            Object param = method.convertArgsToSqlCommandParam(args);\n            // 调用 SqlSession#insert 方法执行插入操作，并对执行结果进行转换\n            result = this.rowCountResult(sqlSession.insert(command.getName(), param));\n            break;\n        }\n        case UPDATE: {\n            // 关联实参与方法参数列表\n            Object param = method.convertArgsToSqlCommandParam(args);\n            // 调用 SqlSession#update 方法执行更新操作，并对执行结果进行转换\n            result = this.rowCountResult(sqlSession.update(command.getName(), param));\n            break;\n        }\n        case DELETE: {\n            // 关联实参与方法参数列表\n            Object param = method.convertArgsToSqlCommandParam(args);\n            // 调用 SqlSession#delete 方法执行删除操作，并对执行结果进行转换\n            result = this.rowCountResult(sqlSession.delete(command.getName(), param));\n            break;\n        }\n        case SELECT:\n            // 返回值是 void 类型，且指定了 ResultHandler 处理结果集\n            if (method.returnsVoid() && method.hasResultHandler()) {\n                this.executeWithResultHandler(sqlSession, args);\n                result = null;\n            }\n            // 返回值为 Collection 或数组\n            else if (method.returnsMany()) {\n                result = this.executeForMany(sqlSession, args);\n            }\n            // 返回值为 Map 类型\n            else if (method.returnsMap()) {\n                result = this.executeForMap(sqlSession, args);\n            }\n            // 返回值为 Cursor 类型\n            else if (method.returnsCursor()) {\n                result = this.executeForCursor(sqlSession, args);\n            }\n            // 处理其它返回类型\n            else {\n                Object param = method.convertArgsToSqlCommandParam(args);\n                result = sqlSession.selectOne(command.getName(), param);\n                if (method.returnsOptional() // Optional 类型\n                    && (result == null || !method.getReturnType().equals(result.getClass()))) {\n                    result = Optional.ofNullable(result);\n                }\n            }\n            break;\n        case FLUSH:\n            // 如果方法注解了 @Flush，则执行 SqlSession#flushStatements 方法提交缓存的批量更新操作\n            result = sqlSession.flushStatements();\n            break;\n        default:\n            throw new BindingException(\"Unknown execution method for: \" + command.getName());\n    }\n    if (result == null && method.getReturnType().isPrimitive() && !method.returnsVoid()) {\n        throw new BindingException(\"Mapper method '\" + command.getName()\n            + \" attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\");\n    }\n    return result;\n}\n```\n\n上述方法会依据具体的 SQL 语句类型分而治之。对于 INSERT、UPDATE，以及 DELETE 类型而言，会先调用 `MethodSignature#convertArgsToSqlCommandParam` 方法关联实参与方法形参，本质上是调用前面介绍的 `ParamNameResolver#getNamedParams` 方法。然后就是调用 SqlSession 对应的方法执行数据库操作，并通过方法 `MapperMethod#rowCountResult` 对结果进行类型转换。关于 SqlSession 相关方法的具体实现留到下一节针对性介绍。对于 SELECT 类型而言，则需要考虑不同的返回类型，分为 void、Collection、数组、Map、Cursor，以及对象几类情况，这里所做的都是对于参数或返回结果的处理，核心逻辑也都位于 SqlSession 中，在这一层面的实现都比较简单，就不再一一展开。对于 FLUSH 类型来说，官方文档的说明如下：\n\n> 如果使用了这个注解，它将调用定义在 Mapper 接口中的 `SqlSession#flushStatements` 方法。\n\n具体的实现也就位于这里。\n\n### SQL 语句执行器\n\nExecutor 接口声明了基本的数据库操作，前面在介绍 SqlSession 时曾描述 SqlSession 是 MyBatis 框架对外提供的 API 接口，其中声明了对数据库的基本操作方法，而这些操作方法基本上都是对 Executor 方法的封装。Executor 接口定义如下：\n\n```java\npublic interface Executor {\n\n    ResultHandler NO_RESULT_HANDLER = null;\n\n    /** 执行数据库更新操作：update、insert、delete */\n    int update(MappedStatement ms, Object parameter) throws SQLException;\n    /** 执行数据库查询操作 */\n    <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey cacheKey, BoundSql boundSql) throws SQLException;\n    <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException;\n    /** 执行数据库查询操作，返回游标对象 */\n    <E> Cursor<E> queryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds) throws SQLException;\n    /** 批量提交 SQL 语句 */\n    List<BatchResult> flushStatements() throws SQLException;\n    /** 提交事务 */\n    void commit(boolean required) throws SQLException;\n    /** 回滚事务 */\n    void rollback(boolean required) throws SQLException;\n    /** 创建缓存 key 对象 */\n    CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql);\n    /** 判断是否缓存 */\n    boolean isCached(MappedStatement ms, CacheKey key);\n    /** 清空一级缓存 */\n    void clearLocalCache();\n    /** 延迟加载一级缓存中的数据 */\n    void deferLoad(MappedStatement ms, MetaObject resultObject, String property, CacheKey key, Class<?> targetType);\n    /** 获取事务对象 */\n    Transaction getTransaction();\n    /** 关闭当前 Executor */\n    void close(boolean forceRollback);\n    /** 是否已经关闭 */\n    boolean isClosed();\n    /** 设置装饰的 Executor 对象 */\n    void setExecutorWrapper(Executor executor);\n}\n```\n\n围绕 Executor 接口的类继承关系如下图，其中 CachingExecutor 实现类用于为 Executor 提供二级缓存支持。\n\n![image](/images/2017/mybatis-executor.png)\n\nBaseExecutor 抽象类实现了 Executor 接口中声明的所有方法，并抽象了 4 个模板方法交由子类实现，这 4 个方法分别是：doUpdate、doFlushStatements、doQuery，以及 doQueryCursor。SimpleExecutor 派生自 BaseExecutor 抽象类，并为这 4 个模板方法提供了最简单的实现。ReuseExecutor 如其名，提供了重用的特性，提供对 Statement 对象的重用，以减少 SQL 预编译，以及创建和销毁 Statement 对象的开销。BatchExecutor 实现类则提供了对 SQL 语句批量执行的特性，也是针对提升性能的一种优化实现。\n\n#### 缓存结构设计\n\n考虑到 Executor 在执行数据库操作时与缓存操作存在密切联系，所以在具体介绍 Executor 的实现之前我们先来了解一下 MyBatis 的缓存机制。\n\n在谈论数据库架构设计时往往需要引入缓存的概念，数据库是相对脆弱且耗时的，所以需要尽量避免请求落库。在实际项目架构设计中，我们一般会引入 Redis、Memcached 这一类的组件对数据进行缓存，MyBatis 作为一个强大的 ORM 框架，也为缓存提供了内建的实现。前面我们在分析配置文件加载与解析时曾介绍过 MyBatis 缓存组件的具体实现，MyBatis 在数据存储上采用 HashMap 作为基本存储结构，并提供了多种装饰器从多个方面为缓存增加相应的特性。\n\n本小节我们关注的是 MyBatis 在缓存结构方面的设计，MyBatis 缓存从结构上可以分为 __一级缓存__ 和 __二级缓存__ ，一级缓存相对于二级缓存在粒度上更细，生命周期也更短。\n\n![image](/images/2017/mybatis-cache.png)\n\n上图描绘了 MyBatis 缓存的结构设计，当我们发起一次数据库查询时，如果启用了二级缓存的话，MyBatis 首先会从二级缓存中检索查询结果，如果缓存不命中则会继续检索一级缓存，只有在这两层缓存都不命中的情况下才会查询数据库，最后会以数据库返回的结果更新一级缓存和二级缓存。\n\nMyBatis 的 __一级缓存是会话级别的缓存（生命周期与本次会话相同）__ ，当我们开启一次数据库会话时，框架默认会为本次会话绑定一个一级缓存对象。此类缓存主要应对在一个会话范围内的冗余查询操作，比如使用同一个 SqlSession 对象同时连续执行多次相同的查询语句。这种情况下每次查询都落库是没有必要的，因为短时间内数据库变化的可能性会很小，但是每次都落库却是一笔不必要的开销。一级缓存默认是开启的，且无需进行配置，即一级缓存对开发者是透明的，如果确实希望干预一级缓存的内在运行，可以借助于插件来实现。\n\n对于二级缓存而言，默认也是开启的，MyBatis 提供了相应的治理选项，具体可以参考官方文档。 __二级缓存是应用级别的缓存__ ，随着服务的启动而存在，并随着服务的关闭消亡。前面我们在分析 `<cache/>` 和 `<cache-ref/>` 标签时介绍了一个二级缓存会与一个具体的 namespace 绑定，并且支持引用一个已定义 namespace 缓存，即多个 namespace 可以共享同一个缓存。\n\n本小节从整体结构上对 MyBatis 的缓存实现机制进行说明，目的在于对 MyBatis 的缓存有一个整体感知，关于一级缓存和二级缓存的具体实现，留到下面介绍分析 Executor 接口具体实现时穿插说明。\n\n#### Statement 处理器\n\nStatementHandler 接口及其实现类是 Executor 实现的基础，可以将其看作是 MyBatis 与数据库操作之间的纽带，实现了对 `java.sql.Statement` 对象的获取，以及 SQL 语句参数绑定与执行的逻辑。StatementHandler 接口及其实现类的类继承关系如下图所示：\n\n![image](/images/2017/mybatis-statementhandler.png)\n\n其中 BaseStatementHandler 中实现了一些公共的逻辑；SimpleStatementHandler、PreparedStatementHandler，以及 CallableStatementHandler 实现类分别对应 Statement、PreparedStatement 和 CallableStatement 的相关实现；RoutingStatementHandler 并没有添加新的实现，而是对前面三种 StatementHandler 实现类的封装，它会在构造方法中依据当前传递的 Statement 类型创建对应的 StatementHandler 实现类对象。\n\nStatementHandler 接口定义如下：\n\n```java\npublic interface StatementHandler {\n\n    /** 获取对应的 {@link Statement } 对象 */\n    Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException;\n    /** 绑定 Statement 执行 SQL 时需要的实参 */\n    void parameterize(Statement statement) throws SQLException;\n    /** 批量执行 SQL 语句 */\n    void batch(Statement statement) throws SQLException;\n    /** 执行数据库更新操作：insert、update、delete */\n    int update(Statement statement) throws SQLException;\n    /** 执行 select 操作 */\n    <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException;\n    /** 执行 select 操作，返回游标对象 */\n    <E> Cursor<E> queryCursor(Statement statement) throws SQLException;\n    /** 获取对应的 SQL 对象 */\n    BoundSql getBoundSql();\n    /** 获取对应的 {@link ParameterHandler} 对象，用于参数绑定 */\n    ParameterHandler getParameterHandler();\n}\n```\n\n首先来看一下 BaseStatementHandler 实现，该类中主要实现了获取 Statement 对象的逻辑，该类的属性定义如下：\n\n```java\nprotected final Configuration configuration;\nprotected final ObjectFactory objectFactory;\nprotected final TypeHandlerRegistry typeHandlerRegistry;\n/** 处理结果集映射 */\nprotected final ResultSetHandler resultSetHandler;\n/** 用于为 SQL 语句绑定实参 */\nprotected final ParameterHandler parameterHandler;\n/** SQL 语句执行器 */\nprotected final Executor executor;\n/** 对应 SQL 语句标签对象 */\nprotected final MappedStatement mappedStatement;\n/** 封装 LIMIT 参数 */\nprotected final RowBounds rowBounds;\n/** 可执行的 SQL 语句 */\nprotected BoundSql boundSql;\n```\n\nBaseStatementHandler 之于 `StatementHandler#prepare` 方法的实现如下：\n\n```java\npublic Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException {\n    ErrorContext.instance().sql(boundSql.getSql());\n    Statement statement = null;\n    try {\n        // 从数据库连接中获取 Statement 对象，由子类实现\n        statement = this.instantiateStatement(connection);\n        // 设置超时时间\n        this.setStatementTimeout(statement, transactionTimeout);\n        // 设置返回的行数\n        this.setFetchSize(statement);\n        return statement;\n    } catch (SQLException e) {\n        this.closeStatement(statement);\n        throw e;\n    } catch (Exception e) {\n        this.closeStatement(statement);\n        throw new ExecutorException(\"Error preparing statement.  Cause: \" + e, e);\n    }\n}\n```\n\n上述方法首先会调用 `BaseStatementHandler#instantiateStatement` 方法获取一个 Statement 对象，这是一个模板方法交由子类实现；然后对拿到的 Statement 对象设置超时时间和返回的行数属性。\n\nBaseStatementHandler 中定义了 ParameterHandler 类型的属性，主要用于为包含 `?` 占位符的 SQL 语句绑定实参。ParameterHandler 接口定义如下：\n\n```java\npublic interface ParameterHandler {\n\n    /** 获取输出类型参数 */\n    Object getParameterObject();\n\n    /** 为 SQL 语句绑定实参 */\n    void setParameters(PreparedStatement ps) throws SQLException;\n\n}\n```\n\n其中，方法 `ParameterHandler#getParameterObject` 与存储过程相关，下面主要分析一下 `ParameterHandler#setParameters` 方法的实现。该方法用来为 SQL 语句绑定实参，具体操作等同于我们在直接使用 PreparedStatement 对象时注入相应类型的参数填充 SQL 语句。DefaultParameterHandler 是目前该接口的唯一实现，其 `DefaultParameterHandler#setParameters` 方法实现如下：\n\n```java\npublic void setParameters(PreparedStatement ps) {\n    ErrorContext.instance().activity(\"setting parameters\").object(mappedStatement.getParameterMap().getId());\n    // 获取 BoundSql 中记录的参数映射关系列表\n    List<ParameterMapping> parameterMappings = boundSql.getParameterMappings();\n    if (parameterMappings != null) {\n        // 遍历为 SQL 语句绑定对应的参数值\n        for (int i = 0; i < parameterMappings.size(); i++) {\n            ParameterMapping parameterMapping = parameterMappings.get(i);\n            // 忽略存储过程中的输出参数\n            if (parameterMapping.getMode() != ParameterMode.OUT) {\n                Object value; // 用于记录对应的参数值\n                // 获取参数名称\n                String propertyName = parameterMapping.getProperty();\n                // 获取对应的参数值\n                if (boundSql.hasAdditionalParameter(propertyName)) { // issue #448 ask first for additional params\n                    value = boundSql.getAdditionalParameter(propertyName);\n                }\n                // 用户未传递实参\n                else if (parameterObject == null) {\n                    value = null;\n                }\n                // 实参类型存在对应的类型处理器，即已经是最终的参数值\n                else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) {\n                    value = parameterObject;\n                }\n                // 获取实参对象中对应的参数值\n                else {\n                    MetaObject metaObject = configuration.newMetaObject(parameterObject);\n                    value = metaObject.getValue(propertyName);\n                }\n                TypeHandler typeHandler = parameterMapping.getTypeHandler();\n                JdbcType jdbcType = parameterMapping.getJdbcType();\n                if (value == null && jdbcType == null) {\n                    jdbcType = configuration.getJdbcTypeForNull();\n                }\n                try {\n                    // 为 SQL 语句绑定对应的实参到 PreparedStatement 对象中\n                    typeHandler.setParameter(ps, i + 1, value, jdbcType);\n                } catch (TypeException | SQLException e) {\n                    throw new TypeException(\"Could not set parameters for mapping: \" + parameterMapping + \". Cause: \" + e, e);\n                }\n            }\n        }\n    }\n}\n```\n\n上述实现整体上就是获取 BoundSql 对象记录的参数名称与 SQL 语句中参数的映射关系，然后获取参数名称对应的用户传递的实参设置到 PreparedStatement 对象中。如果使用过原生 JDBC 操作过数据库，对往 PreparedStatement 中填充实参的过程应该不难理解。\n\n关于其余几个 StatementHandler 实现类的都比较简单，就不再展开。\n\n#### 结果集映射\n\n结果集映射是 MyBatis 提供的一个强大且易用的特性，标签 `<resultMap/>` 用于配置数据库返回的结果集 ResultSet 与实体类属性之间的映射关系。前面我们分析了该标签的解析过程，本小节一起来探究一下 MyBatis 是如何基于这些配置执行结果集映射操作。\n\nSQL 语句执行器 Executor 在调用具体的 StatementHandler 执行数据库查询操作时会针对数据库返回的结果集调用 ResultSetHandler 中相应方法执行结果集到实体类对象的映射处理。例如下面的代码块是 PreparedStatementHandler 在执行 `PreparedStatementHandler#query` 时的具体逻辑：\n\n```java\npublic <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {\n    PreparedStatement ps = (PreparedStatement) statement;\n    // 执行数据库操作\n    ps.execute();\n    // 调用 ResultSetHandler#handleResultSets 执行结果集映射\n    return resultSetHandler.handleResultSets(ps);\n}\n```\n\nResultSetHandler 接口定义了结果集映射所需要的方法，具体如下：\n\n```java\npublic interface ResultSetHandler {\n\n    /** 处理结果集，返回对应的结果对象集合 */\n    <E> List<E> handleResultSets(Statement stmt) throws SQLException;\n\n    /** 处理结果集，返回对应的游标对象 */\n    <E> Cursor<E> handleCursorResultSets(Statement stmt) throws SQLException;\n\n    /** 处理存储过程中的输出类型参数 */\n    void handleOutputParameters(CallableStatement cs) throws SQLException;\n\n}\n```\n\nDefaultResultSetHandler 是目前 ResultSetHandler 接口的唯一实现。MyBatis 为结果集映射提供了灵活的配置，灵活的背后是强（复）大（杂）的映射解析过程，尤其是对于嵌套映射配置的情况。本小节力图对整个映射过程做一个比较详细的介绍，不过还是建议读者自己亲自 debug 跟踪一下整个执行过程。接下来我们围绕 `ResultSetHandler#handleResultSets` 方法对结果集映射处理过程进行分析，该方法实现如下：\n\n```java\npublic List<Object> handleResultSets(Statement stmt) throws SQLException {\n    ErrorContext.instance().activity(\"handling results\").object(mappedStatement.getId());\n\n    /* 1. 处理普通映射情况 */\n\n    // 用于记录结果集映射的结果对象集合\n    final List<Object> multipleResults = new ArrayList<>();\n\n    int resultSetCount = 0;\n    // 获取第一个结果集\n    ResultSetWrapper rsw = this.getFirstResultSet(stmt);\n\n    // 获取之前解析得到的封装结果集映射配置的 ResultMap 对象集合\n    List<ResultMap> resultMaps = mappedStatement.getResultMaps();\n    int resultMapCount = resultMaps.size();\n    // 验证，如果结果集不为 null，则 resultMaps 也不能为空\n    this.validateResultMapsCount(rsw, resultMapCount);\n    // 遍历处理所有的结果集，基于结果集映射规则进行映射，并将结果记录到 multipleResults 集合中\n    while (rsw != null && resultMapCount > resultSetCount) {\n        // 获取一个配置的结果集映射标签 <resultMap/> 配置\n        ResultMap resultMap = resultMaps.get(resultSetCount);\n        // 依据结果集映射配置对结果集对象进行解析，并记录到 multipleResults 集合中\n        this.handleResultSet(rsw, resultMap, multipleResults, null);\n        // 获取下一个待处理的结果集\n        rsw = this.getNextResultSet(stmt);\n        // 清空 nestedResultObjects\n        this.cleanUpAfterHandlingResultSet();\n        resultSetCount++;\n    }\n\n    /*\n     * 2. 处理多结果集的情况\n     *\n     * 常见于存储过程，存在 <select resultSets=\"aaa,bbb\"/> 类似的配置，\n     * 针对过程 1 未执行映射的结果集进行映射\n     */\n\n    String[] resultSets = mappedStatement.getResultSets();\n    if (resultSets != null) {\n        while (rsw != null && resultSetCount < resultSets.length) {\n            // 获取 resultSet 配置名称对应的 ResultMapping 配置\n            ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]);\n            if (parentMapping != null) {\n                // 获取对应的 <resultMap/> 标签配置\n                String nestedResultMapId = parentMapping.getNestedResultMapId();\n                ResultMap resultMap = configuration.getResultMap(nestedResultMapId);\n                // 执行结果集映射\n                this.handleResultSet(rsw, resultMap, null, parentMapping);\n            }\n            // 获取下一个待处理的结果集\n            rsw = this.getNextResultSet(stmt);\n            // 清空 nestedResultObjects\n            this.cleanUpAfterHandlingResultSet();\n            resultSetCount++;\n        }\n    }\n\n    // multipleResults.size() == 1 ? (List<Object>) multipleResults.get(0) : multipleResults\n    return this.collapseSingleResultList(multipleResults);\n}\n```\n\n上述方法的执行过程可以分为两部分：普通结果集映射和多结果集映射。其中，多结果集映射一般用于存储过程，这是一个小众化的需求，所以大部分时候上述方法仅执行第一部分的逻辑。这一部分的执行过程如代码注释，其核心在于 `DefaultResultSetHandler#handleResultSet` 方法，该方法在第二部分中也会被调用，后面会针对该方法进行专门说明。\n\n下面就第二部分的触发机制举例说明，能够执行到这里一般都伴随着存储过程，这里以 MySQL 数据库为例创建一个可以返回多结果集的存储过程，其中 t_blog 表和 t_post 表的定义参考官方文档示例：\n\n```sql\nCREATE PROCEDURE usp_demo(IN ID INT)\n    BEGIN\n        SELECT * FROM t_blog WHERE id = ID;\n        SELECT * FROM t_post WHERE id = ID;\n    END;\n```\n\n对应的映射配置如下：\n\n```xml\n<resultMap id=\"usp_demo_result_map\" type=\"org.zhenchao.mybatis.entity.Blog\">\n    <constructor>\n        <idArg column=\"id\" javaType=\"int\"/>\n    </constructor>\n    <result property=\"title\" column=\"title\"/>\n    <collection property=\"posts\" ofType=\"org.zhenchao.mybatis.entity.Post\" resultSet=\"posts\">\n        <id property=\"id\" column=\"id\"/>\n        <result property=\"subject\" column=\"subject\"/>\n    </collection>\n</resultMap>\n\n<select id=\"uspDemo\" resultSets=\"blogs,posts\" resultMap=\"usp_demo_result_map\" statementType=\"CALLABLE\">\n    {CALL usp_demo(#{id, jdbcType=INTEGER, mode=IN})}\n</select>\n```\n\n上述配置中，我们基于 resultSets 属性分别为对应的结果集命名，在执行该存储过程时会先映射 t_blog 数据表对应的结果集，映射的过程中遇到名为 posts 的结果集时，MyBatis 不会转去解析该结果集，而是会将该结果集记录到 `DefaultResultSetHandler#nextResultMaps` 属性中，等运行到第二部分时再对这些未解析的结果集统一进行映射处理。\n\n上述过程中处理结果集映射的核心逻辑均位于 `DefaultResultSetHandler#handleResultSet` 方法中。该方法执行的主要逻辑在于判断当前是否指定了结果集处理器（即前面介绍过的 ResultHandler），如果没有指定则会创建一个默认的结果集处理器（默认采用 DefaultResultHandler 实现），然后调用 `DefaultResultSetHandler#handleRowValues` 方法执行映射逻辑。方法 `DefaultResultSetHandler#handleResultSet` 的实现如下：\n\n```java\nprivate void handleResultSet(ResultSetWrapper rsw,\n                             ResultMap resultMap,\n                             List<Object> multipleResults,\n                             ResultMapping parentMapping) throws SQLException {\n    try {\n        if (parentMapping != null) {\n            // 处理多结果集嵌套映射的情况\n            this.handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping);\n        } else {\n            // 未指定 ResultHandler，构造默认的处理器\n            if (resultHandler == null) {\n                DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory);\n                // 对结果集进行映射，并将映射结果记录到 DefaultResultHandler 对象中\n                this.handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null);\n                // 获取保存在 DefaultResultHandler 对象中映射结果，记录到 multipleResults 中\n                multipleResults.add(defaultResultHandler.getResultList());\n            }\n            // 用户指定了 ResultHandler，使用该处理器进行处理\n            else {\n                this.handleRowValues(rsw, resultMap, resultHandler, rowBounds, null);\n            }\n        }\n    } finally {\n        // issue #228 (close resultsets)\n        this.closeResultSet(rsw.getResultSet());\n    }\n}\n```\n\n方法 `DefaultResultSetHandler#handleRowValues` 会判断当前映射配置中是否存在嵌套映射的情况，如果存在嵌套映射则执行方法 `DefaultResultSetHandler#handleRowValuesForNestedResultMap` 方法处理嵌套结果集映射，否则执行 `DefaultResultSetHandler#handleRowValuesForSimpleResultMap` 方法处理简单的结果集映射。下面以简单结果集映射的过程进行分析，对于嵌套结果集映射的过程还是强烈建议大家去 debug 跟踪理解，单凭静态文字很难说清楚。\n\n方法 `DefaultResultSetHandler#handleRowValuesForSimpleResultMap` 实现了对简单（相对于嵌套而言）结果集映射的处理逻辑。首先会基于 RowBounds 设置定位具体的处理行，MyBatis 对于 LIMIT 分页的处理是逻辑分页，而不是物理分页，即将符合条件的记录全部载入内存，然后在内存中进行截取，如果希望执行物理分页，可以自己编码插件，或者使用第三方插件，然后会遍历结果集中目标记录行对其逐一映射。\n\n方法 `DefaultResultSetHandler#handleRowValuesForSimpleResultMap` 实现如下：\n\n```java\nprivate void handleRowValuesForSimpleResultMap(ResultSetWrapper rsw,\n                                               ResultMap resultMap,\n                                               ResultHandler<?> resultHandler,\n                                               RowBounds rowBounds,\n                                               ResultMapping parentMapping) throws SQLException {\n    DefaultResultContext<Object> resultContext = new DefaultResultContext<>();\n    ResultSet resultSet = rsw.getResultSet();\n    // 针对设置了 RowBounds 定位指定的记录行\n    this.skipRows(resultSet, rowBounds);\n    // 检测是否可以继续对后续的记录行进行映射操作，可以的话就一直循环\n    while (this.shouldProcessMoreRows(resultContext, rowBounds) && !resultSet.isClosed() && resultSet.next()) {\n        // 确定具体使用的映射配置，如果配置了 <discriminator/> 标签则获取最终引用的 ResultMap，否则使用当前的 ResultMap 对象\n        ResultMap discriminatedResultMap = this.resolveDiscriminatedResultMap(resultSet, resultMap, null);\n        // 基于映射配置对当前记录行进行解析\n        Object rowValue = this.getRowValue(rsw, discriminatedResultMap, null);\n        // 保存映射得到的结果对象\n        this.storeObject(resultHandler, resultContext, rowValue, parentMapping, resultSet);\n    }\n}\n```\n\n针对记录行的映射处理，方法首先会获取记录行对应的真正 ResultMap 映射配置对象，因为可能存在配置了 `<discriminator/>` 标签执行条件映射的情况，如果没有配置该标签则会使用当前实参对应的 ResultMap 对象。标签 `<discriminator/>` 的处理过程位于 `DefaultResultSetHandler#resolveDiscriminatedResultMap` 方法中，对照配置应该比较容易理解。获取到 ResultMap 映射配置对象之后，下一步就可以调用 `DefaultResultSetHandler#getRowValue` 方法对当前记录行执行映射处理，该方法实现如下：\n\n```java\nprivate Object getRowValue(ResultSetWrapper rsw, ResultMap resultMap, String columnPrefix) throws SQLException {\n    final ResultLoaderMap lazyLoader = new ResultLoaderMap();\n    // 创建记录行映射结果对象\n    Object rowValue = this.createResultObject(rsw, resultMap, lazyLoader, columnPrefix);\n    // 如果结果对象不为 null，且没有对应的类型处理器\n    if (rowValue != null && !this.hasTypeHandlerForResultObject(rsw, resultMap.getType())) {\n        // 创建结果对象的 MetaObject 对象\n        final MetaObject metaObject = configuration.newMetaObject(rowValue);\n        // 标记是否成功映射任何一个属性\n        boolean foundValues = this.useConstructorMappings;\n        // 是否需要自动映射\n        if (this.shouldApplyAutomaticMappings(resultMap, false)) {\n            // 自动映射未在 <resultMap/> 标签中指定的列\n            foundValues = this.applyAutomaticMappings(rsw, resultMap, metaObject, columnPrefix) || foundValues;\n        }\n        // 映射在 <resultMap/> 标签中指定的列\n        foundValues = this.applyPropertyMappings(rsw, resultMap, metaObject, lazyLoader, columnPrefix) || foundValues;\n        foundValues = lazyLoader.size() > 0 || foundValues;\n        rowValue = foundValues || configuration.isReturnInstanceForEmptyRow() ? rowValue : null;\n    }\n    return rowValue;\n}\n```\n\n方法首先会调用 `DefaultResultSetHandler#createResultObject` 方法创建实体结果对象，然后为该对象执行属性映射注入。对于未配置映射关系的属性会基于配置决定是否执行自动映射，对于明确指定映射关系的属性，则调用 `DefaultResultSetHandler#applyPropertyMappings` 方法执行映射处理，该方法的具体实现如下：\n\n```java\nprivate boolean applyPropertyMappings(ResultSetWrapper rsw,\n                                      ResultMap resultMap,\n                                      MetaObject metaObject,\n                                      ResultLoaderMap lazyLoader,\n                                      String columnPrefix) throws SQLException {\n    // 获取所有指明了映射关系的列名集合\n    final List<String> mappedColumnNames = rsw.getMappedColumnNames(resultMap, columnPrefix);\n    boolean foundValues = false;\n    // 获取当前 ResultMap 包含的所有映射关系配置对象 ResultMapping 列表\n    final List<ResultMapping> propertyMappings = resultMap.getPropertyResultMappings();\n    // 遍历处理映射关系 ResultMapping 列表，执行映射过程\n    for (ResultMapping propertyMapping : propertyMappings) {\n        // 处理列前缀\n        String column = this.prependPrefix(propertyMapping.getColumn(), columnPrefix);\n        // 忽略嵌套的 ResultMap 映射\n        if (propertyMapping.getNestedResultMapId() != null) {\n            // the user added a column attribute to a nested result map, ignore it\n            column = null;\n        }\n        // 嵌套查询 | 配置了映射关系 | 多结果集\n        if (propertyMapping.isCompositeResult()\n            || (column != null && mappedColumnNames.contains(column.toUpperCase(Locale.ENGLISH)))\n            || propertyMapping.getResultSet() != null) { // 存在多结果集\n            // 执行映射，返回属性值\n            Object value = this.getPropertyMappingValue(\n                rsw.getResultSet(), metaObject, propertyMapping, lazyLoader, columnPrefix);\n            // issue #541 make property optional\n            final String property = propertyMapping.getProperty();\n            if (property == null) {\n                continue;\n            }\n            // 延迟加载的情况\n            else if (value == DEFERRED) {\n                foundValues = true;\n                continue;\n            }\n            if (value != null) {\n                foundValues = true;\n            }\n            // 设置属性值\n            if (value != null\n                || (configuration.isCallSettersOnNulls() && !metaObject.getSetterType(property).isPrimitive())) {\n                // gcode issue #377, call setter on nulls (value is not 'found')\n                metaObject.setValue(property, value);\n            }\n        }\n    }\n    return foundValues;\n}\n```\n\n方法首先会获取当前结果集对应的映射关系配置和列名集合，然后遍历处理映射配置。针对嵌套查询、多结果集映射，以及普通映射的情况分而治之，这一过程位于 `DefaultResultSetHandler#getPropertyMappingValue` 方法中（实现如下）。针对嵌套查询的情况我们后面专门进行分析；对于多结果集的情况会将对应的结果集配置对象记录到 `DefaultResultSetHandler#nextResultMaps` 属性中，稍后会专门处理（即前面的第二部分代码）；针对普通的映射则会基于 TypeHandler 获取属性对应的 java 类型值，也就是我们期望的值。\n\n```java\nprivate Object getPropertyMappingValue(ResultSet rs,\n                                       MetaObject metaResultObject,\n                                       ResultMapping propertyMapping,\n                                       ResultLoaderMap lazyLoader,\n                                       String columnPrefix) throws SQLException {\n    // 嵌套查询\n    if (propertyMapping.getNestedQueryId() != null) {\n        return this.getNestedQueryMappingValue(rs, metaResultObject, propertyMapping, lazyLoader, columnPrefix);\n    }\n    // 多结果集情况，记录对应的 resultSet，后续处理\n    else if (propertyMapping.getResultSet() != null) {\n        this.addPendingChildRelation(rs, metaResultObject, propertyMapping);\n        return DEFERRED;\n    }\n    // 基于 TypeHandler 获取属性值\n    else {\n        final TypeHandler<?> typeHandler = propertyMapping.getTypeHandler();\n        final String column = this.prependPrefix(propertyMapping.getColumn(), columnPrefix);\n        return typeHandler.getResult(rs, column);\n    }\n}\n```\n\n最后会调用 `DefaultResultSetHandler#storeObject` 方法将实体结果对象记录到 `DefaultResultHandler#list` 属性中，并在 `DefaultResultSetHandler#handleResultSet` 方法中调用 `DefaultResultHandler#getResultList` 方法拿到这些结果对象。\n\n#### 执行器实现\n\n前面已经介绍了 Executor 接口以及相关的实现类继承关系，本小节将对这些执行器实现类逐一展开分析。\n\n##### BaseExecutor\n\nBaseExecutor 是一个抽象类，实现了 Executor 接口中声明的所有方法，并采用模板方法模式抽象出 4 个模板方法交由子类实现。需要强调的一点是，BaseExecutor 抽象类引入了一级缓存支持，在相应方法实现中增加了对一级缓存的操作，因此该抽象类的所有实现类都具备一级缓存的特性。BaseExecutor 抽象类的属性定义如下：\n\n```java\n/** 事务对象 */\nprotected Transaction transaction;\n/** 封装的 SQL 语句执行器 */\nprotected Executor wrapper;\n/** 延迟加载队列 */\nprotected ConcurrentLinkedQueue<DeferredLoad> deferredLoads;\n/** 缓存结果对象（一级缓存） */\nprotected PerpetualCache localCache;\n/** 缓存存储过程输出类型参数（一级缓存） */\nprotected PerpetualCache localOutputParameterCache;\n/** 全局唯一的配置对象 */\nprotected Configuration configuration;\n/** 记录嵌套查询的层数 */\nprotected int queryStack;\n/** 标记当前 Executor 是否已经关闭 */\nprivate boolean closed;\n```\n\n下面针对一些比较复杂的方法实现展开说明，首先来看一下 `BaseExecutor#update` 方法实现（如下）。需要注意的是这里的 update 并不等同于 SQL 语句中的 UPDATE 操作，对于 Executor 而言数据库操作只包含 query 和 update 两大类，这里的 query 可以理解为 SQL 语句的 SELECT 操作，而 update 则对应着 SQL 语句中的 INSERT、UPDATE、DELECT 三类操作。\n\n```java\npublic int update(MappedStatement ms, Object parameter) throws SQLException {\n    ErrorContext.instance().resource(ms.getResource()).activity(\"executing an update\").object(ms.getId());\n    if (closed) {\n        throw new ExecutorException(\"Executor was closed.\");\n    }\n    // 先清空一级缓存\n    this.clearLocalCache();\n    // 执行更新操作，交由子类实现\n    return this.doUpdate(ms, parameter);\n}\n```\n\n上述方法首先会判定当前 Executor 是否已被关闭，对于没有关闭的 Executor 会首先清空一级缓存，然后调用 `BaseExecutor#doUpdate` 模板方法，该方法由子类实现。\n\n再来看一下 `BaseExecutor#query` 方法，该方法用于执行数据库查询操作。因为引入了一级缓存，所以这里的查询不是简单的直接查询数据库，而是会先查询一级缓存，只有在缓存不命中的情况下才会查询数据库，并利用数据库返回的结果对象更新一级缓存。该方法的实现如下：\n\n```java\npublic <E> List<E> query(MappedStatement ms,\n                         Object parameter,\n                         RowBounds rowBounds,\n                         ResultHandler resultHandler) throws SQLException {\n    // 获取执行的 SQL 语句\n    BoundSql boundSql = ms.getBoundSql(parameter);\n    // 创建缓存 key\n    CacheKey key = this.createCacheKey(ms, parameter, rowBounds, boundSql);\n    // 调用重载的 query 方法执行查询操作\n    return this.query(ms, parameter, rowBounds, resultHandler, key, boundSql);\n}\n\npublic <E> List<E> query(MappedStatement ms,\n                         Object parameter,\n                         RowBounds rowBounds,\n                         ResultHandler resultHandler,\n                         CacheKey key,\n                         BoundSql boundSql) throws SQLException {\n    ErrorContext.instance().resource(ms.getResource()).activity(\"executing a query\").object(ms.getId());\n    if (closed) {\n        throw new ExecutorException(\"Executor was closed.\");\n    }\n    // 如果是非嵌套查询，且配置 <select flushCache=\"true\"/> 要求执行该语句时清空一级缓存和二级缓存\n    if (queryStack == 0 && ms.isFlushCacheRequired()) {\n        // 清空一级缓存\n        this.clearLocalCache();\n    }\n    List<E> list;\n    try {\n        queryStack++;\n        // 尝试从一级缓存中获取结果\n        list = resultHandler == null ? (List<E>) localCache.getObject(key) : null;\n        // 缓存名命中，针对存储过程特殊处理，获取缓存中保存的输出类型参数记录到实参对象中\n        if (list != null) {\n            this.handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);\n        }\n        // 缓存不命中，查数据库并更新缓存，本质上调用的是 doQuery 方法\n        else {\n            list = this.queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);\n        }\n    } finally {\n        queryStack--;\n    }\n    // 加载缓存中记录的嵌套查询的结果对象\n    if (queryStack == 0) {\n        for (DeferredLoad deferredLoad : deferredLoads) {\n            deferredLoad.load();\n        }\n        // issue #601\n        deferredLoads.clear();\n        if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) {\n            // issue #482\n            this.clearLocalCache();\n        }\n    }\n    return list;\n}\n```\n\n整个 `BaseExecutor#query` 方法的执行过程如上述代码注释。\n\n方法 `BaseExecutor#queryCursor` 与 `BaseExecutor#query` 都是提供数据库查询操作，区别在于前者返回的是一个游标（Cursor）对象，而后者返回的是已经完成结果集映射的结果对象，游标需要等待用户真正操作时才会执行结果集映射的过程。\n\n##### SimpleExecutor\n\nSimpleExecutor 提供了对 Executor 的简单实现，针对每一次数据库操作都会创建一个新的 Statement 对象，并在操作完毕之后进行关闭。SimpleExecutor 针对抽象类 BaseExecutor 中声明的方法实现流程都相同，下面以 `SimpleExecutor#doQuery` 方法为例进行分析，该方法的实现如下：\n\n```java\npublic <E> List<E> doQuery(MappedStatement ms,\n                           Object parameter,\n                           RowBounds rowBounds,\n                           ResultHandler resultHandler,\n                           BoundSql boundSql) throws SQLException {\n    Statement stmt = null;\n    try {\n        Configuration configuration = ms.getConfiguration();\n        // 创建 StatementHandler 对象\n        StatementHandler handler = configuration.newStatementHandler(\n            wrapper, ms, parameter, rowBounds, resultHandler, boundSql);\n        // 创建 Statement 对象并为 SQL 语句绑定实参\n        stmt = this.prepareStatement(handler, ms.getStatementLog());\n        // 执行数据库查询操作，以及结果集映射\n        return handler.query(stmt, resultHandler);\n    } finally {\n        // 关闭 Statement\n        this.closeStatement(stmt);\n    }\n}\n```\n\n方法首先会基于 `Configuration#newStatementHandler` 创建对应的 StatementHandler 对象，这里实际上是采用了前面介绍的 RoutingStatementHandler 实现类依据入参进行创建。然后会调用 `SimpleExecutor#prepareStatement` 方法创建 Statement 对象，并为 SQL 语句绑定实参。接着执行具体的数据库查询操作，对于查询操作此时会执行结果集映射处理。最后关闭 Statement 对象。\n\n方法 `SimpleExecutor#prepareStatement` 实现如下：\n\n```java\nprivate Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException {\n    Statement stmt;\n    // 获取数据库连接\n    Connection connection = this.getConnection(statementLog);\n    // 获取 Statement 对象\n    stmt = handler.prepare(connection, transaction.getTimeout());\n    // 执行参数绑定\n    handler.parameterize(stmt);\n    return stmt;\n}\n```\n\n其中 `StatementHandler#prepare` 方法的运行逻辑前面已经分析过。方法 `StatementHandler#parameterize` 执行了参数绑定的操作，该方法在 SimpleStatementHandler 中为空实现，毕竟对于 Statement 来说不支持设置参数；而对于 PreparedStatementHandler 和 CallableStatementHandler 而言都是调用了 `ParameterHandler#setParameters` 方法，该方法在前面已经专门分析过，不再重复介绍。\n\n- __ReuseExecutor__\n\nReuseExecutor 提供了对 Statement 对象重用的机制，以减少该对象创建和销毁，以及 SQL 预编译所带来的开销。ReuseExecutor 类中定义了一个 `ReuseExecutor#statementMap` 属性（如下），其中 key 为 SQL 语句，value 为对应的 Statement 对象，以此实现对 Statement 对象的复用。\n\n```java\n/** 缓存 Statement 对象，key 为对应的 SQL 语句（带有 ? 占位符） */\nprivate final Map<String, Statement> statementMap = new HashMap<String, Statement>();\n```\n\nReuseExecutor 中的方法实现也基本上沿用了同一套思路，仍然以 `ReuseExecutor#doQuery` 为例进行说明，该方法实现如下：\n\n```java\npublic <E> List<E> doQuery(MappedStatement ms,\n                           Object parameter,\n                           RowBounds rowBounds,\n                           ResultHandler resultHandler,\n                           BoundSql boundSql) throws SQLException {\n    Configuration configuration = ms.getConfiguration();\n    // 创建对应的 StatementHandler 对象\n    StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);\n    // 先尝试从缓存中获取当前 SQL 对应的 Statement 对象，缓存不命中则创建一个新的并缓存\n    Statement stmt = this.prepareStatement(handler, ms.getStatementLog());\n    // 执行数据库查询操作，以及结果集映射\n    return handler.query(stmt, resultHandler);\n}\n```\n\n上述方法与 `SimpleExecutor#doQuery` 的区别在于在获取 Statement 对象时会先尝试从本地缓存中获取，如果缓存不命中则会创建一个新的 Statement 对象，并更新缓存，实现位于 `ReuseExecutor#prepareStatement` 方法中：\n\n```java\nprivate Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException {\n    Statement stmt;\n    BoundSql boundSql = handler.getBoundSql();\n    String sql = boundSql.getSql();\n    // 获取缓存的 Statement 对象\n    if (this.hasStatementFor(sql)) {\n        stmt = this.getStatement(sql);\n        this.applyTransactionTimeout(stmt);\n    }\n    // 缓存不命中，新建一个 Statement 对象并缓存\n    else {\n        Connection connection = this.getConnection(statementLog);\n        stmt = handler.prepare(connection, transaction.getTimeout());\n        this.putStatement(sql, stmt);\n    }\n    // 绑定实参\n    handler.parameterize(stmt);\n    return stmt;\n}\n```\n\n##### BatchExecutor\n\nBatchExecutor 用于批量执行 SQL 语句。通常应用程序都是单行的执行 SQL 语句，但是某些场景下单行执行数据库操作是比较耗时的，比如需要远程执行数据库操作。因此，JDBC 针对 INSERT、UPDATE，以及 DELETE 操作提供了批量执行的支持。\n\nBatchExecutor 是批量 SQL 语句执行器，其属性定义如下：\n\n```java\n/** 缓存多个 {@link Statement} 对象，每个对象都对应多条 SQL 语句 */\nprivate final List<Statement> statementList = new ArrayList<>();\n/** 记录批处理的结果，每个 {@link BatchResult} 对应一个 {@link Statement} 对象 */\nprivate final List<BatchResult> batchResultList = new ArrayList<>();\n/** 当前执行的 SQL 语句 */\nprivate String currentSql;\n/** 当前操作的 {@link MappedStatement} 对象 */\nprivate MappedStatement currentStatement;\n```\n\n下面探究一下 BatchExecutor 的批处理执行过程。首先来看一下 `BatchExecutor#doUpdate` 方法实现，该方法用于添加批处理 SQL 语句：\n\n```java\npublic int doUpdate(MappedStatement ms, Object parameterObject) throws SQLException {\n    final Configuration configuration = ms.getConfiguration();\n    // 基于参数创建对应的 StatementHandler 对象\n    final StatementHandler handler = configuration.newStatementHandler(\n        this, ms, parameterObject, RowBounds.DEFAULT, null, null);\n    final BoundSql boundSql = handler.getBoundSql();\n    final String sql = boundSql.getSql();\n    final Statement stmt;\n    // 当前执行的 SQL 语句与前一次执行的 SQL 语句（不包含实参）相同，且对应的 MappedStatement 对象也相同\n    if (sql.equals(currentSql) && ms.equals(currentStatement)) {\n        // 获取缓存的最后一个 Statement 对象，即前一次使用的 Statement 对象\n        int last = statementList.size() - 1;\n        stmt = statementList.get(last);\n        this.applyTransactionTimeout(stmt);\n        // 绑定实参\n        handler.parameterize(stmt);//fix Issues 322\n        BatchResult batchResult = batchResultList.get(last);\n        batchResult.addParameterObject(parameterObject);\n    }\n    // 当前执行的 SQL 语句与前一次执行的 SQL 语句不同\n    else {\n        Connection connection = this.getConnection(ms.getStatementLog());\n        // 获取一个新的 Statement 对象\n        stmt = handler.prepare(connection, transaction.getTimeout());\n        // 绑定实参\n        handler.parameterize(stmt);    //fix Issues 322\n        // 记录本次执行的 SQL 语句和 MappedStatement 对象\n        currentSql = sql;\n        currentStatement = ms;\n        // 缓存新建的 Statement 对象\n        statementList.add(stmt);\n        batchResultList.add(new BatchResult(ms, sql, parameterObject));\n    }\n    // 基于 Statement#addBatch 方法添加批量 SQL 语句\n    handler.batch(stmt);\n    return BATCH_UPDATE_RETURN_VALUE;\n}\n```\n\n上述方法中会判断当前执行的 SQL 模式（包含 `?` 占位符的 SQL 语句）是否与前一次执行的相同，如果相同就会获取上次执行的 Statement 对象，并为之绑定实参；否则就会创建一个新的 Statement 对象，并记录本次执行的 SQL 模式，最后基于底层的数据库批处理方法 `Statement#addBatch` 添加批量 SQL 语句。由上述方法我们可以知道，对于连续同模式的批处理 SQL 操作会共享同一个 Statement 对象。\n\n那么这些添加的批量 SQL 又是如何被执行的呢？这个过程位于  `BatchExecutor#doFlushStatements` 方法中，方法如下：\n\n```java\npublic List<BatchResult> doFlushStatements(boolean isRollback) throws SQLException {\n    try {\n        // 用于存储批量处理结果\n        List<BatchResult> results = new ArrayList<>();\n        if (isRollback) {\n            return Collections.emptyList();\n        }\n        // 遍历处理缓存的 Statement 集合\n        for (int i = 0, n = statementList.size(); i < n; i++) {\n            Statement stmt = statementList.get(i);\n            this.applyTransactionTimeout(stmt);\n            BatchResult batchResult = batchResultList.get(i);\n            try {\n                // 批量执行当前 Statement 蕴含的多条 SQL 语句，并记录每条 SQL 语句影响的行数\n                batchResult.setUpdateCounts(stmt.executeBatch());\n                MappedStatement ms = batchResult.getMappedStatement();\n                List<Object> parameterObjects = batchResult.getParameterObjects();\n                KeyGenerator keyGenerator = ms.getKeyGenerator();\n                if (Jdbc3KeyGenerator.class.equals(keyGenerator.getClass())) {\n                    // 获取数据库生成的主键，并记录到 parameterObjects 中\n                    Jdbc3KeyGenerator jdbc3KeyGenerator = (Jdbc3KeyGenerator) keyGenerator;\n                    jdbc3KeyGenerator.processBatch(ms, stmt, parameterObjects);\n                } else if (!NoKeyGenerator.class.equals(keyGenerator.getClass())) { //issue #141\n                    for (Object parameter : parameterObjects) {\n                        keyGenerator.processAfter(this, ms, stmt, parameter);\n                    }\n                }\n                // Close statement to close cursor #1109\n                this.closeStatement(stmt);\n            } catch (BatchUpdateException e) {\n                // ... 省略异常处理\n            }\n            // 记录封装当前 Statement 对象执行结果的 batchResult 到集合中\n            results.add(batchResult);\n        }\n        return results;\n    } finally {\n        // 关闭所有的 Statement 对象\n        for (Statement stmt : statementList) {\n            this.closeStatement(stmt);\n        }\n        currentSql = null;\n        statementList.clear();\n        batchResultList.clear();\n    }\n}\n```\n\n方法会遍历我们在 `BatchExecutor#doUpdate` 中构造的 Statement 集合，分别执行集合中蕴含的 Statement 对象，并将执行的结果记录到 BatchResult 对象中（说明：在 `BatchExecutor#doUpdate` 方法中已经为每个 Statement 对象构造好了一个空的 BatchResult 对象，记录在 `BatchExecutor#batchResultList` 集合中），最后将 BatchResult 对象封装到集合中返回。因为都是数据库更新一类的操作，所以这里没有复杂的结果集映射，只需要记录每一条 SQL 语句执行所影响的行数即可。\n\n##### CachingExecutor\n\n由前面 Executor 的继承关系我们可以看到，CachingExecutor 相对于其它 Executor 实现来说似乎有其特别之处。CachingExecutor 直接实现了 Executor 接口，实际上它是一个 Executor 装饰器， __用于为 Executor 提供二级缓存支持__ 。该接口的属性定义如下：\n\n```java\n/** 装饰的 {@link Executor} 对象 */\nprivate final Executor delegate;\n/** 用于管理当前使用的二级缓存对象 */\nprivate final TransactionalCacheManager tcm = new TransactionalCacheManager();\n```\n\n其中第一个属性就是 CachingExecutor 具体修饰的 Executor 对象。我们来看一下第二个属性，TransactionalCacheManager 用来管理当前 CachingExecutor 对应的二级缓存对象，它的方法实现都比较简单，其中相对让人疑惑的是它的唯一一个属性：\n\n```java\n/** key 为对应的 {@link CachingExecutor} 使用的二级缓存对象，value 为采用 {@link TransactionalCache} 装饰的二级缓存对象 */\nprivate final Map<Cache, TransactionalCache> transactionalCaches = new HashMap<>();\n```\n\n该属性的 key 就是当前对应的二级缓存，而 value 则是对于该二级缓存对象采用 TransactionalCache 装饰后的对象。所以 key 和 value 本质上都映射到同一个缓存对象，只是 value 采用了 TransactionalCache 进行增强。TransactionalCache 也是一个缓存装饰器，在前面介绍缓存装饰器实现时特意留着没有说明，这里一起来分析一下。该装饰器的属性定义如下：\n\n```java\n/** 被装饰的 {@link Cache} 对象（二级缓存） */\nprivate final Cache delegate;\n/** 是否在提交事务时清空缓存 */\nprivate boolean clearOnCommit;\n/** 用于缓存数据，当提交事务时会将其中的数据写入二级缓存 */\nprivate final Map<Object, Object> entriesToAddOnCommit;\n/** 缓存未命中的 key */\nprivate final Set<Object> entriesMissedInCache;\n```\n\n对应的读缓存和写缓存操作，以及事务提交方法实现比较简单，读者可以自行阅读源码。\n\n继续回来看 CachingExecutor 的实现，所有实现方法中只有 `CachingExecutor#query` 方法稍微复杂一些，该方法的实现如下：\n\n```java\npublic <E> List<E> query(MappedStatement ms,\n                         Object parameterObject,\n                         RowBounds rowBounds,\n                         ResultHandler resultHandler) throws SQLException {\n    // 获取对应的 BoundSql 对象，并创建对应的 CacheKey\n    BoundSql boundSql = ms.getBoundSql(parameterObject);\n    CacheKey key = this.createCacheKey(ms, parameterObject, rowBounds, boundSql);\n    // 调用重载的 query 方法\n    return this.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);\n}\n\npublic <E> List<E> query(MappedStatement ms,\n                         Object parameterObject,\n                         RowBounds rowBounds,\n                         ResultHandler resultHandler,\n                         CacheKey key,\n                         BoundSql boundSql) throws SQLException {\n    // 获取当前命名空间对应的二级缓存对象\n    Cache cache = ms.getCache();\n    // 判断是否启用了二级缓存\n    if (cache != null) {\n        // 依据配置决定是否清空二级缓存\n        this.flushCacheIfRequired(ms);\n        if (ms.isUseCache() && resultHandler == null) {\n            // 确保不是存储过程输出类型的参数\n            this.ensureNoOutParams(ms, boundSql);\n            // 查询二级缓存\n            @SuppressWarnings(\"unchecked\")\n            List<E> list = (List<E>) tcm.getObject(cache, key);\n            if (list == null) {\n                // 二级缓存不命中，执行一级缓存查询，再不命中就查询数据库\n                list = delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);\n                // 缓存到 TransactionalCache#entriesToAddOnCommit 中\n                tcm.putObject(cache, key, list); // issue #578 and #116\n            }\n            return list;\n        }\n    }\n    // 未启用二级缓存，则查询一级缓存，再不命中就查询数据库\n    return delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);\n}\n```\n\n正如我们一开始对于 MyBatis 缓存结构设计描绘的那样，上述方法首先在二级缓存中进行检索，如果二级缓存不命中则会执行被装饰的 Executor 对象的 `Executor#query` 方法。由前面的分析我们知道，Executor 的实现都自带一级缓存特性，所以接下去会查询一级缓存。只有在一级缓存也不命中的情况下，请求才会落库，并由数据库返回的结果对象更新一级缓存和二级缓存。\n\n那么这里使用的二级缓存对象是在哪里创建的呢？实际上前面我们就定义说二级缓存是应用级别的，所以当应用启动时二级缓存就已经被创建了，这个过程发生在对映射文件进行解析时。在映射文件中我们会按照需要配置一定的 `<cache/>` 和 `<cache-ref>` 标签，而在解析 `<cache/>` 标签时会调用 `MapperBuilderAssistant#useNewCache` 方法创建对应的二级缓存对象。\n\n### 总结\n\n本文对 MyBatis 执行 SQL 语句所涉及到的各个方面做了一个比较详细的分析。当我们基于 MyBatis 触发一次数据库操作时，首先需要开启一次数据库会话，然后获取目标 Mapper 接口，并调用相应的 Mapper 方法执行数据库操作，最后拿到操作结果。MyBatis 在这中间基于动态代理机制实现了 SQL 语句的检索、参数绑定、数据库操作，以及结果集映射等一系列操作，并引入了缓存机制优化数据库查询性能。\n\n回过头来看，MyBatis 的整体设计还是非常巧妙的，却也很是直观且简单，是对动态代理机制的典型应用，其设计思想和对于设计模式的应用值得我们在实际开发中借鉴。\n\n本文是 MyBatis 源码解析系列的最后一篇文章，由于时间仓促，再加上作者水平有限，整个系列的文章中不免有错误之处，还望批评指正！\n\n### 参考\n\n1. [MyBatis 官方文档](https://mybatis.org/mybatis-3/zh/index.html)\n2. [MyBatis 技术内幕](https://book.douban.com/subject/27087564/)\n","tags":["MyBatis"],"categories":["mybatis"]},{"title":"MyBatis 源码解析：映射文件的加载与解析","url":"/2017/10/14/mybatis/mybatis-mapper/","content":"\n上一篇我们分析了配置文件的加载与解析过程，本文将继续对映射文件的加载与解析实现进行分析。MyBatis 的映射文件用于配置 SQL 语句、二级缓存，以及结果集映射等，是区别于其它 ORM 框架的主要特色之一。\n\n在上一篇分析配置文件 `<mappers/>` 标签的解析实现时，了解到 MyBatis 最终通过调用 `XMLMapperBuilder#parse` 方法实现对映射文件的解析操作，本文我们将以此方法作为入口，探究 MyBatis 加载和解析映射文件的实现机制。<!-- more -->\n\n方法 `XMLMapperBuilder#parse` 的实现如下：\n\n```java\npublic void parse() {\n    /* 1. 加载并解析映射文件 */\n    if (!configuration.isResourceLoaded(resource)) {\n        // 加载并解析 <mapper/> 标签下的配置\n        this.configurationElement(parser.evalNode(\"/mapper\"));\n        // 标记该映射文件已被解析\n        configuration.addLoadedResource(resource);\n        // 注册当前映射文件关联的 Mapper 接口（标签 <mapper namespace=\"\"/> 对应的 namespace 属性）\n        this.bindMapperForNamespace();\n    }\n\n    /* 2. 处理解析过程中失败的标签 */\n\n    // 处理解析失败的 <resultMap/> 标签\n    this.parsePendingResultMaps();\n    // 处理解析失败的 <cache-ref/> 标签\n    this.parsePendingCacheRefs();\n    // 处理解析失败的 SQL 语句标签\n    this.parsePendingStatements();\n}\n```\n\nMyBatis 在解析映射文件时首先会判断该映射文件是否被解析过，对于没有被解析过的文件则会调用 `XMLMapperBuilder#configurationElement` 方法解析所有配置，并注册当前映射文件关联的 Mapper 接口。对于解析过程中处理异常的标签，MyBatis 会将其记录到 Configuration 对象对应的属性中，并在方法最后再次尝试二次解析。\n\n整个 `XMLMapperBuilder#configurationElement` 方法实现了对映射文件解析的核心步骤，与配置文件解析的实现方式一样，这也是一个调度方法，实现如下：\n\n```java\nprivate void configurationElement(XNode context) {\n    try {\n        // 获取 <mapper/> 标签的 namespace 属性，设置当前映射文件关联的 Mapper 接口\n        String namespace = context.getStringAttribute(\"namespace\");\n        if (namespace == null || namespace.equals(\"\")) {\n            throw new BuilderException(\"Mapper's namespace cannot be empty\");\n        }\n        builderAssistant.setCurrentNamespace(namespace);\n        // 解析 <cache-ref/> 子标签，多个 mapper 可以共享同一个二级缓存\n        this.cacheRefElement(context.evalNode(\"cache-ref\"));\n        // 解析 <cache/> 子标签\n        this.cacheElement(context.evalNode(\"cache\"));\n        // 解析 <parameterMap/> 子标签，已废弃\n        this.parameterMapElement(context.evalNodes(\"/mapper/parameterMap\"));\n        // 解析 <resultMap/> 子标签，建立结果集与对象属性之间的映射关系\n        this.resultMapElements(context.evalNodes(\"/mapper/resultMap\"));\n        // 解析 <sql/> 子标签\n        this.sqlElement(context.evalNodes(\"/mapper/sql\"));\n        // 解析 <select/>、<insert/>、<update/> 和 <delete/> 子标签\n        this.buildStatementFromContext(context.evalNodes(\"select|insert|update|delete\"));\n    } catch (Exception e) {\n        throw new BuilderException(\"Error parsing Mapper XML. The XML location is '\" + resource + \"'. Cause: \" + e, e);\n    }\n}\n```\n\n每个映射文件都关联一个具体的 Mapper 接口，而 `<mapper/>` 节点的 namespace 属性则用于指定对应的 Mapper 接口限定名。上述方法首先会获取 namespace 属性，然后调用相应方法对每个子标签进行解析，下面逐一展开分析。\n\n### 加载与解析映射文件\n\n下面对各个子标签的解析过程逐一展开分析，考虑到 `<parameterMap/>` 子标签已废弃，所以不再对其多作介绍。\n\n#### 解析 cache 标签\n\nMyBatis 在设计上分为一级缓存和二级缓存（关于缓存机制将会在下一篇分析 SQL 语句执行过程时进行介绍，这里只要知道有这样两个概念即可），该标签用于对二级缓存进行配置。在具体分析 `<cache/>` 标签之前，我们需要对 MyBatis 的缓存类设计有一个了解，不然可能会云里雾里。MyBatis 的缓存类设计还是非常巧妙的，不管是一级缓存还是二级缓存，都实现自同一个 Cache 接口：\n\n```java\npublic interface Cache {\n    /** 缓存对象 ID */\n    String getId();\n    /** 添加数据到缓存，一般来说 key 是 {@link CacheKey} 类型 */\n    void putObject(Object key, Object value);\n    /** 从缓存中获取 key 对应的 value */\n    Object getObject(Object key);\n    /** 从缓存中移除指定对象 */\n    Object removeObject(Object key);\n    /** 清空缓存 */\n    void clear();\n    /**\n     * 获取缓存对象的个数（不是缓存的容量），\n     * 该方法不会在 MyBatis 核心代码中被调用，可以是一个空实现\n     */\n    int getSize();\n    /**\n     * 缓存读写锁，\n     * 该方法不会在 MyBatis 核心代码中被调用，可以是一个空实现\n     */\n    ReadWriteLock getReadWriteLock();\n}\n```\n\nCache 接口中声明的缓存操作方法中规中矩。围绕该接口，MyBatis 实现了基于 HashMap 数据结构的基本实现 PerpetualCache 类，该实现类的各项方法实现都是对 HashMap API 的封装，比较简单。在整个缓存类设计方面，MyBatis 使用了典型的装饰模式为缓存对象增加不同的特性，下表对这些装饰器进行了简单介绍。\n\n实现类 | 名称 | 描述\n--- | --- | ---\nBlockingCache | 阻塞式缓存装饰器 | 采用 ConcurrentHashMap 对象记录每个 key 对应的可重入锁对象，当执行 getObject 操作时会尝试获取 key 对应的锁对象，并应用带有超时机制的加锁操作，在获取到缓存值之后会释放锁。\nFifoCache | 先进先出缓存装饰器 | 采用双端队列记录 key 进入缓存的顺序，队列的大小默认是 1024，当执行 putObject 操作时，如果当前缓存的对象数超过缓存大小，则会触发 FIFO 策略。\nLruCache | 近期最少使用缓存装饰器 | 通过 LinkedHashMap 类型的 keyMap 属性记录缓存中每个 key 的使用情况，并使用 eldestKey 对象记录当前最少被使用的 key，当缓存达到容量上限时将会移除使用频率最小的缓存项。\nLoggingCache | 日志功能缓存装饰器 | 并不是如其字面意思是对缓存增加日志记录功能，该缓存装饰器中增加了两个属性：requests 和 hits，分别用于记录缓存被访问的次数和缓存命中的次数，并提供了 getHitRatio 方法以获取当前缓存的命中率。\nScheduledCache | 周期性清理缓存装饰器 | 用于定期对缓存进行执行 clear 操作，其中定义了两个属性：clearInterval 和 lastClear，分别用来记录执行清理的时间间隔（默认为 1 小时）和最近一次执行清理的时间戳，在每次操作缓存时都会触发对缓存当前清理状态的检查，如果间隔时间达到设置值，就会触发对缓存的清理操作。\nSerializedCache | 序列化支持缓存装饰器 | 用于对缓存值进行序列化处理后再进行缓存，当我们执行 putObject 操作时，该装饰器会基于 java 的序列化机制对缓存值进行序列化（序列化结果存储在内存），反之，当我们执行 getObject 操作时，如果对应的缓存值存在，则会对该值执行反序列化再返回。\nSoftCache | 软引用缓存装饰器 | 通过软引用 Entry 内部类对缓存值进行修饰，值的生命周期受 GC 操作影响。\nWeakCache | 弱引用缓存装饰器 | 实现同 SoftCache，只是这里使用的是弱引用。\nSynchronizedCache | 同步缓存装饰器 | 通过在相应的缓存操作方法前都增加了 synchronized 关键字修饰，类似于 HashTable 的实现方式。\nTransactionalCache | 事务缓存装饰器 | 主要用于二级缓存，留到下一篇介绍缓存模块设计时再进行分析。\n\n介绍完了缓存类的基本设计，我们再回过头来继续分析 `<cache/>` 标签的解析过程，由 `XMLMapperBuilder#cacheElement` 方法实现：\n\n```java\nprivate void cacheElement(XNode context) {\n    if (context != null) {\n        // 获取相应的是属性配置\n        String type = context.getStringAttribute(\"type\", \"PERPETUAL\"); // 缓存实现类型，可以指定自定义实现\n        Class<? extends Cache> typeClass = typeAliasRegistry.resolveAlias(type);\n        String eviction = context.getStringAttribute(\"eviction\", \"LRU\"); // 缓存清除策略，默认是 LRU，还可以是 FIFO、SOFT，以及 WEAK\n        Class<? extends Cache> evictionClass = typeAliasRegistry.resolveAlias(eviction);\n        Long flushInterval = context.getLongAttribute(\"flushInterval\"); // 刷新间隔，单位：毫秒\n        Integer size = context.getIntAttribute(\"size\"); // 缓存大小，默认为 1024\n        boolean readWrite = !context.getBooleanAttribute(\"readOnly\", false); // 是否只读\n        boolean blocking = context.getBooleanAttribute(\"blocking\", false); // 是否阻塞\n        Properties props = context.getChildrenAsProperties();\n        // 创建二级缓存，并填充 Configuration 对象\n        builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props);\n    }\n}\n```\n\n上述方法首先会获取 `<cache/>` 标签的相关属性配置，然后调用 `MapperBuilderAssistant#useNewCache` 方法创建缓存对象，并记录到 Configuration 对象中。方法 `MapperBuilderAssistant#useNewCache` 中使用了缓存对象构造器 CacheBuilder 创建缓存对象，一起来看一下 `CacheBuilder#build` 方法实现：\n\n```java\npublic Cache build() {\n    // 如果没有指定自定义缓存实现类，则设置缓存默认实现（以 PerpetualCache 作为默认实现，以 LruCache 作为默认装饰器）\n    this.setDefaultImplementations();\n    // 反射创建缓存对象\n    Cache cache = this.newBaseCacheInstance(implementation, id);\n    // 初始化缓存对象\n    this.setCacheProperties(cache);\n    // issue #352, do not apply decorators to custom caches\n    // 如果缓存采用 PerpetualCache 实现，则遍历使用注册的装饰器进行装饰\n    if (PerpetualCache.class.equals(cache.getClass())) {\n        // 遍历装饰器集合，基于反射方式装饰缓存对象\n        for (Class<? extends Cache> decorator : decorators) {\n            cache = this.newCacheDecoratorInstance(decorator, cache);\n            this.setCacheProperties(cache);\n        }\n        // 采用标准装饰器进行装饰\n        cache = this.setStandardDecorators(cache);\n    }\n    // 采用日志缓存装饰器对缓存对象进行装饰\n    else if (!LoggingCache.class.isAssignableFrom(cache.getClass())) {\n        cache = new LoggingCache(cache);\n    }\n    return cache;\n}\n```\n\n构造缓存对象时首先会判断是否指定了自定义的缓存实现类，否则使用默认的缓存实现（即以 PerpetualCache 作为默认实现，以 LruCache 作为默认缓存装饰器）；然后选择 String 类型参数的构造方法构造缓存对象，并基于配置对缓存对象进行初始化；最后依据缓存实现采用相应的装饰器予以装饰。\n\n方法 `CacheBuilder#setCacheProperties` 除了用于设置相应属性配置外，还会判断缓存类是否实现了 InitializingObject 接口，以决定是否调用 `InitializingObject#initialize` 初始化方法。\n\n#### 解析 cache-ref 标签\n\n标签 `<cache/>` 默认的作用域限定在标签所在的 namespace 范围内，如果希望能够让一个缓存对象在多个 namespace 之间共享，可以定义 `<cache-ref/>` 标签以引用其它命名空间中定义的缓存对象。标签 `<cache-ref/>` 的解析位于 `XMLMapperBuilder#cacheRefElement` 方法中：\n\n```java\nprivate void cacheRefElement(XNode context) {\n    if (context != null) {\n        // 记录 <当前节点所在的 namespace, 引用缓存对象所在的 namespace> 映射关系到 Configuration 中\n        configuration.addCacheRef(builderAssistant.getCurrentNamespace(), context.getStringAttribute(\"namespace\"));\n        // 构造缓存引用解析器 CacheRefResolver 对象\n        CacheRefResolver cacheRefResolver = new CacheRefResolver(builderAssistant, context.getStringAttribute(\"namespace\"));\n        try {\n            // 从记录缓存对象的 Configuration#caches 集合中获取引用的缓存对象\n            cacheRefResolver.resolveCacheRef();\n        } catch (IncompleteElementException e) {\n            // 如果解析出现异常则记录到 Configuration#incompleteCacheRefs 中，稍后再处理\n            configuration.addIncompleteCacheRef(cacheRefResolver);\n        }\n    }\n}\n```\n\n方法首先会在 `Configuration#cacheRefMap` 属性中记录一下当前的引用关系，其中 key 是 `<cache-ref/>` 所在的 namespace，value 则是引用的缓存对象所在的 namespace。然后从 `Configuration#caches` 属性中获取引用的缓存对象，在分析 `<cache/>` 标签时，我们曾提及到最终解析构造的缓存对象会记录到 `Configuration#caches` 属性中，这里则是一个逆过程。\n\n#### 解析 resultMap 标签\n\n标签 `<resultMap/>` 用于配置结果集映射，建立结果集与实体类对象属性之间的映射关系。这是一个非常有用且提升开发效率的配置，如果是纯 JDBC 开发，在处理结果集与实体类对象之间的映射时还需要手动硬编码注入。对于一张字段较多的表来说，简直写到手抽筋，而 `<resultMap/>` 标签配置配合 mybatis-generator 工具的逆向工程可以解放我们的双手。下面是一个典型的配置，用于建立数据表 t_user 与 User 实体类之间的属性映射关系：\n\n```xml\n<resultMap id=\"BaseResultMap\" type=\"org.zhenchao.mybatis.entity.User\">\n    <id column=\"id\" jdbcType=\"BIGINT\" property=\"id\"/>\n    <result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/>\n    <result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/>\n    <result column=\"age\" jdbcType=\"INTEGER\" property=\"age\"/>\n    <result column=\"phone\" jdbcType=\"VARCHAR\" property=\"phone\"/>\n    <result column=\"email\" jdbcType=\"VARCHAR\" property=\"email\"/>\n</resultMap>\n```\n\n在开始介绍 `<resultMap/>` 标签的解析过程之前，我们需要对该标签涉及到的两个主要的类 ResultMapping 和 ResultMap 有一个了解。前者用于封装除 `<discriminator/>` 标签以外的其它子标签配置（该标签具备自己的封装类），后者则用于封装整个 `<resultMap/>` 标签。\n\n- __ResultMapping__\n\n```java\npublic class ResultMapping {\n\n    private Configuration configuration;\n\n    /** 对应标签的 property 属性 */\n    private String property;\n    /** 对应标签的 column 属，配置数据表列名（or 别名） */\n    private String column;\n    /** 对应 java 类型，配置类型全限定名（or 别名） */\n    private Class<?> javaType;\n    /** 对应列的 JDBC 类型 */\n    private JdbcType jdbcType;\n    /** 类型处理器，会覆盖默认类型处理器 */\n    private TypeHandler<?> typeHandler;\n    /** 对应标签的 resultMap 属性，以 id 的方式引某个已定义的 <resultMap/> */\n    private String nestedResultMapId;\n    /** 对应标签的 select 属性，以 id 的方式引用某个已定义的 <select/> */\n    private String nestedQueryId;\n    /** 对标签的 notNullColumns 属性 */\n    private Set<String> notNullColumns;\n    /** 对应标签的 columnPrefix 属性 */\n    private String columnPrefix;\n    /** 记录处理后的标志 */\n    private List<ResultFlag> flags;\n    /** 记录标签 column 拆分后生成的结果 */\n    private List<ResultMapping> composites;\n    /** 对应标签 resultSet 属性 */\n    private String resultSet;\n    /** 对应标签 foreignColumn 属性 */\n    private String foreignColumn;\n    /** 对应标签 fetchType 属性，配置是否延迟加载 */\n    private boolean lazy;\n\n    // ... 省略构造器类定义，以及 getter 和 setter 方法\n}\n```\n\nResultMapping 类中定义的属性如上述代码注释。此外，还内置了一个 Builder 内部构造器类，用于封装数据构造 ResultMapping 对象，并实现了对属性值的基本校验逻辑。\n\n- __ResultMap__\n\n```java\npublic class ResultMap {\n\n    private Configuration configuration;\n\n    /** 对应标签的 id 属性 */\n    private String id;\n    /** 对应标签的 type 属性 */\n    private Class<?> type;\n    /** 记录除 <discriminator/> 标签以外的其它映射关系 */\n    private List<ResultMapping> resultMappings;\n    /** 记录带有 id 属性的映射关系 */\n    private List<ResultMapping> idResultMappings;\n    /** 记录带有 constructor 属性的映射关系 */\n    private List<ResultMapping> constructorResultMappings;\n    /** 记录带有 property 属性的映射关系 */\n    private List<ResultMapping> propertyResultMappings;\n    /** 记录配置中所有的 column 属性集合 */\n    private Set<String> mappedColumns;\n    /** 记录配置中所有的 property 属性集合 */\n    private Set<String> mappedProperties;\n    /** 封装 <discriminator/> 标签 */\n    private Discriminator discriminator;\n    /** 是否包含嵌套的结果映射 */\n    private boolean hasNestedResultMaps;\n    /** 是否包含嵌套查询 */\n    private boolean hasNestedQueries;\n    /** 是否开启自动映射 */\n    private Boolean autoMapping;\n\n    // ... 省略构造器类，以及 getter 和 setter 方法\n}\n```\n\nResultMap 类中定义的属性如上述代码注释。与 ResultMapping 一样，也是通过内置 Builder 内部构造器类来构造 ResultMap 对象，构造器的实现比较简单，读者可以参考源码实现。\n\n了解了内部数据结构 ResultMapping 和 ResultMap 的定义，以及二者之间的相互依赖关系，接下来开始分析 `<resultMap/>` 标签的解析过程，实现位于 `XMLMapperBuilder#resultMapElements` 方法中：\n\n```java\nprivate ResultMap resultMapElement(XNode resultMapNode, List<ResultMapping> additionalResultMappings, Class<?> enclosingType) {\n    ErrorContext.instance().activity(\"processing \" + resultMapNode.getValueBasedIdentifier());\n    // 获取 type 属性，支持 type、ofType、resultType，以及 javaType 类型配置\n    String type = resultMapNode.getStringAttribute(\"type\",\n        resultMapNode.getStringAttribute(\"ofType\",\n            resultMapNode.getStringAttribute(\"resultType\",\n                resultMapNode.getStringAttribute(\"javaType\"))));\n    // 基于 TypeAliasRegistry 解析 type 属性对应的实体类型\n    Class<?> typeClass = this.resolveClass(type);\n    if (typeClass == null) {\n        // 尝试基于 <association/> 子标签或 <case/> 子标签解析实体类型\n        typeClass = this.inheritEnclosingType(resultMapNode, enclosingType);\n    }\n    Discriminator discriminator = null;\n    // 用于记录解析结果\n    List<ResultMapping> resultMappings = new ArrayList<>(additionalResultMappings);\n    // 获取并遍历处理所有的子标签\n    List<XNode> resultChildren = resultMapNode.getChildren();\n    for (XNode resultChild : resultChildren) {\n        // 解析 <constructor/> 子标签，封装成为 ResultMapping 对象\n        if (\"constructor\".equals(resultChild.getName())) {\n            this.processConstructorElement(resultChild, typeClass, resultMappings);\n        }\n        // 解析 <discriminator/> 子标签，封装成为 Discriminator 对象\n        else if (\"discriminator\".equals(resultChild.getName())) {\n            discriminator = this.processDiscriminatorElement(resultChild, typeClass, resultMappings);\n        }\n        // 解析 <association/>、<collection/>、<id/> 和 <result/> 子标签，封装成为 ResultMapping 对象\n        else {\n            List<ResultFlag> flags = new ArrayList<>();\n            if (\"id\".equals(resultChild.getName())) {\n                flags.add(ResultFlag.ID);\n            }\n            // 创建 ResultMapping 对象，并记录到 resultMappings 集合中\n            resultMappings.add(this.buildResultMappingFromContext(resultChild, typeClass, flags));\n        }\n    }\n    // 获取 id 属性（标识当前 <resultMap/> 标签），如果没有指定则基于规则生成一个\n    String id = resultMapNode.getStringAttribute(\"id\", resultMapNode.getValueBasedIdentifier());\n    // 获取 extends 属性，用于指定继承关系\n    String extend = resultMapNode.getStringAttribute(\"extends\");\n    // 获取 autoMapping 属性，是否启用自动映射（自动查找与列名相同的属性名称，并执行注入）\n    Boolean autoMapping = resultMapNode.getBooleanAttribute(\"autoMapping\");\n    ResultMapResolver resultMapResolver = new ResultMapResolver(\n        builderAssistant, id, typeClass, extend, discriminator, resultMappings, autoMapping);\n    try {\n        // 基于解析得到的配置构造 ResultMap 对象，记录到 Configuration#resultMaps 中\n        return resultMapResolver.resolve();\n    } catch (IncompleteElementException e) {\n        // 记录解析异常的 <resultMap/> 标签，后续尝试二次解析\n        configuration.addIncompleteResultMap(resultMapResolver);\n        throw e;\n    }\n}\n```\n\n标签 `<resultMap/>` 包含 4 个属性配置，即 id、type、extends 和 autoMapping。\n\n- __id__ ：标识当前 `<resultMap/>` 标签，如果没有指定则会调用 `XNode#getValueBasedIdentifier` 方法基于规则自动生成一个，用于提升 MyBatis 的执行性能。\n- __type__ ：设置当前标签所关联的实体类对象，支持 type、ofType、resultType，以及 javaType 等配置方式，以尽可能用简单的配置支持更多的实体类型。\n- __extends__ ：指定当前标签的继承关系。\n- __autoMapping__ ：一个 boolean 类型的配置项，如果为 true 则表示开启自动映射功能，MyBatis 会自动查找实例类对象中与结果集列名相同的属性名，并调用 setter 方法执行注入。标签 `<resultMap/>` 中明确指定的映射关系优先级要高于自动映射。\n\n标签 `<resultMap/>` 包含 `<constructor/>`、`<id/>`、`<result/>`、`<association/>`、`<collection/>`，以及 `<discriminator/>` 六个子标签。关于这些子标签的作用可以参阅 [官方文档](https://mybatis.org/mybatis-3/zh/sqlmap-xml.html#Result_Maps)，除 `<discriminator/>` 以外，其余五个标签的解析实现大同小异，下面以 `<constructor/>` 标签为例对解析实现展开分析。\n\n子标签 `<constructor/>` 的解析由 `XMLMapperBuilder#processConstructorElement` 方法实现，如下：\n\n```java\nprivate void processConstructorElement(\n    XNode resultChild, Class<?> resultType, List<ResultMapping> resultMappings) {\n    // 获取并处理 <constructor/> 标签中配置的子标签列表\n    List<XNode> argChildren = resultChild.getChildren();\n    for (XNode argChild : argChildren) {\n        List<ResultFlag> flags = new ArrayList<>();\n        flags.add(ResultFlag.CONSTRUCTOR);\n        if (\"idArg\".equals(argChild.getName())) {\n            flags.add(ResultFlag.ID); // 添加 ID 标识\n        }\n        // 封装标签配置为 ResultMapping 对象，记录到 resultMappings 集合中\n        resultMappings.add(this.buildResultMappingFromContext(argChild, resultType, flags));\n    }\n}\n```\n\n子标签 `<constructor/>` 用于指定实体类的构造方法以实现在构造实体类对象时注入结果值。上述方法直接遍历处理该标签的所有子标签，即 `<idArg/>` 和 `<arg/>`，并调用 `XMLMapperBuilder#buildResultMappingFromContext` 方法创建对应的 ResultMapping 对象，实现如下：\n\n```java\nprivate ResultMapping buildResultMappingFromContext(\n    XNode context, Class<?> resultType, List<ResultFlag> flags) {\n    // 获取对应的属性配置\n    String property;\n    if (flags.contains(ResultFlag.CONSTRUCTOR)) {\n        property = context.getStringAttribute(\"name\");\n    } else {\n        property = context.getStringAttribute(\"property\");\n    }\n    String column = context.getStringAttribute(\"column\");\n    String javaType = context.getStringAttribute(\"javaType\");\n    String jdbcType = context.getStringAttribute(\"jdbcType\");\n    String nestedSelect = context.getStringAttribute(\"select\");\n    // 存在嵌套配置，嵌套解析\n    String nestedResultMap = context.getStringAttribute(\"resultMap\", () ->\n        this.processNestedResultMappings(context, Collections.emptyList(), resultType));\n    String notNullColumn = context.getStringAttribute(\"notNullColumn\");\n    String columnPrefix = context.getStringAttribute(\"columnPrefix\");\n    String typeHandler = context.getStringAttribute(\"typeHandler\");\n    String resultSet = context.getStringAttribute(\"resultSet\");\n    String foreignColumn = context.getStringAttribute(\"foreignColumn\");\n    boolean lazy = \"lazy\".equals(context.getStringAttribute(\"fetchType\", configuration.isLazyLoadingEnabled() ? \"lazy\" : \"eager\"));\n    // 基于 TypeAliasRegistry 解析 JavaType 对应的 Class 对象\n    Class<?> javaTypeClass = this.resolveClass(javaType);\n    // 基于 TypeAliasRegistry 解析 TypeHandler 对应的 Class 对象\n    Class<? extends TypeHandler<?>> typeHandlerClass = this.resolveClass(typeHandler);\n    // 获取 JdbcType 对应的具体枚举对象\n    JdbcType jdbcTypeEnum = this.resolveJdbcType(jdbcType);\n    // 封装成 ResultMapping 对象\n    return builderAssistant.buildResultMapping(\n        resultType, property, column, javaTypeClass, jdbcTypeEnum, nestedSelect, nestedResultMap,\n        notNullColumn, columnPrefix, typeHandlerClass, flags, resultSet, foreignColumn, lazy);\n}\n```\n\n方法首先会获取标签所有的属性配置项，并基于 TypeAliasRegistry 对属性所表示的类型进行解析，最后调用 `MapperBuilderAssistant#buildResultMapping` 方法构造封装配置项对应的 ResultMapping 对象，这里本质上还是调用 ResultMapping 的构造器进行构造。其中，方法 `XMLMapperBuilder#buildResultMappingFromContext` 是一个通用方法，除了上面用于封装 `<constructor/>` 子标签，对于标签 `<id/>`、`<result/>`、`<association/>` 和 `<collection/>` 来说也都是直接调用该方法进行解析。\n\n继续来看一下 `<discriminator/>` 标签，该标签并没有直接采用 ResultMapping 类进行封装，而是采用 Discriminator 类对 ResultMapping 进行封装，这主要取决于该标签的用途。MyBatis 使用该标签基于具体的结果值选择不同的结果集映射，解析实现位于 `XMLMapperBuilder#processDiscriminatorElement` 方法中，如下：\n\n```java\nprivate Discriminator processDiscriminatorElement(\n    XNode context, Class<?> resultType, List<ResultMapping> resultMappings) {\n    // 获取相关属性配置\n    String column = context.getStringAttribute(\"column\");\n    String javaType = context.getStringAttribute(\"javaType\");\n    String jdbcType = context.getStringAttribute(\"jdbcType\");\n    String typeHandler = context.getStringAttribute(\"typeHandler\");\n    // 基于 TypeAliasRegistry 解析类型属性对应的 Class 对象\n    Class<?> javaTypeClass = this.resolveClass(javaType);\n    Class<? extends TypeHandler<?>> typeHandlerClass = this.resolveClass(typeHandler);\n    JdbcType jdbcTypeEnum = this.resolveJdbcType(jdbcType);\n    // 遍历处理子标签列表\n    Map<String, String> discriminatorMap = new HashMap<>();\n    for (XNode caseChild : context.getChildren()) {\n        String value = caseChild.getStringAttribute(\"value\");\n        String resultMap = caseChild.getStringAttribute(\"resultMap\",\n            // 嵌套解析\n            this.processNestedResultMappings(caseChild, resultMappings, resultType));\n        discriminatorMap.put(value, resultMap);\n    }\n    // 封装成 Discriminator 对象，本质上依赖于 Discriminator 的构造器构建\n    return builderAssistant.buildDiscriminator(\n        resultType, column, javaTypeClass, jdbcTypeEnum, typeHandlerClass, discriminatorMap);\n}\n```\n\n可以看到，具体的解析步骤与其它标签如出一辙，参考代码注释。\n\n在将这六类子标签解析成为相应对象并记录到 resultMappings 集合中之后，下一步就是基于这些配置构造 ResultMapResolver 解析器，并调用 `ResultMapResolver#resolve` 方法解析 `<resultMap/>` 配置为 ResultMap 对象记录到 `Configuration#resultMaps` 属性中。\n\n方法 `ResultMapResolver#resolve` 直接将请求委托给了 `MapperBuilderAssistant#addResultMap` 方法执行，实现如下：\n\n```java\npublic ResultMap resolve() {\n    return assistant.addResultMap(\n        this.id, this.type, this.extend, this.discriminator, this.resultMappings, this.autoMapping);\n}\n\n// org.apache.ibatis.builder.MapperBuilderAssistant#addResultMap\npublic ResultMap addResultMap(\n    String id,\n    Class<?> type,\n    String extend,\n    Discriminator discriminator,\n    List<ResultMapping> resultMappings,\n    Boolean autoMapping) {\n    // 格式化 id 值，格式：namespace.id\n    id = this.applyCurrentNamespace(id, false);\n    extend = this.applyCurrentNamespace(extend, true);\n\n    // 处理 extend 配置\n    if (extend != null) {\n        // 被继承的 ResultMap 不存在\n        if (!configuration.hasResultMap(extend)) {\n            throw new IncompleteElementException(\"Could not find a parent resultmap with id '\" + extend + \"'\");\n        }\n        // 获取需要被继承的 ResultMap 对象\n        ResultMap resultMap = configuration.getResultMap(extend);\n        // 获取父 ResultMap 对象中包含的 ResultMapping 对象集合\n        List<ResultMapping> extendedResultMappings = new ArrayList<>(resultMap.getResultMappings());\n        // 删除被覆盖的 ResultMapping 对象\n        extendedResultMappings.removeAll(resultMappings);\n        // Remove parent constructor if this resultMap declares a constructor.\n        boolean declaresConstructor = false;\n        // 查找当前 <resultMap/> 标签中是否定义了 <constructor/> 子标签\n        for (ResultMapping resultMapping : resultMappings) {\n            if (resultMapping.getFlags().contains(ResultFlag.CONSTRUCTOR)) {\n                declaresConstructor = true;\n                break;\n            }\n        }\n        // 当前 <resultMap/> 中定义了 <constructor/> 子标签，\n        // 则无需父 ResultMap 中记录的相应 <constructor/>，遍历删除\n        if (declaresConstructor) {\n            extendedResultMappings.removeIf(\n                resultMapping -> resultMapping.getFlags().contains(ResultFlag.CONSTRUCTOR));\n        }\n        // 添加需要继承的 ResultMapping 对象集合\n        resultMappings.addAll(extendedResultMappings);\n    }\n    // 创建 ResultMap 对象，并记录到 Configuration#resultMaps 中\n    ResultMap resultMap = new ResultMap.Builder(configuration, id, type, resultMappings, autoMapping)\n        .discriminator(discriminator)\n        .build();\n    configuration.addResultMap(resultMap);\n    return resultMap;\n}\n```\n\n具体过程如代码注释。\n\n#### 解析 sql 标签\n\n在 MyBatis 中可以通过 `<sql/>` 标签配置一些可以被复用的 SQL 语句片段，当我们在某个 SQL 语句中需要使用这些片段时，可以通过 `<include/>` 子标签引入，具体示例可以参考 [官方文档](https://mybatis.org/mybatis-3/zh/sqlmap-xml.html#insert_update_and_delete)。对于 `<sql/>` 标签的解析由 `XMLMapperBuilder#sqlElement` 方法实现，最终记录到 `Configuration#sqlFragments` 集合中，方法实现如下：\n\n```java\nprivate void sqlElement(List<XNode> list, String requiredDatabaseId) {\n    // 遍历处理所有的 <sql/> 标签\n    for (XNode context : list) {\n        // 获取数据库标识 databaseId 属性\n        String databaseId = context.getStringAttribute(\"databaseId\");\n        // 获取 id 属性\n        String id = context.getStringAttribute(\"id\");\n        // 格式化 id，格式：namespace.id\n        id = builderAssistant.applyCurrentNamespace(id, false);\n        /*\n         * 判断数据库标识 databaseId 与当前 Configuration 中配置的是否一致：\n         * 1. 如果指定了 requiredDatabaseId，则 databaseId 必须和 requiredDatabaseId 一致\n         * 2. 如果没有指定了 requiredDatabaseId，则 databaseId 必须为 null\n         */\n        if (this.databaseIdMatchesCurrent(id, databaseId, requiredDatabaseId)) {\n            sqlFragments.put(id, context);\n        }\n    }\n}\n```\n\n方法首先会获取 `<sql/>` 标签的属性配置，即 id 和 databaseId，并对 id 进行格式化处理；然后判断当前 `<sql/>` 标签配置的数据库标识 databaseId 是否与当前运行的数据库环境相匹配，并忽略不匹配的 `<sql/>` 标签。参数 requiredDatabaseId 在重载方法中指定，本质上就是从全局配置 Configuration 对象中获取的 `Configuration#databaseId` 属性值：\n\n```java\nprivate void sqlElement(List<XNode> list) {\n    if (configuration.getDatabaseId() != null) {\n        // 获取当前运行环境对应的数据库标识\n        this.sqlElement(list, configuration.getDatabaseId());\n    }\n    this.sqlElement(list, null);\n}\n```\n\n最终这些解析得到的 `<sql/>` 标签会被记录到 `Configuration#sqlFragments` 属性中（在构造 XMLMapperBuilder 对象时进行初始化），后面分析 `<include/>` 标签时可以看到会从该属性值获取引用的 SQL 语句片段。\n\n#### 解析 select / insert / update / delete 标签\n\n标签 `<select/>`、`<insert/>`、`<update/>` 和 `<delete/>` 用于配置映射文件中最核心的数据库操作语句（下文统称这 4 个标签为 SQL 语句标签），包括静态 SQL 语句和动态 SQL 语句。MyBatis 通过 MappedStatement 类封装这些 SQL 语句标签的配置，并调用 `XMLStatementBuilder#parseStatementNode` 方法对标签进行解析，构建 MappedStatement 对象并记录到 `Configuration#mappedStatements` 属性中。\n\n方法 `XMLMapperBuilder#buildStatementFromContext` 对于标签的解析主要做了一些统筹调度的工作，具体解析还是交由 XMLStatementBuilder 类进行处理，该方法的实现如下：\n\n```java\nprivate void buildStatementFromContext(List<XNode> list) {\n    if (configuration.getDatabaseId() != null) {\n        this.buildStatementFromContext(list, configuration.getDatabaseId());\n    }\n    this.buildStatementFromContext(list, null);\n}\n\nprivate void buildStatementFromContext(List<XNode> list, String requiredDatabaseId) {\n    // 遍历处理获取到的所有 SQL 语句标签\n    for (XNode context : list) {\n        // 创建 XMLStatementBuilder 解析器，负责解析具体的 SQL 语句标签\n        final XMLStatementBuilder statementParser =\n            new XMLStatementBuilder(configuration, builderAssistant, context, requiredDatabaseId);\n        try {\n            // 执行解析操作\n            statementParser.parseStatementNode();\n        } catch (IncompleteElementException e) {\n            // 记录解析异常的 SQL 语句标签，稍后尝试二次解析\n            configuration.addIncompleteStatement(statementParser);\n        }\n    }\n}\n```\n\n上述实现比较简单，无非是遍历获取到的所有 SQL 语句标签列表，然后构建 XMLStatementBuilder 解析器并调用 `XMLStatementBuilder#parseStatementNode` 方法对各个 SQL 语句标签进解析。对于解析异常的标签则会记录到 `Configuration#incompleteStatements` 属性中，稍后会再次尝试解析。\n\n下面分析一下 `XMLStatementBuilder#parseStatementNode` 方法的具体实现：\n\n```java\npublic void parseStatementNode() {\n    // 获取 id 和 databaseId 属性\n    String id = context.getStringAttribute(\"id\");\n    String databaseId = context.getStringAttribute(\"databaseId\");\n\n    // 判断当前 SQL 语句是否适配当前数据库类型，忽略不适配的 SQL 语句\n    if (!this.databaseIdMatchesCurrent(id, databaseId, this.requiredDatabaseId)) {\n        return;\n    }\n\n    /* 获取并解析属性配置 */\n\n    // 解析 SQL 语句类型\n    String nodeName = context.getNode().getNodeName();\n    SqlCommandType sqlCommandType = SqlCommandType.valueOf(nodeName.toUpperCase(Locale.ENGLISH));\n    // 标识是否是 SELECT 语句\n    boolean isSelect = sqlCommandType == SqlCommandType.SELECT;\n    // 标识任何时候只要语句被调用，都会导致本地缓存和二级缓存被清空，适用于修改数据操作\n    boolean flushCache = context.getBooleanAttribute(\"flushCache\", !isSelect);\n    // 设置本条语句的结果是否被二级缓存，默认适用于 SELECT 语句\n    boolean useCache = context.getBooleanAttribute(\"useCache\", isSelect);\n    // 仅针对嵌套结果 SELECT 语句适用\n    boolean resultOrdered = context.getBooleanAttribute(\"resultOrdered\", false);\n\n    // 解析 <include/> 子标签\n    XMLIncludeTransformer includeParser = new XMLIncludeTransformer(configuration, builderAssistant);\n    includeParser.applyIncludes(context.getNode());\n\n    // 解析传入参数类型的完全限定名或别名\n    String parameterType = context.getStringAttribute(\"parameterType\");\n    Class<?> parameterTypeClass = this.resolveClass(parameterType);\n\n    String lang = context.getStringAttribute(\"lang\");\n    LanguageDriver langDriver = this.getLanguageDriver(lang);\n\n    // 解析 <selectKey/> 子标签\n    this.processSelectKeyNodes(id, parameterTypeClass, langDriver);\n\n    // 解析对应的 KeyGenerator 实现，用于生成填充 keyProperty 属性指定的列值\n    KeyGenerator keyGenerator;\n    String keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX;\n    keyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, true);\n    // 当前 SQL 语句标签下存在 <selectKey/> 配置，直接获取对应的 SelectKeyGenerator\n    if (configuration.hasKeyGenerator(keyStatementId)) {\n        keyGenerator = configuration.getKeyGenerator(keyStatementId);\n    }\n    // 当前 SQL 语句标签下不存在 <selectKey/> 配置\n    else {\n        // 依据当前标签的 useGeneratedKeys 配置，或全局的 useGeneratedKeys 配置，以及是否是 INSERT 方法来决定具体的 keyGenerator 实现\n        // 属性 useGeneratedKeys 仅对 INSERT 和 UPDATE 有用，使用 JDBC 的 getGeneratedKeys 方法取出由数据库内部生成的主键\n        keyGenerator = context.getBooleanAttribute(\"useGeneratedKeys\",\n            configuration.isUseGeneratedKeys() && SqlCommandType.INSERT.equals(sqlCommandType))\n            ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE;\n    }\n\n    // 创建 SQL 语句标签对应的 SqlSource 对象\n    SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass);\n    // 获取具体的 Statement 类型，默认使用 PreparedStatement\n    StatementType statementType = StatementType.valueOf(\n        context.getStringAttribute(\"statementType\", StatementType.PREPARED.toString()));\n    // 设置批量返回的结果行数，默认值为 unset（依赖驱动）\n    Integer fetchSize = context.getIntAttribute(\"fetchSize\");\n    // 数据库执行超时时间（单位：秒），默认值为 unset（依赖驱动）\n    Integer timeout = context.getIntAttribute(\"timeout\");\n    String parameterMap = context.getStringAttribute(\"parameterMap\"); // 已废弃\n    // 期望返回类型完全限定名或别名，对于集合类型应该是集合元素类型，而非集合类型本身\n    String resultType = context.getStringAttribute(\"resultType\");\n    Class<?> resultTypeClass = this.resolveClass(resultType);\n    // 引用的 <resultMap/> 的标签 ID\n    String resultMap = context.getStringAttribute(\"resultMap\");\n    // FORWARD_ONLY，SCROLL_SENSITIVE 或 SCROLL_INSENSITIVE 中的一个，默认值为 unset （依赖驱动）\n    String resultSetType = context.getStringAttribute(\"resultSetType\");\n    ResultSetType resultSetTypeEnum = this.resolveResultSetType(resultSetType);\n    if (resultSetTypeEnum == null) {\n        resultSetTypeEnum = configuration.getDefaultResultSetType();\n    }\n    // （仅对 INSERT 和 UPDATE 有用）唯一标记一个属性，通过 getGeneratedKeys 的返回值或者通过 INSERT 语句的 selectKey 子标签设置它的键值\n    String keyProperty = context.getStringAttribute(\"keyProperty\");\n    // （仅对 INSERT 和 UPDATE 有用）通过生成的键值设置表中的列名，这个设置仅在某些数据库（如 PostgreSQL）是必须的，当主键列不是表中的第一列的时候需要设置\n    String keyColumn = context.getStringAttribute(\"keyColumn\");\n    // 仅对多结果集适用，将列出语句执行后返回的结果集并给每个结果集一个名称，名称采用逗号分隔\n    String resultSets = context.getStringAttribute(\"resultSets\");\n\n    // 创建当前 SQL 语句配置对应的 MappedStatement 对象，并记录到 Configuration#mappedStatements 中\n    builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType,\n        fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass,\n        resultSetTypeEnum, flushCache, useCache, resultOrdered,\n        keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets);\n}\n```\n\n解析 SQL 语句标签的过程如上述代码注释，配合官方文档对于各个属性和子标签作用的解释应该不难理解，关于子标签 `<include/>` 和 `<selectKey/>` 的解析实现稍后会详细说明。\n\nMyBatis 使用 MappedStatement 对象封装 SQL 语句标签配置，并记录到 `Configuration#mappedStatements` 属性中，在这个过程中会调用 `LanguageDriver#createSqlSource` 方法创建 SQL 语句标签对应的 SqlSource 对象。SqlSource 类用于封装 SQL 语句标签（或 Mapper 接口方法注解）中配置的 SQL 语句，但是这里的 SQL 语句暂时还不能被数据库执行，因为其中可能包含占位符。关于 SqlSource 类暂时先了解其作用即可，稍后会对其实现做详细介绍，下面先来看一下 `LanguageDriver#createSqlSource` 方法的实现，具体实现类为 XMLLanguageDriver：\n\n```java\npublic SqlSource createSqlSource(Configuration configuration, XNode script, Class<?> parameterType) {\n    XMLScriptBuilder builder = new XMLScriptBuilder(configuration, script, parameterType);\n    return builder.parseScriptNode();\n}\n\n// org.apache.ibatis.scripting.xmltags.XMLScriptBuilder#parseScriptNode\npublic SqlSource parseScriptNode() {\n    // 判断是否是动态 SQL，解析封装为 MixedSqlNode 对象\n    MixedSqlNode rootSqlNode = this.parseDynamicTags(context);\n    SqlSource sqlSource;\n    // 动态 SQL，封装为 DynamicSqlSource 对象\n    if (isDynamic) {\n        sqlSource = new DynamicSqlSource(configuration, rootSqlNode);\n    }\n    // 静态 SQL，封装为 RawSqlSource 对象\n    else {\n        sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType);\n    }\n    return sqlSource;\n}\n```\n\n方法首先会调用 `XMLScriptBuilder#parseDynamicTags` 方法对当前 SQL 语句标签中的占位符进行解析，并判断是否为动态 SQL，实现如下：\n\n```java\nprotected MixedSqlNode parseDynamicTags(XNode node) {\n    List<SqlNode> contents = new ArrayList<>();\n    // 获取并处理所有的子标签\n    NodeList children = node.getNode().getChildNodes();\n    for (int i = 0; i < children.getLength(); i++) {\n        // 构造对应的 XNode 对象，期间会尝试解析所有的 ${} 占位符\n        XNode child = node.newXNode(children.item(i));\n        if (child.getNode().getNodeType() == Node.CDATA_SECTION_NODE || child.getNode().getNodeType() == Node.TEXT_NODE) {\n            // 获取标签的 value 值\n            String data = child.getStringBody(\"\");\n            TextSqlNode textSqlNode = new TextSqlNode(data);\n            // 基于是否存在未解析的占位符 ${} 判断是否是动态 SQL\n            if (textSqlNode.isDynamic()) {\n                contents.add(textSqlNode);\n                // 标记为动态 SQL\n                isDynamic = true;\n            } else {\n                contents.add(new StaticTextSqlNode(data));\n            }\n        }\n        // 如果子标签是 element 类型，则必定是一个动态 SQL\n        else if (child.getNode().getNodeType() == Node.ELEMENT_NODE) { // issue #628\n            String nodeName = child.getNode().getNodeName();\n            // 获取 nodeName 对应的 NodeHandler\n            NodeHandler handler = nodeHandlerMap.get(nodeName);\n            if (handler == null) {\n                throw new BuilderException(\"Unknown element <\" + nodeName + \"> in SQL statement.\");\n            }\n            // 基于具体的 NodeHandler 处理动态 SQL\n            handler.handleNode(child, contents);\n            isDynamic = true;\n        }\n    }\n    // 封装 SqlNode 集合为 MixedSqlNode 对象\n    return new MixedSqlNode(contents);\n}\n```\n\n整个过程主要是遍历当前 SQL 语句标签的所有子标签，并依据当前子标签的类型分而治之，可以配合官方文档的 [动态 SQL 配置示例](https://mybatis.org/mybatis-3/zh/dynamic-sql.html) 进行理解。如果当前子标签是一个具体的字符串或 CDATA 表达式（即 SQL 语句片段），则会获取字面值并依据是否包含未解析的 `${}` 占位符判断是否是动态 SQL，并封装成对应的 SqlNode 对象。SqlNode 是一个接口，用于封装定义的动态 SQL 节点和文本节点，包含多个实现类，该接口及其具体实现类留到后面针对性介绍。如果当前子标签是一个具体的 XML 标签，则必定是一个动态 SQL 配置，此时会依据标签名称选择对应的 NodeHandler 对节点进行处理。标签与具体 NodeHandler 的映射关系如下：\n\n```java\n// org.apache.ibatis.scripting.xmltags.XMLScriptBuilder#initNodeHandlerMap\nprivate void initNodeHandlerMap() {\n    nodeHandlerMap.put(\"trim\", new TrimHandler());\n    nodeHandlerMap.put(\"where\", new WhereHandler());\n    nodeHandlerMap.put(\"set\", new SetHandler());\n    nodeHandlerMap.put(\"foreach\", new ForEachHandler());\n    nodeHandlerMap.put(\"if\", new IfHandler());\n    nodeHandlerMap.put(\"choose\", new ChooseHandler());\n    nodeHandlerMap.put(\"when\", new IfHandler());\n    nodeHandlerMap.put(\"otherwise\", new OtherwiseHandler());\n    nodeHandlerMap.put(\"bind\", new BindHandler());\n}\n```\n\n下面以 ForEachHandler 为例进行说明，其余 NodeHandler 实现与之类似。ForEachHandler 类对应动态 SQL 中的 `<foreach/>` 标签，这是一个我十分喜欢的标签，可以很方便的动态构造较长的条件语句。NodeHandler 中仅声明了 `NodeHandler#handleNode` 这一个方法，ForEachHandler 针对该方法的实现如下：\n\n```java\npublic void handleNode(XNode nodeToHandle, List<SqlNode> targetContents) {\n    // 解析 <foreach/> 的子标签\n    MixedSqlNode mixedSqlNode = XMLScriptBuilder.this.parseDynamicTags(nodeToHandle);\n    // 获取属性配置\n    String collection = nodeToHandle.getStringAttribute(\"collection\");\n    String item = nodeToHandle.getStringAttribute(\"item\");\n    String index = nodeToHandle.getStringAttribute(\"index\");\n    String open = nodeToHandle.getStringAttribute(\"open\");\n    String close = nodeToHandle.getStringAttribute(\"close\");\n    String separator = nodeToHandle.getStringAttribute(\"separator\");\n    // 封装为 ForEachSqlNode 对象\n    ForEachSqlNode forEachSqlNode = new ForEachSqlNode(\n        configuration, mixedSqlNode, collection, index, item, open, close, separator);\n    targetContents.add(forEachSqlNode);\n}\n```\n\n方法首先会调用前面介绍的 `XMLScriptBuilder#parseDynamicTags` 方法对占位符进行嵌套解析，然后获取标签相关属性配置，并构造 ForEachSqlNode 对象。ForEachSqlNode 类在后面介绍 SqlNode 类时会进行介绍，这里先不展开。\n\n介绍完了 `XMLScriptBuilder#parseDynamicTags` 方法，我们继续回到该方法调用的地方，即 `XMLScriptBuilder#parseScriptNode` 方法。接下来，MyBatis 会依据 `XMLScriptBuilder#parseDynamicTags` 方法的解析和判定结果分别创建对应的 SqlSource 对象。如果是动态 SQL，则采用 DynamicSqlSource 进行封装，否则采用 RawSqlSource 进行封装。\n\n至此，我们在映射文件或注解中定义的 SQL 语句就被解析封装成对应的 SqlSource 对象驻于内存之中。接下来，MyBatis 会依据配置创建对应的 KeyGenerator 对象，这个留到后面解析 `<selectKey/>` 子标签时再进行说明。最后，MyBatis 会将 SQL 语句标签封装成 MappedStatement 对象，记录到 `Configuration#mappedStatements` 属性中。\n\n##### 解析 include 子标签\n\nMyBatis 在解析 SQL 语句标签时会包含对 `<include/>` 子标签的解析。前面我们曾分析了 `<sql/>` 标签，该标签用于配置可复用的 SQL 语句片段，而 `<include/>` 标签则是用来引用已定义的 `<sql/>` 标签配置。对于 `<include/>` 子标签的解析由 `XMLIncludeTransformer#applyIncludes` 方法实现，该方法首先会尝试获取记录在 Configuration 配置对象中记录的 `<properties/>` 等属性变量，然后调用重载的 `XMLIncludeTransformer#applyIncludes` 方法进行解析，实现如下：\n\n```java\npublic void applyIncludes(Node source) {\n    Properties variablesContext = new Properties();\n    Properties configurationVariables = configuration.getVariables();\n    Optional.ofNullable(configurationVariables).ifPresent(variablesContext::putAll);\n    this.applyIncludes(source, variablesContext, false);\n}\n\nprivate void applyIncludes(Node source, final Properties variablesContext, boolean included) {\n\n    /* 注意：最开始进入本方法时，source 参数对应的标签并不是 <include/>，而是 <select/> 这类标签 */\n\n    // 处理 <include/> 标签\n    if (source.getNodeName().equals(\"include\")) {\n        // 获取 refid 指向的 <sql/> 标签对象的深拷贝\n        Node toInclude = this.findSqlFragment(this.getStringAttribute(source, \"refid\"), variablesContext);\n        // 获取 <include/> 标签下的 <property/> 子标签列表，与 variablesContext 合并返回新的 Properties 对象\n        Properties toIncludeContext = this.getVariablesContext(source, variablesContext);\n        // 递归处理，这里的 included 参数为 true\n        this.applyIncludes(toInclude, toIncludeContext, true);\n        if (toInclude.getOwnerDocument() != source.getOwnerDocument()) {\n            toInclude = source.getOwnerDocument().importNode(toInclude, true);\n        }\n        // 替换 <include/> 标签为 <sql/> 标签\n        source.getParentNode().replaceChild(toInclude, source);\n        while (toInclude.hasChildNodes()) {\n            // 将 <sql/> 的子标签添加到 <sql/> 标签的前面\n            toInclude.getParentNode().insertBefore(toInclude.getFirstChild(), toInclude);\n        }\n        // 删除 <sql/> 标签\n        toInclude.getParentNode().removeChild(toInclude);\n    } else if (source.getNodeType() == Node.ELEMENT_NODE) {\n        if (included && !variablesContext.isEmpty()) {\n            // 解析 ${} 占位符\n            NamedNodeMap attributes = source.getAttributes();\n            for (int i = 0; i < attributes.getLength(); i++) {\n                Node attr = attributes.item(i);\n                attr.setNodeValue(PropertyParser.parse(attr.getNodeValue(), variablesContext));\n            }\n        }\n        // 遍历处理当前 SQL 语句标签的子标签\n        NodeList children = source.getChildNodes();\n        for (int i = 0; i < children.getLength(); i++) {\n            // 递归调用\n            this.applyIncludes(children.item(i), variablesContext, included);\n        }\n    } else if (included\n        && (source.getNodeType() == Node.TEXT_NODE || source.getNodeType() == Node.CDATA_SECTION_NODE)\n        && !variablesContext.isEmpty()) {\n        // 替换占位符为 variablesContext 中对应的配置值，这里替换的是引用 <sql/> 标签中定义的语句片段中对应的占位符\n        source.setNodeValue(PropertyParser.parse(source.getNodeValue(), variablesContext));\n    }\n}\n```\n\n第一次进入上述方法时，参数 source 对应的并不是一个 `<include/>` 标签，由参数可以推导出它是一个具体的 SQL 语句标签（即 `Node.ELEMENT_NODE`），所以方法一开始会进入中间的 `else if` 代码块（注意，最开始调用 `XMLIncludeTransformer#applyIncludes` 方法时传递的 included 参数为 false，所以对于 SQL 语句标签下面的 `Node.TEXT_NODE` 类型字面值是不会进入最后一个 `else if` 代码块的）。在这里会获取 SQL 语句标签的所有子标签，并递归调用 `XMLIncludeTransformer#applyIncludes` 方法进行处理，只有当存在 `<include/>` 标签时才会继续执行下面的逻辑。如果当前是 `<include/>` 标签，则会尝试获取 refid 属性，并对属性值中的占位符进行解析替换，然后从 `Configuration#sqlFragments` 属性中获取 id 对应的 `<sql/>` 标签节点的深拷贝对象。相关实现如下：\n\n```java\nprivate Node findSqlFragment(String refid, Properties variables) {\n    // 解析带有 ${} 占位符的字符串，将其中的占位符变量替换成 variables 中对应的属性值\n    refid = PropertyParser.parse(refid, variables);  // 注意：这里替换的并不是 <sql/> 语句片段中的占位符\n    refid = builderAssistant.applyCurrentNamespace(refid, true);\n    try {\n        // 从 Configuration#sqlFragments 中获取 id 对应的 <sql/> 标签\n        XNode nodeToInclude = configuration.getSqlFragments().get(refid);\n        // 返回节点的深拷贝对象\n        return nodeToInclude.getNode().cloneNode(true);\n    } catch (IllegalArgumentException e) {\n        throw new IncompleteElementException(\"Could not find SQL statement to include with refid '\" + refid + \"'\", e);\n    }\n}\n```\n\n接下来会尝试获取 `<include/>` 标签下的 `<property/>` 子标签列表，并与入参的 variablesContext 对象合并成为新的 Properties 对象。然后，递归调用 `XMLIncludeTransformer#applyIncludes` 方法，此时第三个参数 included 为 true，意味着会进入最后一个 `else if` 代码块。此时会依据之前解析得到的属性值替换引入的 SQL 语句片段中的占位符，最终将对应的 `<include/>` 标签替换成对应解析后的 `<sql/>` 标签，记录到当前所隶属的 SQL 语句标签中。\n\n##### 解析 selectKey 子标签\n\n标签 `<selectKey/>` 用于为不支持自动生成自增主键的数据库或驱动提供主键生成支持，以及获取插入操作返回的主键值。该标签的解析位于 `XMLStatementBuilder#processSelectKeyNodes` 方法中，实现如下：\n\n```java\nprivate void processSelectKeyNodes(String id, Class<?> parameterTypeClass, LanguageDriver langDriver) {\n    // 获取所有的 <selectKey/> 标签\n    List<XNode> selectKeyNodes = context.evalNodes(\"selectKey\");\n    // 解析 <selectKey/> 标签\n    if (configuration.getDatabaseId() != null) {\n        this.parseSelectKeyNodes(id, selectKeyNodes, parameterTypeClass, langDriver, configuration.getDatabaseId());\n    }\n    this.parseSelectKeyNodes(id, selectKeyNodes, parameterTypeClass, langDriver, null);\n    // 移除 <selectKey/> 标签\n    this.removeSelectKeyNodes(selectKeyNodes);\n}\n\nprivate void parseSelectKeyNodes(\n    String parentId, List<XNode> list, Class<?> parameterTypeClass, LanguageDriver langDriver, String skRequiredDatabaseId) {\n    // 遍历处理所有的 <selectKey/> 标签\n    for (XNode nodeToHandle : list) {\n        String id = parentId + SelectKeyGenerator.SELECT_KEY_SUFFIX;\n        String databaseId = nodeToHandle.getStringAttribute(\"databaseId\");\n        // 验证数据库类型是否匹配，忽略不匹配的 <selectKey/> 标签\n        if (this.databaseIdMatchesCurrent(id, databaseId, skRequiredDatabaseId)) {\n            this.parseSelectKeyNode(id, nodeToHandle, parameterTypeClass, langDriver, databaseId);\n        }\n    }\n}\n```\n\n上述方法执行过程如代码注释，核心步骤位于 `XMLStatementBuilder#parseSelectKeyNode` 方法中。该方法首先会获取 `<selectKey/>` 相应的属性配置，然后封装定义的 SQL 语句为 SqlSource 对象，最后将整个 `<selectKey/>` 配置封装成为 MappedStatement 对象记录到 `Configuration#mappedStatements` 属性中，同时创建对应的 KeyGenerator 对象，记录到 `Configuration#keyGenerators` 属性中。方法 `XMLStatementBuilder#parseSelectKeyNode` 实现如下：\n\n```java\nprivate void parseSelectKeyNode(\n    String id, XNode nodeToHandle, Class<?> parameterTypeClass, LanguageDriver langDriver, String databaseId) {\n\n    /* 获取相应属性配置 */\n\n    // 解析结果类型配置\n    String resultType = nodeToHandle.getStringAttribute(\"resultType\");\n    Class<?> resultTypeClass = this.resolveClass(resultType);\n    // 解析 statementType 配置，默认使用 PreparedStatement\n    StatementType statementType = StatementType.valueOf(\n        nodeToHandle.getStringAttribute(\"statementType\", StatementType.PREPARED.toString()));\n    // 标签 <selectKey/> 生成结果应用的目标属性，多个用逗号分隔个\n    String keyProperty = nodeToHandle.getStringAttribute(\"keyProperty\");\n    // 匹配属性的返回结果集中的列名称，多个以逗号分隔\n    String keyColumn = nodeToHandle.getStringAttribute(\"keyColumn\");\n    // 设置在目标语句前还是后执行\n    boolean executeBefore = \"BEFORE\".equals(nodeToHandle.getStringAttribute(\"order\", \"AFTER\"));\n\n    // 设置默认值\n    boolean useCache = false;\n    boolean resultOrdered = false;\n    KeyGenerator keyGenerator = NoKeyGenerator.INSTANCE;\n    Integer fetchSize = null;\n    Integer timeout = null;\n    boolean flushCache = false;\n    String parameterMap = null;\n    String resultMap = null;\n    ResultSetType resultSetTypeEnum = null;\n\n    // 创建对应的 SqlSource 对象（用于封装配置的 SQL 语句，此时的 SQL 语句仍不可执行），默认使用的是 XMLLanguageDriver\n    SqlSource sqlSource = langDriver.createSqlSource(configuration, nodeToHandle, parameterTypeClass);\n    SqlCommandType sqlCommandType = SqlCommandType.SELECT;\n\n    // 创建 SQL 对应的 MappedStatement 对象，记录到 Configuration#mappedStatements 属性中\n    builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType,\n        fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass,\n        resultSetTypeEnum, flushCache, useCache, resultOrdered,\n        keyGenerator, keyProperty, keyColumn, databaseId, langDriver, null);\n\n    id = builderAssistant.applyCurrentNamespace(id, false);\n\n    MappedStatement keyStatement = configuration.getMappedStatement(id, false);\n    // 创建对应的 KeyGenerator，记录到 Configuration#keyGenerators 属性中\n    configuration.addKeyGenerator(id, new SelectKeyGenerator(keyStatement, executeBefore));\n}\n```\n\n在前面解析 SQL 语句标签时包含如下代码段，用于决策 KeyGenerator 具体实现。如果当前标签配置了 `<selectKey/>` 标签则优先从 `Configuration#keyGenerators` 属性中获取，也就是上面记录到该属性中的 SelectKeyGenerator 对象。对于未配置 `<selectKey/>` 标签的 SQL 语句标签，则会判断当前标签是否有设置 useGeneratedKeys 属性（即使用 JDBC 的 getGeneratedKeys 方法取出由数据库内部生成的主键），或者判断当前是否有设置全局的 useGeneratedKeys 属性，以及当前是否是 INSERT 数据库操作类型以决策具体的 KeyGenerator 实现。\n\n```java\n// 解析对应的 KeyGenerator 实现，用于生成填充 keyProperty 属性指定的列值\nKeyGenerator keyGenerator;\nString keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX;\nkeyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, true);\n// 当前 SQL 语句标签下存在 <selectKey/> 配置，直接获取对应的 SelectKeyGenerator\nif (configuration.hasKeyGenerator(keyStatementId)) {\n    keyGenerator = configuration.getKeyGenerator(keyStatementId);\n}\n// 当前 SQL 语句标签下不存在 <selectKey/> 配置\nelse {\n    // 依据当前标签的 useGeneratedKeys 配置，或全局的 useGeneratedKeys 配置，以及是否是 INSERT 方法来决定具体的 keyGenerator 实现\n    // 属性 useGeneratedKeys 仅对 INSERT 和 UPDATE 有用，使用 JDBC 的 getGeneratedKeys 方法取出由数据库内部生成的主键\n    keyGenerator = context.getBooleanAttribute(\"useGeneratedKeys\",\n        configuration.isUseGeneratedKeys() && SqlCommandType.INSERT.equals(sqlCommandType))\n        ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE;\n}\n```\n\n对于 KeyGenerator 接口来说，包含三种实现类：Jdbc3KeyGenerator、NoKeyGenerator 和 SelectKeyGenerator。该接口的定义如下：\n\n```java\npublic interface KeyGenerator {\n    /** 前置操作， order=BEFORE */\n    void processBefore(Executor executor, MappedStatement ms, Statement stmt, Object parameter);\n    /** 后置操作， order=AFTER */\n    void processAfter(Executor executor, MappedStatement ms, Statement stmt, Object parameter);\n}\n```\n\n对于这三种实现而言，其中 NoKeyGenerator 虽然实现了该接口，但是对应方法体全部都是空实现，所以没什么可以分析的，我们接下来分别探究一下 Jdbc3KeyGenerator 和 SelectKeyGenerator 的实现。\n\n- __Jdbc3KeyGenerator__\n\n首先来看 Jdbc3KeyGenerator 实现类，这是一个用于获取数据库自增主键值的实现版本。Jdbc3KeyGenerator 的 `Jdbc3KeyGenerator#processBefore` 方法是一个空实现，主要实现逻辑位于 `Jdbc3KeyGenerator#processAfter` 方法中：\n\n```java\npublic void processAfter(Executor executor, MappedStatement ms, Statement stmt, Object parameter) {\n    this.processBatch(ms, stmt, parameter);\n}\n\npublic void processBatch(MappedStatement ms, Statement stmt, Object parameter) {\n    // 获取 keyProperty 属性配置，用于指定生成结果所映射的目标属性，可能存在多个\n    final String[] keyProperties = ms.getKeyProperties();\n    if (keyProperties == null || keyProperties.length == 0) {\n        return;\n    }\n    // 调用 Statement#getGeneratedKeys 方法获取数据库自动生成的主键\n    try (ResultSet rs = stmt.getGeneratedKeys()) {\n        // 获取 ResultSet 元数据信息\n        final ResultSetMetaData rsmd = rs.getMetaData();\n        final Configuration configuration = ms.getConfiguration();\n        if (rsmd.getColumnCount() < keyProperties.length) {\n            // Error?\n        } else {\n            // 使用主键值填充 parameter 目标属性\n            this.assignKeys(configuration, rs, rsmd, keyProperties, parameter);\n        }\n    } catch (Exception e) {\n        throw new ExecutorException(\"Error getting generated key or setting result to parameter object. Cause: \" + e, e);\n    }\n}\n\nprivate void assignKeys(Configuration configuration,\n                        ResultSet rs,\n                        ResultSetMetaData rsmd,\n                        String[] keyProperties,\n                        Object parameter) throws SQLException {\n    if (parameter instanceof ParamMap || parameter instanceof StrictMap) {\n        // Multi-param or single param with @Param\n        this.assignKeysToParamMap(configuration, rs, rsmd, keyProperties, (Map<String, ?>) parameter);\n    } else if (parameter instanceof ArrayList\n        && !((ArrayList<?>) parameter).isEmpty()\n        && ((ArrayList<?>) parameter).get(0) instanceof ParamMap) {\n        // Multi-param or single param with @Param in batch operation\n        this.assignKeysToParamMapList(configuration, rs, rsmd, keyProperties, (ArrayList<ParamMap<?>>) parameter);\n    } else {\n        // Single param without @Param\n        this.assignKeysToParam(configuration, rs, rsmd, keyProperties, parameter);\n    }\n}\n```\n\n上述实现的主要逻辑就是获取数据库自增的主键值，并设置到用户传递实参（parameter）的相应属性中。用户指定的实参可以是一个具体的实体类对象、Map 对象，以及集合类型，上述方法会依据入参类型分而治之。以 t_user 这张数据表为例，假设有如下插入语句：\n\n```xml\n<insert id=\"insert\" parameterType=\"org.zhenchao.mybatis.entity.User\" useGeneratedKeys=\"true\" keyProperty=\"id\">\n    insert into t_user (username, password, age, phone, email)\n    values (#{username,jdbcType=VARCHAR}, #{password,jdbcType=VARCHAR},\n            #{age,jdbcType=INTEGER}, #{phone,jdbcType=VARCHAR}, #{email,jdbcType=VARCHAR})\n</insert>\n```\n\n那么 MyBatis 在执行插入时会先获取到数据库的自增 ID 值，并填充到 User 对象中。这里最终会调用 `Jdbc3KeyGenerator#assignKeysToParam` 方法填充目标属性值，实现如下：\n\n```java\nprivate void assignKeysToParam(Configuration configuration,\n                               ResultSet rs,\n                               ResultSetMetaData rsmd,\n                               String[] keyProperties,\n                               Object parameter) throws SQLException {\n    // 将 Object 类型参数转换成相应的集合类型\n    Collection<?> params = collectionize(parameter);\n    if (params.isEmpty()) {\n        return;\n    }\n    // 遍历为每个目标属性配置创建对应的 KeyAssigner 分配器\n    List<KeyAssigner> assignerList = new ArrayList<>();\n    for (int i = 0; i < keyProperties.length; i++) {\n        assignerList.add(new KeyAssigner(configuration, rsmd, i + 1, null, keyProperties[i]));\n    }\n    // 遍历填充目标属性\n    Iterator<?> iterator = params.iterator();\n    while (rs.next()) {\n        if (!iterator.hasNext()) {\n            throw new ExecutorException(String.format(MSG_TOO_MANY_KEYS, params.size()));\n        }\n        Object param = iterator.next();\n        // 基于 KeyAssigner 使用自增 ID 填充目标属性\n        assignerList.forEach(x -> x.assign(rs, param));\n    }\n}\n\n// org.apache.ibatis.executor.keygen.Jdbc3KeyGenerator.KeyAssigner#assign\nprotected void assign(ResultSet rs, Object param) {\n    if (paramName != null) {\n        // If paramName is set, param is ParamMap\n        param = ((ParamMap<?>) param).get(paramName);\n    }\n    // 创建实参对应的 MetaObject 对象，以实现对于实参对象的反射操作\n    MetaObject metaParam = configuration.newMetaObject(param);\n    try {\n        if (typeHandler == null) {\n            // 创建目标属性对应的类型处理器\n            if (metaParam.hasSetter(propertyName)) {\n                Class<?> propertyType = metaParam.getSetterType(propertyName);\n                typeHandler = typeHandlerRegistry.getTypeHandler(\n                    propertyType, JdbcType.forCode(rsmd.getColumnType(columnPosition)));\n            } else {\n                throw new ExecutorException(\"No setter found for the keyProperty '\"\n                    + propertyName + \"' in '\" + metaParam.getOriginalObject().getClass().getName() + \"'.\");\n            }\n        }\n        if (typeHandler == null) {\n            // Error?\n        } else {\n            // 设置目标属性值\n            Object value = typeHandler.getResult(rs, columnPosition);\n            metaParam.setValue(propertyName, value);\n        }\n    } catch (SQLException e) {\n        throw new ExecutorException(\"Error getting generated key or setting result to parameter object. Cause: \" + e,\n            e);\n    }\n}\n```\n\n如果对上述实现不能很好的理解，建议 debug 一下，能够豁然开朗。\n\n- __SelectKeyGenerator__\n\nSelectKeyGenerator 主要适用于那些不支持自动生成自增主键的数据库类型，从而为这些数据库生成主键值。SelectKeyGenerator 实现了 keyGenerator 接口中定义的全部方法，但是这些方法本质上均将请求直接委托给 `SelectKeyGenerator#processGeneratedKeys` 方法处理，实现如下：\n\n```java\nprivate void processGeneratedKeys(Executor executor, MappedStatement ms, Object parameter) {\n    try {\n        if (parameter != null && keyStatement != null && keyStatement.getKeyProperties() != null) {\n            // 获取 keyProperty 属性配置，用于指定生成结果所映射的目标属性，可能存在多个\n            String[] keyProperties = keyStatement.getKeyProperties();\n            final Configuration configuration = ms.getConfiguration();\n            // 创建实参 parameter 对应的 MetaObject 对象，便于反射操作\n            final MetaObject metaParam = configuration.newMetaObject(parameter);\n            // 创建 SQL 执行器，并执行 <selectKey/> 中定义的 SQL 语句\n            Executor keyExecutor = configuration.newExecutor(executor.getTransaction(), ExecutorType.SIMPLE);\n            List<Object> values = keyExecutor.query(\n                keyStatement, parameter, RowBounds.DEFAULT, Executor.NO_RESULT_HANDLER);\n\n            /* 处理 <selectKey/> 的返回值，填充目标属性 */\n\n            if (values.size() == 0) {\n                throw new ExecutorException(\"SelectKey returned no data.\");\n            } else if (values.size() > 1) {\n                throw new ExecutorException(\"SelectKey returned more than one value.\");\n            } else {\n                // 创建主键值对应的 MetaObject 对象\n                MetaObject metaResult = configuration.newMetaObject(values.get(0));\n                // 单列主键的情况\n                if (keyProperties.length == 1) {\n                    if (metaResult.hasGetter(keyProperties[0])) {\n                        this.setValue(metaParam, keyProperties[0], metaResult.getValue(keyProperties[0]));\n                    }\n                    // 没有 getter 方法，尝试直接获取属性值\n                    else {\n                        // no getter for the property - maybe just a single value object, so try that\n                        this.setValue(metaParam, keyProperties[0], values.get(0));\n                    }\n                }\n                // 多列主键的情况，依次从主键对象中获取对应的属性记录到用户参数对象中\n                else {\n                    this.handleMultipleProperties(keyProperties, metaParam, metaResult);\n                }\n            }\n        }\n    } catch (ExecutorException e) {\n        throw e;\n    } catch (Exception e) {\n        throw new ExecutorException(\"Error selecting key or setting result to parameter object. Cause: \" + e, e);\n    }\n}\n```\n\nSelectKeyGenerator 会执行 `<selectKey/>` 中定义的 SQL 语句，拿到具体的返回值依据 keyProperty 配置填充目标属性。\n\n### 封装 SQL 语句\n\n上面的分析中曾遇到 SqlNode 和 SqlSource 这两个接口，本小节将对这两个接口及其实现类做一个分析。在这之前我们需要简单了解一下这两个接口各自的作用，由前面的分析我们知道对于一个 SQL 语句标签而言，最后会被封装成为一个 MappedStatement 对象，而标签中定义的 SQL 语句则由 SqlSource 进行表示，SqlNode 则用来定义动态 SQL 节点和文本节点等。\n\n#### SqlNode\n\n由点及面，我们先来看一下 SqlNode 的相关实现。SqlNode 是一个接口，其中仅声明了一个 `SqlNode#apply` 方法，接口定义如下：\n\n```java\npublic interface SqlNode {\n    /** 基于传递的实参，解析动态 SQL 节点 */\n    boolean apply(DynamicContext context);\n}\n```\n\n围绕该接口的实现类的 UML 图如下：\n\n![image](/images/2017/mybatis-sqlnode.png)\n\n下面逐一对 SqlNode 的实现类进行分析。\n\n- __MixedSqlNode__\n\n首先来看一下前面多次遇到的 MixedSqlNode，它通过一个 `MixedSqlNode#contents` 集合属性记录包含的 SqlNode 对象，其 `MixedSqlNode#apply` 方法会遍历该集合并应用记录的各个 SqlNode 对象的 `SqlNode#apply` 方法，实现比较简单。\n\n- __StaticTextSqlNode__\n\n与 MixedSqlNode 实现类似的还包括 StaticTextSqlNode 类。该类采用一个 String 类型的 `StaticTextSqlNode#text` 属性记录非动态的 SQL 节点，其 `StaticTextSqlNode#apply` 方法直接调用 `DynamicContext#appendSql` 方法将记录的 SQL 节点添加到一个 StringBuilder 类型属性中。该属性用于记录 SQL 语句片段，当我们最后调用 `DynamicContext#getSql` 方法时会调用该属性的 toString 方法拼接记录的 SQL 片段，返回最终完整的 SQL 语句。\n\n- __TextSqlNode__\n\nTextSqlNode 用于封装包含占位符 `${}` 的动态 SQL 节点，前面在分析 SQL 语句标签时也曾遇到。该实现类的 `TextSqlNode#apply` 方法定义如下：\n\n```java\npublic boolean apply(DynamicContext context) {\n    // BindingTokenParser 是内部类，基于 DynamicContext#bindings 中的属性解析 SQL 语句中的占位符\n    GenericTokenParser parser = this.createParser(new BindingTokenParser(context, injectionFilter));\n    // 解析并记录 SQL 片段到 DynamicContext 中\n    context.appendSql(parser.parse(text));\n    return true;\n}\n```\n\nGenericTokenParser 的执行逻辑我们之前遇到过多次，它主要用来查找指定标识的占位符（这里的占位符是 `${}`），并基于指定的 TokenHandler 对解析到的占位符变量进行处理。TextSqlNode 内部实现了 TokenHandler 解析器（即 BindingTokenParser），该解析器基于 `DynamicContext#bindings` 属性中记录的参数值解析 SQL 语句中的占位符，并将解析结果记录到 DynamicContext 对象中。\n\n- __VarDeclSqlNode__\n\nVarDeclSqlNode 对应动态 SQL 中的 `<bind/>` 标签，该标签可以从 OGNL 表达式中创建一个变量并将其绑定到上下文中，官方文档中关于该标签的使用示例如下：\n\n```xml\n<select id=\"selectBlogsLike\" resultType=\"Blog\">\n    <bind name=\"pattern\" value=\"'%' + _parameter.getTitle() + '%'\" />\n    SELECT * FROM BLOG WHERE title LIKE #{pattern}\n</select>\n```\n\nVarDeclSqlNode 定义了 `VarDeclSqlNode#name` 和 `VarDeclSqlNode#expression` 两个属性，分别与 `<bind/>` 标签的属性对应。该实现类的 `VarDeclSqlNode#apply` 方法完成了对 OGNL 表达式的解析，并将解析得到的真实值记录到 `DynamicContext#bindings` 属性中：\n\n```java\npublic boolean apply(DynamicContext context) {\n    // 解析 OGNL 表达式对应的值\n    final Object value = OgnlCache.getValue(expression, context.getBindings());\n    // 绑定到上下文中，name 对应属性 <bind/> 标签的 name 属性配置\n    context.bind(name, value);\n    return true;\n}\n```\n\n- __IfSqlNode__\n\nIfSqlNode 对应动态 SQL 的 `<if/>` 标签，这也是我们频繁使用的条件标签。IfSqlNode 的属性定义如下：\n\n```java\n/** 用于解析 <if/> 标签的 test 表达式 */\nprivate final ExpressionEvaluator evaluator;\n/** 记录 <if/> 标签中的 test 表达式 */\nprivate final String test;\n/** 记录 <if/> 标签的子标签 */\nprivate final SqlNode contents;\n```\n\n相应的 `IfSqlNode#apply` 实现会首先调用 `ExpressionEvaluator#evaluateBoolean` 方法判定 `IfSqlNode#test` 属性记录的表达式是否为 true，如果为 true 则应用记录的子标签的 `SqlNode#apply` 方法：\n\n```java\npublic boolean apply(DynamicContext context) {\n    // 检测 test 表达式是否为 true\n    if (evaluator.evaluateBoolean(test, context.getBindings())) {\n        // 执行子标签的 apply 方法\n        contents.apply(context);\n        return true;\n    }\n    return false;\n}\n\n// org.apache.ibatis.scripting.xmltags.ExpressionEvaluator#evaluateBoolean\npublic boolean evaluateBoolean(String expression, Object parameterObject) {\n    // 获取 OGNL 表达式对应的值\n    Object value = OgnlCache.getValue(expression, parameterObject);\n    // 转换为 boolean 类型返回\n    if (value instanceof Boolean) {\n        return (Boolean) value;\n    }\n    if (value instanceof Number) {\n        return new BigDecimal(String.valueOf(value)).compareTo(BigDecimal.ZERO) != 0;\n    }\n    return value != null;\n}\n```\n\n- __ChooseSqlNode__\n\nChooseSqlNode 对应动态 SQL 中的 `<choose/>` 标签，我们通常利用此标签配合 `<when/>` 和 `<otherwise/>` 标签实现 switch 功能，具体使用方式可以参考官方示例。实现层面，MyBatis 并没有定义 WhenSqlNode 和 OtherwiseSqlNode 类与另外两个标签相对应，而是采用 IfSqlNode 表示 `<when/>` 标签，采用 MixedSqlNode 表示 `<otherwise/>` 标签。ChooseSqlNode 类的属性和 `ChooseSqlNode#apply` 方法定义如下：\n\n```java\n/** 对应 <otherwise/> 标签，采用 {@link MixedSqlNode} 表示 */\nprivate final SqlNode defaultSqlNode;\n/** 对应 <when/> 标签，采用 {@link IfSqlNode} 表示 */\nprivate final List<SqlNode> ifSqlNodes;\n\npublic boolean apply(DynamicContext context) {\n    // 遍历应用 <when/> 标签，一旦成功一个就返回\n    for (SqlNode sqlNode : ifSqlNodes) {\n        if (sqlNode.apply(context)) {\n            return true;\n        }\n    }\n    // 所有的 <when/> 都不满足，执行 <otherwise/> 标签\n    if (defaultSqlNode != null) {\n        defaultSqlNode.apply(context);\n        return true;\n    }\n    return false;\n}\n```\n\n- __TrimSqlNode__\n\nTrimSqlNode 对应 `<trim/>` 标签，用于处理动态 SQL 拼接在一些条件下出现不完整 SQL 的情况，具体使用可以参考官方示例。该实现类的属性和 `TrimSqlNode#apply` 方法定义如下：\n\n```java\n/** 记录 <trim/> 标签的子标签 */\nprivate final SqlNode contents;\n/** 期望追加的前缀字符串 */\nprivate final String prefix;\n/** 期望追加的后缀字符串 */\nprivate final String suffix;\n/** 如果 <trim/> 包裹的 SQL 语句为空，则删除指定前缀 */\nprivate final List<String> prefixesToOverride;\n/** 如果 <trim/> 包裹的 SQL 语句为空，则删除指定后缀 */\nprivate final List<String> suffixesToOverride;\n\npublic boolean apply(DynamicContext context) {\n    // 创建 FilteredDynamicContext 对象，封装上下文\n    FilteredDynamicContext filteredDynamicContext = new FilteredDynamicContext(context);\n    // 应用子标签的 apply 方法\n    boolean result = contents.apply(filteredDynamicContext);\n    // 处理前缀和后缀\n    filteredDynamicContext.applyAll();\n    return result;\n}\n```\n\nTrimSqlNode 中定义了内部类 FilteredDynamicContext，它是对上下文对象 DynamicContext 的封装，其 `FilteredDynamicContext#applyAll` 方法实现了对不完整 SQL 的处理。该方法调用 `FilteredDynamicContext#applyPrefix` 和 `FilteredDynamicContext#applySuffix` 方法分别处理 SQL 的前缀和后缀，并将处理完后的 SQL 片段记录到上下文对象中：\n\n```java\npublic void applyAll() {\n    sqlBuffer = new StringBuilder(sqlBuffer.toString().trim());\n    // 全部转换成大写\n    String trimmedUppercaseSql = sqlBuffer.toString().toUpperCase(Locale.ENGLISH);\n    if (trimmedUppercaseSql.length() > 0) {\n        // 处理前缀\n        this.applyPrefix(sqlBuffer, trimmedUppercaseSql);\n        // 处理后缀\n        this.applySuffix(sqlBuffer, trimmedUppercaseSql);\n    }\n    // 添加解析后的结果到 delegate 中\n    delegate.appendSql(sqlBuffer.toString());\n}\n```\n\n方法 `FilteredDynamicContext#applyPrefix` 和 `FilteredDynamicContext#applySuffix` 的实现思路相同，这里以 `FilteredDynamicContext#applyPrefix` 方法为例进行说明。该方法会遍历指定的前缀并判断当前 SQL 片段是否以包含的前缀开头，是的话则会删除该前缀，如果指定了 prefix 属性则会在 SQL 语句片段前面追加对应的前缀值。WhereSqlNode 和 SetSqlNode 均由 TrimSqlNode 派生而来，实现比较简单，不多作撰述。\n\n- __ForEachSqlNode__\n\n最后再来看一下 ForEachSqlNode 类，该类对应 `<foreach/>` 标签，前面我们曾介绍了相关的 ForEachHandler 类实现。ForEachSqlNode 类是所有 SqlNode 实现类中最复杂的一个，其主要的属性定义如下（建议参考官方文档进行理解）：\n\n```java\n/** 标识符 */\npublic static final String ITEM_PREFIX = \"__frch_\";\n/** 用于判断循环的终止条件 */\nprivate final ExpressionEvaluator evaluator;\n/** 迭代的集合表达式 */\nprivate final String collectionExpression;\n/** 记录子标签 */\nprivate final SqlNode contents;\n/** open 标识 */\nprivate final String open;\n/** close 标识 */\nprivate final String close;\n/** 循环过程中，各项之间的分隔符 */\nprivate final String separator;\n/** index 是迭代的次数，item 是当前迭代的元素 */\nprivate final String item;\nprivate final String index;\n```\n\nForEachSqlNode 中定义了两个内部类：FilteredDynamicContext 和 PrefixedContext。\n\n__FilteredDynamicContext__ 由 DynamicContext 派生而来，其中稍复杂的实现是 `FilteredDynamicContext#appendSql` 方法：\n\n```java\npublic void appendSql(String sql) {\n    GenericTokenParser parser = new GenericTokenParser(\"#{\", \"}\", content -> {\n        // 替换 item 为 __frch_item_index\n        String newContent = content.replaceFirst(\"^\\\\s*\" + item + \"(?![^.,:\\\\s])\", itemizeItem(item, index));\n        // 替换 itemIndex 为 __frch_itemIndex_index\n        if (itemIndex != null && newContent.equals(content)) {\n            newContent = content.replaceFirst(\"^\\\\s*\" + itemIndex + \"(?![^.,:\\\\s])\", itemizeItem(itemIndex, index));\n        }\n        // 追加 #{} 标识\n        return \"#{\" + newContent + \"}\";\n    });\n\n    delegate.appendSql(parser.parse(sql));\n}\n```\n\n实际上这里还是之前多次碰到的 GenericTokenParser 解析占位符的套路（这里的占位符是 `#{}`），对应的 `TokenHandler#handleToken` 方法会将 item 替换成 `__frch_item_index` 的形式，拼接的过程由 `ForEachSqlNode#itemizeItem` 方法实现:\n\n```java\nprivate static String itemizeItem(String item, int i) {\n    // 返回 __frch_item_i 的形式\n    return new StringBuilder(ITEM_PREFIX).append(item).append(\"_\").append(i).toString();\n}\n```\n\n__PrefixedContext__ 也派生自 DynamicContext 类，在遍历集合拼接时主要用于封装一个由指定前缀和集合元素组成的基本元组，具体实现比较简单。\n\n回到 ForEachSqlNode 类本身，继续来看 `ForEachSqlNode#apply` 方法实现：\n\n```java\npublic boolean apply(DynamicContext context) {\n    Map<String, Object> bindings = context.getBindings();\n    // 解析集合 OGNL 表达式对应的值，返回值对应的迭代器\n    final Iterable<?> iterable = evaluator.evaluateIterable(collectionExpression, bindings);\n    if (!iterable.iterator().hasNext()) {\n        return true;\n    }\n    boolean first = true;\n    // 添加 open 前缀标识\n    this.applyOpen(context);\n    int i = 0;\n    // 迭代处理集合\n    for (Object o : iterable) {\n        // 备份一下上下文对象\n        DynamicContext oldContext = context;\n        // 第一次遍历，或未指定分隔符\n        if (first || separator == null) {\n            context = new PrefixedContext(context, \"\");\n        }\n        // 其它情况\n        else {\n            context = new PrefixedContext(context, separator);\n        }\n        int uniqueNumber = context.getUniqueNumber();\n        // 如果是 Map 类型，将 key 和 value 记录到 DynamicContext#bindings 属性中\n        if (o instanceof Map.Entry) {\n            @SuppressWarnings(\"unchecked\")\n            Map.Entry<Object, Object> mapEntry = (Map.Entry<Object, Object>) o;\n            this.applyIndex(context, mapEntry.getKey(), uniqueNumber);\n            this.applyItem(context, mapEntry.getValue(), uniqueNumber);\n        }\n        // 将当前索引值和元素记录到 DynamicContext#bindings 属性中\n        else {\n            this.applyIndex(context, i, uniqueNumber);\n            this.applyItem(context, o, uniqueNumber);\n        }\n        // 应用子标签的 apply 方法\n        contents.apply(new FilteredDynamicContext(configuration, context, index, item, uniqueNumber));\n        if (first) {\n            first = !((PrefixedContext) context).isPrefixApplied();\n        }\n        // 恢复上下文对象\n        context = oldContext;\n        i++;\n    }\n    // 添加 close 后缀标识\n    this.applyClose(context);\n    context.getBindings().remove(item);\n    context.getBindings().remove(index);\n    return true;\n}\n```\n\n上述方法的执行过程阅读起来没什么压力，但就是不知道具体在做什么事情。下面我们以批量查询用户信息表 t_user 中的多个用户信息为例来走一遍上述方法的执行过程，对应的动态查询语句定义如下：\n\n```xml\n<select id=\"selectByIds\" parameterType=\"java.util.List\" resultMap=\"BaseResultMap\">\n    SELECT * FROM t_user WHERE id IN\n    <foreach collection=\"ids\" index=\"idx\" item=\"itm\" open=\"(\" close=\")\" separator=\",\">\n        #{itm}\n    </foreach>\n</select>\n```\n\n假设我们现在希望查询 id 为 1 和 2 的两个用户，执行流程可以表述如下：\n\n1. 解析获取到集合表达式对应的集合迭代器对象，这里对应的是一个 List 类型集合的迭代器，其中包含了 1 和 2 两个元素；\n2. 调用 `ForEachSqlNode#applyOpen` 方法添加 OPEN 标识符，这里即 `(`；\n3. 进入 for 循环，因为是第一次遍历，所以会创建 prefix 参数为空字符串的 PrefixedContext 对象；\n4. 这里集合类型中封装的是 Long 类型（不是 Map 类型）：\n    - 调用 `ForEachSqlNode#applyIndex` 方法，记录键值对 `(idx, 0)` 和 `(__frch_idx_0, 0)` 到 `DynamicContext#bindings` 属性中；\n    - 调用 `ForEachSqlNode#applyItem` 方法，记录键值对 `(itm, 1)` 和 `(__frch_itm_0, 1)` 到 `DynamicContext#bindings` 中；\n5. 应用子标签的 `SqlNode#apply` 方法，这里会触发 `FilteredDynamicContext#appendSql` 方法解析占位符 `#{itm}` 为 `#{__frch_itm_0}`，此时生成的 SQL 语句片段已然成为 `SELECT * FROM t_user WHERE id IN ( #{__frch_itm_0}`；\n6. 进入 for 循环的第二次遍历，此时 first 变量已经置为 false，且这里设置了分隔符，所以执行 `new PrefixedContext(context, separator)` 创建上下文对象；\n7. 这里集合类型同样是 Long 类型（不是 Map 类型）：\n    - 调用 `ForEachSqlNode#applyIndex` 方法，记录键值对 `(idx, 1)` 和 `(__frch_idx_1, 1)` 到 `DynamicContext#bindings` 属性中；\n    - 调用 `ForEachSqlNode#applyItem` 方法，记录键值对 `(itm, 2)` 和 `(__frch_itm_1, 2)` 到 `DynamicContext#bindings` 属性中；\n8. 应用子标签的 `SqlNode#apply` 方法，这里会触发 `FilteredDynamicContext#appendSql` 方法解析占位符 `#{itm}` 为 `#{__frch_itm_1}`，此时生成的 SQL 语句片段已然成为 `SELECT * FROM t_user WHERE id IN ( #{__frch_itm_0}, #{__frch_itm_1}`\n9. for 循环结束，调用 `ForEachSqlNode#applyClose` 追加 CLOSE 标识符，这里即 `)`。\n\n最后解析得到的 SQL 为 `SELECT * FROM t_user WHERE id IN ( #{__frch_itm_0} , #{__frch_itm_1} )`。希望通过这样一个过程辅助读者进行理解，如果还是云里雾里可以 debug 一下整个过程。\n\n#### SqlSource\n\n前面介绍了 SqlSource 用于表示映射文件或注解定义的 SQL 语句标签中的 SQL 语句，但是这里的 SQL 语句并不是可执行的，其中可能包含一些动态占位符。SqlSource 接口的定义如下：\n\n```java\npublic interface SqlSource {\n\n    /**\n     * 基于传入的参数返回可执行的 SQL 语句\n     *\n     * @param parameterObject 用户传递的实参\n     * @return\n     */\n    BoundSql getBoundSql(Object parameterObject);\n\n}\n```\n\n围绕该接口的实现类的 UML 图如下：\n\n![image](/images/2017/mybatis-sqlsource.png)\n\n其中，RawSqlSource 用于封装静态定义的 SQL 语句；DynamicSqlSource 用于封装动态定义的 SQL 语句；ProviderSqlSource 则用于封装注解形式定义的 SQL 语句。不管是动态还是静态的 SQL 语句，经过处理之后都会封装成为 StaticSqlSource 对象，其中包含的 SQL 语句是可以直接执行的。\n\n考虑 MyBatis 目前还是主推 XML 的配置使用方式，所以不打算对 ProviderSqlSource 展开说明。在开始分析剩余三个实现类之前，需要先对这几个类共享的一个核心组件 SqlSourceBuilder 进行分析。SqlSourceBuilder 继承自 BaseBuilder，主要用于解析前面经过 `SqlNode#apply` 方法处理的 SQL 语句中的占位符属性，同时将占位符替换成  `?` 字符串。\n\nSqlSourceBuilder 中仅定义了一个 `SqlSourceBuilder#parse` 方法，实现了对占位符 `#{}` 中属性的解析，并将占位符替换成 `?`。最终将解析得到的 SQL 语句和相关参数封装成 StaticSqlSource 对象返回。方法 `SqlSourceBuilder#parse` 的实现如下：\n\n```java\npublic SqlSource parse(\n    String originalSql, // 经过 SqlNode#apply 方法处理后的 SQL 语句\n    Class<?> parameterType, // 用户传递的实参类型\n    Map<String, Object> additionalParameters) { // 记录形参与实参之间的对应关系，即 SqlNode#apply 方法处理之后记录在 DynamicContext#bindings 属性中的键值对\n    // 创建 ParameterMappingTokenHandler 对象，用于解析 #{} 占位符\n    ParameterMappingTokenHandler handler =\n        new ParameterMappingTokenHandler(configuration, parameterType, additionalParameters);\n    GenericTokenParser parser = new GenericTokenParser(\"#{\", \"}\", handler);\n    String sql = parser.parse(originalSql); // SELECT * FROM t_user WHERE id IN ( ? , ? )\n    // 构造 StaticSqlSource 对象，其中封装了被替换成 ? 的 SQL 语句，以及参数对应的 ParameterMapping 集合\n    return new StaticSqlSource(configuration, sql, handler.getParameterMappings());\n}\n```\n\n该方法的实现还是我们熟悉的套路，获取指定占位符中的属性，然后交由对应的 TokenHandler 进行处理。SqlSourceBuilder 定义了 ParameterMappingTokenHandler 内部类，这是一个具体的 TokenHandler 实现，该内部类同时还继承自 BaseBuilder 抽象类，对应的 `ParameterMappingTokenHandler#handleToken` 方法实现如下;\n\n```java\npublic String handleToken(String content) { // 占位符中定义的属性，例如 __frch_itm_0\n    // 调用 buildParameterMapping 方法构造当前 content 对应的 ParameterMapping 对象，并记录到 parameterMappings 集合中\n    // ParameterMapping{property='__frch_itm_0', mode=IN, javaType=class java.lang.Long, jdbcType=null, numericScale=null, resultMapId='null', jdbcTypeName='null', expression='null'}\n    parameterMappings.add(this.buildParameterMapping(content));\n    // 全部返回 ? 字符串\n    return \"?\";\n}\n```\n\n上述方法会调用 `ParameterMappingTokenHandler#buildParameterMapping` 方法构造实参 content （占位符中的属性）对应的 ParameterMapping 对象，并记录到 `ParameterMappingTokenHandler#parameterMappings` 属性中，同时返回 `?` 占位符将原始 SQL 中对应的占位符全部替换成 `?` 字符。这里我们以前面 `SqlNode#apply` 方法解析得到的 `SELECT * FROM t_user WHERE id IN ( #{__frch_itm_0} , #{__frch_itm_1} )` 为例，该 SQL 语句经过 `SqlSourceBuilder#parse` 方法处理之后会被解析成 `SELECT * FROM t_user WHERE id IN ( ? , ? )` 的形式封装到 StaticSqlSource 对象中。对应的 `ParameterMappingTokenHandler#parameterMappings` 参数内容如下：\n\n```text\nParameterMapping{property='__frch_itm_0', mode=IN, javaType=class java.lang.Long, jdbcType=null, numericScale=null, resultMapId='null', jdbcTypeName='null', expression='null'}\nParameterMapping{property='__frch_itm_1', mode=IN, javaType=class java.lang.Long, jdbcType=null, numericScale=null, resultMapId='null', jdbcTypeName='null', expression='null'}\n```\n\n了解了 SqlSourceBuilder 的作用，我们回头来看 DynamicSqlSource 的实现就会比较容易，DynamicSqlSource 实现了 SqlSource 接口中声明的 `SqlSource#getBoundSql` 方法，如下：\n\n```java\npublic BoundSql getBoundSql(Object parameterObject) {\n    // 构造上下文对象\n    DynamicContext context = new DynamicContext(configuration, parameterObject);\n    // 应用 SqlNode#apply 方法（树型结构，会遍历应用树中各个节点的 SqlNode#apply 方法），各司其职追加 SQL 片段到上下文中\n    rootSqlNode.apply(context);\n    // 创建 SqlSourceBuilder 对象，解析占位符属性，并将 SQL 语句中的 #{} 占位符替换成 ? 字符\n    SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration);\n    Class<?> parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); // 解析用户实参类型\n    SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); // 解析并封装结果为 StaticSqlSource 对象\n    // 基于 SqlSourceBuilder 解析结果和实参创建 BoundSql 对象\n    BoundSql boundSql = sqlSource.getBoundSql(parameterObject);\n    // 将 DynamicContext#bindings 中的参数信息复制到 BoundSql#additionalParameters 属性中\n    context.getBindings().forEach(boundSql::setAdditionalParameter);\n    return boundSql;\n}\n```\n\n该方法最终会将解析得到的 SQL 语句，以及相应的参数全部封装到 BoundSql 对象中返回，具体过程可以参考上述代码注释。\n\n相对于 DynamicSqlSource 来说，RawSqlSource 的 `RawSqlSource#getBoundSql` 方法实现就要简单了许多。RawSqlSource 直接将请求委托给了 StaticSqlSource 处理，本质上就是基于用户传递的参数来构造 BoundSql 对象。对应 SQL 的解析则放置在构造方法中，在构造方法中会调用 `RawSqlSource#getSql` 方法获取对应的 SQL 定义，同样基于 SqlSourceBuilder 对原始 SQL 语句进行解析，封装成 StaticSqlSource 对象记录到属性中，在实际运行时只要填充参数即可。这也是很容易理解的，毕竟对于静态 SQL 来说，它的模式在整个应用程序运行过程中是不变的，所以在系统初始化时完成解析操作，后续可以直接拿来使用，但是对于动态 SQL 来说，SQL 语句的具体模式取决于用户传递的参数，需要在运行时实时解析。\n\n### 绑定 Mapper 接口\n\n饶了一大圈，看起来我们似乎完成了对映射文件的加载和解析工作，实际上我们确实完成了对映射文件的解析，但是光解析还是不够的，实际开发中我们对于这些定义在映射文件中的 SQL 语句的调用一般都是通过 Mapper 接口完成。所以还需要建立映射文件与具体 Mapper 接口之间的映射关系，这一过程由 `XMLMapperBuilder#bindMapperForNamespace` 方法实现：\n\n```java\nprivate void bindMapperForNamespace() {\n    // 获取当前映射文件的 namespace 配置\n    String namespace = builderAssistant.getCurrentNamespace();\n    if (namespace != null) {\n        Class<?> boundType = null;\n        try {\n            // 解析 namespace 对应的 Mapper 接口类型\n            boundType = Resources.classForName(namespace);\n        } catch (ClassNotFoundException e) {\n            // ignore, bound type is not required\n        }\n        if (boundType != null) {\n            // 当前 Mapper 还未加载\n            if (!configuration.hasMapper(boundType)) {\n                // Spring may not know the real resource name so we set a flag\n                // to prevent loading again this resource from the mapper interface\n                // look at MapperAnnotationBuilder#loadXmlResource\n                // 记录当前已经加载的 namespace 标识到 Configuration#loadedResources 属性中\n                configuration.addLoadedResource(\"namespace:\" + namespace);\n                // 注册对应的 Mapper 接口到 Configuration#mapperRegistry 属性中（对应 MapperRegistry）\n                configuration.addMapper(boundType);\n            }\n        }\n    }\n}\n```\n\n上述方法首先会获取对应映射文件的命名空间，然后构造命名空间字面量对应的 Class 类型，并记录到 Configuration 对象中。这里本质上调用的是 `MapperRegistry#addMapper` 方法执行注册操作，MapperRegistry 的实现之前已经分析过，这里就不再重复说明。\n\n### 处理解析失败的标签\n\n在前面分析解析过程时，对于一些解析异常的标签会记录到 Configuration 对象的相应属性中，包括 SQL 语句标签、`<resultMap/>` 标签，以及 `<cache-ref/>` 标签。需要说明的是这些记录的标签不一定全是解析异常所致，有些标签的解析存在依赖关系，如果 A 依赖于 B，在解析 A 时 B 还未被解析，MyBatis 则会将标签 A 记录起来，等到最后再尝试解析。在映射文件解析过程的最后会再次尝试对这些标签进行解析，如下面的代码所示：\n\n```java\n// 处理解析失败的 <resultMap/> 标签\nthis.parsePendingResultMaps();\n// 处理解析失败的 <cache-ref/> 标签\nthis.parsePendingCacheRefs();\n// 处理解析失败的 SQL 语句标签\nthis.parsePendingStatements();\n```\n\n这些再次触发解析的方法在实现上都是一个思路，就是从 Configuration 对象中获取解析失败的标签对象集合，然后遍历执行相应的解析方法，前面已经对这些标签的解析过程进行了分析，不再重复。\n\n### 总结\n\n至此，我们算是真正完成了对映射文件的加载与解析工作，也基本上完成了 MyBatis 框架的初始化过程，接下来可以创建 SqlSession 对象，并执行具体的数据库操作。在下一篇中，我们将一起来分析 MyBatis 执行 SQL 语句的具体过程实现，包括获取 SQL 语句、绑定参数、执行数据库操作，以及结果集映射等操作。\n\n### 参考\n\n1. [MyBatis 官方文档](https://mybatis.org/mybatis-3/zh/index.html)\n2. [MyBatis 技术内幕](https://book.douban.com/subject/27087564/)\n","tags":["MyBatis"],"categories":["mybatis"]},{"title":"MyBatis 源码解析：配置文件的加载与解析","url":"/2017/10/12/mybatis/mybatis-config/","content":"\n上一篇我们曾约定 `mybatis-config.xml` 文件为配置文件，SQL 语句配置文件为映射文件，本文我们将沿用上一篇中的示例程序，一起探究一下 MyBatis 加载和解析配置文件（即 `mybatis-config.xml`）的过程。\n\n### 配置文件的加载过程\n\n在示例程序中，执行配置文件（包括后面要介绍的映射文件）加载与解析的过程位于第一行代码中（如下）。其中，Resources 是一个简单的基于类路径或其它位置获取数据流的工具类，借助该工具类可以获取配置文件的 InputStream 流对象，然后将其传递给 `SqlSessionFactoryBuilder#build` 方法以构造 SqlSessionFactory 对象。<!-- more -->\n\n```java\nSqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder()\n                .build(Resources.getResourceAsStream(\"mybatis-config.xml\"));\n```\n\nSqlSessionFactoryBuilder 由名字可知它是一个构造器，用于构造 SqlSessionFactory 对象。按照 MyBatis 的官方文档来说，SqlSessionFactoryBuilder 一旦构造完 SqlSessionFactory 对象便完成了其使命。其实现也比较简单，只定义了 `SqlSessionFactoryBuilder#build` 这一个方法及其重载版本，如下：\n\n```java\npublic SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) {\n    try {\n        // 创建 XML 配置文件解析器，期间会创建 Configuration 对象\n        XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);\n        // 解析配置文件填充 Configuration 对象，并基于配置构造 SqlSessionFactory\n        return this.build(parser.parse());\n    } catch (Exception e) {\n        throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e);\n    } finally {\n        // 执行关闭前的清理工作\n        ErrorContext.instance().reset();\n        try {\n            inputStream.close();\n        } catch (IOException e) {\n            // Intentionally ignore. Prefer previous error.\n        }\n    }\n}\n\npublic SqlSessionFactory build(Configuration config) {\n    return new DefaultSqlSessionFactory(config);\n}\n```\n\n上述实现的核心在于如下两行：\n\n```java\n1. XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);\n2. return this.build(parser.parse());\n```\n\n第一行用来构造 XMLConfigBuilder 对象，XMLConfigBuilder 可以看作是 `mybatis-config.xml` 配置文件的解析器；第二行则调用该对象的 `XMLConfigBuilder#parse` 方法对配置文件进行解析，并记录相关配置项到 Configuration 对象中，然后基于该配置对象创建 SqlSessionFactory 对象返回。Configuration 可以看作是 MyBatis 框架内部全局唯一的配置类，用于记录几乎所有的配置和映射，以及运行过程中的中间值。后面我们会经常遇到这个类，现在可以将其理解为 MyBatis 框架的配置中心。\n\n我们来看一下 XMLConfigBuilder 对象的构造过程：\n\n```java\npublic XMLConfigBuilder(InputStream inputStream, String environment, Properties props) {\n    this(\n        // 构造 XPath 解析器\n        new XPathParser(inputStream, true, props, new XMLMapperEntityResolver()),\n        environment,\n        props);\n}\n\nprivate XMLConfigBuilder(XPathParser parser, // XPath 解析器\n                         String environment, // 当前使用的配置文件组 ID\n                         Properties props) // 参数指定的配置项\n{\n    // 构造 Configuration 对象\n    super(new Configuration());\n    ErrorContext.instance().resource(\"SQL Mapper Configuration\");\n    // 将参数指定的配置项记录到 Configuration#variables 属性中\n    this.configuration.setVariables(props);\n    // 标识配置文件还未被解析\n    this.parsed = false;\n    this.environment = environment;\n    this.parser = parser;\n}\n```\n\n构造方法各参数的释义见代码注释。这里针对一些比较不太直观的参数作进一步说明，首先看一下 XPathParser 类型的构造参数。我们需要知道的一点是，MyBatis 基于 DOM 树对 XML 配置文件进行解析，而操作 DOM 树的方式则是基于 [XPath(XML Path Language)](https://zh.wikipedia.org/wiki/XPath)。它是一种能够极大简化 XML 操作的路径语言，优点在于简单、直观，并且好用，没有接触过的同学可以针对性的学习一下。XPathParser 基于 XPath 语法对 XML 进行解析，其实现比较简单，这里不展开说明。\n\n接着看一下 environment 参数。基于配置的框架一般都允许配置多套环境，以应对开发、测试、灰度，以及生产环境。除了后面会讲到的 `<environment/>` 配置，MyBatis 也允许我们通过参数指定实际生效的配置环境，我们在调用 `SqlSessionFactoryBuilder#build` 方法时，可以以参数形式指定当前使用的配置环境。\n\n### 配置文件的解析过程\n\n完成了 XMLConfigBuilder 对象的构造，下一步会调用其 `XMLConfigBuilder#parse` 方法执行对配置文件的解析操作。在具体分析配置文件的解析过程之前，先简单介绍一下后续过程依赖的一些基础组件。\n\n上面用到的 XMLConfigBuilder 类派生自 BaseBuilder 抽象类，包括后面会介绍的 XMLMapperBuilder、XMLStatementBuilder，以及 SqlSourceBuilder 等都继承自该抽象类。先来看一下 BaseBuilder 的字段定义：\n\n```java\n/** 全局唯一的配置对象 */\nprotected final Configuration configuration;\n/** 记录别名与类型的映射关系 */\nprotected final TypeAliasRegistry typeAliasRegistry;\n/** 记录类型对应的类型处理器 */\nprotected final TypeHandlerRegistry typeHandlerRegistry;\n```\n\nBaseBuilder 仅定义了三个属性，各属性的作用见代码注释。XMLConfigBuilder 构造方法调用了父类 BaseBuilder 的构造方法以实现对这三个属性的初始化，前面我们提及到的封装全局配置的 Configuration 对象就记录在这里。接下来分析一下属性 `BaseBuilder#typeAliasRegistry` 和 `BaseBuilder#typeHandlerRegistry` 分别对应的 TypeAliasRegistry 类和 TypeHandlerRegistry 类的功能和实现。\n\n- __TypeAliasRegistry__\n\n我们都知道在编写 SQL 语句时可以为表名或列名定义别名（alias），以减少书写量，而 TypeAliasRegistry 是对别名这一机制的延伸，借助于此，我们可以为任意类型定义别名。\n\nTypeAliasRegistry 中仅定义了一个 Map 类型的属性 `TypeAliasRegistry#typeAliases` 充当内存数据库，记录着别名与具体类型之间的映射关系。TypeAliasRegistry 持有一个无参数的构造方法，其中只做一件事，即调用 `TypeAliasRegistry#registerAlias` 方法为常用类型注册对应的别名。该方法的实现如下：\n\n```java\npublic void registerAlias(String alias, Class<?> value) {\n    if (alias == null) {\n        throw new TypeException(\"The parameter alias cannot be null\");\n    }\n    // 将别名转换成小写\n    String key = alias.toLowerCase(Locale.ENGLISH);\n    // 防止重复注册\n    if (typeAliases.containsKey(key) && typeAliases.get(key) != null && !typeAliases.get(key).equals(value)) {\n        throw new TypeException(\"The alias '\" + alias + \"' is already mapped to the value '\" + typeAliases.get(key).getName() + \"'.\");\n    }\n    // 建立映射关系记录到 Map 中\n    typeAliases.put(key, value);\n}\n```\n\n整个方法的执行过程本质上就是将 `(alias, value)` 键值对写入 Map 集合中，只是在插入之前需要保证 alias 不为 null，且不允许相同的别名和类型重复注册。除了这里的单个注册，TypeAliasRegistry 还提供了 `TypeAliasRegistry#registerAliases` 方法，允许扫描注册指定 package 下面的所有类或指定类型及其子类型。在批量扫描注册时，我们可以利用 `@Alias` 注解为类指定别名，否则 MyBatis 将会以当前类的 simple name 作为类型别名。\n\n当然，能够注册就能够获取，方法 `TypeAliasRegistry#resolveAlias` 提供了获取指定别名对应类型的能力。实现比较简单，无非就是从 Map 集合中获取指定 key 对应的 value。\n\n- __TypeHandlerRegistry__\n\n再来看一下 TypeHandlerRegistry 类，在开始分析之前我们必须对 TypeHandler 接口有一个了解。我们都知道 JDBC 定义的类型（枚举类 JdbcType 对已有 JDBC 类型进行了封装）与 java 定义的类型并不是完全匹配的，所以就需要在这中间执行一些转换操作，而 TypeHandler 的职责就在于此。TypeHandler 是一个接口，其中定义了 4 个方法：\n\n```java\npublic interface TypeHandler<T> {\n\n    /** 为 {@link PreparedStatement} 对象绑定参数（将数据由 java 类型转换成 JDBC 类型） */\n    void setParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException;\n\n    /** 获取结果集中对应的参数值（将数据由 JDBC 类型转换成 java 类型） */\n    T getResult(ResultSet rs, String columnName) throws SQLException;\n    T getResult(ResultSet rs, int columnIndex) throws SQLException;\n\n    /** 获取存储过程中输出类型的参数值（将数据由 JDBC 类型转换成 java 类型） */\n    T getResult(CallableStatement cs, int columnIndex) throws SQLException;\n\n}\n```\n\n围绕 TypeHandler 接口的实现类用于处理特定类型，具体可以参考 [官方文档](https://mybatis.org/mybatis-3/zh/configuration.html#typeHandlers)。\n\n对 TypeHandler 有一个基本认识之后，继续来看 TypeHandlerRegistry。顾名思义，这是一个 TypeHandler 的注册中心。TypeHandlerRegistry 中定义了多个 final 类型 Map 类型属性，以记录类型及其类型处理器 TypeHandler 之间的映射关系，其中最核心的两个属性定义如下：\n\n```java\n/**\n * 记录 JDBC 类型与 {@link TypeHandler} 之间映射关系，\n * 用于从结果集读取数据时，将 JDBC 类型转换对应的 java 类型\n */\nprivate final Map<JdbcType, TypeHandler<?>> jdbcTypeHandlerMap = new EnumMap<>(JdbcType.class);\n\n/**\n * 记录 java 类型转 JDBC 类型时所需要的 {@link TypeHandler}，\n * 一个 java 类型可能存在多个 JDBC 类型\n */\nprivate final Map<Type, Map<JdbcType, TypeHandler<?>>> typeHandlerMap = new ConcurrentHashMap<>();\n```\n\n在构造 TypeHandlerRegistry 对象时，会调用 `TypeHandlerRegistry#register` 方法注册类型及其对应的类型处理器，实现如下：\n\n```java\nprivate void register(Type javaType, JdbcType jdbcType, TypeHandler<?> handler) {\n    // 如果 javaType 不为空，则添加对应的类型处理器到 typeHandlerMap 集合中\n    if (javaType != null) {\n        Map<JdbcType, TypeHandler<?>> map = typeHandlerMap.get(javaType);\n        if (map == null || map == NULL_TYPE_HANDLER_MAP) {\n            map = new HashMap<>();\n        }\n        map.put(jdbcType, handler);\n        typeHandlerMap.put(javaType, map);\n    }\n    // 记录所有的 TypeHandler 对象\n    allTypeHandlersMap.put(handler.getClass(), handler);\n}\n```\n\n上述方法的核心逻辑在于往 `TypeHandlerRegistry#typeHandlerMap` 属性中注册 java 类型及其类型处理器。MyBatis 基于该方法封装了多层重载版本，其中大部分实现都比较简单，下面就基于注解 `@MappedJdbcTypes` 和注解 `@MappedTypes` 指定对应类型的版本进一步说明。\n\n注解 `@MappedJdbcTypes` 用于指定类型处理器 TypeHandler 关联的 JDBC 类型列表，对应的解析实现如下：\n\n```java\nprivate <T> void register(Type javaType, TypeHandler<? extends T> typeHandler) {\n    // 获取 MappedJdbcTypes 注解配置\n    MappedJdbcTypes mappedJdbcTypes = typeHandler.getClass().getAnnotation(MappedJdbcTypes.class);\n    if (mappedJdbcTypes != null) {\n        // 一个 TypeHandler 可以关联多个 JDBC 类型，遍历逐一注册\n        for (JdbcType handledJdbcType : mappedJdbcTypes.value()) {\n            this.register(javaType, handledJdbcType, typeHandler);\n        }\n        // 允许处理 null 值\n        if (mappedJdbcTypes.includeNullJdbcType()) {\n            this.register(javaType, null, typeHandler);\n        }\n    } else {\n        this.register(javaType, null, typeHandler);\n    }\n}\n```\n\n上述方法首先获取注解 `@MappedJdbcTypes` 配置的 JDBC 类型列表，然后遍历挨个注册。注解 `@MappedJdbcTypes` 定义如下：\n\n```java\n@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.TYPE)\npublic @interface MappedJdbcTypes {\n\n    /** 当前类型处理器能够处理的 JDBC 类型列表 */\n    JdbcType[] value();\n\n    /** 是否允许处理 null 值 */\n    boolean includeNullJdbcType() default false;\n}\n```\n\n该注解还允许通过 `MappedJdbcTypes#includeNullJdbcType` 属性指定是否允许当前类型处理器处理 null 值。\n\n能够指定 JDBC 类型，当然也就能够指定 JAVA 类型。注解 `@MappedTypes` 用于指定与类型处理器 TypeHandler 关联的 java 类型，对应的解析实现如下：\n\n```java\npublic <T> void register(TypeHandler<T> typeHandler) {\n    boolean mappedTypeFound = false;\n    // 获取 MappedTypes 注解配置\n    MappedTypes mappedTypes = typeHandler.getClass().getAnnotation(MappedTypes.class);\n    if (mappedTypes != null) {\n        // 一个 TypeHandler 可以关联多个 java 类型，遍历逐一注册\n        for (Class<?> handledType : mappedTypes.value()) {\n            this.register(handledType, typeHandler);\n            mappedTypeFound = true;\n        }\n    }\n    // 尝试基于 typeHandler 自动发现对应的 java 类型，需要实现 TypeReference 接口（@since 3.1.0）\n    if (!mappedTypeFound && typeHandler instanceof TypeReference) {\n        try {\n            TypeReference<T> typeReference = (TypeReference<T>) typeHandler;\n            this.register(typeReference.getRawType(), typeHandler);\n            mappedTypeFound = true;\n        } catch (Throwable t) {\n            // maybe users define the TypeReference with a different type and are not assignable, so just ignore it\n        }\n    }\n    if (!mappedTypeFound) {\n        this.register((Class<T>) null, typeHandler);\n    }\n}\n```\n\n上述方法首先获取 `@MappedTypes` 注解配置，并针对关联的 java 类型逐一注册。如果未指定 `@MappedTypes` 注解配置，则 MyBatis 会尝试自动发现并注册 TypeHandler 能够处理的 java 类型。\n\n能够注册也就能够获取，TypeHandlerRegistry 中提供了 `TypeHandlerRegistry#getTypeHandler` 方法的多种重载实现，比较简单，不再展开。\n\n回过头再来看一下 BaseBuilder 抽象类的实现，其中定义了许多方法，但是只要了解上面介绍的 TypeAliasRegistry 和 TypeHandlerRegistry 类，那么这些方法的作用在理解上应该非常容易，这里就不多做撰述，有兴趣的同学可以参考上面的分析去阅读一下源码。\n\n下面正式进入主题，回到 `XMLConfigBuilder#parse` 方法分析配置文件的解析过程，实现如下：\n\n```java\npublic Configuration parse() {\n    // 配置文件已经被解析过，避免重复解析\n    if (parsed) {\n        throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\");\n    }\n    parsed = true;\n    // 解析 mybatis-config.xml 中的各项配置，填充 Configuration 对象\n    this.parseConfiguration(parser.evalNode(\"/configuration\"));\n    return configuration;\n}\n```\n\n配置文件 `mybatis-config.xml` 以 `<configuration/>` 标签作为配置文件根节点，上述方法的核心在于触发调用 `XMLConfigBuilder#parseConfiguration` 方法对配置文件的各个元素进行解析，并封装解析结果到 Configuration 对象中，最终返回该配置对象。方法实现如下：\n\n```java\nprivate void parseConfiguration(XNode root) {\n    try {\n        // 解析 <properties/> 配置\n        this.propertiesElement(root.evalNode(\"properties\"));\n        // 解析 <settings/> 配置\n        Properties settings = this.settingsAsProperties(root.evalNode(\"settings\"));\n        // 获取并设置 vfsImpl 属性\n        this.loadCustomVfs(settings);\n        // 获取并设置 logImpl 属性\n        this.loadCustomLogImpl(settings);\n        // 解析 <typeAliases/> 配置\n        this.typeAliasesElement(root.evalNode(\"typeAliases\"));\n        // 解析 <plugins/> 配置\n        this.pluginElement(root.evalNode(\"plugins\"));\n        // 解析 <objectFactory/> 配置\n        this.objectFactoryElement(root.evalNode(\"objectFactory\"));\n        // 解析 <objectWrapperFactory/> 配置\n        this.objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\"));\n        // 解析 <reflectorFactory/> 配置\n        this.reflectorFactoryElement(root.evalNode(\"reflectorFactory\"));\n        // 将 settings 配置设置到 Configuration 对象中\n        this.settingsElement(settings);\n        // 解析 <environments/> 配置\n        this.environmentsElement(root.evalNode(\"environments\"));\n        // 解析 <databaseIdProvider/> 配置\n        this.databaseIdProviderElement(root.evalNode(\"databaseIdProvider\"));\n        // 解析 <typeHandlers/> 配置\n        this.typeHandlerElement(root.evalNode(\"typeHandlers\"));\n        // 解析 <mappers/> 配置\n        this.mapperElement(root.evalNode(\"mappers\"));\n    } catch (Exception e) {\n        throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e);\n    }\n}\n```\n\n上述方法在实现上比较直观，各配置项的解析都采用专门的方法进行封装，接下来会逐一进行分析。其中 `<plugins/>` 标签用于配置自定义插件，以拦截 SQL 语句的执行过程，相应的解析过程暂时先不展开，留到后面专门介绍插件的实现机制的文章中一并分析。\n\n#### 解析 properties 标签\n\n先来看一下 `<properties/>` 标签怎么玩，其中的配置项可以在整个配置文件中用来动态替换占位符。配置项可以从外部 properties 文件读取，也可以通过 `<property/>` 子标签指定。假设我们希望通过该标签指定数据源配置，如下：\n\n```xml\n<properties resource=\"datasource.properties\">\n    <property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/>\n    <!--为占位符启用默认值配置，默认关闭，需要采用如下方式开启-->\n    <property name=\"org.apache.ibatis.parsing.PropertyParser.enable-default-value\" value=\"true\"/>\n</properties>\n```\n\n文件 `datasource.properties` 内容：\n\n```properties\nurl=jdbc:mysql://localhost:3306/test\nusername=root\npassword=123456\n```\n\n然后可以基于 OGNL 表达式在其它配置项中引用这些配置值，如下：\n\n```xml\n<dataSource type=\"POOLED\"> <!--or UNPOOLED or JNDI-->\n    <property name=\"driver\" value=\"${driver}\"/>\n    <property name=\"url\" value=\"${url}\"/>\n    <property name=\"username\" value=\"${username:zhenchao}\"/> <!--占位符设置默认值，需要专门开启-->\n    <property name=\"password\" value=\"${password}\"/>\n</dataSource>\n```\n\n其中，除了 driver 属性值来自 `<property/>` 子标签，其余属性值均是从 `datasource.properties` 配置文件中获取的。\n\nMyBatis 针对配置的读取顺序约定如下：\n\n1. 在 `<properties/>` 标签体内指定的属性首先被读取；\n2. 然后，根据 `<properties/>` 标签中 resource 属性读取类路径下配置文件，或根据 url 属性指定的路径读取指向的配置文件，并覆盖已读取的同名配置项；\n3. 最后，读取方法参数传递的配置项，并覆盖已读取的同名配置项。\n\n下面分析一下 `<properties/>` 标签的解析过程，由 `XMLConfigBuilder#propertiesElement` 方法实现：\n\n```java\nprivate void propertiesElement(XNode context) throws Exception {\n    if (context != null) {\n        // 获取 <property/> 子标签列表，封装成 Properties 对象\n        Properties defaults = context.getChildrenAsProperties();\n        // 支持通过 resource 或 url 属性指定外部配置文件\n        String resource = context.getStringAttribute(\"resource\");\n        String url = context.getStringAttribute(\"url\");\n        // 这两种类型的配置是互斥的\n        if (resource != null && url != null) {\n            throw new BuilderException(\"The properties element cannot specify both a URL \" +\n                \"and a resource based property file reference.  Please specify one or the other.\");\n        }\n        // 从类路径加载配置文件\n        if (resource != null) {\n            defaults.putAll(Resources.getResourceAsProperties(resource));\n        }\n        // 从 url 指定位置加载配置文件\n        else if (url != null) {\n            defaults.putAll(Resources.getUrlAsProperties(url));\n        }\n        // 合并已有的配置项\n        Properties vars = configuration.getVariables();\n        if (vars != null) {\n            defaults.putAll(vars);\n        }\n        // 填充 XPathParser 和 Configuration 对象\n        parser.setVariables(defaults);\n        configuration.setVariables(defaults);\n    }\n}\n```\n\n由 MyBatis 的官方文档可知，标签 `<properties/>` 支持以 resource 属性或 url 属性指定配置文件所在的路径，由上述实现也可以看出这两个属性配置是互斥的。在将对应的配置加载成为 Properties 对象之后，上述方法会合并 Configuration 对象中已有的配置项，并将结果再次填充到 XPathParser 和 Configuration 对象中，以备后用。\n\n#### 解析 settings 标签\n\nMyBatis 通过 `<settings/>` 标签提供一些全局性的配置，这些配置会影响 MyBatis 的运行行为。[官方文档](https://mybatis.org/mybatis-3/zh/configuration.html#settings) 对这些配置项进行了详细的说明，下面的配置摘自官方文档，其中各项的含义可以参考文档说明：\n\n```xml\n<settings>\n    <setting name=\"cacheEnabled\" value=\"true\"/>\n    <setting name=\"lazyLoadingEnabled\" value=\"true\"/>\n    <setting name=\"multipleResultSetsEnabled\" value=\"true\"/>\n    <setting name=\"useColumnLabel\" value=\"true\"/>\n    <setting name=\"useGeneratedKeys\" value=\"false\"/>\n    <setting name=\"autoMappingBehavior\" value=\"PARTIAL\"/>\n    <setting name=\"autoMappingUnknownColumnBehavior\" value=\"WARNING\"/>\n    <setting name=\"defaultExecutorType\" value=\"SIMPLE\"/>\n    <setting name=\"defaultStatementTimeout\" value=\"25\"/>\n    <setting name=\"defaultFetchSize\" value=\"100\"/>\n    <setting name=\"safeRowBoundsEnabled\" value=\"false\"/>\n    <setting name=\"mapUnderscoreToCamelCase\" value=\"false\"/>\n    <setting name=\"localCacheScope\" value=\"SESSION\"/>\n    <setting name=\"jdbcTypeForNull\" value=\"OTHER\"/>\n    <setting name=\"lazyLoadTriggerMethods\" value=\"equals,clone,hashCode,toString\"/>\n</settings>\n```\n\nMyBatis 对于该标签的解析实现十分简单，首先调用 `XMLConfigBuilder#settingsAsProperties` 方法获取配置项对应的 Properties 对象，同时会检查配置项是否是可识别的，实现如下：\n\n```java\nprivate Properties settingsAsProperties(XNode context) {\n    if (context == null) {\n        return new Properties();\n    }\n    // 解析 <setting/> 配置，封装成 Properties 对象\n    Properties props = context.getChildrenAsProperties();\n    // 构造 Configuration 对应的 MetaClass 对象，用于对 Configuration 类提供反射操作\n    MetaClass metaConfig = MetaClass.forClass(Configuration.class, localReflectorFactory);\n    // 遍历配置项，确保配置项是 MyBatis 可识别的\n    for (Object key : props.keySet()) {\n        // 属性对应的 setter 方法不存在\n        if (!metaConfig.hasSetter(String.valueOf(key))) {\n            throw new BuilderException(\n                \"The setting \" + key + \" is not known.  Make sure you spelled it correctly (case sensitive).\");\n        }\n    }\n    return props;\n}\n```\n\n接下来调用 `XMLConfigBuilder#loadCustomVfs` 方法和 `XMLConfigBuilder#loadCustomLogImpl` 方法分别解析 `vfsImpl` 和 `logImpl` 配置项，其中 `vfsImpl` 配置项用于设置自定义 VFS 的实现类全限定名，以逗号分隔。所有的 `<settings/>` 配置项最后都会通过 `XMLConfigBuilder#settingsElement` 方法记录到 Configuration 对象对应的属性中。\n\n#### 解析 typeAliases 和 typeHandlers 标签\n\n前面介绍了 TypeAliasRegistry 和 TypeHandlerRegistry 两个类的功能和实现，本小节介绍的这两个标签分别对应这两个类的相关配置，前者用于配置类型及其别名的映射关系，后者用于配置类型及其类型处理器 TypeHandler 之间的映射关系。二者在实现上基本相同，这里以 `<typeAliases/>` 标签的解析过程为例进行分析（由 `XMLConfigBuilder#typeAliasesElement` 方法实现），有兴趣的读者可以自己阅读 `<typeHandlers/>` 标签的相关实现。\n\n```java\nprivate void typeAliasesElement(XNode parent) {\n    if (parent != null) {\n        for (XNode child : parent.getChildren()) {\n            // 子标签是 <package name=\"\"/> 配置\n            if (\"package\".equals(child.getName())) {\n                /*\n                 * 如果指定了一个包名，MyBatis 会在包名下搜索需要的 Java Bean，并处理 @Alias 注解，\n                 * 在没有注解的情况下，会使用 Bean 的首字母小写的简单名称作为它的别名。\n                 */\n                String typeAliasPackage = child.getStringAttribute(\"name\");\n                configuration.getTypeAliasRegistry().registerAliases(typeAliasPackage);\n            }\n            // 子标签是 <typeAlias alias=\"\" type=\"\"/> 配置\n            else {\n                String alias = child.getStringAttribute(\"alias\"); // 别名\n                String type = child.getStringAttribute(\"type\"); // 类型限定名\n                try {\n                    // 获取类型对应的 Class 对象\n                    Class<?> clazz = Resources.classForName(type);\n                    // 未配置 alias，先尝试获取 @Alias 注解，如果没有则使用类的简单名称\n                    if (alias == null) {\n                        typeAliasRegistry.registerAlias(clazz);\n                    }\n                    // 配置了 alias，使用该 alias 进行注册\n                    else {\n                        typeAliasRegistry.registerAlias(alias, clazz);\n                    }\n                } catch (ClassNotFoundException e) {\n                    throw new BuilderException(\"Error registering typeAlias for '\" + alias + \"'. Cause: \" + e, e);\n                }\n            }\n        }\n    }\n}\n```\n\n标签 `<typeAliases/>` 具备两种配置方式，单一注册与批量扫描，具体使用可以参考 [官方文档](https://mybatis.org/mybatis-3/zh/configuration.html#typeAliases)。对应的实现也需要区分这两种情况，如果是批量扫描，即子标签是 `<package/>`，则会调用 `TypeAliasRegistry#registerAliases` 方法进行扫描注册：\n\n```java\npublic void registerAliases(String packageName) {\n    this.registerAliases(packageName, Object.class);\n}\n\npublic void registerAliases(String packageName, Class<?> superType) {\n    // 获取指定 package 下所有 superType 类型及其子类型\n    ResolverUtil<Class<?>> resolverUtil = new ResolverUtil<>();\n    resolverUtil.find(new ResolverUtil.IsA(superType), packageName);\n    Set<Class<? extends Class<?>>> typeSet = resolverUtil.getClasses();\n    // 遍历处理扫描到的类型\n    for (Class<?> type : typeSet) {\n        // 忽略内部类、接口，以及抽象类\n        if (!type.isAnonymousClass() && !type.isInterface() && !type.isMemberClass()) {\n            // 尝试获取类的 @Alias 注解，如果没有则使用类的简单名称的小写形式作为别名进行注册\n            this.registerAlias(type);\n        }\n    }\n}\n```\n\n如果子标签是 `<typeAlias alias=\"\" type=\"\"/>` 这种配置形式，则会获取 alias 和 type 属性值，然后基于一定规则进行注册，具体过程如代码注释。\n\n#### 解析 objectFactory 标签\n\n在具体分析 `<objectFactory/>` 标签的解析实现之前，我们必须先了解与之密切相关的 ObjectFactory 接口。由名字我们可以猜测这是一个工厂类，并且是创建对象的工厂，定义如下：\n\n```java\npublic interface ObjectFactory {\n    /** 设置配置信息 */\n    default void setProperties(Properties properties) { }\n    /** 基于无参构造方法创建指定类型对象 */\n    <T> T create(Class<T> type);\n    /** 基于指定的构造参数（类型）选择对应的构造方法创建目标对象 */\n    <T> T create(Class<T> type, List<Class<?>> constructorArgTypes, List<Object> constructorArgs);\n    /** 检测指定类型是否是集合类型 */\n    <T> boolean isCollection(Class<T> type);\n}\n```\n\n各方法的作用如代码注释，DefaultObjectFactory 类是该接口的默认实现。下面重点看一下基于指定构造参数（类型）选择对应的构造方法创建目标对象的实现细节：\n\n```java\npublic <T> T create(Class<T> type, List<Class<?>> constructorArgTypes, List<Object> constructorArgs) {\n    // 如果传入的是接口类型，则选择具体的实现类型以创建对象，毕竟接口类型不能被实例化\n    Class<?> classToCreate = this.resolveInterface(type);\n    // 基于入参选择合适的构造方法进行实例化\n    return (T) this.instantiateClass(classToCreate, constructorArgTypes, constructorArgs);\n}\n```\n\n方法首先会判断当前指定的类型是否是接口类型，因为接口类型无法实例化，所以需要选择相应的实现类代替。例如当我们传递的是一个 List 接口类型会返回相应的 ArrayList 实现类型。再来看一下 `DefaultObjectFactory#instantiateClass` 方法的实现：\n\n```java\nprivate <T> T instantiateClass(Class<T> type, List<Class<?>> constructorArgTypes, List<Object> constructorArgs) {\n    try {\n        Constructor<T> constructor;\n        // 如果没有传递构造参数或类型，则使用无参构造方法创建对象\n        if (constructorArgTypes == null || constructorArgs == null) {\n            constructor = type.getDeclaredConstructor();\n            try {\n                return constructor.newInstance();\n            } catch (IllegalAccessException e) {\n                if (Reflector.canControlMemberAccessible()) {\n                    constructor.setAccessible(true);\n                    return constructor.newInstance();\n                } else {\n                    throw e;\n                }\n            }\n        }\n        // 否则选择对应的构造方法创建对象\n        constructor = type.getDeclaredConstructor(constructorArgTypes.toArray(new Class[0]));\n        try {\n            return constructor.newInstance(constructorArgs.toArray(new Object[0]));\n        } catch (IllegalAccessException e) {\n            if (Reflector.canControlMemberAccessible()) {\n                constructor.setAccessible(true);\n                return constructor.newInstance(constructorArgs.toArray(new Object[0]));\n            } else {\n                throw e;\n            }\n        }\n    } catch (Exception e) {\n        // ... 异常处理略\n    }\n}\n```\n\n上述方法主要基于传递的参数以决策具体创建对象的构造方法版本，并基于反射机制创建对象。\n\n所以说 ObjectFactory 接口的作用主要是对我们传递的类型进行实例化，默认的实现版本比较简单。如果默认实现不能满足需求，则可以扩展 ObjectFactory 接口，并将相应的自定义实现通过 `<objectFactory/>` 标签进行注册，具体的使用方式参见 [官方文档](https://mybatis.org/mybatis-3/zh/configuration.html#objectFactory)。我们继续分析针对该标签的解析过程，由 `XMLConfigBuilder#objectFactoryElement` 方法实现：\n\n```java\nprivate void objectFactoryElement(XNode context) throws Exception {\n    if (context != null) {\n        // 获取 type 属性配置，对应自定义对象工厂类\n        String type = context.getStringAttribute(\"type\");\n        // 获取 <property/> 子标签列表，封装成 Properties 对象\n        Properties properties = context.getChildrenAsProperties();\n        // 实例化自定义工厂类对象\n        ObjectFactory factory = (ObjectFactory) this.resolveClass(type).getDeclaredConstructor().newInstance();\n        // 设置属性配置\n        factory.setProperties(properties);\n        // 填充 Configuration 对象\n        configuration.setObjectFactory(factory);\n    }\n}\n```\n\n解析 `<objectFactory/>` 标签的基本流程就是获取我们在标签中通过 type 属性指定的自定义 ObjectFactory 实现类的全限定名和相应属性配置；然后构造自定义 ObjectFactory 实现类对象，并将获取到的配置项列表记录到对象中；最后将自定义 ObjectFactory 对象填充到 Configuration 对象中。\n\n#### 解析 reflectorFactory 标签\n\n标签 `<reflectorFactory/>` 用于注册自定义 ReflectorFactory 实现，该标签的解析过程与 `<objectFactory/>` 标签基本相同，不再重复撰述，本小节重点分析一下该标签涉及到相关类的功能与实现。\n\nReflectorFactory 顾名思义是一个 Reflector 工厂，接口定义如下：\n\n```java\npublic interface ReflectorFactory {\n    /** 是否缓存 {@link Reflector} 对象 */\n    boolean isClassCacheEnabled();\n    /** 设置是否缓存 {@link Reflector} 对象 */\n    void setClassCacheEnabled(boolean classCacheEnabled);\n    /** 获取指定类型的 {@link Reflector} 对象 */\n    Reflector findForClass(Class<?> type);\n}\n```\n\n默认实现类 DefaultReflectorFactory 通过一个 boolean 变量 `DefaultReflectorFactory#classCacheEnabled` 记录是否启用缓存，并通过一个线程安全的 Map 集合 `DefaultReflectorFactory#reflectorMap` 记录缓存的 Reflector 对象，相应的方法实现都十分简单，不再展开。\n\nReflectorFactory 本质上是用来创建和管理 Reflector 对象，那么 Reflector 又是什么呢？我们先来看一下 Reflector 的属性和构造方法定义：\n\n```java\npublic class Reflector {\n\n    /** 隶属的 Class 类型 */\n    private final Class<?> type;\n    /** 可读属性名称集合 */\n    private final String[] readablePropertyNames;\n    /** 可写属性名称集合 */\n    private final String[] writablePropertyNames;\n    /** 属性对应的 setter 方法（封装成 Invoker 对象） */\n    private final Map<String, Invoker> setMethods = new HashMap<String, Invoker>();\n    /** 属性对应的 getter 方法（封装成 Invoker 对象） */\n    private final Map<String, Invoker> getMethods = new HashMap<String, Invoker>();\n    /** 属性对应 setter 方法的入参类型 */\n    private final Map<String, Class<?>> setTypes = new HashMap<String, Class<?>>();\n    /** 属性对应 getter 方法的返回类型 */\n    private final Map<String, Class<?>> getTypes = new HashMap<String, Class<?>>();\n    /** 记录默认构造方法 */\n    private Constructor<?> defaultConstructor;\n    /** 记录所有的属性名称 */\n    private Map<String, String> caseInsensitivePropertyMap = new HashMap<String, String>();\n\n    public Reflector(Class<?> clazz) {\n        type = clazz;\n        // 解析获取默认构造方法（无参构造方法）\n        this.addDefaultConstructor(clazz);\n        // 解析获取所有的 getter 方法，并记录到 getMethods 与 getTypes 属性中\n        this.addGetMethods(clazz);\n        // 解析获取所有的 setter 方法，并记录到 setMethods 与 setTypes 属性中\n        this.addSetMethods(clazz);\n        // 解析获取所有没有 setter/getter 方法的字段，并添加到相应的集合中\n        this.addFields(clazz);\n        // 填充可读属性名称数组\n        readablePropertyNames = getMethods.keySet().toArray(new String[getMethods.keySet().size()]);\n        // 填充可写属性名称数组\n        writablePropertyNames = setMethods.keySet().toArray(new String[setMethods.keySet().size()]);\n        // 记录所有属性名称到 Map 集合中\n        for (String propName : readablePropertyNames) {\n            caseInsensitivePropertyMap.put(propName.toUpperCase(Locale.ENGLISH), propName);\n        }\n        for (String propName : writablePropertyNames) {\n            caseInsensitivePropertyMap.put(propName.toUpperCase(Locale.ENGLISH), propName);\n        }\n    }\n    // ... 省略方法实现\n}\n```\n\n可以看到 Reflector 是对指定 Class 对象的封装，记录了对应的 Class 类型、属性、getter 和 setter 方法列表等信息，是反射操作的基础，其中的方法实现虽然较长，但是逻辑都比较简单，读者可以自行阅读源码。\n\n#### 解析 objectWrapperFactory 标签\n\n标签 `<objectWrapperFactory/>` 用于注册自定义 ObjectWrapperFactory 实现，该标签的解析过程与 `<objectFactory/>` 标签基本相同，同样不再重复撰述，本小节重点分析该标签涉及到相关类的功能与实现。\n\nObjectWrapperFactory 顾名思义是一个 ObjectWrapper 工厂，其默认实现 DefaultObjectWrapperFactory 并没有实现有用的逻辑，所以可以忽略。然而，借助 `<reflectorFactory/>` 标签，我们可以注册自定义的 ObjectWrapperFactory 实现。\n\n被 ObjectWrapperFactory 创建和管理的 ObjectWrapper 是一个接口，用于包装和处理对象，其中声明了多个操作对象的方法，包括获取、更新对象属性等，接口定义如下：\n\n```java\npublic interface ObjectWrapper {\n    /** 获取对应属性的值（对于集合而言，则是获取对应下标的值） */\n    Object get(PropertyTokenizer prop);\n    /** 设置对应属性的值（对于集合而言，则是设置对应下标的值）*/\n    void set(PropertyTokenizer prop, Object value);\n    /** 查找属性表达式对应的属性 */\n    String findProperty(String name, boolean useCamelCaseMapping);\n    /** 获取可读属性名称集合 */\n    String[] getGetterNames();\n    /** 获取可写属性名称集合 */\n    String[] getSetterNames();\n    /** 获取属性表达式指定属性 setter 方法的入参类型 */\n    Class<?> getSetterType(String name);\n    /** 获取属性表达式指定属性 getter 方法的返回类型 */\n    Class<?> getGetterType(String name);\n    /** 判断属性是否有 setter 方法 */\n    boolean hasSetter(String name);\n    /** 判断属性是否有 getter 方法 */\n    boolean hasGetter(String name);\n    /** 为属性表达式指定的属性创建对应的 {@link MetaObject} 对象 */\n    MetaObject instantiatePropertyValue(String name, PropertyTokenizer prop, ObjectFactory objectFactory);\n    /** 是否是 {@link java.util.Collection} 类型 */\n    boolean isCollection();\n    /** 调用 {@link java.util.Collection} 对应的 add 方法 */\n    void add(Object element);\n    /** 调用 {@link java.util.Collection} 对应的 addAll 方法 */\n    <E> void addAll(List<E> element);\n}\n```\n\n由接口定义可以看出，ObjectWrapper 的主要作用在于简化调用方对于对象的操作。\n\n#### 解析 environments 标签\n\n标签 `<environments/>` 用于配置多套数据库环境，典型的应用场景就是在开发、测试、灰度，以及生产等环境通过该标签分别指定相应的配置。当应用需要同时操作多套数据源时，也可以基于该标签分别配置，具体的使用请参阅 [官方文档](https://mybatis.org/mybatis-3/zh/configuration.html#environments)。MyBatis 解析该标签的过程由 `XMLConfigBuilder#environmentsElement` 方法实现：\n\n```java\nprivate void environmentsElement(XNode context) throws Exception {\n    if (context != null) {\n        // 未通过参数指定生效的 environment 配置，获取 default 属性值\n        if (environment == null) {\n            environment = context.getStringAttribute(\"default\");\n        }\n        // 遍历处理 <environment/> 子标签\n        for (XNode child : context.getChildren()) {\n            // 获取 id 属性配置\n            String id = child.getStringAttribute(\"id\");\n            // 处理指定生效的 <environment/> 配置\n            if (this.isSpecifiedEnvironment(id)) {\n                // 处理 <transactionManager/> 子标签\n                TransactionFactory txFactory = this.transactionManagerElement(child.evalNode(\"transactionManager\"));\n                // 处理 <dataSource/> 子标签\n                DataSourceFactory dsFactory = this.dataSourceElement(child.evalNode(\"dataSource\"));\n                // 基于解析到的值构造 Environment 对象填充 Configuration 对象\n                DataSource dataSource = dsFactory.getDataSource();\n                Environment.Builder environmentBuilder = new Environment.Builder(id)\n                    .transactionFactory(txFactory)\n                    .dataSource(dataSource);\n                configuration.setEnvironment(environmentBuilder.build());\n            }\n        }\n    }\n}\n```\n\n上述方法首先会判断是否通过参数指定了 environment 配置，如果没有则尝试获取 `<environments/>` 标签的 default 属性，说明参数指定相对于 default 属性配置优先级更高。然后开始遍历寻找并解析指定激活的 `<environment/>` 配置。整个解析过程主要是对 `<transactionManager/>` 和 `<dataSource/>` 两个子标签进行解析，前者用于指定 MyBatis 的事务管理器，后者用于配置数据源。\n\n数据源的配置解析比较直观，下面主要看一下事务管理器配置的解析过程，由 `XMLConfigBuilder#transactionManagerElement` 方法实现：\n\n```java\nprivate TransactionFactory transactionManagerElement(XNode context) throws Exception {\n    if (context != null) {\n        // 获取事务管理器类型配置：JDBC or MANAGED\n        String type = context.getStringAttribute(\"type\");\n        // 获取 <property/> 子标签列表，封装成 Properties 对象\n        Properties props = context.getChildrenAsProperties();\n        // 构造对应的 TransactionFactory 对象，并填充属性值\n        TransactionFactory factory = (TransactionFactory) this.resolveClass(type).getDeclaredConstructor().newInstance();\n        factory.setProperties(props);\n        return factory;\n    }\n    throw new BuilderException(\"Environment declaration requires a TransactionFactory.\");\n}\n```\n\nMyBatis 允许我们配置两种类型的事务管理器，即 JDBC 类型和 MANAGED 类型，引用官方文档的话来理解二者的区别：\n\n> 在 MyBatis 中有两种类型的事务管理器（也就是 `type=\"[JDBC|MANAGED]\"`）：\n>\n> - JDBC：这个配置直接使用了 JDBC 的提交和回滚设施，它依赖从数据源获得的连接来管理事务作用域。\n> - MANAGED：这个配置几乎没做什么。它从不提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。 默认情况下它会关闭连接。然而一些容器并不希望连接被关闭，因此需要将 closeConnection 属性设置为 false 来阻止默认的关闭行为。例如:\n>\n> ```xml\n> <transactionManager type=\"MANAGED\">\n>     <property name=\"closeConnection\" value=\"false\"/>\n> </transactionManager>\n> ```\n>\n> 提示：如果你正在使用 Spring + MyBatis，则没有必要配置事务管理器，因为 Spring 模块会使用自带的管理器来覆盖前面的配置。\n\nTransaction 接口定义了事务，并为 JDBC 类型和 MANAGED 类型提供了相应的实现，即 JdbcTransaction 和 ManagedTransaction。正如上面引用的官方文档所说的那样，MyBatis 的事务操作实现的比较简单，考虑实际应用中更多是依赖于 Spring 的事务管理器，这里也就不再深究。\n\n#### 解析 databaseIdProvider 标签\n\n生产环境中可能会存在同时操作多套不同类型数据库的场景，而 `<databaseIdProvider/>` 标签则用于配置数据库厂商标识。我们知道 SQL 不能完全做到数据库无关，且 MyBatis 暂时也还不能做到对上层完全屏蔽底层数据库的实现细节，所以在这种情况下执行 SQL 语句时，我们需要通过 databaseId 指定 SQL 应用的具体数据库类型。\n\n该标签的解析过程由 `XMLConfigBuilder#databaseIdProviderElement` 方法实现，如下：\n\n```java\nprivate void databaseIdProviderElement(XNode context) throws Exception {\n    DatabaseIdProvider databaseIdProvider = null;\n    if (context != null) {\n        String type = context.getStringAttribute(\"type\");\n        // awful patch to keep backward compatibility\n        if (\"VENDOR\".equals(type)) {\n            type = \"DB_VENDOR\"; // 保持兼容\n        }\n        // 获取 <property/> 子节点配置\n        Properties properties = context.getChildrenAsProperties();\n        // 构造 DatabaseIdProvider 对象\n        databaseIdProvider = (DatabaseIdProvider) resolveClass(type).newInstance();\n        // 设置配置的属性\n        databaseIdProvider.setProperties(properties);\n    }\n    Environment environment = configuration.getEnvironment();\n    if (environment != null && databaseIdProvider != null) {\n        // 获取当前数据库环境对应的 databaseId，并记录到 Configuration.databaseId 中，已备后用\n        String databaseId = databaseIdProvider.getDatabaseId(environment.getDataSource());\n        configuration.setDatabaseId(databaseId);\n    }\n}\n```\n\n解析过程如上述代码注释，关于该标签的使用可以参考 [官方文档](https://mybatis.org/mybatis-3/zh/configuration.html#databaseIdProvider)。\n\n#### 解析 mappers 标签\n\n标签 `<mappers/>` 用于指定映射文件列表，这是一个我们非常熟悉的标签。MyBatis 广受欢迎的一个很重要的原因是支持自己定义 SQL 语句，这样就可以保证 SQL 的优化可控。抛去注解配置 SQL 的形式（注解对于复杂 SQL 的支持较弱，一般仅用于编写简单的 SQL），对于框架自动生成的 SQL 和用户自定义的 SQL 都记录在映射 XML 文件中，标签 `<mappers/>` 用于指定映射文件所在的路径。\n\n我们可以通过 `<mapper resource=\"\">` 或 `<mapper url=\"\">` 子标签指定映射 XML 文件所在的位置，也可以通过 `<mapper class=\"\">` 子标签指定一个或多个具体的 Mapper 接口，甚至可以通过 `<package name=\"\"/>` 子标签指定映射文件所在的包名，扫描注册。\n\n该标签的解析过程由 `XMLConfigBuilder#mapperElement` 方法实现，如下：\n\n```java\nprivate void mapperElement(XNode parent) throws Exception {\n    if (parent != null) {\n        for (XNode child : parent.getChildren()) {\n            /*\n             * 配置了 package 属性，从指定包下面扫描注册\n             * <mappers>\n             *      <package name=\"org.mybatis.builder\"/>\n             * </mappers>\n             */\n            if (\"package\".equals(child.getName())) {\n                String mapperPackage = child.getStringAttribute(\"name\");\n                // 调用 MapperRegistry 进行注册\n                configuration.addMappers(mapperPackage);\n            }\n            // 处理 resource、url，以及 class 配置的场景\n            else {\n                String resource = child.getStringAttribute(\"resource\");\n                String url = child.getStringAttribute(\"url\");\n                String mapperClass = child.getStringAttribute(\"class\");\n                /*\n                 * <!-- Using classpath relative resources -->\n                 * <mappers>\n                 *      <mapper resource=\"org/mybatis/builder/AuthorMapper.xml\"/>\n                 *      <mapper resource=\"org/mybatis/builder/BlogMapper.xml\"/>\n                 *      <mapper resource=\"org/mybatis/builder/PostMapper.xml\"/>\n                 * </mappers>\n                 */\n                if (resource != null && url == null && mapperClass == null) {\n                    ErrorContext.instance().resource(resource);\n                    // 从类路径获取文件输入流\n                    InputStream inputStream = Resources.getResourceAsStream(resource);\n                    // 构建 XMLMapperBuilder 对象\n                    XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());\n                    // 执行映射文件解析\n                    mapperParser.parse();\n                }\n                /*\n                 * <!-- Using url fully qualified paths -->\n                 * <mappers>\n                 *      <mapper url=\"file:///var/mappers/AuthorMapper.xml\"/>\n                 *      <mapper url=\"file:///var/mappers/BlogMapper.xml\"/>\n                 *      <mapper url=\"file:///var/mappers/PostMapper.xml\"/>\n                 * </mappers>\n                 */\n                else if (resource == null && url != null && mapperClass == null) {\n                    ErrorContext.instance().resource(url);\n                    // 基于 url 获取配置文件输入流\n                    InputStream inputStream = Resources.getUrlAsStream(url);\n                    // 构建 XMLMapperBuilder 对象\n                    XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments());\n                    // 执行映射文件解析\n                    mapperParser.parse();\n                }\n                /*\n                 * <!-- Using mapper interface classes -->\n                 * <mappers>\n                 *      <mapper class=\"org.mybatis.builder.AuthorMapper\"/>\n                 *      <mapper class=\"org.mybatis.builder.BlogMapper\"/>\n                 *      <mapper class=\"org.mybatis.builder.PostMapper\"/>\n                 * </mappers>\n                 */\n                else if (resource == null && url == null && mapperClass != null) {\n                    // 获取指定接口 Class 对象\n                    Class<?> mapperInterface = Resources.classForName(mapperClass);\n                    // 调用 MapperRegistry 进行注册\n                    configuration.addMapper(mapperInterface);\n                } else {\n                    throw new BuilderException(\"A mapper element may only specify a url, resource or class, but not more than one.\");\n                }\n            }\n        }\n    }\n}\n```\n\n上述方法首先会判断当前是否是 package 配置，如果是则会获取配置的 package 名称，然后执行扫描注册逻辑。如果是 resource 或 url 配置，则先获取指定路径映射文件的输入流，然后构造 XMLMapperBuilder 对象对映射文件进行解析。对于 class 配置而言，则会构建接口限定名对应的 Class 对象，并调用 `MapperRegistry#addMapper` 方法执行注册。\n\n整个方法的运行逻辑还是比较直观的，其中涉及到对映射文件的解析注册过程，即 XMLMapperBuilder 相关类实现，将留到下一篇介绍映射文件加载与解析时专门介绍。\n\n下面来重点分析一下 MapperRegistry 类及其周边类的功能和实现。我们在使用 MyBatis 框架时需要实现数据表对应的 Mapper 接口（以后统称为 Mapper 接口），其中声明了一系列数据库操作方法。我们可以通过注解的方式在方法上编写 SQL 语句，也可以通过映射 XML 文件的方式编写和关联对应的 SQL 语句。上面解析 `<mappers/>` 标签实现时我们看到方法通过调用 `MapperRegistry#addMapper` 方法注册相应的 Mapper 接口，包括以 package 配置的方式在扫描获取到相应的 Mapper 接口之后，也需要通过调用该方法进行注册。MapperRegistry 类中定义了两个属性：\n\n```java\n/** 全局唯一配置对象 */\nprivate final Configuration config;\n/** 记录 Mapper 接口（Class 对象）与 {@link MapperProxyFactory} 之间的映射关系 */\nprivate final Map<Class<?>, MapperProxyFactory<?>> knownMappers = new HashMap<>();\n```\n\n上面调用的 `MapperRegistry#addMapper` 方法实现如下：\n\n```java\npublic <T> void addMapper(Class<T> type) {\n    if (type.isInterface()) {\n        // 对应 Mapper 接口已注册\n        if (this.hasMapper(type)) {\n            throw new BindingException(\"Type \" + type + \" is already known to the MapperRegistry.\");\n        }\n        // 标记整个过程是否成功完成\n        boolean loadCompleted = false;\n        try {\n            // 注册 Mapper 接口 Class 对象与 MapperProxyFactory 之间的映射关系\n            knownMappers.put(type, new MapperProxyFactory<>(type));\n            // It's important that the type is added before the parser is run\n            // otherwise the binding may automatically be attempted by the\n            // mapper parser. If the type is already known, it won't try.\n            MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type);\n            // 解析 Mapper 接口中的注解 SQL 配置\n            parser.parse();\n            loadCompleted = true;\n        } finally {\n            if (!loadCompleted) {\n                knownMappers.remove(type);\n            }\n        }\n    }\n}\n```\n\nMapper 方法必须是一个接口才会被注册，这主要是为了配合 JDK 内置的动态代理机制。上一篇介绍 MyBatis 的基本运行原理时我们曾说过，MyBatis 通过为 Mapper 接口创建相应的动态代理类以执行具体的数据库操作，这一部分的详细过程将留到后面介绍 SQL 语句执行机制时再细讲，这里先知道有这样一个概念即可。如果当前 Mapper 接口还没有被注册，则会创建对应的 MapperProxyFactory 对象并记录到 `MapperRegistry#knownMappers` 属性中，然后解析 Mapper 接口中注解的 SQL 配置，这一过程留到下一篇分析映射文件解析过程时再一并介绍。\n\n### 总结\n\n到此，我们完成了对配置文件 `mybatis-config.xml` 加载和解析过程的分析。总的来说，对于配置文件的解析实际上就是将静态的 XML 配置解析成内存中的 Configuration 对象的过程。Configuration 可以看作是 MyBatis 全局的配置中心，后续对于映射文件的解析，以及 SQL 语句的执行都依赖于其中的配置项。下一篇，我们将一起来探究映射文件的加载和解析过程。\n\n### 参考\n\n1. [MyBatis 官方文档](https://mybatis.org/mybatis-3/zh/index.html)\n2. [MyBatis 技术内幕](https://book.douban.com/subject/27087564/)\n","tags":["MyBatis"],"categories":["mybatis"]},{"title":"MyBatis 源码解析：架构初探","url":"/2017/10/10/mybatis/mybatis-overview/","content":"\n[MyBatis](http://blog.mybatis.org/) 是一个易用、轻量，且强大的半自动化 ORM 框架，在设计思想和代码实现上都有许多值得我们借鉴的地方，例如动态代理机制的应用，资源文件的加载与解析，缓存模块的设计、反射机制的应用，插件模块的设计，架构分层，以及对设计模式的应用等，是一个非常适合初入源码阅读领域的练手项目。本系列文章将从配置文件解析、映射文件解析，以及 SQL 语句执行机制这三个大方向对整个框架的实现展开分析。本文是本系列的第一篇文章，主要从整体的角度对 MyBatis 的架构设计做一个综述性的介绍。<!-- more -->\n\n在正式开始之前，先以一个小例子演示一下 MyBatis 的基本使用。MyBatis 目前已经同时支持 XML 和注解的方式编写 SQL 语句，虽然注解在 Spring 中极大的提升了使用体验，但是对于 MyBatis 而言，个人还是比较倾向于 XML 配置 SQL 语句。下面的示例采用 XML 配置的方式：\n\n```xml\n<resultMap id=\"BaseResultMap\" type=\"org.zhenchao.mybatis.entity.User\">\n    <id column=\"id\" jdbcType=\"BIGINT\" property=\"id\"/>\n    <result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/>\n    <result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/>\n    <result column=\"age\" jdbcType=\"INTEGER\" property=\"age\"/>\n    <result column=\"phone\" jdbcType=\"VARCHAR\" property=\"phone\"/>\n    <result column=\"email\" jdbcType=\"VARCHAR\" property=\"email\"/>\n</resultMap>\n\n<sql id=\"Base_Column_List\">\n    id, username, `password`, age, phone, email\n</sql>\n\n<select id=\"selectByName\" parameterType=\"java.lang.String\" resultMap=\"BaseResultMap\">\n    select\n    <include refid=\"Base_Column_List\"/>\n    from t_user\n    where username = #{name,jdbcType=VARCHAR}\n</select>\n```\n\n接下来，我们就可以编写代码基于 MyBatis 执行数据库操作，示例如下：\n\n```java\nSqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder()\n        .build(Resources.getResourceAsStream(\"mybatis-config.xml\"));\ntry (SqlSession sqlSession = sessionFactory.openSession()) {\n    UserMapper mapper = sqlSession.getMapper(UserMapper.class);\n    User user = mapper.selectByName(\"zhenchao\");\n    // ... use user object\n}\n```\n\n这个小例子演示了查询指定名称对应的用户信息的操作，MyBatis 可以基于传递的参数动态生成对应的 SQL 语句。后面的源码分析章节，我们将围绕这个小例子去探究 MyBatis 加载解析资源文件、绑定实参并执行方法对应的 SQL 语句，以及最终返回目标实体对象的过程。下面先对 MyBatis 的运行机制做一个简单的概括，先从整体上对该框架的执行过程有一个感知。\n\nMyBatis 是基于配置的框架，它包含两大类型的配置文件，即 `mybatis-config.xml` 和 Mapper 接口对应的 SQL 语句配置。这里先约定一下，后面的文章中我们会将前者称为 __配置文件__ ，而将后者称为 __映射文件__ 。MyBatis 框架在启动时会加载并解析这两大类配置，整个过程对应上述示例中的第一行代码。当完成了对框架的初始化过程，接下来我们就可以创建数据库会话，获取 Mapper 对象并执行目标数据库操作，这一过程可以用下面这幅时序图进行描述：\n\n![image](/images/2017/mybatis-execute-sql.png)\n\nSqlSession 是 MyBatis 对外提供的执行数据库操作的统一接口，表示一次数据库会话，所以在具体操作数据库之前需要先开启会话（即获取 SqlSession 对象）。然后需要告知 MyBatis 当前期望操作的具体 Mapper 接口，MyBatis 规定所有的 Mapper 需要定义成接口的形式，这主要是配合 JDK 自带的动态代理机制。MyBatis 会基于动态代理机制为当前 Mapper 接口创建对应的代理对象，并激活对象的 `InvocationHandler#invoke` 方法。在方法执行过程中判断当前的 SQL 语句类型，并转给 SQL 执行器 Executor 去执行。Executor 先尝试从框架自带的缓存（一级缓存和二级缓存）中获取当前查询对应的结果，如果缓存不命中则会执行数据库操作。对于查询操作而言，数据库返回的结果集与我们期望的实体对象之间还差那么一丢丢，此时，MyBatis 强大的结果集映射处理就可以大显身手，将结果集按照我们的配置映射成为具体的实体类对象（集合）返回。\n\n以上只是大致对框架的运行机制做了一个概括，具体的实现细节后续会用专门的文章进行讲解。下面来看一下 MyBatis 整体的架构设计，如下图所示：\n\n![image](/images/2017/mybatis-framework.png)\n\n按照功能进行划分，并参考前人的一些总结，我将 MyBatis 的架构设计分为三层：基础支持层、核心处理层，以及对外接口层。本系列后续的文章中将分别从配置文件解析、映射文件解析，以及 SQL 语句执行机制三个方面对 MyBatis 的实现进行探究，期间会涉及到上图中的各个模块。拟定博文标题如下：\n\n1. MyBatis 源码解析：配置文件的加载与解析\n2. MyBatis 源码解析：映射文件的加载与解析\n3. MyBatis 源码解析：SQL 语句执行机制\n\n上车，走啦～\n","tags":["MyBatis"],"categories":["mybatis"]},{"title":"理解 Paxos 分布式共识算法","url":"/2017/09/14/protocol/paxos/","content":"\n什么？Paxos 号称是最难理解的算法？虽然有些夸张，那也得看一下！\n\n直接入正题，在分布式系统中存在多个主机节点，这些主机之间的通信机制一般分为 __共享内存__ 和 __消息传递__ 两种。这两种方式各有优劣，而 paxos 算法主要用来解决基于消息机制的分布式一致性问题。\n\n在分布式系统中，网络一般被认为是不可靠的，所以传递的消息可能会存在延迟、丢失、重复等问题，发送消息的进程也可能出现运行缓慢、重启，甚至被杀死等情况。Paxos 算法解决的问题是在一个可能发生这些异常（不包括消息可能被篡改的情况）的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决策一致性的问题。<!-- more -->\n\n### 算法陈述\n\n在 paxos 算法中定义了三种角色，包括 __提案者（Proposer）__ 、__决策者（Acceptor）__ ，以及 __学习者（Learner）__ 。其中 proposer 和 acceptor 是整个算法的核心角色，paxos 描述的就是在一个由多个 proposer 和多个 acceptor 构成的系统中，如何让多个 acceptor 针对 proposer 提出的多种提案达成一致的过程，而 learner 只是“学习”最终被批准的提案。\n\n需要注意的是这里的角色不是相互独立的，也就是说一个进程可以充当多种角色，并且为了防止单点故障，在一个分布式系统中往往存在多个 acceptor，其个数一般都是大于 2 的奇数，以实现协议所依赖的少数服从多数原则。\n\n我们先来对整个算法进行描述，暂时先不考虑算法如何保证一致性。假设现在有若干 proposer 和 acceptor，每个 proposer 都可以提出一个或多个提案，而每个 acceptor 也可以批准一个或多个提案，我们最终的目标就是希望在这些被提出的提案中选择唯一一个进行批准，而所有的 proposer 都需要认可这个被批准的提案。我们令提案的格式为 `[m, v]`，其中 m 表示提案的编号（ __全局唯一__ ），而 v 表示提案的内容（提案值），整个算法分为两个阶段：\n\n- __第一阶段__\n\n1. Proposer 选择一个编号为 m 的提案，然后向 acceptor 的某个超过半数的子集发送编号为 m 的 prepare 请求。\n2. 当 acceptor 收到一个编号为 m 的 prepare 请求，且编号 m 大于该 acceptor 已经响应的最大编号的 prepare 请求，则将其批准过的最大编号的提案作为响应发送给 proposer，同时承诺不再批准任何编号小于 m 的提案。\n\n- __第二阶段__\n\n1. 如果 proposer 收到来自半数以上 acceptor 的 prepare 响应，则会发送一个内容为 `[m, v]` 的 accept 请求，这里的 v 是之前 prepare 请求收到的最大编号提案对应的提案值，如果 prepare 响应不包含任何提案，则可以是任意值。\n2. 当 acceptor 收到 accept 请求，只要该 acceptor 尚未对编号大于 m 的提案做出过响应，就可以批准该提案。\n\n由上面的执行过程我们可以看到，其实 paxos 算法并不是很复杂，甚至可以说其执行过程还是很简单的，而真正让大家感觉其难以理解的关键在于如何证明这么简单的两个阶段执行过程能够保证在分布式系统下达成一致。\n\n### 算法推导\n\n在这一节中，将借鉴作者的思路，逐步来推导出整个算法。首先我们需要明白整个算法是建立在 __“少数服从多数”__ 的选举原则之上的，这里的少数和多数指的是批准提案的 acceptor 的数目，然后我们需要清楚目前所面临的限制性条件，实际上主要有两点：\n\n1. 提案只有被 proposer 提出后，才可以被 acceptor 批准。\n2. 在一次算法的执行过程中，仅有一个提案被批准。\n\n注意：这里说的只有一个提案被批准，更准确的说是只有一个提案值被批准，因为我们会对每个提案都附加一个全局唯一的提案编号，不同的编号可以对应同一个提案值，在算法的执行过程中，可以批准多个不同编号的提案，但这些提案必须持有相同的提案值。\n\n为了保证当只有一个提案被提出时也能被正确选举，算法首先做了如下约束：\n\n> P1: 一个 acceptor 必须批准它收到的第一个提案\n\n但是仅有上述条件是不够的，可以设想极端条件下每个 proposer 都将其提出的提案提交给了不同的 acceptor，这个时候按照 P1 原则，每个 acceptor 都需要接受它所收到的第一个提案，这样就无法满足 “少数服从多数” 原则，也就意味着一个 acceptor 可以批准多个提案，于是引出第二个约束（依然按照第一节中我们对于提案的格式定义）：\n\n> P2: 如果提案 `[m, v]` 被选定了，那么所有比编号 m 更高，且被选定的提案，其提案值必须是 v\n\n如果在一个分布式系统中能够同时满足 P1 和 P2，那么一致性就能够保证。其中 P1 可以保证算法能够正常的向前推进，而 P2 能够保证最终仅有一个提案值被批准，这并不难理解，实际上 P2 可以简单理解为对于一致性的描述。\n\n那么如何才能做到这两点呢？我们可以对 P2 做如下增强：\n\n> P2a: 如果提案 `[m, v]` 被选定了，那么所有比编号 m 更高，且被任何 acceptor 批准的提案，其提案值必须是 v\n\n但是 P2a 和 P1 是矛盾的，因为各个 acceptor 之间可以看作是独立的，彼此之间通过消息机制进行通信，所以无法做到各个 acceptor 关于其它已批准提案值的实时同步，如果其中某个未批准过任何提案的 acceptor 还不知道当前已经被批准的提案值，而此时正好有一个 proposer 发送了一个更大编号的新提案，按照 P1 的规则是要接受这个新提案的，但此时就违背了 P2a。\n\n既然 acceptor 无法保证一致性，那么我们就换个角度从 proposer 出发：\n\n> P2b: 如果提案 `[m, v]` 被选定了，那么之后任何 proposer 产生的编号更高的提案，其提案值都为 v\n\n由于 acceptor 收到的提案来源于 proposer，所以 p2b 也算是从源头上对 p2a 进行保证，是更强的约束。那么如何实现呢？如果要实现到这一层面，似乎 proposer 之间需要具备某种协商通信的机制，但是既然 proposer 都能从源头上保证提出提案的一致性了，还需要 paxos 干啥？似乎饶了一大圈又回到了原点。\n\n我们需要换个角度思考 P2b，假设提案 `[m, v]` 已经被批准了，那么什么情况下，对于编号 n (n > m) 来说都有提案值 v 呢？\n\n> P2c：如果一个编号为 n 的提案具有提案值 v，那么存在一个过半数集合满足如下两个条件之一：\n>\n> 1. 集合中所有 acceptor 都没有接受编号小于 n 的任何提案\n> 2. 集合中 acceptor 已经接受的所有编号小于 n 的提案中编号最大的那个提案的值为 v\n\n现在我们的问题变成了如何证明 P2c 蕴含 P2b，我们暂时把证明过程搁置一下，先看看如何满足 P2c。\n\n要满足 P2c 的约束，即当一个 `[m, v]` 的提案被批准之后，proposer 新提出的提案 `[n, w] (n > m)` 要满足 w = v，那么 proposer 必定在提出新的提案之前需要与 acceptor 进行通信，以约束新的新提出的提案值。所以就有了第 1 节中两个阶段的算法执行过程。\n\n我们最后再来整理一下 proposer 生成提案，以及 acceptor 批准提案的过程。\n\n> __Proposer 生成提案__\n\nProposer 在产生一个编号为 m 的提案时，必须要知道当前某一个将要或已经被半数以上 acceptor 批准的编号小于 m 的最大编号提案，并要求所有的 acceptor 不再批准任何编号小于 m 的提案。\n\n- __prepare 请求__\n\nProposer 选择一个新的提案编号 m，并向某个半数以上 acceptor 集合发送提案请求，要求集合中的 acceptor 做如下回应：\n\n1. 向 proposer 承诺不再批准任何编号小于 m 的提案\n2. 如果 acceptor 已经批准过任何提案，那么就向 proposer 反馈已经批准的编号小于 m 的最大编号对应的提案值\n\n- __accept 请求__\n\n当 proposer 收到半数以上 acceptor 响应结果之后，就可以产生 `[m, v]` 的提案，这里的 v 是所有响应中编号最大的提案值。如果之前半数以上的 acceptor 未批准过任何提案，那么响应中也就不会包含任何提案值，此时提案值可以由 proposer 自己决定。一旦确定提案，proposer 就可以向某个 acceptor 集合（注意这时候的集合不一定是 prepare 请求时候的集合）发送提案，并希望该提案被批准。\n\n> __Acceptor 批准提案__\n\nProposer 提案请求包括 prepare 和 accept 两类请求，acceptor 针对这两类请求的响应策略分别为：\n\n针对 __prepare 请求__，acceptor 可以在任何时间响应一个 prepare 请求。针对 __accept 请求__，在不违背 acceptor 现有承诺的前提下，可以任意响应 accept 请求。\n\n到这里整个算法就推导完了，慢着，似乎还有一件事情没有做，我们需要证明 P2c 蕴含 P2b，我们先来回忆一下我们已有的条件是什么，以及我们希望得到什么。\n\n已有的条件（P2c）：\n\n> 假设提案 `[m, v]` 已经被批准了，如果寄希望对于编号 n (n > m) 的提案来说也有提案值 v，则需要满足如下两个条件之一：\n>\n> 1. 集合中所有 acceptor 都没有接受过任何编号小于 n 的提案\n> 2. 集合中 acceptor 已经接受的所有编号小于 n 的提案中编号最大的那个提案的值为 v\n\n希望得到的结论（P2b）:\n\n> 如果提案 `[m, v]` 被选定了，那么之后任何 proposer 产生的编号更高的提案，其提案值都为 v\n\n这里我们采用 __数学归纳法__ 进行证明：\n\n假设提案 `[m, v]` 已经被批准，\n\n当 n=m+1 时，采用反证法，假设有提案 `[n, w] (w ≠ v)` 被批准，则说明至少有一个过半数 acceptor 集合满足如下两个条件之一：\n\n1. 这个集合中的 acceptor 未批准过任何提案\n2. 这个集合中的 acceptor 所接受的所有编号小于 n 的提案中最大编号的提案值是 w\n\n由于两个过半数集合之间必定有交集，且由条件可知其中一个集合已经批准了 `[m, v]` 提案，所以这两个条件均不能满足，所以当 n=m+1 时，w 必定等于 v。\n\n当编号为 `(m+1)...(N-1)` 的所有提案的提案值都为 v，采用反证法，假设有提案 `[N, w] (w ≠ v)` 被批准，则说明至少存在一个过半数 acceptor 集合满足如下两个条件之一：\n\n1. 这个集合中的 acceptor 未批准过任何提案\n2. 这个集合中的 acceptor 所接受的所有编号小于 n 的提案中最大编号的提案值是 w\n\n由于两个过半数集合之间必定存在交集，且由条件可知其中一个集合已经批准了 `[m, v]` 提案，所以这两个条件均不能满足，所以当 n=N 时，w 必定等于 v。\n\n由此我们可以得出 P2c 蕴含 P2b，而整个算法的推导过程也是条件逐渐增强的过程，而算法最终能够满足 P1 和 P2c，再加上 `P2c -> P2b -> P2a -> P2`，所以间接可以得出算法能够满足 P1 和 P2，而由 P1 和 P2 显然可以保证分布式一致性，所以 paxos 算法得证。\n\n### 图解算法\n\n最后我们用一张图演示一次简单的 paxos 执行过程。这里我们设置了 2 个 proposer 和 5 个 acceptor。\n\n![image](/images/2017/paxos.png)\n\n算法的执行过程如下：\n\n1. proposer_1 选择提案编号 1，并向 acceptor_1~3 发送 prepare 请求；\n2. 因为 acceptor_1~3 之前未响应过任何提案，所以响应 null 值（这里以 N/A 代替）；\n3. proposer_1 在收到响应之后，因为响应值都为 null，所以自己可以决定发送的提案值，假设这里发送了提案 (1, x)；\n4. 服务器批准了该提案，并承诺不再接受编号小于 1 的提案；\n5. 于此同时 proposer_2 选择提案编号 2，并向 acceptor_3~5 发送 prepare 请求；\n6. acceptor_4 和 5 因为之前未响应过任何提案，所以响应 null 值，但是 acceptor_3 因为之前已经响应过 proposer_1 的请求，所以此时应该响应 (1, x)；\n7. proposer_2 收到响应之后应该选择编号最大的提案值，而不能自己任意决定，所以 proposer_2 只能发送提案 (2, x)；\n8. 因为 proposer_2 的提案编号更大，同时提案值与之前批准的提案值相同，所以可以批准该提案；\n9. 最终在本次算法执行结束，提案值 x 被唯一确定，各个主机之前没有争议，接下去可以交由 learner 去学习。\n\n### 参考\n\n1. [维基百科: Paxos算法](https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95)\n2. [Paxos Made Simple](http://research.microsoft.com/users/lamport/pubs/paxos-simple.pdf)\n","tags":["Paxos","分布式","分布式共识"],"categories":["protocol"]},{"title":"探秘 ThreadLocal 的实现机制与小地雷","url":"/2017/08/18/java/threadlocal/","content":"\nJava 多线程类库对于共享数据的读写访问主要采用同步机制来保证线程安全，而本文所要探究的 ThreadLocal 则采用了一种完全不同的策略，它不是用来解决共享数据的并发访问问题的，ThreadLocal 让每个线程都将目标数据复制一份作为线程私有，后续对于该数据的操作都是在各自私有的副本上进行，线程之间彼此相互隔离，也就不存在竞争问题。\n\n下面的例子演示了 ThreadLocal 的典型应用场景。在 jdk 1.8 之前，如果我们希望对日期和时间进行格式化操作，则需要使用 SimpleDateFormat 类，而我们知道它是是线程不安全的，在多线程并发执行时会出现一些奇怪的问题。<!-- more -->对于该类使用的最佳实践则是采用 ThreadLocal 进行包装，以保证每个线程都有一份属于自己的 SimpleDateFormat 对象，如下所示：\n\n```java\nThreadLocal<SimpleDateFormat> sdf = new ThreadLocal<SimpleDateFormat>() {\n    @Override\n    protected SimpleDateFormat initialValue() {\n        return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n    }\n};\n```\n\n### 实现机制\n\n那么 ThreadLocal 是怎么做到让修饰的对象能够在每个线程中各自持有一份呢？我们先来从整体的角度简单概括一下。\n\n在 ThreadLocal 中定义了一个静态内部类 ThreadLocalMap，可以将其理解为一个特有的 Map 类型，而在 Thread 类中声明了一个 ThreadLocalMap 类型的 threadLocals 属性。针对每个 Thread 对象，也就是每个线程来说都包含了一个 ThreadLocalMap 对象，即每个线程都有一个属于自己的内存数据库，而数据库中存储的就是我们用 ThreadLocal 修饰的对象。整个过程还是有点绕的，可以借助下面这幅图进行理解：\n\n![image](/images/2017/thread_local.png)\n\n这里的 key 就是对应的 ThreadLocal 对象自身，而 value 就是 ThreadLocal 修饰的属性值。当希望获取该对象时，我们首先需要拿到当前线程对应的 Thread 对象，然后获取到该对象对应的 threadLocals 属性，也就拿到了线程私有的内存数据库，最后以 ThreadLocal 对象为 key 获取到其修饰的目标值。\n\n#### 线程内存数据库\n\n接下来看一下相应的源码实现，首先来看一下内部定义的 ThreadLocalMap 静态内部类：\n\n```java\nstatic class ThreadLocalMap {\n\n    // 弱引用的key，继承自 WeakReference\n    static class Entry extends WeakReference<ThreadLocal<?>> {\n        /** ThreadLocal 修饰的对象 */\n        Object value;\n\n        Entry(ThreadLocal<?> k, Object v) {\n            super(k);\n            value = v;\n        }\n    }\n\n    /** 初始化大小，必须是二次幂 */\n    private static final int INITIAL_CAPACITY = 16;\n    /** 承载键值对的表，长度必须是二次幂 */\n    private Entry[] table;\n    /** 记录键值对表的大小 */\n    private int size = 0;\n    /** 再散列阈值 */\n    private int threshold; // Default to 0\n\n    // 构造方法\n    ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {\n        table = new Entry[INITIAL_CAPACITY];\n        int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);\n        table[i] = new Entry(firstKey, firstValue);\n        size = 1;\n        setThreshold(INITIAL_CAPACITY);\n    }\n\n    // 构造方法\n    private ThreadLocalMap(ThreadLocalMap parentMap) {\n        Entry[] parentTable = parentMap.table;\n        int len = parentTable.length;\n        setThreshold(len);\n        table = new Entry[len];\n\n        for (int j = 0; j < len; j++) {\n            Entry e = parentTable[j];\n            if (e != null) {\n                @SuppressWarnings(\"unchecked\")\n                ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();\n                if (key != null) {\n                    Object value = key.childValue(e.value);\n                    Entry c = new Entry(key, value);\n                    int h = key.threadLocalHashCode & (len - 1);\n                    while (table[h] != null)\n                        h = nextIndex(h, len);\n                    table[h] = c;\n                    size++;\n                }\n            }\n        }\n    }\n\n    // 省略相应的方法实现\n}\n```\n\nThreadLocalMap 是一个定制化的 Map 实现，可以简单将其理解为一般的 Map，用作键值存储的内存数据库，至于为什么要专门实现而不是复用已有的 HashMap，我们在后面进行说明。\n\n#### API 实现分析\n\n了解了 ThreadLocalMap 的定义，我们再来看一下 ThreadLocal 的实现。对于 ThreadLocal 来说，对外暴露的方法主要有 get、set，以及 remove 三个，下面逐一展开分析。\n\n##### 获取线程私有值\n\n与一般的 Map 取值操作不同，这里的 `ThreadLocal#get` 方法并没有要求提供查询的 key，也正如前面所说的，这里的 key 就是调用 `ThreadLocal#get` 方法的 ThreadLocal 对象自身：\n\n```java\npublic T get() {\n    // 获取当前线程对象\n    Thread t = Thread.currentThread();\n    // 获取当前线程对象的 threadLocals 属性\n    ThreadLocalMap map = getMap(t);\n    if (map != null) {\n        // 以 ThreadLocal 对象为 key 获取目标线程私有值\n        ThreadLocalMap.Entry e = map.getEntry(this);\n        if (e != null) {\n            @SuppressWarnings(\"unchecked\")\n            T result = (T)e.value;\n            return result;\n        }\n    }\n    return setInitialValue();\n}\n```\n\n如果当前线程对应的内存数据库 map 对象还未创建，则会调用 `ThreadLocal#setInitialValue` 方法执行创建，如果在构造 ThreadLocal 对象时覆盖实现了 `ThreadLocal#initialValue` 方法，则会调用该方法获取构造的初始化值并记录到创建的 map 对象中：\n\n```java\nprivate T setInitialValue() {\n    // 调用模板方法 initialValue 获取指定的初始值\n    T value = initialValue();\n    Thread t = Thread.currentThread();\n    ThreadLocalMap map = getMap(t);\n    if (map != null)\n        // 以当前 ThreadLocal 对象为 key 记录初始值\n        map.set(this, value);\n    else\n        // 创建 map 并记录初始值\n        createMap(t, value);\n    return value;\n}\n```\n\n##### 设置线程私有值\n\n再来看一下 `ThreadLocal#set` 方法，因为 key 就是当前 ThreadLocal 对象，所以 `ThreadLocal#set` 方法也不需要指定 key：\n\n```java\npublic void set(T value) {\n    // 获取当前线程对象\n    Thread t = Thread.currentThread();\n    // 获取当前线程对象的 threadLocals 属性\n    ThreadLocalMap map = getMap(t);\n    if (map != null)\n        // 以当前 ThreadLocal 对象为 key 记录线程私有值\n        map.set(this, value);\n    else\n        createMap(t, value);\n}\n```\n\n和 `ThreadLocal#get` 方法的流程大致一样，都是操作当前线程私有的内存数据库 ThreadLocalMap，并记录目标值。\n\n##### 删除线程私有值\n\n方法 `ThreadLocal#remove` 以当前 ThreadLocal 对象为 key，从当前线程内存数据库 ThreadLocalMap 中删除目标值，具体逻辑比较简单：\n\n```java\npublic void remove() {\n    ThreadLocalMap m = getMap(Thread.currentThread());\n    if (m != null)\n        // 以当前 ThreadLocal 对象为 key\n        m.remove(this);\n}\n```\n\nThreadLocal 对外暴露的功能虽然有点小神奇，但是具体对应到内部实现并没有什么复杂的逻辑。如果我们把每个线程持有的专属 ThreadLocalMap 对象理解为当前线程的私有数据库，那么也就不难理解 ThreadLocal 的运行机制。每个线程自己维护自己的数据，彼此相互隔离，不存在竞争，也就没有线程安全问题可言。\n\n### 真的就高枕无忧了吗\n\n虽然对于每个线程来说数据是隔离的，但这也不表示任何对象丢到 ThreadLocal 中就万事大吉了，思考一下下面几种情况：\n\n1. __如果记录在 ThreadLocal 中的是一个线程共享的外部对象呢？__\n2. __引入线程池，情况又会有什么变化？__\n3. __如果 ThreadLocal 被 static 关键字修饰呢？__\n\n先来看 __第 1 个问题__ ，如果我们记录的是一个外部线程共享的对象，虽然我们以当前线程私有的 ThreadLocal 对象作为 key 对其进行了存储，但是恶魔终究是恶魔，共享的本质并不会因此而改变，这种情况下的访问还是需要进行同步控制，最好的方法就是从源头屏蔽掉这类问题。我们来举个例子：\n\n```java\npublic class ThreadLocalWithSharedInstance implements Runnable {\n\n    // list 是一个事实共享的实例，即使被 ThreadLocal 修饰\n    private static List<String> list = new ArrayList<>();\n    private ThreadLocal<List<String>> threadLocal = ThreadLocal.withInitial(() -> list);\n\n    @Override\n    public void run() {\n        for (int i = 0; i < 5; i++) {\n            List<String> li = threadLocal.get();\n            li.add(Thread.currentThread().getName() + \"_\" + RandomUtils.nextInt(0, 10));\n            threadLocal.set(li);\n        }\n        System.out.println(\"[Thread-\" + Thread.currentThread().getName() + \"], list=\" + threadLocal.get());\n    }\n\n    public static void main(String[] args) throws Exception {\n        Thread ta = new Thread(new ThreadLocalWithSharedInstance(), \"a\");\n        Thread tb = new Thread(new ThreadLocalWithSharedInstance(), \"b\");\n        Thread tc = new Thread(new ThreadLocalWithSharedInstance(), \"c\");\n        ta.start(); ta.join();\n        tb.start(); tb.join();\n        tc.start(); tc.join();\n    }\n}\n```\n\n以上程序最终的输出如下：\n\n```text\n[Thread-a], list=[a_2, a_7, a_4, a_5, a_7]\n[Thread-b], list=[a_2, a_7, a_4, a_5, a_7, b_3, b_3, b_4, b_7, b_7]\n[Thread-c], list=[a_2, a_7, a_4, a_5, a_7, b_3, b_3, b_4, b_7, b_7, c_8, c_3, c_4, c_7, c_5]\n```\n\n可以看到虽然使用了 ThreadLocal 修饰，但是 list 还是以共享的方式在多个线程之间被访问，如果不加控制则会存在线程安全问题。\n\n再来看 __第 2 个问题__ ，相对问题 1 来说引入线程池就更加可怕，因为大部分时候我们都不会意识到问题的存在，直到代码暴露出奇怪的现象。这一场景并没有违背线程私有的本质，只是一个线程被复用来处理多个业务，而这个被线程私有的对象也会在多个业务之间被共享。例如：\n\n```java\npublic class ThreadLocalWithThreadPool implements Callable<Boolean> {\n\n    private static final int NCPU = Runtime.getRuntime().availableProcessors();\n\n    private ThreadLocal<List<String>> threadLocal = ThreadLocal.withInitial(() -> {\n        System.out.println(\"thread-\" + Thread.currentThread().getId() + \" init thread local\");\n        return new ArrayList<>();\n    });\n\n    @Override\n    public Boolean call() throws Exception {\n        for (int i = 0; i < 5; i++) {\n            List<String> li = threadLocal.get();\n            li.add(Thread.currentThread().getId() + \"_\" + RandomUtils.nextInt(0, 10));\n            threadLocal.set(li);\n        }\n        System.out.println(\"[Thread-\" + Thread.currentThread().getId() + \"], list=\" + threadLocal.get());\n        return true;\n    }\n\n    public static void main(String[] args) throws Exception {\n        System.out.println(\"cpu core size : \" + NCPU);\n        List<Callable<Boolean>> tasks = new ArrayList<>(NCPU * 2);\n        ThreadLocalWithThreadPool tl = new ThreadLocalWithThreadPool();\n        for (int i = 0; i < NCPU * 2; i++) {\n            tasks.add(tl);\n        }\n        ExecutorService es = Executors.newFixedThreadPool(2);\n        List<Future<Boolean>> futures = es.invokeAll(tasks);\n        for (final Future<Boolean> future : futures) {\n            future.get();\n        }\n        es.shutdown();\n    }\n}\n```\n\n以上程序的最终输出如下：\n\n```text\ncpu core size : 8\nthread-12 init thread local\nthread-11 init thread local\n[Thread-12], list=[12_8, 12_8, 12_4, 12_0, 12_1]\n[Thread-11], list=[11_3, 11_3, 11_4, 11_8, 11_4]\n[Thread-12], list=[12_8, 12_8, 12_4, 12_0, 12_1, 12_6, 12_7, 12_8, 12_8, 12_8]\n[Thread-11], list=[11_3, 11_3, 11_4, 11_8, 11_4, 11_0, 11_2, 11_1, 11_7, 11_9]\n[Thread-12], list=[12_8, 12_8, 12_4, 12_0, 12_1, 12_6, 12_7, 12_8, 12_8, 12_8, 12_8, 12_2, 12_8, 12_0, 12_6]\n[Thread-11], list=[11_3, 11_3, 11_4, 11_8, 11_4, 11_0, 11_2, 11_1, 11_7, 11_9, 11_0, 11_6, 11_1, 11_2, 11_9]\n[Thread-12], list=[12_8, 12_8, 12_4, 12_0, 12_1, 12_6, 12_7, 12_8, 12_8, 12_8, 12_8, 12_2, 12_8, 12_0, 12_6, 12_6, 12_3, 12_3, 12_1, 12_1]\n[Thread-11], list=[11_3, 11_3, 11_4, 11_8, 11_4, 11_0, 11_2, 11_1, 11_7, 11_9, 11_0, 11_6, 11_1, 11_2, 11_9, 11_7, 11_5, 11_0, 11_6, 11_9]\n[Thread-12], list=[12_8, 12_8, 12_4, 12_0, 12_1, 12_6, 12_7, 12_8, 12_8, 12_8, 12_8, 12_2, 12_8, 12_0, 12_6, 12_6, 12_3, 12_3, 12_1, 12_1, 12_0, 12_0, 12_1, 12_9, 12_5]\n[Thread-11], list=[11_3, 11_3, 11_4, 11_8, 11_4, 11_0, 11_2, 11_1, 11_7, 11_9, 11_0, 11_6, 11_1, 11_2, 11_9, 11_7, 11_5, 11_0, 11_6, 11_9, 11_2, 11_7, 11_0, 11_8, 11_0]\n[Thread-12], list=[12_8, 12_8, 12_4, 12_0, 12_1, 12_6, 12_7, 12_8, 12_8, 12_8, 12_8, 12_2, 12_8, 12_0, 12_6, 12_6, 12_3, 12_3, 12_1, 12_1, 12_0, 12_0, 12_1, 12_9, 12_5, 12_3, 12_6, 12_6, 12_0, 12_9]\n[Thread-11], list=[11_3, 11_3, 11_4, 11_8, 11_4, 11_0, 11_2, 11_1, 11_7, 11_9, 11_0, 11_6, 11_1, 11_2, 11_9, 11_7, 11_5, 11_0, 11_6, 11_9, 11_2, 11_7, 11_0, 11_8, 11_0, 11_0, 11_9, 11_2, 11_7, 11_2]\n[Thread-12], list=[12_8, 12_8, 12_4, 12_0, 12_1, 12_6, 12_7, 12_8, 12_8, 12_8, 12_8, 12_2, 12_8, 12_0, 12_6, 12_6, 12_3, 12_3, 12_1, 12_1, 12_0, 12_0, 12_1, 12_9, 12_5, 12_3, 12_6, 12_6, 12_0, 12_9, 12_5, 12_7, 12_7, 12_9, 12_7]\n[Thread-11], list=[11_3, 11_3, 11_4, 11_8, 11_4, 11_0, 11_2, 11_1, 11_7, 11_9, 11_0, 11_6, 11_1, 11_2, 11_9, 11_7, 11_5, 11_0, 11_6, 11_9, 11_2, 11_7, 11_0, 11_8, 11_0, 11_0, 11_9, 11_2, 11_7, 11_2, 11_4, 11_9, 11_7, 11_5, 11_5]\n[Thread-12], list=[12_8, 12_8, 12_4, 12_0, 12_1, 12_6, 12_7, 12_8, 12_8, 12_8, 12_8, 12_2, 12_8, 12_0, 12_6, 12_6, 12_3, 12_3, 12_1, 12_1, 12_0, 12_0, 12_1, 12_9, 12_5, 12_3, 12_6, 12_6, 12_0, 12_9, 12_5, 12_7, 12_7, 12_9, 12_7, 12_6, 12_1, 12_7, 12_8, 12_7]\n[Thread-11], list=[11_3, 11_3, 11_4, 11_8, 11_4, 11_0, 11_2, 11_1, 11_7, 11_9, 11_0, 11_6, 11_1, 11_2, 11_9, 11_7, 11_5, 11_0, 11_6, 11_9, 11_2, 11_7, 11_0, 11_8, 11_0, 11_0, 11_9, 11_2, 11_7, 11_2, 11_4, 11_9, 11_7, 11_5, 11_5, 11_8, 11_5, 11_0, 11_2, 11_2]\n```\n\n示例中，我用一个大小为 2 的线程池进行了模拟，可以看到初始化方法被调用了两次，所有线程的操作都是复用这两个线程。\n\n回忆一下前文所说的，ThreadLocal 的本质就是为每个线程维护一个线程私有的内存数据库来记录线程私有的对象，但是在线程池情况下线程是会被复用的，也就是说线程私有的内存数据库也会被复用，如果在一个线程被使用完准备回放到线程池中之前，我们没有对记录在数据库中的数据执行清理，那么这部分数据就会被下一个复用该线程的业务看到，从而间接的共享了该部分数据。\n\n最后我们再来看一下 __第 3 个问题__ ，我们尝试将 ThreadLocal 对象用 static 关键字进行修饰：\n\n```java\npublic class ThreadLocalWithStaticEmbellish implements Runnable {\n\n    private static final int NCPU = Runtime.getRuntime().availableProcessors();\n\n    private static ThreadLocal<List<String>> threadLocal = ThreadLocal.withInitial(() -> {\n        System.out.println(\"thread-\" + Thread.currentThread().getName() + \" init thread local\");\n        return new ArrayList<>();\n    });\n\n    @Override\n    public void run() {\n        for (int i = 0; i < 5; i++) {\n            List<String> li = threadLocal.get();\n            li.add(Thread.currentThread().getId() + \"_\" + RandomUtils.nextInt(0, 10));\n            threadLocal.set(li);\n        }\n        System.out.println(\"[Thread-\" + Thread.currentThread().getName() + \"], list=\" + threadLocal.get());\n    }\n\n    public static void main(String[] args) throws Exception {\n        ThreadLocalWithStaticEmbellish tl = new ThreadLocalWithStaticEmbellish();\n        for (int i = 0; i < NCPU + 1; i++) {\n            Thread thread = new Thread(tl, String.valueOf((char) (i + 97)));\n            thread.start(); thread.join();\n        }\n    }\n}\n```\n\n以上程序的最终输出如下：\n\n```text\nthread-a init thread local\n[Thread-a], list=[11_4, 11_4, 11_4, 11_8, 11_0]\nthread-b init thread local\n[Thread-b], list=[12_0, 12_9, 12_0, 12_3, 12_3]\nthread-c init thread local\n[Thread-c], list=[13_6, 13_7, 13_5, 13_2, 13_0]\nthread-d init thread local\n[Thread-d], list=[14_1, 14_5, 14_5, 14_9, 14_2]\nthread-e init thread local\n[Thread-e], list=[15_4, 15_2, 15_6, 15_0, 15_8]\nthread-f init thread local\n[Thread-f], list=[16_7, 16_3, 16_8, 16_0, 16_0]\nthread-g init thread local\n[Thread-g], list=[17_6, 17_3, 17_8, 17_7, 17_1]\nthread-h init thread local\n[Thread-h], list=[18_0, 18_4, 18_5, 18_9, 18_3]\nthread-i init thread local\n[Thread-i], list=[19_7, 19_3, 19_7, 19_2, 19_0]\n```\n\n由程序运行结果可以看到 static 修饰并没有引出什么问题，实际上这也是很容易理解的，ThreadLocal 采用 static 修饰仅仅是让数据库中记录的 key 是一样的，但是每个线程的内存数据库还是私有的，并没有被共享，就像不同的公司都有自己的用户信息表，即使一些公司之间的用户 ID 是一样的，但是对应的用户数据却是完全隔离的。\n\n以上例子演示了一开始抛出的 3 个问题，其中问题 1 和问题 2 都是 ThreadLocal 使用过程中的小地雷。例子举的不一定恰当，实际中可能也不一定会如示例中这样去使用 ThreadLocal，主要还是为了传达一些意识。如果明白了 ThreadLocal 的内部实现细节，就能够很自然的绕过这些小地雷。\n\n### 真的会内存泄露吗\n\n关于 ThreadLocal 导致内存泄露的问题，曾经有一段时间在网上争得沸沸扬扬，那么到底会不会导致内存泄露呢？这里先给出答案：\n\n> __如果使用不恰当，存在内存泄露的可能性。__\n\n我们来分析一下内存泄露的条件和原因，在最开始看 ThreadLocal 源码的时候，我就有一个疑问，__ThreadLocal 为什么要专门实现 ThreadLocalMap，而不是采用已有的 HashMap 代替__ ？\n\n后来分析具体实现时看到执行存储时的 key 为当前 ThreadLocal 对象，不需要专门指定 key 能够在一定程度上简化使用，但这并不足以为此专门去实现 ThreadLocalMap。继续阅读我发现 ThreadLocalMap 在实现 Entry 的时候有些奇怪，居然继承了 WeakReference：\n\n```java\nstatic class Entry extends WeakReference<ThreadLocal<?>> {\n    /** The value associated with this ThreadLocal. */\n    Object value;\n\n    Entry(ThreadLocal<?> k, Object v) {\n        super(k);\n        value = v;\n    }\n}\n```\n\n从而让 key 成为一个弱引用，我们知道弱引用对象拥有非常短暂的生命周期，在垃圾收集器线程扫描其所管辖的内存区域过程中，一旦发现了弱引用对象，不管当前内存空间是否足够都会回收它的内存。也就是说这样的设计会很容易导致 ThreadLocal 对象被回收，线程所执行任务的时间长度是不固定的，这样的设计能够方便垃圾收集器回收线程私有的变量。\n\n由此可以看出作者这样设计的目的是为了防止内存泄露，那怎么就变成了被很多文章所分析的是内存泄漏的导火索呢？这些文章的共同观点就是 key 被回收了，但是 value 是一个强引用没有被回收，这些 value 就变成了一个个的僵尸。这样的分析没有错，value 确实存在，且和线程是同生命周期的，但是如下策略可以保证尽量避免内存泄露：\n\n1. ThreadLocal 在每次执行 get 和 set 操作的时候都会去清理 key 为 null 的 value 值。\n2. value 与线程同生命周期，线程死亡之时，也是 value 被 GC 之日。\n\n策略 1 没啥好说的，看看源码就知道，我们来举例验证一下策略 2：\n\n```java\npublic class ThreadLocalWithMemoryLeak implements Callable<Boolean> {\n\n    private class My50MB {\n\n        private byte[] buffer = new byte[50 * 1024 * 1024];\n\n        @Override\n        protected void finalize() throws Throwable {\n            super.finalize();\n            System.out.println(\"gc my 50 mb\");\n        }\n    }\n\n    private class MyThreadLocal<T> extends ThreadLocal<T> {\n\n        @Override\n        protected void finalize() throws Throwable {\n            super.finalize();\n            System.out.println(\"gc my thread local\");\n        }\n    }\n\n    private MyThreadLocal<My50MB> threadLocal = new MyThreadLocal<>();\n\n    @Override\n    public Boolean call() throws Exception {\n        System.out.println(\"Thread-\" + Thread.currentThread().getId() + \" is running\");\n        threadLocal.set(new My50MB());\n        threadLocal = null;\n        return true;\n    }\n\n    public static void main(String[] args) throws Exception {\n        ExecutorService es = Executors.newCachedThreadPool();\n        Future<Boolean> future = es.submit(new ThreadLocalWithMemoryLeak());\n        future.get();\n\n        // gc my thread local\n        System.out.println(\"do gc\");\n        System.gc();\n        TimeUnit.SECONDS.sleep(1);\n\n        // sleep 60s\n        System.out.println(\"sleep 60s\");\n        TimeUnit.SECONDS.sleep(60);\n\n        // gc my 50 mb\n        System.out.println(\"do gc\");\n        System.gc();\n\n        es.shutdown();\n    }\n\n}\n```\n\n以上程序的最终输出如下：\n\n```text\nThread-11 is running\ndo gc\ngc my thread local\nsleep 60s\ndo gc\ngc my 50 mb\n```\n\n可以看到 value 最终还是被 GC 了，虽然第 1 次 GC 的时候没有被回收，这也验证 value 和线程是同生命周期的，之所以示例中等待 60 秒是因为 `Executors#newCachedThreadPool` 中的线程默认生命周期是 60 秒，如果生命周期内该线程没有被再次复用则会死亡，我们这里就是要等待线程死亡，一但线程死亡，value 也就被 GC 了。\n\n所以 __出现内存泄露的前提必须是持有 value 的线程一直存活__ ，这在使用线程池时是很正常的，在这种情况下 value 一直不会被 GC，因为线程对象与 value 之间维护的是强引用。此外就是 __后续线程执行的业务一直没有调用 ThreadLocal 的 get 或 set 方法，导致不会主动去删除 key 为 null 的 value 对象__ ，在满足这两个条件下 value 对象一直常驻内存，所以存在内存泄露的可能性。\n\n那么我们应该怎么避免呢？前面我们分析过线程池情况下使用 ThreadLocal 存在小地雷，这里的内存泄露一般也都是发生在线程池的情况下，所以在使用 ThreadLocal 时，对于不再有效的 value 主动调用一下 remove 方法来进行清除，从而消除隐患，这也算是最佳实践吧。\n\n### InheritableThreadLocal 又是什么鬼\n\nInheritableThreadLocal 继承自 ThreadLocal，实现上也比较简单（如下），那么 InheritableThreadLocal 与 ThreadLocal 到底有什么区别呢？\n\n```java\npublic class InheritableThreadLocal<T> extends ThreadLocal<T> {\n\n    @Override\n    protected T childValue(T parentValue) {\n        return parentValue;\n    }\n\n    @Override\n    ThreadLocalMap getMap(Thread t) {\n        return t.inheritableThreadLocals;\n    }\n\n    @Override\n    void createMap(Thread t, T firstValue) {\n        t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);\n    }\n}\n```\n\n在开始分析之前，我们先演示一个 ThreadLocal 的案例，如下：\n\n```java\nprivate static ThreadLocal<String> tl = new ThreadLocal<>();\n\npublic static void main(String[] args) {\n    tl.set(\"zhenchao\");\n    System.out.println(\"Main thread: \" + tl.get());\n    Thread thread = new Thread(() -> System.out.println(\"Sub thread: \" + tl.get()));\n    thread.start();\n}\n```\n\n运行上述示例，输出如下：\n\n```text\nMain thread: zhenchao\nSub thread: null\n```\n\n可以看出，子线程拿不到主线程设置的 ThreadLocal 变量，当然这也是可以理解的，毕竟主线程和子线程之间仍然是两个线程，但是在一些场景下我们希望对于主线程和子线程这种关系而言，ThreadLocal 变量能够被继承。这个时候就可以使用 InheritableThreadLocal 来实现，对于上述示例而言，只需要将 ThreadLocal 改为 InheritableThreadLocal 即可，具体实现比较简单，读者可以自己尝试一下。\n\n下面我们来分析一下 InheritableThreadLocal 是如何做到让 ThreadLocal 变量在主线程和子线程之间进行继承的。由 InheritableThreadLocal 的实现来看，InheritableThreadLocal 使用了 inheritableThreadLocals 变量替换了 ThreadLocal 的 threadLocals 变量，而这两个变量都是 ThreadLocalMap 类型。子线程在初始化时会判断父线程的 inheritableThreadLocals 是否为 null，如果不为 null，则使用父类的 inheritableThreadLocals 变量初始化自己的 inheritableThreadLocals，实现如下（位于 `Thread#init` 方法中）：\n\n```java\n// 如果父线程的 inheritableThreadLocals 变量不为空，则复制给子线程\nif (inheritThreadLocals && parent.inheritableThreadLocals != null) {\n    this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);\n}\n```\n\n而 `ThreadLocal#createInheritedMap` 的实现如下：\n\n```java\nstatic ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) {\n    return new ThreadLocalMap(parentMap);\n}\n\nprivate ThreadLocalMap(ThreadLocalMap parentMap) {\n    Entry[] parentTable = parentMap.table;\n    int len = parentTable.length;\n    setThreshold(len);\n    table = new Entry[len];\n\n    for (int j = 0; j < len; j++) {\n        Entry e = parentTable[j];\n        if (e != null) {\n            @SuppressWarnings(\"unchecked\")\n            ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();\n            if (key != null) {\n                // 调用 InheritableThreadLocal 的 childValue 方法\n                Object value = key.childValue(e.value);\n                Entry c = new Entry(key, value);\n                int h = key.threadLocalHashCode & (len - 1);\n                while (table[h] != null) {\n                    h = nextIndex(h, len);\n                }\n                table[h] = c;\n                size++;\n            }\n        }\n    }\n}\n```\n\n方法 `InheritableThreadLocal#childValue` 的实现只是简单返回了父线程中的值，所以上述过程本质上就是一个拷贝父线程中 ThreadLocal 变量值的过程。\n\n由上述实现我们可以看到，父线程和子线程在 ThreadLocal 变量的存储上仍然是隔离的，只是在初始化子线程时会拷贝父线程的 ThreadLocal 变量，之后在运行期间彼此互不干涉，也就是说在子线程启动起来之后，父线程和子线程各自对同一个 InheritableThreadLocal 实例的改动并不会被对方所看见。\n\n### 总结\n\n本文我们分析了 ThreadLocal 的实现，以及存在的一些小地雷，并讨论了在什么情况下会造成内存泄漏，最后还分析了与 ThreadLocal 师出同宗的 InheritableThreadLocal 类。ThreadLocal 和 InheritableThreadLocal 在保证线程安全性方面算是另辟蹊径，能够在一些场景下简化多线程编程，是 java 程序员必须掌握的一部分。当然，理解其实现原理能够帮助我们更好的使用其特性，避免不经意踩到小地雷。\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"Spring MVC 源码解析：跟踪一次简单的请求处理过程","url":"/2017/07/23/spring/spring-mvc-request-sequence/","content":"\n上一篇我们分析了 web 环境下容器的初始化过程，探究了在 web 项目启动过程中，Spring MVC 所执行的一系列初始化工作，本篇中我们将一起来跟踪一次 Spring MVC 对于请求的具体处理过程，从整体上对 Spring MVC 的逻辑处理进行感知，先把握整体，后追究细节。<!-- more -->\n\n我们定义的控制器方法很简单，接收请求参数，然后记录到 Model 中并回显到页面上，实现如下：\n\n```java\n// http://localhost:8080/demo/hello?name=zhenchao\n@RequestMapping(\"/hello\")\npublic ModelAndView hello(@RequestParam(\"name\") String name) {\n    log.info(\"Do demo hello, name={}\", name);\n    ModelAndView mav = new ModelAndView();\n    mav.setViewName(\"hello\");\n    mav.addObject(\"name\", name);\n    return mav;\n}\n```\n\n当我们在浏览器中输入请求地址 `http://localhost:8080/demo/hello?name=zhenchao` 的时候，在请求到达服务器之前会经历域名解析、TCP连接、数据发送等过程，而这些都不是本文所要关注的重点，我们所要关注的是请求到达了 servlet 容器，执行一系列操作之后准备向客户端发送响应这中间的过程，排除服务器软件解析和封装的操作。\n\n![image](/images/2017/spring-mvc-request-sequence.png)\n\n上面的时序图展示了本次请求处理的完整过程，接下来我们从源码层面对整个过程进行分析。当该请求到达服务器之后，服务器首先会为该请求创建一个 socket 连接，然后创建对应的 request 和 response 对象封装请求信息，并交由相应的 servlet 进行处理。请求首先会进入 HttpServlet 的 `service(ServletRequest req, ServletResponse res)` 方法，该方法会将 ServletRequest 和 ServletResponse 分别转换成 HttpServletRequest 和 HttpServletResponse 对象，然后调用 `service(HttpServletRequest request, HttpServletResponse response)` 方法进行处理，FrameworkServlet 覆盖实现了该方法：\n\n```java\nprotected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n    HttpMethod httpMethod = HttpMethod.resolve(request.getMethod());\n    if (HttpMethod.PATCH == httpMethod || httpMethod == null) {\n        // PATCH方法是新引入的，是对PUT方法的补充，用来对已知资源进行局部更新\n        this.processRequest(request, response);\n    } else {\n        super.service(request, response);\n    }\n}\n```\n\n该方法主要功能是判定当前请求的方法类型，如果是 PATCH 方法或未知的方法类型则调用 processRequest 进行处理，否则直接委托父类的 `service(HttpServletRequest request, HttpServletResponse response)` 方法。而我们这里是以 GET 方法请求，所以直接进入 else 分支，即进入 HttpServlet 的 service 方法，该方法也是一个决策方法，用于判断当前的请求类型，并调用相应的 do 方法，这里我们会进入 doGet 方法逻辑，位于 FrameworkServlet 中的覆盖：\n\n```java\n@Override\nprotected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n    this.processRequest(request, response);\n}\n```\n\n这里只是简单的调用了 processRequest 方法，前面在判定为 PATCH 请求方法类型时调用的也是此方法，而 GET 方法这样绕一下也是为了对请求目标对象的变更时间进行处理：\n\n```java\nprotected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n    long startTime = System.currentTimeMillis();\n    Throwable failureCause = null;\n\n    // 暂存 LocaleContextHolder 中持有的之前的 LocaleContext 对象（存放当前的语言环境）\n    LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext();\n    // 从当前请求中构建 localeContext 对象\n    LocaleContext localeContext = this.buildLocaleContext(request);\n\n    // 暂存 RequestContextHolder 中持有的之前的 RequestAttributes 对象（用于管理 request 和 session 中的属性）\n    RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes();\n    // 从当前请求中构建 ServletRequestAttributes 对象\n    ServletRequestAttributes requestAttributes = this.buildRequestAttributes(request, response, previousAttributes);\n\n    // 获取异步处理管理器\n    WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\n    asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor());\n\n    // 将由当前请求构建的 localeContext 和 requestAttributes 设置到 LocaleContextHolder 和 RequestContextHolder 中\n    this.initContextHolders(request, localeContext, requestAttributes);\n\n    try {\n        // 核心方法\n        this.doService(request, response);\n    } catch (ServletException ex) {\n        failureCause = ex;\n        throw ex;\n    } catch (IOException ex) {\n        failureCause = ex;\n        throw ex;\n    } catch (Throwable ex) {\n        failureCause = ex;\n        throw new NestedServletException(\"Request processing failed\", ex);\n    } finally {\n        // 恢复之前的配置，不影响其它操作\n        this.resetContextHolders(request, previousLocaleContext, previousAttributes);\n        if (requestAttributes != null) {\n            requestAttributes.requestCompleted();\n        }\n        // 省略此处的 debug 日志\n\n        // 发布请求处理完成事件消息\n        this.publishRequestHandledEvent(request, response, startTime, failureCause);\n    }\n}\n```\n\nprocessRequest 首先获取并记录之前的 LocaleContext 和 RequestAttributes 对象，然后基于当前的请求构造新的 LocaleContext 和 RequestAttributes 对象并调用 initContextHolders 方法将其记录到相应的 holder 中，然后调用核心方法 doService 继续处理请求，等到该方法返回时会利用之前记录的 LocaleContext 和 RequestAttributes 对象更新对应的 holder。接下来我们继续探究 doService 方法：\n\n```java\nprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception {\n    if (logger.isDebugEnabled()) {\n        String resumed = WebAsyncUtils.getAsyncManager(request).hasConcurrentResult() ? \" resumed\" : \"\";\n        logger.debug(\"DispatcherServlet with name '\" + getServletName() + \"'\" + resumed + \" processing \" + request.getMethod() + \" request for [\" + getRequestUri(request) + \"]\");\n    }\n\n    // 如果是include请求，备份request中的attribute，便于后续恢复\n    Map<String, Object> attributesSnapshot = null;\n    if (WebUtils.isIncludeRequest(request)) {\n        attributesSnapshot = new HashMap<String, Object>();\n        Enumeration<?> attrNames = request.getAttributeNames();\n        while (attrNames.hasMoreElements()) {\n            String attrName = (String) attrNames.nextElement();\n            if (this.cleanupAfterInclude || attrName.startsWith(\"org.springframework.web.servlet\")) {\n                attributesSnapshot.put(attrName, request.getAttribute(attrName));\n            }\n        }\n    }\n\n    // 记录一些属性\n    request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.getWebApplicationContext()); // 应用上下文对象\n    request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); // localeResolver\n    request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); // themeResolver\n    request.setAttribute(THEME_SOURCE_ATTRIBUTE, this.getThemeSource()); // themeSource\n\n    // flashMap 相关参数，主要用于 redirect 时的参数传递\n    FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response);\n    if (inputFlashMap != null) {\n        request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap));\n    }\n    request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap());\n    request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager);\n\n    try {\n        // 核心方法\n        this.doDispatch(request, response);\n    } finally {\n        if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) {\n            // 还原之前备份的attribute\n            if (attributesSnapshot != null) {\n                this.restoreAttributesAfterInclude(request, attributesSnapshot);\n            }\n        }\n    }\n}\n```\n\n该方法主要还是为调用 doDispatch 方法做一些准备工作，记录了一些信息到 attribute 中。这里对 FlashMap 做一下说明，FlashMap 的主要功能是简化 redirect 请求传参，我们都知道记录在 request 中的参数在 redirect 时无法带到目标方法，基于纯 JSP 开发过 web 服务的同学一定曾经为此机制感到苦恼过，而解决这种问题最朴素的方法就是将参数拼接在请求地址的后面，但是这样的方式除了有长度限制之外，有时候还会有一定的安全问题。Spring MVC 则提供了 FlashMap 组件以解决这一问题，我们可以通过将需要 redirect 时传递的参数记录到 FlashMap 中即可实现传递，框架会自动将这些参数记录到目标接口的 Model 中，而这一机制本质上是基于 session 实现的。下面来举个例子帮大家回忆一下 FlashMap 的使用：\n\n```java\n@RequestMapping(\"/redirect\")\npublic String redirectParams(HttpServletRequest request, RedirectAttributes ra) {\n    /*1. 基于 RedirectAttributes 获取*/\n    ra.addFlashAttribute(\"user_id\", RandomUtils.nextLong()); // 放在flashMap中\n    ra.addAttribute(\"username\", \"zhenchao\"); // 拼接在请求地址的后面\n\n    /*2. 基于 RequestContextUtils 工具类来获取*/\n    FlashMap flashMap = RequestContextUtils.getOutputFlashMap(request);\n    flashMap.put(\"order_id\", RandomUtils.nextLong());\n\n    /*3. 更加底层的方法*/\n    flashMap = (FlashMap) request.getAttribute(DispatcherServlet.OUTPUT_FLASH_MAP_ATTRIBUTE);\n    flashMap.put(\"imei\", RandomStringUtils.randomAlphanumeric(32));\n\n    return \"redirect:display-result\";\n}\n```\n\n我们可以通过 RedirectAttributes 记录需要 redirect 传递的参数，RedirectAttributes 提供了两种方式，addFlashAttribute 方法会将参数记录到 FlashMap 对象中进行传递，而 addAttribute 方法则会将参数拼接在请求地址后面进行传递；此外我们还可以通过 RequestContextUtils 获取 FlashMap 对象直接往里面注入值，而这一方法本质上与上面列子中的第三种方法是相同的，框架最终还是以 `DispatcherServlet.OUTPUT_FLASH_MAP_ATTRIBUTE` 作为 key 将 FlashMap 对象记录在 attribute 中。\n\n```java\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {\n    HttpServletRequest processedRequest = request;\n    HandlerExecutionChain mappedHandler = null;\n    boolean multipartRequestParsed = false;\n    WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\n\n    try {\n        ModelAndView mv = null;\n        Exception dispatchException = null;\n        try {\n            // 如果是文件上传请求，则转换request为MultipartHttpServletRequest类型\n            processedRequest = this.checkMultipart(request);\n            multipartRequestParsed = (processedRequest != request); // 标记是否是上传请求\n\n            // 依据 request 寻找对应的 Handler （包括控制器方法和拦截器）\n            mappedHandler = this.getHandler(processedRequest);\n            if (mappedHandler == null || mappedHandler.getHandler() == null) {\n                // 未找到对应的 Handler\n                this.noHandlerFound(processedRequest, response);\n                return;\n            }\n\n            // 依据当前的 handler 寻找对应的 HandlerAdapter\n            HandlerAdapter adapter = this.getHandlerAdapter(mappedHandler.getHandler());\n\n            // 对于 GET 或 HEAD 方法检查目标页面是否有变更（Last-Modified）\n            String method = request.getMethod();\n            boolean isGet = \"GET\".equals(method);\n            if (isGet || \"HEAD\".equals(method)) {\n                long lastModified = adapter.getLastModified(request, mappedHandler.getHandler());\n                if (logger.isDebugEnabled()) {\n                    logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified);\n                }\n                if (new ServletWebRequest(request, response).checkNotModified(lastModified) && isGet) {\n                    // 页面未变更，且是Get方法\n                    return;\n                }\n            }\n\n            // 调用所有拦截器的 preHandle 方法\n            if (!mappedHandler.applyPreHandle(processedRequest, response)) {\n                return;\n            }\n\n            // 激活 Handler 进行逻辑处理并返回视图（这里会调用我们所写的控制器方法）\n            mv = adapter.handle(processedRequest, response, mappedHandler.getHandler());\n\n            // 需要异步处理\n            if (asyncManager.isConcurrentHandlingStarted()) {\n                return;\n            }\n\n            // 检测，如果 Handler 没有设置视图，则使用默认视图\n            this.applyDefaultViewName(processedRequest, mv);\n\n            // 调用所有拦截器的 postHandle 方法\n            mappedHandler.applyPostHandle(processedRequest, response, mv);\n        } catch (Exception ex) {\n            dispatchException = ex;\n        } catch (Throwable err) {\n            dispatchException = new NestedServletException(\"Handler dispatch failed\", err);\n        }\n        // 处理返回结果（异常处理、页面渲染、执行拦截器的 afterCompletion 方法等）\n        this.processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);\n    } catch (Exception ex) {\n        this.triggerAfterCompletion(processedRequest, response, mappedHandler, ex);\n    } catch (Throwable err) {\n        this.triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err));\n    } finally {\n        // 判断是否需要执行异步请求\n        if (asyncManager.isConcurrentHandlingStarted()) {\n            // Instead of postHandle and afterCompletion\n            if (mappedHandler != null) {\n                mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);\n            }\n        } else {\n            // 删除上传请求过程中的资源\n            if (multipartRequestParsed) {\n                this.cleanupMultipart(processedRequest);\n            }\n        }\n    }\n}\n```\n\ndoDispatch 在实现上定义了整个处理的执行流程，而具体的执行逻辑都交由相应的类来实现，可以概括如下：\n\n1. 检测当前是否是文件上传的请求，如果是的话则调用 MultipartResolver 的 resolveMultipart 方法解析 request 封装为 MultipartHttpServletRequest 对象\n2. 调用 HandlerMapping 获取当前请求对应的处理器\n3. 获取当前处理器对应的 HandlerAdapter\n4. 对于 GET 或 HEAD 方法检查目标页面是否有变更，没有的话直接返回\n5. 应用所有拦截器的 prehandle() 方法\n6. 激活处理器进行逻辑处理并返回视图，这一步最终会调用开发者自定义的实现\n7. 检测上一步如果没有设置视图，则使用默认视图\n8. 应用所有拦截器的 postHandle() 方法\n9. 处理返回结果，包括异常处理、页面渲染，以及执行拦截器的 afterCompletion() 方法\n10. 针对文件上传请求，执行临时数据的清理\n\n整个处理过程的背后是 Spring MVC 九大基础核心类的支撑，在此我们先不展开，后面会用专门的篇章逐一分析，我们先简单介绍一下过程中涉及到的一些概念，以对整个过程进行整体上的感知。\n\n上述过程涉及到三个核心组件的分工合作：Handler、HandlerMapping，以及 HandlerAdapter。方法中首先通过 HandlerMapping 基于当前请求找到对应的 Handler，然后基于 Handler 找到对应的 HandlerAdapter，最后通过 HandlerAdapter 激活 Handler 来执行业务逻辑并返回响应视图。\n\n__Handler__ 可以理解为处理器，简单来说它是对附加了拦截器的控制器方法的封装；而 __HandlerMapping__ 则是用来建立请求与对应 Handler 之间的映射关系，因为一个请求最终还是要落到一个控制器方法上去处理，而 HandlerMapping 则负责中间的过程映射；最后再来看看 __HandlerAdapter__ ，有了 Handler 和 HandlerMapping，我们可以找到一个请求对应的处理方法，并对该请求进行处理和响应，似乎已经完美了，那么我们还缺什么呢？这里还是需要记住一点，Spring MVC 是基于 servlet 的 MVC 框架，不像 [Play Framework](https://playframework.com/)、[Vert.x-Web](http://vertx.io/docs/vertx-web/java/) 等 web 框架另起炉灶的解决方案，所以我们的请求最终还是要交由 servlet 去处理。那么我们为什么要引入 MVC 框架，而不直接基于 servlet 来进行 web 开发呢？简单点来说就是框架比原生的 servlet 好用，我们可以灵活的实现我们的控制器方法，而不需要受 servlet 方法约定的束缚，而这灵活的背后就是 HandlerAdapter 的功劳，HandlerAdapter 的作用从根本上来说就是建立 Handler 与原生 servlet 方法间的适配，所以它是一个适配器。\n\n接下来我们对上述过程的几个核心步骤展开继续分析，首先看一下通过 HandlerMapping 获取 Handler 的过程：\n\n```java\nprotected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception {\n    // 根据请求获取对应的处理器链\n    for (HandlerMapping hm : this.handlerMappings) {\n        if (logger.isTraceEnabled()) {\n            logger.trace(\"Testing handler map [\" + hm + \"] in DispatcherServlet with name '\" + getServletName() + \"'\");\n        }\n        // 调用 HandlerMapping 的 getHandler() 方法\n        HandlerExecutionChain handler = hm.getHandler(request);\n        // 获取到一个即返回\n        if (handler != null) {\n            return handler;\n        }\n    }\n    return null;\n}\n```\n\n该方法通过遍历已注册的 HandlerMapping 来获取当前请求对应的 HandlerExecutionChain（封装了具体的 Handler 和对应的拦截器），核心还是在于调用了 HandlerMapping 的 `getHandler()` 方法：\n\n```java\npublic final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception {\n    // 依据 request 获取对应的 Handler\n    Object handler = this.getHandlerInternal(request);\n\n    // 没有找到，使用默认的\n    if (handler == null) {\n        handler = this.getDefaultHandler();\n    }\n\n    // 默认的都没有\n    if (handler == null) {\n        return null;\n    }\n\n    // 如果获取到的是 beanName，则从容器中去拿 name 对象的实例\n    if (handler instanceof String) {\n        String handlerName = (String) handler;\n        handler = this.getApplicationContext().getBean(handlerName);\n    }\n\n    // 创建 HandlerExecutionChain 对象并附加定义的拦截器\n    HandlerExecutionChain executionChain = this.getHandlerExecutionChain(handler, request);\n\n    // 如果是CORS（跨域资源共享）请求\n    if (CorsUtils.isCorsRequest(request)) {\n        CorsConfiguration globalConfig = this.corsConfigSource.getCorsConfiguration(request);\n        CorsConfiguration handlerConfig = this.getCorsConfiguration(handler, request);\n        CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig);\n        executionChain = this.getCorsHandlerExecutionChain(request, executionChain, config);\n    }\n    return executionChain;\n}\n```\n\n方法首先调用了 getHandlerInternal 方法以解析当前请求对应的 Handler，如果解析不到则获取默认的 Handler。如果当前的 Handler 还仅仅是一个 beanName，则会从容器中去获取对应的实例，然后利用 HandlerExecutionChain 对当前 Handler 实例进行包装，并附加定义的拦截器。最后会检测并处理 [CORS（Cross-origin resource sharing）](https://zh.wikipedia.org/wiki/%E8%B7%A8%E4%BE%86%E6%BA%90%E8%B3%87%E6%BA%90%E5%85%B1%E4%BA%AB) 请求。这里最核心的当属 getHandlerInternal 方法，该方法尝试获取当前请求所映射的自定义控制器方法：\n\n```java\nprotected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception {\n    // 1. 截取用于请求的有效url路径（/demo/hello）\n    String lookupPath = this.getUrlPathHelper().getLookupPathForRequest(request);\n    if (logger.isDebugEnabled()) {\n        logger.debug(\"Looking up handler method for path \" + lookupPath);\n    }\n    this.mappingRegistry.acquireReadLock();\n    try {\n        // 2. 基于 lookupPath 和 request 找到对应的 HandlerMethod\n        HandlerMethod handlerMethod = this.lookupHandlerMethod(lookupPath, request);\n\n        // 省略 debug 日志\n\n        // 3. 基于当前 HandlerMethod 对象创建新的 HandlerMethod 对象（如果仅仅是 beanName 则进行从容器中获取对应的实例）\n        return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null);\n    } finally {\n        this.mappingRegistry.releaseReadLock();\n    }\n}\n```\n\n方法的逻辑还是很简洁的，针对本次的请求在第一步时获取到有效的请求路径 `/demo/hello`，然后调用 `lookupHandlerMethod(String lookupPath, HttpServletRequest request)` 方法基于请求路径获取对应的处理器方法：\n\n```java\nprotected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception {\n    List<Match> matches = new ArrayList<Match>();\n    // 基于请求路径获取对应的匹配信息（mappingRegistry在initHandlerMethods中进行初始化）\n    List<T> directPathMatches = this.mappingRegistry.getMappingsByUrl(lookupPath);\n    if (directPathMatches != null) {\n        // 将匹配条件加入 matches 集合中\n        this.addMatchingMappings(directPathMatches, matches, request);\n    }\n    if (matches.isEmpty()) {\n        // 无法根据 lookupPath 获取对应的匹配条件，则将所有条件加入 matches 集合中\n        this.addMatchingMappings(this.mappingRegistry.getMappings().keySet(), matches, request);\n    }\n\n    // 对包含匹配条件和 Handler 的 matches 集合排序，并取第一个作为最佳匹配\n    if (!matches.isEmpty()) {\n        Comparator<Match> comparator = new MatchComparator(this.getMappingComparator(request));\n        Collections.sort(matches, comparator);\n        if (logger.isTraceEnabled()) {\n            logger.trace(\"Found \" + matches.size() + \" matching mapping(s) for [\" + lookupPath + \"] : \" + matches);\n        }\n        Match bestMatch = matches.get(0);\n        if (matches.size() > 1) {\n            if (CorsUtils.isPreFlightRequest(request)) {\n                return PREFLIGHT_AMBIGUOUS_MATCH;\n            }\n            // 如果存在多个最佳匹配则抛出异常\n            Match secondBestMatch = matches.get(1);\n            if (comparator.compare(bestMatch, secondBestMatch) == 0) {\n                Method m1 = bestMatch.handlerMethod.getMethod();\n                Method m2 = secondBestMatch.handlerMethod.getMethod();\n                throw new IllegalStateException(\"Ambiguous handler methods mapped for HTTP path '\" + request.getRequestURL() + \"': {\" + m1 + \", \" + m2 + \"}\");\n            }\n        }\n        this.handleMatch(bestMatch.mapping, lookupPath, request);\n        return bestMatch.handlerMethod;  // org.zhenchao.spring.mvc.controller.DemoController#hello\n    } else {\n        // 不存在匹配的 HandlerMethod\n        return this.handleNoMatch(this.mappingRegistry.getMappings().keySet(), lookupPath, request);\n    }\n}\n```\n\nlookupHandlerMethod 的主要逻辑是基于当前的请求路径从 mappingRegistry 集合（在 AbstractHandlerMethodMapping 中基于 InitializingBean 机制执行初始化）中获取对应的请求匹配信息 RequestMappingInfo 集合，然后遍历集合从 mappingRegistry 中拿到 RequestMappingInfo 对象所匹配的 HandlerMethod ，并由 Match 对象一起封装记录到匹配信息集合中，最后对集合进行排序并选择排在第一个的 HandlerMethod 作为最佳匹配，同时校验是否存在多个最佳匹配，如果存在则抛 IllegalStateException 异常。\n\n到这里通过 HandlerMapping 获取对应 Handler 的逻辑已经走完，方法返回了创建的 HandlerExecutionChain 对象，接下来我们继续回到 doDispatch 方法中，基于刚刚获取到的 Handler 调用 getHandlerAdapter 方法获取对应的 HandlerAdapter：\n\n```java\nprotected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException {\n    // 遍历获取已注册的处理器适配器\n    for (HandlerAdapter ha : this.handlerAdapters) {\n        if (logger.isTraceEnabled()) {\n            logger.trace(\"Testing handler adapter [\" + ha + \"]\");\n        }\n        // 判断是否支持当前的处理器，支持即返回\n        if (ha.supports(handler)) {\n            return ha;\n        }\n    }\n    throw new ServletException(\"No adapter for handler [\" + handler + \"]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler\");\n}\n```\n\n```java\npublic final boolean supports(Object handler) {\n    // supportsInternal 直接返回 true\n    return (handler instanceof HandlerMethod && this.supportsInternal((HandlerMethod) handler));\n}\n```\n\n适配器的获取过程相当简单，如上述注释。接下来继续来看 HandlerAdapter 执行处理器具体逻辑的过程：\n\n```java\n// org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter#handle\npublic final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\n    return this.handleInternal(request, response, (HandlerMethod) handler);\n}\n```\n\n```java\n// org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter#handleInternal\nprotected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception {\n    ModelAndView mav;\n    // 检查是否支持当前的请求方法，以及是否需要session\n    this.checkRequest(request);\n\n    // 激活处理器方法\n    if (this.synchronizeOnSession) {\n        HttpSession session = request.getSession(false);\n        if (session != null) {\n            Object mutex = WebUtils.getSessionMutex(session);\n            synchronized (mutex) {\n                mav = this.invokeHandlerMethod(request, response, handlerMethod);\n            }\n        } else {\n            // No HttpSession available -> no mutex necessary\n            mav = this.invokeHandlerMethod(request, response, handlerMethod);\n        }\n    } else {\n        // No synchronization on session demanded at all...\n        mav = this.invokeHandlerMethod(request, response, handlerMethod);\n    }\n\n    // 处理 Cache-Control 首部\n    if (!response.containsHeader(HEADER_CACHE_CONTROL)) {\n        if (this.getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) {\n            this.applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers);\n        } else {\n            this.prepareResponse(response);\n        }\n    }\n\n    return mav;\n}\n```\n\n上述方法的逻辑已经注释的比较清晰，首先检查当前的请求方法是否被支持，以及是否需要为当前请求创建 session，然后激活处理器方法，最后为响应头添加 `Cache-Control` 逻辑，来进一步探究 invokeHandlerMethod 方法：\n\n```java\nprotected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception {\n    ServletWebRequest webRequest = new ServletWebRequest(request, response);\n    try {\n        // 获取 WebDataBinderFactory\n        WebDataBinderFactory binderFactory = this.getDataBinderFactory(handlerMethod);\n        // 获取 ModelFactory\n        ModelFactory modelFactory = this.getModelFactory(handlerMethod, binderFactory);\n\n        // 基于 HandlerMethod 创建 ServletInvocableHandlerMethod 对象\n        ServletInvocableHandlerMethod invocableMethod = this.createInvocableHandlerMethod(handlerMethod);\n        invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers);\n        invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers);\n        invocableMethod.setDataBinderFactory(binderFactory);\n        invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer);\n\n        // 创建 ModelAndViewContainer\n        ModelAndViewContainer mavContainer = new ModelAndViewContainer();\n        mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request));\n        // 初始化 Model\n        modelFactory.initModel(webRequest, mavContainer, invocableMethod);\n        mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect);\n\n        AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response);\n        asyncWebRequest.setTimeout(this.asyncRequestTimeout);\n\n        WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\n        asyncManager.setTaskExecutor(this.taskExecutor);\n        asyncManager.setAsyncWebRequest(asyncWebRequest);\n        asyncManager.registerCallableInterceptors(this.callableInterceptors);\n        asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors);\n\n        if (asyncManager.hasConcurrentResult()) {\n            Object result = asyncManager.getConcurrentResult();\n            mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0];\n            asyncManager.clearConcurrentResult();\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"Found concurrent result value [\" + result + \"]\");\n            }\n            invocableMethod = invocableMethod.wrapConcurrentResult(result);\n        }\n\n        // 激活处理器方法\n        invocableMethod.invokeAndHandle(webRequest, mavContainer);\n        if (asyncManager.isConcurrentHandlingStarted()) {\n            return null;\n        }\n\n        // 构建 ModelAndView 对象并返回\n        return this.getModelAndView(mavContainer, modelFactory, webRequest);\n    } finally {\n        // 设置 requestActive = false\n        webRequest.requestCompleted();\n    }\n}\n```\n\n该方法所做的工作主要可以概括为三个步骤：1.构造并初始化处理器方法的执行条件；2.激活调用处理方法；3.构造 ModelAndView 对象并返回。我们来逐步探究各个过程，在第一步中我们主要来深入一下 Model 的初始化过程：\n\n```java\n// org.springframework.web.method.annotation.ModelFactory#initModel\npublic void initModel(NativeWebRequest request, ModelAndViewContainer container, HandlerMethod handlerMethod) throws Exception {\n\n    // 从 SessionAttributes 中取出保存的参数，合并到 ModelAndViewContainer 对象中\n    Map<String, ?> sessionAttributes = this.sessionAttributesHandler.retrieveAttributes(request);\n    container.mergeAttributes(sessionAttributes);\n\n    // 执行 @ModelAttribute 注解的方法，并将结果记录到 Model 中\n    this.invokeModelAttributeMethods(request, container);\n\n    /*\n     * 遍历 @ModelAttribute 和 @SessionAttribute 共同注解的参数\n     * 不要求这两个注解出现在同一个方法中，主要作用是利用其它处理器\n     * 方法中保存的 SessionAttributes 属性来设置当前方法注解了 @ModelAttribute 的参数\n     */\n    for (String name : this.findSessionAttributeArguments(handlerMethod)) {\n        if (!container.containsAttribute(name)) {\n            Object value = this.sessionAttributesHandler.retrieveAttribute(request, name);\n            if (value == null) {\n                throw new HttpSessionRequiredException(\"Expected session attribute '\" + name + \"'\", name);\n            }\n            container.addAttribute(name, value);\n        }\n    }\n}\n```\n\n在整个初始化过程中，方法先取出 SessionAttributes 中保存的参数合并到 ModelAndViewContainer 对象中；然后执行 `@ModelAttribute` 注解的方法，这一步的最终目的是将方法返回值设置到 Model 中；最后遍历被 `@ModelAttribute` 和 `@SessionAttribute` 同时注解的属性，这里的目的还是将对应的属性值记录到 Model 中，区别在于这里的属性来源是其它控制器方法记录到 session 中的值。\n\n接下来我们分析一下处理器方法的激活调用过程，该方法主要做了两件事情：1.激活处理器方法并拿到方法返回值；2.调用注册的 HandlerMethodReturnValueHandler 对返回值进行处理。\n\n```java\n// org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod#invokeAndHandle\npublic void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception {\n    // 激活自定义控制器方法\n    Object returnValue = this.invokeForRequest(webRequest, mavContainer, providedArgs);\n    this.setResponseStatus(webRequest);\n\n    if (returnValue == null) {\n        if (this.isRequestNotModified(webRequest) || hasResponseStatus() || mavContainer.isRequestHandled()) {\n            mavContainer.setRequestHandled(true);\n            return;\n        }\n    } else if (StringUtils.hasText(this.responseReason)) {\n        mavContainer.setRequestHandled(true);\n        return;\n    }\n\n    mavContainer.setRequestHandled(false);\n    try {\n        // 遍历调用注册的 HandlerMethodReturnValueHandler 对返回值进行处理\n        this.returnValueHandlers.handleReturnValue(returnValue, getReturnValueType(returnValue), mavContainer, webRequest);\n    } catch (Exception ex) {\n        if (logger.isTraceEnabled()) {\n            logger.trace(getReturnValueHandlingErrorMessage(\"Error handling return value\", returnValue), ex);\n        }\n        throw ex;\n    }\n}\n```\n\n到这里我们已经离我们自定义的控制器方法已经很近了，接下去的逻辑就是拿到我们自定义控制器方法的参数值，并基于反射执行该方法，这一过程位于 invokeForRequest 中，逻辑比较简单，这里不再展开。如果把整个跟踪的过程比作是一次旅行，那么到这里我们基本上算是到达了旅行的目的地，而接下去将开始返程了，我们首先回到 RequestMappingHandlerAdapte 的 invokeHandlerMethod 中，在执行完上面的 invokeAndHandle 后，我们继续往下执行 ModelAndView 对象的获取过程：\n\n```java\nprivate ModelAndView getModelAndView(ModelAndViewContainer mavContainer,  ModelFactory modelFactory, NativeWebRequest webRequest) throws Exception {\n    // 更新 Model\n    modelFactory.updateModel(webRequest, mavContainer);\n    if (mavContainer.isRequestHandled()) {\n        return null;\n    }\n\n    // 构建 ModelAndView 对象\n    ModelMap model = mavContainer.getModel();\n    ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model, mavContainer.getStatus());\n    if (!mavContainer.isViewReference()) {\n        // 设置视图\n        mav.setView((View) mavContainer.getView());\n    }\n    if (model instanceof RedirectAttributes) {\n        // 将 redirect 参数记录到 outputFlashMap 中\n        Map<String, ?> flashAttributes = ((RedirectAttributes) model).getFlashAttributes();\n        HttpServletRequest request = webRequest.getNativeRequest(HttpServletRequest.class);\n        RequestContextUtils.getOutputFlashMap(request).putAll(flashAttributes);\n    }\n    return mav;\n}\n```\n\n该过程首先更新 Model，然后创建 ModelAndView 对象并设置视图，如果是 redirect 返回还会处理我们添加到 FlashMap 中的跳转参数，整个过程唯一间接实现的逻辑是更新 Model：\n\n```java\npublic void updateModel(NativeWebRequest request, ModelAndViewContainer container) throws Exception {\n    ModelMap defaultModel = container.getDefaultModel();\n    if (container.getSessionStatus().isComplete()) {\n        // 如果在处理器中调用了 SessionStatus.setComplete() 方法，则会清空 SessionAttributes\n        this.sessionAttributesHandler.cleanupAttributes(request);\n    } else {\n        // 将 Model 中的相应属性记录到 SessionAttributes 中\n        this.sessionAttributesHandler.storeAttributes(request, defaultModel);\n    }\n    // 判断如果需要进行页面渲染，则给 Model 中相应的参数添加 BindingResult\n    if (!container.isRequestHandled() && container.getModel() == defaultModel) {\n        this.updateBindingResult(request, defaultModel);\n    }\n}\n```\n\nupdateModel 是 ModelFactory 中主要包含的两个方法之一（另外一个是 initModel，已在前面解读过），该方法的功能如注释所示，主要做了两件事情：\n\n1. 对于 SessionAttributes 进行处理，如果在控制器中调用了 `SessionStatus.setComplete()` 方法，那么这里会执行对 SessionAttributes 的清空，否则将 Model 中相应的属性记录到 SessionAttributes 中。\n2. 判断是否需要执行页面渲染，若需要则为相应的属性添加 BindingResult 对象。\n\ngetModelAndView 方法执行完成之后，接下来我们回到 doDispatch 方法继续后续的处理过程。如果处理器方法未设置视图，则接下来会为本次请求设置一个默认的视图，然后调用所有拦截器的 `postHandle()` 方法，接着开始执行页面的渲染逻辑：\n\n```java\nprivate void processDispatchResult(\n        HttpServletRequest request, HttpServletResponse response, HandlerExecutionChain mappedHandler, ModelAndView mv, Exception exception)\n        throws Exception {\n\n    boolean errorView = false;\n\n    // 1. 如果处理过程出现异常，则进行处理\n    if (exception != null) {\n        if (exception instanceof ModelAndViewDefiningException) {\n            logger.debug(\"ModelAndViewDefiningException encountered\", exception);\n            mv = ((ModelAndViewDefiningException) exception).getModelAndView();\n        } else {\n            Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null);\n            mv = this.processHandlerException(request, response, handler, exception);\n            errorView = (mv != null);\n        }\n    }\n\n    // 2. 对页面进行渲染\n    if (mv != null && !mv.wasCleared()) {\n        this.render(mv, request, response);\n        if (errorView) {\n            WebUtils.clearErrorRequestAttributes(request);\n        }\n    } else {\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"Null ModelAndView returned to DispatcherServlet with name '\" + getServletName() + \"': assuming HandlerAdapter completed request handling\");\n        }\n    }\n\n    // 如果启用了异步处理则返回\n    if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) {\n        return;\n    }\n\n    // 3. 激活拦截器的 afterCompletion 方法\n    if (mappedHandler != null) {\n        mappedHandler.triggerAfterCompletion(request, response, null);\n    }\n}\n```\n\n上述方法首先会判断前面的处理过程中是否出现异常，如果有异常则需要对异常信息进行处理，需要注意的一点是这里的处理逻辑位于页面渲染之前，如果渲染过程中出现了异常则不会被处理。具体的异常处理过程不再展开，留到以后专门讲解，下面来看一下页面的渲染过程：\n\n```java\nprotected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception {\n    // 1. 设置响应 locale\n    Locale locale = this.localeResolver.resolveLocale(request);\n    response.setLocale(locale);\n\n    // 2. 获取视图对象\n    View view;\n    if (mv.isReference()) {\n        // 如果是视图名称，则解析视图名称对应的视图对象\n        view = this.resolveViewName(mv.getViewName(), mv.getModelInternal(), locale, request);\n        if (view == null) {\n            throw new ServletException(\"Could not resolve view with name '\" + mv.getViewName() + \"' in servlet with name '\" + getServletName() + \"'\");\n        }\n    } else {\n        // 已经包含了视图对象\n        view = mv.getView();\n        if (view == null) {\n            throw new ServletException(\"ModelAndView [\" + mv + \"] neither contains a view name nor a View object in servlet with name '\" + getServletName() + \"'\");\n        }\n    }\n\n    if (logger.isDebugEnabled()) {\n        logger.debug(\"Rendering view [\" + view + \"] in DispatcherServlet with name '\" + getServletName() + \"'\");\n    }\n\n    // 3. 页面渲染过程\n    try {\n        if (mv.getStatus() != null) {\n            response.setStatus(mv.getStatus().value());\n        }\n        view.render(mv.getModelInternal(), request, response);\n    } catch (Exception ex) {\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"Error rendering view [\" + view + \"] in DispatcherServlet with name '\" + getServletName() + \"'\", ex);\n        }\n        throw ex;\n    }\n}\n```\n\n整个方法分为三步来执行，如注释所示，其中第一、二步比较基础，而第三步的页面渲染过程则委托给视图对象来执行：\n\n```java\npublic void render(Map<String, ?> model, HttpServletRequest request, HttpServletResponse response) throws Exception {\n    if (logger.isTraceEnabled()) {\n        logger.trace(\"Rendering view with name '\" + this.beanName + \"' with model \" + model + \" and static attributes \" + this.staticAttributes);\n    }\n    // 属性解析（包含动态和静态属性值）\n    Map<String, Object> mergedModel = this.createMergedOutputModel(model, request, response);\n    // 响应准备工作\n    this.prepareResponse(request, response);\n    // 页面渲染\n    this.renderMergedOutputModel(mergedModel, this.getRequestToExpose(request), response);\n}\n```\n\n渲染的过程首先就是解析请求过程的动态和静态属性值，并封装到一个 map 中以便后续取值；然后执行一些准备工作，默认的实现是为了修复 IE 浏览器中响应 HTTPS 下载请求的 [bug](https://support.microsoft.com/en-us/help/316431/internet-explorer-is-unable-to-open-office-documents-from-an-ssl-web-s)；最后执行渲染逻辑，这一块留到后续分析视图实现时进行针对性的说明。\n\n继续回到 doDispatch，拦截器 HandlerInterceptor 中声明了三个方法：preHandle、postHandle，以及 afterCompletion。前面的执行过程围绕处理器方法分别在前后执行了 preHandle 和 postHandle，而 afterCompletion 也在页面渲染过程完成之后被触发。如果本次是上传请求，那么接下来会执行清理上传过程中产生的临时文件的过程，到这里就完成了 doDispatch 整个方法过程的执行。\n\n回到开始位于 FrameworkServlet 中的 processRequest 方法，记得一开始我们对之前的 LocaleContext 和 RequestAttributes 进行了暂存，而此时则需要将相应的 holder 利用这些暂存的值恢复到最开始的状态，从而不影响其它请求的执行，并将 requestActive 置为 false，标记本次请求的完成，最后调用 publishRequestHandledEvent 方法，发布请求处理完成的通知消息。\n\n到这里，这一次简单的请求就处理完成了，我们可以在浏览器中看到具体渲染后的页面。虽然是一个简单的请求，但是通过分析我们也看到框架背后复杂的处理逻辑，这还仅仅是整个处理过程的主线流程，后续我们会针对各个核心支撑组件逐一展开来进行针对性的分析，本篇文章的目的主要还是对整个请求有一个全局的感知，后续我们在具体分析各个组件时时可以具体定位到具体是发生在哪一步的请求，从而能够联系上下文进行理解。\n","tags":["Spring"],"categories":["spring"]},{"title":"Spring MVC 源码解析：Web 环境下容器的初始化过程","url":"/2017/07/20/spring/spring-mvc-initialization/","content":"\nSpring MVC 是目前最流行的 java web 框架（之一），是对传统 servlet 的高级封装，以提升 servlet 的灵活性和易用性。从广义上来说，Spring MVC 的执行过程可以分为 __容器初始化__ 和 __请求响应处理__ 两大部分，前者在 servlet 容器启动过程中完成，为后者的执行提供基本的运行环境，而后者则是 Spring MVC 的核心所在，负责接收请求到最终返回响应数据的复杂处理过程。<!-- more -->\n\n本篇章我们一起来探究 Spring MVC 在 web 环境下的容器初始化过程。Spring MVC 是建立在 Spring 基础组件之上的 MVC 框架，之前我们在分析 IoC 实现的时候，对于传统的容器初始化触发条件都是采用类似下面的方式：\n\n```java\nApplicationContext ac = new ClassPathXmlApplicationContext(\"spring-common.xml\");\n```\n\nSpring MVC 作为基于 IoC 的上层实现，同样也需要执行容器的初始化过程，熟悉使用 Spring MVC 框架的同学都知道在搭建基于 Spring MVC 的 web 项目时，都需要在 web.xml 中添加下面的配置：\n\n```xml\n<!--ContextLoaderListener 配置-->\n<context-param>\n    <param-name>contextConfigLocation</param-name>\n    <param-value>classpath:spring-common.xml</param-value>\n</context-param>\n<listener>\n    <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>\n</listener>\n\n<!--DispatcherServlet 配置-->\n<servlet>\n    <servlet-name>spring_mvc</servlet-name>\n    <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n    <init-param>\n        <param-name>contextConfigLocation</param-name>\n        <param-value>classpath:spring-mvc.xml</param-value>\n    </init-param>\n    <load-on-startup>1</load-on-startup>\n</servlet>\n<servlet-mapping>\n    <servlet-name>spring_mvc</servlet-name>\n    <url-pattern>/</url-pattern>\n</servlet-mapping>\n```\n\n上述配置包含 ContextLoaderListener 和 DispatcherServlet 两部分，MVC 容器的初始化过程可以看做是这两个类的初始化过程。其中 ContextLoaderListener 是一个监听器，它实现了 ServletContextListener 接口：\n\n```java\npublic interface ServletContextListener extends EventListener {\n\n    public void contextInitialized(ServletContextEvent sce);\n\n    public void contextDestroyed(ServletContextEvent sce);\n\n}\n```\n\n这两个方法分别在 servlet 容器启用和关闭时被调用。而 DispatcherServlet 则是一个标准的 servlet，可以看做是一个中央控制器，Spring MVC 基于该 servlet 处理所有的请求和响应。\n\n![image](/images/2017/spring-mvc-dispatcher-servlet.png)\n\n上图是 DispatcherServlet 的类继承关系图，其中左上角的 5 个接口（类）属于 jdk 中定义的接口（类），包括我们在基于原生 servlet 编写 web 程序时经常用到的 HttpServlet。\n\n除此之外 HttpServletBean、FrameworkServlet，以及 DispatcherServlet 可以看做是整个继承体系中最核心的三个类，如果把 MVC 后面的处理逻辑看做是一个黑盒，那么这三个类中的逻辑可以看做是一个 “迎宾”，负责接待和送走 HTTP 请求。这些类实现了 Capable 和 Aware 接口，由前面我们对于 IoC 源码的分析可以知道，Capable 接口可以让目标类具备特定的能力，这里实现了 EnvironmentCapable 接口让目标类具备获取系统环境的能力，这里的环境主要是指 servlet 的初始化配置、JNDI 属性、系统环境变量，以及系统属性等信息；而 Aware 接口则能够让目标类拿到一定的资源，在容器初始化时会检测当前指定的 bean 是否实现了某个 Aware 接口，是的话就会将相应的资源注入到目标 bean 中。比如这里的 ApplicationContextAware 接口，实现了该接口的类容器会将应用上下文对象 ApplicationContext 对象注入到该类的实例中，从而能够持有容器的上下文。\n\n### 一. ContextLoaderListener 的初始化过程\n\nContextLoaderListener 的实现较为简单，他继承了 ContextLoader 类，并覆盖实现 ServletContextListener 接口中声明的方法，以达到在 servlet 容器启动和关闭时执行相应的初始化和清理操作，而这些操作的具体实现均位于 ContextLoader 类中：\n\n```java\npublic class ContextLoaderListener extends ContextLoader implements ServletContextListener {\n\n    public ContextLoaderListener() {\n    }\n\n    public ContextLoaderListener(WebApplicationContext context) {\n        super(context);\n    }\n\n    /**\n     * Initialize the root web application context.\n     */\n    @Override\n    public void contextInitialized(ServletContextEvent event) {\n        // 在 servlet 容器启动时会触发调用该方法\n        this.initWebApplicationContext(event.getServletContext());\n    }\n\n    /**\n     * Close the root web application context.\n     */\n    @Override\n    public void contextDestroyed(ServletContextEvent event) {\n        this.closeWebApplicationContext(event.getServletContext());\n        ContextCleanupListener.cleanupAttributes(event.getServletContext());\n    }\n\n}\n```\n\n初始化方法 `contextInitialized(ServletContextEvent event)` 中只是简单的调用了父类的方法 `initWebApplicationContext(ServletContext servletContext)` 以实现对 WebApplicationContext 上下文的初始化过程，这和我们通常手动 new 来触发 IoC 容器的初始化本质上是一样的，只不过这里是在 web 环境下，而 servlet 容器启动时是初始化 IoC 的最佳时机，所以 Spring 将这一过程基于 ServletContextListener 来实现也不难理解。\n\n```java\npublic WebApplicationContext initWebApplicationContext(ServletContext servletContext) {\n    if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) {\n        // ServletContext 中已经记录了 ApplicationContext 对象，说明之前已经加载过了，可能存在配置多个 ContextLoader 的情况\n        throw new IllegalStateException(\n                \"Cannot initialize context because there is already a root application context present - check whether you have multiple ContextLoader* definitions in your web.xml!\");\n    }\n\n    Log logger = LogFactory.getLog(ContextLoader.class);\n    servletContext.log(\"Initializing Spring root WebApplicationContext\");\n    if (logger.isInfoEnabled()) {\n        logger.info(\"Root WebApplicationContext: initialization started\");\n    }\n    long startTime = System.currentTimeMillis();\n    try {\n        // Store context in local instance variable, to guarantee that it is available on ServletContext shutdown.\n        if (this.context == null) {\n            // 创建 WebApplicationContext 对象\n            this.context = this.createWebApplicationContext(servletContext);\n        }\n        if (this.context instanceof ConfigurableWebApplicationContext) {\n            ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context;\n            if (!cwac.isActive()) { // 不是活跃的\n                if (cwac.getParent() == null) {\n                    ApplicationContext parent = this.loadParentContext(servletContext);\n                    cwac.setParent(parent);\n                }\n                // 初始化应用上下文\n                this.configureAndRefreshWebApplicationContext(cwac, servletContext);\n            }\n        }\n\n        // 将 WebApplicationContext 对象记录在 ServletContext 中\n        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context);\n\n        ClassLoader ccl = Thread.currentThread().getContextClassLoader();\n        if (ccl == ContextLoader.class.getClassLoader()) {\n            currentContext = this.context;\n        } else if (ccl != null) {\n            currentContextPerThread.put(ccl, this.context);\n        }\n\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"Published root WebApplicationContext as ServletContext attribute with name [\" + WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + \"]\");\n        }\n        if (logger.isInfoEnabled()) {\n            long elapsedTime = System.currentTimeMillis() - startTime;\n            logger.info(\"Root WebApplicationContext: initialization completed in \" + elapsedTime + \" ms\");\n        }\n\n        return this.context;\n    } catch (RuntimeException ex) {\n        logger.error(\"Context initialization failed\", ex);\n        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex);\n        throw ex;\n    } catch (Error err) {\n        logger.error(\"Context initialization failed\", err);\n        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err);\n        throw err;\n    }\n}\n```\n\n该方法的执行逻辑可以概括如下：\n\n> 1. 判断 ServletContext 对象中是否已经记录了 WebApplicationContext 对象，如果有记录则说明配置了不止一个 ContextLoaderListener，而这是不允许的\n> 2. 创建 WebApplicationContext 对象\n> 3. 如果 context 是 ConfigurableWebApplicationContext 类型，则有条件的进行配置和刷新应用上下文\n> 4. 将创建的 WebApplicationContext 对象记录到 ServletContext 中\n\n容器的初始化过程执行一次即可，加载多次无益，所以 Spring MVC 会在 ServletContext 中记录已经创建的 WebApplicationContext 对象。我们来看一下该对象的创建过程：\n\n```java\nprotected WebApplicationContext createWebApplicationContext(ServletContext sc) {\n    // 创建 WebApplicationContext 的 Class 对象，尝试获取自定义设置（contextClass），如果没有指定则采用默认 XmlWebApplicationContext\n    Class<?> contextClass = this.determineContextClass(sc);\n    if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) {\n        // 如果不是 ConfigurableWebApplicationContext 类型\n        throw new ApplicationContextException(\"Custom context class [\" + contextClass.getName() + \"] is not of type [\" + ConfigurableWebApplicationContext.class.getName() + \"]\");\n    }\n    // 实例化\n    return (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);\n}\n```\n\n上述方法的核心在于决定具体创建的 WebApplicationContext 类型，该过程位于 `determineContextClass(ServletContext servletContext)` 方法中：\n\n```java\nprotected Class<?> determineContextClass(ServletContext servletContext) {\n    // 获取 contextClass 参数配置\n    String contextClassName = servletContext.getInitParameter(CONTEXT_CLASS_PARAM); // contextClass\n    if (contextClassName != null) {\n        // 说明自定义了 context class\n        try {\n            return ClassUtils.forName(contextClassName, ClassUtils.getDefaultClassLoader());\n        } catch (ClassNotFoundException ex) {\n            throw new ApplicationContextException(\"Failed to load custom context class [\" + contextClassName + \"]\", ex);\n        }\n    } else {\n        /*\n         * 未指定 contextClass，使用默认设置（配置在 ContextLoader.properties 文件中）\n         * 默认采用 org.springframework.web.context.support.XmlWebApplicationContext\n         */\n        contextClassName = defaultStrategies.getProperty(WebApplicationContext.class.getName());\n        try {\n            // 创建 XmlWebApplicationContext 的 Class 对象\n            return ClassUtils.forName(contextClassName, ContextLoader.class.getClassLoader());\n        } catch (ClassNotFoundException ex) {\n            throw new ApplicationContextException(\"Failed to load default context class [\" + contextClassName + \"]\", ex);\n        }\n    }\n}\n```\n\nSpring MVC 允许我们利用 contextClass 属性来指定具体的 WebApplicationContext 类型（参考下面的配置），如果没有配置（一般我们都不会自定义配置）则 Spring MVC 会采用默认 XmlWebApplicationContext 作为具体的创建类型。\n\n```xml\n<context-param>\n    <param-name>contextClass</param-name>\n    <param-value>org.springframework.web.servlet.SimpleWebApplicationContext</param-value>\n</context-param>\n```\n\n而该默认配置位于 classpath 路径下的 ContextLoader.properties 文件中，配置内容为：\n\n```properties\norg.springframework.web.context.WebApplicationContext=org.springframework.web.context.support.XmlWebApplicationContext\n```\n\nSpring MVC 在 ContextLoader 的静态代码块中对该配置文件进行了加载，并记录到 defaultStrategies 属性中：\n\n```java\nprivate static final Properties defaultStrategies;\n\nstatic {\n    /*\n     * 加载 ContextLoader.properties 文件\n     * 该文件仅包含一行内容，用于指定默认的 WebApplicationContext 实现类：\n     * org.springframework.web.context.WebApplicationContext=org.springframework.web.context.support.XmlWebApplicationContext\n     */\n    try {\n        ClassPathResource resource = new ClassPathResource(DEFAULT_STRATEGIES_PATH, ContextLoader.class);\n        defaultStrategies = PropertiesLoaderUtils.loadProperties(resource);\n    } catch (IOException ex) {\n        throw new IllegalStateException(\"Could not load 'ContextLoader.properties': \" + ex.getMessage());\n    }\n}\n```\n\n需要注意的是该配置属于 Spring MVC 的内部配置，如果仅仅是使用 Spring MVC 框架则不建议开发者去更改默认配置值。\n\n继续回来分析，如果创建的对象是 ConfigurableWebApplicationContext 类型（默认情况下即为该类型），则会判断当前的应用上下文对象是否执行过刷新且未被关闭，如果不满足则会执行刷新逻辑：\n\n```java\nprotected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) {\n    // 为 wac 设置一个更加友好的对象 id，用于序列化\n    if (ObjectUtils.identityToString(wac).equals(wac.getId())) {\n        String idParam = sc.getInitParameter(CONTEXT_ID_PARAM);\n        if (idParam != null) {\n            // 如果有指定 contextId，则使用该配置作为 id\n            wac.setId(idParam);\n        } else {\n            // 生成默认的id\n            wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(sc.getContextPath()));\n        }\n    }\n\n    // 记录 ServletContext 对象\n    wac.setServletContext(sc);\n\n    // 获取 contextConfigLocation 配置，记录到 wac 中\n    String configLocationParam = sc.getInitParameter(CONFIG_LOCATION_PARAM);\n    if (configLocationParam != null) {\n        wac.setConfigLocation(configLocationParam);\n    }\n\n    // 初始化系统环境属性（servlet初始化配置、JNDI属性、系统环境变量、系统属性等）\n    ConfigurableEnvironment env = wac.getEnvironment();\n    if (env instanceof ConfigurableWebEnvironment) {\n        ((ConfigurableWebEnvironment) env).initPropertySources(sc, null);\n    }\n\n    // 执行 globalInitializerClasses 和 contextInitializerClasses 配置对 wac 的初始化策略\n    this.customizeContext(sc, wac);\n\n    // 初始化 IoC 容器\n    wac.refresh();\n}\n```\n\n整个方法执行过程已经注释的比较清楚，这里进一步说明一下其中不是特别直观的几个步骤。首先来看系统环境属性的初始化过程，一开始我们在描述 DispatcherServlet 的类继承关系时有提到 EnvironmentCapable 接口，而这里的 ConfigurableWebApplicationContext 也间接实现了该接口以获取系统的环境属性，这里的 Environment 实际使用的是 StandardServletEnvironment，而整个初始化过程也是将 ServletContext 和 ServletConfig 所持有的配置记录到 propertySources 属性中，这是一个 MutablePropertySources 类型。\n\n再来看一下 `customizeContext(ServletContext sc, ConfigurableWebApplicationContext wac)` 方法，Spring MVC 中提供了 ApplicationContextInitializer 接口：\n\n```java\npublic interface ApplicationContextInitializer<C extends ConfigurableApplicationContext> {\n\n    void initialize(C applicationContext);\n\n}\n```\n\n我们可以通过实现该接口来对执行 refresh 前的应用上下文进行更改，只需要在 web.xml 中做类似下面这样的配置即可：\n\n```xml\n<context-param>\n    <param-name>contextInitializerClasses</param-name>\n    <param-value>org.zhenchao.spring.mvc.initializer.MyContextApplicationContextInitializer</param-value>\n</context-param>\n<context-param>\n    <param-name>globalInitializerClasses</param-name>\n    <param-value>org.zhenchao.spring.mvc.initializer.MyGlobalApplicationContextInitializer</param-value>\n</context-param>\n```\n\n而 contextInitializerClasses 和 globalInitializerClasses 的区别也正如其名，仅仅是作用范围不一样而已。我们可以同时配置多个实现类，多个类之间使用分号、逗号之类的分隔符进行分隔，而方法会将 contextInitializerClasses 和 globalInitializerClasses 的配置的所有实现类实例化存储到 List 集合中，并依次调用各个实现类的 initialize 对传入的应用上下文对象执行初始化操作。\n\n最后，和普通高级 IoC 容器一样，方法调用了 ApplicationContext 的 refresh 方法，开始执行对高级容器的初始化策略，而这一部分的详细过程可以参考之前对高级容器初始化过程进行专门分析的[篇章](/2017/06/03/spring-src-application-context/)。\n\n### 二. DispatcherServlet 的初始化过程\n\nDispatcherServlet 本质上是一个 servlet，Spring MVC 对于请求的接收和响应都是基于该 servlet 实现，所以 DispatcherServlet 可以看做是 Spring MVC 中最核心的一个类，后面我们会对请求的具体处理过程进行专门分析，而这里我们把注意力主要集中在其初始化过程上。我们先来回忆一下 servlet 接口定义，如下：\n\n```java\npublic interface Servlet {\n\n    public void init(ServletConfig config) throws ServletException;\n\n    public ServletConfig getServletConfig();\n\n    public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException;\n\n    public String getServletInfo();\n\n    public void destroy();\n}\n```\n\n当一个 servlet 被加载时会首先执行 `init(ServletConfig config)` 方法，而 DispatcherServlet 的 init 方法位于父类 HttpServletBean 中：\n\n```java\npublic final void init() throws ServletException {\n    if (logger.isDebugEnabled()) {\n        logger.debug(\"Initializing servlet '\" + getServletName() + \"'\");\n    }\n\n    try {\n        // 解析初始化参数，采用 PropertyValue 进行封装记录，并检查必要参数是否缺失\n        PropertyValues pvs = new ServletConfigPropertyValues(this.getServletConfig(), this.requiredProperties);\n        // 将当前 bean 包装成 BeanWrapper 对象，便于 Spring 处理\n        BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this);\n        ResourceLoader resourceLoader = new ServletContextResourceLoader(this.getServletContext());\n        // 注册自定义属性编辑器，用于处理 Resource 类型的数据\n        bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment()));\n        // 模板方法\n        this.initBeanWrapper(bw);\n        // 将配置的初始化参数注入的 beanWrapper 对象中\n        bw.setPropertyValues(pvs, true);\n    } catch (BeansException ex) {\n        if (logger.isErrorEnabled()) {\n            logger.error(\"Failed to set bean properties on servlet '\" + getServletName() + \"'\", ex);\n        }\n        throw ex;\n    }\n\n    // 模板方法，FrameworkServlet 对其进行了覆盖实现\n    this.initServletBean();\n\n    if (logger.isDebugEnabled()) {\n        logger.debug(\"Servlet '\" + getServletName() + \"' configured successfully\");\n    }\n}\n```\n\n该初始化方法并没有做太多核心逻辑，它的主要功能就是将我们配置的 servlet 初始化参数，以及当前 servlet 对象封装成 Spring 所习惯的方式（不理解的话可以去看一下前面 IoC 的实现），而核心初始化过程则位于 FrameworkServlet 所覆盖实现的 `initServletBean()` 方法中：\n\n```java\nprotected final void initServletBean() throws ServletException {\n    this.getServletContext().log(\"Initializing Spring FrameworkServlet '\" + getServletName() + \"'\");\n    if (this.logger.isInfoEnabled()) {\n        this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization started\");\n    }\n    long startTime = System.currentTimeMillis();\n\n    try {\n        // 初始化 WebApplicationContext\n        this.webApplicationContext = this.initWebApplicationContext();\n        // 模板方法\n        this.initFrameworkServlet();\n    } catch (ServletException ex) {\n        this.logger.error(\"Context initialization failed\", ex);\n        throw ex;\n    } catch (RuntimeException ex) {\n        this.logger.error(\"Context initialization failed\", ex);\n        throw ex;\n    }\n\n    if (this.logger.isInfoEnabled()) {\n        long elapsedTime = System.currentTimeMillis() - startTime;\n        this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization completed in \" + elapsedTime + \" ms\");\n    }\n}\n```\n\n上述方法的核心在于调用了 `initWebApplicationContext()` 方法：\n\n```java\nprotected WebApplicationContext initWebApplicationContext() {\n    // 从 ServletContext 中拿到 rootContext（前面执行 ContextLoaderListener 初始化时创建的 wac）\n    WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(this.getServletContext());\n    WebApplicationContext wac = null;\n\n    // 1. 检查是否已在构造对象时注入\n    if (this.webApplicationContext != null) {\n        wac = this.webApplicationContext;\n        if (wac instanceof ConfigurableWebApplicationContext) {\n            ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac;\n            if (!cwac.isActive()) {\n                if (cwac.getParent() == null) {\n                    cwac.setParent(rootContext);\n                }\n                // 刷新应用上下文\n                this.configureAndRefreshWebApplicationContext(cwac);\n            }\n        }\n    }\n\n    // 2. 构造对象时未注入，则尝试从 ServletContext 中寻找\n    if (wac == null) {\n        // 从 ServletContext 对象中寻找，一般都会将 ApplicationContext 以 Attribute 的方式记录到 ServletContext 对象中\n        wac = this.findWebApplicationContext();\n    }\n\n    // 3. 没有可用的 context 实例，本地创建一个（一般都是使用该方式）\n    if (wac == null) {\n        wac = this.createWebApplicationContext(rootContext);\n    }\n\n    // 4. 刷新应用上下文，默认为 false\n    if (!this.refreshEventReceived) {\n        // 如果没有刷新过则执行刷新操作，确保该方法只被调用一次\n        // this.onApplicationEvent() 方法中会将该变量置为 true\n        this.onRefresh(wac);\n    }\n\n    // 5. 将 ApplicationContext 对象作为属性保存在 ServletContext 中\n    if (this.publishContext) { // 可以变量可以在初始化参数配置中配置，默认为 true\n        String attrName = this.getServletContextAttributeName();\n        this.getServletContext().setAttribute(attrName, wac);\n        if (this.logger.isDebugEnabled()) {\n            this.logger.debug(\"Published WebApplicationContext of servlet '\" + getServletName() + \"' as ServletContext attribute with name [\" + attrName + \"]\");\n        }\n    }\n\n    return wac;\n}\n```\n\n该方法的执行逻辑概括如下：\n\n> 1. 获取在 ContextLoaderListener 初始化时创建的应用上下文对象作为父容器\n> 2. 依次从构造注入、ServletContext 属性中检测是否有已经创建的 WebApplicationContext 的对象，如果未找到则创建一个\n> 3. 有条件执行 onRefresh 逻辑\n> 4. 有条件记录 WebApplicationContext 对象到 ServletContext 中\n\n整个逻辑还是很清晰的，我们进一步探究各个过程，先跳过第 1 个步骤，等分析完后面几个步骤之后，我们再回过来思考这一步的意义。\n\n首先方法会检测是否有在构造对象时注入了 WebApplicationContext 对象，如果有的话则判断是否是 ConfigurableWebApplicationContext 类型，如果是则执行相应的刷新逻辑：\n\n```java\nprotected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac) {\n    // 为 wac 设置一个更加友好的 id\n    if (ObjectUtils.identityToString(wac).equals(wac.getId())) {\n        if (this.contextId != null) {\n            // 如果指定了 contextId，则使用该配置作为 id\n            wac.setId(this.contextId);\n        } else {\n            // 生成一个默认的 id\n            wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(getServletContext().getContextPath()) + '/' + getServletName());\n        }\n    }\n\n    wac.setServletContext(this.getServletContext());\n    wac.setServletConfig(this.getServletConfig());\n    wac.setNamespace(this.getNamespace());\n    // 添加监听器，本质上是 ContextRefreshListener\n    wac.addApplicationListener(new SourceFilteringListener(wac, new ContextRefreshListener()));\n\n    // 初始化系统环境属性（servlet初始化配置、JNDI属性、系统环境变量、系统属性等）\n    ConfigurableEnvironment env = wac.getEnvironment();\n    if (env instanceof ConfigurableWebEnvironment) {\n        ((ConfigurableWebEnvironment) env).initPropertySources(this.getServletContext(), this.getServletConfig());\n    }\n\n    // 模板方法\n    this.postProcessWebApplicationContext(wac);\n\n    // 执行 globalInitializerClasses 和 contextInitializerClasses 配置对 wac 的初始化策略\n    this.applyInitializers(wac);\n\n    // 初始化 IoC 容器\n    wac.refresh();\n}\n```\n\n是不是很眼熟？实际上该方法与前面分析 ContextLoaderListener 初始化过程中的 `ContextLoader#configureAndRefreshWebApplicationContext` 方法在逻辑上相差无几。\n\n如果没有在构造对象时注入，则会继续在 ServletContext 中寻找，因为一般会将创建的 WebApplicationContext 对象记录到 ServletContext 的 attribute 中。再不然就会执行创建逻辑主动创建一个：\n\n```java\nprotected WebApplicationContext createWebApplicationContext(ApplicationContext parent) {\n    // 获取初始化参数 contextClass 对应的值，如果没有配置则默认使用 XmlWebApplicationContext\n    Class<?> contextClass = this.getContextClass();\n    if (this.logger.isDebugEnabled()) {\n        this.logger.debug(\"Servlet with name '\" + getServletName() + \"' will try to create custom WebApplicationContext context of class '\" + contextClass.getName() + \"'\" + \", using parent context [\" + parent + \"]\");\n    }\n    if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) {\n        throw new ApplicationContextException(\"Fatal initialization error in servlet with name '\" + getServletName() + \"': custom WebApplicationContext class [\" + contextClass.getName() + \"] is not of type ConfigurableWebApplicationContext\");\n    }\n    // 通过反射创建对象\n    ConfigurableWebApplicationContext wac = (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);\n\n    // 记录系统环境属性\n    wac.setEnvironment(this.getEnvironment());\n    wac.setParent(parent);\n    // 将配置 spring-mvc.xml 配置文件的位置记录到 wac 中，默认传入 WEB-INFO/{servletName}-servlet.xml\n    wac.setConfigLocation(this.getContextConfigLocation());\n\n    // 初始化Spring环境，以及加载配置文件\n    this.configureAndRefreshWebApplicationContext(wac);\n\n    return wac;\n}\n```\n\n方法执行逻辑已注释的比较清楚，不再多做撰述。\n\n接下来将会判断 refreshEventReceived 是否为 false （默认为 false，该属性会在 `FrameworkServlet#onApplicationEvent` 中被置为 true，以防止重复执行 `onRefresh()` 逻辑），如果是的话则执行 `onRefresh()` 逻辑，这是一个模板方法，DispatcherServlet 对其进行了覆盖实现：\n\n```java\n@Override\nprotected void onRefresh(ApplicationContext context) {\n    this.initStrategies(context);\n}\n```\n\n```java\nprotected void initStrategies(ApplicationContext context) {\n    /*\n     * 在此之前已经完成了IoC容器的初始化，所以bean实例可以直接getBean\n     * 除了 MultipartResolver，其余的解析器均有默认配置\n     */\n\n    // 1. 初始化文件上传解析器 MultipartResolver\n    this.initMultipartResolver(context);\n    // 2. 初始化国际化解析器 LocaleResolver\n    this.initLocaleResolver(context);\n    // 3. 初始化主题解析器 ThemeResolver\n    this.initThemeResolver(context);\n    // 4. 初始化处理器映射器 HandlerMapping\n    this.initHandlerMappings(context);\n    // 5. 初始化处理器适配器 HandlerAdapter\n    this.initHandlerAdapters(context);\n    // 6. 初始化异常处理解析器 HandlerExceptionResolver\n    this.initHandlerExceptionResolvers(context);\n    // 7. 初始化请求到视图名的翻译器 RequestToViewNameTranslator\n    this.initRequestToViewNameTranslator(context);\n    // 8. 初始化视图解析器\n    this.initViewResolvers(context);\n    // 9. 初始化 FlashMapManager，主要用于在 redirect 请求间传递参数\n    this.initFlashMapManager(context);\n}\n```\n\n该方法完成了对 Spring MVC 中核心支持类的初始化过程，关于各解析器的具体功能先不展开，后续会用专门的篇章进行讲解。上述过程调用了 9 个方法分别对各类型解析器执行初始化，这 9 个方法除了第一个 MultipartResolver 之外，其余方法的执行逻辑基本相同，可以概括为调用 getBean 方法从容器中去获取自定义的 bean，如果不存在这采用默认的 bean 代替，我们以其中一个方法 initLocaleResolver 来展开说明，该方法用于初始化本地化支持解析器：\n\n```java\nprivate void initLocaleResolver(ApplicationContext context) {\n    try {\n        // 获取配置的 localeResolver\n        this.localeResolver = context.getBean(LOCALE_RESOLVER_BEAN_NAME, LocaleResolver.class);\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"Using LocaleResolver [\" + this.localeResolver + \"]\");\n        }\n    } catch (NoSuchBeanDefinitionException ex) {\n        // 使用默认策略：org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolver\n        this.localeResolver = this.getDefaultStrategy(context, LocaleResolver.class);\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"Unable to locate LocaleResolver with name '\" + LOCALE_RESOLVER_BEAN_NAME + \"': using default [\" + this.localeResolver + \"]\");\n        }\n    }\n}\n```\n\n方法首先会从容器中获取约定的名为 “localeResolver” 的 bean，如果不存在则从 defaultStrategies 属性中获取默认配置的解析器，该属性位于 DispatcherServlet 中，并在静态代码块中完成初始化：\n\n```java\nstatic {\n    try {\n        // 从 DispatcherServlet.properties 配置文件中加载默认的策略配置\n        ClassPathResource resource = new ClassPathResource(DEFAULT_STRATEGIES_PATH, DispatcherServlet.class);\n        defaultStrategies = PropertiesLoaderUtils.loadProperties(resource);\n    } catch (IOException ex) {\n        throw new IllegalStateException(\"Could not load 'DispatcherServlet.properties': \" + ex.getMessage());\n    }\n}\n```\n\n这与之前 ContextLoader 中 WebApplicationContext 的默认配置和加载策略思想相同，DispatcherServlet.properties 配置文件中包含了上述 9 个方法中除第 1 个方法外的 8 类解析器的默认配置：\n\n```properties\n# 默认策略配置，总共 8 个（没有默认的 MultipartResolver）\n\n# 默认国际化解析器\norg.springframework.web.servlet.LocaleResolver=org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolver\n\n# 默认主题解析器\norg.springframework.web.servlet.ThemeResolver=org.springframework.web.servlet.theme.FixedThemeResolver\n\n# 默认处理器映射\norg.springframework.web.servlet.HandlerMapping=org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping,\\\n    org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMapping\n\n# 默认处理器适配器\norg.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\\\n    org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\\\n    org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter\n\n# 默认异常处理器\norg.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerExceptionResolver,\\\n    org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\\\n    org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver\n\n# 默认视图名称翻译器\norg.springframework.web.servlet.RequestToViewNameTranslator=org.springframework.web.servlet.view.DefaultRequestToViewNameTranslator\n\n# 默认视图解析器\norg.springframework.web.servlet.ViewResolver=org.springframework.web.servlet.view.InternalResourceViewResolver\n\n# 默认的 FlashMapManager\norg.springframework.web.servlet.FlashMapManager=org.springframework.web.servlet.support.SessionFlashMapManager\n```\n\n那么为什么单单就 MultipartResolver 没有默认配置呢？这得联想一下 MultipartResolver 的功能，该解析器主要用于文件上传，这是一个基础但又小众的需求，所以没有必要为所有系统都添加默认的上传请求处理器，很多时候这样的设计是对资源的一种浪费。执行完所有解析器的初始化过程之后，接下来的逻辑就是有条件的将获取到的 WebApplicationContext 对象记录到 ServletContext 对象中，以备在后续需要用到时能够简单的获取。\n\n说到这里我们再回头来看看第一步中的获取在初始化 ContextLoaderServlet 时创建的应用上下文对象。不知道您在阅读这两个组件的初始化的时候有没有这样的疑问，感觉两个组件的初始化过程重复度很高，Spring MVC 为什么要将其拆分成两个过程来实现？这两个过程的初始化是否存在覆盖呢？如果您看过之前我分析 IoC 容器基本结构设计的文章可能还记得下面这样一段话：\n\n> HierarchicalBeanFactory 译为中文是“分层的”，它相对于 BeanFactory 增加了对父 BeanFactory 的获取，子容器可以通过接口方法访问父容器，让容器的设计具备了层次性。这种层次性增强了容器的扩展性和灵活性，我们可以通过编程的方式为一个已有的容器添加一个或多个子容器，从而实现一些特殊功能。层次容器有一个特点就是子容器对于父容器来说是透明的，而子容器则能感知到父容器的存在。\n\nSpring MVC 容器的设计就是分层容器的典型应用场景，我们在配置 ContextLoaderListener 时，会指定 Spring 的一般配置文件，这其中包含 service 层、dao 层，以及一般业务类 bean 的配置，而在配置 DispatcherServlet 时则会指定 mvc 的配置文件，这其中主要是 web 层的相关配置。\n\n上述初始化过程先执行 ContextLoaderListener 的初始化，并将初始化返回的应用上下文对象设置为 DispatcherServlet 初始化过程创建的应用上下文对象的父容器。参考分层容器的隔离规则，__这样的设计能够保证 web 层的 bean 能够访问 service 层等低层次的 bean，而反之则无法访问，从而在容器层面支持友好的系统结构分层__ 。所以说整个初始化过程虽然在执行过程上有一定的冗余度，但确实创建的是两套上下文环境，并且这两套环境具备父子层次关系，希望这样的解释能够让你解惑。\n\nWeb 环境下容器的初始化过程就分析到这里，后续的文章我们将继续探究 MVC 的核心逻辑，看看请求是如何一步步被 Spring MVC 所处理和响应的。\n","tags":["Spring"],"categories":["spring"]},{"title":"Spring AOP 源码解析：注解式切面增强机制","url":"/2017/07/16/spring/spring-aop/","content":"\nIoC 和 AOP 被称为 Spring 两大基础模块，支撑着上层扩展的实现和运行。虽然 AOP 同样建立在 IoC 的实现基础之上，但是作为对 OOP(Object-Oriented Programing) 的补充，AOP(Aspect-Oriented Programming) 在程序设计领域拥有其不可替代的适用场景和地位。Spring AOP 作为 AOP 思想的实现，被誉为 Spring 框架的基础模块也算是实至名归。Spring 在 1.0 版本的时候就引入了对 AOP 的支持，并且随着版本的迭代逐渐提供了基于 XML 配置、注解，以及 schema 配置的使用方式，考虑到实际开发中使用注解配置的方式相对较多，所以本文主要分析注解式 AOP 的实现和运行机制。<!-- more -->\n\n### 注解式 AOP 示例\n\n首先我们还是通过一个简单的示例演示一下注解式 AOP 的具体使用。假设我们声明了一个 IService 接口，并提供了相应的实现类 ServiceImpl，如下：\n\n```java\npublic interface IService {\n    void sayHello();\n    void sayHelloTo(String name);\n    void sayByebye();\n    void sayByebyeTo(String name);\n}\n\n@Service\npublic class ServiceImpl implements IService {\n\n    @Override\n    public void sayHello() {\n        this.sayHelloTo(\"zhenchao\");\n    }\n\n    @Override\n    public void sayHelloTo(String name) {\n        System.out.println(\"hello, \" + name);\n    }\n\n    @Override\n    public void sayByebye() {\n        this.sayByebyeTo(\"zhenchao\");\n    }\n\n    @Override\n    public void sayByebyeTo(String name) {\n        System.out.println(\"byebye, \" + name);\n    }\n\n}\n```\n\n现在我们希望借助 Spring AOP 实现对方法调用的打点功能。首先我们需要定义一个切面：\n\n```java\n@Aspect\n@Component\npublic class MetricAspect {\n\n    @Before(\"execution(* sayHello*(..))\")\n    public void beforeMetrics4sayHello(JoinPoint point) {\n        System.out.println(\"[BEFORE] metrics for method: \" + point.getSignature().getName());\n    }\n\n    @Around(\"execution(* say*(..))\")\n    public Object aroundMetrics4say(ProceedingJoinPoint point) throws Throwable {\n        System.out.println(\"[AROUND] before metrics for method: \" + point.getSignature().getName());\n        Object obj = point.proceed();\n        System.out.println(\"[AROUND] after metrics for method: \" + point.getSignature().getName());\n        return obj;\n    }\n\n    @After(\"execution(* sayByebye*(..))\")\n    public void afterMetrics4sayByebye(JoinPoint point) {\n        System.out.println(\"[AFTER] metrics for method: \" + point.getSignature().getName());\n    }\n\n}\n```\n\n通过 `@Aspect` 注解标记 MetricAspect 是一个切面，通过注解 `@Before`、`@After`，以及 `@Around`，我们在切面中定义了相应的前置、后置，以及环绕增强。然后我们需要在 XML 配置中添加一行如下配置以启用注解式 AOP：\n\n```xml\n<aop:aspectj-autoproxy/>\n```\n\n现在，我们就算大功告成了。\n\n当然，上面的实现只是注解式 AOP 使用的一个简单示例，并没有覆盖所有的特性。对于 Spring AOP 特性的介绍不属于本文的范畴，不过我们还是会在下面分析源码的过程中进行针对性的介绍。\n\n### 注解式 AOP 实现机制\n\n下面从启用注解式 AOP 的那一行配置切入，即 `<aop:aspectj-autoproxy/>` 标签。前面在分析 Spring IoC 实现的文章中，曾专门分析过 Spring 默认标签和自定义标签的解析过程。对于一个标签而言，除了标签的定义，还需要有对应的标签的解析器，并在 Spring 启动时将标签及其解析器注册到 Spring 容器中。标签 `<aop:aspectj-autoproxy />` 的注册过程由 `AopNamespaceHandler#init` 方法实现：\n\n```java\n// 注册 <aspectj-autoproxy/> 标签及其解析器\nthis.registerBeanDefinitionParser(\"aspectj-autoproxy\", new AspectJAutoProxyBeanDefinitionParser());\n```\n\nAspectJAutoProxyBeanDefinitionParser 类是标签 `<aop:aspectj-autoproxy />` 的解析器，该类实现了 BeanDefinitionParser 接口，并实现了 `BeanDefinitionParser#parse` 接口方法，属于标准的标签解析器定义。Spring 容器在启动时会调用 `AspectJAutoProxyBeanDefinitionParser#parse` 方法解析标签，实现如下：\n\n```java\npublic BeanDefinition parse(Element element, ParserContext parserContext) {\n    // 注册标签解析器，默认使用 AnnotationAwareAspectJAutoProxyCreator\n    AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(parserContext, element);\n    // 解析 <aop:include /> 子标签，记录到 BeanDefinition 到 includePatterns 属性中\n    this.extendBeanDefinition(element, parserContext);\n    return null;\n}\n```\n\n该方法做了两件事情：注册标签解析器和处理 `<aop:include />` 子标签。本文我们重点来看标签解析器的注册过程，即 `AopNamespaceUtils#registerAspectJAnnotationAutoProxyCreatorIfNecessary` 方法：\n\n```java\npublic static void registerAspectJAnnotationAutoProxyCreatorIfNecessary(ParserContext parserContext, Element sourceElement) {\n    // 1. 注册或更新代理创建器 ProxyCreator 的 BeanDefinition 对象\n    BeanDefinition beanDefinition = AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(\n            parserContext.getRegistry(), parserContext.extractSource(sourceElement));\n    // 2. 获取并处理标签的 proxy-target-class 和 expose-proxy 属性\n    useClassProxyingIfNecessary(parserContext.getRegistry(), sourceElement);\n    // 3. 注册组件，并发布事件通知\n    registerComponentIfNecessary(beanDefinition, parserContext);\n}\n```\n\n我们在代码注释中标明了该方法所做的 3 件事情，其中 1 和 2 是我们分析的关键，首先来看 1 过程所做的事情：\n\n```java\npublic static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(\n        BeanDefinitionRegistry registry, @Nullable Object source) {\n    return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source);\n}\n\nprivate static BeanDefinition registerOrEscalateApcAsRequired(\n        Class<?> cls, BeanDefinitionRegistry registry, @Nullable Object source) {\n\n    Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\");\n\n    // 如果名为 org.springframework.aop.config.internalAutoProxyCreator 的 bean 已经在册\n    if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) {\n        BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME);\n        // 已经在册的 ProxyCreator 与当前期望的类型不一致，则依据优先级进行选择\n        if (!cls.getName().equals(apcDefinition.getBeanClassName())) {\n            int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName());\n            int requiredPriority = findPriorityForClass(cls);\n            // 选择优先级高的 ProxyCreator 更新注册\n            if (currentPriority < requiredPriority) {\n                apcDefinition.setBeanClassName(cls.getName());\n            }\n        }\n        return null;\n    }\n\n    // 没有对应在册的 ProxyCreator，注册一个新的\n    RootBeanDefinition beanDefinition = new RootBeanDefinition(cls);\n    beanDefinition.setSource(source);\n    beanDefinition.getPropertyValues().add(\"order\", Ordered.HIGHEST_PRECEDENCE);\n    beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n    registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition);\n    return beanDefinition;\n}\n```\n\n上述实现的逻辑还是挺简单的，即注册一个名为 `org.springframework.aop.config.internalAutoProxyCreator` 的 BeanDefinition，我们称之为代理创建器（ProxyCreator）。这里使用的默认实现为 AnnotationAwareAspectJAutoProxyCreator 类，如果存在多个候选实现，则选择优先级最高的进行注册。\n\n接下来看一下过程 2，这一步主要是用来解析标签 `<aop:aspectj-autoproxy/>` 的 `proxy-target-class` 和 `expose-proxy` 属性配置，由 `AopNamespaceUtils#useClassProxyingIfNecessary` 方法实现：\n\n```java\nprivate static void useClassProxyingIfNecessary(BeanDefinitionRegistry registry, @Nullable Element sourceElement) {\n    if (sourceElement != null) {\n        /*\n         * 获取并处理 proxy-target-class 属性：\n         * - false 表示使用 java 原生动态代理\n         * - true 表示使用 CGLib 动态\n         *\n         * 但是对于一些没有接口实现的类来说，即使设置为 false 也会使用 CGlib 进行代理\n         */\n        boolean proxyTargetClass = Boolean.parseBoolean(sourceElement.getAttribute(PROXY_TARGET_CLASS_ATTRIBUTE));\n        if (proxyTargetClass) {\n            // 为之前注册的 ProxyCreator 添加一个名为 proxyTargetClass 的属性，值为 true\n            AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);\n        }\n\n        /*\n         * 获取并处理 expose-proxy 标签，实现对于内部方法调用的 AOP 增强\n         */\n        boolean exposeProxy = Boolean.parseBoolean(sourceElement.getAttribute(EXPOSE_PROXY_ATTRIBUTE));\n        if (exposeProxy) {\n            // 为之前注册的 ProxyCreator 添加一个名为 exposeProxy 的属性，值为 true\n            AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry);\n        }\n    }\n}\n```\n\n其中 `proxy-target-class` 属性用来配置是否使用 CGLib 代理，而 `expose-proxy` 属性则用来配置是否对内部方法调用启用 AOP 增强。属性 `proxy-target-class` 的作用大家应该都比较熟悉，下面介绍一下 `expose-proxy` 属性。前面给出的 AOP 示例中，我们在 `IService#sayHello` 方法中调用了 `IService#sayHelloTo` 方法，虽然两个方法都满足对应的 AOP 增强定义，但是只有 `IService#sayHello` 方法被增强了，这主要是因为 `IService#sayHelloTo` 方法是在对象内部调用的，调用该方法的对象并不是代理对象。如果期望内部调用时也能够被增强，我们需要配置 `expose-proxy=true`，并修改 `IService#sayHello` 方法对于 `IService#sayHelloTo` 方法的调用方式：\n\n```java\npublic void sayHello() {\n    ((IService) AopContext.currentProxy()).sayHelloTo(\"zhenchao\");\n}\n```\n\n上面分析了这么多，总的说来就是向 Spring 容器中注册了一个 AnnotationAwareAspectJAutoProxyCreator 类型的 ProxyCreator，并将配置的 `proxy-target-class` 和 `expose-proxy` 属性添加到对应 BeanDefinition 的属性列表中。那么 AnnotationAwareAspectJAutoProxyCreator 到底是来做什么的呢？我们先来看一下它的类继承关系图：\n\n![image](/images/2017/spring-aop-proxy-creator.png)\n\n从类继承关系图中可以看到该类实现了 BeanPostProcessor 接口，该接口定义如下：\n\n```java\npublic interface BeanPostProcessor {\n\n    @Nullable\n    default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {\n        return bean;\n    }\n\n    @Nullable\n    default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {\n        return bean;\n    }\n\n}\n```\n\n由之前对 Spring IoC 容器启动过程的分析，我们知道在容器启动过程中会在初始化 bean 实例的前后分别调用 BeanPostProcessor 中定义的这两个方法。针对这两个方法的实现主要位于继承链的 AbstractAutoProxyCreator 类中，并且主要是实现了 `BeanPostProcessor#postProcessAfterInitialization` 方法：\n\n```java\npublic Object postProcessAfterInitialization(@Nullable Object bean, String beanName) {\n    if (bean != null) {\n        // 如果 beanName 不为空则直接使用 beanName（FactoryBean 则使用 &{beanName}），否则使用 bean 的 className\n        Object cacheKey = this.getCacheKey(bean.getClass(), beanName);\n        if (!this.earlyProxyReferences.contains(cacheKey)) {\n            // 尝试对 bean 进行增强，创建返回增强后的代理对象\n            return this.wrapIfNecessary(bean, beanName, cacheKey);\n        }\n    }\n    return bean;\n}\n```\n\n该方法的核心在于调用 `AbstractAutoProxyCreator#wrapIfNecessary` 方法尝试基于 AOP 配置对当前 bean 进行增强，并返回增强后的代理对象。方法 `AbstractAutoProxyCreator#wrapIfNecessary` 的实现如下：\n\n```java\nprotected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) {\n    // 已经处理过，直接返回\n    if (StringUtils.hasLength(beanName) && this.targetSourcedBeans.contains(beanName)) {\n        return bean;\n    }\n    // 不需要进行增强的 bean 实例，直接跳过\n    if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) {\n        return bean;\n    }\n    // 对于 AOP 的基础支撑类，或者指定不需要被代理的类，设置为不进行代理\n    if (this.isInfrastructureClass(bean.getClass()) || this.shouldSkip(bean.getClass(), beanName)) {\n        this.advisedBeans.put(cacheKey, Boolean.FALSE);\n        return bean;\n    }\n\n    // 获取适用于当前 bean 的 Advisor\n    Object[] specificInterceptors = this.getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);\n    // 基于获取到的 Advisor 为当前 bean 创建代理对象\n    if (specificInterceptors != DO_NOT_PROXY) {\n        this.advisedBeans.put(cacheKey, Boolean.TRUE);\n        Object proxy = this.createProxy(\n                bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));\n        this.proxyTypes.put(cacheKey, proxy.getClass());\n        return proxy;\n    }\n\n    this.advisedBeans.put(cacheKey, Boolean.FALSE);\n    return bean;\n}\n```\n\n上述方法主要的工作是对 bean 实例进行筛选，过滤掉那些已经增强过的、支持 AOP 基础运行的，以及指定不需要被代理的 bean 实例。对于剩下的 bean 实例来说，首先会调用 `AbstractAdvisorAutoProxyCreator#getAdvicesAndAdvisorsForBean` 方法获取适用于当前 bean 的增强器（Advisor），并基于这些增强器调用 `AbstractAutoProxyCreator#createProxy` 方法为当前 bean 创建增强后的代理对象。\n\n#### 筛选适用于 bean 的增强器\n\n我们首先来看一下筛选适用于当前 bean 的合格增强器的过程，实现位于 `AbstractAdvisorAutoProxyCreator#getAdvicesAndAdvisorsForBean` 方法中：\n\n```java\nprotected Object[] getAdvicesAndAdvisorsForBean(\n        Class<?> beanClass, String beanName, @Nullable TargetSource targetSource) {\n    // 获取适用于当前 bean 的 Advisor\n    List<Advisor> advisors = this.findEligibleAdvisors(beanClass, beanName);\n    // 没有合格的 Advisor，不进行代理\n    if (advisors.isEmpty()) {\n        return DO_NOT_PROXY; // null\n    }\n    return advisors.toArray();\n}\n\nprotected List<Advisor> findEligibleAdvisors(Class<?> beanClass, String beanName) {\n    // 获取所有候选的 Advisor（包括注解的、XML 中配置的）\n    List<Advisor> candidateAdvisors = this.findCandidateAdvisors();\n    // 从所有 Advisor 中寻找适用于当前 bean 的 Advisor\n    List<Advisor> eligibleAdvisors = this.findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName);\n    // 如果 Advisor 不为空，则在最前面追加一个 ExposeInvocationInterceptor\n    this.extendAdvisors(eligibleAdvisors);\n    // 对 Advisor 进行排序\n    if (!eligibleAdvisors.isEmpty()) {\n        eligibleAdvisors = this.sortAdvisors(eligibleAdvisors);\n    }\n    return eligibleAdvisors;\n}\n```\n\n整个方法的执行流程很简单，获取所有的候选增强器，并从中找出适用于当前 bean 的增强器。首先来看获取所有候选增强器的过程，实现位于 `AnnotationAwareAspectJAutoProxyCreator#findCandidateAdvisors` 方法中：\n\n```java\nprotected List<Advisor> findCandidateAdvisors() {\n    // 调用父类的 findCandidateAdvisors 方法，兼容父类查找 Advisor 的规则\n    List<Advisor> advisors = super.findCandidateAdvisors();\n    // 获取所有注解定义的 Advisor\n    if (this.aspectJAdvisorsBuilder != null) {\n        advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors());\n    }\n    return advisors;\n}\n```\n\n方法首先调用了父类的实现，这主要是为了兼容父类查找候选增强器的规则，例如我们的示例中使用的是注解方式定义的增强，但是父类却是基于 XML 配置的方式查找增强器，这里的兼容能够让我们在以注解方式编程时兼容其它以 XML 配置的方式定义的增强。下面还是将主要精力放在解析注解式增强定义上，该过程位于 `BeanFactoryAspectJAdvisorsBuilder#buildAspectJAdvisors` 方法中。不过该方法实现比较冗长，但是逻辑却很清晰，所以这里主要概括一下其执行流程：\n\n1. 获取所有类型 bean 实例对应的 beanName 集合；\n2. 过滤不是切面类型的 bean 对应的 beanName，即没有被 `@Aspect` 注解，或包含以 `ajc$` 开头的字段，同时支持覆盖 `BeanFactoryAspectJAdvisorsBuilder#isEligibleBean` 方法扩展过滤规则；\n3. 对于切面 bean 类型，获取 bean 中定义的所有切点，并为每个切点生成对应的增强器；\n4. 缓存解析得到的增强器，避免重复解析。\n\n上述流程中我们重点看一下过程 3，实现位于 `ReflectiveAspectJAdvisorFactory#getAdvisors` 方法中：\n\n```java\npublic List<Advisor> getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory) {\n    // 获取切面 aspect 对应的 class 和 beanName\n    Class<?> aspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass();\n    String aspectName = aspectInstanceFactory.getAspectMetadata().getAspectName();\n    // 校验切面定义的合法性\n    this.validate(aspectClass);\n\n    // We need to wrap the MetadataAwareAspectInstanceFactory with a decorator\n    // so that it will only instantiate once.\n    MetadataAwareAspectInstanceFactory lazySingletonAspectInstanceFactory =\n            new LazySingletonAspectInstanceFactoryDecorator(aspectInstanceFactory);\n\n    List<Advisor> advisors = new ArrayList<>();\n\n    // 1. 遍历处理切面中除被 @Pointcut 注解以外的方法\n    for (Method method : this.getAdvisorMethods(aspectClass)) {\n        Advisor advisor = this.getAdvisor(method, lazySingletonAspectInstanceFactory, advisors.size(), aspectName);\n        if (advisor != null) {\n            advisors.add(advisor);\n        }\n    }\n\n    // 2. 如果增强器不为空，同时又配置了增强延迟初始化，则需要追加实例化增强器 SyntheticInstantiationAdvisor\n    if (!advisors.isEmpty() && lazySingletonAspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) {\n        Advisor instantiationAdvisor = new SyntheticInstantiationAdvisor(lazySingletonAspectInstanceFactory);\n        advisors.add(0, instantiationAdvisor);\n    }\n\n    // 3. 获取所有引介增强定义\n    for (Field field : aspectClass.getDeclaredFields()) {\n        // 创建引介增强器 DeclareParentsAdvisor\n        Advisor advisor = this.getDeclareParentsAdvisor(field);\n        if (advisor != null) {\n            advisors.add(advisor);\n        }\n    }\n\n    return advisors;\n}\n```\n\n上述实现的整体执行流程如代码注释。拿到一个切面定义，Spring 首先会遍历获取切面中的增强方法，即被 `@Around`、`@Before`、`@After`、`@AfterReturning`，以及 `@AfterThrowing` 注解的方法，并调用 `ReflectiveAspectJAdvisorFactory#getAdvisor` 方法为每一个增强方法生成对应的增强器：\n\n```java\npublic Advisor getAdvisor(Method candidateAdviceMethod,\n                          MetadataAwareAspectInstanceFactory aspectInstanceFactory,\n                          int declarationOrderInAspect,\n                          String aspectName) {\n\n    // 校验切面类定义的合法性\n    this.validate(aspectInstanceFactory.getAspectMetadata().getAspectClass());\n\n    // 获取注解配置的切点信息，封装成 AspectJExpressionPointcut 对象\n    AspectJExpressionPointcut expressionPointcut = this.getPointcut(\n            candidateAdviceMethod, aspectInstanceFactory.getAspectMetadata().getAspectClass());\n    if (expressionPointcut == null) {\n        return null;\n    }\n\n    // 依据切点信息生成对应的增强器\n    return new InstantiationModelAwarePointcutAdvisorImpl(\n            expressionPointcut, candidateAdviceMethod, this, aspectInstanceFactory, declarationOrderInAspect, aspectName);\n}\n```\n\n上述实现首先对当前切面定义执行合法性校验，如果切面配置合法则获取目标方法上的切点注解定义，并封装成 AspectJExpressionPointcut 对象。该过程位于 `ReflectiveAspectJAdvisorFactory#getPointcut` 方法中，实现比较简单。\n\n拿到切点注解定义之后，方法会依据切点的配置信息使用 InstantiationModelAwarePointcutAdvisorImpl 实现类创建对应的增强器。类 InstantiationModelAwarePointcutAdvisorImpl 的实例化过程除了初始化了一些基本属性之外，主要是调用了 `InstantiationModelAwarePointcutAdvisorImpl#instantiateAdvice` 方法，依据增强类型对增强器实施相应的初始化操作：\n\n```java\nprivate Advice instantiateAdvice(AspectJExpressionPointcut pointcut) {\n    Advice advice = this.aspectJAdvisorFactory.getAdvice(\n            this.aspectJAdviceMethod, pointcut, this.aspectInstanceFactory, this.declarationOrder, this.aspectName);\n    return (advice != null ? advice : EMPTY_ADVICE);\n}\n\n// org.springframework.aop.aspectj.annotation.ReflectiveAspectJAdvisorFactory#getAdvice\npublic Advice getAdvice(Method candidateAdviceMethod,\n                        AspectJExpressionPointcut expressionPointcut,\n                        MetadataAwareAspectInstanceFactory aspectInstanceFactory,\n                        int declarationOrder,\n                        String aspectName) {\n\n    // 获取切面 class 对象，并校验切面定义\n    Class<?> candidateAspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass();\n    this.validate(candidateAspectClass);\n\n    // 获取方法的切点注解定义\n    AspectJAnnotation<?> aspectJAnnotation =\n            AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod);\n    if (aspectJAnnotation == null) {\n        return null;\n    }\n\n    // If we get here, we know we have an AspectJ method.\n    // Check that it's an AspectJ-annotated class\n    if (!this.isAspect(candidateAspectClass)) {\n        throw new AopConfigException(\"Advice must be declared inside an aspect type: \" +\n                \"Offending method '\" + candidateAdviceMethod + \"' in class [\" + candidateAspectClass.getName() + \"]\");\n    }\n\n    AbstractAspectJAdvice springAdvice;\n\n    // 依据切点注解类型使用对应的增强类进行封装\n    switch (aspectJAnnotation.getAnnotationType()) {\n        // @Pointcut\n        case AtPointcut:\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"Processing pointcut '\" + candidateAdviceMethod.getName() + \"'\");\n            }\n            return null;\n        // @Around\n        case AtAround:\n            springAdvice = new AspectJAroundAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);\n            break;\n        // @Before\n        case AtBefore:\n            springAdvice = new AspectJMethodBeforeAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);\n            break;\n        // @After\n        case AtAfter:\n            springAdvice = new AspectJAfterAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);\n            break;\n        // @AfterReturning\n        case AtAfterReturning:\n            springAdvice = new AspectJAfterReturningAdvice(candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);\n            AfterReturning afterReturningAnnotation = (AfterReturning) aspectJAnnotation.getAnnotation();\n            if (StringUtils.hasText(afterReturningAnnotation.returning())) {\n                springAdvice.setReturningName(afterReturningAnnotation.returning());\n            }\n            break;\n        // @AfterThrowing\n        case AtAfterThrowing:\n            springAdvice = new AspectJAfterThrowingAdvice(\n                    candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);\n            AfterThrowing afterThrowingAnnotation = (AfterThrowing) aspectJAnnotation.getAnnotation();\n            if (StringUtils.hasText(afterThrowingAnnotation.throwing())) {\n                springAdvice.setThrowingName(afterThrowingAnnotation.throwing());\n            }\n            break;\n        default:\n            throw new UnsupportedOperationException(\"Unsupported advice type on method: \" + candidateAdviceMethod);\n    }\n\n    // Now to configure the advice...\n    springAdvice.setAspectName(aspectName);\n    springAdvice.setDeclarationOrder(declarationOrder);\n    String[] argNames = this.parameterNameDiscoverer.getParameterNames(candidateAdviceMethod);\n    if (argNames != null) {\n        springAdvice.setArgumentNamesFromStringArray(argNames);\n    }\n    springAdvice.calculateArgumentBindings();\n\n    return springAdvice;\n}\n```\n\n方法的整体执行流程如代码注释，逻辑比较清晰，Spring 会依据具体的增强注解类型，选择相应的增强类对切点定义进行封装。这里我们以 `@Before` 为例说明一下增强的执行流程，AspectJMethodBeforeAdvice 增强类关联注册的处理器是 MethodBeforeAdviceInterceptor，当我们调用一个被前置增强的目标方法时，`MethodBeforeAdviceInterceptor#invoke` 方法会被触发：\n\n```java\npublic Object invoke(MethodInvocation mi) throws Throwable {\n    // 执行增强方法\n    this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis());\n    // 执行目标方法\n    return mi.proceed();\n}\n```\n\n这里执行的增强方法就对应着 `AspectJMethodBeforeAdvice#before` 方法，该方法会依据切点配置将相应的参数绑定传递给我们自定义的增强方法，并最终通过反射调用触发执行。\n\n上面分析了普通方法级别增强的处理过程，对于另外一类增强（引介增强），方法 `ReflectiveAspectJAdvisorFactory#getAdvisors` 则使用专门的 DeclareParentsAdvisor 类创建对应的增强器：\n\n```java\n// 3. 获取所有引介增强定义\nfor (Field field : aspectClass.getDeclaredFields()) {\n    // 创建引介增强器\n    Advisor advisor = this.getDeclareParentsAdvisor(field);\n    if (advisor != null) {\n        advisors.add(advisor);\n    }\n}\n\nprivate Advisor getDeclareParentsAdvisor(Field introductionField) {\n    // 获取 @DeclareParents 注解定义\n    DeclareParents declareParents = introductionField.getAnnotation(DeclareParents.class);\n    if (declareParents == null) {\n        return null;\n    }\n\n    // 没有指定默认的接口实现类\n    if (DeclareParents.class == declareParents.defaultImpl()) {\n        throw new IllegalStateException(\"'defaultImpl' attribute must be set on DeclareParents\");\n    }\n\n    // 使用 DeclareParentsAdvisor 类型创建对应的引介增强器\n    return new DeclareParentsAdvisor(\n            introductionField.getType(), declareParents.value(), declareParents.defaultImpl());\n}\n```\n\n对于引介增强来说，Spring 会注入 DelegatePerTargetObjectIntroductionInterceptor 处理器对其进行专门的处理，思想上与前面分析前置增强大同小异，这里不再展开。\n\n继续回到 `AbstractAdvisorAutoProxyCreator#findEligibleAdvisors` 方法，上面的过程我们分析了获取所有类型增强器的过程，但是这些增强器不一定都适用于当前 bean 实例，我们需要依据切点配置信息对其进行筛选。这一过程位于 `AbstractAdvisorAutoProxyCreator#findAdvisorsThatCanApply` 方法中：\n\n```java\nprotected List<Advisor> findAdvisorsThatCanApply(\n        List<Advisor> candidateAdvisors, Class<?> beanClass, String beanName) {\n    ProxyCreationContext.setCurrentProxiedBeanName(beanName);\n    try {\n        return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass);\n    } finally {\n        ProxyCreationContext.setCurrentProxiedBeanName(null);\n    }\n}\n\n// org.springframework.aop.support.AopUtils#findAdvisorsThatCanApply\npublic static List<Advisor> findAdvisorsThatCanApply(List<Advisor> candidateAdvisors, Class<?> clazz) {\n    // 没有候选的增强器，直接返回\n    if (candidateAdvisors.isEmpty()) {\n        return candidateAdvisors;\n    }\n    List<Advisor> eligibleAdvisors = new ArrayList<>();\n\n    // 1. 筛选引介增强器\n    for (Advisor candidate : candidateAdvisors) {\n        if (candidate instanceof IntroductionAdvisor && canApply(candidate, clazz)) {\n            eligibleAdvisors.add(candidate);\n        }\n    }\n    // 表示是否含有引介增强\n    boolean hasIntroductions = !eligibleAdvisors.isEmpty();\n\n    // 2. 筛选其它类型的增强器\n    for (Advisor candidate : candidateAdvisors) {\n        // 引介增强已经处理过，这里直接跳过\n        if (candidate instanceof IntroductionAdvisor) {\n            // already processed\n            continue;\n        }\n        // 筛选其它类型的增强器\n        if (canApply(candidate, clazz, hasIntroductions)) {\n            eligibleAdvisors.add(candidate);\n        }\n    }\n    return eligibleAdvisors;\n}\n```\n\n方法首先会使用类过滤器（ClassFilter）筛选引介增强器，除了我们手动注册的类过滤器外，这里默认还会使用 TypePatternClassFilter 类过滤器执行过滤操作。然后，方法会过滤筛选其它类型的增强器，这里除了使用类过滤器外，考虑方法级别增强的定义形式，还会使用方法匹配器（MethodMatcher）进行筛选。如果增强器适用于当前 bean 类型，则将其加入到集合中用于下一步为当前 bean 创建增强代理对象。如果没有任何一个增强器适用于当前 bean 类型，则方法 `AbstractAdvisorAutoProxyCreator#getAdvicesAndAdvisorsForBean` 最终会返回值为 null 的 `DO_NOT_PROXY` 数组对象，表示当前 bean 不需要被增强。\n\n#### 为 bean 创建增强代理对象\n\n完成了对于当前 bean 增强器的筛选，接下来我们继续回到 `AbstractAutoProxyCreator#wrapIfNecessary` 方法，看一下基于前面筛选出的增强器为当前 bean 创建增强代理对象的过程，实现位于 `AbstractAutoProxyCreator#createProxy` 方法中：\n\n```java\nprotected Object createProxy(Class<?> beanClass,\n                             @Nullable String beanName,\n                             @Nullable Object[] specificInterceptors,\n                             TargetSource targetSource) {\n\n    if (this.beanFactory instanceof ConfigurableListableBeanFactory) {\n        AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass);\n    }\n\n    // ProxyFactory 用于为目标 bean 实例创建代理对象\n    ProxyFactory proxyFactory = new ProxyFactory();\n    proxyFactory.copyFrom(this);\n\n    // proxy-target-class = false，表示使用 JDK 原生动态代理\n    if (!proxyFactory.isProxyTargetClass()) {\n        // 检测当前 bean 是否应该基于类而非接口生成代理对象，即包含 preserveTargetClass=true 属性\n        if (this.shouldProxyTargetClass(beanClass, beanName)) {\n            proxyFactory.setProxyTargetClass(true);\n        }\n        // 如果是基于接口生成代理，则添加需要代理的接口到 ProxyFactory 中（除内置 callback 接口、语言内在接口，以及标记接口）\n        else {\n            this.evaluateProxyInterfaces(beanClass, proxyFactory);\n        }\n    }\n\n    // 将拦截器封装成 Advisor 对象\n    Advisor[] advisors = this.buildAdvisors(beanName, specificInterceptors);\n    proxyFactory.addAdvisors(advisors);\n    proxyFactory.setTargetSource(targetSource);\n    // 模板方法，定制代理工厂\n    this.customizeProxyFactory(proxyFactory);\n\n    // 设置代理工厂被配置之后是否还允许修改，默认为 false，表示不允许修改\n    proxyFactory.setFrozen(this.freezeProxy);\n    if (this.advisorsPreFiltered()) {\n        proxyFactory.setPreFiltered(true);\n    }\n\n    // 基于 ProxyFactory 创建代理类\n    return proxyFactory.getProxy(this.getProxyClassLoader());\n}\n```\n\n方法的执行流程如代码注释。下面我们主要分析将拦截器封装成 Advisor 对象的过程，以及基于 ProxyFactory 创建增强代理对象的过程。\n\nSpring 定义了非常多的拦截器、增强器，以及增强方法等，这里通过 `AbstractAutoProxyCreator#buildAdvisors` 方法统一将他们封装成 Advisor 对象，从而简化代理的创建过程。封装的核心步骤由 `DefaultAdvisorAdapterRegistry#wrap` 方法实现：\n\n```java\npublic Advisor wrap(Object adviceObject) throws UnknownAdviceTypeException {\n    // 已经是 Advisor，则无需多做处理\n    if (adviceObject instanceof Advisor) {\n        return (Advisor) adviceObject;\n    }\n    // 要求必须是 Advice 类型\n    if (!(adviceObject instanceof Advice)) {\n        throw new UnknownAdviceTypeException(adviceObject);\n    }\n    Advice advice = (Advice) adviceObject;\n    // 如果是 MethodInterceptor，则直接使用 DefaultPointcutAdvisor 进行包装\n    if (advice instanceof MethodInterceptor) {\n        // So well-known it doesn't even need an adapter.\n        return new DefaultPointcutAdvisor(advice);\n    }\n    // 否则遍历注册的适配器，如果存在关联的适配器则使用 DefaultPointcutAdvisor 进行包装\n    for (AdvisorAdapter adapter : this.adapters) {\n        // Check that it is supported.\n        if (adapter.supportsAdvice(advice)) {\n            return new DefaultPointcutAdvisor(advice);\n        }\n    }\n    throw new UnknownAdviceTypeException(advice);\n}\n```\n\n接下来我们重点分析一下通过代理工厂 ProxyFactory 创建增强代理对象的过程，实现位于 `ProxyFactory#getProxy` 方法中：\n\n```java\npublic Object getProxy(@Nullable ClassLoader classLoader) {\n    return this.createAopProxy() // 1. 创建 AOP 代理\n            .getProxy(classLoader); // 2. 基于 AOP 代理创建目标类的增强代理对象\n}\n```\n\n该方法的执行过程可以拆分成两个步骤：\n\n1. 创建 AOP 代理，Spring 默认提供了两种 AOP 代理实现，即 java 原生代理和 CGLib 代理；\n2. 基于 AOP 代理创建目标类的增强代理对象。\n\n我们首先来看一下步骤 1 的实现，位于 `ProxyCreatorSupport#createAopProxy` 方法中：\n\n```java\nprotected final synchronized AopProxy createAopProxy() {\n    if (!this.active) {\n        this.activate();\n    }\n    return this.getAopProxyFactory().createAopProxy(this);\n}\n\n// org.springframework.aop.framework.DefaultAopProxyFactory#createAopProxy\npublic AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException {\n    if (config.isOptimize() // 需要对代理策略进行优化\n            || config.isProxyTargetClass() // // 指定使用 CGLib 生成代理对象\n            || this.hasNoUserSuppliedProxyInterfaces(config)) // 当前类没有接口定义，不得不使用 CGLib\n    {\n        Class<?> targetClass = config.getTargetClass();\n        if (targetClass == null) {\n            throw new AopConfigException(\"TargetSource cannot determine target class: \" +\n                    \"Either an interface or a target is required for proxy creation.\");\n        }\n        // 目标类是接口或代理类，使用 JDK 原生代理\n        if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) {\n            return new JdkDynamicAopProxy(config);\n        }\n        // 使用 CGLib 动态代理\n        return new ObjenesisCglibAopProxy(config);\n    }\n    // 使用 JDK 原生动态代理\n    else {\n        return new JdkDynamicAopProxy(config);\n    }\n}\n```\n\n这部分代码清晰说明了 Spring 在生成代理对象时如何在 java 原生代理和 CGLib 代理之间进行选择，可以概括如下：\n\n1. 如果目标类实现了接口，则 Spring 默认会使用 java 原生代理。\n2. 如果目标类未实现接口，则 Spring 会使用 CGLib 生成代理。\n3. 如果目标类实现了接口，但是在配置时指定了 `proxy-target-class=true`，则使用 CGLib 生成代理。\n\n下面分别对基于 java 原生代理和 CGLib 代理生成增强代理对象的过程进行分析。\n\n##### 基于 java 原生代理创建增强代理对象\n\n首先来看一下基于 java 原生代理生成增强代理对象的过程，位于 JdkDynamicAopProxy 类中。Java 原生代理要求代理类实现 InvocationHandler 接口，并在 `InvocationHandler#invoke` 方法中实现代理增强逻辑。JdkDynamicAopProxy 正好实现了该接口，对应的 `JdkDynamicAopProxy#invoke` 方法实现如下：\n\n```java\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n    Object oldProxy = null;\n    boolean setProxyContext = false;\n\n    TargetSource targetSource = this.advised.targetSource;\n    Object target = null;\n\n    try {\n        // 当前是 equals 方法，但是被代理类接口中未定义 equals 方法\n        if (!this.equalsDefined && AopUtils.isEqualsMethod(method)) {\n            return this.equals(args[0]);\n        }\n        // 当前是 hashCode 方法，但是被代理类接口中未定义 hashCode 方法\n        else if (!this.hashCodeDefined && AopUtils.isHashCodeMethod(method)) {\n            return this.hashCode();\n        }\n        // 如果是 DecoratingProxy 中定义的方法（即 DecoratingProxy#getDecoratedClass），直接返回目标类对象\n        else if (method.getDeclaringClass() == DecoratingProxy.class) {\n            return AopProxyUtils.ultimateTargetClass(this.advised);\n        } else if (!this.advised.opaque // 允许被转换成 Advised 类型\n                && method.getDeclaringClass().isInterface() // 接口类型\n                && method.getDeclaringClass().isAssignableFrom(Advised.class)) // 方法所在类是 Advised 类及其父类\n        {\n            // 直接反射调用该方法\n            return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args);\n        }\n\n        // 结果值\n        Object retVal;\n\n        // 指定内部间调用也需要代理\n        if (this.advised.exposeProxy) {\n            // Make invocation available if necessary.\n            oldProxy = AopContext.setCurrentProxy(proxy);\n            setProxyContext = true;\n        }\n\n        // Get as late as possible to minimize the time we \"own\" the target, in case it comes from a pool.\n        target = targetSource.getTarget();\n        Class<?> targetClass = (target != null ? target.getClass() : null);\n\n        // 获取当前方法的拦截器链\n        List<Object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);\n\n        // Check whether we have any advice. If we don't, we can fallback on direct\n        // reflective invocation of the target, and avoid creating a MethodInvocation.\n        // 拦截器链为空，则直接反射调用增强方法\n        if (chain.isEmpty()) {\n            // We can skip creating a MethodInvocation: just invoke the target directly\n            // Note that the final invoker must be an InvokerInterceptor so we know it does\n            // nothing but a reflective operation on the target, and no hot swapping or fancy proxying.\n            Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);\n            retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);\n        }\n        // 否则需要创建对应的 MethodInvocation，以链式调用拦截器方法和增强方法\n        else {\n            MethodInvocation invocation =\n                    new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);\n            // Proceed to the joinpoint through the interceptor chain.\n            retVal = invocation.proceed();\n        }\n\n        // 处理返回值\n        Class<?> returnType = method.getReturnType();\n        if (retVal != null && retVal == target &&\n                returnType != Object.class && returnType.isInstance(proxy) &&\n                !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) {\n            // Special case: it returned \"this\" and the return type of the method is type-compatible.\n            // Note that we can't help if the target sets a reference to itself in another returned object.\n            retVal = proxy;\n        } else if (retVal == null && returnType != Void.TYPE && returnType.isPrimitive()) {\n            throw new AopInvocationException(\n                    \"Null return value from advice does not match primitive return type for: \" + method);\n        }\n        return retVal;\n    } finally {\n        if (target != null && !targetSource.isStatic()) {\n            // Must have come from TargetSource.\n            targetSource.releaseTarget(target);\n        }\n        if (setProxyContext) {\n            // Restore old proxy.\n            AopContext.setCurrentProxy(oldProxy);\n        }\n    }\n}\n```\n\n由上述方法实现，我们可以概括出整个增强代理的执行过程，如下：\n\n1. 特殊处理 `Object#equals`、`Object#hashCode`、`DecoratingProxy#getDecoratedClass`，以及 Advised 类及其父类中定义的方法；\n2. 如果配置了 expose-proxy 属性，则记录当前代理对象，以备在内部间调用时实施增强；\n3. 获取当前方法的拦截器链；\n4. 如果没有拦截器定义，则直接反射调用增强方法，否则先逐一执行拦截器方法，最后再应用增强方法；\n5. 处理返回值。\n\n重点来看一下步骤 4 中应用拦截器方法的实现，位于 `ReflectiveMethodInvocation#proceed` 方法中：\n\n```java\npublic Object proceed() throws Throwable {\n    // 如果所有的增强都执行完成，则执行增强方法\n    if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) {\n        return this.invokeJoinpoint();\n    }\n\n    // 获取下一个需要执行的拦截器\n    Object interceptorOrInterceptionAdvice =\n            this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex);\n    // 动态拦截器，执行动态方法匹配\n    if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) {\n        // Evaluate dynamic method matcher here: static part will already have been evaluated and found to match.\n        InterceptorAndDynamicMethodMatcher dm =\n                (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice;\n        Class<?> targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass());\n        // 动态匹配成功，执行对应的拦截方法\n        if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) {\n            return dm.interceptor.invoke(this);\n        }\n        // 动态匹配失败，忽略当前拦截器方法，继续执行下一个拦截器\n        else {\n            return this.proceed();\n        }\n    }\n    // 静态拦截器，直接应用拦截方法\n    else {\n        return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);\n    }\n}\n```\n\n拦截器方法的执行流程如上述代码注释，是一个递归调用的过程，并在最后应用增强方法。\n\n完成了对于 AOP 代理对象 JdkDynamicAopProxy 的创建，最后来看一下获取该对象的过程，实现位于 `JdkDynamicAopProxy#getProxy` 方法中：\n\n```java\npublic Object getProxy(@Nullable ClassLoader classLoader) {\n    // 获取需要被代理的接口集合\n    Class<?>[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true);\n    // 检测是否在被代理接口中声明了 equals 和 hashCode 方法\n    this.findDefinedEqualsAndHashCodeMethods(proxiedInterfaces);\n    // 基于 java 原生代理生成代理对象\n    return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);\n}\n```\n\n这里的逻辑也就是 java 原生代理的模板代码，如果对 java 代理比较熟悉的话，应该不难理解。\n\n##### 基于 CGLib 代理创建增强代理对象\n\n基于 CGLib 代理生成增强代理对象的过程位于 ObjenesisCglibAopProxy 类中，该类继承自 CglibAopProxy 类。获取 CGLib 代理类对象的方法定义在 CglibAopProxy 中，即 `CglibAopProxy#getProxy` 方法。该方法基于 CGLib 的 Enhancer 类创建代理对象，属于 CGLib 的标准使用模式，因为有多个 callback 实现，所以这里使用了 CallbackFilter 模式，依据场景选择并应用对应的 callback 拦截器。\n\n我们重点关注 callback 的实现，位于 `CglibAopProxy#getCallbacks` 方法中。受制于 CGLib 在执行时一次只允许应用一个 callback 的约束，所以该方法依据参数配置实现了一组 callback，以覆盖不同的场景。核心的 AOP callback 实现是 DynamicAdvisedInterceptor 类，它实现了 MethodInterceptor 接口，对应的 `DynamicAdvisedInterceptor#intercept` 方法实现如下：\n\n```java\npublic Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {\n    Object oldProxy = null;\n    boolean setProxyContext = false;\n    Object target = null;\n    TargetSource targetSource = this.advised.getTargetSource();\n    try {\n        // 指定内部间调用也需要代理\n        if (this.advised.exposeProxy) {\n            // Make invocation available if necessary.\n            oldProxy = AopContext.setCurrentProxy(proxy);\n            setProxyContext = true;\n        }\n        // Get as late as possible to minimize the time we \"own\" the target, in case it comes from a pool...\n        target = targetSource.getTarget();\n        Class<?> targetClass = (target != null ? target.getClass() : null);\n\n        // 获取当前方法的拦截器链\n        List<Object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);\n        // 结果值\n        Object retVal;\n        // Check whether we only have one InvokerInterceptor:\n        // that is, no real advice, but just reflective invocation of the target.\n        // 拦截器链为空，则直接反射调用增强方法\n        if (chain.isEmpty() && Modifier.isPublic(method.getModifiers())) {\n            // We can skip creating a MethodInvocation: just invoke the target directly.\n            // Note that the final invoker must be an InvokerInterceptor, so we know\n            // it does nothing but a reflective operation on the target, and no hot swapping or fancy proxying.\n            Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);\n            retVal = methodProxy.invoke(target, argsToUse);\n        }\n        // 否则需要创建对应的 MethodInvocation，以链式调用拦截器方法和增强方法\n        else {\n            retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed();\n        }\n        // 处理返回值\n        retVal = processReturnType(proxy, target, method, retVal);\n        return retVal;\n    } finally {\n        if (target != null && !targetSource.isStatic()) {\n            targetSource.releaseTarget(target);\n        }\n        if (setProxyContext) {\n            // Restore old proxy.\n            AopContext.setCurrentProxy(oldProxy);\n        }\n    }\n}\n```\n\n可以看出上述方法在实现流程上与前面介绍的 `JdkDynamicAopProxy#invoke` 方法是一致的，只是这里是基于 CGLib 实现而已。\n\n### 总结\n\n最后我们对 Spring AOP 的运行机制进行一个总结。Spring AOP 的实现本质上是一个动态代理的过程，Spring 引入了 java 原生代理和 CGLib 代理，并依据场景选择基于哪种代理机制对目标对象进行增强。由前面对于 Spring IoC 实现的分析可以了解到，Spring 容器在完成对 bean 对象的创建之后会执行初始化操作，而 AOP 初始化的过程就发生在 bean 的后置初始化阶段，整体流程可以概括为：\n\n1. 从容器中获取所有的切面定义；\n2. 筛选适用于当前 bean 的增强器集合；\n3. 依据增强器集合基于动态代理机制生成相应的增强代理对象。\n\n当我们在调用一个被增强的方法时，相应的拦截器会依据连接点的方位在适当的位置触发对应的增强定义，从而最终实现 AOP 中定义的各类增强语义。\n","tags":["Spring"],"categories":["spring"]},{"title":"Spring IoC 源码解析：循环依赖的检测与处理","url":"/2017/07/08/spring/spring-ioc-circular-reference/","content":"\nSpring 为开发人员提供了极其灵活和强大的配置使用方式，在方便开发的同时也为容器的初始化过程带来了不确定性。本文所要介绍的循环依赖就是其中之一，尤其在一些大型项目中，循环依赖的配置往往是我们不经意而为之的，幸好 Spring 能够在初始化的过程中检测到对象之间的循环依赖，并能够在一定程度上予以处理。<!-- more -->\n\n### 什么是循环依赖\n\n以最简单的循环依赖举例，假设我们定义了两个类 A 和 B，如下：\n\n```java\n@Component\npublic class A {\n\n    private B b;\n\n    public A(@Autowired B b) {\n        this.b = b;\n    }\n\n    // ... getter & setter\n}\n\n@Component\npublic class B {\n\n    private A a;\n\n    public B(@Autowired A a) {\n        this.a = a;\n    }\n\n    // ... getter & setter\n}\n```\n\n上述示例中 A 对象引用了 B 对象，B 对象反过来又引用了 A 对象，此时如果我们基于 Spring 管理对象 A 和 B 之间的依赖关系，就会存在循环依赖的问题。启动容器会看到抛出的异常中包含如下字样：\n\n> Requested bean is currently in creation: Is there an unresolvable circular reference?\n\n当然，上述示例只是一个演示，实际开发中我们不会犯这么低级的配置错误，但是如果项目规模足够大，经过多层引用之后难免出现循环依赖，这往往是我们不经意而为之的。\n\n### 循环依赖的检测与处理\n\n那么 Spring 如何检测和处理循环依赖呢？我们先给出结论：\n\n> __Spring 仅能够处理 singleton 对象之间基于 setter 注入方式造成的循环依赖，除此之外全部抛出 BeanCurrentlyInCreationException 异常。__\n\n也就是说如果按照如下配置，Spring 是能够正常完成初始化的：\n\n```xml\n<!--单例：setter注入-->\n<bean id=\"a\" class=\"org.zhenchao.spring.ioc.A\">\n    <property name=\"b\" ref=\"b\"/>\n</bean>\n<bean id=\"b\" class=\"org.zhenchao.spring.ioc.B\">\n    <property name=\"a\" ref=\"a\"/>\n</bean>\n```\n\n当然， __如果是属性注入方式同样能够被解决，该注入方式本质上还是 setter 注入__ ，只是不再被 Spring 推荐使用。然而，如果是采用构造方法注入，或者造成循环依赖的对象不是 singleton 类型，则容器只能以抛出 BeanCurrentlyInCreationException 异常而结束。\n\n那么 Spring 又是怎么检测出循环依赖配置的呢？由前面文章对于容器初始化过程的分析，我们知道实例化一个 bean 的过程主要分为三步：\n\n1. 创建 bean 实例，主要由 `AbstractAutowireCapableBeanFactory#createBeanInstance` 方法完成；\n2. 填充 bean 属性，依赖注入的过程发生于此，由 `AbstractAutowireCapableBeanFactory#populateBean` 方法完成；\n3. 初始化 bean 实例，主要是调用初始化方法，由 `AbstractAutowireCapableBeanFactory#initializeBean` 方法完成。\n\n循环依赖主要发生在上述步骤中的第 1 和第 2 步。设想，如果我们在创建 A 对象的时候发现需要填充类型为 B 的属性，这个时候就需要转而去创建 B 对象，但是在创建 B 对象的时候发现又需要填充类型为 A 的属性，这个时候 A 对象和 B 对象都处于创建过程中，造成了死循环。如果我们把这两步拆开又会怎么样呢？即先把 A 对象和 B 对象先创建好，对应的属性先用 null 填充，然后再使用相应类型的对象填充属性，这样就破解了环路，这也是 Spring 解决基于 setter 注入方式导致的循环依赖的基本思路。\n\n下面具体分析 Spring 是如何实现这一思路的。首先列出整个过程中需要用到的几个用于记录状态的集合类型属性：\n\n- `DefaultSingletonBeanRegistry#singletonFactories`：Map 类型，用于记录 beanName 和创建 bean 对象的工厂之间的映射关系。\n- `DefaultSingletonBeanRegistry#earlySingletonObjects`：Map 类型，用于记录 beanName 和原始 bean 实例之间的映射关系，此时的 bean 对象刚刚被创建，还没有注入属性。\n- `DefaultSingletonBeanRegistry#singletonObjects`：Map 类型，用于记录 beanName 和最终 bean 实例之间的映射关系。\n\n这三个属性构成了一些人口中描述的三级缓存。其中 singletonObjects 和 earlySingletonObjects 两个属性虽然都是记录 beanName 与 bean 实例之间的映射关系，但是区别在于后者中记录的 bean 实例还没有填充属性值，并且这两个集合中存放的内容是互斥的。\n\nSpring 在完成创建 bean 实例之后，且在填充 bean 属性之前，即上述步骤中的 1 和 2 之间，会执行如下这样一段代码：\n\n```java\nboolean earlySingletonExposure = (mbd.isSingleton() // 单例\n        && this.allowCircularReferences // 允许自动解决循环依赖\n        && this.isSingletonCurrentlyInCreation(beanName)); // 当前 bean 正在创建中\nif (earlySingletonExposure) {\n    // 为避免循环依赖，在完成 bean 实例化之前，将对应的 ObjectFactory 注册到容器中\n    this.addSingletonFactory(beanName,\n            // 获取 bean 的提前引用\n            () -> this.getEarlyBeanReference(beanName, mbd, bean));\n}\n\nprotected void addSingletonFactory(String beanName, ObjectFactory<?> singletonFactory) {\n    Assert.notNull(singletonFactory, \"Singleton factory must not be null\");\n    synchronized (this.singletonObjects) {\n        if (!this.singletonObjects.containsKey(beanName)) {\n            this.singletonFactories.put(beanName, singletonFactory);\n            this.earlySingletonObjects.remove(beanName);\n            this.registeredSingletons.add(beanName);\n        }\n    }\n}\n```\n\n上述实现的主要逻辑就是判断是否需要提前曝光正在实例化的 bean 对象，如果需要则将创建 bean 实例的 ObjectFactory 对象记录到 singletonFactories 属性中。\n\n如果此时正好有另外一个操作试图获取正在创建中的 bean 实例，则会进入 `DefaultSingletonBeanRegistry#getSingleton(java.lang.String)` 方法。该方法将获取我们之前缓存的 ObjectFactory 对象，并调用 `ObjectFactory#getObject` 方法获取到之前创建的目标 bean 实例，并记录到 earlySingletonObjects 中，同时移除 singletonFactories 中缓存的 ObjectFactory 对象。而实例化过程也会很快调用 `DefaultSingletonBeanRegistry#addSingleton` 方法，将最终的 bean 实例记录到 singletonObjects 属性中，并移除所有的临时记录。\n\n那么为什么用构造方法注入就会抛异常，而 setter 注入则不会呢？这是因为在创建 singleton 对象之前，Spring 会调用 `DefaultSingletonBeanRegistry#beforeSingletonCreation` 方法检查指定 bean 是否正在被创建，实现如下：\n\n```java\nprotected void beforeSingletonCreation(String beanName) {\n    if (!this.inCreationCheckExclusions.contains(beanName) && !this.singletonsCurrentlyInCreation.add(beanName)) {\n        throw new BeanCurrentlyInCreationException(beanName);\n    }\n}\n```\n\n上述方法在每次创建 singleton 对象之前都会被调用，对于创建同一个 bean 实例的第二次之后的调用就会触发该方法抛出异常。如果是构造方法注入，因为创建目标 bean 对象需要调用包含依赖对象类型参数的构造方法，而循环依赖势必导致当前构造方法的循环调用，从而触发上述方法抛出异常。然而，对于 setter 注入来说就不存在这样的问题，因为 Spring 对于 bean 实例的构造是分两步走的：第一步创建目标 bean 对象；第二步执行属性填充，将相应的依赖注入到该对象中。这样即使有循环依赖也不会阻碍对象的创建，因为此时调用的是无参构造方法（即使有参数，参数中也不包含循环依赖的对象），所以基于 setter 方式注入的 singleton 对象导致的循环依赖，容器的初始化机制能够很好的予以处理。\n\n那么非 singleton 的怎么就不行了呢？我们先来看一下相关实现，Spring 定义了一个 `AbstractBeanFactory#prototypesCurrentlyInCreation` 集合变量记录当前线程内正在创建 bean 实例的 beanName，并且在创建一个非 singleton bean 之前，容器会调用 `AbstractBeanFactory#isPrototypeCurrentlyInCreation` 方法进行校验，实现如下：\n\n```java\nif (this.isPrototypeCurrentlyInCreation(beanName)) {\n    /*\n     * 只有在单例模式下才会尝试解决循环依赖问题，\n     * 对于原型模式，如果存在循环依赖，直接抛出异常\n     */\n    throw new BeanCurrentlyInCreationException(beanName);\n}\n\nprotected boolean isPrototypeCurrentlyInCreation(String beanName) {\n    Object curVal = this.prototypesCurrentlyInCreation.get();\n    return (curVal != null && (curVal.equals(beanName) || (curVal instanceof Set && ((Set<?>) curVal).contains(beanName))));\n}\n```\n\n如果存在循环依赖则抛出 BeanCurrentlyInCreationException 异常。\n\nSpring 为什么需要这样设计呢？一些解释是 Spring 没有缓存创建非 singleton bean 实例的中间状态，我个人觉得这只考虑到了一个方面。对于非 singleton bean 而言，完全可以复用 singleton 那一套予以实现，保证好线程安全即可。之所以 Spring 不这么做，个人认为还出于性能方面的考量。非 singleton bean 对象的特点是每次获取都会返回一个新的对象，并且这个过程可能是频繁调用的，这样就会降低框架的性能，同时增加内存占用，而很多时候循环依赖是因为开发者的错误配置导致的，这个时候还不如直接抛出异常，快速失败为好。\n\n### 总结\n\n本文我们分析了 Spring 如何检测和处理循环依赖。Spring 通过拆分对象创建和属性注入为两个独立过程，巧妙的破解了对于 singleton 对象执行 setter 注入场景下的依赖环路，从而在一定程度上解决了循环依赖问题。尽管如此，还是建议大家在日常开发中在编码层面避免循环依赖问题，让实现更加优雅。\n","tags":["Spring"],"categories":["spring"]},{"title":"Spring IoC 源码解析：高级容器的初始化过程","url":"/2017/06/03/spring/spring-ioc-application-context/","content":"\n前面的几篇文章我们一直围绕着 BeanFactory 分析容器的初始化和依赖注入过程，本篇我们将从 ApplicationContext 触发探究容器的高级形式。ApplicationContext 相对于 BeanFactory 扩展了许多实用功能，方便开发者的使用。二者的结构设计我们在前面的文章中已经介绍过，本篇将详细分析基于 ApplicationContext 的容器初始化和注入过程。<!-- more -->\n\n关于 ApplicationContext 的使用方式，广大开发者应该是信手拈来，这里还是简单的举例一下：\n\n```java\nApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:spring-core.xml\");\nMyBean myBean = (MyBean) context.getBean(\"myBean\");\n```\n\n相对于 BeanFactory 来说，ApplicationContext 在使用方式上没有太大的区别，也是分成两步走：第一步加载配置；第二步执行 bean 实例的创建和初始化过程。其中，第二步与之前我们分析 BeanFactory 时的 `BeanFactory#getBean` 方法复用的是一套逻辑。\n\n由前面文章介绍的继承关系我们知道，ApplicationContext 不是一个新的策略实现类，而是从 BeanFactory 扩展而来，并且将主要的精力都放在了对配置文件加载和解析层面。这样的实现也是很容易理解的，毕竟第一步是和开发者息息相关的，是开发者能够直接配置的东西，这一块的优化能够直观反映在框架的使用上，而第二步主要是框架内部的运作流程。所以接下来我们主要探究第一步的实现过程，而第二步则可以参考上一篇专门分析 bean 实例创建与初始化过程的文章。\n\n第一步的逻辑暴露给开发者的接口位于 ClassPathXmlApplicationContext 类的构造方法中，我们通过 `new ClassPathXmlApplicationContext(\"classpath:spring-core.xml\")` 触发高级容器加载和解析配置的逻辑，实现如下：\n\n```java\npublic ClassPathXmlApplicationContext(String configLocation) throws BeansException {\n    this(new String[] {configLocation}, true, null);\n}\n\npublic ClassPathXmlApplicationContext(\n        String[] configLocations, boolean refresh, @Nullable ApplicationContext parent)\n        throws BeansException {\n    super(parent);\n    // 支持多个配置文件以数组形式传入\n    this.setConfigLocations(configLocations);\n    if (refresh) {\n        // 加载配置，并初始化 IoC 容器\n        refresh();\n    }\n}\n```\n\nSpring 定义了 `AbstractRefreshableConfigApplicationContext#configLocation` 数组用来记录传递的配置文件路径。因为允许传递多个配置文件，考虑配置文件的组织形式不一定是容器能够理解的方式，所以还需要执行一些解析的工作：\n\n```java\npublic void setConfigLocations(@Nullable String... locations) {\n    if (locations != null) {\n        Assert.noNullElements(locations, \"Config locations must not be null\");\n        this.configLocations = new String[locations.length];\n        // 遍历解析指定的路径，将占位符替换成具体的值\n        for (int i = 0; i < locations.length; i++) {\n            this.configLocations[i] = resolvePath(locations[i]).trim();\n        }\n    } else {\n        this.configLocations = null;\n    }\n}\n```\n\n我们传递的配置文件路径可能存在一些占位符，所以容器需要对这些占位符进行解析，使用真实指代的值进行替换。\n\n接下来，Spring 会调用 `AbstractApplicationContext#refresh` 方法初始化 IoC 容器，该方法是 ApplicationContext 的核心，概括了高级容器的整体初始化过程，实现如下：\n\n```java\npublic void refresh() throws BeansException, IllegalStateException {\n    synchronized (this.startupShutdownMonitor) {\n        // 1. 初始化上下文环境\n        this.prepareRefresh();\n\n        // 2. 初始化 BeanFactory，加载并解析配置\n        ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory();\n\n        // 3. 对 BeanFactory 进行功能增强\n        this.prepareBeanFactory(beanFactory);\n        try {\n            // 4. 模板方法，后置处理 BeanFactory 实例\n            this.postProcessBeanFactory(beanFactory);\n\n            // 5. 应用 BeanFactoryPostProcessor 处理器对 BeanFactory 实例进行后置处理\n            this.invokeBeanFactoryPostProcessors(beanFactory);\n\n            // 6. 注册 BeanPostProcessor 处理器，这里仅仅是注册，调用发生在 getBean 的时候\n            this.registerBeanPostProcessors(beanFactory);\n\n            // 7. 初始化国际化资源\n            this.initMessageSource();\n\n            // 8. 注册事件通知广播器\n            this.initApplicationEventMulticaster();\n\n            // 9. 模板方法\n            this.onRefresh();\n\n            // 10. 注册事件监听器\n            this.registerListeners();\n\n            // 11. 实例化非延迟加载的 singleton 类对象\n            this.finishBeanFactoryInitialization(beanFactory);\n\n            // 12. 完成 refresh 过程，发布事件通知\n            this.finishRefresh();\n        } catch (BeansException ex) {\n            if (logger.isWarnEnabled()) {\n                logger.warn(\"Exception encountered during context initialization - cancelling refresh attempt: \" + ex);\n            }\n\n            // Destroy already created singletons to avoid dangling resources.\n            this.destroyBeans();\n\n            // Reset 'active' flag.\n            this.cancelRefresh(ex);\n\n            // Propagate exception to caller.\n            throw ex;\n        } finally {\n            // Reset common introspection caches in Spring's core, since we\n            // might not ever need metadata for singleton beans anymore...\n            this.resetCommonCaches();\n        }\n    }\n}\n```\n\n高级容器的初始化整体流程可以概括为：\n\n1. 初始化上下文环境；\n2. 初始化 BeanFactory，加载并解析配置；\n3. 增强 BeanFactory，附加标准上下文特征；\n4. 后置处理 BeanFactory，这一过程交由子类实现，以提升容器的可扩展性；\n5. 后置处理 BeanFactory，应用 BeanFactoryPostProcessor 处理器；\n6. 注册 BeanPostProcessor 处理器；\n7. 初始化国际化资源；\n8. 注册事件通知广播器；\n9. 调用模板方法 `AbstractApplicationContext#onRefresh`，可以通过覆盖实现该方法扩展 refresh 流程；\n10. 向事件通知广播器中注册事件监听器；\n11. 实例化非延迟加载的 singleton 类对象；\n12. 完成刷新过程，发布事件通知。\n\n其中步骤 1 和 2 已经完成了简单容器中解析配置文件、以 BeanDefinition 对象承载配置，并注册到容器的全部过程，从第 3 步开始进入属于高级容器的扩展实现。下面对上述步骤中的关键点展开分析。\n\n### 初始化上下文环境\n\n初始化上下文作为整个流程的第一步，包含了重置上下文状态、解析属性占位符，以及验证必要属性是否缺失等工作，由 `AbstractApplicationContext#prepareRefresh` 方法实现：\n\n```java\nprotected void prepareRefresh() {\n    // Switch to active.\n    this.startupDate = System.currentTimeMillis();\n    this.closed.set(false);\n    // 标记当前上下文被激活\n    this.active.set(true);\n\n    // 模板方法，执行一些初始化操作，例如解析属性占位符\n    this.initPropertySources();\n\n    // Validate that all properties marked as required are resolvable: see ConfigurablePropertyResolver#setRequiredProperties\n    // 验证所有必要的属性是否都有配置\n    this.getEnvironment().validateRequiredProperties();\n\n    // Store pre-refresh ApplicationListeners...\n    if (this.earlyApplicationListeners == null) {\n        this.earlyApplicationListeners = new LinkedHashSet<>(this.applicationListeners);\n    } else {\n        // Reset local application listeners to pre-refresh state.\n        this.applicationListeners.clear();\n        this.applicationListeners.addAll(this.earlyApplicationListeners);\n    }\n\n    // 记录需要提前感知的应用事件 ApplicationEvent，一旦 multicaster 可用则会发布这些事件\n    this.earlyApplicationEvents = new LinkedHashSet<>();\n}\n```\n\n对于一些必要的属性，如果缺失会影响系统的正常执行逻辑，对于这类属性可以调用 `ConfigurablePropertyResolver#setRequiredProperties` 方法将其设置为 required，这样在初始化上下文时就会校验其是否存在，如果不存在则会提前抛出异常。\n\n### 创建并初始化 BeanFactory\n\nApplicationContext 是基于 BeanFactory 的扩展实现，复用了 BeanFactory 加载并解析配置文件的过程。所以在这一步，ApplicationContext 就已经完成了加载静态配置，并解析成为 BeanDefinition 对象注册到 IoC 容器的过程。这里的 BeanFactory 具体实现是 DefaultListableBeanFactory 类，前面曾强调过该类在 BeanFactory 的继承体系中占有着相当重要的地位，是 IoC 容器完整功能的一个基本实现。\n\n基于 DefaultListableBeanFactory 创建并初始化 BeanFactory 的实现位于 `AbstractApplicationContext#obtainFreshBeanFactory` 方法中，实现如下：\n\n```java\nprotected ConfigurableListableBeanFactory obtainFreshBeanFactory() {\n    // 1. 初始化 BeanFactory，加载并解析配置，在这一步已经得到了 BeanDefinition 对象\n    this.refreshBeanFactory();\n    // 2. 返回 BeanFactory 对象\n    return this.getBeanFactory();\n}\n\nprotected final void refreshBeanFactory() throws BeansException {\n    // 之前已经被 refresh 过，还没有被关闭，先执行关闭操作\n    if (this.hasBeanFactory()) {\n        // 销毁所有的 bean 实例\n        this.destroyBeans();\n        // 关闭 BeanFactory\n        this.closeBeanFactory();\n    }\n    try {\n        // 创建 BeanFactory 对象，基于 DefaultListableBeanFactory 实现类\n        DefaultListableBeanFactory beanFactory = this.createBeanFactory();\n        // 指定序列化 ID，必要的话可以反序列化得到 BeanFactory 对象\n        beanFactory.setSerializationId(this.getId());\n        /*\n         * 1. 是否允许配置同名称的 bean（后面的配置会覆盖前面的配置）\n         * 2. 是否允许循环依赖\n         */\n        this.customizeBeanFactory(beanFactory);\n        // 加载并解析配置，由静态配置转为 BeanDefinition 对象\n        this.loadBeanDefinitions(beanFactory);\n        synchronized (this.beanFactoryMonitor) {\n            this.beanFactory = beanFactory;\n        }\n    } catch (IOException ex) {\n        throw new ApplicationContextException(\"I/O error parsing bean definition source for \" + this.getDisplayName(), ex);\n    }\n}\n```\n\n上述方法首先会判断是否已经有创建的 BeanFactory 实例存在，如果存在则说明上下文之前已经被 refresh 过，且没有正常关闭对应的 BeanFactory，所以再次被 refresh 之前需要执行关闭操作。接着，调用 `AbstractXmlApplicationContext#loadBeanDefinitions` 方法加载并解析配置。\n\n如果看过本系列之前的文章，你一定会理解本方法的作用，并体会到其过程的复杂程度。该方法包含了获取配置文件 Document 对象、执行默认标签和自定义标签的解析，并最终将配置封装到 BeanDefinition 对象中返回的逻辑。经过这一系列步骤，XML 中静态的配置就会转变成内存中的数据结构 BeanDefinition 对象注册到 IoC 容器中。\n\n### 为 BeanFactory 附加标准上下文特征\n\n上面两个步骤已经完成了简单容器中加载并解析配置的功能，以此为分界线将开始对简单容器进行功能增强处理。增强的第一步就是调用 `AbstractApplicationContext#prepareBeanFactory` 方法为 BeanFactory 设置一些上下文所应该具备的标准特性，实现如下：\n\n```java\nprotected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) {\n    // 设置类加载器，用于加载 bean 对象\n    beanFactory.setBeanClassLoader(this.getClassLoader());\n    // 设置表达式解析器，以提供 EL 表达式风格的属性调用\n    beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader()));\n    // 添加默认属性编辑器\n    beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, this.getEnvironment()));\n\n    /*\n     * 添加后置处理器 ApplicationContextAwareProcessor, 如果实现了如下相应的 Aware 接口，则注入对应的资源：\n     * 1. EnvironmentAware\n     * 2. EmbeddedValueResolverAware\n     * 3. ResourceLoaderAware\n     * 4. ApplicationEventPublisherAware\n     * 5. MessageSourceAware\n     * 6. ApplicationContextAware\n     */\n    beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this));\n    // 忽略以下接口的自动装配，即上面已经处理的 Aware 接口\n    beanFactory.ignoreDependencyInterface(EnvironmentAware.class);\n    beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class);\n    beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class);\n    beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class);\n    beanFactory.ignoreDependencyInterface(MessageSourceAware.class);\n    beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);\n\n    // BeanFactory interface not registered as resolvable type in a plain factory.\n    // MessageSource registered (and found for autowiring) as a bean.\n    // 注册几个自动装配的规则\n    beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);\n    beanFactory.registerResolvableDependency(ResourceLoader.class, this);\n    beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this);\n    beanFactory.registerResolvableDependency(ApplicationContext.class, this);\n\n    // 注册后置处理器 ApplicationListenerDetector，用于探测 ApplicationListener 类型接口\n    beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this));\n\n    // 增加对 AspectJ 的支持\n    if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) {\n        beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));\n        // Set a temporary ClassLoader for type matching.\n        beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));\n    }\n\n    // 注册默认系统环境相关的 bean 实例\n    if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) {\n        // Environment\n        beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, this.getEnvironment());\n    }\n    if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) {\n        // System Properties\n        beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, this.getEnvironment().getSystemProperties());\n    }\n    if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) {\n        // System Environment\n        beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, this.getEnvironment().getSystemEnvironment());\n    }\n}\n```\n\n上述实现为 BeanFactory 增加了如下上下文特性：\n\n1. 增加了对 Spring SpEL 表达式的支持。\n2. 添加属性编辑器，以实现对某些类型属性的统一处理。\n3. 自动装配 Aware 类，注入相应的资源。\n4. 自动探测 ApplicationListener 监听器类。\n5. 增加了对 AspectJ 的支持。\n6. 注册系统环境变量相关的 bean 实例，用于获取系统环境变量。\n\nSpring Expression Language，即 SpEL 表达式是在 3.0 版本引入的新特性，允许我们在配置时候以类似 EL 表达式的方式引用上下文中的变量，未接触过的同学可以自己去体验一下。\n\n- __属性编辑器__\n\n执行属性注入时，如果希望对某一类型的属性执行一些处理，可以通过自定义属性编辑器 PropertyEditor 实现。典型的应用场景就是对时间类型属性的转换，假设某个 bean 实例存在 LocalDate 类型的属性，这个时候我们直接以字符串配置进行注入是会出错的，解决的方法就是通过自定义属性编辑器实现类型的转换，如下：\n\n```java\npublic class LocalDatePropertyEditor extends PropertyEditorSupport implements InitializingBean {\n\n    private String format = \"yyyy-MM-dd\";\n    private DateTimeFormatter formatter;\n\n    @Override\n    public void afterPropertiesSet() throws Exception {\n        formatter = DateTimeFormatter.ofPattern(format);\n    }\n\n    @Override\n    public void setAsText(String text) throws IllegalArgumentException {\n        if (StringUtils.hasText(text)) {\n            this.setValue(LocalDate.parse(text, formatter));\n        }\n        throw new IllegalArgumentException(\"illegal property: \" + text);\n    }\n\n    public void setFormat(String format) {\n        this.format = format;\n        this.formatter = DateTimeFormatter.ofPattern(format);\n    }\n}\n```\n\n```xml\n<!-- 注册自定义属性解析器 -->\n<bean class=\"org.springframework.beans.factory.config.CustomEditorConfigurer\">\n    <property name=\"customEditors\">\n        <map>\n            <entry key=\"java.time.LocalDate\">\n                <bean class=\"org.zhenchao.spring.ioc.LocalDatePropertyEditor\">\n                    <property name=\"format\" value=\"yyyy-MM-dd\"/>\n                </bean>\n            </entry>\n        </map>\n    </property>\n</bean>\n```\n\n通过自定义属性编辑器 LocalDatePropertyEditor，基于时间格式化工具对指定格式的字符串日期进行转换和注入。上述转换只能在以 ApplicationContext 方式加载 bean 实例的前提下才生效，如果使用的是 BeanFactory 则还是会抛出异常，毕竟这属于高级容器中增强的功能。\n\n- __Aware 特性处理__\n\n当定义的 bean 实现了 Aware 接口时，这些 bean 可以比一般的 bean 多拿到一些资源。ApplicationContext 对于 BeanFactory 的扩展增加了对一些 Aware 类自动装配支持。ApplicationContextAwareProcessor 实现了 BeanPostProcessor 接口，并主要覆盖实现了 `ApplicationContextAwareProcessor#postProcessBeforeInitialization` 方法：\n\n```java\npublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {\n    // 仅处理实现了指定接口的 bean 实例\n    if (!(bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware ||\n            bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware ||\n            bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) {\n        return bean;\n    }\n\n    /* 调用 ApplicationContextAwareProcessor#invokeAwareInterfaces 方法为 bean 实例附加一些资源 */\n\n    AccessControlContext acc = null;\n\n    if (System.getSecurityManager() != null) {\n        acc = this.applicationContext.getBeanFactory().getAccessControlContext();\n    }\n\n    if (acc != null) {\n        AccessController.doPrivileged((PrivilegedAction<Object>) () -> {\n            this.invokeAwareInterfaces(bean);\n            return null;\n        }, acc);\n    } else {\n        this.invokeAwareInterfaces(bean);\n    }\n\n    return bean;\n}\n\nprivate void invokeAwareInterfaces(Object bean) {\n    // EnvironmentAware\n    if (bean instanceof EnvironmentAware) {\n        ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment());\n    }\n    // EmbeddedValueResolverAware\n    if (bean instanceof EmbeddedValueResolverAware) {\n        ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver);\n    }\n    // ResourceLoaderAware\n    if (bean instanceof ResourceLoaderAware) {\n        ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext);\n    }\n    // ApplicationEventPublisherAware\n    if (bean instanceof ApplicationEventPublisherAware) {\n        ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext);\n    }\n    // MessageSourceAware\n    if (bean instanceof MessageSourceAware) {\n        ((MessageSourceAware) bean).setMessageSource(this.applicationContext);\n    }\n    // ApplicationContextAware\n    if (bean instanceof ApplicationContextAware) {\n        ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext);\n    }\n}\n```\n\n对于实现了指定 Aware 接口的 bean 类，上述方法会将相应的资源给到该 bean 实例。以 ApplicationContextAware 接口为例，实现了该接口的 bean 都持有 ApplicationContext 实例，而上述方法也正是通过调用 bean 的 setter 方法将 ApplicationContext 实例注入到 bean 实例中。\n\n- __自动探测 ApplicationListener 监听器__\n\n自 4.3.4 版本起，Spring 增加了对实现了 ApplicationListener 接口监听器的探测。这一机制由 ApplicationListenerDetector 类实现，核心逻辑为 `` 方法中：。ApplicationListenerDetector 实现了 MergedBeanDefinitionPostProcessor 和 DestructionAwareBeanPostProcessor 后置处理接口，并相应实现了这些后置处理器定义的模板方法，其中核心的方法 postProcessAfterInitialization 逻辑如下：\n\n```java\npublic Object postProcessAfterInitialization(Object bean, String beanName) {\n    // 仅处理实现了 ApplicationListener 接口的 bean 实例\n    if (bean instanceof ApplicationListener) {\n        // potentially not detected as a listener by getBeanNamesForType retrieval\n        Boolean flag = this.singletonNames.get(beanName);\n        // singleton 类型\n        if (Boolean.TRUE.equals(flag)) {\n            // singleton bean (top-level or inner): register on the fly\n            this.applicationContext.addApplicationListener((ApplicationListener<?>) bean);\n        }\n        // 非 singleton 类型\n        else if (Boolean.FALSE.equals(flag)) {\n            if (logger.isWarnEnabled() && !this.applicationContext.containsBean(beanName)) {\n                // inner bean with other scope - can't reliably process events\n                logger.warn(\"Inner bean '\" + beanName + \"' implements ApplicationListener interface \" +\n                        \"but is not reachable for event multicasting by its containing ApplicationContext \" +\n                        \"because it does not have singleton scope. Only top-level listener beans are allowed to be of non-singleton scope.\");\n            }\n            this.singletonNames.remove(beanName);\n        }\n    }\n    return bean;\n}\n```\n\n该方法针对实现了 ApplicationListener 接口的单例对象，统一注册到监听器集合中监听事件。方法中的 `ApplicationListenerDetector#singletonNames` 变量则是在 `ApplicationListenerDetector#postProcessMergedBeanDefinition` 方法中完成构建：\n\n```java\npublic void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class<?> beanType, String beanName) {\n    if (ApplicationListener.class.isAssignableFrom(beanType)) {\n        this.singletonNames.put(beanName, beanDefinition.isSingleton());\n    }\n}\n```\n\n因此，我们可以知道该变量中记录了 beanName 与实现了 ApplicationListener 接口的 singleton 实例之间的映射关系。\n\n### 应用 BeanFactoryPostProcessor 处理器\n\nBeanFactoryPostProcessor 处理器用于对 BeanFactory 实例进行后置处理，这和 BeanPostProcessor 以 bean 实例作为处理对象有着本质的区别。所以，执行到这里就已经开始应用这些已注册的 BeanFactoryPostProcessor 处理器对前面已经准备好的 BeanFactory 对象进行处理，但是需要清楚的一点是此时还没有开始创建 bean 实例。应用 BeanFactoryPostProcessor 处理器的过程位于 `AbstractApplicationContext#invokeBeanFactoryPostProcessors` 方法中：\n\n```java\nprotected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) {\n    // 应用 BeanFactoryPostProcessor 后置处理器\n    PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, this.getBeanFactoryPostProcessors());\n\n    // AOP 支持：LoadTimeWeaver\n    // Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime\n    // (e.g. through an @Bean method registered by ConfigurationClassPostProcessor)\n    if (beanFactory.getTempClassLoader() == null && beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) {\n        beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));\n        beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));\n    }\n}\n```\n\n注意，这里调用 `AbstractApplicationContext#getBeanFactoryPostProcessors` 方法获取的 BeanFactoryPostProcessor 全部是通过编码注册而非配置的。通过调用如下方法可以以编码的方式注册 BeanFactoryPostProcessor 处理器：\n\n```java\npublic void addBeanFactoryPostProcessor(BeanFactoryPostProcessor postProcessor) {\n    Assert.notNull(postProcessor, \"BeanFactoryPostProcessor must not be null\");\n    this.beanFactoryPostProcessors.add(postProcessor);\n}\n```\n\n笔者最开始看这段代码时，潜意识认为所有的 BeanFactoryPostProcessor 都是记录在 `AbstractApplicationContext#beanFactoryPostProcessors` 属性中的，如果以配置的方式使用过 BeanFactoryPostProcessor 的同学都知道该处理器的配置仅仅需要在配置文件中配置一个 `<bean />` 标签，而不需要在其它任何地方去注册或引用这个 bean 实例。如下：\n\n```xml\n<bean id=\"myBeanFactoryPostProcessor\" class=\"org.zhenchao.processor.MyBeanFactoryPostProcessor\"/>\n```\n\n所以，我就去代码中寻找 Spring 是如何把上述配置给添加到 `AbstractApplicationContext#beanFactoryPostProcessors` 属性中的，即在哪里调用了 `AbstractApplicationContext#addBeanFactoryPostProcessor` 方法，结果当然是一无所获，因为出发点就是错误的。由下面的实现你将会看到这里传递的仅仅是通过编码注册的 BeanFactoryPostProcessor 处理器，而基于配置注册的 BeanFactoryPostProcessor 处理器则通过其它方式获取。\n\n相应的实现位于 `PostProcessorRegistrationDelegate#invokeBeanFactoryPostProcessors` 方法中，如下：\n\n```java\npublic static void invokeBeanFactoryPostProcessors(\n        ConfigurableListableBeanFactory beanFactory,\n        List<BeanFactoryPostProcessor> beanFactoryPostProcessors) // 保存了所有通过编码注册的 BeanFactoryPostProcessor 处理器\n{\n\n    Set<String> processedBeans = new HashSet<>();\n\n    // 1. 遍历处理注册的 BeanDefinitionRegistryPostProcessor 处理器，扩展自 BeanFactoryPostProcessor\n    if (beanFactory instanceof BeanDefinitionRegistry) {\n        BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;\n        // 记录注册的 BeanFactoryPostProcessor 类型处理器\n        List<BeanFactoryPostProcessor> regularPostProcessors = new ArrayList<>();\n        // 记录注册的 BeanDefinitionRegistryPostProcessor 类型处理器\n        List<BeanDefinitionRegistryPostProcessor> registryProcessors = new ArrayList<>();\n\n        /* 获取并处理通过编码注册的 BeanDefinitionRegistryPostProcessor 处理器 */\n\n        // 1.1 处理通过编码注册 BeanDefinitionRegistryPostProcessor 处理器\n        for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) {\n            if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) {\n                // 执行 BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry 方法\n                BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor;\n                registryProcessor.postProcessBeanDefinitionRegistry(registry);\n                registryProcessors.add(registryProcessor);\n            } else {\n                regularPostProcessors.add(postProcessor);\n            }\n        }\n\n        /* 获取并处理通过配置的 BeanDefinitionRegistryPostProcessor 处理器 */\n\n        // Do not initialize FactoryBeans here: We need to leave all regular beans\n        // uninitialized to let the bean factory post-processors apply to them!\n        // Separate between BeanDefinitionRegistryPostProcessors that implement PriorityOrdered, Ordered, and the rest.\n        List<BeanDefinitionRegistryPostProcessor> currentRegistryProcessors = new ArrayList<>();\n\n        // 1.2 处理实现了 PriorityOrdered 接口的 BeanDefinitionRegistryPostProcessor 处理器\n        String[] postProcessorNames =\n                beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);\n        for (String ppName : postProcessorNames) {\n            if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {\n                currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));\n                processedBeans.add(ppName);\n            }\n        }\n        // 按照优先级对处理器进行排序\n        sortPostProcessors(currentRegistryProcessors, beanFactory);\n        registryProcessors.addAll(currentRegistryProcessors);\n        // 执行 BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry 方法\n        invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);\n        currentRegistryProcessors.clear();\n\n        // 1.3 处理实现了 Ordered 接口的 BeanDefinitionRegistryPostProcessor 处理器\n        postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);\n        for (String ppName : postProcessorNames) {\n            if (!processedBeans.contains(ppName) && beanFactory.isTypeMatch(ppName, Ordered.class)) {\n                currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));\n                processedBeans.add(ppName);\n            }\n        }\n        // 按照指定的顺序对处理器进行排序\n        sortPostProcessors(currentRegistryProcessors, beanFactory);\n        registryProcessors.addAll(currentRegistryProcessors);\n        // 执行 BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry 方法\n        invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);\n        currentRegistryProcessors.clear();\n\n        // 1.4 处理其它的 BeanDefinitionRegistryPostProcessor 处理器\n        boolean reiterate = true;\n        while (reiterate) {\n            reiterate = false;\n            postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);\n            for (String ppName : postProcessorNames) {\n                if (!processedBeans.contains(ppName)) {\n                    currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));\n                    processedBeans.add(ppName);\n                    reiterate = true;\n                }\n            }\n            // 对处理器进行排序\n            sortPostProcessors(currentRegistryProcessors, beanFactory);\n            registryProcessors.addAll(currentRegistryProcessors);\n            // 执行 BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry 方法\n            invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);\n            currentRegistryProcessors.clear();\n        }\n\n        // 执行 BeanDefinitionRegistryPostProcessor#postProcessBeanFactory 方法\n        invokeBeanFactoryPostProcessors(registryProcessors, beanFactory);\n        // 执行 BeanFactoryPostProcessor#postProcessBeanFactory 方法\n        invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory);\n    } else {\n        // 执行 BeanFactoryPostProcessor#postProcessBeanFactory 方法\n        invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory);\n    }\n\n    // Do not initialize FactoryBeans here: We need to leave all regular beans\n    // uninitialized to let the bean factory post-processors apply to them!\n    String[] postProcessorNames =\n            beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false);\n\n    // 2. 遍历处理注册的 BeanFactoryPostProcessor 处理器，来自配置\n\n    // 记录实现了 PriorityOrdered 接口的 BeanFactoryPostProcessor\n    List<BeanFactoryPostProcessor> priorityOrderedPostProcessors = new ArrayList<>();\n    // 记录实现了 Ordered 接口的 BeanFactoryPostProcessor\n    List<String> orderedPostProcessorNames = new ArrayList<>();\n    // 记录剩余的 BeanFactoryPostProcessor\n    List<String> nonOrderedPostProcessorNames = new ArrayList<>();\n    for (String ppName : postProcessorNames) {\n        if (processedBeans.contains(ppName)) {\n            // skip - already processed in first phase above\n        } else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {\n            priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class));\n        } else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {\n            orderedPostProcessorNames.add(ppName);\n        } else {\n            nonOrderedPostProcessorNames.add(ppName);\n        }\n    }\n\n    // 2.1 处理实现了 PriorityOrdered 接口的 BeanDefinitionRegistryPostProcessor 处理器\n    sortPostProcessors(priorityOrderedPostProcessors, beanFactory);\n    invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory);\n\n    // 2.2 处理实现了 Ordered 接口的 BeanDefinitionRegistryPostProcessor 处理器\n    List<BeanFactoryPostProcessor> orderedPostProcessors = new ArrayList<>(orderedPostProcessorNames.size());\n    for (String postProcessorName : orderedPostProcessorNames) {\n        orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));\n    }\n    sortPostProcessors(orderedPostProcessors, beanFactory);\n    invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory);\n\n    // 2.3 处理剩余的 BeanDefinitionRegistryPostProcessor 处理器\n    List<BeanFactoryPostProcessor> nonOrderedPostProcessors = new ArrayList<>(nonOrderedPostProcessorNames.size());\n    for (String postProcessorName : nonOrderedPostProcessorNames) {\n        nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));\n    }\n    invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory);\n\n    // Clear cached merged bean definitions since the post-processors might have\n    // modified the original metadata, e.g. replacing placeholders in values...\n    beanFactory.clearMetadataCache(); // 执行一些清理工作\n}\n```\n\n可以看到针对编码注册和以配置方式注册的 BeanFactoryPostProcessor 处理器实例，Spring 的获取方式是不一样的。前者都是注册到之前提到的 `AbstractApplicationContext#beanFactoryPostProcessors` 属性中，而后者都是通过 `BeanFactory#getBean` 方法获取到，所以是由 IoC 容器管理的。\n\n上述方法的执行流程可以分为处理 BeanDefinitionRegistryPostProcessor 和处理 BeanFactoryPostProcessor 两部分。BeanDefinitionRegistryPostProcessor 扩展自 BeanFactoryPostProcessor，继承关系如下：\n\n```java\npublic interface BeanFactoryPostProcessor {\n    void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;\n}\n\npublic interface BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor {\n    void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException;\n}\n```\n\n整个方法的前半部分都是在应用 `BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry` 方法对实现了 BeanDefinitionRegistry 接口的 BeanFactory 实例进行后置处理，而后半部分则是在应用 `BeanFactoryPostProcessor#postProcessBeanFactory` 方法对所有类型的 BeanFactory 实例进行后置处理。考虑配置 BeanFactoryPostProcessor 顺序的不确定性，Spring 支持对其设置优先级。由实现也可以看出，Spring 会依次应用 PriorityOrdered、Ordered，以及剩余类型的处理器，并针对各类型按照比较器进行排序处理。\n\n### 注册 BeanPostProcessor 处理器\n\n不同于上一步介绍的对 BeanFactoryPostProcessor 的处理过程，对于 BeanPostProcessor 而言，这一步仅仅是注册而非应用。因为 BeanPostProcessor 处理器作用于 bean 实例之上，而当前还没有开始创建 bean 实例。之前讲解 `BeanFactory#getBean` 过程的文章中我们已经分析过，对于 BeanPostProcessor 的应用是发生在 bean 实例的创建和初始化过程中，具体来说是围绕 bean 初始化过程的前后：\n\n```java\npublic interface BeanPostProcessor {\n\n    default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {\n        return bean;\n    }\n\n    default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {\n        return bean;\n    }\n\n}\n```\n\n注册 BeanPostProcessor 处理器的过程本质上是将配置的 BeanPostProcessor 实例记录到 `AbstractBeanFactory#beanPostProcessors` 属性中的过程。在简单容器中需要通过调用 `AbstractBeanFactory#addBeanPostProcessor` 方法手动注册我们实现的 BeanPostProcessor 处理器，而在高级容器中则支持自动扫描注册。相应的实现位于 `AbstractApplicationContext#registerBeanPostProcessors` 方法中，如下：\n\n```java\nprotected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) {\n    PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);\n}\n\n// org.springframework.context.support.PostProcessorRegistrationDelegate#registerBeanPostProcessors\npublic static void registerBeanPostProcessors(\n        ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) {\n\n    // 获取已加载 BeanPostProcessor 类型的 beanName 集合\n    String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);\n\n    // Register BeanPostProcessorChecker that logs an info message when\n    // a bean is created during BeanPostProcessor instantiation, i.e. when\n    // a bean is not eligible for getting processed by all BeanPostProcessors.\n    int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length;\n    // 注册一个 BeanPostProcessorChecker，用于在还没有注册后置处理器就开始实例化 bean 的情况下打印日志\n    beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount));\n\n    // 记录实现了 PriorityOrdered 接口的 BeanPostProcessor 处理器\n    List<BeanPostProcessor> priorityOrderedPostProcessors = new ArrayList<>();\n    // 存放 MergedBeanDefinitionPostProcessor 处理器\n    List<BeanPostProcessor> internalPostProcessors = new ArrayList<>();\n    // 记录实现了 Ordered 接口的 BeanPostProcessor 处理器\n    List<String> orderedPostProcessorNames = new ArrayList<>();\n    // 记录其它的 BeanPostProcessor 处理器\n    List<String> nonOrderedPostProcessorNames = new ArrayList<>();\n    // 遍历对加载到 BeanPostProcessor 进行分类\n    for (String ppName : postProcessorNames) {\n        if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {\n            BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);\n            priorityOrderedPostProcessors.add(pp);\n            if (pp instanceof MergedBeanDefinitionPostProcessor) {\n                internalPostProcessors.add(pp);\n            }\n        } else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {\n            orderedPostProcessorNames.add(ppName);\n        } else {\n            nonOrderedPostProcessorNames.add(ppName);\n        }\n    }\n\n    // 1. 注册实现了 PriorityOrdered 接口的 BeanPostProcessor 处理器，不包含 MergedBeanDefinitionPostProcessor\n    sortPostProcessors(priorityOrderedPostProcessors, beanFactory);\n    registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors);\n\n    // 2. 注册实现了 Ordered 接口的 BeanPostProcessor 处理器\n    List<BeanPostProcessor> orderedPostProcessors = new ArrayList<>(orderedPostProcessorNames.size());\n    for (String ppName : orderedPostProcessorNames) {\n        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);\n        orderedPostProcessors.add(pp);\n        if (pp instanceof MergedBeanDefinitionPostProcessor) {\n            internalPostProcessors.add(pp);\n        }\n    }\n    sortPostProcessors(orderedPostProcessors, beanFactory);\n    registerBeanPostProcessors(beanFactory, orderedPostProcessors);\n\n    // 3. 注册其余除 MergedBeanDefinitionPostProcessor 类型以外的 BeanPostProcessor 处理器\n    List<BeanPostProcessor> nonOrderedPostProcessors = new ArrayList<>(nonOrderedPostProcessorNames.size());\n    for (String ppName : nonOrderedPostProcessorNames) {\n        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);\n        nonOrderedPostProcessors.add(pp);\n        if (pp instanceof MergedBeanDefinitionPostProcessor) {\n            internalPostProcessors.add(pp);\n        }\n    }\n    registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors);\n\n    // 4. 注册所有的 MergedBeanDefinitionPostProcessor 处理器\n    sortPostProcessors(internalPostProcessors, beanFactory);\n    registerBeanPostProcessors(beanFactory, internalPostProcessors);\n\n    // Re-register post-processor for detecting inner beans as ApplicationListeners,\n    // moving it to the end of the processor chain (for picking up proxies etc).\n    // 重新注册 ApplicationListenerDetector 探测器，将其移到链尾\n    beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));\n}\n```\n\n上述实现与处理 BeanFactoryPostProcessor 处理的过程大同小异，同样按优先级进行注册。\n\n### 初始化国际化资源\n\n笔者之前所负责的几个项目都需要考虑国际化支持，有的直接基于 JDK 原生的 ResourceBundle，有的则基于 Spring 提供的 MessageSource。在具体分析 MessageSource 的初始化过程之前，我们先来了解一下 Spring 国际化支持的设计与简单使用。\n\nSpring MessageSource 支持本质上也是对 ResourceBundle 的封装。MessageSource 接口的定义如下：\n\n```java\npublic interface MessageSource {\n\n    /**\n     * 获取指定语言的文案信息，参数说明：\n     * - code: 属性名称\n     * - args: 用于传递格式化参数\n     * - defaultMessage: 表示在找不到指定属性时返回的默认信息\n     * - locale 表示本地化对象\n     */\n    String getMessage(String code, Object[] args, String defaultMessage, Locale locale);\n\n    /**\n     * 获取指定语言的文案信息，当找不到对应属性时直接抛出异常\n     */\n    String getMessage(String code, Object[] args, Locale locale) throws NoSuchMessageException;\n\n    /**\n     * 获取指定语言的文案信息，采用 MessageSourceResolvable 来封装第一个方法中的前三个参数\n     */\n    String getMessage(MessageSourceResolvable resolvable, Locale locale) throws NoSuchMessageException;\n\n}\n```\n\nSpring MessageSource 相关类的继承关系如下图所示：\n\n![image](/images/2017/spring-ioc-message-source.png)\n\n其中 HierarchicalMessageSource 的设计为 MessageSource 提供了层次支持，建立了父子层级结构。ResourceBundleMessageSource 和 ReloadableResourceBundleMessageSource 是我们常用的两个类，均可以看做是对 JDK 原生国际化支持的封装，后者相对于前者提供了定时更新资源文件的支持，避免资源更新时重启系统。StaticMessageSource 用于支持编码式资源注册，DelegatingMessageSource 则可以看作是 MessageSource 的一个代理，必要时对 MessageSource 进行封装。\n\n下面通过示例演示一下 MessageSource 的简单使用。首先我们定义好国际化资源文件：\n\n- resource.properties\n\n```text\nspring=Spring framework is a good design, the latest version is {0}\n```\n\n- resource_zh.properties\n\n```text\nspring=Spring 框架設計精良，當前最新版本是 {0}\n```\n\n- resource_zh_CN.properties\n\n```text\nspring=Spring 框架设计精良，当前最新版本是 {0}\n```\n\n需要注意的是，如果资源文件包含非 ASCII 字符，则需要将文本内容转换成 Unicode 编码，JDK 自带的 native2ascii 工具可以达到目的，操作如下：\n\n```bash\nnative2ascii -encoding utf-8 resource_zh.properties resource_zh_tmp.properties\n```\n\n然后我们在配置文件中进行如下配置：\n\n```xml\n<!--推荐以 messageResource 作为 id-->\n<bean id=\"messageResource\" class=\"org.springframework.context.support.ResourceBundleMessageSource\">\n    <property name=\"basenames\">\n        <list>\n            <value>i18n/resource</value>\n        </list>\n    </property>\n</bean>\n```\n\n调用方式如下：\n\n```java\nApplicationContext context = new ClassPathXmlApplicationContext(\"spring-core.xml\");\nObject[] params = {\"5.2.6.RELEASE\"};\nSystem.out.println(context.getMessage(\"spring\", params, Locale.ENGLISH));\nSystem.out.println(context.getMessage(\"spring\", params, Locale.TRADITIONAL_CHINESE));\nSystem.out.println(context.getMessage(\"spring\", params, Locale.SIMPLIFIED_CHINESE));\n```\n\n因为 ApplicationContext 同样实现了 MessageSource 接口，所以可以直接调用 `ApplicationContext#getMessage` 方法，但是这样调用的前提是配置中的 ID 必须设置为 `messageResource`。上述示例如下：\n\n```text\nSpring framework is a good design, the latest version is 5.2.6.RELEASE\nSpring 框架設計精良，當前最新版本是 5.2.6.RELEASE\nSpring 框架设计精良，当前最新版本是 5.2.6.RELEASE\n```\n\n下面分析高级容器对于 MessageSource 的初始化过程，由 `AbstractApplicationContext#initMessageSource` 方法实现：\n\n```java\nprotected void initMessageSource() {\n    ConfigurableListableBeanFactory beanFactory = this.getBeanFactory();\n    // 存在 ID 为 messageSource 的 bean 实例\n    if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) {\n        // 获取 MessageSource 实例\n        this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class);\n        // Make MessageSource aware of parent MessageSource.\n        if (this.parent != null && this.messageSource instanceof HierarchicalMessageSource) {\n            HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource;\n            if (hms.getParentMessageSource() == null) {\n                // Only set parent context as parent MessageSource if no parent MessageSource registered already.\n                hms.setParentMessageSource(this.getInternalParentMessageSource());\n            }\n        }\n    }\n    // 不存在 ID 为 messageSource 的 bean 实例\n    else {\n        // 创建一个 DelegatingMessageSource 代理对象\n        DelegatingMessageSource dms = new DelegatingMessageSource();\n        // 尝试继承父上下文中的 MessageSource 实例\n        dms.setParentMessageSource(this.getInternalParentMessageSource());\n        this.messageSource = dms;\n        // 以 messageSource 作为 ID 注册代理的 DelegatingMessageSource 对象\n        beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource);\n    }\n}\n```\n\n前面的示例在配置时推荐将 ID 配置为 `messageSource` 是有原因的，通过阅读上述实现一目了然。代码中硬编码要求我们配置 `messageSource` 作为 MessageSource 实例的 ID，否则不执行初始化，而是创建一个默认的代理，（如果存在的话）委托给父上下文中的 MessageSource 实例。如果通过调用 `ApplicationContext#getMessage` 方法尝试获取对应的资源则会出现异常，此时就需要我们手动指定 `ApplicationContext#getBean` 时的名称。然而，Spring 并不推荐这样做，既然框架以约定的方式提供了相应的实现，还是推荐以 `messageSource` 作为 ID 进行配置为好，毕竟约定优于配置。\n\n### 注册事件通知广播器\n\n事件广播和监听机制是典型的观察者模式实现，而 ApplicationEventMulticaster 则充当观察者模式中主题角色。如果在 Spring 中希望监听事件广播器广播的事件，需要定义一个实现了 ApplicationListener 接口的监听器。Spring 支持通过编码注册和自动扫描注册两种方式注册 ApplicationListener 监听器，这个我们稍后会细说，首先来看一下广播器的初始化过程，实现位于 `AbstractApplicationContext#initApplicationEventMulticaster` 方法中：\n\n```java\nprotected void initApplicationEventMulticaster() {\n    ConfigurableListableBeanFactory beanFactory = this.getBeanFactory();\n    // 包含 ID 为 applicationEventMulticaster 的 bean 实例\n    if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) {\n        this.applicationEventMulticaster =\n                beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class);\n    }\n    // 不包含 ID 为 applicationEventMulticaster 的 bean 实例\n    else {\n        // 创建并注册一个 SimpleApplicationEventMulticaster 实例\n        this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory);\n        beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster);\n    }\n}\n```\n\n如果我们以约定的方式配置了自定义的事件广播器，则上述过程会初始化该广播器实例；否则容器会创建并注册一个默认的 SimpleApplicationEventMulticaster 广播器。下面以 SimpleApplicationEventMulticaster 广播器为例分析广播事件通知的过程，主要来看对于 `ApplicationEventMulticaster#multicastEvent` 方法的实现，如下：\n\n```java\npublic void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) {\n    ResolvableType type = (eventType != null ? eventType : this.resolveDefaultEventType(event));\n    Executor executor = this.getTaskExecutor();\n    // 获取并回调监听指定事件的各个监听器\n    for (ApplicationListener<?> listener : this.getApplicationListeners(event, type)) {\n        if (executor != null) {\n            // 异步执行\n            executor.execute(() -> this.invokeListener(listener, event));\n        } else {\n\n            this.invokeListener(listener, event);\n        }\n    }\n}\n\nprotected void invokeListener(ApplicationListener<?> listener, ApplicationEvent event) {\n    ErrorHandler errorHandler = this.getErrorHandler();\n    if (errorHandler != null) {\n        try {\n            this.doInvokeListener(listener, event);\n        } catch (Throwable err) {\n            errorHandler.handleError(err);\n        }\n    } else {\n        this.doInvokeListener(listener, event);\n    }\n}\n\nprivate void doInvokeListener(ApplicationListener listener, ApplicationEvent event) {\n    try {\n        // 回调 ApplicationListener#onApplicationEvent 方法\n        listener.onApplicationEvent(event);\n    } catch (ClassCastException ex) {\n        String msg = ex.getMessage();\n        if (msg == null || this.matchesClassCastMessage(msg, event.getClass())) {\n            // Possibly a lambda-defined listener which we could not resolve the generic event type for\n            // -> let's suppress the exception and just log a debug message.\n            Log logger = LogFactory.getLog(this.getClass());\n            if (logger.isTraceEnabled()) {\n                logger.trace(\"Non-matching event type for listener: \" + listener, ex);\n            }\n        } else {\n            throw ex;\n        }\n    }\n}\n```\n\n典型的回调观察者监听方法的逻辑，如果对于观察者模式了解的话，这里的逻辑会比较好理解。\n\n### 注册事件监听器\n\n既然有被观察者，就应该有对应的观察者，事件监听器 ApplicationListener 充当观察者角色。我们需要通过注册 ApplicationListener 来监听事件通知，针对 ApplicationListener 的注册，可以通过编码的方式进行注册，如果我们将其配置到配置文件中，容器也会自动扫描并注册。注册 ApplicationListener 的过程由 `AbstractApplicationContext#registerListeners` 方法实现，如下：\n\n```java\nprotected void registerListeners() {\n    // 1. 注册所有通过编码方式添加的事件监听器\n    for (ApplicationListener<?> listener : this.getApplicationListeners()) {\n        this.getApplicationEventMulticaster().addApplicationListener(listener);\n    }\n\n    // 2. 扫描注册以配置方式添加的事件监听器\n    String[] listenerBeanNames = this.getBeanNamesForType(ApplicationListener.class, true, false);\n    for (String listenerBeanName : listenerBeanNames) {\n        this.getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName);\n    }\n\n    // 3. 发布需要提前广播的事件\n    Set<ApplicationEvent> earlyEventsToProcess = this.earlyApplicationEvents;\n    this.earlyApplicationEvents = null;\n    if (earlyEventsToProcess != null) {\n        // 调用广播器的 ApplicationEventMulticaster#multicastEvent 方法\n        for (ApplicationEvent earlyEvent : earlyEventsToProcess) {\n            this.getApplicationEventMulticaster().multicastEvent(earlyEvent);\n        }\n    }\n}\n```\n\n上一步已经完成了对于事件广播器 ApplicationEventMulticaster 的注册操作，这一步所完成的工作就是将编码和配置注册的 ApplicationListener 注册到广播器中。如果在前面的过程中已经记录了一些需要广播的事件，那么在这一步会触发对于这些事件的广播通知，因为此时已经有事件广播器可用了。\n\n### 实例化非延迟加载的 singleton 类对象\n\n记得最开始学习 Spring 框架的时候，就看到说 BeanFactory 和 ApplicationContext 有一个很大的区别，即 BeanFactory 在初始化容器时不会实例化 bean 对象，而 ApplicationContext 则会实例化所有非延迟加载的 singleton 类实例。这是因为 ApplicationContext 会在初始化容器时通过调用 `AbstractApplicationContext#finishBeanFactoryInitialization` 方法对所有非延迟加载的 singleton 类进行实例化操作，实现如下：\n\n```java\nprotected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) {\n    // 如果存在类型转换器，则进行加载\n    if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME)\n            && beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) {\n        beanFactory.setConversionService(beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class));\n    }\n\n    // 如果不存在 embedded value resolver 则设置一个默认的\n    if (!beanFactory.hasEmbeddedValueResolver()) {\n        beanFactory.addEmbeddedValueResolver(new StringValueResolver() {\n            @Override\n            public String resolveStringValue(String strVal) {\n                return getEnvironment().resolvePlaceholders(strVal);\n            }\n        });\n    }\n\n    // AOP支持，实例化 LoadTimeWeaverAware\n    String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false);\n    for (String weaverAwareName : weaverAwareNames) {\n        this.getBean(weaverAwareName);\n    }\n\n    beanFactory.setTempClassLoader(null);\n\n    // 冻结所有 bean 的定义，不再允许更改\n    beanFactory.freezeConfiguration();\n\n    // 实例化所有的非延迟加载的bean（非abstract && 单例 && 非延迟加载）\n    beanFactory.preInstantiateSingletons();\n}\n```\n\n由上述实现可以知道，Spring 在实例化非延迟加载的 singleton 对象之前先校验一些必要的工具实例是否存在，如果没有注册则会创建一个默认的作为代替。然后会冻结所有的 BeanDefinition 定义，毕竟即将开始执行实例化了，后续的更改也不会再生效。完成准备工作之后，容器即开始实例化所有满足条件（非 abstract && 单例 && 非 lazy-init）的 bean 对象。\n\n实例化的过程由 `DefaultListableBeanFactory#preInstantiateSingletons` 方法实现，如下：\n\n```java\npublic void preInstantiateSingletons() throws BeansException {\n    // Iterate over a copy to allow for init methods which in turn register new bean definitions.\n    // While this may not be part of the regular factory bootstrap, it does otherwise work fine.\n    List<String> beanNames = new ArrayList<>(this.beanDefinitionNames);\n\n    // 遍历实例化所有满足条件的 bean 对象\n    for (String beanName : beanNames) {\n        // 获取对应 bean 最终的 BeanDefinition 定义\n        RootBeanDefinition bd = this.getMergedLocalBeanDefinition(beanName);\n        // 不是 abstract && 单例 && 不是 lazy-init\n        if (!bd.isAbstract() && bd.isSingleton() && !bd.isLazyInit()) {\n            // 处理 FactoryBean\n            if (this.isFactoryBean(beanName)) {\n                // 获取 FactoryBean 对象\n                Object bean = this.getBean(FACTORY_BEAN_PREFIX + beanName);\n                if (bean instanceof FactoryBean) {\n                    final FactoryBean<?> factory = (FactoryBean<?>) bean;\n                    boolean isEagerInit;\n                    if (System.getSecurityManager() != null && factory instanceof SmartFactoryBean) {\n                        isEagerInit = AccessController.doPrivileged((PrivilegedAction<Boolean>) ((SmartFactoryBean<?>) factory)::isEagerInit,\n                                this.getAccessControlContext());\n                    } else {\n                        isEagerInit = (factory instanceof SmartFactoryBean && ((SmartFactoryBean<?>) factory).isEagerInit());\n                    }\n                    if (isEagerInit) {\n                        this.getBean(beanName);\n                    }\n                }\n            }\n            // 加载普通 bean 对象\n            else {\n                this.getBean(beanName);\n            }\n        }\n    }\n\n    /* 完成对所有满足条件的 singleton bean 的实例化操作 */\n\n    // 遍历处理所有实现了 SmartInitializingSingleton 接口的 bean 实例\n    for (String beanName : beanNames) {\n        Object singletonInstance = this.getSingleton(beanName);\n        // 回调 SmartInitializingSingleton#afterSingletonsInstantiated 方法\n        if (singletonInstance instanceof SmartInitializingSingleton) {\n            final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance;\n            if (System.getSecurityManager() != null) {\n                AccessController.doPrivileged((PrivilegedAction<Object>) () -> {\n                    smartSingleton.afterSingletonsInstantiated();\n                    return null;\n                }, this.getAccessControlContext());\n            } else {\n                smartSingleton.afterSingletonsInstantiated();\n            }\n        }\n    }\n}\n```\n\nSpring 在 4.1 版本增加了 SmartInitializingSingleton 接口，实现了该接口的单例可以感知所有单例实例化完成的事件，而回调接口中声明的 `SmartInitializingSingleton#afterSingletonsInstantiated` 方法的逻辑由上述方法完成。\n\n### 完成刷新过程\n\n经过前面的过程，对于 ApplicationContext 而言已经完成了加载并解析配置，以及实例化所有非延迟加载的 singleton 类对象的过程。也就是说，高级容器初始化过程的主要工作已经做完了，最后需要调用 `AbstractApplicationContext#finishRefresh` 方法完成整个初始化进程，实现如下：\n\n```java\nprotected void finishRefresh() {\n    // 初始化 LifecycleProcessor\n    this.initLifecycleProcessor();\n\n    // 调用所有实现了 Lifecycle 的 start 方法\n    this.getLifecycleProcessor().onRefresh();\n\n    // 发布上下文刷新完毕事件\n    this.publishEvent(new ContextRefreshedEvent(this));\n\n    // 注册到 LiveBeansView MBean\n    LiveBeansView.registerApplicationContext(this);\n}\n```\n\nSpring 很早就提供了 Lifecycle 接口，实现了该接口的 bean 可以感知到容器的启动和关闭状态，对应接口的 `Lifecycle#start` 和 `Lifecycle#stop` 方法，而方法 `Lifecycle#start` 的回调则位于此。Lifecycle 中方法的执行需要依赖于 LifecycleProcessor 处理器，我们可以自定义 LifecycleProcessor 实现，否则容器会创建一个默认的 DefaultLifecycleProcessor 对象，然后基于定义的 LifecycleProcessor 处理器调用满足条件的 bean 实例的 `Lifecycle#start` 方法。在完成了这一操作后，容器的初始化过程也就完成了，此时容器可以将容器刷新完毕事件通知到对应的事件监听器，即所有订阅 ContextRefreshedEvent 事件的监听器。\n\n### 总结\n\n至此，高级容器的初始化过程我们已经分析完了，不同于 BeanFactory 在该阶段仅仅是将静态配置转换成容器中对应的 BeanDefinition 实例，ApplicationContext 因为需要实例化所有非延迟加载的 singleton 对象，所以大部分的 bean 对象已经以实例的形式注册到容器中，后续我们再调用 `ApplicationContext#getBean` 方法也仅需要针对非单例的 bean 对象才执行复杂的实例化操作，所以在高级容器中本篇所分析的过程基本可以概括容器的大部分工作。\n\n### 参考\n\n1. [Spring 源码深度解析](https://book.douban.com/subject/25866350/)\n","tags":["Spring"],"categories":["spring"]},{"title":"Spring IoC 源码解析：创建和初始化 bean 实例","url":"/2017/05/28/spring/spring-ioc-get-bean/","content":"\n到目前为止，我们已经分析了 bean 配置的解析与注册过程。经过这一系列的操作，我们编写在 XML 中的半结构化静态配置已经转换成一个个的 BeanDefinition 实例存在于容器之中，接下来就可以调用 `BeanFactory#getBean` 方法获取目标 bean 实例。本文我们将从 `BeanFactory#getBean` 方法出发，探究容器基于 BeanDefinition 创建和初始化 bean 实例的过程。<!-- more -->\n\n下图描绘了从 BeanFactory 中按照 beanName 获取 bean 实例的核心过程：\n\n![image](https://github.com/plotor/plotor.github.io/blob/master/images/2017/spring-ioc-bean-factory-flow.png?raw=false)\n\n我们可以从整体上将 bean 的生命周期分为 5 个阶段：\n\n1. 实例化 bean 对象；\n2. 执行属性注入；\n3. 执行初始化（调用 `InitializingBean#afterPropertiesSet` 方法和 `init-method` 方法）；\n4. 使用 bean 实例；\n5. 销毁 bean 实例（调用 `DisposableBean#destroy` 方法和 `destroy-method` 方法）。\n\nSpring 会在 bean 实例的生命周期中设置多个拦截器，主要可以分为以下几类（按照生命周期进行排序）：\n\n1. 实例化前置拦截器：我们可以在该拦截器中自定义实例化，从而替换 Spring 自身的实例化操作。\n2. Bean Definition 拦截器：用于在实例化 bean 对象之前对 bean 定义进行拦截修改。\n3. 实例化后置拦截器：此时还未执行属性注入，所以我们可以在此实现自定义属性注入逻辑。\n4. 属性拦截器：用于在执行属性注入之前对待注入的属性值进行修改。\n5. Aware 拦截器：实现了这类拦截器的 bean 希望在 IoC 容器初始化期间从容器中获取一些属性。\n6. 初始化前置拦截器：在执行初始化方法之前对 bean 实例进行拦截处理。\n7. 初始化后置拦截器：在执行初始化方法之后对 bean 实例进行拦截处理。\n8. 销毁前置拦截器：在销毁 bean 实例之前对 bean 实例进行拦截处理。\n\n以上我们从 bean 实例整体生命周期的角度对 IoC 容器从创建到最终销毁一个 bean 实例的过程进行了简单的概括，下面我们将从源码实现的层面去分析 IoC 容器是如何创建并初始化 bean 实例的。\n\n我们从 `BeanFactory#getBean` 方法切入，Spring 为该方法提供了多种重载和覆盖版本的实现，当我们执行该方法时一般都是由抽象类 AbstractBeanFactory 予以处理。\n\n方法 `AbstractBeanFactory#getBean` 实现如下：\n\n```java\npublic Object getBean(String name) throws BeansException {\n    return this.doGetBean(name, null, null, false);\n}\n\nprotected <T> T doGetBean(final String name,\n                          @Nullable final Class<T> requiredType,\n                          @Nullable final Object[] args,\n                          boolean typeCheckOnly) throws BeansException {\n\n    /*\n     * 获取 name 对应的真正 beanName\n     *\n     * 因为传入的参数可以是 alias，也可能是 FactoryBean 的 name，所以需要进行解析，包含以下内容：\n     * 1. 如果是 FactoryBean，则去掉 “&” 前缀\n     * 2. 沿着引用链获取 alias 对应的最终 name\n     */\n    final String beanName = this.transformedBeanName(name);\n    Object bean;\n\n    /*\n     * 尝试从单例集合中获取对应的单实例，\n     * 在实例化 bean 的时候可能需要实例化依赖的 bean 对象，Spring 为了避免循环依赖会采用早期引用机制\n     */\n    Object sharedInstance = this.getSingleton(beanName);\n    // 目标实例已经实例化过\n    if (sharedInstance != null && args == null) {\n        if (logger.isTraceEnabled()) {\n            if (this.isSingletonCurrentlyInCreation(beanName)) {\n                logger.trace(\"Returning eagerly cached instance of singleton bean '\" + beanName +\n                        \"' that is not fully initialized yet - a consequence of a circular reference\");\n            } else {\n                logger.trace(\"Returning cached instance of singleton bean '\" + beanName + \"'\");\n            }\n        }\n        // 处理 FactoryBean\n        bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, null);\n    }\n    // 目标实例不存在\n    else {\n        // Fail if we're already creating this bean instance: We're assumably within a circular reference.\n        if (this.isPrototypeCurrentlyInCreation(beanName)) {\n            /*\n             * 只有在单例模式下才会尝试解决循环依赖问题，\n             * 对于原型模式，如果存在循环依赖，直接抛出异常\n             */\n            throw new BeanCurrentlyInCreationException(beanName);\n        }\n\n        // 获取父 BeanFactory 实例\n        BeanFactory parentBeanFactory = this.getParentBeanFactory();\n        // 如果已经加载的 bean 定义中不包含目标 bean，则尝试从父 BeanFactory 中获取\n        if (parentBeanFactory != null && !this.containsBeanDefinition(beanName)) {\n            // 递归到父 BeanFactory 中进行检索\n            String nameToLookup = this.originalBeanName(name);\n            if (parentBeanFactory instanceof AbstractBeanFactory) {\n                return ((AbstractBeanFactory) parentBeanFactory)\n                        .doGetBean(nameToLookup, requiredType, args, typeCheckOnly);\n            } else if (args != null) {\n                // Delegation to parent with explicit args.\n                return (T) parentBeanFactory.getBean(nameToLookup, args);\n            } else if (requiredType != null) {\n                // No args -> delegate to standard getBean method.\n                return parentBeanFactory.getBean(nameToLookup, requiredType);\n            } else {\n                return (T) parentBeanFactory.getBean(nameToLookup);\n            }\n        }\n\n        // 如果不仅仅是做类型检查，则标记该 bean 即将被创建\n        if (!typeCheckOnly) {\n            this.markBeanAsCreated(beanName);\n        }\n\n        try {\n            // 如果存在父 bean，则继承父 bean 定义\n            final RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName);\n            // 检查 bean 是否是抽象的，如果是则抛出异常\n            this.checkMergedBeanDefinition(mbd, beanName, args);\n\n            // 加载当前 bean 依赖的 bean 实例\n            String[] dependsOn = mbd.getDependsOn();\n            // 存在依赖，递归实例化依赖的 bean 实例\n            if (dependsOn != null) {\n                for (String dep : dependsOn) {\n                    // 检查是否存在循环依赖\n                    if (this.isDependent(beanName, dep)) {\n                        throw new BeanCreationException(mbd.getResourceDescription(), beanName,\n                                \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\");\n                    }\n                    // 缓存依赖调用\n                    this.registerDependentBean(dep, beanName);\n                    try {\n                        // 初始化依赖的 bean 实例\n                        this.getBean(dep);\n                    } catch (NoSuchBeanDefinitionException ex) {\n                        throw new BeanCreationException(mbd.getResourceDescription(), beanName,\n                                \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex);\n                    }\n                }\n            }\n\n            /* 创建 bean 实例 */\n\n            // scope == singleton\n            if (mbd.isSingleton()) {\n                sharedInstance = this.getSingleton(beanName, () -> {\n                    try {\n                        // 实例化 bean 对象\n                        return this.createBean(beanName, mbd, args);\n                    } catch (BeansException ex) {\n                        // Explicitly remove instance from singleton cache: It might have been put there\n                        // eagerly by the creation process, to allow for circular reference resolution.\n                        // Also remove any beans that received a temporary reference to the bean.\n                        this.destroySingleton(beanName); // 清理工作，从单例缓存中移除\n                        throw ex;\n                    }\n                });\n                // 处理 FactoryBean\n                bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, mbd);\n            }\n            // scope == prototype\n            else if (mbd.isPrototype()) {\n                // It's a prototype -> create a new instance.\n                Object prototypeInstance = null;\n                try {\n                    // 设置正在创建的状态\n                    this.beforePrototypeCreation(beanName);\n                    // 创建 bean 实例\n                    prototypeInstance = this.createBean(beanName, mbd, args);\n                } finally {\n                    this.afterPrototypeCreation(beanName);\n                }\n                // 处理 FactoryBean\n                bean = this.getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);\n            }\n            // other scope\n            else {\n                String scopeName = mbd.getScope();\n                final Scope scope = this.scopes.get(scopeName);\n                if (scope == null) {\n                    throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\");\n                }\n                try {\n                    Object scopedInstance = scope.get(beanName, () -> {\n                        this.beforePrototypeCreation(beanName);\n                        try {\n                            return this.createBean(beanName, mbd, args);\n                        } finally {\n                            this.afterPrototypeCreation(beanName);\n                        }\n                    });\n                    // 处理 FactoryBean\n                    bean = this.getObjectForBeanInstance(scopedInstance, name, beanName, mbd);\n                } catch (IllegalStateException ex) {\n                    throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" +\n                            \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex);\n                }\n            }\n        } catch (BeansException ex) {\n            this.cleanupAfterBeanCreationFailure(beanName);\n            throw ex;\n        }\n    }\n\n    // 如果要求做类型检查，则检查 bean 的实际类型是否是期望的类型，对应 getBean 时指定的 requireType\n    if (requiredType != null && !requiredType.isInstance(bean)) {\n        try {\n            // 执行类型转换，转换成期望的类型\n            T convertedBean = this.getTypeConverter().convertIfNecessary(bean, requiredType);\n            if (convertedBean == null) {\n                throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());\n            }\n            return convertedBean;\n        } catch (TypeMismatchException ex) {\n            if (logger.isTraceEnabled()) {\n                logger.trace(\"Failed to convert bean '\" + name + \"' to required type '\" +\n                        ClassUtils.getQualifiedName(requiredType) + \"'\", ex);\n            }\n            throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());\n        }\n    }\n    return (T) bean;\n}\n```\n\n整个方法的执行流程可以概括为：\n\n1. 将参数 name 转换成对应的真实 beanName，因为入参可能是 alias，或者是 FactoryBean 的 name；\n2. 尝试从单例集合中获取 bean 实例，如果存在则直接返回，否则如果存在循环依赖，则尝试基于提前引用机制予以解决；\n3. 如果是获取 prototype 类型对象，则检查依赖关系，防止出现循环依赖；\n4. 如果目标 bean 不在当前 BeanFactory 的管辖范围，则尝试从父 BeanFactory 中获取；\n5. 如何当前 bean 存在继承关系，则合并父 bean 定义；\n6. 如果依赖的 bean 未被实例化，则递归实例化依赖的 bean 对象；\n7. 依据 bean 的作用域类型实例化目标 bean 对象；\n8. 如果对 bean 类型有要求，则执行类型检查，并按需做类型转换；\n9. 返回目标 bean 实例，期间会处理 FactoryBean。\n\n接下来我们针对各步骤中的详细过程按照需要进行逐一探究。\n\n### 解析 bean 标识\n\n我们在调用 `BeanFactory#getBean` 方法时传递的 name 可以是 bean 的别名，也可以是获取 FactoryBean 实例的 name。所以当我们以 name 为 key 检索 bean 实例的时候，首先需要获取 name 对应的唯一标识 bean 的真正名称 beanName，这一过程位于 `AbstractBeanFactory#transformedBeanName` 方法中：\n\n```java\nprotected String transformedBeanName(String name) {\n    return this.canonicalName(BeanFactoryUtils.transformedBeanName(name));\n}\n```\n\n上述实现首先会通过 `BeanFactoryUtils#transformedBeanName` 工具类方法判断是不是获取 FactoryBean 实例，如果是则去掉 name 前面的 `&` 字符（我们已经在前面的文章中专门介绍了 FactoryBean，不熟悉的读者可以重新回顾一下），然后执行 `SimpleAliasRegistry#canonicalName` 逻辑：\n\n```java\npublic String canonicalName(String name) {\n    String canonicalName = name;\n    // Handle aliasing...\n    String resolvedName;\n    do {\n        // 如果是别名，则直接从映射集合中获取对应的 beanName\n        resolvedName = this.aliasMap.get(canonicalName);\n        if (resolvedName != null) {\n            canonicalName = resolvedName;\n        }\n        // 遍历寻找真正的 name，可能存在引用链\n    } while (resolvedName != null);\n    return canonicalName;\n}\n```\n\n前面我们在分析默认标签的解析过程时了解到，Spring 会通过调用 `SimpleAliasRegistry#registerAlias` 方法建立 alias 与 beanName 之间的映射关系，而这一映射关系实际上就是记录在 `SimpleAliasRegistry#aliasMap` 属性中，所以上述实现实际上就是从该属性中基于 alias 检索 beanName 的过程。\n\n那么，为什么这里当 `resolvedName != null` 的时候需要继续循环呢？这是因为一个别名所引用的不一定是最终的 beanName，可以是另外一个别名，这个时候就是一个链式引用的场景，我们需要继续沿着引用链往下寻找最终的 beanName。\n\n### 检索单实例集合\n\n获取到 beanName 标识之后，容器首先尝试从单例对象集合中获取 bean 实例。我们知道单例对象在容器中只会存在一份，所以首先检查单例集合也符合常理，获取单例对象的方法如下：\n\n```java\npublic Object getSingleton(String beanName) {\n    // 允许提前引用\n    return this.getSingleton(beanName, true);\n}\n```\n\n上述方法的第二个参数设置为 true，即 `allowEarlyReference=true`，表示允许提前引用，此时的 bean 实例虽然已经被创建，但是还未执行初始化。\n\nSpring 中 bean 的依赖关系由开发者控制，具备极大的自由配置空间，如果配置不当可能会导致循环依赖的问题，即 A 依赖于 B，而 B 又依赖于 A。当创建 A 对象的时候，容器检测到引用的 B 还没有实例化，就会转去创建 B 对象；实例化 B 的过程中又会发现 A 还没有实例化完成，从而又回来实例化 A，因此陷入死循环。\n\nSpring 能够解决一些场景下的循环依赖问题，而参数 allowEarlyReference 则在其中起到了关键的作用。方法 `DefaultSingletonBeanRegistry#getSingleton(String, boolean)` 的具体实现如下：\n\n```java\nprotected Object getSingleton(String beanName, boolean allowEarlyReference) {\n    // 尝试获取对应的单例对象\n    Object singletonObject = this.singletonObjects.get(beanName);\n    // 实例不存在 && 正在创建中\n    if (singletonObject == null && this.isSingletonCurrentlyInCreation(beanName)) {\n        synchronized (this.singletonObjects) {\n            // 尝试获取早期的实例，此时的实例还未完成初始化\n            singletonObject = this.earlySingletonObjects.get(beanName);\n            // 如果早期的实例不存在，且允许提前引用，则基于对应的 ObjectFactory 创建\n            if (singletonObject == null && allowEarlyReference) {\n                ObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);\n                if (singletonFactory != null) {\n                    singletonObject = singletonFactory.getObject();\n                    // earlySingletonObjects 和 singletonFactories 是互斥的\n                    this.earlySingletonObjects.put(beanName, singletonObject);\n                    this.singletonFactories.remove(beanName);\n                }\n            }\n        }\n    }\n    // 返回目标单例对象，可能为 null\n    return singletonObject;\n}\n```\n\n上述方法首先尝试从存放单实例的集合 `DefaultSingletonBeanRegistry#singletonObjects` 中获取实例，这里分为 3 种情况：\n\n1. 目标 bean 实例已经存在，说明之前已经实例化过，直接返回即可。\n2. 目标 bean 实例不存在，且未处于正在创建中的状态，直接返回 null，接下去会执行实例化进程。\n3. 目标 bean 实例不存在，但处于正在创建中的状态，说明存在循环依赖的情况。\n\n针对第 3 种情况，Spring 定义了 `DefaultSingletonBeanRegistry#earlySingletonObjects` 属性，记录那些那些被创建出来还未执行初始化的对象。毕竟，依赖注入的过程是将一个对象的引用赋值给另一个对象的某个属性，并不要求被注入的对象已经完成了初始化。简单而言，就是先把对象间的依赖关系建立好，再去初始化各个对象，这一机制能够在一些场景下破解循环依赖的环路。\n\n以上述 A 和 B 循环引用为例，我们可以先把 A 和 B 的对象先创建完成，期间相互引用的属性先置为 null，这样就不会阻碍这两个对象的创建过程，然后再初始化相互引用的属性值。\n\n由上述实现还可以看到 singletonObjects 和 earlySingletonObjects 这两个属性中记录的实例是互斥的，即一个实例只可能存在于两者中的一个，不可能同时存在，这也是很容易理解的。\n\n### 处理 FactoryBean\n\n如果上一步我们获取到了单例 bean 实例，那么需要接着调用 `AbstractBeanFactory#getObjectForBeanInstance` 方法处理 FactoryBean。该方法在 `AbstractBeanFactory#doGetBean` 实现中多次被调用，每次我们获取到 bean 实例之后，不管是从单例集合中获取还是实时创建的各作用域对象，都需执行一次该方法对获取到的实例进行最后的处理。该方法的主要目的是判断当前 bean 实例是否是 FactoryBean，如果是 FactoryBean 实例，且用户又希望获取由该 FactoryBean 所创建的最终 bean 实例，此时就需要调用 `FactoryBean#getObject` 方法创建最终 bean 实例。\n\n方法 `AbstractBeanFactory#getObjectForBeanInstance` 的实现如下：\n\n```java\nprotected Object getObjectForBeanInstance(Object beanInstance, // bean 实例\n                                          String name, // 请求的 beanName\n                                          String beanName, // 解析后的 beanName\n                                          @Nullable RootBeanDefinition mbd) { // 父 bean 定义\n\n    // 用户期望获取 FactoryBean 实例\n    if (BeanFactoryUtils.isFactoryDereference(name)) {\n        // NullBean 是对 null 实例的内部表示\n        if (beanInstance instanceof NullBean) {\n            return beanInstance;\n        }\n        // 获取FactoryBean，但是对应的bean并不是FactoryBean类型\n        if (!(beanInstance instanceof FactoryBean)) {\n            throw new BeanIsNotAFactoryException(beanName, beanInstance.getClass());\n        }\n        // 标识是 FactoryBean 实例\n        if (mbd != null) {\n            mbd.isFactoryBean = true;\n        }\n        return beanInstance;\n    }\n\n    /*\n     * 一个 bean 实例，可以是普通的 bean，也可能是 FactoryBean 实例\n     * 该bean实例不是FactoryBean or 本来就是希望获取FactoryBean实例\n     */\n    // 用户并不期望获取 FactoryBean 实例，且当前 bean 也不是 FactoryBean，直接返回\n    if (!(beanInstance instanceof FactoryBean)) {\n        return beanInstance;\n    }\n\n    /* 当前 bean 是 FactoryBean，但用户期望获取由该 FactoryBean 创建的 bean 实例 */\n\n    Object object = null;\n    if (mbd != null) {\n        // 标识是 FactoryBean 实例\n        mbd.isFactoryBean = true;\n    } else {\n        // 尝试从缓存中获取最终 bean 实例\n        object = this.getCachedObjectForFactoryBean(beanName);\n    }\n\n    // 基于 FactoryBean 获取最终 bean 实例\n    if (object == null) {\n        FactoryBean<?> factory = (FactoryBean<?>) beanInstance;\n        // Caches object obtained from FactoryBean if it is a singleton.\n        if (mbd == null && this.containsBeanDefinition(beanName)) {\n            // 执行对 bean 定义的 merge 操作\n            mbd = this.getMergedLocalBeanDefinition(beanName);\n        }\n        // 是否是用户定义的，而不是应用程序自己定义的\n        boolean synthetic = (mbd != null && mbd.isSynthetic());\n        // 核心实现，基于 FactoryBean 获取最终 bean 实例\n        object = this.getObjectFromFactoryBean(factory, beanName, !synthetic);\n    }\n    return object;\n}\n```\n\n上述方法的实现可以分为四种情况：\n\n1. 用户期望获取 FactoryBean 实例，当前 bean 实例是 FactoryBean 类型，直接返回。\n2. 用户期望获取 FactoryBean 实例，当前 bean 实例不是 FactoryBean 类型，抛出异常。\n3. 用户期望获取最终 bean 实例，当前 bean 实例不是 FactoryBean 类型，直接返回。\n4. 用户期望获取最终 bean 实例，当前 bean 实例是 FactoryBean 类型，需要基于 FactoryBean 创建最终 bean 实例。\n\n前面三种情况都比较简单，重点看一下第四种情况，这一步的核心在于如何由 FactoryBean 获取到最终的 bean 实例。容器首先会尝试从缓存中获取，因为对于一些单例的 bean 来说，可能之前已经完成了实例化。Spring 定义了 `FactoryBeanRegistrySupport#factoryBeanObjectCache` 属性，用于记录 FactoryBean 与对应 bean 实例之间的映射关系。如果缓存不命中则执行创建过程，继续执行 `FactoryBeanRegistrySupport#getObjectFromFactoryBean` 方法：\n\n```java\nprotected Object getObjectFromFactoryBean(\n        FactoryBean<?> factory, // FactoryBean 实例\n        String beanName, // 真实 beanName\n        boolean shouldPostProcess) // 是否执行后处理\n{\n    // 如果是单例，且已经实例化\n    if (factory.isSingleton() && this.containsSingleton(beanName)) {\n        synchronized (this.getSingletonMutex()) {\n            // 尝试从缓存中获取，key 为 factoryBeanName，value 为由 FactoryBean 创建的 bean 实例\n            Object object = this.factoryBeanObjectCache.get(beanName);\n            if (object == null) {\n                // 调用 FactoryBean 的 getObject 方法创建对象\n                object = this.doGetObjectFromFactoryBean(factory, beanName);\n                // Only post-process and store if not put there already during getObject() call above\n                // (e.g. because of circular reference processing triggered by custom getBean calls)\n                Object alreadyThere = this.factoryBeanObjectCache.get(beanName);\n                if (alreadyThere != null) {\n                    object = alreadyThere;\n                } else {\n                    if (shouldPostProcess) {\n                        // 提前引用\n                        if (this.isSingletonCurrentlyInCreation(beanName)) {\n                            // Temporarily return non-post-processed object, not storing it yet..\n                            return object;\n                        }\n                        this.beforeSingletonCreation(beanName);\n                        try {\n                            // 后置处理\n                            object = this.postProcessObjectFromFactoryBean(object, beanName);\n                        } catch (Throwable ex) {\n                            throw new BeanCreationException(beanName, \"Post-processing of FactoryBean's singleton object failed\", ex);\n                        } finally {\n                            this.afterSingletonCreation(beanName);\n                        }\n                    }\n                    // 如果最终的 bean 实例已经实例化完成，则缓存\n                    if (this.containsSingleton(beanName)) {\n                        this.factoryBeanObjectCache.put(beanName, object);\n                    }\n                }\n            }\n            // 返回由 FactoryBean 创建的 bean 实例\n            return object;\n        }\n    }\n    // 不是单例，或未实例化过\n    else {\n        // 调用 FactoryBean 的 getObject 方法创建对象\n        Object object = this.doGetObjectFromFactoryBean(factory, beanName);\n        if (shouldPostProcess) {\n            try {\n                // 后置处理\n                object = this.postProcessObjectFromFactoryBean(object, beanName);\n            } catch (Throwable ex) {\n                throw new BeanCreationException(beanName, \"Post-processing of FactoryBean's object failed\", ex);\n            }\n        }\n        return object;\n    }\n}\n```\n\n上述实现对于单例来说保证单例在容器中的唯一性。我们期望的调用 `FactoryBean#getObject` 方法创建 bean 实例的逻辑位于 `FactoryBeanRegistrySupport#doGetObjectFromFactoryBean` 方法中。前面的文章已经介绍过 FactoryBean，并演示了 FactoryBean 的使用方法，再来回顾一下 FactoryBean 接口的定义：\n\n```java\npublic interface FactoryBean<T> {\n    /** 获取由 FactoryBean 创建的目标 bean 实例 */\n    T getObject() throws Exception;\n    /** 返回目标 bean 类型 */\n    Class<?> getObjectType();\n    /** 是否是单实例 */\n    default boolean isSingleton() {\n        return true;\n    }\n}\n```\n\nFactoryBean 接口声明了三个方法，而 `FactoryBean#getObject` 方法是用来真正创建对象的地方。当我们在调用 `BeanFactory#getBean` 方法时如果不加 `&` 前缀，这个时候该方法可以看作是 `FactoryBean#getObject` 方法的代理方法，而具体实现就在 `FactoryBeanRegistrySupport#doGetObjectFromFactoryBean` 方法中：\n\n```java\nprivate Object doGetObjectFromFactoryBean(final FactoryBean<?> factory, final String beanName)\n        throws BeanCreationException {\n\n    // 调用 getObject 方法创建最终 bean 实例，该方法由用户实现\n    Object object;\n    try {\n        if (System.getSecurityManager() != null) {\n            AccessControlContext acc = this.getAccessControlContext();\n            try {\n                object = AccessController.doPrivileged((PrivilegedExceptionAction<Object>) factory::getObject, acc);\n            } catch (PrivilegedActionException pae) {\n                throw pae.getException();\n            }\n        } else {\n            object = factory.getObject();\n        }\n    } catch (FactoryBeanNotInitializedException ex) {\n        throw new BeanCurrentlyInCreationException(beanName, ex.toString());\n    } catch (Throwable ex) {\n        throw new BeanCreationException(beanName, \"FactoryBean threw exception on object creation\", ex);\n    }\n\n    // Do not accept a null value for a FactoryBean that's not fully initialized yet: Many FactoryBeans just return null then.\n    if (object == null) {\n        // FactoryBean 正在实例化中，此时获取最终 bean 实例太早\n        if (this.isSingletonCurrentlyInCreation(beanName)) {\n            throw new BeanCurrentlyInCreationException(beanName,\n                    \"FactoryBean which is currently in creation returned null from getObject\");\n        }\n        // 如果用户指定返回 null 值，则使用 NullBean 代替\n        object = new NullBean();\n    }\n    return object;\n}\n```\n\n上述方法中执行 `FactoryBean#getObject` 的实现是我们一层层剥离外表所触及到的核心，该方法的具体实现则交给了开发者。\n\n### 实例化 bean 对象\n\n如果单例集合中不存在目标 bean 实例，那么说明当前 bean 可能是一个非单例对象，或者是一个单例但却是第一次加载。如果将前面的操作看作是获取对象，那么这里就需要真正创建对象了。在开始实例化 bean 之前，需要做如下几件事情：\n\n1. 对 prototype 对象的循环依赖进行检查，如果存在则直接抛出异常，而不尝试去解决循环依赖。\n2. 检测目标 bean 定义是否属于当前 BeanFactory 的管辖范围，如果不属于且同时存在父 BeanFactory，则委托给父 BeanFactory 进行处理。\n3. 检测是不是仅仅做类型检查（eg. `BeanFactory#isTypeMatch`），如果不是则标记该 bean 即将被创建。\n4. 如果存在父 bean，则继承父 bean 定义，并检查 bean 是否是抽象类，如果是则抛出异常。\n5. 检查依赖的 bean，如果存在且未实例化，则先递归实例化依赖的 bean 对象。\n\n完成了上述准备工作之后，容器依据作用域采取适当的方法创建对应的 bean 实例。由于创建 prototype 类型对象，或其它作用域类型对象与创建 singleton 类型对象大同小异，所以下面以创建 singleton 类型对象为例，分析 bean 对象的实例化过程。\n\n前面分析了从单例缓存集合中获取单例对象的实现，而能够执行到当前位置说明之前的缓存不命中，对应的单例对象还没有创建，需要实例化该对象。该过程位于 `DefaultSingletonBeanRegistry#getSingleton` 方法中，这是一个重载方法，与前面从缓存中获取单例对象的方法在参数上存在差别，方法实现如下：\n\n```java\npublic Object getSingleton(String beanName, ObjectFactory<?> singletonFactory) {\n    Assert.notNull(beanName, \"Bean name must not be null\");\n    synchronized (this.singletonObjects) { // singletonObjects 用于记录 beanName 与已创建的单例对象之间的映射关系\n        // 尝试从缓存中获取已经实例化完成的 bean 实例\n        Object singletonObject = this.singletonObjects.get(beanName);\n        // 缓存不命中，需要进行实例化\n        if (singletonObject == null) {\n            // 目标 bean 正在被销毁，期间不允许创建\n            if (this.singletonsCurrentlyInDestruction) {\n                throw new BeanCreationNotAllowedException(beanName,\n                        \"Singleton bean creation not allowed while singletons of this factory are in destruction \" +\n                                \"(Do not request a bean from a BeanFactory in a destroy method implementation!)\");\n            }\n\n            // 校验 bean 是否正在被实例化\n            this.beforeSingletonCreation(beanName);\n\n            boolean newSingleton = false;\n            boolean recordSuppressedExceptions = (this.suppressedExceptions == null);\n            if (recordSuppressedExceptions) {\n                this.suppressedExceptions = new LinkedHashSet<>();\n            }\n\n            try {\n                // 基于 ObjectFactory 创建 bean 对象\n                singletonObject = singletonFactory.getObject();\n                newSingleton = true;\n            } catch (IllegalStateException ex) {\n                // Has the singleton object implicitly appeared in the meantime ->\n                // if yes, proceed with it since the exception indicates that state.\n                // 异常，再次尝试从缓存中获取\n                singletonObject = this.singletonObjects.get(beanName);\n                if (singletonObject == null) {\n                    throw ex;\n                }\n            } catch (BeanCreationException ex) {\n                if (recordSuppressedExceptions) {\n                    for (Exception suppressedException : this.suppressedExceptions) {\n                        ex.addRelatedCause(suppressedException);\n                    }\n                }\n                throw ex;\n            } finally {\n                if (recordSuppressedExceptions) {\n                    this.suppressedExceptions = null;\n                }\n                // 后置处理，移除正在被实例化的状态\n                this.afterSingletonCreation(beanName);\n            }\n\n            // 新创建的单例，记录到缓存中，并移除中间状态\n            if (newSingleton) {\n                this.addSingleton(beanName, singletonObject);\n            }\n        }\n\n        // 返回实例\n        return singletonObject;\n    }\n}\n```\n\n上述方法的执行逻辑还是很直观的，概括如下：\n\n1. 检测 bean 是否正在被销毁，如果是则期间不允许重新实例化；\n2. 设置 bean 的状态为正在被创建；\n3. 实例化 bean 对象；\n4. 移除 bean 的正在被创建状态；\n5. 将新创建的 bean 实例记录到缓存，并返回该实例。\n\n步骤 3 中的实例化 bean 是整个流程的关键所在，这里调用了 `ObjectFactory#getObject` 方法，由传入的参数我们可以知道该方法的实现如下：\n\n```java\nthis.getSingleton(beanName, () -> {\n    try {\n        return this.createBean(beanName, mbd, args);\n    } catch (BeansException ex) {\n        // Explicitly remove instance from singleton cache: It might have been put there\n        // eagerly by the creation process, to allow for circular reference resolution.\n        // Also remove any beans that received a temporary reference to the bean.\n        this.destroySingleton(beanName); // 清理工作，从单例缓存中移除\n        throw ex;\n    }\n});\n```\n\n所以实例化 bean 的真正逻辑位于 `AbstractAutowireCapableBeanFactory#createBean` 方法中，实现如下：\n\n```java\nprotected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args)\n        throws BeanCreationException {\n\n    if (logger.isTraceEnabled()) {\n        logger.trace(\"Creating instance of bean '\" + beanName + \"'\");\n    }\n    RootBeanDefinition mbdToUse = mbd;\n\n    // 1.根据设置的 class 属性或 className 解析得到对应的 Class 引用\n    Class<?> resolvedClass = this.resolveBeanClass(mbd, beanName);\n    if (resolvedClass != null && !mbd.hasBeanClass() && mbd.getBeanClassName() != null) {\n        mbdToUse = new RootBeanDefinition(mbd);\n        mbdToUse.setBeanClass(resolvedClass);\n    }\n\n    // 2.校验 lookup-method 和 replaced-method 标签应用的方法是否存在\n    try {\n        mbdToUse.prepareMethodOverrides();\n    } catch (BeanDefinitionValidationException ex) {\n        throw new BeanDefinitionStoreException(\n                mbdToUse.getResourceDescription(), beanName, \"Validation of method overrides failed\", ex);\n    }\n\n    // 3. 应用 InstantiationAwareBeanPostProcessor 处理器\n    try {\n        // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.\n        Object bean = this.resolveBeforeInstantiation(beanName, mbdToUse);\n        // 如果在处理器中已经完成了对 bean 的实例化操作，则直接返回\n        if (bean != null) {\n            return bean;\n        }\n    } catch (Throwable ex) {\n        throw new BeanCreationException(\n                mbdToUse.getResourceDescription(), beanName, \"BeanPostProcessor before instantiation of bean failed\", ex);\n    }\n\n    // 4. 创建 bean 实例\n    try {\n        Object beanInstance = this.doCreateBean(beanName, mbdToUse, args);\n        if (logger.isTraceEnabled()) {\n            logger.trace(\"Finished creating instance of bean '\" + beanName + \"'\");\n        }\n        return beanInstance;\n    } catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) {\n        // A previously detected exception with proper bean creation context already,\n        // or illegal singleton state to be communicated up to DefaultSingletonBeanRegistry.\n        throw ex;\n    } catch (Throwable ex) {\n        throw new BeanCreationException(\n                mbdToUse.getResourceDescription(), beanName, \"Unexpected exception during bean creation\", ex);\n    }\n}\n```\n\n该方法虽然名字叫 createBean，顾名思义是创建 bean 实例的地方，通过调用 `AbstractAutowireCapableBeanFactory#doCreateBean` 方法完成对 bean 的实例化。不过，在开始执行创建之前，该方法还做了一些前期准备工作，具体流程如代码注释，下面针对各个过程逐一分析。\n\n#### 解析 Class 引用\n\n不知道你是否还记得，在分析标签解析的过程中对于 class 属性的解析，如果参数中传入了类加载器则会尝试获取对应的 Class 引用，否则直接记录类的全称类名。对于前者而言，这里的解析就是直接返回 Class 引用对象即可，而对于后者则需要解析获取对应的 Class 引用。相关实现位于 `AbstractBeanFactory#resolveBeanClass` 方法中，如下：\n\n```java\nprotected Class<?> resolveBeanClass(final RootBeanDefinition mbd, String beanName, final Class<?>... typesToMatch)\n        throws CannotLoadBeanClassException {\n\n    try {\n        // 如果之前直接存储的是 Class 引用，则直接返回\n        if (mbd.hasBeanClass()) {\n            return mbd.getBeanClass();\n        }\n\n        // 否则由 className 解析得到对应的 Class 引用\n        if (System.getSecurityManager() != null) {\n            return AccessController.doPrivileged((PrivilegedExceptionAction<Class<?>>) () ->\n                    this.doResolveBeanClass(mbd, typesToMatch), this.getAccessControlContext());\n        } else {\n            return this.doResolveBeanClass(mbd, typesToMatch);\n        }\n    }\n    // ... 省略异常处理\n}\n```\n\n逻辑很清晰，如果 BeanDefinition 实例中记录已经是 Class 引用，则直接返回即可；否则需要进行解析，具体由 `AbstractBeanFactory#doResolveBeanClass` 方法实现，该方法会验证类全称类名，并利用类加载器解析获取对应的 Class 引用，具体实现不再展开。\n\n#### 校验 override 方法\n\nSpring 中并不存在 `<override-method />` 标签，这里的 override 指的是 `<lookup-method/>` 和 `<replaced-method/>` 这两个标签。之前解析这两个标签时是将标签配置以 MethodOverride 对象的形式记录在 `AbstractBeanDefinition#methodOverrides` 属性中，而这里的处理逻辑主要是逐一检查被覆盖的方法是否真实存在，如果不存在则说明配置不合法，需要抛出异常；如果存在唯一的方法版本则说明覆盖是明确的，标记 `MethodOverride#overloaded` 为 false 表明后期无需再依据参数类型和个数进行推测：\n\n```java\npublic void prepareMethodOverrides() throws BeanDefinitionValidationException {\n    // Check that lookup methods exist and determine their overloaded status.\n    if (this.hasMethodOverrides()) {\n        // 获取之前解析的 <lookup-method/> 和 <replaced-method/> 标签配置，并逐一应用 prepareMethodOverride 方法\n        this.getMethodOverrides().getOverrides().forEach(this::prepareMethodOverride);\n    }\n}\n\nprotected void prepareMethodOverride(MethodOverride mo) throws BeanDefinitionValidationException {\n    // 获取指定类中指定方法的个数\n    int count = ClassUtils.getMethodCountForName(this.getBeanClass(), mo.getMethodName());\n    // 该类并未定义相应名称的方法\n    if (count == 0) {\n        throw new BeanDefinitionValidationException(\n                \"Invalid method override: no method with name '\" + mo.getMethodName() + \"' on class [\" + this.getBeanClassName() + \"]\");\n    }\n    // 该类仅定义了唯一一个相应名称的方法\n    else if (count == 1) {\n        /*\n         * 标记 MethodOverride 暂未被重载，避免参数类型检查的开销\n         *\n         * 如果一个方法存在多个重载版本，那么在调用及增强的时候还需要根据参数类型进行匹配来确认最终调用的方法版本，\n         * 如果方法未被重载，也就是对应这里的只有一个版本，就在设置重载标识为 false，后续可以直接定位方法\n         */\n        mo.setOverloaded(false);\n    }\n}\n```\n\n#### 实例化前置处理\n\nInstantiationAwareBeanPostProcessor 处理器一般在做基于 Spring 的基础组件研发时用的比较多，先来介绍一下该处理器的作用。该处理器的接口定义如下：\n\n```java\npublic interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor {\n\n    /** 实例化 bean 前调用，是对 bean 定义进行修改的最后机会 */\n    default Object postProcessBeforeInstantiation(Class<?> beanClass, String beanName) throws BeansException {\n        return null;\n    }\n\n    /** 实例化 bean 后立即调用，位于属性注入之前 */\n    default boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException {\n        return true;\n    }\n\n    /** 在将属性注入 bean 实例前对属性进行处理 */\n    default PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName)\n            throws BeansException {\n        return null;\n    }\n\n    /** 该方法已过期，功能同 postProcessProperties */\n    default PropertyValues postProcessPropertyValues(\n            PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException {\n        return pvs;\n    }\n\n}\n```\n\n由代码注释还是能够清晰的知道这个处理器的功能的。接口中定义的方法紧挨着 bean 实例化的过程，如果我们希望在实例化前后对 bean 对象应用一些修改，可以通过实现该接口并注册到 BeanFactory 中。不过需要注意一点的是处理器会对所有的 bean 实例生效，需要处理好筛选的逻辑。\n\n继续分析对于 InstantiationAwareBeanPostProcessor 处理器的执行逻辑。Spring 首先会去解析 bean 所属的真正 Class 引用，因为可能存在一些工厂 bean，而具体的 bean 类型还需要通过工厂方法去推测。相关实现位于 `AbstractAutowireCapableBeanFactory#resolveBeforeInstantiation` 方法中：\n\n```java\nprotected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) {\n    Object bean = null;\n    // 如果 bean 尚未实例化\n    if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) {\n        // 当前 bean 不是合成的，且注册了 InstantiationAwareBeanPostProcessor\n        if (!mbd.isSynthetic() && this.hasInstantiationAwareBeanPostProcessors()) {\n            // 获取最终的 Class 引用，如果是工厂方法则获取工厂所创建的实例类型\n            Class<?> targetType = this.determineTargetType(beanName, mbd);\n            if (targetType != null) {\n                // 应用实例化前置处理\n                bean = this.applyBeanPostProcessorsBeforeInstantiation(targetType, beanName);\n                if (bean != null) {\n                    // 应用实例初始化后置处理\n                    bean = this.applyBeanPostProcessorsAfterInitialization(bean, beanName);\n                }\n            }\n        }\n        // 标识对于当前 bean 已经应用过该处理器，避免重复应用\n        mbd.beforeInstantiationResolved = (bean != null);\n    }\n    return bean;\n}\n```\n\n接着就是调用注册的 InstantiationAwareBeanPostProcessor 处理器在创建 bean 实例之前对 BeanDefinition 进行前置处理，具体实现如下：\n\n```java\n// 应用实例化前置处理\nprotected Object applyBeanPostProcessorsBeforeInstantiation(Class<?> beanClass, String beanName) {\n    // 遍历应用注册的 InstantiationAwareBeanPostProcessor 的 postProcessBeforeInstantiation 方法\n    for (BeanPostProcessor bp : this.getBeanPostProcessors()) {\n        if (bp instanceof InstantiationAwareBeanPostProcessor) {\n            InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;\n            Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName);\n            if (result != null) {\n                return result;\n            }\n        }\n    }\n    return null;\n}\n```\n\n如果 InstantiationAwareBeanPostProcessor 在执行前置处理期间完成了对 bean 的实例化操作，则会触发执行 `InstantiationAwareBeanPostProcessor#postProcessAfterInitialization` 方法（如下），该方法会在完成对 bean 实例的初始化操作之后被调用，而这里对于 bean 实例的创建和初始化均在 `InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation` 中已完成。\n\n```java\npublic Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException {\n    Object result = existingBean;\n    // 遍历应用注册的 InstantiationAwareBeanPostProcessor 的 postProcessAfterInitialization 方法\n    for (BeanPostProcessor processor : this.getBeanPostProcessors()) {\n        Object current = processor.postProcessAfterInitialization(result, beanName);\n        if (current == null) {\n            return result;\n        }\n        result = current;\n    }\n    return result;\n}\n```\n\n注意这两个方法的后缀一个是 Instantiation，另一个是 Initialization，前者表示创建 bean 实例，后者表示对创建的 bean 实例执行初始化操作。\n\n#### 创建 bean 实例\n\n如果在 `InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation` 方法中完成了实例化 bean 的过程，则直接返回相应的 bean 实例即可，否则就需要继续执行创建 bean 实例的过程，并且大部分 bean 实例都是在这一步完成创建的。实例化 bean 的逻辑还是相当复杂的，由 `AbstractAutowireCapableBeanFactory#doCreateBean` 方法实现，如下：\n\n```java\nprotected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args)\n        throws BeanCreationException {\n\n    /* 1. 采用合适的方式创建 bean 对象 */\n\n    // 尝试获取对应的 FactoryBean 的 BeanWrapper 对象，如果存在则基于对应的 FactoryBean 创建 bean 对象\n    BeanWrapper instanceWrapper = null;\n    if (mbd.isSingleton()) {\n        instanceWrapper = this.factoryBeanInstanceCache.remove(beanName);\n    }\n\n    // 如果对应的 FactoryBean 不存在，则采用适当的策略实例化 bean 对象\n    if (instanceWrapper == null) {\n        /*\n         * 采用一定的策略创建 bean 实例：\n         *\n         * 1. 如果设置了 instanceSupplier 回调，则基于该 Supplier 获取 bean 对象；\n         * 2. 否则，如果指定了工厂方法，则使用工厂方法创建 bean 对象；\n         * 3. 否则，调用相应的构造方法创建 bean 对象。\n         */\n        instanceWrapper = this.createBeanInstance(beanName, mbd, args);\n    }\n    // 获取 bean 实例\n    final Object bean = instanceWrapper.getWrappedInstance();\n    // 获取 bean 实例对应的 Class 对象\n    Class<?> beanType = instanceWrapper.getWrappedClass();\n    if (beanType != NullBean.class) {\n        mbd.resolvedTargetType = beanType;\n    }\n\n    // 2. 应用 MergedBeanDefinitionPostProcessor 处理器\n    synchronized (mbd.postProcessingLock) {\n        if (!mbd.postProcessed) {\n            try {\n                // 应用 postProcessMergedBeanDefinition 方法，@Autowired 注解即依赖此处理器实现\n                this.applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);\n            } catch (Throwable ex) {\n                throw new BeanCreationException(mbd.getResourceDescription(), beanName,\n                        \"Post-processing of merged bean definition failed\", ex);\n            }\n            mbd.postProcessed = true;\n        }\n    }\n\n    // 3. 检查是否需要提前曝光 bean 实例，用于解决循环依赖\n    boolean earlySingletonExposure = (mbd.isSingleton() // 单例\n            && this.allowCircularReferences // 允许自动解决循环依赖\n            && this.isSingletonCurrentlyInCreation(beanName)); // 当前 bean 正在创建中\n    if (earlySingletonExposure) {\n        if (logger.isTraceEnabled()) {\n            logger.trace(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\");\n        }\n        // 为避免循环依赖，在完成 bean 实例化之前，将对应的 ObjectFactory 注册到容器中\n        this.addSingletonFactory(beanName,\n                // 获取 bean 的提前引用\n                () -> this.getEarlyBeanReference(beanName, mbd, bean));\n    }\n\n    // 4. 初始化 bean 实例\n    Object exposedObject = bean;\n    try {\n        // 对 bean 进行填充，注入各个属性值，如果存在依赖的 bean 则递归初始化\n        this.populateBean(beanName, mbd, instanceWrapper);\n        // 初始化 bean，调用初始化方法，比如 init-method\n        exposedObject = this.initializeBean(beanName, exposedObject, mbd);\n    } catch (Throwable ex) {\n        if (ex instanceof BeanCreationException && beanName.equals(((BeanCreationException) ex).getBeanName())) {\n            throw (BeanCreationException) ex;\n        } else {\n            throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Initialization of bean failed\", ex);\n        }\n    }\n\n    // 5. 基于依赖关系验证是否存在循环依赖\n    if (earlySingletonExposure) {\n        // 获取 bean 实例\n        Object earlySingletonReference = this.getSingleton(beanName, false);\n        if (earlySingletonReference != null) {\n            if (exposedObject == bean) {\n                exposedObject = earlySingletonReference;\n            }\n            // 如果不允许注入 raw bean 实例 && 存在依赖的 bean\n            else if (!this.allowRawInjectionDespiteWrapping && this.hasDependentBean(beanName)) {\n                // 获取依赖的 bean 的 beanName 集合\n                String[] dependentBeans = this.getDependentBeans(beanName);\n                Set<String> actualDependentBeans = new LinkedHashSet<>(dependentBeans.length);\n                // 遍历逐个检测依赖的 bean 实例，记录未完成创建的 bean 实例\n                for (String dependentBean : dependentBeans) {\n                    if (!this.removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) {\n                        actualDependentBeans.add(dependentBean);\n                    }\n                }\n                /*\n                 * 因为 bean 在实例化完成之后，其依赖的 bean 实例一定也是完成实例化的，\n                 * 如果 actualDependentBeans 不为空，则说明依赖的 bean 实例没有完成创建，存在循环依赖\n                 */\n                if (!actualDependentBeans.isEmpty()) {\n                    throw new BeanCurrentlyInCreationException(beanName,\n                            \"Bean with name '\" + beanName + \"' has been injected into other beans [\" +\n                                    StringUtils.collectionToCommaDelimitedString(actualDependentBeans) +\n                                    \"] in its raw version as part of a circular reference, but has eventually been \" +\n                                    \"wrapped. This means that said other beans do not use the final version of the \" +\n                                    \"bean. This is often the result of over-eager type matching - consider using \" +\n                                    \"'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example.\");\n                }\n            }\n        }\n    }\n\n    // 6. 注册销毁机制\n    try {\n        this.registerDisposableBeanIfNecessary(beanName, bean, mbd);\n    } catch (BeanDefinitionValidationException ex) {\n        throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex);\n    }\n\n    return exposedObject;\n}\n```\n\n上述方法的执行流程可以概括为：\n\n1. 采用合适的策略创建 bean 实例；\n2. 如果注册了 BeanDefinition 处理器，则在初始化 bean 实例之前对相应的 BeanDefinition 实例进行修改；\n3. 如果允许自动解决循环依赖，则提前曝光 bean 实例；\n4. 初始化 bean 实例，执行属性注入，调用初始化方法；\n5. 基于依赖关系验证是否存在未完成初始化的 bean 实例，如果存在则说明存在无法解决的循环依赖，抛出异常；\n6. 为实现了销毁逻辑的 bean 注册销毁机制。\n\n下面逐步展开分析。首先来看 __步骤一__ ，这一步主要用于创建 bean 对象，Spring 在内部定义了 BeanWrapper 接口，用于对 bean 实例进行封装和操作。关于创建 bean 对象的过程，Spring 采取的策略如下：\n\n1. 如果是 FactoryBean，则基于 FactoryBean 对象获取最终 bean 实例；\n2. 否则，如果设置了 instanceSupplier 回调，则调用 `Supplier#get` 方法获取 bean 实例；\n3. 否则，如果指定了工厂方法，则调用工厂方法创建 bean 实例；\n4. 否则，基于参数调用确定版本的构造方法创建 bean 实例。\n\n上述过程的后三步由 `AbstractAutowireCapableBeanFactory#createBeanInstance` 方法实现，如下：\n\n```java\nprotected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) {\n    // 解析 Class 对象\n    Class<?> beanClass = this.resolveBeanClass(mbd, beanName);\n    // 不是 public 类，或者对应的构造方法不能访问\n    if (beanClass != null && !Modifier.isPublic(beanClass.getModifiers()) && !mbd.isNonPublicAccessAllowed()) {\n        throw new BeanCreationException(mbd.getResourceDescription(), beanName,\n                \"Bean class isn't public, and non-public access not allowed: \" + beanClass.getName());\n    }\n\n    // 1. 如果设置了 instanceSupplier，则调用 Supplier#get 获取 bean 实例\n    Supplier<?> instanceSupplier = mbd.getInstanceSupplier();\n    if (instanceSupplier != null) {\n        return this.obtainFromSupplier(instanceSupplier, beanName);\n    }\n\n    // 2. 如果指定了工厂方法，则使用工厂方法创建 bean 实例\n    if (mbd.getFactoryMethodName() != null) {\n        return this.instantiateUsingFactoryMethod(beanName, mbd, args);\n    }\n\n    // 3. 解析并确定构造方法版本，调用构造方法创建 bean 实例\n    boolean resolved = false;\n    boolean autowireNecessary = false;\n    if (args == null) {\n        synchronized (mbd.constructorArgumentLock) {\n            if (mbd.resolvedConstructorOrFactoryMethod != null) {\n                resolved = true;\n                autowireNecessary = mbd.constructorArgumentsResolved;\n            }\n        }\n    }\n    // 之前已经解析过构造方法版本，直接复用，避免重复解析\n    if (resolved) {\n        // 使用之前确定的构造方法版本\n        if (autowireNecessary) {\n            return this.autowireConstructor(beanName, mbd, null, null);\n        }\n        // 使用默认构造方法\n        else {\n            return this.instantiateBean(beanName, mbd);\n        }\n    }\n\n    // 依据参数决定使用哪个构造方法\n    Constructor<?>[] ctors = this.determineConstructorsFromBeanPostProcessors(beanClass, beanName);\n    if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR\n            || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) {\n        return this.autowireConstructor(beanName, mbd, ctors, args);\n    }\n\n    // 解析构造方法失败，使用首选的构造方法，如果有指定的话\n    ctors = mbd.getPreferredConstructors();\n    if (ctors != null) {\n        return this.autowireConstructor(beanName, mbd, ctors, null);\n    }\n\n    // 使用默认的构造方法\n    return this.instantiateBean(beanName, mbd);\n}\n```\n\n下面进一步说明一下基于工厂方法和基于构造方法创建 bean 对象的过程。如果在配置时使用 factory-method 属性指明了工厂方法，则 Spring 在初始化 IoC 容器时会调用 `AbstractAutowireCapableBeanFactory#instantiateUsingFactoryMethod` 方法创建 bean 实例，该方法的实现比较冗长，故不在此贴出。总结来说，该方法的主要执行流程如下：\n\n1. 确定当前使用的是静态工厂配置，还是非静态工厂配置；\n2. 基于参数类型和个数确定用于实例化 bean 的工厂方法版本；\n3. 调用工厂方法创建 bean 对象。\n\n其中最复杂的是第二步，因为可能存在多个工厂方法的重载版本，所以需要依据给定或配置的参数个数和类型去解析确定具体使用哪个工厂方法。Spring 会对所有的候选工厂方法按照 public 优先，以及参数个数多的方法优先的原则进行排序，然后逐个比对是否满足当前指定的参数列表，依次确定具体使用哪个工厂方法创建 bean 实例。基于构造方法创建 bean 对象的过程与上述过程大同小异，核心都是基于参数个数和类型确定最终调用的方法版本，不再展开。\n\n需要清楚的一点是，经过上述过程创建的 bean 实例，不管是通过工厂方法还是构造方法，到这里得到 bean 实例也仅仅是一个最初实例，接下去还需要对该实例进行初始化，注入相应的属性值等。如果将此时的 bean 实例看作是一张白纸，那么初始化操作就可以类比在白纸上作画，而颜料就是之前解析得到的 BeanDefinition 对象。Spring 定义了 MergedBeanDefinitionPostProcessor 处理器接口，允许用户在容器执行初始化操作之前对最终的 BeanDefinition 对象进行修改。\n\n__步骤二__ 所做的工作就是应用 MergedBeanDefinitionPostProcessor 处理器，相应的实现位于 `AbstractAutowireCapableBeanFactory#applyMergedBeanDefinitionPostProcessors` 方法中：\n\n```java\nprotected void applyMergedBeanDefinitionPostProcessors(RootBeanDefinition mbd, Class<?> beanType, String beanName) {\n    // 获取并遍历所有的后置处理器\n    for (BeanPostProcessor bp : this.getBeanPostProcessors()) {\n        // 如果是 MergedBeanDefinitionPostProcessor，则进行应用 postProcessMergedBeanDefinition 方法\n        if (bp instanceof MergedBeanDefinitionPostProcessor) {\n            MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp;\n            bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName);\n        }\n    }\n}\n```\n\n对于 singleton 类型对象而言， __步骤三__ 会提前曝光 bean 实例，Spring 基于该机制尝试自动解决循环依赖问题。循环依赖可能发生在构造方法注入过程中，也可能发生在 setter 方法注入过程中，对于前者来说 Spring 是无法解决的，对于后者则可以通过提前曝光机制达到“先引用，后初始化”的目的，从而巧妙的破解环路。提前曝光机制的实现如下：\n\n```java\nboolean earlySingletonExposure = (mbd.isSingleton() // 单例\n        && this.allowCircularReferences // 允许自动解决循环依赖\n        && this.isSingletonCurrentlyInCreation(beanName)); // 当前 bean 正在创建中\nif (earlySingletonExposure) {\n    if (logger.isTraceEnabled()) {\n        logger.trace(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\");\n    }\n    // 为避免循环依赖，在完成 bean 实例化之前，将对应的 ObjectFactory 注册到容器中\n    this.addSingletonFactory(beanName,\n            // 获取 bean 的提前引用\n            () -> this.getEarlyBeanReference(beanName, mbd, bean));\n}\n\n// org.springframework.beans.factory.support.DefaultSingletonBeanRegistry#addSingletonFactory\nprotected void addSingletonFactory(String beanName, ObjectFactory<?> singletonFactory) {\n    Assert.notNull(singletonFactory, \"Singleton factory must not be null\");\n    synchronized (this.singletonObjects) {\n        if (!this.singletonObjects.containsKey(beanName)) {\n            this.singletonFactories.put(beanName, singletonFactory);\n            this.earlySingletonObjects.remove(beanName);\n            this.registeredSingletons.add(beanName);\n        }\n    }\n}\n```\n\n说明一下上述方法中几个变量的含义：\n\n- singletonObjects：用于记录 beanName 和 bean 实例之间的映射关系。\n- singletonFactories：用于记录 beanName 和创建 bean 的工厂 ObjectFactory 对象之间的映射关系。\n- earlySingletonObjects：也是记录 beanName 和 bean 实例之间的映射关系，不同于 singletonObjects，其中记录的 bean 实例在创建过程中就可以通过 getBean 方法获取到。\n- registeredSingletons：用来记录当前所有已注册的 beanName，按照注册顺序存放。\n\n提前曝光也就是在初始化 bean 对象之前曝光该对象，其目的是先创建好对象，再建立依赖关系，将这两步拆分开以破解依赖环路。当初始化一个 bean 对象时，如果引用了另外一个 bean 对象，此时就需要转而去创建并初始化引用的 bean 对象，如果恰好该 bean 对象又引用了之前的 bean 对象就出现了循环依赖。假设我们令第一个 bean 为 A，第二个 bean 为 B，基于这段代码的执行逻辑，B 就可以先给自己类型为 A 的属性注入 A 的实例（这个时候 A 还没有被初始化）然后完成初始化，此时继续回到初始化 A 的逻辑，因为都是单例，所以当 A 完成了初始化之后，B 所引用的 A 对象也就是一个完成了初始化过程的对象，而不是之前的刚刚完成创建还没有注入属性的对象。\n\n__步骤四__ 实现了对上面创建的 bean 实例执行初始化的逻辑，包括 __属性注入__ 和 __调用初始化方法__ 两个步骤。先来分析属性注入的过程，该过程由 `AbstractAutowireCapableBeanFactory#populateBean` 方法实现（populate，这个词很有想象力~）：\n\n```java\nprotected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) {\n    // 未创建 bean 对象\n    if (bw == null) {\n        // 但是存在需要注入的属性\n        if (mbd.hasPropertyValues()) {\n            throw new BeanCreationException(\n                    mbd.getResourceDescription(), beanName, \"Cannot apply property values to null instance\");\n        } else {\n            // Skip property population phase for null instance.\n            return;\n        }\n    }\n\n    // 调用 InstantiationAwareBeanPostProcessor#postProcessAfterInstantiation 方法对初始化前的 bean 实例进行处理\n    if (!mbd.isSynthetic() && this.hasInstantiationAwareBeanPostProcessors()) {\n        for (BeanPostProcessor bp : this.getBeanPostProcessors()) {\n            if (bp instanceof InstantiationAwareBeanPostProcessor) {\n                InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;\n                if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) {\n                    return;\n                }\n            }\n        }\n    }\n\n    // 获取 bean 实例的属性值集合\n    PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null);\n\n    // 获取注入类型\n    int resolvedAutowireMode = mbd.getResolvedAutowireMode();\n    if (resolvedAutowireMode == AUTOWIRE_BY_NAME || resolvedAutowireMode == AUTOWIRE_BY_TYPE) {\n        MutablePropertyValues newPvs = new MutablePropertyValues(pvs);\n        // 根据名称注入\n        if (resolvedAutowireMode == AUTOWIRE_BY_NAME) {\n            this.autowireByName(beanName, mbd, bw, newPvs);\n        }\n        // 根据类型注入\n        if (resolvedAutowireMode == AUTOWIRE_BY_TYPE) {\n            this.autowireByType(beanName, mbd, bw, newPvs);\n        }\n        pvs = newPvs;\n    }\n\n    boolean hasInstAwareBpps = this.hasInstantiationAwareBeanPostProcessors();\n    boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE);\n\n    // 应用 InstantiationAwareBeanPostProcessor#postProcessProperties 方法在注入属性之前对属性值进行处理\n    PropertyDescriptor[] filteredPds = null;\n    if (hasInstAwareBpps) {\n        if (pvs == null) {\n            pvs = mbd.getPropertyValues();\n        }\n        for (BeanPostProcessor bp : this.getBeanPostProcessors()) {\n            if (bp instanceof InstantiationAwareBeanPostProcessor) {\n                InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;\n                PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName);\n                if (pvsToUse == null) {\n                    if (filteredPds == null) {\n                        filteredPds = this.filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);\n                    }\n                    // 兼容已过期的方法\n                    pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName);\n                    // 处理器把属性值处理没了，继续执行属性注入已经没有意义，直接返回\n                    if (pvsToUse == null) {\n                        return;\n                    }\n                }\n                pvs = pvsToUse;\n            }\n        }\n    }\n\n    // 依赖检查，对应 dependency-check 属性，该属性已过期\n    if (needsDepCheck) {\n        if (filteredPds == null) {\n            filteredPds = this.filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);\n        }\n        this.checkDependencies(beanName, mbd, filteredPds, pvs);\n    }\n\n    // 执行属性注入\n    if (pvs != null) {\n        this.applyPropertyValues(beanName, mbd, bw, pvs);\n    }\n}\n```\n\n上述方法会执行 `InstantiationAwareBeanPostProcessor#postProcessAfterInstantiation` 后置处理方法，以实现对完成创建但还未注入属性值的对象进行最后的更改。如果该方法指明不需要执行后续的属性注入过程，则运行到此结束；否则方法会检测当前的注入类型是 `byName` 还是 `byType`，并执行对应的注入逻辑获取依赖的属性值。在真正执行注入之前，还会应用 `InstantiationAwareBeanPostProcessor#postProcessProperties` 处理方法对待注入的属性值执行最后的修改，并依据配置决定是否执行依赖检查，以确保所有的属性都被赋值（这里的赋值是指 BeanDefinition 对象中的属性都有对应的值，而不是指最终 bean 实例的属性是否注入了对应的值）。最后将属性值注入给 bean 实例对应的属性中。\n\n整个流程还是比较清晰的，下面进一步分析基于 name 或 type 解析属性值，以及注入属性值的过程。\n\n- __基于 name 解析属性值__\n\n如果当前注入类型是 `byName`，则容器会基于 beanName 获取依赖的 bean 实例，并将依赖关系记录到对应的集合中，如果依赖的 bean 未被实例化则需要转而执行实例化。基于 name 解析属性值的过程由 `AbstractAutowireCapableBeanFactory#autowireByName` 方法实现：\n\n```java\nprotected void autowireByName(\n        String beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) {\n    // 获取需要注入的属性名称集合\n    String[] propertyNames = this.unsatisfiedNonSimpleProperties(mbd, bw);\n    for (String propertyName : propertyNames) {\n        // 当前属性是由容器管理\n        if (this.containsBean(propertyName)) {\n            // 获取 bean 实例，如果没有实例化则执行实例化操作\n            Object bean = this.getBean(propertyName);\n            // 记录到属性集合中\n            pvs.add(propertyName, bean);\n            // 记录 bean 之间的依赖关系\n            this.registerDependentBean(propertyName, beanName);\n        } else {\n            // ... 省略日志打印\n        }\n    }\n}\n```\n\n- __基于 type 解析属性值__\n\n如果当前注入类型是 `byType`，则容器会依据属性类型去确定依赖的 bean 实例，并将依赖关系记录到对应的集合中，如果依赖的 bean 未被实例化则需要转而执行实例化。因为类型注入需要有一个推断的过程，所以实现逻辑要复杂很多，位于 `AbstractAutowireCapableBeanFactory#autowireByType` 方法中：\n\n```java\nprotected void autowireByType(\n        String beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) {\n\n    TypeConverter converter = this.getCustomTypeConverter();\n    if (converter == null) {\n        converter = bw;\n    }\n\n    Set<String> autowiredBeanNames = new LinkedHashSet<>(4);\n    // 获取需要注入的属性名称集合\n    String[] propertyNames = this.unsatisfiedNonSimpleProperties(mbd, bw);\n    for (String propertyName : propertyNames) {\n        try {\n            PropertyDescriptor pd = bw.getPropertyDescriptor(propertyName);\n            // Don't try autowiring by type for type Object: never makes sense,\n            // even if it technically is a unsatisfied, non-simple property.\n            if (Object.class != pd.getPropertyType()) {\n                // 获取对应的 setter 方法\n                MethodParameter methodParam = BeanUtils.getWriteMethodParameter(pd);\n                // Do not allow eager init for type matching in case of a prioritized post-processor.\n                boolean eager = !(bw.getWrappedInstance() instanceof PriorityOrdered);\n                DependencyDescriptor desc = new AutowireByTypeDependencyDescriptor(methodParam, eager);\n                /*\n                 * 解析指定 beanName 属性所匹配的值，并把解析到的属性存储在 autowiredBeanNames 中，当属性存在多个候选 bean 时，比如：\n                 *\n                 * @Autowired\n                 * private List<A> list\n                 *\n                 * 则会注入找到的所有匹配 A 类型的 bean 实例\n                 */\n                Object autowiredArgument = this.resolveDependency(desc, beanName, autowiredBeanNames, converter);\n                // 记录到属性集合中\n                if (autowiredArgument != null) {\n                    pvs.add(propertyName, autowiredArgument);\n                }\n                // 记录 bean 之间的依赖关系\n                for (String autowiredBeanName : autowiredBeanNames) {\n                    this.registerDependentBean(autowiredBeanName, beanName);\n                }\n                autowiredBeanNames.clear();\n            }\n        } catch (BeansException ex) {\n            throw new UnsatisfiedDependencyException(mbd.getResourceDescription(), beanName, propertyName, ex);\n        }\n    }\n}\n\npublic Object resolveDependency(DependencyDescriptor descriptor,\n                                @Nullable String requestingBeanName,\n                                @Nullable Set<String> autowiredBeanNames,\n                                @Nullable TypeConverter typeConverter) throws BeansException {\n\n    // 获取并初始化参数名称探测器\n    descriptor.initParameterNameDiscovery(this.getParameterNameDiscoverer());\n    // 支持 java8 的 Optional\n    if (Optional.class == descriptor.getDependencyType()) {\n        return this.createOptionalDependency(descriptor, requestingBeanName);\n    }\n    // 对应 ObjectFactory 类注入的特殊处理\n    else if (ObjectFactory.class == descriptor.getDependencyType()\n            || ObjectProvider.class == descriptor.getDependencyType()) {\n        return new DependencyObjectProvider(descriptor, requestingBeanName);\n    }\n    // 支持 javax.inject.Provider\n    else if (javaxInjectProviderClass == descriptor.getDependencyType()) {\n        return new Jsr330Factory().createDependencyProvider(descriptor, requestingBeanName);\n    }\n    // 通用处理逻辑\n    else {\n        Object result = this.getAutowireCandidateResolver().getLazyResolutionProxyIfNecessary(descriptor, requestingBeanName);\n        if (result == null) {\n            result = this.doResolveDependency(descriptor, requestingBeanName, autowiredBeanNames, typeConverter);\n        }\n        return result;\n    }\n}\n```\n\n对于通用处理逻辑而言，Spring 的解析过程如下：\n\n1. 以确定的 `@Value` 注解和集合类型进行解析，如果不是这些类型则获取匹配类型的 bean 实例集合；\n2. 如果存在多个匹配项则尝试以优先级配置（比如 Primary 或 Priority）确定首选的 bean 实例，否则无需做推断逻辑；\n3. 检测当前解析得到的 bean 是不是期望的 bean 实例，如果是工厂之类的 bean，则还要继续获取工厂所创建的 bean 实例。\n\n- __注入属性值__\n\n执行到这一步才真正将 bean 的所有属性全部注入到 bean 实例中，之前虽然已经创建了实例，但是属性仍存在于 BeanDefinition 实例中。注入的过程由 `AbstractAutowireCapableBeanFactory#applyPropertyValues` 方法实现，该方法会将相应属性转换成目标 bean 实例中对应属性的真实类型，并注入到对应属性上：\n\n```java\nprotected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) {\n    if (pvs.isEmpty()) {\n        return;\n    }\n\n    if (System.getSecurityManager() != null && bw instanceof BeanWrapperImpl) {\n        ((BeanWrapperImpl) bw).setSecurityContext(this.getAccessControlContext());\n    }\n\n    MutablePropertyValues mpvs = null;\n    // 记录待执行类型转换的属性值\n    List<PropertyValue> original;\n\n    if (pvs instanceof MutablePropertyValues) {\n        mpvs = (MutablePropertyValues) pvs;\n        // 之前已经完成了类型转换，直接注入\n        if (mpvs.isConverted()) {\n            // Shortcut: use the pre-converted values as-is.\n            try {\n                bw.setPropertyValues(mpvs);\n                return;\n            } catch (BeansException ex) {\n                throw new BeanCreationException(\n                        mbd.getResourceDescription(), beanName, \"Error setting property values\", ex);\n            }\n        }\n        original = mpvs.getPropertyValueList();\n    } else {\n        original = Arrays.asList(pvs.getPropertyValues());\n    }\n\n    TypeConverter converter = this.getCustomTypeConverter();\n    if (converter == null) {\n        converter = bw;\n    }\n    // 创建属性值解析器\n    BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter);\n\n    // Create a deep copy, resolving any references for values.\n    List<PropertyValue> deepCopy = new ArrayList<>(original.size());\n    boolean resolveNecessary = false;\n    // 遍历属性值，执行类型转换\n    for (PropertyValue pv : original) {\n        // 已经转换过\n        if (pv.isConverted()) {\n            deepCopy.add(pv);\n        }\n        // 未转换，执行类型转换\n        else {\n            String propertyName = pv.getName();\n            Object originalValue = pv.getValue();\n            if (originalValue == AutowiredPropertyMarker.INSTANCE) {\n                Method writeMethod = bw.getPropertyDescriptor(propertyName).getWriteMethod();\n                if (writeMethod == null) {\n                    throw new IllegalArgumentException(\"Autowire marker for property without write method: \" + pv);\n                }\n                originalValue = new DependencyDescriptor(new MethodParameter(writeMethod, 0), true);\n            }\n            Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue);\n            Object convertedValue = resolvedValue;\n            boolean convertible = bw.isWritableProperty(propertyName)\n                    && !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName);\n            // 判定可以转换，执行转换\n            if (convertible) {\n                convertedValue = this.convertForProperty(resolvedValue, propertyName, bw, converter);\n            }\n            // Possibly store converted value in merged bean definition,\n            // in order to avoid re-conversion for every created bean instance.\n            // 转换后的值等于原始值\n            if (resolvedValue == originalValue) {\n                if (convertible) {\n                    pv.setConvertedValue(convertedValue);\n                }\n                deepCopy.add(pv);\n            }\n            // 转换后的类型不是集合和数组类型\n            else if (convertible && originalValue instanceof TypedStringValue\n                    && !((TypedStringValue) originalValue).isDynamic()\n                    && !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) {\n                pv.setConvertedValue(convertedValue);\n                deepCopy.add(pv);\n            }\n            // 未解析完全（对应集合或数组类型），标记需要继续解析\n            else {\n                resolveNecessary = true;\n                deepCopy.add(new PropertyValue(pv, convertedValue));\n            }\n        }\n    }\n\n    // 标记已经全部转换完成\n    if (mpvs != null && !resolveNecessary) {\n        mpvs.setConverted();\n    }\n\n    // 设置属性值，深拷贝\n    try {\n        bw.setPropertyValues(new MutablePropertyValues(deepCopy));\n    } catch (BeansException ex) {\n        throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Error setting property values\", ex);\n    }\n}\n```\n\n完成了属性注入过程，接下来容器会执行指定的 init-method 方法。不过，Spring 并不是单纯的调用一下对应的初始化方法，在 `AbstractAutowireCapableBeanFactory#initializeBean` 实现中主要做了 4 件事情：\n\n1. 激活 bean 实现的 Aware 类，包括 BeanNameAware、BeanClassLoaderAware，以及 BeanFactoryAware；\n2. 应用 `BeanPostProcessor#postProcessBeforeInitialization` 方法，实现初始化前置处理；\n3. 调用用户自定义的 init-method 方法，以及常用的 `InitializingBean#afterPropertiesSet` 方法；\n4. 应用 `BeanPostProcessor#postProcessAfterInitialization` 方法，实现初始化后置处理。\n\n方法实现如下：\n\n```java\nprotected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) {\n    // 1. 激活 bean 实现的 Aware 类：BeanNameAware, BeanClassLoaderAware, BeanFactoryAware\n    if (System.getSecurityManager() != null) {\n        AccessController.doPrivileged((PrivilegedAction<Object>) () -> {\n            this.invokeAwareMethods(beanName, bean);\n            return null;\n        }, this.getAccessControlContext());\n    } else {\n        this.invokeAwareMethods(beanName, bean);\n    }\n\n    // 2. 应用 BeanPostProcessor#postProcessBeforeInitialization 方法\n    Object wrappedBean = bean;\n    if (mbd == null || !mbd.isSynthetic()) {\n        wrappedBean = this.applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);\n    }\n\n    // 3. 调用用户自定义的 init-method 方法，以及常用的 afterPropertiesSet 方法\n    try {\n        this.invokeInitMethods(beanName, wrappedBean, mbd);\n    } catch (Throwable ex) {\n        throw new BeanCreationException((mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex);\n    }\n\n    // 应用 BeanPostProcessor#postProcessAfterInitialization 方法\n    if (mbd == null || !mbd.isSynthetic()) {\n        wrappedBean = this.applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);\n    }\n\n    return wrappedBean;\n}\n```\n\n到此，一个 bean 也就基本实例化完成了。在返回该 bean 实例之前，为了确保正确性，Spring 会基于依赖关系检测当前 bean 所依赖的 bean 实例是否都已经实例化完成（ __步骤五__ ），如果存在未完成实例化的 bean 则说明配置存在问题，需要抛出异常。这种情况通常都是循环依赖所导致的，这对于使用 Spring 的正确运行而言是一个极大的隐患，所以需要确保所有实例化的 bean 都完成了对象的创建和初始化过程，否则应用不应该正常启动。\n\n对于配置了 destroy-method 属性的 bean，或者该 bean 实现了 DisposableBean 或 DestructionAwareBeanPostProcessor 接口，那么在返回 bean 实例之前，Spring 还需要为该 bean 注册销毁机制（ __步骤六__ ）。以常用的 DisposableBean 接口为例，当执行销毁一个实现了该接口的 bean 实例时，相应的 `DisposableBean#destroy` 方法会被调用。对应的注册过程由 `AbstractBeanFactory#registerDisposableBeanIfNecessary` 方法实现：\n\n```java\nprotected void registerDisposableBeanIfNecessary(String beanName, Object bean, RootBeanDefinition mbd) {\n    AccessControlContext acc = (System.getSecurityManager() != null ? this.getAccessControlContext() : null);\n    if (!mbd.isPrototype() && this.requiresDestruction(bean, mbd)) {\n        // singleton 类型\n        if (mbd.isSingleton()) {\n            // Register a DisposableBean implementation that performs all destruction\n            // work for the given bean: DestructionAwareBeanPostProcessors, DisposableBean interface, custom destroy method.\n            this.registerDisposableBean(beanName,\n                    new DisposableBeanAdapter(bean, beanName, mbd, this.getBeanPostProcessors(), acc));\n        }\n        // 其它作用域\n        else {\n            // A bean with a custom scope...\n            Scope scope = this.scopes.get(mbd.getScope());\n            if (scope == null) {\n                throw new IllegalStateException(\"No Scope registered for scope name '\" + mbd.getScope() + \"'\");\n            }\n            scope.registerDestructionCallback(beanName,\n                    new DisposableBeanAdapter(bean, beanName, mbd, this.getBeanPostProcessors(), acc));\n        }\n    }\n}\n```\n\n以 singleton 类型为例，如果一个 bean 需要注册销毁机制，那么 Spring 会以 beanName 为 key，以包装销毁逻辑的 DisposableBeanAdapter 对象为 value 记录到 `DefaultSingletonBeanRegistry#disposableBeans` 属性中。当相应的 bean 被销毁时，容器就会尝试获取对应的 DisposableBeanAdapter 实例，并执行销毁逻辑。\n\n### 类型检查和转换\n\n在调用 `BeanFactory#getBean(String name, Class<T> requiredType)` 方法获取 bean 实例，或者做类型检查时，可以指定期望的 bean 类型。如果指定该参数则容器在创建和初始化 bean 对象的最后一步需要执行类型校验，并尝试将 bean 实例转换成期望类型，实现如下：\n\n```java\n// 如果要求做类型检查，则检查 bean 的实际类型是否是期望的类型，对应 getBean 时指定的 requireType\nif (requiredType != null && !requiredType.isInstance(bean)) {\n    try {\n        // 执行类型转换，转换成期望的类型\n        T convertedBean = this.getTypeConverter().convertIfNecessary(bean, requiredType);\n        if (convertedBean == null) {\n            throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());\n        }\n        return convertedBean;\n    } catch (TypeMismatchException ex) {\n        if (logger.isTraceEnabled()) {\n            logger.trace(\"Failed to convert bean '\" + name + \"' to required type '\" +\n                    ClassUtils.getQualifiedName(requiredType) + \"'\", ex);\n        }\n        throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());\n    }\n}\n```\n\n转换的过程还是比较复杂的，鉴于本篇已经写的够长了，就不再展开啦。\n\n### 总结\n\n至此，我们已经完成了对 `BeanFactory#getBean` 完整过程的分析。回顾过去这几篇文章，我们探究了容器加载、解析配置文件得到 BeanDefinition 实例，并基于该实例创建、初始化得到目标 bean 实例的过程。虽然 Spring 暴露的使用方式只有短短几行，但是背后却暗藏着十分复杂的逻辑。实际中我们一般不会直接使用 BeanFactory 操作容器，使用更多的是 ApplicationContext 对象，下一篇我们将继续探究基于 ApplicationContext 的 bean 的加载和初始化过程。\n\n### 参考\n\n1. [Spring 源码深度解析](https://book.douban.com/subject/25866350/)\n","tags":["Spring"],"categories":["spring"]},{"title":"Spring IoC 源码解析：自定义标签的解析过程","url":"/2017/05/19/spring/spring-ioc-custom-element/","content":"\nSpring 中的标签分为默认标签和自定义标签两类，上一篇我们分析了默认标签的解析过程，当然在分析过程中我们也看到默认标签中嵌套了对自定义标签的解析，这是因为默认标签中可以嵌套使用自定义标签。然而，这和本篇所要讨论的自定义标签还是有些区别的，上一篇中介绍的自定义标签可以看作是 `<bean />` 标签的子标签元素，而本篇所要分析的自定义标签是与 `<bean />` 这类标签平级的标签。<!-- more -->\n\n### 自定义标签的定义与使用\n\n在开始分析自定义标签的解析过程之前，我们还是通过示例演示一下自定义标签的定义和使用方式，整体与上一篇所介绍的类似，但还是有些许差别。自定义标签分为 5 步：\n\n1. 创建标签实体类；\n2. 定义标签的描述 XSD 文件；\n3. 创建一个标签元素解析器，实现 BeanDefinitionParser 接口；\n4. 创建一个 handler 类，继承自 NamespaceHandlerSupport 抽象类；\n5. 编写 spring.handlers 和 spring.schemas 文件。\n\n本节我们自定义实现一个与 `<alias />` 标签功能类似的自定义标签，用于为指定的 bean 添加别名。第一步，先创建标签对应的实体类：\n\n```java\npublic class Alias {\n\n    private String name;\n    private String alias;\n\n    // ... 省略 getter 和 setter\n}\n```\n\n第二步，定义标签的 XSD 文件 custom-alias.xsd，如下：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<schema xmlns=\"http://www.w3.org/2001/XMLSchema\"\n        targetNamespace=\"http://www.zhenchao.org/schema/alias\"\n        xmlns:tns=\"http://www.zhenchao.org/schema/alias\"\n        elementFormDefault=\"qualified\">\n    <element name=\"alias\">\n        <complexType>\n            <attribute name=\"id\" type=\"string\"/>\n            <attribute name=\"name\" type=\"string\"/>\n            <attribute name=\"parentName\" type=\"string\"/>\n            <attribute name=\"c_name\" type=\"string\"/>\n            <attribute name=\"c_alias\" type=\"string\"/>\n        </complexType>\n    </element>\n</schema>\n```\n\n第三步，创建标签元素解析器。解析器需要实现 BeanDefinitionParser 接口，这里我们继承该接口的抽象子类 AbstractSingleBeanDefinitionParser，并覆盖相应的方法：\n\n```java\npublic class CustomBeanDefinitionParser extends AbstractSingleBeanDefinitionParser {\n\n    @Override\n    protected Class<?> getBeanClass(Element element) {\n        return Alias.class;\n    }\n\n    @Override\n    protected void doParse(Element element, ParserContext parserContext, BeanDefinitionBuilder builder) {\n        String beanName = element.getAttribute(\"c_name\");\n        Assert.hasText(beanName, \"The 'name' in alias tag is missing!\");\n        Assert.isTrue(parserContext.getRegistry().containsBeanDefinition(beanName), \"No bean name \" + beanName + \" exist!\");\n        String alias = element.getAttribute(\"c_alias\");\n        Assert.hasText(beanName, \"The 'alias' in alias tag is missing!\");\n        String[] aliasArray = alias.replaceAll(\"\\\\s+\", \"\").split(\"[,;]\");\n        for (final String ali : aliasArray) {\n            parserContext.getRegistry().registerAlias(beanName, ali);\n        }\n    }\n}\n```\n\n上述方法首先会判断对应的 beanName 是否存在，如果存在的话就建立 beanName 与 alias 之间的映射关系。\n\n第四步，创建标签 handler 类，继承自 NamespaceHandlerSupport 抽象类，用于注册第三步中定义的标签解析器：\n\n```java\npublic class CustomNamespaceHandler extends NamespaceHandlerSupport {\n\n    @Override\n    public void init() {\n        this.registerBeanDefinitionParser(\"alias\", new CustomBeanDefinitionParser());\n    }\n\n}\n```\n\n第五步，编写 spring.handlers 和 spring.schemas 文件：\n\n- spring.handlers\n\n```text\nhttp://www.zhenchao.org/schema/alias=org.zhenchao.handler.CustomNamespaceHandler\n```\n\n- spring.schemas\n\n```text\nhttp://www.zhenchao.org/schema/alias.xsd=META-INF/custom-alias.xsd\n```\n\n最后，演示一下如何使用上述自定义标签，首先需要在 `<beans />` 标签属性中定义标签的命名空间：\n\n```xml\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:myalias=\"http://www.zhenchao.org/schema/alias\"\n       xsi:schemaLocation=\n               \"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n                http://www.zhenchao.org/schema/alias http://www.zhenchao.org/schema/alias.xsd\"\n```\n\n然后使用我们自定义的标签为已定义的 bean 添加别名：\n\n```xml\n<!-- myBean 是一个已定义的 bean -->\n<myalias:alias id=\"myAlias\" c_name=\"myBean\" c_alias=\"aaa; bbb\"/>\n```\n\n这样我们完成了利用自定义的标签为 myBean 添加别名的功能。\n\n### 自定义标签的解析过程\n\n了解了如果自定义和使用自定义标签，下面开始分析 Spring 如何解析自定义标签。首先，回顾一下开始解析标签的入口函数 `DefaultBeanDefinitionDocumentReader#parseBeanDefinitions`，如下：：\n\n```java\nprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) {\n    // 解析默认标签\n    if (delegate.isDefaultNamespace(root)) {\n        NodeList nl = root.getChildNodes();\n        for (int i = 0; i < nl.getLength(); i++) {\n            Node node = nl.item(i);\n            if (node instanceof Element) {\n                Element ele = (Element) node;\n                // 解析默认标签\n                if (delegate.isDefaultNamespace(ele)) {\n                    this.parseDefaultElement(ele, delegate);\n                }\n                // 解析自定义标签\n                else {\n                    delegate.parseCustomElement(ele);\n                }\n            }\n        }\n    }\n    // 解析自定义标签\n    else {\n        delegate.parseCustomElement(root);\n    }\n}\n```\n\n上一篇中我们分析了默认标签的解析过程，也就是 `DefaultBeanDefinitionDocumentReader#parseDefaultElement` 方法，接下来我们来分析自定义标签的解析过程，即 `BeanDefinitionParserDelegate#parseCustomElement` 方法：\n\n```java\npublic BeanDefinition parseCustomElement(Element ele) {\n    return this.parseCustomElement(ele, null);\n}\n\npublic BeanDefinition parseCustomElement(Element ele, @Nullable BeanDefinition containingBd) {\n    // 获取标签的命名空间\n    String namespaceUri = this.getNamespaceURI(ele);\n    if (namespaceUri == null) {\n        return null;\n    }\n    // 解析自定义标签命名空间处理器\n    NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri);\n    if (handler == null) {\n        this.error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", ele);\n        return null;\n    }\n    // 解析标签\n    return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));\n}\n```\n\n上述方法首先获取自定义标签的命名空间定义，然后基于命名空间解析得到对应的 NamespaceHandler 实现类，最后调用 `NamespaceHandler#parse` 方法对自定义标签进行解析处理，这里本质上调用的就是前面自定义实现的 `CustomBeanDefinitionParser#doParse` 方法。先来看一下 NamespaceHandler 的解析过程，位于 `DefaultNamespaceHandlerResolver#resolve` 方法中：\n\n```java\npublic NamespaceHandler resolve(String namespaceUri) {\n    // 获取所有已注册的 handler 集合\n    Map<String, Object> handlerMappings = this.getHandlerMappings();\n    // 获取namespaceUri 对应的 handler 全称类名或 handler 实例\n    Object handlerOrClassName = handlerMappings.get(namespaceUri);\n    // 未注册\n    if (handlerOrClassName == null) {\n        return null;\n    }\n    // 已解析过，直接返回 handler 实例\n    else if (handlerOrClassName instanceof NamespaceHandler) {\n        return (NamespaceHandler) handlerOrClassName;\n    }\n    // 未解析过，基于 className 构造对应的 handler 实例，并注册\n    else {\n        String className = (String) handlerOrClassName;\n        try {\n            // 获取 handler 对应的 Class 对象\n            Class<?> handlerClass = ClassUtils.forName(className, this.classLoader);\n            if (!NamespaceHandler.class.isAssignableFrom(handlerClass)) {\n                throw new FatalBeanException(\"Class [\" + className + \"] for namespace [\" + namespaceUri +\n                        \"] does not implement the [\" + NamespaceHandler.class.getName() + \"] interface\");\n            }\n            // 实例化 handler\n            NamespaceHandler namespaceHandler = (NamespaceHandler) BeanUtils.instantiateClass(handlerClass);\n            // 初始化 handler\n            namespaceHandler.init();\n            // 注册 handler\n            handlerMappings.put(namespaceUri, namespaceHandler);\n            return namespaceHandler;\n        } catch (ClassNotFoundException ex) {\n            throw new FatalBeanException(\n                    \"Could not find NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"]\", ex);\n        } catch (LinkageError err) {\n            throw new FatalBeanException(\n                    \"Unresolvable class definition for NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"]\", err);\n        }\n    }\n}\n```\n\n上述方法的执行逻辑可以概括为：\n\n1. 从 spring.handlers 获取所有注册的 handler 集合；\n2. 从集合中获取 namespace 对应 handler 实例；\n3. 如果 handler 已经被解析过，则返回对应的 handler 实例；\n4. 否则，利用反射创建 handler 实例，并初始化；\n5. 注册解析得到的 handler 实例。\n\n上述过程中的第 4 步稍微复杂一些，下面进一步说明一下具体过程。我们在 spring.handlers 文件中会配置 namespaceUri 与对应 handler 全称类名的映射关系:\n\n```properties\nhttp://www.zhenchao.org/schema/alias=org.zhenchao.handler.CustomNamespaceHandler\n```\n\n所以，这一步会基于该配置获取到对应 handler 类的全称类名；然后基于反射机制创建 handler 实例；接下来就是调用 `NamespaceHandler#init` 方法对 handler 实例进行初始化。该方法是由开发人员自己实现的，我们前面的例子中通过该方法将我们自定义的解析器 CustomBeanDefinitionParser 注册到 handler 实例中。\n\n完成了对 handler 实例的解析，接下来就是调用 `NamespaceHandler#parse` 方法处理自定义标签：\n\n```java\npublic BeanDefinition parse(Element element, ParserContext parserContext) {\n    // 寻找对应的解析器\n    BeanDefinitionParser parser = this.findParserForElement(element, parserContext);\n    // 基于解析器执行对自定义标签的解析（这里的解析过程是开发者自定义实现的）\n    return (parser != null ? parser.parse(element, parserContext) : null);\n}\n```\n\n上述实现主要分为 __获取解析器__ 和 __解析自定义标签__ 两个步骤，其中获取解析器就是依据我们使用的标签名从之前注册的 map 数据结构中获取相应的对象，然后调用 `AbstractBeanDefinitionParser#parse` 方法执行解析操作，实现如下：\n\n```java\npublic final BeanDefinition parse(Element element, ParserContext parserContext) {\n    // 1. 创建自定义标签对应的 BeanDefinition 实例，并调用自定义解析器进行解析处理\n    AbstractBeanDefinition definition = this.parseInternal(element, parserContext);\n    // BeanDefinition 实例存在且不是嵌套的\n    if (definition != null && !parserContext.isNested()) {\n        try {\n            // 2. 获取标签的 id 属性，该属性是必备的\n            String id = this.resolveId(element, definition, parserContext);\n            if (!StringUtils.hasText(id)) {\n                parserContext.getReaderContext().error(\n                        \"Id is required for element '\" + parserContext.getDelegate().getLocalName(element) + \"' when used as a top-level tag\", element);\n            }\n\n            // 3. 获取 name 属性\n            String[] aliases = null;\n            if (this.shouldParseNameAsAliases()) {\n                String name = element.getAttribute(NAME_ATTRIBUTE);\n                if (StringUtils.hasLength(name)) {\n                    aliases = StringUtils.trimArrayElements(StringUtils.commaDelimitedListToStringArray(name));\n                }\n            }\n\n            // 4. 使用 BeanDefinitionHolder 封装 BeanDefinition 实例，便于注册到容器中\n            BeanDefinitionHolder holder = new BeanDefinitionHolder(definition, id, aliases);\n            this.registerBeanDefinition(holder, parserContext.getRegistry());\n\n            // 5. 发布事件通知\n            if (this.shouldFireEvents()) {\n                BeanComponentDefinition componentDefinition = new BeanComponentDefinition(holder);\n                this.postProcessComponentDefinition(componentDefinition);\n                parserContext.registerComponent(componentDefinition);\n            }\n        } catch (BeanDefinitionStoreException ex) {\n            String msg = ex.getMessage();\n            parserContext.getReaderContext().error((msg != null ? msg : ex.toString()), element);\n            return null;\n        }\n    }\n    return definition;\n}\n```\n\n上述方法中的第一步是整个方法的核心，我们后面细讲，先来看一下第二、三步骤。对于自定义标签来说，id 属性是必备的，此外 Spring 还内置了 name 和 parentName 字段，这些名称是不允许使用的，否则达不到我们预期的结果，笔者第一次使用自定义标签时就踩了坑，用了 name 作为自定义标签属性名，结果就是各种奇怪的问题。\n\n接下来看看第一步的实现逻辑，位于 `AbstractSingleBeanDefinitionParser#parseInternal` 方法中：\n\n```java\nprotected final AbstractBeanDefinition parseInternal(Element element, ParserContext parserContext) {\n    // 初始化自定义标签实例\n    BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition();\n    // 获取并设置 parentName\n    String parentName = this.getParentName(element);\n    if (parentName != null) {\n        builder.getRawBeanDefinition().setParentName(parentName);\n    }\n\n    // 调用自定义 BeanDefinitionParser 中的 getBeanClass 方法\n    Class<?> beanClass = this.getBeanClass(element);\n    if (beanClass != null) {\n        builder.getRawBeanDefinition().setBeanClass(beanClass);\n    } else {\n        // 如果自定义解析器没有重写 getBeanClass 方法，则检查子类是否重写了getBeanClassName 方法\n        String beanClassName = this.getBeanClassName(element);\n        if (beanClassName != null) {\n            builder.getRawBeanDefinition().setBeanClassName(beanClassName);\n        }\n    }\n    builder.getRawBeanDefinition().setSource(parserContext.extractSource(element));\n\n    // 如果当前标签是嵌套的，则继承外围 bean 的 scope 属性\n    BeanDefinition containingBd = parserContext.getContainingBeanDefinition();\n    if (containingBd != null) {\n        // Inner bean definition must receive same scope as containing bean.\n        builder.setScope(containingBd.getScope());\n    }\n\n    // 解析并设置延迟加载\n    if (parserContext.isDefaultLazyInit()) {\n        // Default-lazy-init applies to custom bean definitions as well.\n        builder.setLazyInit(true);\n    }\n\n    // 调用自定义解析器覆盖实现的 doParse 方法进行解析\n    this.doParse(element, parserContext, builder);\n\n    // 返回自定义标签的 BeanDefinition 实例\n    return builder.getBeanDefinition();\n}\n```\n\n上述方法首先会初始化创建一个 BeanDefinitionBuilder 对象，然后依据配置设置对象的相应属性，其中会尝试调用自定义标签解析器覆盖实现的 `AbstractSingleBeanDefinitionParser#getBeanClass` 方法获取 bean 对应的 Class 对象。然后会调用 `AbstractSingleBeanDefinitionParser#doParse` 方法解析自定义标签，该方法由开发者实现：\n\n```java\nprotected void doParse(Element element, ParserContext parserContext, BeanDefinitionBuilder builder) {\n    String beanName = element.getAttribute(\"c_name\");\n    Assert.hasText(beanName, \"The 'name' in alias tag is missing!\");\n    Assert.isTrue(parserContext.getRegistry().containsBeanDefinition(beanName), \"No bean name \" + beanName + \" exist!\");\n    String alias = element.getAttribute(\"c_alias\");\n    Assert.hasText(beanName, \"The 'alias' in alias tag is missing!\");\n    String[] aliasArray = alias.replaceAll(\"\\\\s+\", \"\").split(\"[,;]\");\n    for (final String ali : aliasArray) {\n        parserContext.getRegistry().registerAlias(beanName, ali);\n    }\n}\n```\n\n最后，返回自定义标签对应的 BeanDefinition 实例。\n\n### 总结\n\n本文演示了如何按照规范定义和使用自定义标签，并分析了 Spring 解析用户自定义标签的实现。分析到此，对于配置文件的解析过程也就基本分析完了。Spring 将一个个 bean 的静态配置解析成 BeanDefinition 实例注册到 IoC 容器中，接下去就可以调用 `BeanFactory#getBean` 方法获取 bean 实例了。建和初始化 bean 实例的过程也都由该方法触发，我们将在下一篇对这一过程的具体实现进行探究。\n\n### 参考\n\n1. [Spring 源码深度解析](https://book.douban.com/subject/25866350/)\n","tags":["Spring"],"categories":["spring"]},{"title":"Spring IoC 源码解析：默认标签的解析过程","url":"/2017/05/18/spring/spring-ioc-default-element/","content":"\n上一篇我们梳理了容器初始化的整体流程，了解了一个 bean 是如何从静态配置变为一个可运行的实例的，但是对于过程中涉及到的具体细节并未进行深入探究。从本篇开始，我们将回到起点重新沿着主线走一遍，与之前不同的是，这一次我们更加关注细节。\n\n由前面的分析我们已经大致知晓 IoC 容器在初始化期间主要分为两个阶段：加载并解析配置文件和初始化 bean 实例。本文所要介绍的对于默认标签的解析发生在加载并解析配置文件阶段，以 XML 配置为例，容器会将 XML 形式的静态配置解析成对应的 BeanDefinition 对象注册到容器中。在配置方面，Spring 为开发者提供了许多可用的标签，比如 `<beans />`、`<bean />`、`<import />`，以及 `<alias />` 等等。这些标签统称为 __默认标签__ （个人觉得翻译成内置标签更加合理），同时 Spring 还允许开发者自己定义标签，方法 `DefaultBeanDefinitionDocumentReader#parseBeanDefinitions` 中的逻辑就是判断当前标签是默认标签还是自定义标签，并调用相应的方法对标签进行解析（实现如下），本篇我们主要分析默认标签的解析过程，对于自定义标签则留到下一篇进行讲解。<!-- more -->\n\n```java\nprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) {\n    // 解析默认标签\n    if (delegate.isDefaultNamespace(root)) {\n        NodeList nl = root.getChildNodes();\n        for (int i = 0; i < nl.getLength(); i++) {\n            Node node = nl.item(i);\n            if (node instanceof Element) {\n                Element ele = (Element) node;\n                // 解析默认标签\n                if (delegate.isDefaultNamespace(ele)) {\n                    this.parseDefaultElement(ele, delegate);\n                }\n                // 解析自定义标签\n                else {\n                    delegate.parseCustomElement(ele);\n                }\n            }\n        }\n    }\n    // 解析自定义标签\n    else {\n        delegate.parseCustomElement(root);\n    }\n}\n```\n\n我们在上一篇中已经和上述方法打过照面，如果不清楚该方法的调用时机，可以重新阅读一下。\n\n本文，我们主要关注 `DefaultBeanDefinitionDocumentReader#parseDefaultElement` 方法。该方法用于对默认标签进行解析，整个方法的逻辑很清晰，判断当前的标签类型，然后调用对应的解析器去做解析处理，实现如下：\n\n```java\nprivate void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) {\n    // 处理 import 标签，该标签用于引入其它的 xml 配置文件\n    if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) {\n        this.importBeanDefinitionResource(ele);\n    }\n    // 处理 alias 标签，该标签用于为 bean 配置别名\n    else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) {\n        this.processAliasRegistration(ele);\n    }\n    // 处理 bean 标签\n    else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) {\n        this.processBeanDefinition(ele, delegate);\n    }\n    // 处理 beans 标签，即在 <beans /> 中再嵌套 <beans /> 标签\n    else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) {\n        // recurse\n        this.doRegisterBeanDefinitions(ele);\n    }\n}\n```\n\n方法按照标签类型分而治之，下面逐个探究各个标签的解析过程。\n\n### 标签 bean 的解析过程\n\n标签 `<bean/>` 是基于 XML 进行配置时使用频次最多的标签，所以我们首先从这里开挖。该标签对应的处理方法是 `DefaultBeanDefinitionDocumentReader#processBeanDefinition`，先来总览一下整个方法的执行逻辑：\n\n```java\nprotected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) {\n    // 1. 解析 bean 元素，包括 id、name、alias 和 class\n    BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);\n    if (bdHolder != null) {\n        // 2. 如果默认标签下有自定义标签，则进行解析\n        bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);\n        try {\n            // 3. 注册解析得到的 BeanDefinitionHolder\n            BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, this.getReaderContext().getRegistry());\n        } catch (BeanDefinitionStoreException ex) {\n            this.getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex);\n        }\n        /*\n         * 4. 发出响应事件，通知相关监听器这个 bean 定义已经加载完了\n         *\n         * 这里的实现只是为了扩展，Spring 自己并没有对注册实现做任何逻辑处理\n         */\n        this.getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));\n    }\n}\n```\n\n上述方法的执行流程可以概括为：\n\n1. 解析各个默认标签元素，将配置语义转换成 BeanDefinition 对象，并记录到 BeanDefinitionHolder 中；\n2. 检查当前标签下是否有自定义标签元素，若存在则进行解析；\n3. 注册由前两步得到的 BeanDefinitionHolder 对象；\n4. 发布事件，通知相应的监听者当前 bean 的默认标签已经解析完成。\n\n#### 解析默认标签元素\n\n默认标签元素的解析位于 `DefinitionParserDelegate#parseBeanDefinitionElement` 方法中，实现如下：\n\n```java\npublic BeanDefinitionHolder parseBeanDefinitionElement(Element ele) {\n    return this.parseBeanDefinitionElement(ele, null);\n}\n\npublic BeanDefinitionHolder parseBeanDefinitionElement(Element ele, @Nullable BeanDefinition containingBean) {\n    // 获取 id 属性\n    String id = ele.getAttribute(ID_ATTRIBUTE);\n    // 获取 name 属性\n    String nameAttr = ele.getAttribute(NAME_ATTRIBUTE);\n\n    // 如果配置了多个 name（以逗号、分号，或者空格分隔），则解析成 List\n    List<String> aliases = new ArrayList<>();\n    if (StringUtils.hasLength(nameAttr)) {\n        String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS);\n        aliases.addAll(Arrays.asList(nameArr));\n    }\n\n    // 没有配置 id 属性，但配置了至少一个 name，则以第一个 name 作为 id\n    String beanName = id;\n    if (!StringUtils.hasText(beanName) && !aliases.isEmpty()) {\n        beanName = aliases.remove(0);\n    }\n\n    // 检查 name 和 alias 的在容器中的唯一性\n    if (containingBean == null) {\n        this.checkNameUniqueness(beanName, aliases, ele);\n    }\n\n    // 解析 bean 标签，使用 GenericBeanDefinition 对象封装\n    AbstractBeanDefinition beanDefinition = this.parseBeanDefinitionElement(ele, beanName, containingBean);\n    if (beanDefinition != null) {\n        // 未设置 beanName，按照规则自动生成一个\n        if (!StringUtils.hasText(beanName)) {\n            try {\n                if (containingBean != null) {\n                    beanName = BeanDefinitionReaderUtils.generateBeanName(\n                            beanDefinition, this.readerContext.getRegistry(), true);\n                } else {\n                    beanName = this.readerContext.generateBeanName(beanDefinition);\n                    // Register an alias for the plain bean class name, if still possible,\n                    // if the generator returned the class name plus a suffix.\n                    // This is expected for Spring 1.2/2.0 backwards compatibility.\n                    String beanClassName = beanDefinition.getBeanClassName();\n                    if (beanClassName != null\n                            && beanName.startsWith(beanClassName) && beanName.length() > beanClassName.length()\n                            && !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) {\n                        aliases.add(beanClassName);\n                    }\n                }\n            } catch (Exception ex) {\n                this.error(ex.getMessage(), ele);\n                return null;\n            }\n        }\n        String[] aliasesArray = StringUtils.toStringArray(aliases);\n        // 使用 BeanDefinitionHolder 对象封装解析后的信息\n        return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray);\n    }\n\n    return null;\n}\n```\n\n上述解析 `<bean />` 标签的执行过程可以概括为：\n\n1. 获取 id 和 name 属性，并检查属性值在整个配置中的唯一性；\n2. 解析其它属性元素，封装成 GenericBeanDefinition 对象；\n3. Spring 会以 id 或第一个 name 值作为 bean 的唯一标识（即 beanName），如果没有设置则依据命名规则自动生成一个；\n4. 将解析得到的 BeanDefinition 实例、beanName，以及 alias 列表封装成 BeanDefinitionHolder 对象返回。\n\n整个过程中最核心的步骤是第 2 步，这一步完成了由配置到 BeanDefinition 实例的转换，实现如下：\n\n```java\npublic AbstractBeanDefinition parseBeanDefinitionElement(\n        Element ele, String beanName, @Nullable BeanDefinition containingBean) {\n\n    // 入栈，用于发生异常时打印异常链\n    this.parseState.push(new BeanEntry(beanName));\n\n    // 获取 class 属性\n    String className = null;\n    if (ele.hasAttribute(CLASS_ATTRIBUTE)) {\n        className = ele.getAttribute(CLASS_ATTRIBUTE).trim();\n    }\n\n    // 获取 parent 属性\n    String parent = null;\n    if (ele.hasAttribute(PARENT_ATTRIBUTE)) {\n        parent = ele.getAttribute(PARENT_ATTRIBUTE);\n    }\n\n    try {\n        // 创建 BeanDefinition 对象，采用 GenericBeanDefinition 实现类\n        AbstractBeanDefinition bd = this.createBeanDefinition(className, parent);\n\n        // 解析 <bean/> 标签的各种属性元素\n        this.parseBeanDefinitionAttributes(ele, beanName, containingBean, bd);\n        // 获取并设置 description 属性\n        bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT));\n\n        // 解析元数据子标签 <meta key=\"\" value=\"\"/>\n        this.parseMetaElements(ele, bd);\n        // 解析 lookup-method 子标签\n        this.parseLookupOverrideSubElements(ele, bd.getMethodOverrides());\n        // 解析 replaced-method 子标签\n        this.parseReplacedMethodSubElements(ele, bd.getMethodOverrides());\n\n        // 解析构造方法参数\n        this.parseConstructorArgElements(ele, bd);\n        // 解析 property 子标签\n        this.parsePropertyElements(ele, bd);\n        // 解析 qualifier 子标签\n        this.parseQualifierElements(ele, bd);\n\n        bd.setResource(this.readerContext.getResource());\n        bd.setSource(this.extractSource(ele));\n\n        return bd;\n    } catch (ClassNotFoundException ex) {\n        this.error(\"Bean class [\" + className + \"] not found\", ele, ex);\n    } catch (NoClassDefFoundError err) {\n        this.error(\"Class that bean class [\" + className + \"] depends on not found\", ele, err);\n    } catch (Throwable ex) {\n        this.error(\"Unexpected failure during bean definition parsing\", ele, ex);\n    } finally {\n        this.parseState.pop();\n    }\n\n    return null;\n}\n```\n\n上述方法会先获取配置的 class 和 parent 属性值，然后基于这两个值创建最初的 BeanDefinition 对象：\n\n```java\nprotected AbstractBeanDefinition createBeanDefinition(\n        @Nullable String className, @Nullable String parentName) throws ClassNotFoundException {\n    return BeanDefinitionReaderUtils.createBeanDefinition(\n            parentName, className, this.readerContext.getBeanClassLoader());\n}\n\n// org.springframework.beans.factory.support.BeanDefinitionReaderUtils#createBeanDefinition\npublic static AbstractBeanDefinition createBeanDefinition(\n        @Nullable String parentName, @Nullable String className, @Nullable ClassLoader classLoader)\n        throws ClassNotFoundException {\n    // 创建 GenericBeanDefinition 对象\n    GenericBeanDefinition bd = new GenericBeanDefinition();\n    // 设置 parent 属性\n    bd.setParentName(parentName);\n    // 设置 class 属性\n    if (className != null) {\n        // 如果指定了类加载器，则基于此类加载器解析 className 对应的 Class 对象\n        if (classLoader != null) {\n            bd.setBeanClass(ClassUtils.forName(className, classLoader));\n        } else {\n            bd.setBeanClassName(className);\n        }\n    }\n    return bd;\n}\n```\n\n由上述实现可以看到，这里创建的 BeanDefinition 对象是 GenericBeanDefinition 类型，并设置对象的 `GenericBeanDefinition#parentName` 属性。如果指定了类加载器，则基于该类加载器获取 bean 对应的 Class 对象，并设置 `AbstractBeanDefinition#beanClass` 属性，否则直接将 bean 的 className 记录到该属性上。\n\n##### 解析属性元素\n\n接下来，Spring 会去解析 `<bean />` 标签中的各种属性配置，并依据获取到的属性值去设置上面创建的 GenericBeanDefinition 对象。相关实现位于 `BeanDefinitionParserDelegate#parseBeanDefinitionAttributes` 方法中：\n\n```java\npublic AbstractBeanDefinition parseBeanDefinitionAttributes(Element ele,\n                                                            String beanName,\n                                                            @Nullable BeanDefinition containingBean,\n                                                            AbstractBeanDefinition bd) {\n\n    // 属性 singleton 已经过时，推荐使用 scope 属性\n    if (ele.hasAttribute(SINGLETON_ATTRIBUTE)) {\n        this.error(\"Old 1.x 'singleton' attribute in use - upgrade to 'scope' declaration\", ele);\n    }\n    // 解析并设置 scope 属性\n    else if (ele.hasAttribute(SCOPE_ATTRIBUTE)) {\n        bd.setScope(ele.getAttribute(SCOPE_ATTRIBUTE));\n    }\n    // 当前 bean 没有指定 scope，如果传入了containingBean，则继承其scope\n    else if (containingBean != null) {\n        // Take default from containing bean in case of an inner bean definition.\n        bd.setScope(containingBean.getScope());\n    }\n\n    // 解析并设置 abstract 属性\n    if (ele.hasAttribute(ABSTRACT_ATTRIBUTE)) {\n        bd.setAbstract(TRUE_VALUE.equals(ele.getAttribute(ABSTRACT_ATTRIBUTE)));\n    }\n\n    // 解析并设置 lazy-init 属性（false、true、default）\n    String lazyInit = ele.getAttribute(LAZY_INIT_ATTRIBUTE);\n    if (this.isDefaultValue(lazyInit)) {\n        // 如果是默认配置，则继承 default-lazy-init\n        lazyInit = this.defaults.getLazyInit();\n    }\n    bd.setLazyInit(TRUE_VALUE.equals(lazyInit));\n\n    // 解析并设置 autowire 属性\n    String autowire = ele.getAttribute(AUTOWIRE_ATTRIBUTE);\n    bd.setAutowireMode(this.getAutowireMode(autowire));\n\n    // 解析并设置 depends-on 属性\n    if (ele.hasAttribute(DEPENDS_ON_ATTRIBUTE)) {\n        String dependsOn = ele.getAttribute(DEPENDS_ON_ATTRIBUTE);\n        // 多个 depends 以逗号、分号，或空格分隔\n        bd.setDependsOn(StringUtils.tokenizeToStringArray(dependsOn, MULTI_VALUE_ATTRIBUTE_DELIMITERS));\n    }\n\n    // 解析并设置 autowire-candidate 属性\n    String autowireCandidate = ele.getAttribute(AUTOWIRE_CANDIDATE_ATTRIBUTE);\n    if (this.isDefaultValue(autowireCandidate)) {\n        String candidatePattern = this.defaults.getAutowireCandidates();\n        if (candidatePattern != null) {\n            String[] patterns = StringUtils.commaDelimitedListToStringArray(candidatePattern);\n            bd.setAutowireCandidate(PatternMatchUtils.simpleMatch(patterns, beanName));\n        }\n    } else {\n        bd.setAutowireCandidate(TRUE_VALUE.equals(autowireCandidate));\n    }\n\n    // 解析并设置 primary 属性\n    if (ele.hasAttribute(PRIMARY_ATTRIBUTE)) {\n        bd.setPrimary(TRUE_VALUE.equals(ele.getAttribute(PRIMARY_ATTRIBUTE)));\n    }\n\n    // 解析并设置 init-method 属性\n    if (ele.hasAttribute(INIT_METHOD_ATTRIBUTE)) {\n        String initMethodName = ele.getAttribute(INIT_METHOD_ATTRIBUTE);\n        bd.setInitMethodName(initMethodName);\n    }\n    // 尝试使用 default-init-method 配置\n    else if (this.defaults.getInitMethod() != null) {\n        bd.setInitMethodName(this.defaults.getInitMethod());\n        bd.setEnforceInitMethod(false);\n    }\n\n    // 解析并设置 destroy-method 属性\n    if (ele.hasAttribute(DESTROY_METHOD_ATTRIBUTE)) {\n        String destroyMethodName = ele.getAttribute(DESTROY_METHOD_ATTRIBUTE);\n        bd.setDestroyMethodName(destroyMethodName);\n    }\n    // 尝试使用 default-destroy-method 配置\n    else if (this.defaults.getDestroyMethod() != null) {\n        bd.setDestroyMethodName(this.defaults.getDestroyMethod());\n        bd.setEnforceDestroyMethod(false);\n    }\n\n    // 解析并设置 factory-method 属性\n    if (ele.hasAttribute(FACTORY_METHOD_ATTRIBUTE)) {\n        bd.setFactoryMethodName(ele.getAttribute(FACTORY_METHOD_ATTRIBUTE));\n    }\n\n    // 解析并设置 factory-bean 属性\n    if (ele.hasAttribute(FACTORY_BEAN_ATTRIBUTE)) {\n        bd.setFactoryBeanName(ele.getAttribute(FACTORY_BEAN_ATTRIBUTE));\n    }\n\n    return bd;\n}\n```\n\n整个方法解析了 `<bean />` 标签所有的属性，包括常用和不常用的，虽然实现很长，但是都是在做一件事情，即判断是否配置了相应的属性，如果配置了则解析并记录到 BeanDefinition 对象中。对于部分具备继承性质的属性，如果没有配置则沿用上游配置的值。下面选择几个不是特别常用的属性举例说明一下。\n\n- __abstract__\n\n属性 abstract 与 parent 属性组合使用，让配置具备继承性质。如果多个 bean 在配置上存在大量的重复，这个时候就可以考虑使用继承的配置，抽象出重复的属性配置在父 bean 中，而子 bean 则配置特有的属性，如下：\n\n```xml\n<bean id=\"abstractCar\" class=\"org.zhenchao.spring.ioc.Car\" abstract=\"true\" p:brand=\"benz\"/>\n<bean id=\"whiteCar\" parent=\"abstractCar\" p:color=\"white\"/>\n<bean id=\"blackCar\" parent=\"abstractCar\" p:color=\"black\"/>\n```\n\n通过 `abstract=\"true\"` 属性将父 bean 置为抽象，然后在子 bean 中利用 parent 属性进行引用，这样相同的属性只需要配置一份即可。\n\n- __autowire-candidate__\n\n在自动注入时，有时候往往存在多个候选的注入对象，Spring 在无法确定正确的候选者时就会抛出 UnsatisfiedDependencyException 异常，这个时候我们可以将某个或多个候选者配置为 `autowire-candidate=false`，从而剥夺其候选者的身份。\n\n- __primary__\n\n属性 primary 的功能类似于 autowire-candidate，后者是剥夺某个 bean 的自动注入候选者身份，但是如果存在多个候选者时，一个个的配置会比较麻烦，这个时候我们可以使用 primary 属性将某个候选 bean 设置为 `primary=true`，这样就使得该 bean 在候选时具备了最高优先级。\n\n##### 解析子标签元素\n\n标签 `<bean />` 除了提供了大量的属性配置外，还允许我们在该标签中配置子标签，Spring 内置了多种子标签，下面对各个子标签的功能和解析过程逐一分析。\n\n- __解析 meta 标签__\n\n标签 meta 使用的不多，这个配置最终会记录到 BeanDefinition 实例中。假设有如下配置：\n\n```xml\n<bean id=\"myBean\" class=\"org.zhenchao.spring.ioc.MyBean\">\n    <meta key=\"meta_name\" value=\"zhenchao\"/>\n</bean>\n```\n\n那么我们可以通过如下方式从 bean 对应的 BeanDefinition 实例中获取配置的 meta 值：\n\n```java\nfinal BeanDefinition definition = beanFactory.getBeanDefinition(\"myBean\");\nfinal Object metaName = definition.getAttribute(\"meta_name\");\n```\n\n通过分析源码我们可以清晰看到 `<meta />` 标签解析和记录的过程，位于 `BeanDefinitionParserDelegate#parseMetaElements` 方法中：\n\n```java\npublic void parseMetaElements(Element ele, BeanMetadataAttributeAccessor attributeAccessor) {\n    // 获取当前结点下的所有子标签\n    NodeList nl = ele.getChildNodes();\n    for (int i = 0; i < nl.getLength(); i++) {\n        Node node = nl.item(i);\n        // 如果是 <meta/> 标签则进行解析\n        if (this.isCandidateElement(node) && this.nodeNameEquals(node, META_ELEMENT)) {\n            Element metaElement = (Element) node;\n            // 获取配置的 key 属性\n            String key = metaElement.getAttribute(KEY_ATTRIBUTE);\n            // 获取配置的 value 属性\n            String value = metaElement.getAttribute(VALUE_ATTRIBUTE);\n            // 使用 BeanMetadataAttribute 对象进行封装\n            BeanMetadataAttribute attribute = new BeanMetadataAttribute(key, value);\n            attribute.setSource(this.extractSource(metaElement));\n            // 记录到 BeanDefinition 的属性集合中\n            attributeAccessor.addMetadataAttribute(attribute);\n        }\n    }\n}\n```\n\n由上述实现可以看到，容器是将 `<meta />` 标签配置值通过 BeanMetadataAttribute 对象进行封装，并调用 `BeanMetadataAttributeAccessor#addMetadataAttribute` 方法记录到 attributes 属性中。该属性是一个 map 型的对象，而我们之所以可以从 BeanDefinition 实例中获取到配置值，是因为 BeanDefinition 继承自 BeanMetadataAttributeAccessor 类。\n\n- __解析 lookup-method 标签__\n\n标签 `<lookup-method />` 一般用于希望在一个 singleton 对象中获取一个 prototype 对象的场景。假如我们在一个 singleton 对象中寄希望每次调用 getter 方法时获取一个 prototype 类型的新对象，因为外围 bean 实例是 singleton 类型的，其属性也都只有一份，所以不可能每次都返回 prototype 类型属性的新实例，此时我们就可以使用 `<lookup-method />` 标签来达到目的。示例如下：\n\n```java\npublic class MyBean {\n\n    private PrototypeBean prototypeBean;\n\n    public PrototypeBean getPrototypeBean() {\n        return prototypeBean;\n    }\n\n    public void setPrototypeBean(PrototypeBean prototypeBean) {\n        this.prototypeBean = prototypeBean;\n    }\n}\n```\n\nMyBean 为 singleton 类型，虽然 PrototypeBean 是 prototype 的，但是我们每次调用 `MyBean#getPrototypeBean` 方法返回的仍然是同一个对象，这个时候就可以使用 `<lookup-method />` 标签：\n\n```xml\n<bean id=\"prototype-bean\" class=\"org.zhenchao.spring.ioc.PrototypeBean\" scope=\"prototype\"/>\n\n<bean id=\"myBean\" class=\"org.zhenchao.spring.ioc.MyBean\">\n    <lookup-method name=\"getPrototypeBean\" bean=\"prototype-bean\"/>\n</bean>\n```\n\n标签 `<lookup-method />`  让 `MyBean#getPrototypeBean` 方法每次都会去调用一遍 prototype 对象，从而每次都返回新的对象。该标签的解析位于 `BeanDefinitionParserDelegate#parseLookupOverrideSubElements` 方法中：\n\n```java\npublic void parseLookupOverrideSubElements(Element beanEle, MethodOverrides overrides) {\n    // 获取当前结点下的所有子标签\n    NodeList nl = beanEle.getChildNodes();\n    for (int i = 0; i < nl.getLength(); i++) {\n        Node node = nl.item(i);\n        // 如果是 <lookup-method /> 标签则进行解析\n        if (this.isCandidateElement(node) && this.nodeNameEquals(node, LOOKUP_METHOD_ELEMENT)) {\n            Element ele = (Element) node;\n            // 获取配置的 name 属性\n            String methodName = ele.getAttribute(NAME_ATTRIBUTE);\n            // 获取配置的 bean 属性\n            String beanRef = ele.getAttribute(BEAN_ELEMENT);\n            // 使用 LookupOverride 对象进行封装\n            LookupOverride override = new LookupOverride(methodName, beanRef);\n            override.setSource(this.extractSource(ele));\n            // 记录到 BeanDefinition 的 overrides 属性中\n            overrides.addOverride(override);\n        }\n    }\n}\n```\n\n上述方法的执行逻辑主要是解析 `<lookup-method>` 标签配置封装成 LookupOverride 对象，并调用 `MethodOverrides#addOverride` 方法将该对象添加到 overrides 属性中，这是一个线程安全的 Set 集合。实现每次返回一个新对象的机制是通过覆盖目标 bean 的对应方法，在每次调用该方法时都创建一个被引用 bean 的新实例。\n\n- __解析 replaced-method 标签__\n\n标签 `<replaced-method />` 顾名思义，是用来替换一个方法的实现。如果希望替换 MyBean 的如下方法：\n\n```java\npublic void originalMethod() {\n    System.out.println(\"This is original method.\");\n}\n```\n\n我们首先需要定义一个实现了 MethodReplacer 接口的 bean，并实现 `MethodReplacer#reimplement` 方法：\n\n```java\npublic class MyMethodReplacer implements MethodReplacer {\n\n    @Override\n    public Object reimplement(Object o, Method method, Object[] objects) throws Throwable {\n        System.out.println(\"This is replaced method.\");\n        return o;\n    }\n\n}\n```\n\n然后利用 `<replaced-method />` 子标签进行配置：\n\n```xml\n<bean id=\"method-replacer\" class=\"org.zhenchao.spring.ioc.MyMethodReplacer\"/>\n\n<bean id=\"myBean\" class=\"org.zhenchao.spring.ioc.MyBean\">\n    <replaced-method name=\"originalMethod\" replacer=\"method-replacer\"/>\n</bean>\n```\n\n这样在调用 `MyBean#originalMethod` 方法时，本质上是在调用 `MyMethodReplacer#reimplement`  方法。该标签的解析位于 parseReplacedMethodSubElements(Element beanEle, MethodOverrides overrides) 方法中：\n\n```java\npublic void parseReplacedMethodSubElements(Element beanEle, MethodOverrides overrides) {\n    // 获取当前结点下的所有子标签\n    NodeList nl = beanEle.getChildNodes();\n    for (int i = 0; i < nl.getLength(); i++) {\n        Node node = nl.item(i);\n        // 如果是 <replaced-method /> 标签则进行解析\n        if (this.isCandidateElement(node) && this.nodeNameEquals(node, REPLACED_METHOD_ELEMENT)) {\n            Element replacedMethodEle = (Element) node;\n            // 获取配置的 name 属性\n            String name = replacedMethodEle.getAttribute(NAME_ATTRIBUTE);\n            // 获取配置的 replacer 属性\n            String callback = replacedMethodEle.getAttribute(REPLACER_ATTRIBUTE);\n            // 使用 ReplaceOverride 对象进行封装\n            ReplaceOverride replaceOverride = new ReplaceOverride(name, callback);\n            // 如果配置了 <arg-type /> 子标签，则进行解析\n            List<Element> argTypeEles = DomUtils.getChildElementsByTagName(replacedMethodEle, ARG_TYPE_ELEMENT);\n            for (Element argTypeEle : argTypeEles) {\n                String match = argTypeEle.getAttribute(ARG_TYPE_MATCH_ATTRIBUTE);\n                match = (StringUtils.hasText(match) ? match : DomUtils.getTextValue(argTypeEle));\n                if (StringUtils.hasText(match)) {\n                    replaceOverride.addTypeIdentifier(match);\n                }\n            }\n            replaceOverride.setSource(this.extractSource(replacedMethodEle));\n            // 记录到 BeanDefinition 的 overrides 属性中\n            overrides.addOverride(replaceOverride);\n        }\n    }\n}\n```\n\n对于 `<replaced-method />` 标签的解析类似于 `<lookup-method />` 标签，不过标签 `<replaced-method />` 在替换方法时可能存在多个方法的重载版本，这个时候就需要通过参数类型进一步确认，所以实现时增加了对于参数类型配置的解析逻辑。\n\n- __解析构造函数参数标签__\n\n构造函数标签 `<constructor-arg />` 是我们常用的标签，也是三种依赖注入方式之一。使用示例：\n\n```xml\n<!--参数配置顺序并不能决定在构造方法中的匹配顺序-->\n<constructor-arg index=\"0\" name=\"id\" type=\"long\" value=\"100001\"/>\n<constructor-arg index=\"1\" name=\"username\" type=\"java.lang.String\" value=\"zhenchao\"/>\n<constructor-arg index=\"2\" name=\"password\" type=\"java.lang.String\" value=\"123456\"/>\n```\n\n配置顺序与构造方法中参数定义顺序没有直接关系，所以大部分时候都可能会映射错误，此时我们可以凭借 index 属性和 type 属性从两个维度上做唯一性限制。标签 `<constructor-arg />` 可以看作是 `<property />` 标签的一种特殊形式，在实现上复用了解析 `<property />` 标签的实现，这些复用的实现将留到后面分析 `<property />` 标签时再展开。该标签的解析实现位于 `BeanDefinitionParserDelegate#parseConstructorArgElements` 方法中：\n\n```java\npublic void parseConstructorArgElements(Element beanEle, BeanDefinition bd) {\n    // 获取当前结点下的所有子标签\n    NodeList nl = beanEle.getChildNodes();\n    for (int i = 0; i < nl.getLength(); i++) {\n        Node node = nl.item(i);\n        // 如果是 <constructor-arg/> 标签则进行解析\n        if (this.isCandidateElement(node) && this.nodeNameEquals(node, CONSTRUCTOR_ARG_ELEMENT)) {\n            this.parseConstructorArgElement((Element) node, bd);\n        }\n    }\n}\n\npublic void parseConstructorArgElement(Element ele, BeanDefinition bd) {\n    // 获取 index 属性\n    String indexAttr = ele.getAttribute(INDEX_ATTRIBUTE);\n    // 获取 type 属性\n    String typeAttr = ele.getAttribute(TYPE_ATTRIBUTE);\n    // 获取 name 属性\n    String nameAttr = ele.getAttribute(NAME_ATTRIBUTE);\n\n    // 配置了 index 属性\n    if (StringUtils.hasLength(indexAttr)) {\n        try {\n            int index = Integer.parseInt(indexAttr);\n            if (index < 0) {\n                this.error(\"'index' cannot be lower than 0\", ele);\n            } else {\n                try {\n                    this.parseState.push(new ConstructorArgumentEntry(index));\n                    // 解析标签元素，复用 <property/> 标签的解析过程\n                    Object value = this.parsePropertyValue(ele, bd, null);\n                    ConstructorArgumentValues.ValueHolder valueHolder = new ConstructorArgumentValues.ValueHolder(value);\n                    // 设置 type 属性\n                    if (StringUtils.hasLength(typeAttr)) {\n                        valueHolder.setType(typeAttr);\n                    }\n                    // 设置 name 属性\n                    if (StringUtils.hasLength(nameAttr)) {\n                        valueHolder.setName(nameAttr);\n                    }\n                    valueHolder.setSource(this.extractSource(ele));\n                    // 不允许有重复的 index\n                    if (bd.getConstructorArgumentValues().hasIndexedArgumentValue(index)) {\n                        this.error(\"Ambiguous constructor-arg entries for index \" + index, ele);\n                    } else {\n                        // 记录 index 对应的构造参数 ValueHolder 对象\n                        bd.getConstructorArgumentValues().addIndexedArgumentValue(index, valueHolder);\n                    }\n                } finally {\n                    this.parseState.pop();\n                }\n            }\n        } catch (NumberFormatException ex) {\n            this.error(\"Attribute 'index' of tag 'constructor-arg' must be an integer\", ele);\n        }\n    }\n    // 未配置 index 属性\n    else {\n        try {\n            this.parseState.push(new ConstructorArgumentEntry());\n            // 解析标签元素，复用 <property/> 标签的解析过程\n            Object value = this.parsePropertyValue(ele, bd, null);\n            ConstructorArgumentValues.ValueHolder valueHolder = new ConstructorArgumentValues.ValueHolder(value);\n            // 设置 type 属性\n            if (StringUtils.hasLength(typeAttr)) {\n                valueHolder.setType(typeAttr);\n            }\n            // 设置 name 属性\n            if (StringUtils.hasLength(nameAttr)) {\n                valueHolder.setName(nameAttr);\n            }\n            valueHolder.setSource(this.extractSource(ele));\n            // 依据 type 或 name 做参数映射\n            bd.getConstructorArgumentValues().addGenericArgumentValue(valueHolder);\n        } finally {\n            this.parseState.pop();\n        }\n    }\n}\n```\n\n标签 `<constructor-arg />` 的解析过程中首先会获取 index、type 和 name 三个属性，然后依据是否设置了 index 属性分成两部分。如果设置了 index 属性，则整个解析过程如下：\n\n1. 解析 `<constructor-arg />` 标签元素，这里复用了 `<property />` 标签的解析过程；\n2. 利用 ValueHolder 封装解析出来的元素值，如果设置 type 和 name 属性则记录到到 ValueHolder 对象中；\n3. 检查是否存在重复的 index 配置，没有则以 index 为 key，将 ValueHolder 对象以 Map 的形式记录到 BeanDefinition 实例中。\n\n如果没有设置 index 属性，则整个解析过程如下：\n\n1. 解析 `<constructor-arg />` 标签元素，这里复用了 `<property />` 标签的解析过程；\n2. 利用 ValueHolder 封装解析出来的元素值，如果设置 type 和 name 属性则记录到到 ValueHolder 对象中；\n3. 以 type 或 name 去推断当前 ValueHolder 对象所对应的参数，并以 List 的形式记录到 BeanDefinition 实例中。\n\n上述步骤 3 的源码如下：\n\n```java\npublic void addGenericArgumentValue(ValueHolder newValue) {\n    Assert.notNull(newValue, \"ValueHolder must not be null\");\n    if (!this.genericArgumentValues.contains(newValue)) {\n        this.addOrMergeGenericArgumentValue(newValue);\n    }\n}\n\nprivate void addOrMergeGenericArgumentValue(ValueHolder newValue) {\n    if (newValue.getName() != null) {\n        // 如果在册的参数对象存在与当前相同的参数名称，则尝试 merge 操作\n        for (Iterator<ValueHolder> it = this.genericArgumentValues.iterator(); it.hasNext(); ) {\n            ValueHolder currentValue = it.next();\n            // name 相同\n            if (newValue.getName().equals(currentValue.getName())) {\n                if (newValue.getValue() instanceof Mergeable) {\n                    Mergeable mergeable = (Mergeable) newValue.getValue();\n                    if (mergeable.isMergeEnabled()) {\n                        newValue.setValue(mergeable.merge(currentValue.getValue()));\n                    }\n                }\n                it.remove();\n            }\n        }\n    }\n    this.genericArgumentValues.add(newValue);\n}\n```\n\n上述方法会去检查当前 ValueHolder 对象是否之前有加载过，没有则判断当前参数是否设置了 name 属性，如果有设置且当前 ValueHolder 对象与已有的 ValueHolder 对象存在相同的 name，则尝试对这个两个对象执行 merge 操作，最后记录 ValueHolder 对象到 `ConstructorArgumentValues#genericArgumentValues` 属性中，这是一个 List 类型属性。\n\n标签 `<constructor-arg />` 的解析过程还是相当复杂的，这里面有相当一部分逻辑复用了 `<property />` 标签的解析过程。\n\n- __解析 property 标签__\n\n标签 `<property />` 应该是 `<bean />` 标签中最常用的子标签，配置方式相当多元化，并且包含丰富的子标签元素。该标签的解析位于 `BeanDefinitionParserDelegate#parsePropertyElements` 方法中：\n\n```java\npublic void parsePropertyElements(Element beanEle, BeanDefinition bd) {\n    // 获取当前结点下的所有子标签\n    NodeList nl = beanEle.getChildNodes();\n    for (int i = 0; i < nl.getLength(); i++) {\n        Node node = nl.item(i);\n        // 如果是 <property/> 标签则进行解析\n        if (this.isCandidateElement(node) && this.nodeNameEquals(node, PROPERTY_ELEMENT)) {\n            this.parsePropertyElement((Element) node, bd);\n        }\n    }\n}\n\npublic void parsePropertyElement(Element ele, BeanDefinition bd) {\n    // 获取 name 属性值\n    String propertyName = ele.getAttribute(NAME_ATTRIBUTE);\n    if (!StringUtils.hasLength(propertyName)) {\n        this.error(\"Tag 'property' must have a 'name' attribute\", ele);\n        return;\n    }\n    this.parseState.push(new PropertyEntry(propertyName));\n    try {\n        // name 必须是唯一的\n        if (bd.getPropertyValues().contains(propertyName)) {\n            this.error(\"Multiple 'property' definitions for property '\" + propertyName + \"'\", ele);\n            return;\n        }\n        // 获取 value 值\n        Object val = this.parsePropertyValue(ele, bd, propertyName);\n        PropertyValue pv = new PropertyValue(propertyName, val);\n        // 解析 <meta/> 子标签\n        this.parseMetaElements(ele, pv);\n        pv.setSource(this.extractSource(ele));\n        // 记录到 BeanDefinition 实例中\n        bd.getPropertyValues().addPropertyValue(pv);\n    } finally {\n        this.parseState.pop();\n    }\n}\n```\n\n上述方法首先会去获取 `<property />` 标签的 name 属性，并确保 name 配置在 `<bean />` 标签范围内的唯一性；然后调用 `BeanDefinitionParserDelegate#parsePropertyValue` 方法解析标签值，接着调用 `BeanDefinitionParserDelegate#parseMetaElements` 方法来解析标签内的 `<meta />` 子标签，这个与之前 `<bean />` 标签的 `<meta />` 子标签的解析过程是一样的，唯一的区别在于这里将最终的解析结果存放到 PropertyValue 实例中，不过最终该实例还是交由 BeanDefinition 实例持有。\n\n下面的示例演示了在 `<property />` 标签下嵌入 `<meta />` 子标签，假设我们为 `MyBean#age` 属性配置了 meta：\n\n```xml\n<bean id=\"myBean\" class=\"org.zhenchao.spring.ioc.MyBean\">\n    <property name=\"age\" value=\"26\">\n        <meta key=\"age-meta-key\" value=\"age-meta-value\"/>\n    </property>\n</bean>\n```\n\n那么我们可以通过如下方式获取到该 meta 值：\n\n```java\nfinal BeanDefinition beanDefinition = beanFactory.getBeanDefinition(\"myBean\");\nfinal String metaValue = beanDefinition.getPropertyValues().getPropertyValue(\"age\").getMetadataAttribute(\"age-meta-key\").getValue();\n```\n\n上述过程的核心在于解析 `<property />` 标签的 value 配置，即 `BeanDefinitionParserDelegate#parsePropertyValue` 方法，这也是之前在分析 `<constructor-arg />` 标签时留着没有分析的方法，实现如下：\n\n```java\npublic Object parsePropertyValue(Element ele, BeanDefinition bd, @Nullable String propertyName) {\n    String elementName = (propertyName != null ? \"<property> element for property '\" + propertyName + \"'\" : \"<constructor-arg> element\");\n\n    // Should only have one child element: ref, value, list, etc.\n    NodeList nl = ele.getChildNodes();\n    Element subElement = null;\n    for (int i = 0; i < nl.getLength(); i++) {\n        Node node = nl.item(i);\n        // 跳过 description 和 meta 属性\n        if (node instanceof Element && !this.nodeNameEquals(node, DESCRIPTION_ELEMENT) && !this.nodeNameEquals(node, META_ELEMENT)) {\n            // 一个 <property/> 标签只能对应一种类型：ref, value, list, etc.\n            if (subElement != null) {\n                this.error(elementName + \" must not contain more than one sub-element\", ele);\n            } else {\n                subElement = (Element) node;\n            }\n        }\n    }\n\n    // 获取 ref 属性\n    boolean hasRefAttribute = ele.hasAttribute(REF_ATTRIBUTE);\n    // 获取 value 属性\n    boolean hasValueAttribute = ele.hasAttribute(VALUE_ATTRIBUTE);\n    if ((hasRefAttribute && hasValueAttribute) // 不能既配置了 ref，又配置了 value\n            || ((hasRefAttribute || hasValueAttribute) && subElement != null)) // 配置了 ref 或 value 属性，但是又配置了子标签\n    {\n        this.error(elementName + \" is only allowed to contain either 'ref' attribute OR 'value' attribute OR sub-element\", ele);\n    }\n\n    // 获取并解析 ref 属性\n    if (hasRefAttribute) {\n        String refName = ele.getAttribute(REF_ATTRIBUTE);\n        if (!StringUtils.hasText(refName)) {\n            this.error(elementName + \" contains empty 'ref' attribute\", ele);\n        }\n        RuntimeBeanReference ref = new RuntimeBeanReference(refName);\n        ref.setSource(this.extractSource(ele));\n        return ref;\n    }\n    // 获取并解析 value 配置\n    else if (hasValueAttribute) {\n        TypedStringValue valueHolder = new TypedStringValue(ele.getAttribute(VALUE_ATTRIBUTE));\n        valueHolder.setSource(this.extractSource(ele));\n        return valueHolder;\n    }\n    // 解析子标签\n    else if (subElement != null) {\n        return this.parsePropertySubElement(subElement, bd);\n    }\n    // 非法配置\n    else {\n        // Neither child element nor \"ref\" or \"value\" attribute found.\n        this.error(elementName + \" must specify a ref or value\", ele);\n        return null;\n    }\n}\n```\n\n标签 `<property />` 的配置方式分为三种：`<property name=\"\" value=\"\"/>`、`<property name=\"\" ref=\"\"/>`，以及 `<property name=\"\"></property>`，并且同一时刻只能使用其中的一种方式，上述方法也是针对这三种配置分而治之。\n\n如果配置方式是 `<property name=\"\" ref=\"\"/>`，则获取并解析 ref 属性值封装成 RuntimeBeanReference 对象返回。如果配置方式是 `<property name=\"\" value=\"\"/>`，则获取并解析 value 值封装成 TypedStringValue 对象返回。而对于 `<property name=\"\"></property>` 方式来说，因为配置的多元化，Spring 采用专门的方法 `BeanDefinitionParserDelegate#parsePropertySubElement` 对其进行解析处理：\n\n```java\npublic Object parsePropertySubElement(Element ele, BeanDefinition bd) {\n    return this.parsePropertySubElement(ele, bd, null);\n}\n\npublic Object parsePropertySubElement(Element ele, @Nullable BeanDefinition bd, @Nullable String defaultValueType) {\n    // 自定义标签\n    if (!this.isDefaultNamespace(ele)) {\n        return this.parseNestedCustomElement(ele, bd);\n    }\n    // 嵌套的 <bean/> 标签\n    else if (this.nodeNameEquals(ele, BEAN_ELEMENT)) {\n        BeanDefinitionHolder nestedBd = this.parseBeanDefinitionElement(ele, bd);\n        if (nestedBd != null) {\n            nestedBd = this.decorateBeanDefinitionIfRequired(ele, nestedBd, bd);\n        }\n        return nestedBd;\n    }\n    // 解析 <ref/> 标签\n    else if (this.nodeNameEquals(ele, REF_ELEMENT)) {\n        // 获取 bean 属性\n        String refName = ele.getAttribute(BEAN_REF_ATTRIBUTE);\n        boolean toParent = false;\n        // 未配置 bean 属性，尝试获取并解析 parent 属性\n        if (!StringUtils.hasLength(refName)) {\n            // A reference to the id of another bean in a parent context.\n            refName = ele.getAttribute(PARENT_REF_ATTRIBUTE);\n            toParent = true;\n            if (!StringUtils.hasLength(refName)) {\n                this.error(\"'bean' or 'parent' is required for <ref> element\", ele);\n                return null;\n            }\n        }\n        if (!StringUtils.hasText(refName)) {\n            this.error(\"<ref> element contains empty target attribute\", ele);\n            return null;\n        }\n        RuntimeBeanReference ref = new RuntimeBeanReference(refName, toParent);\n        ref.setSource(this.extractSource(ele));\n        return ref;\n    }\n    // 解析 <idref/> 标签\n    else if (this.nodeNameEquals(ele, IDREF_ELEMENT)) {\n        return this.parseIdRefElement(ele);\n    }\n    // 解析 <value/> 标签\n    else if (this.nodeNameEquals(ele, VALUE_ELEMENT)) {\n        return this.parseValueElement(ele, defaultValueType);\n    }\n    // 解析 <null/> 标签\n    else if (this.nodeNameEquals(ele, NULL_ELEMENT)) {\n        // It's a distinguished null value. Let's wrap it in a TypedStringValue\n        // object in order to preserve the source location.\n        TypedStringValue nullHolder = new TypedStringValue(null);\n        nullHolder.setSource(this.extractSource(ele));\n        return nullHolder;\n    }\n    // 解析 <array/> 标签\n    else if (this.nodeNameEquals(ele, ARRAY_ELEMENT)) {\n        return this.parseArrayElement(ele, bd);\n    }\n    // 解析 <list/> 标签\n    else if (this.nodeNameEquals(ele, LIST_ELEMENT)) {\n        return this.parseListElement(ele, bd);\n    }\n    // 解析 <set/> 标签\n    else if (this.nodeNameEquals(ele, SET_ELEMENT)) {\n        return this.parseSetElement(ele, bd);\n    }\n    // 解析 <map/> 标签\n    else if (this.nodeNameEquals(ele, MAP_ELEMENT)) {\n        return this.parseMapElement(ele, bd);\n    }\n    // 解析 <props/> 标签\n    else if (this.nodeNameEquals(ele, PROPS_ELEMENT)) {\n        return this.parsePropsElement(ele);\n    }\n    // 未知的标签\n    else {\n        this.error(\"Unknown property sub-element: [\" + ele.getNodeName() + \"]\", ele);\n        return null;\n    }\n}\n```\n\n上述方法的逻辑还是很清楚的，即判断当前标签类型，然后调用对应的解析方法进行针对性的处理。当前标签可以是自定义标签，也可以是默认标签，甚至是两种标签类型的多层嵌套，而 Spring 的实现也是采用方法的嵌套来处理复杂的配置。\n\n对于 `<ref />` 标签来说，提供的使用方式有 `<ref bean=\"...\" />` 和 `<ref parent=\"...\" />` 两种类型，这两种配置的区别如下：\n\n- `<ref bean=\"ref-bean\"/>` 表示可以引用同一容器或父容器中的 bean，这是最常用的形式。\n- `<ref parent=\"ref-bean\"/>` 表示引用父容器中的 bean。\n\n对于剩余的标签而言，除了 `<idref />`、`<value />` 和 `<null />`，其余的基本都是对集合类型的处理，对应的实现逻辑都比较清晰，这里不再深入。\n\n- __解析 qualifier 标签__\n\n注解 `@Qualifier` 在日常使用中较为常用，标签 `<qualifier />` 的作用与其相同，但是在配置中我们一般较少使用。该标签的解析实现位于 `BeanDefinitionParserDelegate#parseQualifierElements` 方法中：\n\n```java\npublic void parseQualifierElements(Element beanEle, AbstractBeanDefinition bd) {\n    // 获取当前结点下的所有子标签\n    NodeList nl = beanEle.getChildNodes();\n    for (int i = 0; i < nl.getLength(); i++) {\n        Node node = nl.item(i);\n        // 如果是 <qualifier/> 标签则进行解析\n        if (this.isCandidateElement(node) && this.nodeNameEquals(node, QUALIFIER_ELEMENT)) {\n            this.parseQualifierElement((Element) node, bd);\n        }\n    }\n}\n\npublic void parseQualifierElement(Element ele, AbstractBeanDefinition bd) {\n    // 获取 type 属性\n    String typeName = ele.getAttribute(TYPE_ATTRIBUTE);\n    if (!StringUtils.hasLength(typeName)) {\n        this.error(\"Tag 'qualifier' must have a 'type' attribute\", ele);\n        return;\n    }\n    this.parseState.push(new QualifierEntry(typeName));\n    try {\n        // 封装 <qualifier/> 标签配置\n        AutowireCandidateQualifier qualifier = new AutowireCandidateQualifier(typeName);\n        qualifier.setSource(this.extractSource(ele));\n        // 获取并设置 value 属性\n        String value = ele.getAttribute(VALUE_ATTRIBUTE);\n        if (StringUtils.hasLength(value)) {\n            qualifier.setAttribute(AutowireCandidateQualifier.VALUE_KEY, value);\n        }\n\n        // 获取并解析 <attribute/> 子标签\n        NodeList nl = ele.getChildNodes();\n        for (int i = 0; i < nl.getLength(); i++) {\n            Node node = nl.item(i);\n            if (this.isCandidateElement(node) && this.nodeNameEquals(node, QUALIFIER_ATTRIBUTE_ELEMENT)) {\n                Element attributeEle = (Element) node;\n                // 获取配置的 key 属性\n                String attributeName = attributeEle.getAttribute(KEY_ATTRIBUTE);\n                // 获取配置的 value 属性\n                String attributeValue = attributeEle.getAttribute(VALUE_ATTRIBUTE);\n                if (StringUtils.hasLength(attributeName) && StringUtils.hasLength(attributeValue)) {\n                    // 封装 <attribute/> 标签配置，并记录到 qualifier 对象中\n                    BeanMetadataAttribute attribute = new BeanMetadataAttribute(attributeName, attributeValue);\n                    attribute.setSource(this.extractSource(attributeEle));\n                    qualifier.addMetadataAttribute(attribute);\n                } else {\n                    this.error(\"Qualifier 'attribute' tag must have a 'name' and 'value'\", attributeEle);\n                    return;\n                }\n            }\n        }\n        // 记录 qualifier 对象到 BeanDefinition 中\n        bd.addQualifier(qualifier);\n    } finally {\n        this.parseState.pop();\n    }\n}\n```\n\n上述解析过程的逻辑比较简单，通过 AutowireCandidateQualifier 对象对 `<qualifier />` 标签及其子标签进行封装，然后记录到 BeanDefinition 实例中。\n\n至此，默认标签中的默认元素都已经全部解析完成，并设置到 GenericBeanDefinition 对象的相应属性中，该对象会被记录到 BeanDefinitionHolder 对象中返回，最后再回顾一下我们最开始出发的地方：\n\n```java\nBeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);\n```\n\n#### 解析自定义标签\n\n上一节我们介绍了 Spring 对于默认标签的解析过程，实际上在默认标签作用域内，Spring 还允许我们按照规范自定义标签。在开始分析自定义标签的解析过程之前，我们先来简单介绍一下自定义标签的用法，可能很多人还从来没有自定义过属于自己的标签。\n\n需要注意的一点是，这里我们自定义的标签与下一篇讲解的与默认标签对标的自定义标签并不是同一概念，这里的自定义标签是嵌套在默认标签内的，更准确的说是一种 __自定义属性标签__ 。自定义的过程分为如下几步：\n\n1. 创建标签实体类；\n2. 定义标签的描述 XSD 文件；\n3. 创建一个标签元素解析器，实现 BeanDefinitionDecorator 接口；\n4. 创建一个 handler 类，继承自 NamespaceHandlerSupport；\n5. 编写 spring.handlers 和 spring.schemas 文件。\n\n下面通过自定义一个简化版的 `<property />` 标签演示自定义和使用的过程，该自定义标签包含 name 和 value 两个属性，目的是将 value 值注入到 bean 对应的名为 name 值的属性中。\n\n第一步，先定义一个 `<property />` 标签对应的 POJO 类：\n\n```java\npublic class Property {\n\n    private String name;\n    private String value;\n\n    // 省略 getter 和 setter\n}\n```\n\n第二步，定义标签的 XSD 文件，以约束配置：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<schema xmlns=\"http://www.w3.org/2001/XMLSchema\"\n        targetNamespace=\"http://www.zhenchao.org/schema/property\"\n        xmlns:tns=\"http://www.zhenchao.org/schema/property\"\n        elementFormDefault=\"qualified\">\n    <element name=\"property\">\n        <complexType>\n            <attribute name=\"id\" type=\"string\"/>\n            <attribute name=\"name\" type=\"string\"/>\n            <attribute name=\"value\" type=\"string\"/>\n        </complexType>\n    </element>\n</schema>\n```\n\n第三步，创建标签元素解析器，这里需要实现 BeanDefinitionDecorator 接口。解析器用于对标签配置属性进行解析，并设置到 BeanDefinition 实例的属性集合中，后续在执行 `BeanFactory#getBean` 时容器会将属性集合中的值赋值给 bean 实例：\n\n```java\npublic class PropertyBeanDefinitionDecorator implements BeanDefinitionDecorator {\n\n    @Override\n    public BeanDefinitionHolder decorate(Node node, BeanDefinitionHolder definition, ParserContext parserContext) {\n        Element element = (Element) node;\n        if (\"mytag:property\".equals(element.getNodeName())) {\n            String name = element.getAttribute(\"name\");\n            Assert.hasText(name, \"The 'name' in 'mytag:property' is missing!\");\n            String value = element.getAttribute(\"value\");\n            Assert.hasText(value, \"The 'value' in 'mytag:property' is missing!\");\n            PropertyValue propertyValue = new PropertyValue(name, value);\n            definition.getBeanDefinition().getPropertyValues().addPropertyValue(propertyValue);\n        }\n        return definition;\n    }\n}\n```\n\n第四步，创建一个继承自 NamespaceHandlerSupport 抽象类的 handler 类，用于注册上面定义的解析器：\n\n```java\npublic class PropertyNamespaceHandler extends NamespaceHandlerSupport {\n\n    @Override\n    public void init() {\n        this.registerBeanDefinitionDecorator(\"property\", new PropertyBeanDefinitionDecorator());\n    }\n\n}\n```\n\n第五步，编写 spring.handlers 和 spring.schemas 文件，放于 META-INF 目录下面，内容如下：\n\n- spring.handlers\n\n```text\nhttp\\://www.zhenchao.org/schema/property=org.zhenchao.handler.PropertyNamespaceHandler\n```\n\n- spring.schemas\n\n```text\nhttp\\://www.zhenchao.org/schema/property.xsd=META-INF/property.xsd\n```\n\n下面来看一下如何使用。首先需要在头部定义标签命名空间：\n\n```xml\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:mytag=\"http://www.zhenchao.org/schema/property\"\n       xsi:schemaLocation=\n               \"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n                http://www.zhenchao.org/schema/property http://www.zhenchao.org/schema/property.xsd\"\n```\n\n假设 MyBean 中有一个 tag 属性，那么我们可以利用我们自定义的标签进行如下配置：\n\n```xml\n<bean id=\"myBean\" class=\"org.zhenchao.spring.ioc.MyBean\">\n    <mytag:property name=\"tag\" value=\"myCustomTagValue\"/>\n</bean>\n```\n\n当我们获取 MyBean 实例的 tag 属性值时，就能够得到我们配置的值，类似于标准 `<property />` 标签的效果，不过 Spring 提供的 `<property />` 标签功能要强大很多，这里只是演示如何自定义一个属于自己的标签，实际开发中我们自定义的标签也会比这要复杂的多。当我们在使用 Spring 默认的标签配置时，如果发现配置异常复杂，这个时候就可以考虑是否可以通过自定义标签来简化配置。不过笔者也不推荐为了自定义而自定义，自定义的标签给后来人阅读源码带来了很大的负担，增加了学习成本。\n\n介绍完了自定义标签的定义和使用方式，我们继续来剖析 Spring 对于自定义标签解析过程的实现。自定义标签的解析过程位于 `BeanDefinitionParserDelegate#decorateBeanDefinitionIfRequired` 方法中：\n\n```java\npublic BeanDefinitionHolder decorateBeanDefinitionIfRequired(Element ele, BeanDefinitionHolder originalDef) {\n    return this.decorateBeanDefinitionIfRequired(ele, originalDef, null);\n}\n\npublic BeanDefinitionHolder decorateBeanDefinitionIfRequired(\n        Element ele, BeanDefinitionHolder originalDef, @Nullable BeanDefinition containingBd) {\n\n    BeanDefinitionHolder finalDefinition = originalDef;\n\n    // Decorate based on custom attributes first.\n    // 1. 获取并处理当前标签的属性集合\n    NamedNodeMap attributes = ele.getAttributes();\n    // 遍历所有的属性，如果是目标自定义标签则进行处理\n    for (int i = 0; i < attributes.getLength(); i++) {\n        Node node = attributes.item(i);\n        finalDefinition = this.decorateIfRequired(node, finalDefinition, containingBd);\n    }\n\n    // Decorate based on custom nested elements.\n    // 2. 获取并处理当前标签的子标签集合\n    NodeList children = ele.getChildNodes();\n    // 遍历所有的子标签，如果是目标自定义标签则进行处理\n    for (int i = 0; i < children.getLength(); i++) {\n        Node node = children.item(i);\n        if (node.getNodeType() == Node.ELEMENT_NODE) {\n            finalDefinition = this.decorateIfRequired(node, finalDefinition, containingBd);\n        }\n    }\n    return finalDefinition;\n}\n```\n\n上述方法的实现逻辑分为两步执行：第一步处理当前标签所有的自定义属性；第二步处理当前标签的所有自定义子标签。不过，这两步最终都是通过调用 `BeanDefinitionParserDelegate#decorateIfRequired` 方法完成处理，实现如下：\n\n```java\npublic BeanDefinitionHolder decorateIfRequired(\n        Node node, BeanDefinitionHolder originalDef, @Nullable BeanDefinition containingBd) {\n\n    // 获取自定义标签的命名空间\n    String namespaceUri = this.getNamespaceURI(node);\n    if (namespaceUri != null && !this.isDefaultNamespace(namespaceUri)) {\n        // 根据命名空间找到对应的 NamespaceHandler\n        NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri);\n        if (handler != null) {\n            // 调用 decorate 方法处理自定义标签\n            BeanDefinitionHolder decorated =\n                    handler.decorate(node, originalDef, new ParserContext(this.readerContext, this, containingBd));\n            if (decorated != null) {\n                return decorated;\n            }\n        } else if (namespaceUri.startsWith(\"http://www.springframework.org/schema/\")) {\n            this.error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", node);\n        } else {\n            // A custom namespace, not to be handled by Spring - maybe \"xml:...\".\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"No Spring NamespaceHandler found for XML schema namespace [\" + namespaceUri + \"]\");\n            }\n        }\n    }\n    return originalDef;\n}\n```\n\n解析过程与我们定义自定义标签的过程相呼应。首先获取标签的命名空间，并以此来判断当前属性或标签是否是自定义的，如果是则获取对应的 NamespaceHandler 类对象，也就是我们之前自定义的 PropertyNamespaceHandler 类，我们在该类的 `PropertyNamespaceHandler#init` 方法中注册了我们的 BeanDefinitionDecorator 实例：\n\n```java\npublic void init() {\n    this.registerBeanDefinitionDecorator(\"property\", new PropertyBeanDefinitionDecorator());\n}\n```\n\n然后调用 handler 处理自定义的标签，这里本质上还是调用了我们自定义实现的 `PropertyBeanDefinitionDecorator#decorate` 方法，这样就将我们自定义的实现和 Spring 框架集成在了一起。\n\n#### 注册 BeanDefinition 对象\n\n在将 bean 的默认标签和自定义标签都设置到 BeanDefinition 实例中后，接下来就是向 IoC 容器注册 BeanDefinition 对象啦。Spring 定义了 BeanDefinitionHolder 类用于封装 BeanDefinition 对象，以及 bean 对应的唯一 name 和 alias 列表，并将 BeanDefinition 以 BeanDefinitionHolder 对象的形式注册到容器中。BeanDefinitionHolder 类的定义如下：\n\n```java\npublic class BeanDefinitionHolder implements BeanMetadataElement {\n\n    private final BeanDefinition beanDefinition;\n    private final String beanName;\n    private final String[] aliases;\n\n    // ... 省略方法\n}\n```\n\n往容器注册 BeanDefinitionHolder 对象的实现位于工具方法 `BeanDefinitionReaderUtils#registerBeanDefinition`  中，实现如下：\n\n```java\npublic static void registerBeanDefinition(\n        BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)\n        throws BeanDefinitionStoreException {\n\n    // 以 beanName 作为唯一标识进行注册\n    String beanName = definitionHolder.getBeanName();\n    registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());\n\n    // 建立 alias 与 beanName 之间的映射关系\n    String[] aliases = definitionHolder.getAliases();\n    if (aliases != null) {\n        for (String alias : aliases) {\n            registry.registerAlias(beanName, alias);\n        }\n    }\n}\n```\n\n整个注册过程主要做了两件事情：\n\n1. 以唯一的 beanName 作为 key，注册 BeanDefinition 实例，本质上就是以 map 进行内存存储；\n2. 建立 alias 与 beanName 之间的映射关系。\n\n下面分别对这两个过程展开分析。\n\n##### 往容器注册 BeanDefinition 对象\n\n注册 BeanDefinition 实例由 `DefaultListableBeanFactory#registerBeanDefinition` 方法实现，如下：\n\n```java\npublic void registerBeanDefinition(String beanName, BeanDefinition beanDefinition)\n        throws BeanDefinitionStoreException {\n    Assert.hasText(beanName, \"Bean name must not be empty\");\n    Assert.notNull(beanDefinition, \"BeanDefinition must not be null\");\n\n    if (beanDefinition instanceof AbstractBeanDefinition) {\n        try {\n            /*\n             * 校验 AbstractBeanDefinition 的 methodOverrides 属性，\n             * 验证 methodOverrides 是否与工厂方法并存或覆盖的方法根本不存在\n             */\n            ((AbstractBeanDefinition) beanDefinition).validate();\n        } catch (BeanDefinitionValidationException ex) {\n            throw new BeanDefinitionStoreException(\n                    beanDefinition.getResourceDescription(), beanName, \"Validation of bean definition failed\", ex);\n        }\n    }\n\n    // 尝试获取 beanName 已绑定的 BeanDefinition\n    BeanDefinition existingDefinition = this.beanDefinitionMap.get(beanName);\n    // 当前 beanName 已经绑定了某个 BeanDefinition 实例\n    if (existingDefinition != null) {\n        // 不允许覆盖绑定，则抛出异常\n        if (!this.isAllowBeanDefinitionOverriding()) {\n            throw new BeanDefinitionOverrideException(beanName, beanDefinition, existingDefinition);\n        }\n        // 覆盖后的 bean 的应用场景变小\n        else if (existingDefinition.getRole() < beanDefinition.getRole()) {\n            /*\n             * role 用于定义 bean 的应用场景：\n             * ROLE_APPLICATION：值为 0，用户\n             * ROLE_SUPPORT：值为 1，某些复杂配置的一部分\n             * ROLE_INFRASTRUCTURE：值为 2，完全内部使用\n             */\n            if (logger.isInfoEnabled()) {\n                // e.g. was ROLE_APPLICATION, now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE\n                logger.info(\"Overriding user-defined bean definition for bean '\" + beanName +\n                        \"' with a framework-generated bean definition: replacing [\" + existingDefinition + \"] with [\" + beanDefinition + \"]\");\n            }\n        } else if (!beanDefinition.equals(existingDefinition)) {\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"Overriding bean definition for bean '\" + beanName +\n                        \"' with a different definition: replacing [\" + existingDefinition + \"] with [\" + beanDefinition + \"]\");\n            }\n        } else {\n            if (logger.isTraceEnabled()) {\n                logger.trace(\"Overriding bean definition for bean '\" + beanName +\n                        \"' with an equivalent definition: replacing [\" + existingDefinition + \"] with [\" + beanDefinition + \"]\");\n            }\n        }\n        // 注册到容器中，本质上用 map 保存注册信息\n        this.beanDefinitionMap.put(beanName, beanDefinition);\n    }\n    // 当前 beanName 未绑定任何 BeanDefinition 实例\n    else {\n        if (this.hasBeanCreationStarted()) {\n            // Cannot modify startup-time collection elements anymore (for stable iteration)\n            synchronized (this.beanDefinitionMap) {\n                this.beanDefinitionMap.put(beanName, beanDefinition);\n                List<String> updatedDefinitions = new ArrayList<>(this.beanDefinitionNames.size() + 1);\n                updatedDefinitions.addAll(this.beanDefinitionNames);\n                updatedDefinitions.add(beanName);\n                this.beanDefinitionNames = updatedDefinitions;\n                this.removeManualSingletonName(beanName);\n            }\n        } else {\n            // Still in startup registration phase\n            this.beanDefinitionMap.put(beanName, beanDefinition);\n            this.beanDefinitionNames.add(beanName);\n            this.removeManualSingletonName(beanName);\n        }\n        this.frozenBeanDefinitionNames = null;\n    }\n\n    // 清空当前 beanName 对应的 BeanDefinition 缓存\n    if (existingDefinition != null || this.containsSingleton(beanName)) {\n        this.resetBeanDefinition(beanName);\n    }\n}\n```\n\n往容器注册 BeanDefinition 时首先会判断 BeanDefinition 是否是 AbstractBeanDefinition 类型实例，如果是则进一步验证其 methodOverrides 属性，防止出现与工厂方法并存或覆盖的方法根本不存在的情况。然后检查 beanName 是否已经绑定了 BeanDefinition 实例，如果已经绑定且允许覆盖已有的实例，则执行覆盖操作，如果没有绑定则直接注册。注册操作本质上是以 beanName 作为 key，以 BeanDefinition 实例作为 value 记录到 map 数据结构中，后续加载 bean 时会从依据给定的 beanName 从中获取 BeanDefinition,并依据 BeanDefinition 创建 bean 对象。\n\n##### 建立 alias 到 beanName 之间的映射\n\n往容器注册 BeanDefinition 的第二步是建立 alias 与 beanName 之间的映射关系。如果把 BeanDefinition 实例看做是文件的话，那么 beanName 可以看作是文件的硬链接，而 alias 则可以看作是软连接，是 beanName 的快捷方式。建立映射的过程由 `SimpleAliasRegistry#registerAlias` 方法实现：\n\n```java\npublic void registerAlias(String name, String alias) {\n    Assert.hasText(name, \"'name' must not be empty\");\n    Assert.hasText(alias, \"'alias' must not be empty\");\n    synchronized (this.aliasMap) {\n        // alias 与 name 相同，则将 alias 从映射关系中删除\n        if (alias.equals(name)) {\n            this.aliasMap.remove(alias);\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"Alias definition '\" + alias + \"' ignored since it points to same name\");\n            }\n        }\n        // alias 与 name 不同，建立映射关系\n        else {\n            String registeredName = this.aliasMap.get(alias);\n            if (registeredName != null) {\n                // 已经建立了正确的映射，直接返回\n                if (registeredName.equals(name)) {\n                    // An existing alias - no need to re-register\n                    return;\n                }\n                // 已经与其它 beanName 建立了映射，且不允许覆盖\n                if (!this.allowAliasOverriding()) {\n                    throw new IllegalStateException(\"Cannot define alias '\" + alias + \"' for name '\" +\n                            name + \"': It is already registered for name '\" + registeredName + \"'.\");\n                }\n            }\n            // 检测 name 和 alias 之间是否构成环路，如果构成环路则抛出异常\n            this.checkForAliasCircle(name, alias);\n            // 不存在环路，建立 alias 与 name 之间的映射关系\n            this.aliasMap.put(alias, name);\n        }\n    }\n}\n```\n\n上述实现比较简单，如代码注释，不再多做撰述。\n\n#### 发布事件通知\n\n至此，Spring 完成了对 `<bean />` 标签的解析过程，将 `<bean />` 标签配置转换成 BeanDefinition 对象注册到 IoC 容器中。考虑到一些应用可能需要感知这一事件，Spring 在完成对一个 `<bean />` 标签的解析之后会发布事件通知，通过调用 `ReaderContext#fireComponentRegistered` 方法将消息通知到具体的监听者。如果用户希望监听这一事件，可以实现 ReaderEventListener 接口，Spring 会在发布事件通知时回调 `ReaderEventListener#componentRegistered` 方法。\n\n### 标签 import 的解析过程\n\n标签 `<import />` 也是我们比较常用的标签，尤其是在大型项目中，通过将各个模块的 Spring 配置分开定义，并在需要的地方通过 `<import />` 标签引入，可以让配置更加的清晰，易于管理。该标签的解析过程位于 `DefaultBeanDefinitionDocumentReader#importBeanDefinitionResource` 方法中：\n\n```java\nprotected void importBeanDefinitionResource(Element ele) {\n    // 获取 resource 属性，例如 <import resource=\"xx.xml\"/>\n    String location = ele.getAttribute(RESOURCE_ATTRIBUTE);\n    if (!StringUtils.hasText(location)) {\n        this.getReaderContext().error(\"Resource location must not be empty\", ele);\n        return;\n    }\n\n    // 解析路径中的系统属性，比如可能存在如 ${user.dir} 的占位符\n    location = this.getReaderContext().getEnvironment().resolveRequiredPlaceholders(location);\n\n    Set<Resource> actualResources = new LinkedHashSet<>(4);\n\n    // 检测是绝对路径，还是相对路径\n    boolean absoluteLocation = false;\n    try {\n        absoluteLocation = ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute();\n    } catch (URISyntaxException ex) {\n        // cannot convert to an URI, considering the location relative\n        // unless it is the well-known Spring prefix \"classpath*:\"\n    }\n\n    // 绝对路径\n    if (absoluteLocation) {\n        try {\n            // 加载 bean 定义，并返回加载的数目\n            int importCount = this.getReaderContext().getReader().loadBeanDefinitions(location, actualResources);\n            if (logger.isTraceEnabled()) {\n                logger.trace(\"Imported \" + importCount + \" bean definitions from URL location [\" + location + \"]\");\n            }\n        } catch (BeanDefinitionStoreException ex) {\n            this.getReaderContext().error(\"Failed to import bean definitions from URL location [\" + location + \"]\", ele, ex);\n        }\n    }\n    // 相对路径\n    else {\n        // No URL -> considering resource location as relative to the current file.\n        try {\n            int importCount;\n            // Resource 存在多个子类，各子类的 createRelative 实现不一样，这里先使用子类的方法尝试解析\n            Resource relativeResource = this.getReaderContext().getResource().createRelative(location);\n            if (relativeResource.exists()) {\n                // 加载 bean 定义，并返回加载的数目\n                importCount = this.getReaderContext().getReader().loadBeanDefinitions(relativeResource);\n                actualResources.add(relativeResource);\n            } else {\n                // 解析不成功，使用默认的解析器 ResourcePatternResolver 进行解析\n                String baseLocation = this.getReaderContext().getResource().getURL().toString();\n                importCount = this.getReaderContext().getReader().loadBeanDefinitions(\n                        StringUtils.applyRelativePath(baseLocation, location), actualResources);\n            }\n            if (logger.isTraceEnabled()) {\n                logger.trace(\"Imported \" + importCount + \" bean definitions from relative location [\" + location + \"]\");\n            }\n        } catch (IOException ex) {\n            this.getReaderContext().error(\"Failed to resolve current resource location\", ele, ex);\n        } catch (BeanDefinitionStoreException ex) {\n            this.getReaderContext().error(\"Failed to import bean definitions from relative location [\" + location + \"]\", ele, ex);\n        }\n    }\n    Resource[] actResArray = actualResources.toArray(new Resource[0]);\n    // 解析完成之后，发布事件通知\n    this.getReaderContext().fireImportProcessed(location, actResArray, this.extractSource(ele));\n}\n```\n\n标签 `<import />` 仅包含一个 resource 属性，该属性指定了配置文件的路径。路径可以是相对路径，也可以是绝对路径，路径中还可能存在一些系统属性占位符，比如 `${user.dir}`。上述方法首先对系统属性进行了处理，然后判断当前路径属于绝对路径还是相对路径，并分而治之。\n\n### 标签 alias 的解析过程\n\n标签 `<alias />` 用于为一个已定义的 bean 设置别名，虽然在 `<bean />` 标签中可以通过 name 属性定义别名，但是存在即合理，标签 `<alias/>` 总有它的应用场景。针对该标签的解析由 `DefaultBeanDefinitionDocumentReader#processAliasRegistration` 方法实现：\n\n```java\nprotected void processAliasRegistration(Element ele) {\n    // 获取 name 属性\n    String name = ele.getAttribute(NAME_ATTRIBUTE);\n    // 获取 alias 属性\n    String alias = ele.getAttribute(ALIAS_ATTRIBUTE);\n    boolean valid = true;\n    // name 不允许为空\n    if (!StringUtils.hasText(name)) {\n        this.getReaderContext().error(\"Name must not be empty\", ele);\n        valid = false;\n    }\n    // alias 不允许为空\n    if (!StringUtils.hasText(alias)) {\n        this.getReaderContext().error(\"Alias must not be empty\", ele);\n        valid = false;\n    }\n    if (valid) {\n        try {\n            // 注册 alias\n            this.getReaderContext().getRegistry().registerAlias(name, alias);\n        } catch (Exception ex) {\n            this.getReaderContext().error(\"Failed to register alias '\" + alias + \"' for bean with name '\" + name + \"'\", ele, ex);\n        }\n        // 注册完成，发布事件通知\n        this.getReaderContext().fireAliasRegistered(name, alias, this.extractSource(ele));\n    }\n}\n```\n\n标签 `<alias/>` 的解析过程复用了上面介绍的 `SimpleAliasRegistry#registerAlias` 方法，用于建立 alias 与 beanName 之间的映射关系，同时避免出现环路。\n\n### 标签 beans 的解析过程\n\n上面介绍的几种标签都是位于 `<beans />` 标签下面，本小节将要分析的 `<beans />` 标签是嵌套在外围 `<beans />` 标签中的，本质上没有什么区别，所以 Spring 的解析过程也是递归调用了之前的解析过程，实现如下：\n\n```java\nprotected void doRegisterBeanDefinitions(Element root) {\n    // Any nested <beans> elements will cause recursion in this method. In\n    // order to propagate and preserve <beans> default-* attributes correctly,\n    // keep track of the current (parent) delegate, which may be null. Create\n    // the new (child) delegate with a reference to the parent for fallback purposes,\n    // then ultimately reset this.delegate back to its original (parent) reference.\n    // this behavior emulates a stack of delegates without actually necessitating one.\n    BeanDefinitionParserDelegate parent = this.delegate;\n    this.delegate = this.createDelegate(this.getReaderContext(), root, parent);\n\n    // 处理 profile 标签（其作用类比 pom.xml 中的 profile）\n    if (this.delegate.isDefaultNamespace(root)) {\n        String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE);\n        if (StringUtils.hasText(profileSpec)) {\n            String[] specifiedProfiles = StringUtils.tokenizeToStringArray(\n                    profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS);\n            // We cannot use Profiles.of(...) since profile expressions are not supported in XML config. See SPR-12458 for details.\n            if (!this.getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) {\n                if (logger.isDebugEnabled()) {\n                    logger.debug(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec +\n                            \"] not matching: \" + this.getReaderContext().getResource());\n                }\n                return;\n            }\n        }\n    }\n\n    // 模板方法，预处理\n    this.preProcessXml(root);\n    // 解析并注册 BeanDefinition\n    this.parseBeanDefinitions(root, this.delegate);\n    // 模板方法，后处理\n    this.postProcessXml(root);\n\n    this.delegate = parent;\n}\n```\n\n上述方法用于解析 `<beans />` 标签。慢着！是不是看着有点眼熟，没错，本文最开始就是从这个方法中的 `DefaultBeanDefinitionDocumentReader#parseBeanDefinitions` 方法开挖的。饶了一大圈，我们又回到了起点，突然想到了一部电影 [《恐怖游轮》](https://movie.douban.com/subject/3011051/)，不多说了，睡觉~\n\n### 参考\n\n1. [Spring 源码深度解析](https://book.douban.com/subject/25866350/)\n","tags":["Spring"],"categories":["spring"]},{"title":"Spring IoC 源码解析：简单容器的初始化过程","url":"/2017/05/10/spring/spring-ioc-bean-factory/","content":"\n本文将主要对定义在 XML 文件中的 bean 从静态配置到加载成为可使用对象的过程，即 IoC 容器的初始化过程进行一个整体的分析。在讲解上不主张对各个组件进行深究，只求对简单容器的实现有一个整体的认识，具体实现细节留到后面专门用针对性的篇章进行讲解。\n\n首先我们引入一个 Spring 入门示例，假设我们现在定义了一个类 MyBean，我们希望利用 Spring 管理类对象。<!-- more -->这里我们采用 Spring 经典的 XML 配置文件形式进行配置：\n\n```xml\n<bean id=\"myBean\" class=\"org.zhenchao.spring.ioc.MyBean\"/>\n```\n\n我们将配置文件命名为 `spring-core.xml`，获取 bean 实例最原始的方式如下：\n\n```java\n// 1. 定义资源描述\nResource resource = new ClassPathResource(\"spring-core.xml\");\n// 2. 基于 XmlBeanFactory 初始化 IoC 容器\nXmlBeanFactory beanFactory = new XmlBeanFactory(resource);\n// 3. 从 IoC 容器中加载获取 bean 实例\nMyBean myBean = (MyBean) beanFactory.getBean(\"myBean\");\n```\n\n上述示例虽然简单，但麻雀虽小，五脏俱全，完整的让 Spring 执行了一遍加载配置文件，创建并初始化 bean 实例的过程。虽然从 Spring 3.1 版本开始，XmlBeanFactory 已经被置为 `deprecated`，但是 Spring 并没有定义出更加高级的基于 XML 加载 bean 实例的 BeanFactory，而是推荐采用更加原生的方式，即组合使用 DefaultListableBeanFactory 和 XmlBeanDefinitionReader 来完成上述过程：\n\n```java\nResource resource = new ClassPathResource(\"spring-core.xml\");\nDefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();\nXmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(beanFactory);\nreader.loadBeanDefinitions(resource);\nMyBean myBean = (MyBean) beanFactory.getBean(\"myBean\");\n```\n\nXmlBeanFactory 实际上是对 DefaultListableBeanFactory 和 XmlBeanDefinitionReader 组合使用方式的封装，并没有增加新的处理逻辑。考虑到使用习惯，我们仍将继续基于 XmlBeanFactory 分析 bean 的加载过程。\n\nBean 的加载过程整体上可以分成两步：\n\n1. 完成由静态配置到内存表示 BeanDefinition 的转换；\n2. 基于 BeanDefinition 实例创建并初始化 bean 实例。\n\n我们将第一步称为 bean 的解析与注册的过程，解析配置并注册到容器；将第二步看作是 bean 的创建和初始化的过程。\n\n### 资源的描述与加载\n\n如上面的例子所示，在加载配置文件之前，Spring 都会将配置文件封装成 Resource 对象。Resource 本身是一个接口，是对资源描述符的一种抽象。资源（File、URL、Classpath 等等）是众多框架使用和运行的基础，Spring 当然也不例外，框架诞生之初就是基于 XML 文件对 bean 进行配置。在开始分析容器的初始化过程之前，我们先来对支撑容器运行的 Resource 接口及其实现类做一个简单的了解。\n\n#### 资源的抽象声明\n\n资源在 java 中被抽象成 URL，通过注册相应的 handler 来处理不同资源的操作逻辑，而 Spring 则采用 Resource 接口对各种资源进行统一抽象。Resource 接口声明了针对资源的基本操作，包括是否存在、是否可读，以及是否已经打开等等。Resource 接口实现如下：\n\n```java\npublic interface InputStreamSource {\n    /** 返回一个新的输入流 */\n    InputStream getInputStream() throws IOException;\n}\n```\n\n```java\npublic interface Resource extends InputStreamSource {\n    /** 资源是否存在 */\n    boolean exists();\n\n    /** 资源是否可读 */\n    default boolean isReadable() {\n        return exists();\n    }\n\n    /** 资源流是否已经打开 */\n    default boolean isOpen() {\n        return false;\n    }\n\n    /** 是否是 File 对象 */\n    default boolean isFile() {\n        return false;\n    }\n\n    /** 返回资源对应的 URL 对象 */\n    URL getURL() throws IOException;\n\n    /** 返回资源对应的 URI 对象 */\n    URI getURI() throws IOException;\n\n    /** 返回资源对应的 File 对象 */\n    File getFile() throws IOException;\n\n    /** 返回资源对应的 ReadableByteChannel 对象 */\n    default ReadableByteChannel readableChannel() throws IOException {\n        return Channels.newChannel(getInputStream());\n    }\n\n    /** 返回文件的长度 */\n    long contentLength() throws IOException;\n\n    /** 返回文件上次被修改的时间戳 */\n    long lastModified() throws IOException;\n\n    /** 依据当前资源创建一个相对的资源，并返回资源对象 */\n    Resource createRelative(String relativePath) throws IOException;\n\n    /** 返回资源的文件名 */\n    String getFilename();\n\n    /** 返回资源的描述信息 */\n    String getDescription();\n}\n```\n\n由继承关系可以看到 Resource 继承了 InputStreamSource 接口，该接口描述任何可以返回 InputStream 的类，通过 `InputStreamSource#getInputStream` 方法获取对应的 InputStream 对象。\n\nResource 本身则声明了针对资源的基本操作，Spring 也针对不同类型的资源定义了相应的类实现，比如：文件（FileSystemResource）、字节数组资源（ByteArrayResource）、ClassPath 路径资源（ClassPathResource），以及 URL 资源（UrlResource）等，如下图所示（仅包含 IoC 层面的 Resource 定义）：\n\n![image](/images/2017/spring-ioc-resource.png)\n\n#### 资源的具体定义\n\n参考上述 UML 图，可以将 Resource 的定义分为三层，其中第 1 层是 Resource 接口定义；第 2 层是对 Resource 接口的扩展，包括 AbstractResource 抽象类、WritableResource 接口，以及 ContextResource 接口；第 3 层是具体的针对不同类型资源的 Resource 实现类。\n\n关于第 1 层 Resource 接口的定义已经在上一小节进行了说明，下面来简单介绍一下第 2 层和第 3 层中的 Resource 的定义。首先来看一下 __第 2 层__ ，包括：\n\n- __WritableResource__\n\nWritableResource 接口用于描述一个资源是否支持可写的特性。在 Resource 接口定义中仅描述了一个资源是否可读，因为可读相对于可写是更加基本的特性，而对于可读又可写的文件来说，可以使用 WritableResource 接口予以描述。该接口声明了 3 个方法，其中 `WritableResource#isWritable` 方法用于判断文件是否可写；方法 `WritableResource#getOutputStream` 用于获取可写文件的 OutputStream 对象；方法 `WritableResource#writableChannel` 用于获取可写文件的 WritableByteChannel 对象。\n\n- __ContextResource__\n\nContextResource 是在 2.5 版本引入的一个扩展接口，用于描述从上下文环境中加载的资源，该接口仅声明了一个方法 `ContextResource#getPathWithinContext`，用于获取上下文环境的相对路径。\n\n- __AbstractResource__\n\nAbstractResource 抽象类不是对某一具体资源的描述，而是一种编程技巧。Resource 接口中声明了资源的多种操作方法，如果我们直接去实现 Resource 接口，势必要提供针对每一个方法的实现，而这些方法可能并不需要全部提供支持。AbstractResource 抽象类对所有方法提供了默认实现，通过继承 AbstractResource 抽象类可以针对性的选择实现相应的方法。\n\n下面来看一下 __第 3 层__ Resource 定义，这一层针对不同的资源类型定义了相应的 Resource 实现，这些实现类均派生自 AbstractResource 抽象类，其中一部分实现了 WritableResource 接口或 ContextResource 接口。\n\n- __AbstractFileResolvingResource__\n\nAbstractFileResolvingResource 抽象了解析 URL 所指代的文件为 File 对象的过程，具体的实现典型的有 UrlResource 和 ClassPathResource。AbstractFileResolvingResource 抽象类定义如下：\n\n```java\npublic abstract class AbstractFileResolvingResource extends AbstractResource {\n    /** 解析 URL 所指向的 File 对象 */\n    public File getFile() throws IOException;\n    /** 解析 URI 所指向的 File 对象 */\n    protected File getFile(URI uri) throws IOException;\n    /** 解析 URL 所指向的底层文件为 File 对象，比如压缩包中的文件 */\n    protected File getFileForLastModifiedCheck() throws IOException;\n    public boolean exists()\n    public boolean isReadable();\n    public boolean isFile();\n    public long contentLength() throws IOException;\n    public long lastModified() throws IOException;\n    public ReadableByteChannel readableChannel() throws IOException;\n}\n```\n\n我们来看一下 `AbstractFileResolvingResource#getFile` 和 `AbstractFileResolvingResource#getFileForLastModifiedCheck` 方法的实现：\n\n```java\npublic File getFile() throws IOException {\n    // 获取 URL 对象\n    URL url = getURL();\n    // 如果是 JBoss VFS 文件\n    if (url.getProtocol().startsWith(ResourceUtils.URL_PROTOCOL_VFS)) {\n        return VfsResourceDelegate.getResource(url).getFile();\n    }\n    return ResourceUtils.getFile(url, getDescription());\n}\n```\n\n上述方法用于解析 URL 所指向的文件为 File 对象，首先调用 `AbstractResource#getURL` 方法获取 URL 对象，然后检查当前 URL 是不是 JBoss VFS 文件，如果是则走 VFS 文件解析策略，否则调用工具类方法 `ResourceUtils#getFile` 进行解析，过程如下：\n\n```java\npublic static File getFile(URL resourceUrl, String description) throws FileNotFoundException {\n    Assert.notNull(resourceUrl, \"Resource URL must not be null\");\n    // URL 不是 file 协议，说明不是指代文件\n    if (!URL_PROTOCOL_FILE.equals(resourceUrl.getProtocol())) {\n        throw new FileNotFoundException(\n                description + \" cannot be resolved to absolute file path \" +\n                        \"because it does not reside in the file system: \" + resourceUrl);\n    }\n    try {\n        // 由 URL 对象构造 File 对象\n        return new File(toURI(resourceUrl).getSchemeSpecificPart());\n    } catch (URISyntaxException ex) {\n        // Fallback for URLs that are not valid URIs (should hardly ever happen).\n        return new File(resourceUrl.getFile());\n    }\n}\n```\n\n方法 `AbstractFileResolvingResource#getFileForLastModifiedCheck` 相对于上述方法提供了对压缩文件 URL 路径的解析，实现如下：\n\n```java\nprotected File getFileForLastModifiedCheck() throws IOException {\n    // 获取 URL 对象\n    URL url = getURL();\n    // 如果 URL 的协议是 jar、war、zip、vfszip 或 wsjar 之一，则执行解析\n    if (ResourceUtils.isJarURL(url)) {\n        URL actualUrl = ResourceUtils.extractArchiveURL(url);\n        // 如果是 JBoss VFS 文件\n        if (actualUrl.getProtocol().startsWith(ResourceUtils.URL_PROTOCOL_VFS)) {\n            return VfsResourceDelegate.getResource(actualUrl).getFile();\n        }\n        return ResourceUtils.getFile(actualUrl, \"Jar URL\");\n    } else {\n        // 走普通的解析逻辑\n        return getFile();\n    }\n}\n```\n\n方法首先获取 URL 对象，然后判断是不是压缩文件 URL，如果不是就走前面的 `AbstractFileResolvingResource#getFile` 进行常规解析；否则，即当前 URL 的协议是 jar、war、zip、vfszip 或 wsjar 中的一个，则首先解析 URL 得到常规 URL 对象，然后执行与 `AbstractFileResolvingResource#getFile` 方法相同的逻辑。\n\n针对 AbstractFileResolvingResource 主要由两个直接实现类，即 UrlResource 和 ClassPathResource。其中 __UrlResource__ 主要是解析 `file:` 协议；而 __ClassPathResource__ 主要是对类上下文环境中资源的描述，基于 ClassLoader 或 Class 来定位加载资源。\n\n- __FileSystemResource__\n\nFileSystemResource 是对文件系统类型资源的描述，这也是 Spring 中典型的资源类型。该类继承自 AbstractResource，并实现了 WritableResource 接口。\n\nFileSystemResource 提供了两个构造方法分别由 File 对象和文件路径来构造资源对象，对于传入的路径，考虑输入的不确定性会执行 `StringUtils#cleanPath` 方法对其进行格式化。FileSystemResource 中的方法实现几乎都依赖于 File 类的 API。这里提一下 `FileSystemResource#createRelative` 方法，该方法会基于相对路径创建 FileSystemResource 对象，实现如下：\n\n```java\npublic Resource createRelative(String relativePath) {\n    String pathToUse = StringUtils.applyRelativePath(this.path, relativePath);\n    return (this.file != null ? new FileSystemResource(pathToUse) :\n            new FileSystemResource(this.filePath.getFileSystem(), pathToUse));\n}\n```\n\n首先利用 `StringUtils#applyRelativePath` 方法创建资源绝对路径，主要操作是截取 path 的最后一个文件分隔符 `/` 前面的内容与 relativePath 进行拼接，然后基于新的路径构造 FileSystemResource 对象。\n\n- __PathResource__\n\nPathResource 在 4.0 版本引入的基于 JDK 7 NIO 2.0 中的 Path 类所实现的资源类型。NIO 2.0 针对本地 I/O 引入了许多新的类，用来改变 java 语言在 I/O 方面一直被人诟病的慢特性，所以 PathResource 也表示 Spring 由 BIO 向 NIO 的迈进。\n\n- __DescriptiveResource__\n\nDescriptiveResource 资源并非表示一个真实可读的资源，而是对文件的一种描述，所以这类资源的 `DescriptiveResource#exists` 方法始终返回 false。这类资源的作用在于必要的时候用来占坑，例如文档所说的，当一个方法需要你传递一个资源对象，但又不会在方法中真正读取该对象的时候，如果没有合适的资源对象作为参数，就创建一个 DescriptiveResource 资源做参数吧。\n\n- __BeanDefinitionResource__\n\nBeanDefinitionResource 是对 BeanDefinition 对象的一个包装。上一篇我们曾介绍过 BeanDefinition 对象是 Spring 核心类之一，是对 bean 定义在 IoC 容器内部进行表示的数据结构，我们在配置文件中定义的 bean，经过加载之后都会以 BeanDefinition 对象的形式存储在 IoC 容器中。BeanDefinitionResource 在实现上仅仅是持有 BeanDefinition 对象，并提供 getter 方法，而一般资源操作方法几乎都不支持。\n\n- __ByteArrayResource__\n\nByteArrayResource 利用字节数组作为资源存储的标的，JDK 原生也提供了字节数组式的 I/O 流，所以二者在设计思想是相通的。\n\n- __VfsResource__\n\nVfsResource 对 [JBoss Virtual File System (VFS)](https://developer.jboss.org/wiki/VFS3UserGuide) 提供了支持，针对 JBoss VFS 的说明，官网简介如下：\n\n> The Virtual File System (VFS) framework is an abstraction layer designed to simplify the programmatic access to file system resources.  One of the key benefits of VFS is to hide certain file system details and allow for file system layouts that are not required to reflect a real file system.  This allows for great flexibility and makes it possible to navigate arbitrary structures (ex. archives) as though they are part of a single file system.\n\n具体没用过，不多做解释。\n\n- __InputStreamResource__\n\nInputStreamResource 基于给定的 InputStream 来创建资源，流是一般文件的更低一层，程序设计的共性就是越往底层走需要考虑的问题就越多，所以 Spring 明确表示，如果有相应的上层实现则不推荐直接使用 InputStreamResource。\n\n#### 资源加载\n\nSpring 定义了 ResourceLoader 接口用于抽象对于资源的加载操作，该接口的定义如下：\n\n```java\npublic interface ResourceLoader {\n    Resource getResource(String location);\n    ClassLoader getClassLoader();\n}\n```\n\n其中 `ResourceLoader#getResource` 方法用于获取指定路径的 Resource 对象；方法 `ResourceLoader#getClassLoader` 则返回当前 ResourceLoader 所使用的类加载器，一些情况下我们可能需要基于该类加载器执行一些相对定位操作。\n\n![image](/images/2017/spring-ioc-resource-loader.png)\n\n上述 UML 图展示了 ResourceLoader 的继承关系，我们可以将所有的接口分为加载器和解析器两类。加载器的作用不言而喻，对于解析器而言，由前面的分析我们知道 Spring 针对不同资源类型分别定义响应的 Resource 实现类，Spring 通过解析器解析具体资源类型，并加载返回对应的 Resource 对象。\n\n在日常使用过程中，我们通常都是以 Ant 风格来配置资源路径。Ant 风格的支持给我们的配置带来了极大的灵活性，这也是 PathMatchingResourcePatternResolver 的功劳。路径的解析本质上依赖于各种规则，Ant 风格也不例外，有兴趣的同学可以自己阅读一下 PathMatchingResourcePatternResolver 解析路径的过程。\n\n### Bean 的解析与注册\n\n![image](/images/2017/spring-ioc-bean-initialization.png)\n\n当启动 IoC 容器时，Spring 需要读取 bean 相关的配置，并将各个 bean 的配置封装成 BeanDefinition 对象注册到容器中，上图展示了这一解析并注册过程的交互时序。当我们执行 `new XmlBeanFactory(resource)` 的时候已经完成了将配置文件包装成 Spring 定义的 Resource 对象，并开始执行解析和注册过程。XmlBeanFactory 的构造方法定义如下：\n\n```java\npublic XmlBeanFactory(Resource resource) throws BeansException {\n    this(resource, null);\n}\n\npublic XmlBeanFactory(Resource resource, BeanFactory parentBeanFactory) throws BeansException {\n    super(parentBeanFactory);\n    // 加载 XML 资源\n    this.reader.loadBeanDefinitions(resource);\n}\n```\n\n构造方法首先是调用了父类 DefaultListableBeanFactory 构造方法，这是一个非常核心的类，它包含了简单 IoC 容器所具备的重要功能，是一个 IoC 容器的基本实现。然后调用了 `XmlBeanDefinitionReader#loadBeanDefinitions` 方法开始加载配置。\n\nSpring 在设计上采用了许多程序设计的基本原则，比如迪米特法则、开闭原则，以及接口隔离原则等等，这样的设计为后续的扩展提供了极大的灵活性，也增强了模块的复用性。\n\nSpring 使用了专门的 BeanDefinition 加载器对资源进行加载，这里使用的是 XmlBeanDefinitionReader 类，用来加载基于 XML 文件配置的 bean。整个加载过程可以概括如下：\n\n1. 利用 EncodedResource 二次包装 Resource 对象；\n2. 获取资源对应的输入流，并构造 InputSource 对象；\n3. 获取 XML 文件的实体解析器和验证模式，并加载 XML 文件返回 Document 对象；\n4. 由 Document 对象解析并注册 BeanDefinition。\n\n上述过程执行期间，Spring 会暂存正在加载的 Resource 对象，避免在配置中出现配置文件之间的循环 import。\n\n下面针对上述步骤展开说明。首先来看 __步骤一__ ，这一步会采用 EncodedResource 对 Resource 对象进行二次封装。EncodedResource 从命名来看是对于 Resource 的一种修饰，而不是用来描述某一类具体的资源，所以 EncodedResource 并没有实现 Resource 接口，而是采用了类似装饰者模式的方式对 Resource 对象进行包装，以实现对 Resource 输入流按照指定的字符集进行编码。\n\n完成了对 Resource 对象进行编码封装之后， __步骤二__  会依据编码将 Resource 对应的输入流封装成 InputSource 对象，从而为加载 XML 做准备。InputSource 并非是 Spring 中定义的类，这个类是 JDK 提供的对 XML 实体的原生支持\n\n接下来，Spring 会调用 `XmlBeanDefinitionReader#doLoadBeanDefinitions` 方法正式开始针对 BeanDefinition 的加载和注册过程，对应 __步骤三__ 和 __步骤四__ ，该方法实现如下：\n\n```java\nprotected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException {\n      try {\n          // 获取 XML 文件的实体解析器和验证模式，并加载 XML 文件返回 Document 对象\n          Document doc = this.doLoadDocument(inputSource, resource);\n          // 由 Document 对象解析并注册 BeanDefinition\n          int count = this.registerBeanDefinitions(doc, resource);\n          return count;\n      }\n      // ... 省略异常处理\n  }\n```\n\n方法逻辑还是很清晰的，第一步加载 XML 获取 Document 对象，第二步由 Document 对象解析得到 BeanDefinition 对象并注册到 IoC 容器中。\n\n加载 XML 文件首先会获取对应的实体解析器和验证模式，方法 `XmlBeanDefinitionReader#doLoadDocument` 实现了获取实体解析器、验证模式，以及构造 Document 对象的逻辑：\n\n```java\nprotected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception {\n    return this.documentLoader.loadDocument(\n            inputSource,\n            this.getEntityResolver(),  // 获取实体解析器\n            this.errorHandler,\n            this.getValidationModeForResource(resource),  // 获取验证模式\n            this.isNamespaceAware());\n}\n```\n\nXML 是半结构化数据，其验证模式用于保证结构的正确性，常见的验证模式有 DTD 和 XSD 两种。获取验证模式的过程实现如下：\n\n```java\nprotected int getValidationModeForResource(Resource resource) {\n    int validationModeToUse = this.getValidationMode();\n    if (validationModeToUse != VALIDATION_AUTO) {\n        // 手动指定了验证模式\n        return validationModeToUse;\n    }\n\n    // 没有指定验证模式，自动检测\n    int detectedMode = this.detectValidationMode(resource);\n    if (detectedMode != VALIDATION_AUTO) {\n        return detectedMode;\n    }\n\n    // 检测验证模式失败，默认采用 XSD 模式\n    return VALIDATION_XSD;\n}\n```\n\n上述实现描述了获取验证模式的执行流程，如果没有手动指定那么 Spring 会去自动检测。对于 XML 文件的解析，SAX 首先会读取 XML 文件头声明，以获取相应验证文件地址，并下载验证文件。网络异常会影响下载过程，这个时候可以通过注册一个实体解析器实现寻找验证文件的逻辑。\n\n完成了对于验证模式和解析器的获取，就可以开始加载 Document 对象了，这里本质上调用的是 `DefaultDocumentLoader#loadDocument` 方法，实现如下：\n\n```java\npublic Document loadDocument(InputSource inputSource,\n                             EntityResolver entityResolver,\n                             ErrorHandler errorHandler,\n                             int validationMode,\n                             boolean namespaceAware) throws Exception {\n\n    DocumentBuilderFactory factory = this.createDocumentBuilderFactory(validationMode, namespaceAware);\n    if (logger.isTraceEnabled()) {\n        logger.trace(\"Using JAXP provider [\" + factory.getClass().getName() + \"]\");\n    }\n    DocumentBuilder builder = this.createDocumentBuilder(factory, entityResolver, errorHandler);\n    return builder.parse(inputSource);\n}\n```\n\n整个过程与我们平常解析 XML 文件的流程大致相同。\n\n完成了对 XML 文件到 Document 对象的构造，我们终于可以解析 Document 对象并注册 BeanDefinition 了，这一过程由 `XmlBeanDefinitionReader#registerBeanDefinitions` 方法实现：\n\n```java\npublic int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException {\n    // 使用 DefaultBeanDefinitionDocumentReader 构造\n    BeanDefinitionDocumentReader documentReader = this.createBeanDefinitionDocumentReader();\n    // 记录之前已经注册的 BeanDefinition 数目\n    int countBefore = this.getRegistry().getBeanDefinitionCount();\n    // 加载并注册 BeanDefinition\n    documentReader.registerBeanDefinitions(doc, this.createReaderContext(resource));\n    // 返回本次加载的 BeanDefinition 数目\n    return this.getRegistry().getBeanDefinitionCount() - countBefore;\n}\n```\n\n上述方法所做的工作就是创建对应的 BeanDefinitionDocumentReader 对象，基于该对象加载并注册 BeanDefinition，并最终返回本次新注册的 BeanDefinition 的数量。加载并注册 BeanDefinition 的过程具体由 DefaultBeanDefinitionDocumentReader 实现：\n\n```java\npublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) {\n    this.readerContext = readerContext;\n    // 从文档的 ROOT 结点开始解析\n    this.doRegisterBeanDefinitions(doc.getDocumentElement());\n}\n\nprotected void doRegisterBeanDefinitions(Element root) {\n    // Any nested <beans> elements will cause recursion in this method. In\n    // order to propagate and preserve <beans> default-* attributes correctly,\n    // keep track of the current (parent) delegate, which may be null. Create\n    // the new (child) delegate with a reference to the parent for fallback purposes,\n    // then ultimately reset this.delegate back to its original (parent) reference.\n    // this behavior emulates a stack of delegates without actually necessitating one.\n    BeanDefinitionParserDelegate parent = this.delegate;\n    this.delegate = this.createDelegate(this.getReaderContext(), root, parent);\n\n    // 处理 profile 标签（其作用类比 pom.xml 中的 profile）\n    if (this.delegate.isDefaultNamespace(root)) {\n        String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE);\n        if (StringUtils.hasText(profileSpec)) {\n            String[] specifiedProfiles = StringUtils.tokenizeToStringArray(\n                    profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS);\n            // We cannot use Profiles.of(...) since profile expressions are not supported in XML config. See SPR-12458 for details.\n            if (!this.getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) {\n                return;\n            }\n        }\n    }\n\n    // 模板方法，预处理\n    this.preProcessXml(root);\n    // 解析并注册 BeanDefinition\n    this.parseBeanDefinitions(root, this.delegate);\n    // 模板方法，后处理\n    this.postProcessXml(root);\n\n    this.delegate = parent;\n}\n```\n\n解析的过程首先处理 `<profile/>` 标签，这个属性在 Spring 中不是很常用，不过在 maven 中倒是挺常见，可以类比进行理解，即在配置多套环境时可以根据部署的具体环境来选择使用哪一套配置。上述方法会先检测是否配置了 profile 标签，如果是就需要从上下文环境中确认当前激活了哪一套配置。\n\n具体解析并注册 BeanDefinition 的过程交由 `DefaultBeanDefinitionDocumentReader#parseBeanDefinitions` 方法完成，实现如下：\n\n```java\nprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) {\n    // 解析默认标签\n    if (delegate.isDefaultNamespace(root)) {\n        NodeList nl = root.getChildNodes();\n        for (int i = 0; i < nl.getLength(); i++) {\n            Node node = nl.item(i);\n            if (node instanceof Element) {\n                Element ele = (Element) node;\n                // 解析默认标签\n                if (delegate.isDefaultNamespace(ele)) {\n                    this.parseDefaultElement(ele, delegate);\n                }\n                // 解析自定义标签\n                else {\n                    delegate.parseCustomElement(ele);\n                }\n            }\n        }\n    }\n    // 解析自定义标签\n    else {\n        delegate.parseCustomElement(root);\n    }\n}\n```\n\n解析期间会判断当前标签是默认标签还是自定义标签，并按照不同的策略进行解析，这是一个复杂的过程，后面会用文章进行针对性讲解，这里暂不深究。\n\n到这里我们已经完成了由静态配置到 BeanDefinition 的解析，并注册到 IoC 容器中的过程，下一节将继续探究如何创建并初始化 bean 实例。\n\n### Bean 实例的创建和初始化\n\n完成了对 bean 配置的加载和解析之后，相应的配置就全部转换成 BeanDefinition 对象的形式存在于 IoC 容器中。接下来我们可以调用 `AbstractBeanFactory#getBean` 方法获取 bean 实例，该方法实现如下：\n\n```java\npublic Object getBean(String name) throws BeansException {\n    return this.doGetBean(name, null, null, false);\n}\n```\n\n上述方法只是简单的将请求委托给  `AbstractBeanFactory#doGetBean` 方法进行处理，这也符合我们的预期。方法   `AbstractBeanFactory#doGetBean`  可以看作是是获取 bean 实例的整体框架代码，通过调度各个模块完成对 bean 实例及其依赖的 bean 实例的初始化操作，并最终返回我们期望的 bean 实例。方法实现如下：\n\n```java\nprotected <T> T doGetBean(final String name,\n                          @Nullable final Class<T> requiredType,\n                          @Nullable final Object[] args,\n                          boolean typeCheckOnly) throws BeansException {\n\n    /*\n     * 获取 name 对应的真正 beanName\n     *\n     * 因为传入的参数可以是 alias，也可能是 FactoryBean 的 name，所以需要进行解析，包含以下内容：\n     * 1. 如果是 FactoryBean，则去掉 “&” 前缀\n     * 2. 沿着引用链获取 alias 对应的最终 name\n     */\n    final String beanName = this.transformedBeanName(name);\n    Object bean;\n\n    /*\n     * 尝试从单例集合中获取对应的单实例，\n     * 在实例化 bean 的时候可能需要实例化依赖的 bean 对象，Spring 为了避免循环依赖会采用早期引用机制\n     */\n    Object sharedInstance = this.getSingleton(beanName);\n    // 目标实例已经实例化过\n    if (sharedInstance != null && args == null) {\n        if (logger.isTraceEnabled()) {\n            if (this.isSingletonCurrentlyInCreation(beanName)) {\n                logger.trace(\"Returning eagerly cached instance of singleton bean '\" + beanName +\n                        \"' that is not fully initialized yet - a consequence of a circular reference\");\n            } else {\n                logger.trace(\"Returning cached instance of singleton bean '\" + beanName + \"'\");\n            }\n        }\n        // 处理 FactoryBean\n        bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, null);\n    }\n    // 目标实例不存在\n    else {\n        // Fail if we're already creating this bean instance: We're assumably within a circular reference.\n        if (this.isPrototypeCurrentlyInCreation(beanName)) {\n            /*\n             * 只有在单例模式下才会尝试解决循环依赖问题，\n             * 对于原型模式，如果存在循环依赖，直接抛出异常\n             */\n            throw new BeanCurrentlyInCreationException(beanName);\n        }\n\n        // 获取父 BeanFactory 实例\n        BeanFactory parentBeanFactory = this.getParentBeanFactory();\n        // 如果已经加载的 bean 定义中不包含目标 bean，则尝试从父 BeanFactory 中获取\n        if (parentBeanFactory != null && !this.containsBeanDefinition(beanName)) {\n            // 递归到父 BeanFactory 中进行检索\n            String nameToLookup = this.originalBeanName(name);\n            if (parentBeanFactory instanceof AbstractBeanFactory) {\n                return ((AbstractBeanFactory) parentBeanFactory)\n                        .doGetBean(nameToLookup, requiredType, args, typeCheckOnly);\n            } else if (args != null) {\n                // Delegation to parent with explicit args.\n                return (T) parentBeanFactory.getBean(nameToLookup, args);\n            } else if (requiredType != null) {\n                // No args -> delegate to standard getBean method.\n                return parentBeanFactory.getBean(nameToLookup, requiredType);\n            } else {\n                return (T) parentBeanFactory.getBean(nameToLookup);\n            }\n        }\n\n        // 如果不仅仅是做类型检查，则标记该 bean 即将被创建\n        if (!typeCheckOnly) {\n            this.markBeanAsCreated(beanName);\n        }\n\n        try {\n            // 如果存在父 bean，则继承父 bean 定义\n            final RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName);\n            // 检查 bean 是否是抽象的，如果是则抛出异常\n            this.checkMergedBeanDefinition(mbd, beanName, args);\n\n            // 加载当前 bean 依赖的 bean 实例\n            String[] dependsOn = mbd.getDependsOn();\n            // 存在依赖，递归实例化依赖的 bean 实例\n            if (dependsOn != null) {\n                for (String dep : dependsOn) {\n                    // 检查是否存在循环依赖\n                    if (this.isDependent(beanName, dep)) {\n                        throw new BeanCreationException(mbd.getResourceDescription(), beanName,\n                                \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\");\n                    }\n                    // 缓存依赖调用\n                    this.registerDependentBean(dep, beanName);\n                    try {\n                        // 初始化依赖的 bean 实例\n                        this.getBean(dep);\n                    } catch (NoSuchBeanDefinitionException ex) {\n                        throw new BeanCreationException(mbd.getResourceDescription(), beanName,\n                                \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex);\n                    }\n                }\n            }\n\n            /* 创建 bean 实例 */\n\n            // scope == singleton\n            if (mbd.isSingleton()) {\n                sharedInstance = this.getSingleton(beanName, () -> {\n                    try {\n                        // 实例化 bean 对象\n                        return this.createBean(beanName, mbd, args);\n                    } catch (BeansException ex) {\n                        // Explicitly remove instance from singleton cache: It might have been put there\n                        // eagerly by the creation process, to allow for circular reference resolution.\n                        // Also remove any beans that received a temporary reference to the bean.\n                        this.destroySingleton(beanName); // 清理工作，从单例缓存中移除\n                        throw ex;\n                    }\n                });\n                // 处理 FactoryBean\n                bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, mbd);\n            }\n            // scope == prototype\n            else if (mbd.isPrototype()) {\n                // It's a prototype -> create a new instance.\n                Object prototypeInstance = null;\n                try {\n                    // 设置正在创建的状态\n                    this.beforePrototypeCreation(beanName);\n                    // 创建 bean 实例\n                    prototypeInstance = this.createBean(beanName, mbd, args);\n                } finally {\n                    this.afterPrototypeCreation(beanName);\n                }\n                // 处理 FactoryBean\n                bean = this.getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);\n            }\n            // other scope\n            else {\n                String scopeName = mbd.getScope();\n                final Scope scope = this.scopes.get(scopeName);\n                if (scope == null) {\n                    throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\");\n                }\n                try {\n                    Object scopedInstance = scope.get(beanName, () -> {\n                        this.beforePrototypeCreation(beanName);\n                        try {\n                            return this.createBean(beanName, mbd, args);\n                        } finally {\n                            this.afterPrototypeCreation(beanName);\n                        }\n                    });\n                    // 处理 FactoryBean\n                    bean = this.getObjectForBeanInstance(scopedInstance, name, beanName, mbd);\n                } catch (IllegalStateException ex) {\n                    throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" +\n                            \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex);\n                }\n            }\n        } catch (BeansException ex) {\n            this.cleanupAfterBeanCreationFailure(beanName);\n            throw ex;\n        }\n    }\n\n    // 如果要求做类型检查，则检查 bean 的实际类型是否是期望的类型，对应 getBean 时指定的 requireType\n    if (requiredType != null && !requiredType.isInstance(bean)) {\n        try {\n            // 执行类型转换，转换成期望的类型\n            T convertedBean = this.getTypeConverter().convertIfNecessary(bean, requiredType);\n            if (convertedBean == null) {\n                throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());\n            }\n            return convertedBean;\n        } catch (TypeMismatchException ex) {\n            if (logger.isTraceEnabled()) {\n                logger.trace(\"Failed to convert bean '\" + name + \"' to required type '\" +\n                        ClassUtils.getQualifiedName(requiredType) + \"'\", ex);\n            }\n            throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());\n        }\n    }\n    return (T) bean;\n}\n```\n\n整个方法的执行流程可以概括为：\n\n1. 获取参数 name 对应的真正的 beanName；\n2. 检查缓存或者实例工厂中是否有对应的单例，若存在则进行实例化并返回对象，否则继续往下执行；\n3. 执行 prototype 类型依赖检查，防止循环依赖；\n4. 如果当前 BeanFactory 中不存在需要的 bean 实例，则尝试从父 BeanFactory 中获取；\n5. 将之前解析过程返得到的 GenericBeanDefinition 对象合并为 RootBeanDefinition 对象，便于后续处理；\n6. 如果存在依赖的 bean，则递归初始化依赖的 bean 实例；\n7. 依据当前 bean 的作用域对 bean 进行实例化；\n8. 如果对返回 bean 类型有要求则进行检查，按需做类型转换；\n9. 返回 bean 实例。\n\n上述方法从整体来看就是一个框架代码，总结了从接收一个 beanName 到返回对应 bean 实例的完整流程。\n\n### 总结\n\n本文从整体的角度分析了一个 bean 从 XML 配置，到载入 IoC 容器中封装成 BeanDefinition 对象，最后依据请求初始化并返回 bean 实例的完整流程，目的在于从整体建立对 IoC 容器运行机制的认识。从下一篇开始，我们将回到起点，沿着本文梳理的 IoC 容器运行主线，对中间执行的具体细节进行深入分析。\n\n### 参考\n\n1. [Spring 源码深度解析](https://book.douban.com/subject/25866350/)\n","tags":["Spring"],"categories":["spring"]},{"title":"Spring IoC 源码解析：容器的基本层次结构","url":"/2017/04/30/spring/spring-ioc-container/","content":"\n控制反转（IoC: Inversion of Control）是 Spring Framework 的核心基础特性，也是面向对象程序设计中的重要原则，其目的在于降低程序之间的耦合度。控制反转一般分为 __依赖注入（DI: Dependency Injection）__ 和 __依赖查找（DL: Dependency Lookup）__ 两种类型，不过依赖注入应用更加广泛，所以大部分时候依赖注入等同于控制反转。\n\n在面向对象程序设计中，对象一般用于承载和处理数据，不同对象之间的相互依赖与合作构成了我们的软件系统。设想在大型软件系统设计中，需要大量的对象通过相互依赖和交互进行合作，如果这些依赖关系由对象自己去控制和管理，那么耦合度将会非常高，不易于系统的扩展和维护。这个时候我们可以将对象的依赖关系交由 IoC 容器进行管理，将对象的新建和引用赋值等操作交由 IoC 容器统一完成，而对象只需要专心负责承载和处理数据即可。这样的设计可以降低系统在实现上的复杂性和耦合度，让系统更加灵活，满足“开闭原则”，并易于扩展和维护。<!-- more -->\n\nSpring IoC 是 IoC 设计原则的轻量化实现，纵览 Spring IoC 容器类的 UML 图（如下）将会发现 Spring IoC 容器的设计可以分为两条主线：\n\n1. 实现了 BeanFactory 接口的简单容器。\n2. 以 ApplicationContext 应用上下文为核心的高级容器。\n\n其中 ApplicationContext 相对于 BeanFactory 而言增加了许多高级特性，让原本在 BeanFactory 中需要编码实现的功能，简化到用配置或注解即可完成。\n\n![image](/images/2017/spring-ioc.png)\n\n如上图所示，若以一条直线从中间将该图分为左右两半的话，那么简单容器结构主要分布在左半部分，继承路径为：\n\n```text\nBeanFactory\n--> HierarchicalBeanFactory\n-----> ConfigurableBeanFactory\n--------> ConfigurableListableBeanFactory\n-----------> DefaultListableBeanFactory\n```\n\n而高级容器结构主要分布在右半部分，当然高级容器的实现是建立在简单容器基础之上的，继承路径为：\n\n```text\nBeanFactory\n--> ListableBeanFactory\n-----> ApplicationContext\n--------> ConfigurableApplicationContext & WebApplicationContext\n```\n\n### Bean 的内存表示\n\n现实中的容器用来盛放物品，Spring 的容器也不例外，这里的物品就是 bean 定义和实例。我们通常对于 bean 的印象是一个个躺在配置文件中的 `<bean/>` 标签，或者是被注解的类，但是这些都是 bean 的静态形式，是还没有被放入容器的物料，最终（加载完配置之后，调用 `BeanFactory#getBean` 之前）加载到容器中的是一个个 BeanDefinition 对象。\n\nBeanDefinition 的继承关系如下图所示，其中 RootBeanDefinition、ChildBeanDefinition，以及 GenericBeanDefinition 是三个主要的类实现。有时我们需要在配置时通过 `parent` 属性指定 bean 之间的父子关系，这时父 bean 采用 RootBeanDefinition 表示，而子 bean 则采用 ChildBeanDefinition 表示。GenericBeanDefinition 自 2.5 版本引入，是服务于一般的 bean 定义的一站式中心。\n\n![image](/images/2017/spring-ioc-bean-definition.png)\n\n这三个类都是由 AbstractBeanDefinition 抽象类派生而来，该抽象类中包含了 bean 的所有配置项和一些支持程序运行的属性，实现如下：\n\n```java\npublic abstract class AbstractBeanDefinition extends BeanMetadataAttributeAccessor implements BeanDefinition, Cloneable {\n\n    // ... 省略常量定义\n\n    /** 对应的类 Class 对象 */\n    private volatile Object beanClass;\n    /** 作用域，对应 scope 属性 */\n    private String scope = SCOPE_DEFAULT;\n    /** 抽象类标识，对应 abstract 属性 */\n    private boolean abstractFlag = false;\n    /** 延迟加载标识，对应 lazy-init 属性 */\n    private Boolean lazyInit;\n    /** 自定装载类型，对应 autowire 配置 */\n    private int autowireMode = AUTOWIRE_NO;\n    /** 依赖检查，对应 dependency-check 属性 */\n    private int dependencyCheck = DEPENDENCY_CHECK_NONE;\n    /** 对应 depends-on 属性，表示一个 bean 实例化前置依赖另一个 bean */\n    private String[] dependsOn;\n    /** 对应 autowire-candidate 属性，设置为 false 时表示取消当前 bean 作为自动装配候选者的资格 */\n    private boolean autowireCandidate = true;\n    /** 对应 primary 属性，当自动装配存在多个候选者时，将当前 bean 作为首选 */\n    private boolean primary = false;\n    /** 对应 qualifier 属性 */\n    private final Map<String, AutowireCandidateQualifier> qualifiers = new LinkedHashMap<>();\n    /** 创建 bean 实例时的回调函数 */\n    private Supplier<?> instanceSupplier;\n    /** 非配置项，表示允许访问非公开的构造器和方法，由程序设置 */\n    private boolean nonPublicAccessAllowed = true;\n    /**\n     * 非配置项，表示是否允许以宽松的模式解析构造函数，由程序设置\n     *\n     * 例如：如果设置为 true，则在下列情况时不会抛出异常（示例来源于《Spring 源码深度解析》）\n     * interface ITest{}\n     * class ITestImpl implements ITest {}\n     * class Main {\n     * Main(ITest i){}\n     * Main(ITestImpl i){}\n     * }\n     */\n    private boolean lenientConstructorResolution = true;\n    /** 对应 factory-bean 属性 */\n    private String factoryBeanName;\n    /** 对应 factory-method 属性 */\n    private String factoryMethodName;\n    /** 构造函数注入属性，对应 <construct-arg/> 标签 */\n    private ConstructorArgumentValues constructorArgumentValues;\n    /** 记录 <property/> 属性集合 */\n    private MutablePropertyValues propertyValues;\n    /** 记录 <lookup-method/> 和 <replaced-method/> 标签配置 */\n    private MethodOverrides methodOverrides = new MethodOverrides();\n    /** 对应 init-method 属性 */\n    private String initMethodName;\n    /** 对应 destroy-method 属性 */\n    private String destroyMethodName;\n    /** 非配置项，是否执行 init-method，由程序设置 */\n    private boolean enforceInitMethod = true;\n    /** 非配置项，是否执行 destroy-method，由程序设置 */\n    private boolean enforceDestroyMethod = true;\n    /** 非配置项，表示 bean 是否是用户定义而不是程序定义的，创建 AOP 时为 true，由程序设置 */\n    private boolean synthetic = false;\n    /**\n     * 非配置项，定义 bean 的应用场景，由程序设置，角色如下：\n     * ROLE_APPLICATION：用户\n     * ROLE_INFRASTRUCTURE：完全内部使用\n     * ROLE_SUPPORT：某些复杂配置的一部分\n     */\n    private int role = BeanDefinition.ROLE_APPLICATION;\n    /** 描述信息，对应 description 标签 */\n    private String description;\n    /** 定义的资源 */\n    private Resource resource;\n\n    // ... 省略方法定义\n}\n```\n\nBeanDefinition 是 Spring IoC 容器表示 bean 配置的内部数据结构，Spring 将各个 bean 对应的 BeanDefinition 实例注册记录在 BeanDefinitionRegistry 中，该接口定义了对 BeanDefinition 的各种增删查操作，类似于内存数据库，其实现类 SimpleBeanDefinitionRegistry 主要以 Map 作为存储介质。\n\n### 简单 IoC 容器\n\nBeanFactory 是 Spring IoC 容器设计的基础，定义了容器所具备的最基本的方法，实现如下：\n\n```java\npublic interface BeanFactory {\n    /**\n     * 用户使用容器时可以使用转义符“&”来得到 FactoryBean 实例，用来区分通过容器获取的是 FactoryBean 产生的对象还是获取 FactoryBean 实例本身，\n     * 例如：如果 myBean 是一个 FactoryBean，那么使用“&myBean”得到的是 FactoryBean 实例，而不是 myBean 这个由 FactoryBean 构造的实例\n     */\n    String FACTORY_BEAN_PREFIX = \"&\";\n\n    /** 根据 bean 的名字获取对应的 bean 实例 */\n    Object getBean(String name) throws BeansException;\n\n    /** 根据 bean 的名字获取对应的 bean 实例，增加了对象类型检查 */\n    <T> T getBean(String name, Class<T> requiredType) throws BeansException;\n\n    /** 根据 bean 的名字获取对应的 bean 实例，可以指定构造函数的参数或者工厂方法的参数 */\n    Object getBean(String name, Object... args) throws BeansException;\n\n    /** 根据 bean 类型获取对应的 bean 实例 */\n    <T> T getBean(Class<T> requiredType) throws BeansException;\n\n    /** 根据 bean 类型获取对应的 bean 实例，可以指定构造函数的参数或者工厂方法的参数 */\n    <T> T getBean(Class<T> requiredType, Object... args) throws BeansException;\n\n    /** 判断容器是否持有指定名称的 bean 实例 */\n    boolean containsBean(String name);\n\n    /** 是不是单例 */\n    boolean isSingleton(String name) throws NoSuchBeanDefinitionException;\n\n    /** 是不是原型对象 */\n    boolean isPrototype(String name) throws NoSuchBeanDefinitionException;\n\n    /** 判断 name 对应的 bean 实例是不是指定 Class 类型 */\n    boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException;\n\n    /** 判断 name 对应的 bean 实例是不是指定 Class 类型 */\n    boolean isTypeMatch(String name, Class<?> typeToMatch) throws NoSuchBeanDefinitionException;\n\n    /** 获取 bean 实例的 Class 对象 */\n    Class<?> getType(String name) throws NoSuchBeanDefinitionException;\n\n    /** 获取 bean 的所有别名，如果不存在则返回空 */\n    String[] getAliases(String name);\n}\n```\n\nBeanFactory 中定义的各个方法及其作用如上述代码注释。整个设计还是比较简洁和直观的，其中将近一半是获取 bean 对象的方法重载，另外就是对 bean 属性的获取和判定。BeanFactory 接口仅仅是定义了 IoC 容器的最基本形式，具体实现都交由子类完成，后面我们会举例说明。\n\n#### FactoryBean 与 BeanFactory\n\nSpring 在 BeanFactory 接口中定义了一个 `FACTORY_BEAN_PREFIX` 常量，用来获取 FactoryBean 对象，这个需要与我们本节所讨论的 BeanFactory 相区分开来，虽然两者在名字上很相似，但却是完全不同的两个类。BeanFactory 以 Factory 结尾，顾名思义它是一个工厂，用来管理 bean 对象，而 FactoryBean 则以 Bean 结尾，说明它本质上还是一个 bean，只是比我们通常所见的 bean 稍微特殊了一点。\n\nFactoryBean 接口的定义如下，主要是用来构造一些复杂对象。如果一个对象的配置十分复杂，通过编码实现相对于配置可能是更好的选择。\n\n```java\npublic interface FactoryBean<T> {\n\n    /** 获取由 FactoryBean 创建的 bean 实例*/\n    T getObject() throws Exception;\n\n    /** 返回由 FactoryBean 创建的 bean 的 Class 类型 */\n    Class<?> getObjectType();\n\n    /** 是否是单实例 */\n    default boolean isSingleton() {\n        return true;\n    }\n\n}\n```\n\n下面举例说明 FactoryBean 的用法。假设有一个接口 Printer 和两个实现类：OddPrinter 和 EvenPrinter，定义如下：\n\n```java\npublic interface Printer {\n\n    void print(int x);\n\n}\n\n@Component\npublic class EvenPrinter implements Printer {\n\n    @Override\n    public void print(int x) {\n        System.out.println(\"even: \" + x);\n    }\n\n}\n\n@Component\npublic class OddPrinter implements Printer {\n\n    @Override\n    public void print(int x) {\n        System.out.println(\"odd: \" + x);\n    }\n\n}\n```\n\nOddPrinter 和 EvenPrinter 的功能很简单，分别用于打印奇数和偶数，假设现在有这样一个需求：对于一个入参 x，如果 x 是偶数则调用 EvenPrinter 实例的 `EvenPrinter#print` 方法，否则调用 OddPrinter 实例的 `OddPrinter#print` 方法，也就是说我们需要依据入参的值动态选择 Printer 的实例。\n\n针对上述需求，基于 FactoryBean 的实现如下：\n\n```java\n@Component(\"printer-factory\")\npublic class PrinterFactory extends AbstractFactoryBean<Printer> {\n\n    private final Printer printer;\n\n    private final OddPrinter oddPrinter;\n    private final EvenPrinter evenPrinter;\n\n    public PrinterFactory(@Autowired OddPrinter oddPrinter, @Autowired EvenPrinter evenPrinter) {\n        this.oddPrinter = oddPrinter;\n        this.evenPrinter = evenPrinter;\n        this.printer = new ProxyPrinter();\n    }\n\n    @Override\n    protected Printer createInstance() throws Exception {\n        return this.printer;\n    }\n\n    @Override\n    public Class<?> getObjectType() {\n        return ProxyPrinter.class;\n    }\n\n    private class ProxyPrinter implements Printer {\n\n        @Override\n        public void print(int x) {\n            if (x % 2 == 0) {\n                evenPrinter.print(x);\n            } else {\n                oddPrinter.print(x);\n            }\n        }\n    }\n\n}\n```\n\n主函数：\n\n```java\nApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:spring-core.xml\");\nfinal Printer printer = (Printer) context.getBean(\"printer-factory\");\nprinter.print(1); // odd: 1\nprinter.print(2); // even: 2\n```\n\n基于 FactoryBean 可以利用静态 IoC 来模拟动态 IoC。\n\n由上述示例可以看出当调用 `BeanFactory#getBean` 方法获取名为 `printer-factory` 的 bean 时，实际返回的却是 Printer 类实例，如果我们希望返回 ProxyPrinter 类示例，可以在 `printer-factory` 名称前加 `&` 标识符，即 `context.getBean(\"&printer-factory\")`，这样就可以拿到 FactoryBean 实例。\n\n#### 基本结构设计\n\nBeanFactory 定义了容器的基本形式，Spring 又在此基础上逐层扩展以丰富容器的特性，如下图所示：\n\n![image](/images/2017/spring-ioc-bean-factory.png)\n\n下面针对主要的类和接口的功能进行一个简单的介绍：\n\n- __HierarchicalBeanFactory__\n\nHierarchicalBeanFactory 译为中文是分层的 BeanFactory，它相对于 BeanFactory 增加了对父 BeanFactory 的获取。下层 IoC 容器（也叫子容器）可以通过 `HierarchicalBeanFactory#getParentBeanFactory` 方法访问父 IoC 容器，让容器的设计具备了层次性。这种层次性增强了容器的扩展性和灵活性，我们可以通过编程的方式为一个已有的容器添加一个或多个子容器，从而实现一些特殊功能。\n\n层次容器的一个特点就是子容器对于父容器来说是透明的，而子容器则能感知到父容器的存在。典型的应用场景就是 Spring MVC，控制层的 bean 位于子容器中，而业务层和持久层的 bean 则位于父容器中，这样的设计可以让控制层的 bean 访问业务层和持久层的 bean，反之则不行，从而在容器层面对三层软件结构设计提供约束。\n\n- __ListableBeanFactory__\n\nListableBeanFactory 中文译为可列举的 BeanFactory，对于 IoC 容器而言，bean 的定义和属性是可以列举的对象。\n\nListableBeanFactory 相对于 BeanFactory 增加了获取容器中 bean 的配置信息的若干方法，比如获取容器中 bean 的个数、获取容器中所有 bean 的名称列表、按照目标类型获取 bean 名称，以及检查容器中是否包含指定名称的 bean 等等。\n\n- __AutowireCapableBeanFactory__\n\nAutowireCapableBeanFactory 提供了创建 bean 实例、自动注入、初始化，以及应用 bean 的后置处理器等功能。自动注入让配置变得更加简单，也让注解配置成为可能，Spring 目前提供了四种自动注入类型：\n\n1. __byName__ ：根据名称自动注入，假设 bean A 有一个名为 b 的属性，如果容器中刚好存在一个名称为 b 的 bean，则将该 bean 注入给 bean A 的 b 属性。\n2. __byType__ ：根据类型自动注入，假设 bean A 有一个类型为 B 的属性，如果容器中刚好存在一个类型为 B 的 bean，则将该 bean 注入给 bean A 对应的属性。\n3. __constructor__ ：仅针对构造方法注入而言，类似于 byType，如果 bean A 有一个包含 B 类型入参的构造方法，如果容器中有一个类型为 B 的 bean，则使用该 bean 作为入参，如果找不到则抛出异常。\n4. __autodetect__ ：根据 bean 的自省机制决定采用 byType 还是 constructor 进行自动注入，如果 bean 提供了默认的构造函数，则采用 byType，否则采用 constructor。\n\n标签 `<beans/>` 中的 `default-autowire` 属性可以配置为全局自动匹配，默认值为 no，表示不启用自动装配。在实际开发中，基于 XML 配置的方式很少启用自动装配功能，而基于注解的配置方式则默认采用 byType 自动装配策略。\n\n- __ConfigurableBeanFactory__\n\nConfigurableBeanFactory 定义了配置 BeanFactory 的各种方法，增强了 IoC 容器的可定制性，包括设置类装载器、属性编辑器，以及容器初始化后置处理器等方法。\n\n- __DefaultListableBeanFactory__\n\nDefaultListableBeanFactory 是一个非常重要的类，定义了 IoC 容器所应该具备的重要功能，是容器完整功能的基本实现。XmlBeanFactory 是一个典型的由该类派生出来的 BeanFactory，并且只是增加了加载 XML 配置资源的逻辑，而容器相关的特性则全部由 DefaultListableBeanFactory 来实现。XmlBeanFactory 类的实现如下：\n\n```java\npublic class XmlBeanFactory extends DefaultListableBeanFactory {\n\n    private final XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(this);\n\n    public XmlBeanFactory(Resource resource) throws BeansException {\n        this(resource, null);\n    }\n\n    public XmlBeanFactory(Resource resource, BeanFactory parentBeanFactory) throws BeansException {\n        super(parentBeanFactory);\n        // 加载 XML 资源\n        this.reader.loadBeanDefinitions(resource);\n    }\n}\n```\n\n我们将在下一篇中分析 XmlBeanFactory 加载 bean 的基本过程。Spring 在 3.1 版本之后将 XmlBeanFactory 标记为 `deprecated`，并推荐使用更加原生的方式，即组合使用 DefaultListableBeanFactory 和 XmlBeanDefinitionReader 来取代 XmlBeanFactory 的功能。\n\n### 高级 IoC 容器\n\nApplicationContext 是 Spring 为开发者提供的高级 IoC 容器形式，也是我们初始化 Spring 容器的常用方式。除了具备简单容器所有的功能外，ApplicationContext 还提供了许多额外功能以降低开发人员的开发量，提升框架的使用效率。这些额外的功能主要包括：\n\n- __国际化支持__ ：实现了 MessageSource 接口，为容器提供国际化消息访问功能，支持具备多语言版本需求的应用开发，并提供了多种实现来简化国际化资源文件的装载和获取。\n- __发布应用上下文事件__ ：实现了 ApplicationEventPublisher 接口，让容器拥有发布应用上下文事件的功能，包括容器启动、关闭事件等。如果一个 bean 需要接收容器事件，则只需要实现 ApplicationListener 接口即可，Spring 会自动扫描对应的监听器配置，并注册成为事件的订阅者。\n- __丰富的资源获取的方式__ ：实现了 ResourcePatternResolver 接口，该接口的实现类 PathMatchingResourcePatternResolver 让我们可以采用 Ant 风格的资源路径去加载配置文件。\n\n基于 ApplicationContext 派生出了众多的扩展实现，如下图所示：\n\n![image](/images/2017/spring-ioc-application-context.png)\n\nConfigurableApplicationContext 和 WebApplicationContext 是直接实现 ApplicationContext 的两个接口。\n\n- __ConfigurableApplicationContext__\n\nConfigurableApplicationContext 中主要增加了 `ConfigurableApplicationContext#refresh` 和 `ConfigurableApplicationContext#close` 两个方法，从而为应用上下文提供了启动、刷新和关闭的能力。其中 `ConfigurableApplicationContext#refresh` 方法是高级容器的核心方法，该方法概括了高级容器初始化的主要流程（包含简单容器的全部功能，以及高级容器扩展的功能），比如我们通常会采用如下方式启动高级容器：\n\n```java\nApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"spring-core.xml\");\n```\n\n在执行 `new ClassPathXmlApplicationContext(\"spring-core.xml\")` 时，本质上就是在触发 `ConfigurableApplicationContext#refresh` 方法，如下：\n\n```java\npublic ClassPathXmlApplicationContext(String configLocation) throws BeansException {\n    this(new String[] {configLocation}, true, null);\n}\n\npublic ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException {\n    super(parent);\n    // 支持多个配置文件以数组形式传入\n    this.setConfigLocations(configLocations);\n    if (refresh) {\n        // 加载配置，并初始化 IoC 容器\n        this.refresh();\n    }\n}\n```\n\n在调用 `ConfigurableApplicationContext#refresh` 方法之前，Spring 会先去解析配置文件的路径并存储到字符串数组中，然后开始执行容器的初始化逻辑。该方法的实现位于 AbstractApplicationContext 抽象类中，如下所示：\n\n```java\npublic void refresh() throws BeansException, IllegalStateException {\n    synchronized (this.startupShutdownMonitor) {\n        // 1. 初始化待 refresh 的上下文环境\n        prepareRefresh();\n        // 2. 初始化 BeanFactory，加载并解析配置\n        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();\n\n        /* 至此，完成了简单容器的所有功能，下面开始对简单容器进行增强 */\n\n        // 3. 对 BeanFactory 进行功能增强\n        prepareBeanFactory(beanFactory);\n        try {\n            // 4. 模板方法，后置处理 BeanFactory 实例\n            postProcessBeanFactory(beanFactory);\n            // 5. 调用已注册的 BeanFactoryPostProcessor\n            invokeBeanFactoryPostProcessors(beanFactory);\n            // 6. 注册 BeanPostProcessor，这里仅仅是注册，调用发生在 getBean 的时候\n            registerBeanPostProcessors(beanFactory);\n            // 7. 初始化国际化资源\n            initMessageSource();\n            // 8. 初始化事件广播器\n            initApplicationEventMulticaster();\n            // 9. 模板方法\n            onRefresh();\n            // 10. 注册事件监听器\n            registerListeners();\n            // 11. 实例化所有非延迟加载的单例\n            finishBeanFactoryInitialization(beanFactory);\n            // 12. 完成 refresh 过程，发布相关事件\n            finishRefresh();\n        } catch (BeansException ex) {\n            if (logger.isWarnEnabled()) {\n                logger.warn(\"Exception encountered during context initialization - cancelling refresh attempt: \" + ex);\n            }\n            // Destroy already created singletons to avoid dangling resources.\n            destroyBeans();\n            // Reset 'active' flag.\n            cancelRefresh(ex);\n            // Propagate exception to caller.\n            throw ex;\n        } finally {\n            // Reset common introspection caches in Spring's core, since we\n            // might not ever need metadata for singleton beans anymore...\n            resetCommonCaches();\n        }\n    }\n}\n```\n\n后续的篇章将详细分析上述整个过程的源码实现，这里只需要了解整个初始化的整体流程即可。\n\n- __WebApplicationContext__\n\nWebApplicationContext 是为 WEB 应用定制的上下文类，基于 servlet 实现配置文件的加载和初始化工作。对于非 WEB 应用而言，bean 只有 singleton 和 prototype 两种作用域，而在 WebApplicationContext 中则新增了 request、session、globalSession，以及 application 四种作用域。\n\nWebApplicationContext 将整个应用上下文对象以属性的形式记录到 ServletContext 中，我们可以通过 `WebApplicationContextUtils#getWebApplicationContext` 工具方法从 ServletContext 对象中获取 WebApplicationContext 实例。\n\n为了支持这一特性，WebApplicationContext 类定义了一个常量：\n\n```java\nROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE = WebApplicationContext.class.getName() + \".ROOT\"\n```\n\n在初始化应用上下文时会以该常量为 key，将 WebApplicationContext 实例存放到 ServletContext 的属性列表中。当我们调用 `WebApplicationContextUtils#getWebApplicationContext` 工具方法时，本质上是在调用 `ServletContext#getAttribute` 方法，不过 Spring 会对获取的结果做一些校验工作。\n\n### 总结\n\n总的来说，Spring IoC 容器的基本设计主要分为 BeanFactory 和 ApplicationContext 两大部分，本文中我们对整个容器的结构层次进行了简单的介绍，目的在于从整体上对 Spring IoC 容器建立起感官上认识。\n\n### 参考\n\n1. [Spring 源码深度解析](https://book.douban.com/subject/25866350/)\n","tags":["Spring"],"categories":["spring"]},{"title":"程序设计中的基本原则","url":"/2017/04/15/design-pattern/principle/","content":"\n在编写一个系统的时候，我们总是希望我们的系统在设计上具备较好的可维护性和可扩展性，当客户需求有变，或者需要增加新功能时，能够从容应对，而一些前人总结的设计原则可以让我们在遇到这样的情况时候，不至于被动，从而能够以尽可能小的工作量来实现客户的需求。<!-- more -->\n\n### 开闭原则\n\n> OCP: Open-Closed Principle\n\n开闭原则是指一个软件或系统应该 __对扩展开放，对修改关闭__ ，即在不修改原有代码的基础上实现需要扩展的功能。\n\n所有的系统需求都会随着时间的推移而发生或大或小的变化，当系统面临新的需求时，一个好的设计应该只是增加新的代码，而不改变原有的设计，系统需要提供规范的接口来支持这样的扩展。比如我们的电脑，当我们需要更换或者扩展内存时，只需要买一块插进去即可，而不需要去修改主板上的接口设计。\n\n满足开闭原则的系统，具备如下 __两个优点__ ：\n\n1. 通过扩展已有的系统，可以提供新的功能，以满足新的需求，使变化中的系统具备一定的适应性和灵活性。\n2. 已有的系统模块，特别是最重要的抽象层模块无需更改，从而使变化中的系统具备一定的稳定性和延续性。\n\n__如何让系统满足开闭原则？__\n\n- __抽象是关键__\n\n在面向对象设计语言中，可以对系统的需求进行抽象设计，而具体的实现则交给实现层，这样当有新的需求时，我们只需要扩展一个新的实现类，并实现之前的抽象设计接口，上层调用方式不需要改变，从而可以对扩展开放。\n\n- __封装可变性__\n\n将系统中容易变化的地方封装起来，当这些地方改变时不会导致重新设计。要做到对变化的封装，主要考虑如下 2 点：\n\n1. 变化不应该在代码中分散，而应该被封装在一个对象里面。相同可变性的不同表象应该反应在继承结构的具体子类中，所以继承应该被看做是封装变化的方法，而不应该被看做从一般对象生成特殊对象的方法。\n2. 不同的可变性不应该混淆在一起。要区分和抽离可变的点，当某一个点需要变化时做针对性的处理，而混淆的变化往往会牵一发而动全身。\n\n### 里氏替换原则\n\n> LSP: Liskov Substitution Principle\n\n里氏替换原则描述如下：\n\n> 如果对于每一个类型 T1 的对象 o1，都有类型为 T2 的对象 o2，使得以 T1 类型定义的所有程序 P，在将 o1 替换成 o2 时，程序 P 的行为没有发生任何变化，那么 T2 就是 T1 的子类型。\n\n里氏替换原则被广泛用在接口参数设计中，即一个系统如果使用了基类的话，则一定适用于子类，并且系统不会察觉基类对象与子类对象的区别。比如说定义了一个方法 `method(Base base)`，则我们可以将 Base 子类的对象作为参数传递进去。\n\n里氏替换原则是继承复用的基石，只有衍生类可以替换掉基类，系统功能不会受到影响时，基类才能真正被复用，而衍生类也才能够在基类的基础上扩展新的行为。\n\n### 依赖倒置原则\n\n> DIP: Dependency Inversion Principle\n\n依赖倒置原则要求 __要依赖于抽象，不要依赖于具体。__\n\nGoF的书中强调要 __针对接口编程，不要针对实现编程__ ，这是依赖倒置原则的一种表述。所要表达的意思是说应当使用接口或抽象类进行变量、参数，以及方法返回类型进行声明，而不是具体的实现类。\n\n一个系统都是通过两个或多个类彼此合作来实现业务逻辑，这使得每个对象都需要引用与其合作的对象，如果这个引用获取的过程需要有对象自己来实现，则将导致代码高度耦合并且难以满足开闭原则。\n\n在具体编码时我们可以通过一些设计模式，比如工厂方法模式、模板方法模式等，来将对象之间的引用耦合抽离出来单独管理，封装其可变性。而很多编程框架也提供了对这一原则的强大支持，比如 java 编程框架 Spring，就是将依赖倒置原则作为其核心功能，Spring 的 IoC 容器把对象之间引用管理的控制权从业务手中抽取出来由自己管理，并完成对对象的注入。\n\n### 接口隔离原则\n\n> ISP: Interface Segregation Principle\n\n接口隔离原则主张接口功能最小化，即使用多个专门的接口比使用一个单一的总接口要好。在这样的设计下可以对外暴露尽可能少的 API，从而让一个衍生类只关注自己需要的功能。\n\n### 组合 / 聚合复用原则\n\n> CARP: Composition/Aggregation Principle\n\n组合 / 聚合复用原则表述为要 __多用组合，少用继承__ 。\n\n在面向对象程序设计中，可以通过两种途径实现已有的设计的复用：组合/聚合和继承。\n\n__组合 / 聚合复用（Has-A）__ 通过组合已有的对象（也叫成分对象）到新的对象中，使之成为新对象的一部分，新的对象可以调用成分对象的功能，这种复用方式具有如下优点：\n\n1. 新对象通过成分对象接口来存储成分对象。\n2. 这种复用是黑箱复用，成分对象内部细节对于新对象是透明的。\n3. 动态复用，新对象可以动态引用成分对象。\n\n组合 / 聚合复用的缺点是需要管理较多的成分对象。\n\n__继承复用（Is-A）__ 通过继承多个成分对象来得到新对象，这种方式的优点如下：\n\n1. 通过继承获得新功能，实现上较为简单。\n2. 修改或扩展继承得到的实现较为容易。\n\n继承复用的缺点也是显而易见的：\n\n1. 这种复用是白箱复用，继承破坏了包装，因为父类的实现细节暴露给了子类。\n2. 如果超类发生变化，子类也需要做适应性调整。\n3. 从超类继承而来的特性都是静态的，不可能在运行时动态改变。\n\n### 迪米特法则\n\n> LoD: Law of Demeter\n\n迪米特法则也叫最少知识法则，就是说 __一个对象应该对另一个对象有最少的了解__ 。比如对象 A 持有对象 B 的引用，对象 B 持有对象 C 的引用，如果此时 A 希望使用 C 的某个功能，则应该尽量通过 B 对象达到目的，而不是直接引用 C 对象。\n\n除了在使用上注意，在类的设计上也要做好封装。在系统设计中，一个好的模块的设计标志就是该模块在多大程度上将自己的内部数据和其它与实现有关的细节隐藏了起来，彻底的将对外提供的 API 与自己的实现分隔开来。这样一来模块间的通信通过 API 完成，而不需要考虑模块的具体内部实现。这个可以解耦各个模块和子系统，从而实现独立的开发、优化、使用、阅读，以及修改。\n\n迪米特法则的主要用途是 __控制信息过载__ ，在系统设计时，主要考虑以下几点：\n\n1. 在类的划分上应当创建弱耦合的类，这样有利于复用。\n2. 在类的结构上应当降低成员变量的访问权限，包装自己的 private 属性。\n3. 在类的设计上如果可能尽量设计成不变类。\n4. 在类的引用上一个类对其它对象的引用应该降到最低。\n","tags":["设计模式"],"categories":["design-pattern"]},{"title":"利用享元模式解决内存大量细粒度对象","url":"/2017/04/13/design-pattern/flyweight/","content":"\n最近在看之前一个自己写的项目代码的时候，发现之前构造的责任链像个楼梯台阶一样的堆在那里，很是影响代码的美观性，并且一条链上的七、八个对象在每次请求时都需要创建一遍，对于一个高并发的项目来说，是一笔不小的开销，于是想对这一块的代码进行优化，而享元模式刚好满足我的需求。\n\n享元模式（Flyweight）是 __以共享的方式有效地支持大量的细粒度对象__ 。能做到共享的关键是区分 __内部状态（Internal State）__ 和 __外部状态（External State）__ 。<!-- more -->\n\n__内部状态__ ：存储在享元对象内部，且不会随环境改变而改变的状态。\n\n__外部状态__ ：随环境改变而改变，不可以共享的状态，必须由客户端保存，并在享元对象被创建之后，在需要使用的时候以参数形式传入到享元对象内部。\n\n__外部状态不可以影响享元对象的内部状态，即外部状态和内部状态是独立的__ 。\n\n享元模式就是将内部状态分离出来共享，称之为享元，通过共享享元对象来减少内存的占用，并将外部状态分离出来，放到外部让客户端去维护，并在需要的时候传递给享元对象使用。\n\n享元模式分为 __单纯享元模式__ 和 __复合享元模式__ 。\n\n### 单纯享元模式\n\n单纯享元模式所定义的角色如下：\n\n- 抽象享元\n\n此角色是所有具体享元的超类，规定了具体享元需要实现的公共接口。\n\n```java\n/**\n * 抽象享元\n *\n * @author zhenchao.wang 2017-04-09 17:48\n * @version 1.0.0\n */\npublic interface AbstractFlyweight {\n\n    /**\n     * 操作函数\n     *\n     * @param externalState 外部状态\n     */\n    void operate(Object externalState);\n\n}\n```\n\n- 具体享元\n\n实现了抽象享元的具体的类，如果有内部状态的话，必须为内部状态提供存储空间。\n\n```java\n/**\n * 具体享元\n *\n * @author zhenchao.wang 2017-04-09 17:50\n * @version 1.0.0\n */\npublic class ConcreteFlyweight implements AbstractFlyweight {\n\n    /** 内部状态 */\n    private Object internalState;\n\n    public ConcreteFlyweight(Object internalState) {\n        this.internalState = internalState;\n    }\n\n    @Override\n    public void operate(Object externalState) {\n\n    }\n\n}\n```\n\n- 享元工厂\n\n负责创建和管理享元角色，需要保证享元角色被适当的共享，当客户端需要一个享元对象的时候，工厂需要检查是否有已定义的合适的对象可供使用，如果没有则创建新的享元对象。\n\n```java\n/**\n * 享元工厂（单例）\n *\n * @author zhenchao.wang 2017-04-09 17:53\n * @version 1.0.0\n */\npublic class FlyweightFactory {\n\n    private Map<String, AbstractFlyweight> map = new ConcurrentHashMap<>();\n\n    private static final FlyweightFactory INSTANCE = new FlyweightFactory();\n\n    private FlyweightFactory() {\n    }\n\n    public static FlyweightFactory getInstance() {\n        return INSTANCE;\n    }\n\n    /**\n     * 获取享元\n     *\n     * @param key\n     * @return\n     */\n    public AbstractFlyweight getFlyweight(String key) {\n        AbstractFlyweight flyweight = map.get(key);\n        if (null == flyweight) {\n            flyweight = new ConcreteFlyweight(\"some internal state\");\n            map.put(key, flyweight);\n        }\n        return flyweight;\n    }\n}\n```\n\n- 客户端\n\n维护一个对所有享元对象的引用，自行存储所有享元对象的外部状态。客户端不可以直接创建享元对象实例，而必须从工厂中获取。\n\n```java\n/**\n * 客户端\n *\n * @author zhenchao.wang 2017-04-09 18:16\n * @version 1.0.0\n */\npublic class Client {\n\n    public static void main(String[] args) {\n        FlyweightFactory factory = FlyweightFactory.getInstance();\n        AbstractFlyweight flyweight = factory.getFlyweight(\"any key\");\n        flyweight.operate(\"any external state\");\n    }\n\n}\n```\n\n介绍完了单纯享元定义的各个角色，我以一个自己的实际项目来举例说明。游客账号是我们常见的一种账号类型，考虑到一般用户名密码的登录方式门槛较高，很多用户不愿意去登录，所以对于一些安全性要求不高的业务来说，我们可以为用户生成游客账号。比如在我的项目里，我选择了一些元素包括设备IMEI信息、安全芯片ID等信息生成游客账号，如果实在没有可以参考的因素，则直接生成随机的游客账号。在代码层面，针对每一种类型的账号，我都为其设计了相应的处理器，并且每个处理器都可以设置降级委托处理器，当当前处理器处理失败时，可以采用降级处理器处理。如果不用享元模式，那么每次来一个请求，我都需要根据具体的类型创建相应的处理器对象，然后处理请求，考虑到游客账号的请求量一般较大，所以有必要尽量避免创建一些不必要的对象。\n\n我们先来分析一下这里面哪些是内部状态，哪些是外部状态，因为享元模式的核心就是要将内部状态和外部状态区分开来，将内部状态封装在享元内部实现共享，而外部状态则有客户端传递进来。很显然，游客账号生成的参考元素是外部状态，因为每一个设备都有不同的设备IMEI信息，有的设备甚至还有安全芯片，这些东西必须由外面传递进来，而一个处理器的降级处理器则是内部状态，因为降级处理器一旦设定，不会动态变化。具体代码的实现如下：\n\n- 游客类型定义\n\n```java\n/**\n * 游客类型\n *\n * @author zhenchao.wang 2017-04-09 18:31\n * @version 1.0.0\n */\npublic enum VisitorType {\n\n    /** 默认类型 */\n    DEFAULT(0),\n\n    /** 基于安全芯片 */\n    FID(1),\n\n    /** 基于设备IMEI信息 */\n    DEVICE(2);\n\n    private int id;\n\n    VisitorType(int id) {\n        this.id = id;\n    }\n}\n```\n\n- 游客处理器抽象享元\n\n```java\n/**\n * 游客类型处理器抽象享元\n *\n * @author zhenchao.wang 2017-04-09 18:19\n * @version 1.0.0\n */\npublic abstract class AbstractVisitorTypeFlyweight {\n\n    /**\n     * 创建或恢复游客信息\n     *\n     * @param id\n     * @return\n     */\n    public abstract void createOrRecoverVisitor(String id);\n\n    /**\n     * 内部创建或恢复游客信息\n     *\n     * @return\n     */\n    protected boolean createOrRecoverVisitorInternal() {\n        // 模拟操作是否成功\n        return RandomUtils.nextInt(0, 10) > 5;\n    }\n\n}\n```\n\n- 游客处理器具体享元\n\n```java\n/**\n * 默认游客处理器享元\n *\n * @author zhenchao.wang 2017-04-09 18:24\n * @version 1.0.0\n */\npublic class DefaultVisitorTypeFlyweight extends AbstractVisitorTypeFlyweight {\n\n    /** 内部状态：委托处理器 */\n    private AbstractVisitorTypeFlyweight delegateFlyweight;\n\n    public DefaultVisitorTypeFlyweight() {\n    }\n\n    public DefaultVisitorTypeFlyweight(AbstractVisitorTypeFlyweight delegateFlyweight) {\n        this.delegateFlyweight = delegateFlyweight;\n    }\n\n    @Override\n    public void createOrRecoverVisitor(String id) {\n        System.out.println(\"Create visitor info in default schema!\");\n    }\n\n}\n\n/**\n * fid类型游客处理器享元\n *\n * @author zhenchao.wang 2017-04-09 18:26\n * @version 1.0.0\n */\npublic class FidVisitorTypeFlyweight extends AbstractVisitorTypeFlyweight {\n\n    /** 内部状态：委托处理器 */\n    private AbstractVisitorTypeFlyweight delegateFlyweight;\n\n    public FidVisitorTypeFlyweight() {\n    }\n\n    public FidVisitorTypeFlyweight(AbstractVisitorTypeFlyweight delegateFlyweight) {\n        this.delegateFlyweight = delegateFlyweight;\n    }\n\n    @Override\n    public void createOrRecoverVisitor(String fid) {\n        System.out.println(\"Create or recover visitor info by fid : \" + fid);\n\n        if (null != delegateFlyweight && !this.createOrRecoverVisitorInternal()) {\n            // 调用委托处理器处理\n            delegateFlyweight.createOrRecoverVisitor(fid);\n        }\n    }\n\n}\n\n/**\n * DeviceId类型游客处理器享元\n *\n * @author zhenchao.wang 2017-04-09 18:28\n * @version 1.0.0\n */\npublic class DeviceIdVisitorTypeFlyweight extends AbstractVisitorTypeFlyweight {\n\n    /** 内部状态：委托处理器 */\n    private AbstractVisitorTypeFlyweight delegateFlyweight;\n\n    public DeviceIdVisitorTypeFlyweight() {\n    }\n\n    public DeviceIdVisitorTypeFlyweight(AbstractVisitorTypeFlyweight delegateFlyweight) {\n        this.delegateFlyweight = delegateFlyweight;\n    }\n\n    @Override\n    public void createOrRecoverVisitor(String deviceId) {\n        System.out.println(\"Create or recover visitor info by device id : \" + deviceId);\n    }\n\n}\n```\n\n- 游客处理器享元工厂\n\n```java\n/**\n * 游客类型处理器享元工厂\n *\n * @author zhenchao.wang 2017-04-09 18:32\n * @version 1.0.0\n */\npublic class VisitorTypeFlyweightFactory {\n\n    private static final VisitorTypeFlyweightFactory INSTANCE = new VisitorTypeFlyweightFactory();\n\n    private Map<VisitorType, AbstractVisitorTypeFlyweight> flyweightMap = new ConcurrentHashMap<>();\n\n    private VisitorTypeFlyweightFactory() {\n    }\n\n    public static VisitorTypeFlyweightFactory getInstance() {\n        return INSTANCE;\n    }\n\n    /**\n     * 获取对应的享元\n     *\n     * @param visitorType\n     * @return\n     */\n    public AbstractVisitorTypeFlyweight getFlyweight(VisitorType visitorType) {\n        if (null == visitorType) {\n            return null;\n        }\n\n        // 先从缓存中找\n        AbstractVisitorTypeFlyweight flyweight = flyweightMap.get(visitorType);\n        if (null != flyweight) {\n            return flyweight;\n        }\n\n        switch (visitorType) {\n            case DEFAULT: {\n                flyweight = new DefaultVisitorTypeFlyweight();\n                flyweightMap.put(VisitorType.DEFAULT, flyweight);\n                break;\n            }\n            case FID: {\n                // 设置降级委托处理器\n                flyweight = new FidVisitorTypeFlyweight(new DefaultVisitorTypeFlyweight());\n                flyweightMap.put(VisitorType.FID, flyweight);\n                break;\n            }\n            case DEVICE: {\n                flyweight = new DeviceIdVisitorTypeFlyweight();\n                flyweightMap.put(VisitorType.DEVICE, flyweight);\n                break;\n            }\n            default:\n                break;\n        }\n        return flyweight;\n    }\n}\n```\n\n- 客户端\n\n```java\n/**\n * 客户端\n *\n * @author zhenchao.wang 2017-04-09 22:04\n * @version 1.0.0\n */\npublic class Client {\n\n    public static void main(String[] args) {\n        VisitorTypeFlyweightFactory factory = VisitorTypeFlyweightFactory.getInstance();\n\n        AbstractVisitorTypeFlyweight flyweight = factory.getFlyweight(VisitorType.DEFAULT);\n        flyweight.createOrRecoverVisitor(randomStr());\n\n        flyweight = factory.getFlyweight(VisitorType.FID);\n        flyweight.createOrRecoverVisitor(randomStr());\n\n        flyweight = factory.getFlyweight(VisitorType.DEVICE);\n        flyweight.createOrRecoverVisitor(randomStr());\n    }\n\n    private static String randomStr() {\n        return RandomStringUtils.randomAlphanumeric(32);\n    }\n\n}\n```\n\n通过上面的代码实现，可以发现享元工厂是整个享元模式实现共享的核心实现所在，通过对享元对象的缓存来保证每一个享元都只有一份，不过在实现之前要区分好内部状态和外部状态，不然会存在线程安全问题。\n\n### 复合享元模式\n\n复合享元由单纯享元复合而成，一般来说复合享元的组成元素是随外部状态而变化的，所以复合享元通常被描述为不可共享的，这里的不可共享是指这个复合享元不可共享，但是组成复合享元的单纯享元还是共享的，但是我觉得如果外部状态的种类是有限的，我们也可以将复合享元设计成可共享的。\n\n复合享元定义了 5 种角色：抽象享元、具体享元、复合享元、享元工厂，客户端。其中除了复合享元，其余角色定义与单纯享元角色定义相同。 __复合享元__ 所代表的对象是不可以共享的（所以也称作不可共享的享元对象），一个复合享元对象可以分解成多个单纯享元对象，复合享元具有以下两个责任：\n\n1. 由单纯的享元对象复合而成，因此需要提供 `add()` 这样的聚集管理方法，一个复合对象具有不同的聚集，并且可以在对象创建之后被修改，所以复合对象的状态是可变的，也就不可共享的。\n\n2. 复合享元对象实现了抽象享元接口。\n\n我还是以一个自己在项目中遇到的实际例子来举例说明，话说有一天我在看自己以前写的项目代码的时候，看到了下面这样的一坨代码：\n\n```java\n// 构建处理器链\nAbstractResultHandler resultHandler =\n        new VisitorPassTokenCreateHandler(\n                new SecurityHintUpdateHandler(\n                        new AuthorizationModeHandler(\n                                new SuccessResultHandler(), visitorInfo.getVisitorId(), requestParams.getSid()),\n                        visitorInfo.getVisitorId(), requestParams.getSid()), visitorInfo);\n```\n\n实际上这一坨代码虽然看起来不好看，但是其中的设计还是还是很灵活的，这里面我采用了责任链模式，并允许随机组合各个 handler，但是在构造上采用了静态构造的方式，所以就有了这样一坨构造的过程，也一直想干掉他。仔细分析一下，这坨代码不光不好看，其中每次创都要创建这么多对象也是不必要的，我们来用复合享元进行重构。\n\n首先对这段代码及其背后的实现做一个抽象的描述，实际项目中我们可能需要对方法结果做一些后置的处理，假设我们有1, 2, 3, 4四个后置结果处理器，并且这些处理器具备优先级，同时可以随机进行组合，对于结果处理器而言，没有必要每次请求都现场创建，所以可以用享元模式进行改造，因为结果处理器是可以随意组合的，所以这里可以采用复合享元来根据外部状态构建合适的复合处理器。\n\n前面有介绍说复合享元是由单纯享元复合而成的，所以我们可以先设计好单纯享元，然后由单纯享元复合成复合享元。区分外部状态和内部状态是享元的关键，对于本例子而言，处理器的优先级是内部状态，而待处理的结果则是外部状态，单纯享元的实现如下：\n\n- 结果处理器抽象享元\n\n```java\n/**\n * 抽象结果处理器\n *\n * @author zhenchao.wang 2017-04-12 23:42\n * @version 1.0.0\n */\npublic abstract class AbstractResultHandler implements Comparable<AbstractResultHandler> {\n\n    /** 内部状态：基础优先级 */\n    protected static final int BASE_PRIORITY = 0;\n\n    /**\n     * 处理函数\n     *\n     * @param obj\n     */\n    public abstract void handle(Object obj);\n\n    /**\n     * 返回处理器的优先级\n     *\n     * @return\n     */\n    public abstract int getPriority();\n\n    @Override\n    public int compareTo(AbstractResultHandler handler) {\n        return handler.getPriority() - this.getPriority();\n    }\n}\n```\n\n- 结果处理器具体享元\n\n```java\n/**\n * first result handler implementation\n *\n * @author zhenchao.wang 2017-04-12 23:47\n * @version 1.0.0\n */\npublic class FirstResultHandler extends AbstractResultHandler {\n\n    @Override\n    public void handle(Object obj) {\n        System.out.println(\"first handle\");\n    }\n\n    @Override\n    public int getPriority() {\n        return BASE_PRIORITY + 40;\n    }\n\n}\n\n/**\n * second result handler implementation\n *\n * @author zhenchao.wang 2017-4-12 23:48:56\n * @version 1.0.0\n */\npublic class SecondResultHandler extends AbstractResultHandler {\n\n    @Override\n    public void handle(Object obj) {\n        System.out.println(\"second handle\");\n    }\n\n    @Override\n    public int getPriority() {\n        return BASE_PRIORITY + 30;\n    }\n\n}\n\n/**\n * third result handler implementation\n *\n * @author zhenchao.wang 2017-4-12 23:49:25\n * @version 1.0.0\n */\npublic class ThirdResultHandler extends AbstractResultHandler {\n\n    @Override\n    public void handle(Object obj) {\n        System.out.println(\"third handle\");\n    }\n\n    @Override\n    public int getPriority() {\n        return BASE_PRIORITY + 20;\n    }\n\n}\n\n/**\n * fourth result handler implementation\n *\n * @author zhenchao.wang 2017-4-12 23:50:11\n * @version 1.0.0\n */\npublic class FourthResultHandler extends AbstractResultHandler {\n\n    @Override\n    public void handle(Object obj) {\n        System.out.println(\"fourth handle\");\n    }\n\n    @Override\n    public int getPriority() {\n        return BASE_PRIORITY + 10;\n    }\n\n}\n```\n\n- 享元工厂\n\n```java\n/**\n * 单纯的结果处理器享元工厂（单例）\n *\n * @author zhenchao.wang 2017-04-13 22:09\n * @version 1.0.0\n */\npublic class ResultHandlerFactory {\n\n    private Map<String, AbstractResultHandler> handlerMap = new ConcurrentHashMap<>(4);\n\n    private static volatile ResultHandlerFactory instance;\n\n    private ResultHandlerFactory() {\n    }\n\n    /**\n     * 双检查单例\n     *\n     * @return\n     */\n    public static ResultHandlerFactory getInstance() {\n        if (null == instance) {\n            synchronized (ResultHandlerFactory.class) {\n                if (null == instance) {\n                    instance = new ResultHandlerFactory();\n                }\n            }\n        }\n        return instance;\n    }\n\n    /**\n     * 获取结构处理器享元\n     *\n     * @param key\n     * @return\n     */\n    public AbstractResultHandler getResultHandler(String key) {\n        if (StringUtils.isBlank(key)) {\n            return null;\n        }\n\n        AbstractResultHandler handler = handlerMap.get(key);\n        if (null != handler) {\n            return handler;\n        }\n\n        switch (key) {\n            case \"1\": {\n                handler = new FirstResultHandler();\n                handlerMap.put(\"1\", handler);\n                break;\n            }\n            case \"2\": {\n                handler = new SecondResultHandler();\n                handlerMap.put(\"2\", handler);\n                break;\n            }\n            case \"3\": {\n                handler = new ThirdResultHandler();\n                handlerMap.put(\"3\", handler);\n                break;\n            }\n            case \"4\": {\n                handler = new FourthResultHandler();\n                handlerMap.put(\"4\", handler);\n                break;\n            }\n            default:\n                // nothing\n        }\n        return handler;\n    }\n}\n```\n\n构造好了单纯的享元，我们再来复合实现复合享元：\n\n- 结果处理器复合享元\n\n```java\n/**\n * 结果处理器复合享元\n *\n * @author zhenchao.wang 2017-04-13 21:42\n * @version 1.0.0\n */\npublic class CompositeResultHandler extends AbstractResultHandler {\n\n    /** 存储构造复合享元的单纯享元集合 */\n    private List<AbstractResultHandler> handlers = new ArrayList<>();\n\n    @Override\n    public void handle(Object obj) {\n        for (final AbstractResultHandler handler : handlers) {\n            handler.handle(obj);\n        }\n    }\n\n    @Override\n    public int getPriority() {\n        return BASE_PRIORITY;\n    }\n\n    public void add(AbstractResultHandler handler) {\n        handlers.add(handler);\n        // 对处理按照优先级由大到小排序\n        Collections.sort(handlers);\n    }\n\n}\n```\n\n- 复合享元工厂\n\n```java\n/**\n * 复合享元工厂（单例）\n *\n * @author zhenchao.wang 2017-04-12 23:52\n * @version 1.0.0\n */\npublic class CompositeResultHandlerFactory {\n\n    private ResultHandlerFactory resultHandlerFactory = ResultHandlerFactory.getInstance();\n\n    /** 基于静态内部类的单例实现 */\n    private static class InnerClass {\n        private static final CompositeResultHandlerFactory INSTANCE = new CompositeResultHandlerFactory();\n    }\n\n    private CompositeResultHandlerFactory() {\n    }\n\n    public static CompositeResultHandlerFactory getInstance() {\n        return InnerClass.INSTANCE;\n    }\n\n    /**\n     * 获取结果处理器复合享元\n     *\n     * @param key\n     * @return\n     */\n    public CompositeResultHandler getCompositeResultHandler(String key) {\n        if (StringUtils.isBlank(key)) {\n            return null;\n        }\n\n        // 构建复合享元\n        CompositeResultHandler compositeHandler = new CompositeResultHandler();\n        for (int i = 0; i < key.length(); i++) {\n            AbstractResultHandler handler = resultHandlerFactory.getResultHandler(String.valueOf(key.charAt(i)));\n            if (null != handler) {\n                compositeHandler.add(handler);\n            }\n        }\n        return compositeHandler;\n    }\n\n}\n```\n\n- 客户端\n\n```java\n/**\n * 客户端\n *\n * @author zhenchao.wang 2017-04-13 22:45\n * @version 1.0.0\n */\npublic class Client {\n\n    public static void main(String[] args) {\n        CompositeResultHandlerFactory factory = CompositeResultHandlerFactory.getInstance();\n        AbstractResultHandler handler = factory.getCompositeResultHandler(\"124\");\n        handler.handle(new Object());\n    }\n\n}\n```\n\n### 享元模式的应用场景\n\n满足下列所有条件时，可以考虑使用享元模式：\n\n> 1. 一个系统有大量的对象\n> 2. 这些对象消耗着大量的内存\n> 3. 这些对象中的大部分都可以外部化\n> 4. 这些对象可以按照内部状态分成很多的组，当把外部对象从对象中剔除时，每一个组都可以仅用一个对象表示\n> 5. 软件对象不依赖于这些对象的身份，即这些对象是不可分辨的\n\n### 享元模式的优缺点\n\n- 优点\n\n大幅度降低了内存中对象的数量\n\n- 缺点\n\n系统设计更加复杂，将享元独享的状态外部化，拉长运行时间\n","tags":["设计模式"],"categories":["design-pattern"]},{"title":"OAuth 2.0 协议原理与实现：Token 生成策略","url":"/2017/03/11/protocol/oauth-v2-token/","content":"\nOAuth2.0 协议定义了授权详细流程，并最终以 token 的形式作为用户授权的凭证下发给客户端，客户端后续可以带着 token 去请求资源服务器，获取 token 权限范围内的用户资源。\n\n对于 token 的描述，OAuth 2.0 协议只是一笔带过的说它是一个字符串，用于表示特定的权限、生命周期等，但是却没有明确阐述 token 的生成策略，以及如何去验证一个 token。[RFC6749](https://tools.ietf.org/html/rfc6749) 对于 access token 的描述：\n\n> The client obtains an access token -- a string denoting a specific scope, lifetime, and other access attributes.\n\n<!-- more -->\n\n协议不去详细阐述 token 的生成和验证过程，个人觉得是因为这一块各个业务都有自己的特点，无法完全做到抽象，并且在这一块去做详细的规定，其意义并不大。Token 本质上就是对用户授权这一操作在时间和权限范围两个维度上的一个表征，协议可以对 token 的传递和基本验证做相应规定，但是具体的一个 token 包含哪些元素，采用什么样的生成算法还是需要由自己去把握。\n\n本文主要讲解自己对于 token 生成的一些思考，以及介绍两种类型：BEARER 和 MAC。\n\n### 一. TOKEN 的基本构成\n\nToken 表征了用户授权这一操作，授权服务器通过下发 token 来给客户端颁发获取用户受保护资源的资格，且不会因此而泄露用户的登录凭证信息。Token 对于客户端应该是非透明的，客户端只知道这是一个字符串，能够用它来获取用户的受保护资源，对于字符串内部所含的信息应该无从知晓，也不能通过其它方法去解密其中的信息。所以 token 应该是一类对称加密得到的字符串，并且只有授权服务器持有对称密钥，用于对生成的 token 进行加密和验证。\n\n对于构成token的元素，各个业务都有自己的需求，不过仍然存在一些基本通用的元素，比如：\n\n> 1. clientId：客户端 ID，当前 token 隶属的客户端\n> 2. userId：用户的 ID，表示当前 token 来自哪个用户授权\n> 3. scope: 权限范围，该 token 允许换取的用户受保护资源范围\n> 4. issueTime： 下发时间，用于控制 token 的生命周期\n> 5. tokenType： token 的类型，不同类型可能会采用不同的验证措施\n\n以上是个人根据经验总结的一些基础的 token 组成元素，具体业务还可以根据具体的需求添加一些其他的元素。\n\n### 二. Bearer Type Access Token\n\nBEARER 类型的 token 是在 [RFC6750](https://tools.ietf.org/html/rfc6750) 中定义的一种 token 类型，OAuth 2.0 协议 [RFC6749](https://tools.ietf.org/html/rfc6749) 对其也有所提及，算是对 [RFC6749](https://tools.ietf.org/html/rfc6749) 的一个补充。BEARER 类型 token 是建立在 [HTTP/1.1](https://tools.ietf.org/html/rfc2616) 版本之上的 token 类型，需要 [TLS（Transport Layer Security）](https://tools.ietf.org/html/rfc5246) 提供安全支持，该协议主要规定了BEARER类型token的客户端请求和服务端验证的具体细节。\n\n#### 2.1 客户端请求\n\n客户端在携带token请求用户的受保护资源时，需要保证token的安全性，以防止token被窃取或篡改，从而损害用户数据安全。BEARER类型token定义了三种token传递策略，客户端在传递token时必须使用其中的一种，且最多一种。\n\n##### 2.1.1 放在`Authorization`请求首部\n\n> Authorization首部说明\n>\n> Authorization首部是由客户端发送，以向服务器回应自己的身份验证信息，客户端在收到服务器的401 Authentication Required响应之后，需要在请求中包含该首部。\n>\n> 基本用法：Authorization: <authentication-scheme> <authentication-param>\n\n在传输时，`Authorization` 首部的 `authentication-scheme` 需要设置为 `Bearer`，请求示例：\n\n```http\nGET /resource HTTP/1.1\nHost: server.example.com\nAuthorization: Bearer mF_9.B5f-4.1JqM\n```\n\n##### 2.1.2 放在请求实体中\n\nToken需放置在 `access_token` 参数后面，且 `Content-Type` 需要设置为 `application/x-www-form-urlencoded`，请求示例如下：\n\n```http\nPOST /resource HTTP/1.1\nHost: server.example.com\nContent-Type: application/x-www-form-urlencoded\n\naccess_token=mF_9.B5f-4.1JqM\n```\n\n协议推荐使用第一种方式，对于该请求方式，必须在满足如下条件时才允许使用：\n\n> 1. The HTTP request entity-header includes the \"Content-Type\" header field set to \"application/x-www-form-urlencoded\".\n> 2. The entity-body follows the encoding requirements of the \"application/x-www-form-urlencoded\" content-type as defined by HTML 4.01.\n> 3. The HTTP request entity-body is single-part.\n> 4. The content to be encoded in the entity-body MUST consist entirely of ASCII characters.\n> 5. The HTTP request method is one for which the request-body has defined semantics. In particular, this means that the \"GET\" method MUST NOT be used.\n\n##### 2.1.3 放在URI请求参数中\n\n该方式通过在请求URl后面添加 `access_token` 参数来传递token，请求示例如下：\n\n```http\nGET /resource?access_token=mF_9.B5f-4.1JqM HTTP/1.1\nHost: server.example.com\n```\n\n客户端在请求时需要设置 `Cache-Control: no-store`，服务端在成功响应时也需要设置 `Cache-Control: private`。\n\n由于很多服务都会以日志方式去记录用户的请求，此类方式存在较大的安全隐患，所以一般不推荐使用，除非前两种方案均不可用。\n\n#### 2.2 服务端验证\n\n如果服务端拒绝客户端的访问请求，则需要在响应中添加 `WWW-Authenticate` 首部，响应示例如下：\n\n```http\nHTTP/1.1 401 Unauthorized\nWWW-Authenticate: Bearer realm=\"example\"\n```\n\n> WWW-Authenticate首部说明\n>\n> WWW-Authenticate首部用于401 Unauthorized响应，用于向客户端发送一个质询认证方案。\n>\n> 基本用法：WWW-Authenticate：<auth-scheme> <challenge>\n\n这里的响应，其中 `auth-scheme` 必须设置为 `Bearer`，如果客户端携带了无效的token，那么按照上一篇[《OAuth 2.0 协议原理与实现：协议原理》](/2017/03/04/oauth-v2-principle/) 讲解的，OAuth 2.0 协议要求错误响应中必须携带 `error` 字段，并选择性携带 `error_description`和 `error_uri`，具体释义请参考上一篇，响应示例如下：\n\n```http\nHTTP/1.1 401 Unauthorized\nWWW-Authenticate: Bearer realm=\"example\",\n                  error=\"invalid_token\",\n                  error_description=\"The access token expired\"\n```\n\n### 三. MAC Type Access Token\n\n前面介绍了BEARER类型的token，[RFC6750](https://tools.ietf.org/html/rfc6750)明确说明该类型token需要[TLS（Transport Layer Security）](https://tools.ietf.org/html/rfc5246)提供安全支持。虽然现今大部分站点都已经或正在由HTTP向HTTPS迁移，但是仍然会有站点继续在使用HTTP，在这类站点中BEARER类型的token存在安全隐患，这个时候MAC类型的token正是用武之地，MAC类型的token设计的主要目的就是为了应对不可靠的网络环境。\n\nMAC类型相对于BEARER类型对于用户资源请求的区别在于，BEARER类型只需要携带授权服务器下发的token即可，而对于MAC类型来说，除了携带授权服务器下发的token，客户端还要携带时间戳，nonce，以及在客户端计算得到的mac值等信息，并通过这些额外的信息来保证传输的可靠性。\n\n#### 3.1 下发 MAC 类型令牌\n\nOAuth2.0协议在规定下发accessToken时，包含 `access_token`，`token_type`，`expires_in`、`refresh_token`，以及 `scope` 字段，其中部分字段可选，具体参见上一篇[《OAuth 2.0 协议原理与实现：协议原理》](/2017/03/04/oauth-v2-principle/)，示例如下：\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n    \"token_type\":\"example\",\n    \"expires_in\":3600,\n    \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n    \"example_parameter\":\"example_value\"\n}\n```\n\n响应字段是可扩展的，对于MAC类型token则增加了 `mac_key` 和 `mac_algorithm` 两个字段，`mac_key` 是一个客户端和服务端共享的对称密钥，`mac_algorithm` 则指明了加密算法（比如hmac-sha-1，hmac-sha-256），示例响应如下：\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"access_token\":\"SlAV32hkKG\",\n    \"token_type\":\"mac\",\n    \"expires_in\":3600,\n    \"refresh_token\":\"8xLOxBtZp8\",\n    \"mac_key\":\"adijq39jdlaska9asud\",\n    \"mac_algorithm\":\"hmac-sha-256\"\n}\n```\n\n#### 3.2 构造 MAC 类型请求\n\n一些开放API接口可能会强制要求以MAC类型令牌来请求，这个时候就需要在客户端构造合法的请求，一个标准的请求示例如下：\n\n```http\nGET /resource/1?b=1&a=2 HTTP/1.1\nHost: example.com\nAuthorization: MAC id=\"h480djs93hd8\",\n                   ts=\"1336363200\",\n                   nonce=\"dj83hs9s\",\n                   mac=\"bhCQXTVyfj5cmA9uKkPFx1zeOXM=\"\n\n```\n\n请求参数说明：\n\n参数名 | 必须 | 描述信息\n--- | --- | ----\nid | 必须 | 访问令牌\nts | 必须 | 时间戳\nnonce | 必须 | 客户端生成的字符串，对于相同token和timespan的请求nonce必须相同\next | 可选 | 扩展信息\nmac | 必须 | 根据MAC key和MAC algorithm计算出来的值\n\n通过添加 `id、ts、nonce、mac` 字段到 `Authorization` 请求首部以发起对用户资源的请求，这里的 `id` 就是授权服务器下发的 accessToken；`ts` 则是时间戳，由客户端生成，以秒为单位；`nonce` 是客户端生成的一个字符串形式的签名，是对 ts 和 id 两个维度的唯一、可重复性标识；而 `mac` 则是整个客户端构造最核心和复杂的部分，可以看做是对本次请求参数的一个签名，1.2.3 小节专门讲解。此外客户端还以用 `ext` 字段来携带一些扩展数据。\n\n#### 3.3 mac 值算法\n\nmac 值可以看作是对本次请求参数的一个签名，通过对请求数据进行本地加密计算得到，用于防止请求过程中参数被更改。服务器端收到请求之后，会以相同的算法和密钥重新计算一遍 mac值，并与客户端传递过来的作比较，如果不一致则拒绝该请求。因为密钥仅保存在客户端和服务端本地，所以无需担心mac值被更改或伪造，从而确保在没有TLS保证的环境下可靠传输，实际上这里可以看做是 MAC 类型请求自己实现了一遍 TLS。\n\nmac值对于相同的请求参数必须是一致和可再计算的，对于参与计算元素的选择，协议选取了如下元素：\n\n> 1. The timestamp value calculated for the request.\n> 2. The nonce value generated for the request.\n> 3. The HTTP request method in upper case. For example: HEAD, GET, POST, etc.\n> 4. The HTTP request-URI as defined by RFC2616 section 5.1.2.\n> 5. The hostname included in the HTTP request using the Host request header field in lower case.\n> 6. The port as included in the HTTP request using the Host request header field. If the header field does not include a port, the default value for the scheme MUST be used (e.g. 80 for HTTP and 443 for HTTPS).\n> 7. The value of the ext Authorization request header field attribute if one was included in the request, otherwise, an empty string.\n\n通过对这些元素按照顺序组织，并以换行符 `\\n` 作分隔（最后一行也需要包含一个 `\\n`），利用 `mac_algorithm` 指定的算法和 `mac_key` 指定的密钥对组织好的数据进行加密计算得到 mac 值。\n\n__计算示例：__\n\n假设有一个请求：\n\n```http\nPOST /request?b5=%3D%253D&a3=a&c%40=&a2=r%20b&c2&a3=2+q HTTP/1.1\nHost: example.com\n\nHello World!\n```\n\n其中 ts=`264095:7d8f3e4a`，nonce=`7d8f3e4a`，ext=`a,b,c`。\n\n对该请求按照之前的说明进行组织，以`\\n`分隔得到：\n\n```\n264095\\n\n7d8f3e4a\\n\nPOST\\n\n/request?b5=%3D%253D&a3=a&c%40=&a2=r%20b&c2&a3=2+q\\n\nexample.com\\n\n80\\n\na,b,c\\n\n```\n\n其中 `\\n` 仅仅是为了展示，实际中以 ASCII 码 `%x0A` 的意义表示，不要忘了最后一行的 `\\n`。假设授权服务器指定的 `mac_algorithm` 为 hmac-sha-1，令 `text` 表示上面的字符串，那么最后的 mac 值得计算方式如下：\n\n> mac = hmac-sha-1(mac_key, text)\n\n#### 3.4 服务端验证\n\n服务器端在收到客户端的请求之后，需要做如下验证：\n\n> 1. 重新计算mac值，并与客户端传递的值进行比较\n> 2. 确保(timestam, nonce, token)三个维度之前没有被请求过，以防止重放攻击\n> 3. 验证scope，以及token\n\n如果服务端拒绝客户端的请求，则需要指定 `WWW- Authenticate` 响应首部，例如客户端携带了无效的授权信息，则服务器响应示例如下：\n\n```http\nHTTP/1.1 401 Unauthorized\nWWW-Authenticate: MAC error=\"The MAC credentials expired\"\n```\n\n### 四. 本篇小结\n\n本篇主要介绍了两种 token 类型，基本可以覆盖实际应用中的各种场景。Token 是对用户授权操作的一类凭证，一旦下发到客户端，其安全性就需要客户端去保证，为了尽量在保护用户数据和提升用户体验上寻找一个平衡点，token 的生命周期不应该设置的太短或太长。\n\n本篇和上一篇[《OAuth 2.0 协议原理与实现：协议原理》](/2017/03/04/oauth-v2-principle/) 介绍了 OAuth 2.0 协议涉及到的理论知识，相关实现可以参考考 [oauth4j](https://github.com/plotor/oauth4j)。\n\n### 参考文献\n\n1. [RFC5849 - The OAuth 1.0 Protocol](https://tools.ietf.org/html/rfc5849)\n2. [RFC6749 - The OAuth 2.0 Authorization Framework](https://tools.ietf.org/html/rfc6749)\n3. [RFC6750 - The OAuth 2.0 Authorization Framework: Bearer Token Usage](https://tools.ietf.org/html/rfc6750)\n4. [HTTP Authentication: MAC Authentication (draft-hammer-oauth-v2-mac-token-02)](https://tools.ietf.org/html/draft-hammer-oauth-v2-mac-token-02)\n","tags":["OAuth"],"categories":["protocol"]},{"title":"OAuth 2.0 协议原理与实现：协议原理","url":"/2017/03/04/protocol/oauth-v2-principle/","content":"\nOAuth 2.0 协议是一种三方授权协议，目前大部分的第三方登录与授权都是基于该协议的标准或改进实现。OAuth 1.0 的标准在 2007 年发布，2.0 的标准则在 2011 年发布，其中 2.0 的标准取消所有 token 的加密过程，并简化了授权流程，但因强制使用 HTTPS 协议，被认为安全性高于 1.0 的标准。<!-- more -->\n\n### 一. 基础应用：第三方登录\n\n对于 OAuth 2.0 协议（以下简称 OAuth 协议）的第一次接触，我相信大部分开发者都是通过对接第三方登录才开始知道和了解该协议。的确，OAuth 协议被广泛应用于第三方授权登录中，借助第三方登录可以让用户免于再次注册之苦，支持第三方登录也对这些网站、APP 起到了积极的作用，免去了复杂的注册过程，用户体验更佳，更愿意去登录。这样在提高留存率的同时，也更加易于收集用户的一些非敏感信息等，另外还可以借助一些社交类的第三方账号进行站点推广等。\n\n账号服务对于一个公司来说是一个基础类服务，既简单也复。说它简单，是因为账号的主要业务就是注册和登录，相信很多人在初次接触 WEB 开发的时候，第一个作业就是实现一个用户注册和登录的流程；说它复杂，是因为账号服务往往是一个公司开展其它业务的基础，必须是公司业务中 QPS 最高的业务之一，需具备高可用、低延迟等特点，因为涉及到用户的敏感信息，还需要在安全方面下足功夫，近几年听到的盗号、拖库事件越来越没有新鲜感了。所以对于一个规模不大的公司来说，将主要人力投入在建立自己的账号业务上是一件性价比很低的事情，这个时候接入大公司的第三方账户登录，应该是更加可取的一种选择。\n\n### 二. OAuth 2.0 协议的基本定义与授权流程\n\n作为第三方登录服务提供方，我们的核心矛盾点就是 __既要让用户在对接我们服务的 APP 上登录，同时还不能让该 APP 拿到用户的登录凭证__ 。解决这一矛盾的利器就是 token（中文译为令牌），而 OAuth 协议的最终目的就是给第三方应用下发 token，它记录了用户的登录或授权状态，通过将 token 传递给第三方应用，既能让第三方应用登录并拿到用户许可数据，也可以将用户的凭证牢牢拽在自己的手里（token 是加密存储的，所以不担心因 token 下发而泄露用户凭证数据）。\n\n说到用户登录状态的记录，我们可能最先想到的是 session 机制，想想你在做的第一个用户登录应用的时候，是不是拿服务器的 session 去记录用户是否登录。这一做法简单，但是也存在问题，session 说到底也还是缓存，当用户量较大的时候，需要相当大容量的缓存才能够容纳所有用户的登录状态，并且我们的 WEB 服务器往往有多台，通过负载均衡机制来提升服务的可用性，这样的场景下，我们不能简单的通过本地 session 来记录用户的登录状态，必须有专门的 session 服务器，或者其它的一些 session 复制措施，还需要考虑宕机造成的 session 丢失等问题，总之用户量大了，许多最初不是问题的问题逐渐暴露出来，有的甚至可能是极其棘手的。实际上对于用户登录状态的保存，我们可以走 token 机制，让客户端自己去保存用户的登录状态，将服务器从繁重的压力中解脱出来，利用 SSO（单点登录：Single Sign On）来实现公司内各业务之间 “一次登录，到处可用”。\n\n回到 OAuth 协议，上面的论述可能侧重了第三方登录，实际上登录只是一个授权的过程，对于一个应用，其最终目的还是希望能够拿到用户存储在资源服务器上的用户数据，所以登录授权还只是第一步，后续 APP 还需要携带 token 去资源服务器请求用户数据，这个时候是一个鉴权的过程，OAuth 协议的主要目的在于授权，至于鉴权，实现上主要是还是对 APP 传递过来的 token 进行解析和验证，这一块相对要简单一些，所以下面主要讲解 OAuth 授权的流程。\n\n#### 2.1 OAuth 2.0 定义的 5 种角色\n\n- __客户端（Client）__\n\n客户端是 OAuth 服务的接入方，其目的是请求用户存储在资源服务器上的受保护资源，客户端可以移动应用、网页应用，以及电视应用等等。\n\n- __用户代理（User Agent）__\n\n用户代理是用户参与互联网的工具，一般可以理解为浏览器。\n\n- __资源所有者（Resource Owner）__\n\n受保护资源所属的实体，比如资源的持有人等，下文的用户即资源所有者。\n\n- __授权服务器（Authorization Server）__\n\n授权服务器的主要职责是验证资源所有者的身份，并依据资源所有者的许可对第三方应用下发令牌。\n\n- __资源服务器（Resource Server）__\n\n托管资源的服务器，能够接收和响应持有令牌的资源访问请求，可以与授权服务器是同一台服务器，也可以分开。\n\n#### 2.2 基本概念\n\n##### 2.2.1 访问令牌（access token）\n\n访问令牌是在用户授权许可下，授权服务器下发给客户端的一个授权凭证，该令牌所要表达的意思是“用户授予该 APP 在多少时间范围内允许访问哪些与自己相关的服务”，所以访问令牌主要在 __时间范围__ 和 __权限范围__ 两个维度进行控制，此外访问令牌对于客户端来说是非透明的，外在表现就是一个字符串，客户端无法知晓字符串背后所隐藏的用户信息，因此不用担心用户的登录凭证会因此而泄露。\n\nOAuth 协议虽然最终以令牌的形式授权，却没有对令牌的具体生成策略和构成元素作过多的说明，这一块的实现给予 OAuth 的实现者充分的自由，在本系列的下一篇，我们将会详细介绍两种令牌实现策略：BEARER 类型和 MAC 类型。\n\n##### 2.2.2 刷新令牌（refresh token）\n\n刷新令牌的作用在于更新访问令牌，访问令牌的有效期一般较短，这样可以保证在发生访问令牌泄露时，不至于造成太坏的影响，但是访问令牌有效期设置太短存在的副作用就是用户需要频繁授权，虽然可以通过一定的机制进行静默授权，但是频繁的调用授权接口，之于授权服务器也是一种压力，这种情况下就可以在下发访问令牌的同时下发一个刷新令牌，刷新令牌的有效期明显长于访问令牌，这样在访问令牌失效时，可以利用刷新令牌去授权服务器换取新的访问令牌，不过协议对于刷新令牌没有强制规定，是否需要该令牌是客户端可以自行选择。\n\n\n##### 2.2.3 回调地址（redirect uri）\n\nOAuth 2.0 是一类基于回调的授权协议，在授权码模式中，整个授权需要分为两步进行，第一步下发授权码，第二步根据第一步拿到的授权码请求授权服务器下发访问令牌。OAuth 在第一步下发授权码时，是将授权码以参数的形式添加到回调地址后面，并以302跳转的形式进行下发，这样简化了客户端的操作，不需要再主动去触发一次请求，即可进入下一步流程。\n\n回调请求的设计却存在一个很大的安全隐患，坏人如果在客户端请求过程中修改了对应的回调地址，并指向自己的服务器，那么坏人可以利用这种机制去拿到客户端的授权码，继而走后面的流程，最终拿到访问令牌，另外坏人可以利用该机制引导用户到一个恶意站点，继而对用户发起攻击。以上两点都是该机制对于用户所造成的安全威胁，对于授权服务器而言，也存在一定的危害，坏人可以利用该机制让授权服务器变成“请求发送器”，以授权服务器为代理请求目标地址，这样在消耗授权服务器性能的同时，也对目标地址服务器产生 DDOS 攻击。\n\n为了避免上述安全隐患，OAuth 协议强制要求客户端在注册时填写自己的回调地址，这个回调地址的目的是为了让回调请求能够到达客户端自己的服务器，从而可以走获取访问令牌的流程。客户端可以同时配置多个回调地址，并在请求授权时携带一个地址，服务器会验证客户端传递上来的回调地址是否与之前注册的回调地址相同，或者前者是后者集合的一个元素，只有在满足这一条件下才允许下发授权码，同时协议还要求两步请求客户端携带的回调地址必须一致，通过这些措施来保证回调过程能够正常达到客户端自己的服务器，并继续后面拿授权码换取访问令牌的流程。\n\n##### 2.2.4 权限范围（scope）\n\n访问令牌自带过期时间，可以在时间维度上对授权进行控制，而在范围维度上，OAuth 引入了一个 scope 的概念。scope 可以看做是一个对象，包含一个权限的 ID，名称，以及描述信息等，比如“获取您的基本资料（头像、昵称）”。应该在接入账号服务时必须向第三方登录服务提供方申请响应的 scope，并在请求授权时指明该参数（否则表明获取该应用所允许的所有权限），这些权限在用户确认授权时，必须毫无保留的展示给用户，以让用户知道该 APP 需要获取用户的哪些数据或服务。\n\n#### 2.3 基本授权流程\n\nOAuth 协议已定义了 4 种授权模式，其中最具代表性的就是授权码模式，这个在 3.1 小节中详细介绍，这里先以该模式来简单感受一下 OAuth2.0 的授权流程，授权流程图如下：\n\n![image](/images/2017/oauth-simple-procedure.png)\n\n假设整个流程开始之前，用户已经登录，那么整个授权流程如下：\n\n1. 客户端请求授权服务器授权；\n2. 授权服务的授权端点重定向用户至授权交互页面，并询问用户是否授权；\n3. 如果用户许可，则授权端点验证客户端的身份，并发放授权码给客户端；\n4. 客户端拿到授权码之后，携带授权码请求授权服务器的令牌端点下发访问令牌；\n5. 令牌端点验证客户端的身份和授权码，通过则下发访问令牌和刷新令牌（可选）；\n6. 客户端拿到访问令牌后，携带访问令牌请求资源服务器上的受保护资源；\n7. 资源服务器验证客户端身份和访问令牌，通过则响应受保护资源访问请求。\n\n整个流程中，客户端都无法接触到用户的登录凭证信息，客户端通过访问令牌请求受保护资源，用户可以通过对授权操作的控制来间接控制客户端对于受保护资源的访问权限范围和时效。\n\n### 三. 四种授权模式\n\nOAuth 2.0 相对于 1.0 版本在授权模式上做了更多的细化，已定义的授权模式分为四种：1）授权码模式（Authorization Code Grant）；2)隐式授权模式（Implicit Grant）；3）资源所有者密码凭证模式（Resource Owner Password Credentials Grant）；4）以及客户端凭证模式（Client Credentials Grant）。\n\n#### 3.1 授权码授权模式（Authorization Code Grant）\n\n授权码模式在整个授权流程上与 1.0 版本最贴近，但是整个流程还是要简化了许多，也是 OAuth 2.0 中最标准，应用最广泛的授权模式。这类授权模式非常适合于具备服务端的应用，当然现在大多数 APP 都有自己的服务端，所以大部分 APP 的 OAuth 授权都可以采取授权码模式，下图为授权码各个角色之间的交互时序（这里让用户直接参与其中，省略了用户代理）：\n\n![image](/images/2017/oauth-v2-authorization-code.png)\n\n整个授权流程说明如下（具体参数释义见下文）：\n\n1. 客户端携带 client_id, scope, redirect_uri, state 等信息引导用户请求授权服务器的授权端点下发 code；\n2. 授权服务器验证客户端身份，验证通过则询问用户是否同意授权（此时会跳转到用户能够直观看到的授权页面，等待用户点击确认授权）；\n3. 假设用户同意授权，此时授权服务器会将 code 和 state（如果客户端传递了该参数）拼接在 redirect_uri 后面，以 302 形式下发 code；\n4. 客户端携带 code, redirect_uri, 以及 client_secret 请求授权服务器的令牌端点下发 access_token（这一步实际上中间经过了客户端的服务器，除了 code，其它参数都是在应用服务器端添加，下文会细讲）；\n5. 授权服务器验证客户端身份，同时验证 code，以及 redirect_uri 是否与请求 code 时相同，验证通过后下发 access_token，并选择性下发 refresh_token。\n\n##### 3.1.1 获取授权码\n\n授权码是授权流程的一个中间临时凭证，是对用户确认授权这一操作的一个暂时性的证书，其生命周期一般较短，协议建议最大不要超过 10 分钟，在这一有效时间周期内，客户端可以凭借该暂时性证书去授权服务器换取访问令牌。\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nresponse_type | 必须 | 对于授权码模式 `response_type=code`\nclient_id | 必须 | 客户端 ID，用于标识一个客户端，等同于 appId，在注册应用时生成\nredirect_uri | 可选 | 授权回调地址，具体参见 2.2.3 小节\nscope | 可选 | 权限范围，用于对客户端的权限进行控制，如果客户端没有传递该参数，那么服务器则以该应用的所有权限代替\nstate | 推荐 | 用于维持请求和回调过程中的状态，防止 [CSRF攻击](https://zh.wikipedia.org/wiki/%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0)，服务器不对该参数做任何处理，如果客户端携带了该参数，则服务器在响应时原封不动的返回\n\n__请求参数示例：__\n\n```http\nGET /authorize?response_type=code&client_id=s6BhdRkqt3&state=xyz&redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1\nHost: server.example.com\n```\n\n客户端携带上述参数请求授权服务器的令牌端点，授权服务器会验证客户端的身份以及相关参数，并在确认用户登录的前提下弹出确认授权页询问用户是否授权，如果用户同意授权，则会将授权码（code）和 state 信息（如果客户端传递了该参数）添加到回调地址后面，以 302 的形式下发。\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\ncode | 必须 | 授权码，授权码代表用户确认授权的暂时性凭证，只能使用一次，推荐最大生命周期不超过 10 分钟\nstate | 可选 | 如果客户端传递了该参数，则必须原封不动返回\n\n__成功响应示例：__\n\n```http\nHTTP/1.1 302 Found\nLocation: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA&state=xyz\n```\n\n如果请求参数错误，或者服务器端响应错误，那么需要将错误信息添加在回调地址后面，以302形式下发（回调地址错误，或客户端标识无效除外）。\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码\nerror_description | 可选 | 具备可读性的错误描述信息\nerror_uri | 可选 | 错误描述信息页面地址\nstate | 可选 | 如果客户端传递了该参数，则必须原封不动返回\n\n__错误响应示例：__\n\n```http\nHTTP/1.1 302 Found\nLocation: https://client.example.com/cb?error=access_denied&state=xyz\n```\n\n##### 3.1.2 下发访问令牌\n\n授权服务器的授权端点在以302形式下发 code 之后，用户 User-Agent，比如浏览器，将携带对应的 code 回调请求用户指定的 redirect_url，这个地址应该能够保证请求打到应用服务器的对应接口，该接口可以由此拿到 code，并附加相应参数请求授权服务器的令牌端点，授权端点验证 code 和相关参数，验证通过则下发 access_token。\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\ngrant_type | 必须 | 对于授权码模式 `grant_type=authorization_code`\ncode | 必须 | 上一步骤获取的授权码\nredirect_uri | 必须 | 授权回调地址，具体参见2.2.3小节，如果上一步有设置，则必须相同\nclient_id | 必须 | 客户端ID，用于标识一个客户端，等同于appId，在注册应用时生成\n\n如果在注册应用时有下发客户端凭证信息（client_secret），那么客户端必须携带该参数以让授权服务器验证客户端的有效性。针对客户端凭证需要多说的一点就是，不能将其传递到客户端，客户端无法保证凭证的安全，凭证应该始终留在应用的服务器端，当下发code回调请求到应用服务器时，在服务器端携带上凭证再次请求下发令牌。\n\n__请求参数示例：__\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=authorization_code&code=SplxlOBeZQQYbYS6WxSbIA&redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb\n```\n\n授权服务器需要验证客户端的有效性，以及是否与之前请求授权码的客户端是同一个（请求授权时的信息可以记录在 code，或以 code 为 key 建立缓存），授权服务器还要保证 code 处于生命周期内（推荐 10 分钟内有效），且只能被使用一次。授权服务器验证通过之后，生成 access_token，并选择性下发 refresh_token，OAuth 2.0 协议明确了 token 的下发策略，对于生成策略没有做太多说明，我们将在本系列的下一篇详细介绍两种 token 类型，即 BEARER 类型和 MAC 类型。\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\naccess_token | 必须 | 访问令牌\ntoken_type | 必须 | 访问令牌类型，比如bearer，mac等等\nexpires_in | 推荐 | 访问令牌的生命周期，以秒为单位，表示令牌下发后多久时间过期，如果没有指定该项，则使用默认值\nrefresh_token | 可选 | 刷新令牌，选择性下发，参见2.2.2\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明\n\n最后访问令牌以JSON格式响应，并要求指定响应首部 `Cache-Control: no-store` 和 `Pragma: no-cache`。\n\n__成功响应示例：__\n\n```json\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n{\n\"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n\"token_type\":\"example\",\n\"expires_in\":3600,\n\"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n\"example_parameter\":\"example_value\"\n}\n```\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码\nerror_description | 可选 | 具备可读性的错误描述信息\nerror_uri | 可选 | 错误描述信息页面地址\n\n__错误响应示例：__\n\n```json\nHTTP/1.1 400 Bad Request\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n\"error\":\"invalid_request\"\n}\n```\n\n##### 3.1.3 对于授权码模式的一点感悟\n\n授权码授权模式是 OAuth 2.0 协议已定义 4 种模式中最严谨的模式，剩余 3 中模式都是建立在一些特殊场景下，并对这些场景做了一些妥协和优化。授权码授权流程分为两步走，将用户授权与下发 token 分开，这给授权带来了更多的灵活性，正常授权过程中必须经过用户登录这一步骤，在用户已登录的前提下，可以直接询问用户是否同意授权，但是在一些场景下，比如内部走 SSO 登录的应用集成了基于 OAuth 登录的第三方应用，这个时候在 OAuth 授权登录第三方应用时用户体验较好的流程是不需要用户再一次输入用户名和密码登录的，这就需要将外围 APP 的登录态传递给该应用，但是这样是存在安全问题的，用户的登录态必须把握在走 SSO 登录流程的应用中，这样的场景下授权码授权模式的两步走流程就可以满足在不交出用户登录态的情况下，无需再次登录即可授权。\n\n内部应用可以拿着第三方应用的 client_id 等信息代替第三方应用去请求获取 code，因为自己持有用户的登录态，所以过程中无需用户再次输入用户名和密码，拿到 code 之后将其交给第三方应用，第三方应用利用 code 和自己的 client_secret 信息去请求授权服务器下发 token，整个流程内部应用不需要交出自己持有的用户登录态，第三方应用也无需交出自己的 client_secret 信息，最终却能够实现在保护用户登录凭证的前提下无需再次登录即可完成整个授权流程。\n\n#### 3.2 隐式授权模式（Implicit Grant）\n\n对于一些纯客户端应用，往往无法妥善的保管客户端的凭证，但是因为没有服务器端，所以无法向授权服务器传递客户端凭证，并且纯客户端应用在请求交互上要弱于有服务器的应用，这时候减少交互可以让应用的稳定性和用户体验更好，隐式授权模式是对这一应用场景的优化。\n\n隐式授权模式在安全性上要弱于授权码模式，因为无法对当前客户端的真实性进行验证，同时对于下发的 access_token 存在被同设备上其它应用窃取的风险，为了降低这类风险，隐式授权模式强制要求不能下发 refresh_token，这一强制要求的另外一个考量个人觉得是因为 refresh_token 的生命周期较长，而客户端无法安全的对其进行存储和保护。下图为授权码各个角色之间的交互时序（这里让用户直接参与其中，省略了用户代理）：\n\n![image](/images/2017/oauth-v2-implicit-grant.png)\n\n整个授权流程说明如下：\n\n1. 客户端携带 client_id, scope, redirect_uri, state 等信息引导用户请求授权服务器下发 access_token；\n2. 授权服务器验证客户端身份，验证通过则询问用户是否同意授权（此时会跳转到用户能够直观看到的授权页面，等待用户点击确认授权）；\n3. 假设用户同意授权，此时授权服务器会将 access_token 和 state（如果客户端传递了该参数）等信息以 URI Fragment 形式拼接在 redirect_uri 后面，并以 302 形式下发；\n4. 客户端利用脚本解析获取 access_token。\n\n##### 3.2.1 请求获取访问令牌\n\n不同于授权码模式的分两步走，隐式授权码模式一步即可拿到访问令牌。\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nresponse_type | 必须 | 对于授权码模式 `response_type=token`\nclient_id | 必须 | 客户端 ID，用于标识一个客户端，等同 于appId，在注册应用时生成\nredirect_uri | 可选 | 授权回调地址，具体参见 2.2.3 小节\nscope | 可选 | 权限范围，用于对客户端的权限进行控制，如果客户端没有传递该参数，那么服务器则以该应用的所有权限代替\nstate | 推荐 | 用于维持请求和回调过程中的状态，防止 [CSRF攻击](https://zh.wikipedia.org/wiki/%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0)，服务器不对该参数做任何处理，如果客户端携带了该参数，则服务器在响应时原封不动的返回\n\n__请求参数示例：__\n\n```http\nGET /authorize?response_type=token&client_id=s6BhdRkqt3&state=xyz&redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1\nHost: server.example.com\n```\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\naccess_token | 必须 | 访问令牌\ntoken_type | 必须 | 访问令牌类型，比如bearer，mac等等\nexpires_in | 推荐 | 访问令牌的生命周期，以秒为单位，表示令牌下发后多久时间过期，如果没有指定该项，则使用默认值\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明\nstate | 可选 | 如果客户端传递了该参数，则必须原封不动返回\n\n隐式授权模式不下发刷新令牌，访问令牌以 URI Fragment 的形式拼接在授权回调地址后面以302形式下发，并要求指定响应首部 `Cache-Control: no-store` 和 `Pragma: no-cache`。\n\n__成功响应示例：__\n\n```http\nHTTP/1.1 302 Found\nLocation: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA&state=xyz&token_type=example&expires_in=3600\n```\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码\nerror_description | 可选 | 具备可读性的错误描述信息\nerror_uri | 可选 | 错误描述信息页面地址\nstate | 可选 | 如果客户端传递了该参数，则必须原封不动返回\n\n授权服务器将上述元素以URI Fragment形式拼接在授权回调地址后面以302形式下发（redirect_uri 或 client_id 错误除外）。\n\n__错误响应参数示例：__\n\n```http\nHTTP/1.1 302 Found\nLocation: https://client.example.com/cb#error=access_denied&state=xyz\n```\n\n#### 3.3 资源所有者密码凭证授权模式（Resource Owner Password Credentials Grant）\n\n资源所有者密码凭证授权模式建立在资源所有者充分信任客户端的前提下，因为该模式客户端可以拿到用的登录凭证，从而在用户无感知的情况下完成整个授权流程，毕竟都有用户的登录凭证了，再弹窗让用户确认授权也是多此一举。\n\n这里可能有一个比较疑惑的地方是既然已经拿到了用户的登录凭证，为什么还需要绕一大圈子走 OAuth 授权，拿到令牌再去请求用户的受保护资源呢？实际中事情可能并不会这么简单，拿到用户登录凭证的不一定是用户本身，而且这里协议指的用户登录凭证是用户的用户名和密码，实际中还可以是走 SSO 登录下发的 token，token 在持有权限上要小于等于用户的用户名和密码，这是从客户端角度出发，对于资源服务器来说，有些敏感数据需要在用户级别做权限控制，对于服务级别的控制粒度太粗，所以这些服务往往需要服务携带 access_token来请求某一个用户的敏感数据。\n\n举个例子来说，比如有一个服务是获取某个用户的通讯录，这是一个十分敏感的数据，且一般只能授予内部应用，如果是在服务级别进行控制，那么只要拿到服务权限，该应用可以请求获取任何一个用户的通讯录数据，这是一件十分危险的事情。然而如果基于 access_token 来做鉴权，那么就可以将粒度控制在用户级别，前面讲的两种授权方式在这里应用时都有一个共同的缺点，需要弹出授权页让用户确认授权，要知道这样的场景往往是发生在内部应用里面，内部应用是可以持有用户登录态的，这里的确认授权对于一个用户体验好的 APP 来说就应该发生在用户登录时，通过用户协议等方式直接告诉用户，从而让用户在一次登录过程中可以让应用拿到用户的登录态和访问令牌。资源所有者密码凭证授权模式的交互时序如下：\n\n![image](/images/2017/oauth-v2-resource-owner-password-credentials.png)\n\n整个授权流程说明如下：\n\n1. 用于授予客户端登录凭证（比如用户名和密码信息）；\n2. 客户端携带用户的登录凭证和scope等信息请授权服务器的令牌端点下发refresh_token；\n3. 授权服务器验证用户的登录凭证和客户端信息的有效性，验证通过则下发access_token，并选择性下发refresh_token。\n\n##### 3.3.1 用户授予登录凭证\n\n用于登录凭证如何传递给客户端这一块协议未做说明，实际应用中该类授权一般应用在内部应用，这类应用的特点就是为用户提供登录功能，当用户登录之后，这类应用也就持有了用户的登录态，可以是用户登录的 session 标识，也可以是走 SSO 下发的 token 信息。\n\n##### 3.3.2 请求获取访问令牌\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\ngrant_type | 必须 | 对于本模式 `grant_type=password`\nusername | 必须 | 用户名\npassword | 必须 | 用户密码\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明\n\n如果在注册应用时有下发客户端凭证信息（client_secret），那么客户端必须携带该参数以让授权服务器验证客户端的有效性。\n\n__请求参数示例：__\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=password&username=johndoe&password=A3ddj3w\n```\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\naccess_token | 必须 | 访问令牌\ntoken_type | 必须 | 访问令牌类型，比如bearer，mac等等\nexpires_in | 推荐 | 访问令牌的生命周期，以秒为单位，表示令牌下发后多久时间过期，如果没有指定该项，则使用默认值\nrefresh_token | 可选 | 刷新令牌，选择性下发，参见2.2.2\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明\n\n最后访问令牌以JSON格式响应，并要求指定响应首部 `Cache-Control: no-store` 和 `Pragma: no-cache`。\n\n__成功响应参数示例：__\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n    \"token_type\":\"example\",\n    \"expires_in\":3600,\n    \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\",\n    \"example_parameter\":\"example_value\"\n}\n```\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码\nerror_description | 可选 | 具备可读性的错误描述信息\nerror_uri | 可选 | 错误描述信息页面地址\n\n__错误响应示例：__\n\n```http\nHTTP/1.1 400 Bad Request\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"error\":\"invalid_request\"\n}\n```\n\n#### 3.4 客户端凭证授权模式（Client Credentials Grant）\n\n客户端凭证授权模式基于客户端持有的证书去请求用户的受保护资源，如果把这里的受保护资源定义得更加宽泛一点，比如说是对一个内网接口权限的调用，那么这类授权方式可以被改造为内网权限验证服务。客户端凭证授权模式的交互时序如下：\n\n![image](/images/2017/oauth-v2-client-credentials.png)\n\n整个授权流程说明如下：\n\n1. 客户端携带客户端凭证和scope等信息请求授权服务器的令牌端点；\n2. 授权服务器验证客户端凭证，验证通过下发 access_token。\n\n##### 3.4.1 请求获取访问令牌：\n\n__请求参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\ngrant_type | 必须 | 对于本模式 `grant_type=client_credentials`\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明\n\n__请求参数示例：__\n\n```http\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=client_credentials\n```\n\n__成功响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\naccess_token | 必须 | 访问令牌\ntoken_type | 必须 | 访问令牌类型，比如bearer，mac等等\nexpires_in | 推荐 | 访问令牌的生命周期，以秒为单位，表示令牌下发后多久时间过期，如果没有指定该项，则使用默认值\nscope | 可选 | 权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明\n\n最后访问令牌以JSON格式响应，并要求指定响应首部 `Cache-Control: no-store` 和 `Pragma: no-cache`。\n\n__成功响应参数示例：__\n\n```http\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\",\n    \"token_type\":\"example\",\n    \"expires_in\":3600,\n    \"example_parameter\":\"example_value\"\n}\n```\n\n__错误响应参数说明：__\n\n名称 | 是否必须 | 描述信息\n--- | --- | ---\nerror | 必须 | 错误代码\nerror_description | 可选 | 具备可读性的错误描述信息\nerror_uri | 可选 | 错误描述信息页面地址\n\n__错误响应示例：__\n\n```http\nHTTP/1.1 400 Bad Request\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n\n{\n    \"error\":\"invalid_request\"\n}\n```\n\n### 四. 本篇小结\n\n本篇介绍了 OAuth 2.0 授权协议的理论知识，OAuth 2.0 被广泛应用于第三方授权登录，很多其它的协议都是可以基于该协议进行改造的，比如前面多次提到的 SSO，作为开发人员，还是建议对该协议或多或少有些了解。\n\nOAuth 2.0 协议是一个介绍授权框架的协议，对于 token 的生成没有做太多说明，如果要自己实现一个 OAuth 授权和鉴权服务，OAuth 2.0 协议为我们的服务的框架建立绘制了蓝图，但是还有很多细节实现需要我们再去查阅各种资料和实践，下一篇我将介绍 token 的生成策略。\n\n### 参考文献\n\n1. [RFC5849 - The OAuth 1.0 Protocol](https://tools.ietf.org/html/rfc5849)\n2. [RFC6749 - The OAuth 2.0 Authorization Framework](https://tools.ietf.org/html/rfc6749)\n3. [RFC6750 - The OAuth 2.0 Authorization Framework: Bearer Token Usage](https://tools.ietf.org/html/rfc6750)\n4. [HTTP Authentication: MAC Authentication (draft-hammer-oauth-v2-mac-token-02)](https://tools.ietf.org/html/draft-hammer-oauth-v2-mac-token-02)\n","tags":["OAuth"],"categories":["protocol"]},{"title":"探秘 JVM：监控与诊断工具","url":"/2016/12/16/jvm/diagnostic-tools/","content":"\nJDK 在给提供基础的 java 依赖库的同时，也在 bin 目录下提供了一系列的小工具，除了我们常用的 java 和 javac 以外，还包含许多对 JVM 进行性能监控和故障诊断的工具。这些工具能够为我们日常程序开发和问题排查提供极大的便利，主要包含以下几种：\n\n工具 | 描述\n--- | ---\n__jps__ | 显示系统运行中的 JVM 进程列表\n__jstat__ | 用于收集 JVM 各方面的运行数据（类加载、GC、JIT 编译等）\n__jinfo__ | 查看和编辑 JVM 配置信息（JVM 启动参数、系统环境变量等）\n__jmap__ | 生成 JVM 的堆转储快照（heapdump 文件）\njhat | 用于分析 jmp 命令生成的 heapdump 文件，它会建立一个 HTTP/HTML 服务器，让用户可以在浏览器上查看分析结果\n__jstack__ | 生成 JVM 的线程转储快照（通常所说的 threaddump 文件或 javacore 文件），用于判断是否存在死锁、死循环，以及阻塞等情况\njconsole | 可视化 java 监视与管理控制台，基于 JMX\njvisualvm | 多合一故障处理工具，jconsole 的增强版，自 JDK 9 开始不再随 JDK 默认提供，需要独立下载，地址：[http://visualvm.github.io/](http://visualvm.github.io/)\n\n<!-- more -->\n\n补充：\n\n- __jcmd__ ：Java Command，JDK 7 引入，可以用来替代除 jstat 之外的所有命令。\n- __jmc__ ：Java Mission Control，JDK 7 引入，用于监控和管理 java 应用程序，且不会引入额外的性能开销。\n- __jhsdb__ ：Java HotSpot Debugger，JDK 9 引入，基于 Serviceability Agent 实现的 HotSpot 进程调试器。\n\n上面这些工具都是对 `jdk/lib/tools.jar` 类库的上层封装，我们也可以在应用程序中利用该工具进行 JVM 监控分析。需要注意的是，tools 中的类库不属于 java 标准 API，也就是说不是所有的虚拟机都默认支持，如果不支持则需要随项目一起部署。此外，部分工具基于 JMX 实现，如果是在 JDK 5 上运行，在程序启动时需要添加 `-Dcom.sun.management.jmxremote` 参数以开启 JMX 管理功能。\n\n一些 __注意事项__ ：\n\n- 命令 jinfo、jstack，以及 jcmd 依赖于 JVM 的 Attach API，所以只能监控本地 JVM 进程。一旦设置了 JVM 的 DisableAttachMechanism 特性（可以通过 `-XX:+DisableAttachMechanism` 参数配置），基于 Attach API 的命令将无法执行。\n- 如果 JVM 进程关闭了 UsePerfData 参数（默认开启，可以通过 `-XX:-UsePerfData` 参数配置），则 jps 命令和 jstat 命令将无法探知该 JVM 进程。\n\n### 命令行工具\n\n#### jps\n\n命令 jps 用于显示正在运行的 JVM 进程信息，以及这些进程对应的本地虚拟机唯一 ID（LVMID: Local Virtual Machine Identifier），可以类比 linux 的 ps 命令，不过相对来说功能要简单一些。对于本地虚拟机进程来说，LVMID 与操作系统的进程 ID 一致。默认情况下，jps 将显示当前正在运行的 JVM 进程 ID 和主类名信息。\n\n```bash\njps [参数] [hostid]\n\n参数说明：\n-q： 只显示 LVMID，省略主类名\n-m： 输出启动时传递给 main 函数的参数\n-l： 输出主类的全名，如果执行的是 jar 包，则输出 jar 路径\n-v： 输出启动时的 JVM 参数\n```\n\n示例：\n\n```bash\n$ jps -lm\n22513 org.zhenchao.jvm.archangel.inspect.ArchangelDriver -r\n13555 org.zhenchao.jvm.archangel.data.ArchangelDataDriver -r\n```\n\n```bash\n$ jps -v\n22513 ArchangelDriver -Xms2048m -Xmx4096m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -Dapp.name=archangel_inspector.sh -Dapp.pid=22513 -Dapp.repo=/home/work/bin/archangel-inspector/lib -Dapp.home=/home/work/bin/archangel-inspector -Dbasedir=/home/work/bin/archangel-inspector\n```\n\n如果希望通过 RMI 协议查询开启了 RMI 服务的远程虚拟机进程列表，可以通过设置 hostid 参数为 RMI 注册表中注册的主机名执行 jps 查询。\n\n#### jstat\n\n命令 jstat 用于监视 JVM 各种运行状态数据，包括本地或远程虚拟机进程中的类装载、内存、垃圾收集，以及 JIT 编译等运行数据，是在没有图形界面环境中执行性能监控和分析的首选工具。\n\n```bash\njstat [参数] [vmid] [时间间隔(单位：s 或 ms)] [执行次数]\n\n参数说明：\n-class: 监视已加载类数目和内存占用、已卸载类数目和内存占用，以及类装载所耗费的时间\n-compiler: 输出 JIT 编译过的方法和耗时等信息\n-printcompilation: 输出已被 JIT 编译的方法\n-gc: 监视 java 堆的使用情况，包括 Eden 区、两个 survivor 区、老年代、永久代等的容量，已用空间，GC 时间等信息\n-gccapacity: 监视内容同 -gc，但输出主要关注 java 堆各个区域使用到的最大和最小空间\n-gcutil: 监视内容同 -gc，但输出主要关注已使用空间占总空间的百分比\n-gaccause: 相对于 -gcutil，会额外输出导致上一次 GC 产生的原因\n-gcnew: 监视新生代的 GC 状况\n-gcnewcapacity: 监视内容同 -gcnew，但是主要关注使用到的最大和最小空间\n-gcold: 监视老年代的 GC 情况\n-gcoldcapacity: 监视内容同 -gcold，但是主要关注使用到的最大和最小空间\n-gcpermcapacity: 监视永久代使用到的最大和最小空间\n```\n\n__说明__ ：如果是本地虚拟机进程，则 VMID 与 LVMID 是一致的，如果是远程虚拟机进程，则 VMID 的格式为 `[protocol:][//]lvmid[@hostname[:port]/servername]`。\n\n默认情况下，jstat 命令只会打印一次监控数据，可以设置时间间隔和执行次数以实现每隔一段时间打印一次，直至目标 JVM 进程终止为止，或者达到最大打印次数。\n\n- 打印进程的类加载情况\n\n```bash\n$ jstat -class 22513 1s 5\nLoaded  Bytes  Unloaded  Bytes     Time\n  9778 19180.7       55    79.3       5.29\n  9778 19180.7       55    79.3       5.29\n  9778 19180.7       55    79.3       5.29\n  9778 19180.7       55    79.3       5.29\n  9778 19180.7       55    79.3       5.29\n```\n\n- 打印进程的 GC 情况\n\n```bash\n$ jstat -gc 22513 1s 5\n S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT\n139776.0 139776.0  0.0    0.0   1118528.0 141496.6 2566856.0   30911.3   61292.0 59811.2 7000.0 6588.5      7    0.190  15      0.931    1.121\n139776.0 139776.0  0.0    0.0   1118528.0 141496.6 2566856.0   30911.3   61292.0 59811.2 7000.0 6588.5      7    0.190  15      0.931    1.121\n139776.0 139776.0  0.0    0.0   1118528.0 141496.6 2566856.0   30911.3   61292.0 59811.2 7000.0 6588.5      7    0.190  15      0.931    1.121\n139776.0 139776.0  0.0    0.0   1118528.0 141496.6 2566856.0   30911.3   61292.0 59811.2 7000.0 6588.5      7    0.190  15      0.931    1.121\n139776.0 139776.0  0.0    0.0   1118528.0 141496.6 2566856.0   30911.3   61292.0 59811.2 7000.0 6588.5      7    0.190  15      0.931    1.121\n\n$ jstat -gccapacity 22513 1s 5\n NGCMN    NGCMX     NGC     S0C   S1C       EC      OGCMN      OGCMX       OGC         OC       MCMN     MCMX      MC     CCSMN    CCSMX     CCSC    YGC    FGC\n1398080.0 1398080.0 1398080.0 139776.0 139776.0 1118528.0   699072.0  2796224.0  2566856.0  2566856.0      0.0 1103872.0  61292.0      0.0 1048576.0   7000.0      7    15\n1398080.0 1398080.0 1398080.0 139776.0 139776.0 1118528.0   699072.0  2796224.0  2566856.0  2566856.0      0.0 1103872.0  61292.0      0.0 1048576.0   7000.0      7    15\n1398080.0 1398080.0 1398080.0 139776.0 139776.0 1118528.0   699072.0  2796224.0  2566856.0  2566856.0      0.0 1103872.0  61292.0      0.0 1048576.0   7000.0      7    15\n1398080.0 1398080.0 1398080.0 139776.0 139776.0 1118528.0   699072.0  2796224.0  2566856.0  2566856.0      0.0 1103872.0  61292.0      0.0 1048576.0   7000.0      7    15\n1398080.0 1398080.0 1398080.0 139776.0 139776.0 1118528.0   699072.0  2796224.0  2566856.0  2566856.0      0.0 1103872.0  61292.0      0.0 1048576.0   7000.0      7    15\n\n$ jstat -gcutil 22513 1s 5\nS0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT\n0.00   0.00  12.65   1.20  97.58  94.12      7    0.190    15    0.931    1.121\n0.00   0.00  12.65   1.20  97.58  94.12      7    0.190    15    0.931    1.121\n0.00   0.00  12.65   1.20  97.58  94.12      7    0.190    15    0.931    1.121\n0.00   0.00  12.65   1.20  97.58  94.12      7    0.190    15    0.931    1.121\n0.00   0.00  12.65   1.20  97.58  94.12      7    0.190    15    0.931    1.121\n\n$ jstat -gccause 22513\nS0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT    LGCC                 GCC\n0.00   0.00  13.42   1.20  97.58  94.12      7    0.190    15    0.931    1.121 CMS Final Remark     No GC\n```\n\n监控项说明：\n\n变量 | 说明 | 单位\n--- | --- | ---\nS0 | 年轻代中第 1 个 survivor 已使用容量占比 | 百分比\nS1 | 年轻代中第 2 个 survivor 已使用容量占比 | 百分比\nS0C | 年轻代中第 1 个 survivor 的容量 | 字节\nS1C | 年轻代中第 2 个 survivor 的容量 | 字节\nS0U | 年轻代中第 1 个 survivor 已使用容量 | 字节\nS1U | 年轻代中第 2 个 survivor 已使用容量 | 字节\nS0CMX | 年轻代中第 1 个 survivor 的最大容量 | 字节\nS1CMX | 年轻代中第 2 个 survivor 的最大容量 | 字节\nEC | 年轻代中 Eden 的容量 | 字节\nEU | 年轻代中 Eden 目前已使用容量 | 字节\nOC | 老年代的容量 | 字节\nOU | 老年代已使用容量 | 字节\nPC | 永久代的容量 | 字节\nPU | 永久代已使用容量 | 字节\nYGC | 从应用程序启动到采样时年轻代中 GC 次数 |\nYGCT | 从应用程序启动到采样时年轻代中 GC 所用时间 | 秒\nFGC | 从应用程序启动到采样时老年代 GC 次数 |\nFGCT | 从应用程序启动到采样时老年代 GC 所用时间 | 秒\nGCT | 从应用程序启动到采样时 GC 所用总时间 | 秒\nNGC | 年轻代当前容量 | 字节\nNGCMN | 年轻代初始容量 | 字节\nNGCMX | 年轻代最大容量 | 字节\nOGC | 老年代当前容量 | 字节\nOGCMN | 老年代初始容量 | 字节\nOGCMX | 老年代最大容量 | 字节\nPGC | 永久代当前容量 | 字节\nPGCMN | 永久代初始容量 | 字节\nPGCMX | 永久代最大容量 | 字节\nE | 年轻代中 Eden 已使用容量占比 | 百分比\nO | 老年代已使用容量占比 | 百分比\nP | 永久代已使用容量占比 | 百分比\nECMX | 年轻代中 Eden 的最大容量 | 字节\nDSS | 当前所需 survivor 容量，此时 Eden 区已满 | 字节\nTT | s 持有次数限制 |\nMTT | s 最大持有次数限制 |\n\n#### jinfo\n\n命令 jinfo 用于实时查看和调整虚拟机的各项参数，相对于 `jps -v` 仅显示显式设置的 JVM 启动参数而言，能够显示一些默认的 JVM 启动参数。\n\n```bash\njinfo [option] pid\n\n参数：\n-flag [参数名]: 查询和调整参数值\n-sysprops: 打印 System.getProperties 的环境变量值\n```\n\n可以通过 `jinfo -flag [+|-] name` 或 `jinfo -flag name=value` 修改一部分运行时可写的 JVM 参数，需要注意的是 jinfo 在一些平台下功能受限。\n\n需要注意的是，在 java 8 中，jinfo 虽然可以更改任一标志的值，但并不意味着 JVM 会响应这些更改。例如，大多数影响 GC 算法行为的标志会在启动时决定垃圾回收器的行为方式，之后通过 jinfo 更改这些标志并不会改变 JVM 的行为，JVM 会根据初始的算法继续执行。所以这个方法只对 PrintFlagsFinal 命令的输出结果中标记为 manageable 的标志起作用。在 java 11 中，jinfo 会在你尝试修改不可变标志的值时报告错误。\n\n#### jmap & jhat\n\n命令 jmap 主要用于生成堆转储快照（通常所说的 heapdump 或 dump 文件），此外还可用于查询 finalize 执行队列，java 堆和方法区的详细信息（空间使用率、收集器类型等）。\n\n```bash\njmap [参数] vmid\n\n-dump：生成 java 堆转储快照，格式：jmap -dump:[live,] format=b, file=<filename.hprof>，其中 live 参数用于指定只 dump 出存活的对象\n-finalizerinfo: 显示在 F-Queue 中等待 Finalizer 线程执行 finalize 方法的对象\n-heap: 显示 java 堆的详细信息（收集器类型、参数配置、分代状况等）\n-histo: 显示堆中对象统计信息，包括类、实例数、合计容量\n-clstats: 以 ClassLoader 为统计口径，显式类加载统计信息\n-F: 当虚拟机对 -dump 参数没有响应时，可以使用该选项强制生成 dump 快照\n```\n\n显式 java 堆的详细信息：\n\n```bash\n$ jmap -heap 22513\nAttaching to process ID 22513, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.202-b08\n\nusing parallel threads in the new generation.\nusing thread-local object allocation.\nConcurrent Mark-Sweep GC\n\nHeap Configuration:\n   MinHeapFreeRatio         = 40\n   MaxHeapFreeRatio         = 70\n   MaxHeapSize              = 4294967296 (4096.0MB)\n   NewSize                  = 1431633920 (1365.3125MB)\n   MaxNewSize               = 1431633920 (1365.3125MB)\n   OldSize                  = 715849728 (682.6875MB)\n   NewRatio                 = 2\n   SurvivorRatio            = 8\n   MetaspaceSize            = 21807104 (20.796875MB)\n   CompressedClassSpaceSize = 1073741824 (1024.0MB)\n   MaxMetaspaceSize         = 17592186044415 MB\n   G1HeapRegionSize         = 0 (0.0MB)\n\nHeap Usage:\nNew Generation (Eden + 1 Survivor Space):\n   capacity = 1288503296 (1228.8125MB)\n   used     = 678135408 (646.7203216552734MB)\n   free     = 610367888 (582.0921783447266MB)\n   52.629699132721505% used\nEden Space:\n   capacity = 1145372672 (1092.3125MB)\n   used     = 678135408 (646.7203216552734MB)\n   free     = 467237264 (445.59217834472656MB)\n   59.20652941857513% used\nFrom Space:\n   capacity = 143130624 (136.5MB)\n   used     = 0 (0.0MB)\n   free     = 143130624 (136.5MB)\n   0.0% used\nTo Space:\n   capacity = 143130624 (136.5MB)\n   used     = 0 (0.0MB)\n   free     = 143130624 (136.5MB)\n   0.0% used\nconcurrent mark-sweep generation: # 老年代使用情况\n   capacity = 2628460544 (2506.6953125MB)\n   used     = 31653136 (30.186782836914062MB)\n   free     = 2596807408 (2476.508529663086MB)\n   1.2042461916445644% used\n\n22244 interned Strings occupying 2251000 bytes.\n```\n\n由于 jmap 需要访问堆中的所有对象，为了保证整个过程中不被应用线程所干扰，jmap 需要借助安全点机制让所有线程暂停以不改变堆中数据的状态，这可能导致基于该堆转储快照分析出的结果存在偏差。此外，如果某个线程长时间无法运行至安全点，jmap 命令将一直等下去。\n\n命令 jhat 提供了对 jmap 生成的堆转储快照的分析支持，但是一般情况下不推荐使用该命令，通常的做法都是将转储文件拷贝到本地，借助可视化工具（比如：[VisualVM](https://visualvm.github.io/)、[MAT: Eclipse Memory Analyzer](https://www.eclipse.org/mat/)、[IBM HeapAnalyzer](https://www.ibm.com/support/pages/ibm-heapanalyzer) 等）进行分析。\n\n#### jstack\n\n命令 jstack 用于生成虚拟机当前的线程转储快照（通常所说的 threaddump 文件或 javacore 文件），包含当前虚拟机内每个条线程正在执行的方法的堆栈信息，从而分析程序当前是否存在死锁、死循环，以及阻塞等情况。\n\n```bash\njstack [参数] vmid\n\n参数说明：\n-F: 当正常的输出请求不被响应时，强制输出线程堆栈\n-l: 除堆栈外，显示关于锁的附加信息\n-m: 如果调用的是本地方法，可以显示 C/C++ 的堆栈\n```\n\n从 JDK 5 起，Thread 类新增了 `Thread#getAllStackTraces` 方法以获取虚拟机中所有线程的 StackTraceElement 对象，可以基于该方法以程序的方式实现 jstack 命令的大部分功能。\n\n下面我们来写一个死锁程序，并通过 jstack 命令输出程序在死锁时的堆栈信息：\n\n```java\nprivate static class A {\n}\n\nprivate static class B {\n}\n\npublic static void main(String[] args) {\n    A a = new A();\n    B b = new B();\n\n    final Thread thread1 = new Thread(() -> {\n        synchronized (a) {\n            sleep(10); // 暂停一下，给其它线程获取锁的时间\n            synchronized (b) {\n                System.out.println(\"thread: \" + Thread.currentThread().getName());\n            }\n        }\n    }, \"1\");\n\n    final Thread thread2 = new Thread(() -> {\n        synchronized (b) {\n            sleep(10); // 暂停一下，给其它线程获取锁的时间\n            synchronized (a) {\n                System.out.println(\"thread: \" + Thread.currentThread().getName());\n            }\n        }\n    }, \"2\");\n\n    thread1.start();\n    thread2.start();\n}\n```\n\n执行 jstack 命令输出堆栈信息：\n\n```bash\n$ jstack 16844\nFull thread dump Java HotSpot(TM) 64-Bit Server VM (25.241-b07 mixed mode):\n\n\"DestroyJavaVM\" #14 prio=5 os_prio=0 tid=0x00000000032c3000 nid=0x3e90 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"2\" #13 prio=5 os_prio=0 tid=0x00000000202b9800 nid=0x3d60 waiting for monitor entry [0x0000000020c2f000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n        at org.zhenchao.jvm.DeadLock.lambda$main$1(DeadLock.java:32)\n        - waiting to lock <0x000000076be2a648> (a org.zhenchao.jvm.DeadLock$A)\n        - locked <0x000000076be2c9e8> (a org.zhenchao.jvm.DeadLock$B)\n        at org.zhenchao.jvm.DeadLock$$Lambda$2/999966131.run(Unknown Source)\n        at java.lang.Thread.run(Thread.java:748)\n\n\"1\" #12 prio=5 os_prio=0 tid=0x00000000202b9000 nid=0x10dc waiting for monitor entry [0x0000000020b2f000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n        at org.zhenchao.jvm.DeadLock.lambda$main$0(DeadLock.java:23)\n        - waiting to lock <0x000000076be2c9e8> (a org.zhenchao.jvm.DeadLock$B)\n        - locked <0x000000076be2a648> (a org.zhenchao.jvm.DeadLock$A)\n        at org.zhenchao.jvm.DeadLock$$Lambda$1/2093631819.run(Unknown Source)\n        at java.lang.Thread.run(Thread.java:748)\n\n\"Service Thread\" #11 daemon prio=9 os_prio=0 tid=0x000000001e766000 nid=0x8b4 runnable [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C1 CompilerThread3\" #10 daemon prio=9 os_prio=2 tid=0x000000001e6c1000 nid=0x4214 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread2\" #9 daemon prio=9 os_prio=2 tid=0x000000001e6be800 nid=0x355c waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread1\" #8 daemon prio=9 os_prio=2 tid=0x000000001e6bd800 nid=0x4140 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread0\" #7 daemon prio=9 os_prio=2 tid=0x000000001e6ba000 nid=0x3ce0 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Monitor Ctrl-Break\" #6 daemon prio=5 os_prio=0 tid=0x000000001e6b5000 nid=0x3120 runnable [0x000000001fc2e000]\n   java.lang.Thread.State: RUNNABLE\n        at java.net.SocketInputStream.socketRead0(Native Method)\n        at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)\n        at java.net.SocketInputStream.read(SocketInputStream.java:171)\n        at java.net.SocketInputStream.read(SocketInputStream.java:141)\n        at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)\n        at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)\n        at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)\n        - locked <0x000000076bd049c0> (a java.io.InputStreamReader)\n        at java.io.InputStreamReader.read(InputStreamReader.java:184)\n        at java.io.BufferedReader.fill(BufferedReader.java:161)\n        at java.io.BufferedReader.readLine(BufferedReader.java:324)\n        - locked <0x000000076bd049c0> (a java.io.InputStreamReader)\n        at java.io.BufferedReader.readLine(BufferedReader.java:389)\n        at com.intellij.rt.execution.application.AppMainV2$1.run(AppMainV2.java:64)\n\n\"Attach Listener\" #5 daemon prio=5 os_prio=2 tid=0x000000001e645000 nid=0x43cc waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Signal Dispatcher\" #4 daemon prio=9 os_prio=2 tid=0x000000001e642800 nid=0x19f0 runnable [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Finalizer\" #3 daemon prio=8 os_prio=1 tid=0x000000001cf13000 nid=0x3ec4 in Object.wait() [0x000000001f92f000]\n   java.lang.Thread.State: WAITING (on object monitor)\n        at java.lang.Object.wait(Native Method)\n        - waiting on <0x000000076bb88ee0> (a java.lang.ref.ReferenceQueue$Lock)\n        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)\n        - locked <0x000000076bb88ee0> (a java.lang.ref.ReferenceQueue$Lock)\n        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)\n        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)\n\n\"Reference Handler\" #2 daemon prio=10 os_prio=2 tid=0x000000001e5d3000 nid=0x25a0 in Object.wait() [0x000000001f82e000]\n   java.lang.Thread.State: WAITING (on object monitor)\n        at java.lang.Object.wait(Native Method)\n        - waiting on <0x000000076bb86c00> (a java.lang.ref.Reference$Lock)\n        at java.lang.Object.wait(Object.java:502)\n        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)\n        - locked <0x000000076bb86c00> (a java.lang.ref.Reference$Lock)\n        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)\n\n\"VM Thread\" os_prio=2 tid=0x000000001cf07000 nid=0x4278 runnable\n\n\"GC task thread#0 (ParallelGC)\" os_prio=0 tid=0x00000000032d8800 nid=0x3fbc runnable\n\n\"GC task thread#1 (ParallelGC)\" os_prio=0 tid=0x00000000032da000 nid=0x4174 runnable\n\n\"GC task thread#2 (ParallelGC)\" os_prio=0 tid=0x00000000032db800 nid=0x3028 runnable\n\n\"GC task thread#3 (ParallelGC)\" os_prio=0 tid=0x00000000032dd000 nid=0x25e8 runnable\n\n\"GC task thread#4 (ParallelGC)\" os_prio=0 tid=0x00000000032e0800 nid=0x3edc runnable\n\n\"GC task thread#5 (ParallelGC)\" os_prio=0 tid=0x00000000032e1800 nid=0x43f8 runnable\n\n\"GC task thread#6 (ParallelGC)\" os_prio=0 tid=0x00000000032e5000 nid=0x2678 runnable\n\n\"GC task thread#7 (ParallelGC)\" os_prio=0 tid=0x00000000032e6000 nid=0x1a8c runnable\n\n\"GC task thread#8 (ParallelGC)\" os_prio=0 tid=0x00000000032e7000 nid=0x3f30 runnable\n\n\"GC task thread#9 (ParallelGC)\" os_prio=0 tid=0x00000000032e8800 nid=0x24b0 runnable\n\n\"VM Periodic Task Thread\" os_prio=2 tid=0x000000001e77c800 nid=0x15c0 waiting on condition\n\nJNI global references: 316\n\n\nFound one Java-level deadlock:\n=============================\n\"2\":\n  waiting to lock monitor 0x000000001cf12688 (object 0x000000076be2a648, a org.zhenchao.jvm.DeadLock$A),\n  which is held by \"1\"\n\"1\":\n  waiting to lock monitor 0x000000001cf111e8 (object 0x000000076be2c9e8, a org.zhenchao.jvm.DeadLock$B),\n  which is held by \"2\"\n\nJava stack information for the threads listed above:\n===================================================\n\"2\":\n        at org.zhenchao.jvm.DeadLock.lambda$main$1(DeadLock.java:32)\n        - waiting to lock <0x000000076be2a648> (a org.zhenchao.jvm.DeadLock$A)\n        - locked <0x000000076be2c9e8> (a org.zhenchao.jvm.DeadLock$B)\n        at org.zhenchao.jvm.DeadLock$$Lambda$2/999966131.run(Unknown Source)\n        at java.lang.Thread.run(Thread.java:748)\n\"1\":\n        at org.zhenchao.jvm.DeadLock.lambda$main$0(DeadLock.java:23)\n        - waiting to lock <0x000000076be2c9e8> (a org.zhenchao.jvm.DeadLock$B)\n        - locked <0x000000076be2a648> (a org.zhenchao.jvm.DeadLock$A)\n        at org.zhenchao.jvm.DeadLock$$Lambda$1/2093631819.run(Unknown Source)\n        at java.lang.Thread.run(Thread.java:748)\n\nFound 1 deadlock.\n```\n\n由堆栈信息可以清楚的看到两个线程都在等待获取锁（处于 BLOCKED 状态），并形成了死锁状态。\n\n### 常用命令\n\n- `java -XX:+PrintFlagsFinal -version`：查看当前 JVM 的运行参数设置。\n- `jps -l`：查看 JVM 进程和对应的驱动类。\n- `jstat -gc <pid> <间隔时间>`：查看指定 JVM 进程的 GC 情况。\n- `jstack -l <pid> > <filename>`：生成指定 JVM 的栈内存快照转储文件。\n- `jmap -heap <pid>`：查看堆内存的使用情况，包括新生代（Eden、From 和 To）和老年代。\n- `jmap -histo <pid>`：查看堆内存中对象的统计信息，包括对象所属类全限定名、实例数、空间占用等。如果添加 live 后缀（`jmap -histo:live <pid>`）表示仅显示存活的对象，此时会手动触发一次 Full GC。\n- `jmap -dump, format=b, file=<filename>.hprof <pid>`：Dump 出指定 JVM 进程的堆内存快照转储，同样可以添加 live 后缀，表示只保留存活的对象，会触发一次 Full GC。\n\n### 参数调优\n\n任何时候希望为 JVM 设置启动参数之前，建议执行 `java -XX:+PrintFlagsFinal -version` 查看当前的 JVM 的版本，以及对应参数的默认值，确保目标参数是当前版本 JVM 所支持的，并且默认没有启用。示例：\n\n```bash\n$ java -XX:+PrintFlagsFinal -version\n[Global flags]\n     intx ActiveProcessorCount                      = -1                                  {product}\n    uintx AdaptiveSizeDecrementScaleFactor          = 4                                   {product}\n    uintx AdaptiveSizeMajorGCDecayTimeScale         = 10                                  {product}\n    uintx AdaptiveSizePausePolicy                   = 0                                   {product}\n    uintx AdaptiveSizePolicyCollectionCostMargin    = 50                                  {product}\n     intx CICompilerCount                          := 4                                   {product}\n```\n\n一些说明：\n\n- `=` 和 `:=` 的区别：冒号 `:=` 表示标志使用了非默认值，而 `:` 表示当前的值是这个版本 JVM 的默认值。\n- 一些标志的默认值在不同平台上可能不一样，通过最后一列可判定：\n  - product：表示该标志的默认设置在所有平台是统一的。\n  - pd product：表示该标志的默认值依赖于平台。\n  - manageable：表示标志的值可以在运行期间动态更改。\n  - C2 diagnostic：表示标志可以为编译器工程师提供诊断输出，以了解编译器如何运行。\n\n\n### 参考\n\n1. [Java 虚拟机规范（Java SE 8 版）](https://book.douban.com/subject/26418340/)\n2. [深入理解 java 虚拟机（第 2 版）](https://book.douban.com/subject/24722612/)\n3. [深入理解 java 虚拟机（第 3 版）](https://book.douban.com/subject/34907497/)\n4. [极客时间：深入拆解 java 虚拟机](https://time.geekbang.org/column/intro/108)\n5. [关键系统的JVM参数推荐(2018仲夏版)](https://mp.weixin.qq.com/s/FHY0MelBfmgdRpT4zWF9dQ)\n","tags":["JVM"],"categories":["java"]},{"title":"探秘 JVM：编译与优化","url":"/2016/12/12/jvm/compile-optimization/","content":"\n以 java 语言为例，JVM 针对 java 程序的优化可以发生在编译期和运行期，相应的优化操作分别发生在 javac 编译器在将 java 源程序编译成字节码期间，以及运行时即时编译器（JIT: Just In Time Compiler）将字节码编译成本地机器码期间。此外，还有一类编译器可以将源程序直接编译成与目标机器指令集相关的二进制代码，此类编译器称为提前编译器。运行期依赖于 JIT 的编译优化的主要目的在于提升程序的执行效率，而编译期优化的主要目的在于支持 java 语法糖，提升语言的易用性和编码效率。如果以字节码所处的位置作为参考线，那么编译期的编译可以称为前端编译，而即时编译和提前编译合起来则可以称为后端编译。<!-- more -->\n\n### 前端编译与优化\n\n编译期优化主要发生在 javac 命令将 java 源码编译成字节码期间，其主要目的在于支撑 java 语法糖，提升语言的易用性和编码效率。\n\n#### Javac 编译器\n\nJavac 编译器是 java 语言内置的编译器，采用 java 语言实现，其编译过程大致分为如下 4 个阶段：\n\n1. 初始化插入式注解处理器；\n2. 解析与填充符号表，包括词法解析、语法解析，以及填充符号表；\n3. 执行插入式注解处理器；\n4. 分析与字节码生成，包括：标注检查、数据流与控制流分析、解语法糖，以及生成字节码。\n\n执行步骤如下图所示：\n\n![image](/images/2016/jvm-javac-compiler.png)\n\n- __解析与填充符号表__\n\n解析过程主要包含词法分析和语法分析两个过程，由 `JavaCompiler#parseFiles` 方法实现：\n\n- __词法分析__ ：将源码的字符流转换成标记集合的过程，类比 NLP 中的分词，标记是编译过程的最小元素。该过程主要由 `com.sun.tools.javac.parser.Scanner` 类实现。\n- __语法分析__ ：由标记构造抽象语法树的过程，该过程在 `com.sun.tools.javac.parser.Parser` 类中实现，对应的抽象语法树则有类 `com.sun.tools.javac.tree.JCTree` 表示。\n\n经过这两个步骤之后，编译器基本不会再对源码文件进行操作，后续的操作都建立在抽象语法树上。\n\n完成了词法分析和语法分析之后，下一阶段是对符号（Symbol Table）表进行填充（位于 `JavaCompiler#enterTrees` 方法）。符号表是由一组符号地址和符号信息构成的数据结构，其中的信息在编译的不同阶段都会用到，填充符号表的过程由 `com.sun.tools.javac.comp.Enter` 类实现。\n\n- __应用插入式注解__\n\n插入式注解可以看作是一组编译器的插件，允许对抽象语法树中的任意元素执行读取、修改和添加操作。如果这些注解对语法树进行了修改，编译器需要回到解析与填充符号表阶段重新执行，直到所有插入式注解不再对语法树进行修改为止，每次循环称为一个轮次（Round），这也是为什么上述图中会有一个循环的原因。有了插入式注解，我们可以通过编写自己的代码来干涉编译器的行为，典型的例子就是 [Lombok](https://projectlombok.org/)。\n\n插入式注解的初始化过程在 `JavaCompiler#initProcessAnnotations` 方法中完成，而执行则是在 `JavaCompiler#processAnnotations` 方法中完成，该方法会判断是否有新的注解处理器需要执行，若有则通过 `JavacProcessingEnvironment#doProcessing` 方法生成一个新的 JavaCompiler 对象，对编译的后续步骤进行处理。\n\n- __语义分析与字节码生成__\n\n抽象语法树能够描述一个正确的源程序，但无法保证程序语义的正确性，而语义分析的主要目的就在于结合上下文对程序的相关性质进行检查，包括标注检查和数据及控制流分析两个步骤。下面的代码块对应语义分析和字节码生成的执行步骤：\n\n```java\ncase BY_TODO:\n    while (!todo.isEmpty())\n        generate( // 生成字节码\n                desugar(// 解语法糖\n                        flow(// 数据及控制流分析\n                                attribute(// 标注检查\n                                        todo.remove()))));\n```\n\n__标注检查__ 的内容主要包括如变量使用前是否声明，变量与赋值之间的数据类型是否匹配，以及常量折叠（比如将 `int a = 1 + 2` 折叠为为 `int a = 3`）等。 __数据与控制流分析__ 用于对程序的上下文执行更进一步的验证，与类加载时的数据与控制流分析的目的基本一致，但校验范围有所区别。\n\n语法糖（Syntactic Sugar）是这样一类语法，它对语言的编译结果和功能没有实质性的影响，但却能够让开发人员更加方便的使用语言，例如 java 语言中的泛型、变长参数、自动装箱与拆箱机制等。JVM 并不直接支持语法糖对应的语法，所以需要在编译阶段将其还原成基础语法结构，这个过程称为 __解语法糖__ 。\n\n__字节码生成__ 阶段不仅仅是把各个步骤生成的信息（语法树、符号表）转换成字节码，编译器还会进行少量的代码添加和转换工作。这一过程在 `com.sun.tools.javac.jvm.Gen` 类中完成，并由方法 `ClassWriter#writeClass` 方法输出字节码。\n\n至此，整个编译过程宣告结束。\n\n#### Java 语法糖\n\n语法糖是这样一类语法，它对语言的编译结果和功能没有实质性的影响，但却能够让开发人员更加方便的使用语言，提升编码效率和语言的严谨性，降低编码出错的机会。\n\n- __泛型与类型的擦除__\n\nJava 中的泛型并不是真正意义上的泛型，而是为了方便使用的一种语法糖实现，这也是 java 泛型被人所诟病的原因。Java 的泛型仅存在于源码层面，在将源码编译成字节码的过程中，泛型就会被擦除成为原生类型，可以理解为 Object 类型。不过，这里的擦除仅仅作用于方法 Code 属性中的字节码，实际上元数据中还是保留了泛型信息，这也是我们能够通过反射手段取得参数化类型的根本依据。\n\n- __自动装箱、拆箱与遍历循环__\n\n自动装箱和拆箱在编译之后被转换成了对应的包装（eg. `Integer#valueOf`）和还原（eg. `Integer#intValue`）方法，而遍历循环则还原成了迭代器的实现。\n\n除了上述介绍的语法糖之外，java 中还有很多语法糖，包括条件编译、内部类、枚举类、断言语句、数值字面量、对枚举和字符串的 switch 语法支持、try-with-resources，以及 java 8 新增的 lambda 表达式等。\n\n### 后端编译与优化\n\n后端编译主要包含即时编译和提前编译，其中即时编译会在程序运行期间依据环境和程序的运行状态选择性的将字节码编译生成机器码执行，而提前编译则是直接将源程序编译成平台相关的二进制指令。\n\n#### 即时编译器\n\n主流虚拟机（eg. HotSpot, J9）对于 java 程序一开始采用解释器解释执行，当发现某个方法或代码块被频繁调用时会将这些代码标记为热点代码，JIT 在运行时会将热点代码编译成机器相关的机器码，并执行各种层次的优化。运行期优化发生在将字节码编译成本地机器码期间，其主要目的在于提升程序的运行性能。\n\n##### 分层编译\n\n解释器和编译器各有优势，前者因为省去了编译的时间，程序可以具备较快的启动速度，同时占用更少的内存；后者因为将代码编译成本地机器码，所以具备更快的执行速度，但是需要额外的编译时间和内存开销。\n\n![image](/images/2016/jvm-interpreter-compiler-interaction.png)\n\n以 HotSpot 为例，采用了解释器与编译器共存的架构，如上图所示。在 JDK 10 之前，HotSpot 内置了 1 款解释器和 2 款即时编译器，其中即时编译器分为：Client 编译器（简称 C1）和 Server 编译器（简称 C2）。在 JDK 10 之后增加了 Graal 编译器，其目的在于取代 C2 编译器，不过目前 Graal 还处于实验阶段。\n\n在分层编译（Tiered Compilation）工作模式出现之前，HotSpot 虚拟机通常采用一个解释器搭配一个 JIT 的方式工作。我们可以在程序启动时通过 `-client` 参数或 `-server` 参数来强制虚拟机所使用的 JIT 类型，前者使用 C1 编译器，具备较好的编译速度，后者使用 C2 编译器，具备较好的编译质量。\n\nHotSpot 虚拟机默认采用解释器与编译器混合运行的模式，可以通过 `java -version` 命令查看，如下所示：\n\n```bash\n$ java -version\njava version \"1.8.0_241\"\nJava(TM) SE Runtime Environment (build 1.8.0_241-b07)\nJava HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)  # 这里的 mixed mode 表示采用混合模式\n```\n\n我们也可以通过 `-Xint` 参数指定虚拟机仅运行于解释模式，这时 JIT 将完全不介入工作；或者通过 `-Xcomp` 参数指定虚拟机运行于编译模式，这时优先采用编译方式执行，只有当编译无法进行的情况下才会让解释器介入执行。\n\n前面已经介绍了解释器和编译器各有其优点，解释执行模式能够让程序具备较快的启动速度，但是编译模式执行能够让程序具备较快的执行速度，并且不同级别的编译器在编译速度和执行速度上是矛盾的。如何在解释执行和编译执行，以及不同级别编译器的编译速度和执行速度之间进行取舍，从而让程序能够兼顾启动速度和运行速度，HotSpot 的解决方案是引入分层编译机制，并在 JDK 7 的 server 模式中采用了默认开启（分层编译最早在 JDK 6 中引入，但是需要通过 `-XX:+TieredCompilation` 参数来手动开启）。分层编译机制具体分层细节如下：\n\n- __第 0 层__ ：程序纯解释执行，解释器不开启性能监控。\n- __第 1 层__ ：使用 C1 编译器将字节码编译成本地机器码执行，并进行简单、可靠的稳定优化，但不开启性能监控。\n- __第 2 层__ ：仍然使用 C1 编译器执行，但开启方法及回边次数统计等有限的性能监控。\n- __第 3 层__ ：仍然使用 C1 编译器执行，但开启全部的性能监控，如分支跳转、虚方法调用版本等。\n- __第 4 层__ ：使用 C2 编译器将字节码编译成本地机器码执行，相对于 C1 而言会启动更多编译耗时更长的优化，甚至是一些不可靠的激进优化。\n\n上述分层策略并不是固定不变的，可以依据运行参数和版本来调整分层数量。\n\n##### 热点探测\n\nJIT 会对热点代码执行即时编译，这里的热点代码主要包含 __被多次调用的方法__ 和 __被多次执行的循环体__ 两类，但不管是哪种类型的热点代码，即使编译的单位都是针对整个方法体，而不是单独的循环体。\n\n针对被多次执行的循环体进行优化的原因主要在于一些方法虽然被调用的次数不多，但是因为方法中存在较多的循环，导致循环部分代码被多次执行，这样的代码也是热点代码。对多次被调用的方法执行即时编译属于 JIT 的标准编译方式，而针对被多次执行的循环体的即时编译则发生在方法执行过程中，形象称之为 __栈上替换（OSR: On Stack Replacement）__ 。\n\n判断一段代码是否属于热点代码称之为 __热点探测（Hot Spot Code Detection）__ ，判断的方式主要分为两种：\n\n1. __基于采样的热点探测__ ：JVM 周期性检查各个线程的调用栈顶，如果发现某个方法经常出现在栈顶则视为热点方法，该策略实现简单且高效，但是存在一定的误判率。\n2. __基于计数器的热点探测__ ：JVM 会为每个方法（或代码块）设置一个计数器以统计方法的执行次数，超过一定的阈值则视为热点方法，该策略实现相对复杂，但是统计结果更加精确严谨。\n\nHotSpot 虚拟机采用基于计数器的热点探测策略，而 J9 虚拟机则采用基于采样的热点探测策略。\n\n以 HotSpot 为例，它为每个方法设置了两个计数器：__方法调用计数器__ 和 __回边计数器__ 。\n\n![image](/images/2016/jvm-hotspot-code-detection.png)\n\n上图分别展示了两种基于两种计数器的热点探测流程。\n\n对于 __方法调用计数器__ 而言，当一个方法被调用时会先去检查这个方法是否有对应已编译的版本，如果没有则将方法调用计数器的值加 1；然后判断方法调用计数器和回边调用计数器之和是否超过阈值，如果超过则向即时编译器提交编译请求。默认执行引擎不会阻塞等待编译完成（可以通过 `-XX:BackgroundCompilation` 参数调整），而是继续以解释器的方式执行该方法，编译完成后会更新相应方法的入口地址，当下一次调用该方法时就会切换成编译后的版本。\n\n方法计数器触发编译的阈值默认在客户端模式下是 1500 次，而在服务端模式下是 10000 次，可以通过 `-XX:CompileThreshold` 参数进行调整。计数器在依据计数器值判定是否需要触发编译时，默认调用的并非是计数器计数的绝对值，而是一个相对的值，即一段时间内方法被调用的次数。当超过这个时间段，方法的调用次数仍然没有达到阈值，则方法调用计数会将计数值减半，这一机制称之为 __热度衰减（Counter Decay）__ ，这个时间跨度也被称为 __半衰周期（Counter Half Life Time）__ 。可以通过参数（`-XX:-UseCounterDecay`）关闭热度衰减策略，以及设定半衰周期（`-XX:CounterHalfLifeTime`），当关闭热度衰减之后，只要时间足够长，绝大部分方法都会被编译成本地代码。\n\n对于 __回边计数器__ 而言，当遇到一条回边指令（即字节码中控制流向后跳转的指令）时，会先检查需要执行的代码片段是否有对应已编译的版本，如果没有则将回边计数器的值加 1；然后判断方法调用计数器和回边调用计数器之和是否超过阈值，如果超过则发起一个 OSR 编译请求，并将回调计数器的值降低一些。默认情况下执行引擎同样不会等待编译完成，而是继续以解释器的方式执行该方法，编译完成后会更新相应方法的入口地址，当下一次调用该方法时就会切换成编译后的版本。\n\n回边计数器虽然提供了 `-XX:CompileThreshold` 和 `-XX:BackEdgeThreshold` 两个参数用于对阈值进行控制，但是当前 HotSpot 虚拟机并未实现这两个参数，而是通过 `-XX:OnStackReplacePercentage` 参数间接控制该计数器的阈值。\n\n不同于方法调用计数器，回边计数器并没有热度衰减机制。\n\n#### 提前编译器\n\n即时编译虽然极大提升了 JVM 对于程序的执行效率，但是不能忽视其所带来的运行时资源消耗，所以就衍生出了一种想法，在程序启动之前先提前编译成平台相关的机器码，对应的编译器就是提前编译器。\n\n提前编译在 java 客户端和服务端应用领域一直不温不火，但却在 Android 领域大放异彩。Android 在 2013 年推出的基于提前编译器 ART(Android Runtime) 虚拟机，一经推出就马上干掉了之前基于即时编译的 Dalvik 虚拟机。\n\n目前，提前编译主要分为两种思路：\n\n1. 与传统 C/C++ 编译器类似，在程序运行之前将其编译成平台相关机器码。\n2. 讲之前即时编译的编译结果保存下来，供下次运行时直接使用，以减少再次即时编译的时间，俗称即时编译缓存（JIT Caching）。\n\n#### 即时编译优化技术\n\n##### 方法内联\n\n方法内联优化机制的本质就是将目标方法的代码“复制”到发起调用的方法之中，避免产生真实的方法调用。方法内联是编译器最重要的优化手段，为其它优化手段建立了良好的基础。\n\n然而，java 语言中默认的实例方法都是虚方法，所以无法简单的进行内联，需要借助 __类型继承关系分析（CHA: Class Hierarchy Analysis）__ 技术。CHA 是一种基于整个应用程序的类型分析技术，用于确定在目前已加载的类中，某个接口是否有多于一种的实现，某个类是否存在子类，子类是否覆盖实现了父类的某个虚方法等信息，从而为编译器执行方法内联提供分析依据。\n\n##### 逃逸分析\n\n逃逸分析（Escape Analysis）与 CHA 一样，同样是为其它优化策略提供分析依据，其基本原理是分析对象的动态作用域，从而判定一个对象是否发生逃逸，是方法逃逸还是线程逃逸。\n\n- __方法逃逸__ ：当一个对象在方法中被定义后，它可能被外部方法所引用，例如通过参数传递给其它方法。\n- __线程逃逸__ ：当一个对象在线程中被定义后，它可能被外部线程所访问，例如将对象赋值给其它线程中的实例变量。\n\n如果可以确定一个对象不会逃逸到方法或线程外，或者逃逸程度较低（`线程逃逸 > 方法逃逸 > 不逃逸`），则可以对这个对象变量进行一些高效的优化，比如：\n\n- __栈上分配（Stack Allocations）__ ：对象一般在堆上进行创建，这些对象可以被各个线程所共享，也是垃圾收集的主要目标。如果能够确定一个对象不会出现线程逃逸，就可以在栈上进行分配，这个对象的生命周期与栈帧相同（无需 GC），并且这部分对象的占比较大，所以栈上分配可以极大优化内存使用率和运行效率。栈上分配支持方法逃逸，但不支持线程逃逸。\n- __标量替换（Scalar Replacement）__ ：所谓标量是指一个数据已经无法再被分解（例如原始数据类型），与其对应的可以继续分解的数据称为聚合量，对象是典型的聚合量。标量替换就是将一个聚合量拆散，根据程序访问情况将其使用到的成员变量恢复成原始类型来访问。如果可以确定一个对象不会逃逸，且这个对象是可拆分的，程序执行时就可以不创建该对象，而改为直接创建若干个被这个方法使用到的成员变量进行代替，这样可以在栈上进行内存分配，同时为后续进一步优化创造条件。\n- __同步消除（Synchronization Elimination）__ ：多线程访问一个可以被共享的变量，为保证安全性需要同步加锁，如果可以确定一个对象不会逃逸，那么就不存在线程竞争关系，相应的加锁就是多余的，可以被消除。\n\n逃逸分析从 JDK 7 开始默认开启，虽然目前技术成熟度一般，但却是 JIT 编译优化的一个重要方向。\n\n##### 公共子表达式消除\n\n如果一个表达式 E 已经计算过了，并且到目前为止 E 中的所有变量的值均未发生变化，那么 E 的这次出现就成了公共子表达式，没有再次计算的必要，直接用之前的计算结果替换即可。\n\n如果这种优化仅限于程序基本块内，称之为 __局部公共子表达式消除__ ，如果涉及多个程序基本块，则称之为 __全局公共子表达式消除__ 。\n\n##### 数组边界检查消除\n\nJava 是动态安全的语言，对数组的读写不会像 C/C++ 那样裸指针操作。Java 在执行数组访问时会去检查当前指针是否越界，这样在保证运行安全的同时也造成了一定的负担，但是这种机制是不能去除的。\n\n实际上我们不需要每次去访问元素都检查一下是否越界，一些数组的访问越界在编译期即可确定，对于另外一些无法确定的可以借助 __隐式异常机制__ ，让原本边界判定操作变为在越界时主动触发异常，这样的优化措施可以在保证边界检查的前提下，又减少了非必要的边界判定。然而，异常处理过程是一个从用户态转到内核态，再转到用户态的过程，所以如果频繁发生异常的话，隐式异常处理机制也是一个比较耗时的过程，还不如边界检查，不过 JVM 会根据实际情况来选择是否采用隐式异常处理机制。\n\n### 参考\n\n1. [Java 虚拟机规范（Java SE 8 版）](https://book.douban.com/subject/26418340/)\n2. [深入理解 java 虚拟机（第 2 版）](https://book.douban.com/subject/24722612/)\n3. [深入理解 java 虚拟机（第 3 版）](https://book.douban.com/subject/34907497/)\n","tags":["JVM"],"categories":["java"]},{"title":"探秘 JVM：字节码执行引擎","url":"/2016/12/10/jvm/bytecode-engine/","content":"\n在不同的虚拟机实现中，执行引擎在执行 java 代码时可能会有 __解释执行__ （通过解释器执行）和 __编译执行__ （通过 JIT 生成本地代码执行）两种选择，也可能是二者兼备，但不管采用哪种方式执行，当我们调用一个方法的时候，都需要确定目标方法的具体版本，因为在面向对象语言中存在封装、继承和多态的三大特性，一个方法可能因为重载或覆盖而存在多个版本。\n\n方法调用阶段的主要工作是确定被调用方法的版本，而非执行具体的方法。字节码文件中存储的是方法的符号引用，只有将符号引用解析成直接引用（运行时方法的入口内存地址）才能确定具体调用的方法是谁，这个映射的过程有的发生在类加载的解析阶段，有的则发生在运行期间。<!-- more -->\n\n### 解析调用\n\n在类加载的解析阶段会将一部分能够确定的目标方法的符号引用转化为直接应用，这类方法需要同时满足以下两个条件：\n\n1. 方法在程序运行之前就有一个可确定的调用版本。\n2. 方法的调用版本在运行期间不会发生改变。\n\n这类方法称为 __编译期可知，运行期不变__ 的方法，满足上述条件的方法包括静态方法、私有方法、实例构造方法、父类方法，以及 final 方法 5 种。这些方法在类加载的解析阶段就会将符号引用解析成直接引用，也称为 __非虚方法__ ，除此之外的方法称为 __虚方法__ 。\n\nJVM 中提供了 5 条方法调用字节码指令：\n\n1. invokestatic：调用静态方法。\n2. invokespecial：调用构造方法、私有方法，以及父类方法。\n3. invokevirtual：调用所有的虚方法。\n4. invokeinterface：调用接口方法，在运行期间再确定具体实现该接口的对象。\n5. invokedynamic：动态语言支持，先在运行时动态解析出调用点限定符所引用的方法，然后再执行该方法。\n\n被 invokestatic 和 invokespecial 指令调用的方法都可以在解析阶段唯一确定方法版本，包括静态方法、私有方法、构造方法和父类方法。此外，final 方法虽然被 invokevirtual 指令调用，但是因为 final 方法不能被覆盖，所以也能够给在编译期唯一确定版本。\n\n### 分派调用\n\n解析操作发生在类加载阶段，是一个静态调用的过程，在编译期可以完全确定，而分派则可以是静态的，也可以是动态的。分派调用相对于解析调用要复杂很多，依据宗量（方法的接收者与方法的参数统称为方法的宗量）数可以进一步分为单分派和多分派。因此，分派调用按照组合理论可以细分为静态单分派、静态多分派、动态单分派，以及动态多分派。\n\n#### 静态分派\n\n假设我们定义了一个 Parent 类，并派生出一个子类 Child，那么以 `Parent person = new Child();` 为例，我们可以称 Parent 为变量 person 的 __静态类型__ ，称 Child 为变量 person 的 __实际类型__ 。\n\n所谓静态分派是指在编译期依据静态类型确定方法的执行版本，而动态分派则是在运行期依据实际类型确定方法的执行版本。\n\n静态分派发生在编译阶段，典型的应用场景就是方法重载， __JVM 在处理重载时依据的是参数的静态类型而非实际类型__ ，在编译阶段就已经依据变量的静态类型确定了方法的执行版本。示例：\n\n```java\nabstract class Parent { }\nclass Boy extends Parent { }\nclass Girl extends Parent { }\n\npublic void foo(Parent person) {\n    System.out.println(\"Hello, this is the parent.\");\n}\n\npublic void foo(Boy boy) {\n    System.out.println(\"Hello, this is the boy.\");\n}\n\npublic void foo(Girl girl) {\n    System.out.println(\"Hello, this is the girl.\");\n}\n\npublic static void main(String[] args) {\n    StaticDispatch dispatch = new StaticDispatch();\n    Parent boy = new Boy();\n    Parent girl = new Girl();\n    dispatch.foo(boy); // Hello, this is the parent.\n    dispatch.foo(girl); // Hello, this is the parent.\n}\n```\n\n上述示例中我们定义了类型为 Parent 的变量 boy 和 girl，我们称 Parent 为这两个变量的静态类型，这两个变量的实际类型分别是 Boy 和 Girl。由于 JVM 在处理重载时依据静态类型去判断方法的执行版本，所以这里的输出结果也就不难理解。如果我们将这两个变量的静态类型分别改为 Boy 和 Girl，那么输出也就变成了我们预期的样子，如下：\n\n```java\npublic static void main(String[] args) {\n    StaticDispatch dispatch = new StaticDispatch();\n    Boy boy = new Boy();\n    Girl girl = new Girl();\n    dispatch.foo(boy); // Hello, this is the boy.\n    dispatch.foo(girl); // Hello, this is the girl.\n}\n```\n\n#### 动态分派\n\n动态分派发生在运行阶段，典型的应用场景就是方法覆盖， __JVM 在处理方法覆盖时依据的是参数的实际类型而非静态类型__ 。示例：\n\n```java\nabstract class Parent {\n\n    public void sayHello() {\n        System.out.println(\"Hello, this is the parent.\");\n    }\n\n}\n\nclass Boy extends Parent {\n\n    @Override\n    public void sayHello() {\n        System.out.println(\"Hello, this is the boy.\");\n    }\n\n}\n\nclass Girl extends Parent {\n\n    @Override\n    public void sayHello() {\n        System.out.println(\"Hello, this is the girl.\");\n    }\n\n}\n\npublic static void main(String[] args) {\n    Parent boy = new Boy();\n    Parent girl = new Girl();\n    boy.sayHello(); // Hello, this is the boy.\n    girl.sayHello(); // Hello, this is the girl.\n}\n```\n\n下面的字节码对应源码中 main 方法调用 `sayHello()` 方法的两行代码：\n\n```bytecode\npublic static void main(java.lang.String[]);\n  descriptor: ([Ljava/lang/String;)V\n  flags: ACC_PUBLIC, ACC_STATIC\n  Code:\n    stack=3, locals=3, args_size=1\n       0: new           #2                  // class org/zhenchao/jvm/DynamicDispatch$Boy\n       3: dup\n       4: aconst_null\n       5: invokespecial #3                  // Method org/zhenchao/jvm/DynamicDispatch$Boy.\"<init>\":(Lorg/zhenchao/jvm/DynamicDispatch$1;)V\n       8: astore_1\n       9: new           #4                  // class org/zhenchao/jvm/DynamicDispatch$Girl\n      12: dup\n      13: aconst_null\n      14: invokespecial #5                  // Method org/zhenchao/jvm/DynamicDispatch$Girl.\"<init>\":(Lorg/zhenchao/jvm/DynamicDispatch$1;)V\n      17: astore_2\n      18: aload_1\n      19: invokevirtual #6                  // Method org/zhenchao/jvm/DynamicDispatch$Parent.sayHello:()V\n      22: aload_2\n      23: invokevirtual #6                  // Method org/zhenchao/jvm/DynamicDispatch$Parent.sayHello:()V\n      26: return\n    LineNumberTable:\n      line 36: 0\n      line 37: 9\n      line 38: 18\n      line 39: 22\n      line 40: 26\n    LocalVariableTable:\n      Start  Length  Slot  Name   Signature\n          0      27     0  args   [Ljava/lang/String;\n          9      18     1   boy   Lorg/zhenchao/jvm/DynamicDispatch$Parent;\n         18       9     2  girl   Lorg/zhenchao/jvm/DynamicDispatch$Parent;\n```\n\n通过字节码可以看到，覆盖是通过 invokevirtual 指令去确认方法的具体执行版本，该指令的执行过程如下：\n\n1. 查找操作数栈顶第一个元素所指向的对象的实际类型，记作 C；\n2. 如果 C 中存在与常量中的描述符和简单名称都相符的方法（即方法签名与当前目标调用的方法匹配），则执行访问权限校验，通过则返回这个方法的直接引用，否则抛 IllegalAccessError 异常；\n3. 如果不存在，则 __沿继承关系从下往上__ 依次遍历 C 的各个父类型，执行步骤 2 中的验证过程；\n4. 如果还是没有找到，则抛 AbstractMethodError 异常。\n\n简单来说，该指令的执行过程就是从当前对象所属类开始沿着继承链从下往上检索，过程中判断方法签名和访问权限，如果都匹配则说明检索成功。\n\n#### 单分派和多分派\n\n所谓的单分派和多分派是依据确定目标方法所需要的条件而定义的，分为两方面：方法签名和方法隶属的类。如果分派仅需一个条件就能唯一确定目标方法，那么称该分派为单分派，否则称为为多分派。\n\nJava 语言中的静态分派就是多分派，动态分派则是单分派，所以到目前为止（至少 JDK 13 之前），java 语言仍然是一门 __静态多分派，动态单分派__ 的语言。\n\n### 参考\n\n1. [Java 虚拟机规范（Java SE 8 版）](https://book.douban.com/subject/26418340/)\n2. [深入理解 java 虚拟机（第 2 版）](https://book.douban.com/subject/24722612/)\n3. [深入理解 java 虚拟机（第 3 版）](https://book.douban.com/subject/34907497/)\n","tags":["JVM"],"categories":["java"]},{"title":"探秘 JVM：类加载机制","url":"/2016/12/04/jvm/class-loading/","content":"\nJVM 的类加载机制描述了类数据从字节码文件加载到内存，并对其进行校验、解析、初始化，并最终成为能够直接被 JVM 使用的 java 数据类型的过程。\n\n类的整个生命周期可以分为  __加载、连接（验证、准备、解析）、初始化、使用、卸载__ 5 个阶段（加载、连接和初始化构成了类加载全过程），其中连接又可以细分为验证、准备、解析 3 个阶段。如下图所示：\n\n![image](/images/2016/jvm-class-loading.png)\n\n<!-- more -->\n\n上述步骤除解析步骤外，对于同一个类而言各个阶段的执行按照图示箭头所指的顺序逐步执行（相邻阶段的结束和开始不严格按照先后顺序，可能存在重叠）。解析阶段在一些情况下会在初始化之后进行，主要是为了支持 java 语言的动态绑定机制。\n\nJVM 规范并未明确触发加载机制的时机，但是规定执行初始化操作 __有且只有 6 种__ 情况（此前一定执行了对相应类的加载、验证，以及准备操作），如下：\n\n1. 遇到 `new`、`getstatic`、`putstatic`、`invokestatic` 指令，即 new 一个对象，亦或是读写类的静态字段（被 final 修饰的除外），亦或是调用一个类的静态方法。\n2. 利用反射机制对类进行反射调用。\n3. 当初始化一个类时，如果其父类没有被初始化，则先初始化其父类。\n4. 虚拟机启动时，用户需要指定一个驱动类（包含 main 方法的类），JVM 会先初始化这个类。\n5. 使用 JDK 7 的动态语言支持，如果一个 MethodHandle 实例最后的解析结果为 REF_getStatic、REF_putStatic、REF_invokeStatic 和 REF_newInvokeSpecial 四种类型的方法句柄，且该方法句柄对应的类没有进行过初始化。\n6. 如果一个类实现的接口中定义了 default 方法，当初始化该类时会触发初始化该接口。\n\n上述 6 种场景称为对一个类型的主动引用，除此之外所有的引用类型的方式都不会触发初始化操作，称为被动引用。\n\n__注意：__ 上述第 3 点对于接口而言并不适用，初始化一个接口或类并不要求其实现的接口全部都完成了初始化，只有在接口的非常量字段被使用时才会初始化该接口，这也是单独规定第 6 条的原因。\n\n关于对象的创建，这里再引申一点，在 java 中显式创建一个对象的方式主要分为 5 种，包括：new 一个对象；克隆机制；反射机制；反序列化机制；调用 `Unsafe#allocateInstance` 方法。\n\n除了显式创建对象外，虚拟机还会隐式的创建对象，比如创建类的 Class 引用，创建常量对象等。其中，克隆机制和反序列化机制通过直接复制已有的数据来初始化新建对象的实例字段；方法 `Unsafe#allocateInstance` 则没有初始化实例字段；而 new 语句和反射机制则是通过调用构造器来初始化实例字段。\n\n### 类加载过程\n\n加载、连接（验证、准备和解析），以及初始化构成了类加载的全过程。\n\n#### 加载\n\n当我们编写的代码被编译成字节码文件之后，虚拟机必须将其装载到内存中才能执行，而加载通俗的说就是将静态字节码二进制流文件加载到内存中的过程，该阶段主要完成 3 件事情：\n\n1. 通过一个类的全限定名获取该类的二进制字节流，具体从哪里获取没有要求，可以是文件系统、运行时生成，也可以来自网络等；\n2. 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构；\n3. 在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。\n\n__注意：__ 一个类的 Class 引用虽然是一个对象，但却存储在方法区，而不是堆内存中。\n\n在加载阶段，对于非数组类型而言，可以通过 JVM 内置的类加载器或用户自定义的类加载器去加载二进制字节流。对于数组类型而言，情况则有所不同， __数组类本身并不通过类加载器创建，而是由 JVM 直接在内存中动态构造__ ，但是数组类的元素类型还是需要由类加载器完成加载。\n\n#### 连接\n\n连接阶段可以进一步分为 __验证、准备，以及解析__ 三个阶段，下面就各阶段所执行的工作进行介绍。\n\n##### 验证\n\n验证阶段主要是验证字节码文件中包含的信息是否符合 JVM 规范，并且不会危害 JVM 运行安全，主要从文件格式、元数据、字节码，以及符号引用 4 个层面进行验证，如果验证不通过则抛出 VerifyError 异常。\n\n1. __文件格式验证__ ：该阶段主要验证字节流是否符合字节码文件的格式规范，同时保证能够被当前版本的虚拟机处理。这一阶段基于字节流进行验证，是整个验证过程的第一阶段，验证通过之后字节流才能够进入方法区中进行储存，后面三个阶段的验证都是基于方法区中的数据展开验证。\n2. __元数据验证__ ：该阶段主要是对字节码描述的信息进行语义分析，保证这些消息不违反 java 语言规范，主要是对类的元数据信息进行语义校验。\n3. __字节码验证__ ：该阶段主要是对类的方法实现进行校验分析，通过数据流分析和控制流分析以确定程序实现是合法且符合逻辑的。这一阶段的验证相当复杂，所以在 JDK 6 之后引入了 StackMapTable 属性，该属性描述了方法体所有基本块开始时本地变量表和操作数栈应有的状态，从而不再需要根据推导来验证这些状态的合法性，只要检查 StackMapTable 即可。\n4. __符号引用验证__ ：该阶段发生在虚拟机将符号引用转换化为直接引用的时候，这个动作发生在解析阶段，主要是校验引用自身和被引用方的正确性，以保证解析阶段能够正常执行。\n\n验证阶段相对比较耗时，是非常重要却不必要的过程，如果所运行的全部代码都已经被反复使用和验证过，那么可以使用 `-Xverify:none` 参数关闭大部分的类验证策略，从而缩短虚拟机的加载过程。\n\n##### 准备\n\n准备阶段主要是为类变量（即 static 变量）分配内存并初始化为相应的类型默认值。需要注意的是这里的操作只针对类变量，实例变量会在对象实例化时随着对象一起被分配到堆内存中。此外，这里的赋值是赋类型默认值，我们在代码中显式指定的初始值将会在调用类初始化方法 `<clinit>` 时（即初始化阶段）完成赋值，但是对于静态常量（被 static final 修饰）在这一步已经具备了真实值。\n\n```java\nprivate static int a = 123;\nprivate static final int b = 456;\nprivate static final int c = 123 + 456;\n```\n\n例如上述代码中的两个变量，在当前阶段 a 对应的值是 0，而 b 对应的值是 456，因为 a 是一个类变量，在本阶段会为其分配内存空间，并初始化为类型默认值（int 类型的默认值为 0），而真正赋值为 123 要等到初始化阶段。然而，b 就不一样，因为 b 是一个静态常量，编译器会在编译阶段就将其赋值为 456，对于 c 也同样如此，编译器在编译阶段就会将其赋值为 579。\n\n##### 解析\n\n解析阶段的目的是将常量池中的符号引用替换为直接引用，主要针对 __类或接口、字段、类方法、接口方法、方法类型、方法句柄，以及调用点限定符__ 7 类符号引用进行解析。\n\n__符号引用__ 以一组符号描述所引用的目标对象，可以是任何形式的字面量，只要使用时能够无歧义定位目标即可。符号引用与虚拟机实现内存布局无关，不同虚拟机接受的符号引用是相同的（因为符号引用是字节码层面定义的），引用的目标也不一定已经加载到内存。在字节码文件中以 CONSTANT_Class_info、CONSTANT_Fieldref_info，以及 CONSTANT_Methodref_info 等类型的常量形式出现。 __直接引用__ 可以是直接指向目标的指针、相对偏移量，或是一个能间接定位目标的句柄。直接引用与虚拟机内存布局相关，不同虚拟机翻译出来的直接引用一般不同，且其引用的目标一定存在于内存。\n\n- __类或接口符号引用解析__\n\n假设当前代码所处的类为 A，现在需要把符号引用 N 解析为对应的类或接口 B 的直接引用，整个解析过程如下：\n\n1. 如果 B 不是数组类型，那么虚拟机会将代表 N 的全限定名传递给 A 的类加载器去加载整个类 B，加载过程中由于元数据验证、字节码验证的需要，可能会触发其他的类加载操作，一旦出现任何异常则解析阶段失败；\n2. 如果 B 是数组类型，并且数组的元素类型为对象（`eg. [Ljava/lang/Integer`），则依据 1 中的规则加载数据元素类型，否则由虚拟机生成一个代表此数组维度和元素的数组对象；\n3. 验证 A 是否具备对 B 的访问权限，如果不具备则抛 IllegalAccessError 异常。\n\n- __字段解析__\n\n字段符号解析需要先对字段所属的类或接口的符号引用进行解析，假设这个类或接口是 B，那么字段的解析过程：\n\n1. 如果 B 本身包含的 __简单名称和字段描述符__ 都与目标相匹配的字段，则返回该字段的直接引用；\n2. 否则，如果 B 实现了接口，将会按照继承关系从下往上递归搜索各个接口，如果发现了相应字段则返回该字段的直接引用；\n3. 否则，如果具备父类（Object 类除外），则递归搜索父类，如果发现了相应字段则返回该字段的直接引用；\n4. 否则，查找失败，抛 NoSuchFieldError\n\n上述过程中对于查找到的字段会进行权限验证，如果不具备访问权限，则抛 IllegalAccessError。\n\n- __类方法解析__\n\n类方法解析也需要先对方法所属的类（不包括接口，类方法和接口方法的解析是分开的）的符号引用进行解析，假设这个类是 B，那么方法的解析过程：\n\n1. 在 B 中查找是否有 __简单名称和描述符__ 都与目标方法匹配的方法，如果有的话则返回该方法的直接引用；\n2. 否则，在父类中递归查找；\n3. 否则，在 B 实现的接口中递归查找，如果找到说明 B 是一个抽象类，抛 AbstractMethodError；\n4. 否则，查找失败，抛 NoSuchMethodError。\n\n上述过程中对于查找到的方法会进行权限验证，如果不具备访问权限则抛 IllegalAccessError。\n\n- __接口方法解析__\n\n接口方法也需要先对方法所属的接口（不包括类）的符号引用进行解析，假设这个接口是 B，那么方法的解析过程：\n\n1. 在 B 中查找是否有 __简单名称和描述符__ 都与目标方法匹配的方法，如果有的话则返回该方法的直接引用；\n2. 否则，在父接口中递归查找；\n3. 否则，查找失败，抛 NoSuchMethodError；\n\n接口方法的访问权限都是 public，所以不存在访问权限问题。\n\n#### 初始化\n\n初始化阶段主要是执行类或接口初始化方法 `<clinit>`，该方法由编译器自动收集类中所有类变量赋值动作和静态语句块（`static{...}`）中的语句合并而成（ __如果没有定义类变量和静态语句块，可以不用生成 `<clinit>` 方法__ ），组织顺序按照在源文件中定义的顺序，例如：\n\n```java\npublic class ClinitMethod {\n\n    private static int a = 1;\n\n    static {\n        b = 2;\n    }\n\n    private static int b;\n}\n```\n\n编译器会自动收集类变量赋值语句和静态代码块生成对应的类初始化方法，编译后的字节码如下：\n\n```java\nstatic {};\n  descriptor: ()V\n  flags: ACC_STATIC\n  Code:\n    stack=1, locals=0, args_size=0\n       0: iconst_1\n       1: putstatic     #2                  // Field a:I\n       4: iconst_2\n       5: putstatic     #3                  // Field b:I\n       8: return\n    LineNumberTable:\n      line 9: 0\n      line 12: 4\n      line 13: 8\n```\n\n类变量在 `<clinit>` 方法中的组织顺序遵循在代码中定义的顺序，需要注意的是 __在静态代码块中只能访问定义在静态语句块之前的变量，定义在之后的变量在静态语句块中可以赋值但不能访问__ 。如下：\n\n```java\npublic class ClinitMethod {\n\n    private static int a = 1;\n\n    static {\n        System.out.println(a); // OK\n        b = 2;\n        System.out.println(b); // ERROR\n        System.out.println(ClinitMethod.b); // OK\n    }\n\n    private static int b;\n}\n```\n\n类初始化方法 `<clinit>` 不同于构造方法 `<init>`，不需要在 `<clinit>` 中隐式或者显式调用父类的初始化方法，JVM 可以保证在执行子类的 `<clinit>` 方法之前完成对父类的 `<clinit>` 方法的执行， __因此父类的静态代码块要先于子类执行__ 。\n\n接口中虽然不允许使用静态代码块，但是仍然存在变量初始化的赋值操作，所以也会生成 `<clinit>` 方法。然而，与类不同的是， __接口中的 `<clinit>` 方法在执行时不要求父接口的 `<clinit>` 方法执行完毕，只有当使用到一个接口的变量时才会触发执行 `<clinit>` 方法__ 。\n\n方法 `<clinit>` 是线程安全的，可以将其视为一个同步的方法，当一个线程执行该方法时其它线程会被阻塞，所以一般不推荐在其中编写比较耗时的代码逻辑。\n\n### 类加载器\n\n类加载器（Class Loader）的作用是用来获取一个全限定类名对应的字节流，对于任何一个类都需要由加载它的类加载器和这个类本身一同确立其在 JVM 中的唯一性。下面的示例演示了对于同一个类，使用自定义类加载器和虚拟机内置类加载器加载之后的场景：\n\n```java\nClassLoader loader = new ClassLoader() {\n    @Override\n    public Class<?> loadClass(String name) throws ClassNotFoundException {\n        try {\n            InputStream is = this.getClass().getResourceAsStream(name.substring(name.lastIndexOf(\".\") + 1) + \".class\");\n            if (null == is) {\n                return super.loadClass(name);\n            }\n            byte[] buffer = new byte[is.available()];\n            is.read(buffer);\n            return super.defineClass(name, buffer, 0, buffer.length);\n        } catch (IOException e) {\n            throw new ClassNotFoundException(name, e);\n        }\n    }\n};\n\nfinal String className = ClassLoading.class.getName();\n\nObject obj1 = loader.loadClass(className).newInstance();\nSystem.out.println(obj1.getClass().getName());\n\nClassLoader classLoader = ClassLoader.getSystemClassLoader();\nObject obj2 = classLoader.loadClass(className).newInstance();\nObject obj3 = classLoader.loadClass(className).newInstance();\nSystem.out.println(\"obj2.class equals obj1.class: \" + obj2.getClass().equals(obj1.getClass())); // true\nSystem.out.println(\"obj2.class equals obj3.class: \" + obj2.getClass().equals(obj3.getClass())); // false\n```\n\n运行结果：\n\n```text\norg.zhenchao.jvm.ClassLoading\nobj2.class equals obj1.class: false\nobj2.class equals obj3.class: true\n```\n\n可以看到针对同一个类，使用自定义类加载器和应用程序类加载器加载得到的对象所指向的 Class 引用并不是同一个，也就是说在方法区中存在两个不同的 ClassLoading 类的 Class 引用。这证明了在 JVM 中唯一确定一个类，除了类的全限定名之外，还需要考虑加载该类的类加载器。\n\n#### 三层类加载器\n\n站在开发者的角度来看，JVM 类加载器可以分为三层进行组织，由上到下依次是启动类加载器（Bootstrap Class Loader）、扩展类加载器（Extension Class Loader），以及应用程序类加载器（Application Class Loader）。\n\n- __启动类加载器__\n\n启动类加载器负责加载 `${JAVA_HOME}/lib` 目录下，或者 __-Xbootclasspath__ 参数指定路径下，且能够被 JVM 识别的类库（仅按照文件名进行匹配）。该类加载器采用 C++ 语言编写，且无法被 java 程序直接引用，如果在编写自定义类加载器时希望指定启动类加载器为父类加载器，直接利用 null 值代替即可。\n\n- __扩展类加载器__\n\n扩展类加载器由 `sun.misc.Launcher$ExtClassLoader` 类实现，采用 java 语言编写，负责加载 `${JAVA_HOME}/lib/ext` 目录下，或者被 `java.ext.dirs` 系统变量所指定路径中的所有类库。\n\n- __应用程序类加载器__\n\n应用程序类加载器由 `sun.misc.Launcher$AppClassLoader` 类实现，采用 java 语言编写，上述例子中 `ClassLoader#getSystenClassLoader` 返回的即是该加载器（所以也叫系统类加载器），负责加载用户类路径（ClassPath）所指定的类库。\n\n#### 双亲委派机制\n\nJVM 中类加载器关系如下图所示，各个类加载器之间是一种父子关系，但是这种父子关系不是以继承来实现，而是使用了组合。\n\n![image](/images/2016/jvm-classloader.png)\n\n当一个类需要被加载时，JVM 采用双亲委派机制为该类寻找合适的类加载器。因为类加载器采用的是装饰模式，即子类加载器会包装父类加载器，所以子类的加载器的功能要比父类更强。除了系统内置的三个类加载器以外，还允许用户自定义类加载器。然而，我们不能保证所有用户都是善意的（比如用户自定义了一个 `java.lang.String` 类，如果能够覆盖 JDK 自带的 String 类则是一件非常危险的事情）。\n\n为了保证安全性，JVM 会尽量采用上层类加载器去加载类（因为上层加载器相对下层类加载器更加安全），所以当要加载一个类时，当前类加载器就会首先委托父类加载器尝试加载，如果父类加载器有能力加载则会继续向上委托，直到某一个类加载器的父类加载器不能加载时即开始执行真正加载操作。\n\n所有的类加载器中除了启动类加载器是由 C++ 语言实现外，其余的类加载器均由 java 语言实现。下面从源码层面来看一下双亲委派机制的实现：\n\n```java\nprotected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {\n    synchronized (this.getClassLoadingLock(name)) { // 同步加锁\n        // 校验输入的类名，并检查类是否已经被加载过\n        Class<?> c = this.findLoadedClass(name);\n        if (c == null) {\n            try {\n                if (parent != null) {\n                    // 委托给父类加载器进行加载\n                    c = parent.loadClass(name, false);\n                } else {\n                    // 父类加载器为 null，说明是启动类加载器\n                    c = this.findBootstrapClassOrNull(name);\n                }\n            } catch (ClassNotFoundException e) {\n                // ClassNotFoundException thrown if class not found from the non-null parent class loader\n            }\n\n            // 父类加载器加载失败，使用当前类加载器进行加载\n            if (c == null) {\n                // If still not found, then invoke findClass in order to find the class.\n                // 模板方法，由子类实现\n                c = this.findClass(name);\n            }\n        }\n\n        // 如果需要，执行解析操作\n        if (resolve) {\n            this.resolveClass(c);\n        }\n        return c;\n    }\n}\n```\n\n双亲委派机制的规则本来也不复杂，所以源码实现上也比较简单，具体的执行过程如上述代码注释。\n\n我们看到 `ClassLoader#loadClass` 方法在双亲加载失败时会执行 `ClassLoader#findClass` 逻辑，这是一个模板方法，也是我们自定义类加载器时推荐覆盖实现的方法。下面的示例自定义了一个类加载器 MyClassLoader：\n\n```java\npublic class MyClassLoader extends ClassLoader {\n\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        try {\n          byte[] bytes = FileUtils.readFileToByteArray(FileUtils.getFile(\n                  String.format(\"/home/work/bin/%s.class\", name.replaceAll(\"\\\\.\", File.separator))));\n            return super.defineClass(name, bytes, 0, bytes.length);\n        } catch (IOException e) {\n            throw new ClassNotFoundException(\"class not found : \" + name, e);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        MyClassLoader loader = new MyClassLoader();\n        Class clazz = loader.loadClass(\"org.zhenchao.jvm.User\");\n        Object obj = clazz.newInstance(); // 这里如果强转会抛 ClassNotFoundException，因为两个类对应的 Class 对象不一致\n        System.out.println(obj.getClass().getClassLoader().toString());\n    }\n\n}\n```\n\nMyClassLoader 的逻辑就是尝试加载我们指定的类。通过覆盖实现 `ClassLoader#findClass` 方法，我们定义了从本地文件系统加载 User 类字节码文件，并调用 `ClassLoader#defineClass` 方法由字节数组解析获取类的 Class 对象，从而完成了自定义类加载逻辑。\n\n这里我们加载的 class 文件位于 `/home/work/bin` 目录下，由前面的讲解我们知道启动类加载器会加载 `${JAVA_HOME}/lib` 路径或 `-Xbootstrapclasspath` 参数指定路径下的类；扩展类加载器会加载 `${JAVA_HOME}/lib/ext` 路径下或 `java.ext.dirs` 指定路径下的类；应用程序类加载器则会加载用户类路径（ClassPath）下的类。一般来说，即使我们自定义了类加载器加载 User 类，但是按照双亲委派原则该类还是会被应用程序类加载器所加载，因为 User 类位于用户类路径下。为了让 MyClassLoader 能够加载该类，这里特意将 User.class 放置在了一个系统类加载器找不到的地方，也就达到了我们的目的。\n\n双亲委派机制虽然是 JVM 默认的，但却不是强制的，所以我们可以破坏该机制。典型破坏双亲委派机制的应用场景就是 Tomcat 的类加载机制，这个我们留到后面再说。下面我们自定义一个 HackClassLoader 类加载器来破坏这一机制，我们需要做的就是覆盖 `ClassLoader#loadClass` 方法。HackClassLoader 类加载器的实现中会判定当前类的全限定名，如果是 `org.zhenchao.jvm` 包下面的类就采用 HackClassLoader 类加载器进行加载，否则继续执行双亲委派。具体实现如下：\n\n```java\npublic class HackClassLoader extends ClassLoader {\n\n    @Override\n    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {\n        if (null != name && name.startsWith(\"org.zhenchao.jvm\")) {\n            try {\n                File file = FileUtils.getFile(name.replaceAll(\"\\\\.\", File.separator) + \".class\");\n                byte[] bytes = FileUtils.readFileToByteArray(file);\n                return super.defineClass(name, bytes, 0, bytes.length);\n            } catch (IOException e) {\n                throw new ClassNotFoundException(\"class not found : \" + name, e);\n            }\n        }\n        return super.loadClass(name, resolve);\n    }\n\n    public static void main(String[] args) throws Exception {\n        Class clazz = Class.forName(\"org.zhenchao.jvm.User\", true, new HackClassLoader());\n        Object obj = clazz.newInstance();\n        System.out.println(obj.getClass().getClassLoader().toString());\n    }\n}\n```\n\n所以，通过覆盖实现 `ClassLoader#loadClass` 方法是很容易实现对于双亲委派机制的破坏的，有时候这种破坏是有意为之的，而有时候则是不小心造成的错误。为了避免错误的覆盖 `ClassLoader#loadClass` 方法而破坏双亲委派机制，JDK 提供了 `ClassLoader#findClass` 方法供我们选择。如果仅仅是希望改变虚拟机检索字节码文件的方式，则完全可以通过覆盖 `ClassLoader#findClass` 方法予以实现。\n\n最后我们一起来了解一下 Tomcat 对于双亲委派机制的“破坏”。Tomcat 为什么要自定义类加载器呢，我觉得主要有两方面的原因：\n\n1. 一个 tomcat 实例下可以运行多个 web 应用，需要保证应用之间的依赖不相互干扰。\n2. 提供自动装载的能力，当 `WEB-INF/classes` 或 `WEB-INF/lib` 目录下的类发生变化时，WEB 应用程序可以重新载入这些类，而不需要重启服务器。Tomcat 通过设置一个单独的线程来不断检查这些类的时间戳，以便能够及时载入。\n\n关于 tomcat 的类加载机制这里先不展开探讨，留待以后用专门的文章进行说明。\n\n### 类成员初始化顺序\n\n类成员初始化的基本原则是 __先静态，后非静态，先父类，后子类__ 。初始化顺序可以基本概括为：\n\n1. 父类静态变量 > 父类静态代码块；\n2. 子类静态变量 > 子类静态代码块；\n3. main 函数；\n4. 父类实例变量 > 父类构造代码块 > 父类构造方法；\n5. 子类实例变量 > 子类构造代码块 > 子类构造方法。\n\n下面定义了一个父类 Parent 和一个子类 Child：\n\n```java\npublic class Parent {\n\n    public static int spa = 11;\n\n    static {\n        System.out.println(\"parent static code block\");\n        System.out.println(\"spa = \" + spa);\n        System.out.println(\"spb = \" + Parent.spb);\n    }\n\n    public static int spb = 12;\n\n    static {\n        System.out.println(\"spb = \" + spb);\n    }\n\n    public int pa = 13;\n    public int pb = 14;\n\n    {\n        System.out.println(\"parent code block\");\n        System.out.println(\"pa = \" + pa);\n        System.out.println(\"pb = \" + pb);\n    }\n\n    public Parent() {\n        System.out.println(\"parent constructor\");\n        this.foo();\n    }\n\n    public void foo() {\n        System.out.println(\"parent foo\");\n        System.out.println(\"spa: \" + spa);\n        System.out.println(\"spb: \" + spb);\n        System.out.println(\"pa: \" + pa);\n        System.out.println(\"pb: \" + pb);\n    }\n}\n\npublic class Child extends Parent {\n\n    public static int sca = 21;\n\n    static {\n        System.out.println(\"child static code block\");\n        System.out.println(\"sca = \" + sca);\n        System.out.println(\"scb = \" + Child.scb);\n    }\n\n    public static int scb = 22;\n\n    static {\n        System.out.println(\"scb = \" + scb);\n    }\n\n    public int ca = 23;\n    public int cb = 24;\n\n    {\n        System.out.println(\"child code block\");\n        System.out.println(\"ca = \" + ca);\n        System.out.println(\"cb = \" + cb);\n    }\n\n    public Child() {\n        System.out.println(\"child constructor\");\n    }\n\n    public static void main(String[] args) {\n        System.out.println(\"main method\");\n        Child child = new Child();\n    }\n\n    @Override\n    public void foo() {\n        System.out.println(\"child foo\");\n        System.out.println(\"sca: \" + sca);\n        System.out.println(\"scb: \" + scb);\n        System.out.println(\"ca: \" + ca);\n        System.out.println(\"cb: \" + cb);\n    }\n\n}\n```\n\n以上述代码为例，类中成员的初始化顺序如下：\n\n1. 当首次创建某个类对象的时候，或者该类的静态字段或静态方法首次被访问时，JVM 需要查找该类的路径以定位该类的字节码文件；\n2. 载入父类的字节码文件（创建对应的 Class 对象），初始化父类 Parent 中的静态字段，同时执行父类中静态代码块 `static{...}`，顺序按照从上到下执行；\n3. 载入子类的字节码文件（创建对应的 Class 对象），初始化子类 Child 中的静态字段，同时执行子类中的静态代码块 `static{...}`，顺序按照从上到下执行；\n4. 进入 main 方法（因为接下去要创建对象，而 main 方法是入口，这也是为什么 main 需要用 static 修饰）；\n5. 使用 new 操作符创建对象，首先在堆上为待创建的对象分配足够的存储空间，这块存储空间会被清零，所以自动将类中所有字段设置成对应的类型默认值；\n6. 对 Parent 类中的非静态字段和构造代码块按照从上到下进行初始化（执行构造代码块 `{...}`，将属性设为用户指定的值），每次创建子类对象都会执行一次父类的非静态字段和构造代码块；\n7. 执行 Parent 类的构造方法，这里到底执行父类的哪一个构造方法取决于子类的具体调用；\n8. 对 Child 类中的非静态字段和构造代码块按照从上到下进行初始化（执行构造代码块 `{...}`，将属性设为用户指定的值）；\n9. 执行 Child 类的构造方法。\n\n需要注意的几点：\n\n1. 静态字段和代码块的初始化只在类首次被加载时执行一次，静态字段的初始化不必担心非法向前引用，因为会导致编译报错。\n2. 如果某个方法被子类覆盖了，那么在父类的构造方法中调用这个方法的时候会去调用子类中的这个方法，如果这个方法使用了子类的成员变量，由于这时子类的成员变量还未来得及初始化，就会出现向前引用的问题。所以不要在构造方法中调用可以让子类覆盖的方法，以避免发生向前引用，在构造方法中应该只调用声明为 private 或者 final 的方法。\n3. 如果一个 final 字段在声明的时候进行了初始化，且初始化值是常量或常量表达式，那么该字段在所属类字节码文件还未被加载的时候就已经完成了初始化，如果赋值延迟到构造方法中则另当别论。\n\n### 参考\n\n1. [Java 虚拟机规范（Java SE 8 版）](https://book.douban.com/subject/26418340/)\n2. [深入理解 java 虚拟机（第 2 版）](https://book.douban.com/subject/24722612/)\n3. [深入理解 java 虚拟机（第 3 版）](https://book.douban.com/subject/34907497/)\n","tags":["JVM"],"categories":["java"]},{"title":"探秘 JVM：字节码文件结构与指令","url":"/2016/10/30/jvm/class-file-format/","content":"\nClass 文件（也叫字节码文件）与 JVM 一起支撑着 java 程序的跨平台运行，虽然两者目前主要服务于 java 语言，但是其最初的设计是为编程语言构建一个跨平台的基础运行环境，任何语言只要可以被编译为字节码文件，就可以依托于这一套基础运行环境，实现平台无关性。\n\n### 字节码文件结构\n\n字节码文件是一组以 8 位字节为基础单位的二进制流，各个数据项目（见下图）严格按照顺序紧凑排列，中间没有分隔符，当遇到需要占用 8 位字节以上空间的数据项时，则按照 __高位优先__ 的方式分割成若干个 8 位字节进行存储。<!-- more -->\n\n![image](/images/2016/jvm-class-file-format.jpg)\n\n字节码文件主要包含两种数据类型：\n\n1. __无符号数__ ：无符号数属于基本数据类型，用于描述数字、索引引用、数量值，以及按照 UTF-8 编码的字符串，以 u1、u2、u4、u8 分表代表 1 个字节、2 个字节、4 个字节和 8 个字节的无符号数。\n2. __表__ ：通常由多个无符号数或其它表作为数据项构成复合数据类型，一般以 `_info` 结尾，用于描述具有层次关系的复合机构的数据。\n\n#### 文件类型与版本\n\n字节码文件作为一种文件类型，和普通文件类型一样，也是通过在字节流最开始设置标志位来表示当前文件为字节码类型文件，标志位的值为： __0xCAFEBABE__ 。如下所示，类型标志位占用前 4 个字节，第 5 和 6 两个字节表示 __次版本号（Minor Version）__ ，第 7 和 8 两个字节表示 __主版本号（Major Version）__ 。示例中的次版本号是 0，主版本号是 `0x0034`，对应十进制是 52，也就是 java1.8 版本，通常 jdk 版本过低导致编译出错时，编译器会打印出需要的 jdk 版本信息就是这里对应的十进制数字。\n\n```text\n编号：0102 0304 0506 0708 0910 1112 1314 1516\n字节：CAFE BABE 0000 0034 0014 0a00 0300 1107\n```\n\n除了查看字节码文件的字节流，我们还可以通过 `javap -verbose <class file>` 来查看一个字节码文件的结构，相对于字节流更加直观。\n\n#### 常量池\n\n常量池挨着版本信息，主要用于存放字面量和符号引用，其大小通常是不固定的，所以在常量池的最开始需要设置一个 u2 类型的数据（即 constant_pool_count），以表示常量池的大小。需要注意的一点是， __这个容量值的计数是从 1 开始的，而 0 则作为一个特殊值，用于某些指向常量池的索引在特定情况下需要表达“不引用任何常量池项目”的含义__ 。\n\nJava 截止目前（JDK 13）共定义了 17 种常量池表类型（如下表所示），这些类型的共同点就是在表开始的第一位定义了一个 u1 类型的标志位（tag），用于表示当前具体的常量类型。\n\n类型 | 标志 | 描述\n--- | --- | ---\nCONSTANT_Utf8_info | 1 | UTF-8 编码的字符串\nCONSTANT_Integer_info | 3 | 整型字面量\nCONSTANT_Float_info | 4 | 浮点型字面量\nCONSTANT_Long_info | 5 | 长整型字面量\nCONSTANT_Double_info | 6 | 双精度浮点型字面量\nCONSTANT_Class_info | 7 | 类或接口的符号引用\nCONSTANT_String_info | 8 | 字符串类型字面量\nCONSTANT_Filedref_info | 9 | 字段的符号引用\nCONSTANT_Methodref_info | 10 | 类中方法的符号引用\nCONSTANT_InterfaceMethodref_info | 11 | 接口中方法的符号引用\nCONSTANT_NameAndType_info | 12 | 字段或方法的部分符号引用\nCONSTANT_MethodHandle_info | 15 | 方法句柄\nCONSTANT_MethodType_info | 16 | 方法类型\nCONSTANT_Dynamic_info | 17 | 动态计算常量\nCONSTANT_InvokeDynamic_info | 18 | 动态方法调用点\nCONSTANT_Module_info | 19 | 模块\nCONSTANT_Package_info | 20 | 模块中开放或者导出的包\n\n详细结构总表：\n\n![image](/images/2016/jvm-constant-pool-type.jpg)\n\n#### 访问标志位\n\n访问标志位用于标识类或接口的访问信息，占据一个 u2，可用的标志位有 16 个，当前只定义了 9 个，具体如下：\n\n名称 | 标志位 | 说明\n--- | --- | ---\nACC_PUBLIC | 0x0001 | 是否是 public 类型\nACC_FINAL | 0x0010 | 是否被声明为 final\nACC_SUPER | 0x0020 | 是否允许使用 invokespecial 字节码指令的新语义， invokespecial 在 jdk1.0.2 语义发生过改变，所以需要标识使用的是新语义还是旧语义\nACC_INTERFACE | 0x0200 | 标识接口\nACC_ABSTRACT | 0x0400 | 对于接口和抽象类而言值为 true\nACC_SYNTHETIC | 0x1000 | 标识当前类不是由用户代码产生的\nACC_ANNOTATION | 0x2000 | 标识注解\nACC_ENUM | 0x4000 | 标识枚举\nACC_MODULE | 0x8000 | 标识模块\n\n#### 索引\n\n索引包含类索引（this_class）、父类索引（super_class），以及接口索引集合（interfaces），这三项联合起来确定类的继承关系。\n\n__类索引__ 用于确定类的全限定名，占用一个 u2，指向一个类型为 `CONSTANT_Class_info` 的类描述符常量，据此可以找到定义在 `CONSTANT_Utf8_info` 类型常量中的全限定名字符串。\n\n__父类索引__ 用于确定当前类的父类的全限定名，由于 java 不允许多重继承，且对象默认继承 Object 类，所以除了 Object 类外，所有的其它类都有父类索引。\n\n父类索引占用一个 u2，指向一个类型为 `CONSTANT_Class_info` 的类描述符常量，据此可以找到定义在 `CONSTANT_Utf8_info` 类型常量中的全限定名字符串。\n\n__接口索引集合__ 用于描述一个类实现了哪些接口，按照在 implements 关键字后面的组织顺序在字节码文件中依次排列。接口索引是一组 u2 类型数据的集合，并在最前面设置一个 u2 类型的接口计数器（interfaces_count），用于记录实现接口的数目。\n\n#### 字段表集合\n\n字段表用于描述接口或者类中声明的变量（包括类变量和实例变量，但不包括局部变量），不包含从父类或父接口继承而来的字段。字段表的格式如下：\n\n类型 | 名称 | 数量 | 说明\n--- | --- | --- | ---\nu2 | access_flags | 1 | 访问标识符，参考字段访问标识符表\nu2 | name_index | 1 | 对于常量池项的引用，代表字段的简单名称\nu2 | descriptor_index | 1 | 对于常量池项的引用，代表字段的描述符\nu2 | arrtibutes_count | 1 | 属性个数\nattribute_info | attributes | attributes_count | 属性表\n\n- __字段访问标识符表__\n\n标志名称 | 标志值 | 说明\n--- | --- | ---\nACC_PUBLIC | 0x0001 | public\nACC_PRIVATE | 0x0002 | private\nACC_PROTECTED | 0x0004 | protected\nACC_STATIC | 0x0008 | static\nACC_FINAL | 0x0010 | final\nACC_VOLATILE | 0x0040 | volatile\nACC_TRANSIENT | 0x0080 | transient\nACC_SYNTHETIC | 0x1000 | 是否由编译器自动生成\nACC_ENUM | 0x4000 | enum\n\n- __方法和字段描述符__\n\n描述符的作用在于用来描述字段的 __数据类型__ 、__方法的参数列表（数量、类型、顺序）__ ，以及 __返回值__ 。依据规则，基本数据类型和 void 都用一个大写字母表示（具体如下），而对象类型则用字符 L 加对象的全限定名来表示。\n\n- B：表示 byte\n- C：表示 char\n- D：表示 double\n- F：表示 float\n- I：表示 int\n- J：表示 long，因为 L 表示对象\n- S：表示 short\n- Z：表示 boolean\n- V：表示 void\n- L：表示对象，包括所有基本类型的包装类型，比如 Ljava/lang/Object\n\n对于数组类型，每一维度都用一个前置的 `[` 字符来描述，比如二维数组 `String[][]` 表示成 `[[Ljava.lang.String;`，一维整型数组 `int[]` 表示成 `[I`。\n\n对于方法的描述，则按照 __先参数列表，后返回值__ 的原则，所有的参数按照定义的顺序放在 `()` 内，比如：\n\n```text\nvoid method() -> ()V\nString method() -> ()Ljava.lang.String;\nint method(char[] a, int b, int c, double d) -> ([CIID)I\n```\n\n#### 方法表集合\n\nClass 文件存储格式对于方法的描述几乎与属性完全一致，同样主要包含访问标志（access_flags）、名称索引（name_index）、描述符索引（descriptor_index），以及属性集合（attributes）等，如下表所示：\n\n类型 | 名称 | 数量 | 说明\n--- | --- | --- | ---\nu2 | access_flags | 1 | 访问标识符，参考方法访问标识符表\nu2 | name_index | 1 | 对于常量池项的引用，代表方法的简单名称\nu2 | descriptor_index | 1 | 对于常量池项的引用，代表方法的描述符\nu2 | arrtibutes_count | 1 | 属性个数\nattribute_info | attributes | attributes_count | 属性表\n\n- __方法访问标识符表__\n\n标志名称 | 标志值 | 说明\n--- | --- | ---\nACC_PUBLIC | 0x0001 | public\nACC_PRIVATE | 0x0002 | private\nACC_PROTECTED | 0x0004 | protected\nACC_STATIC | 0x0008 | static\nACC_FINAL | 0x0010 | final\nACC_SYNCHRONIZED | 0x0020 | synchronized\nACC_BRIDGE | 0x0040 | 是否是由编译器生成的桥接方法\nACC_VARARGS | 0x0080 | 是否接受可变参数\nACC_NATIVE | 0x0100 | native\nACC_ABSTRACT | 0x0400 | abstract\nACC_STRICT | 0x0800 | strictfp\nACC_SYNTHETIC | 0x1000 | 是否由编译器自生成\n\n对于方法体而言，在经过编译成字节码指令之后存放在属性表的一个名为 Code 的属性中。下面的示例是一个构造方法的字节码（javap 指令默认不显示 private 方法，需要添加 `-p` 参数）：\n```java\npublic org.zhenchao.jvm.ClassFormat();\ndescriptor: ()V\nflags: ACC_PUBLIC\nCode:\n  stack=2, locals=1, args_size=1\n     0: aload_0\n     1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n     4: aload_0\n     5: ldc           #2                  // String any\n     7: putfield      #3                  // Field instanceVariable:Ljava/lang/String;\n    10: return\n  LineNumberTable:\n    line 11: 0\n    line 19: 4\n  LocalVariableTable:\n    Start  Length  Slot  Name   Signature\n        0      11     0  this   Lorg/zhenchao/jvm/ClassFormat;\n```\n\n在 java 程序中，方法的重载条件是方法名相同，但是参数签名不同（类型、个数，以及顺序），如果仅仅是返回值不同则不能视为重载。然而，对应到字节码文件则范围则更大， 也就是说如果两个方法的名称和参数签名相同，但是返回值不同，同样可以共存于同一个字节码文件中。这也为一些其他运行在 JVM 上的语言实现有别于 java 语言的特性留出了发挥空间。\n\n#### 属性表集合\n\n在 Class 文件、字段表，以及方法表中都可以携带自己的属性表集合，各属性表不要求严格顺序，只要不与已有的属性名重复即可，JVM 针对不能识别的属性在运行时会选择忽略。截止 JDK 12，预定义的属性共有 29 项，如下表所示：\n\n属性 | 作用域 | 描述\n--- | --- | ---\nCode | 方法表 | 用于记录 java 方法体编译后的字节码\nConstantValue | 字段表 | 记录由 final 关键字定义的常量值\nDeprecated | 类 / 方法表 / 字段表 | deprecated 标识\nExceptions | 方法表 |  方法异常列表\nEnclosingMethod | 类文件 | 用于标识类所属的外围方法，只有当该类是局部类或匿名类时才会拥有此属性\nInnerClasses | 类文件 | 内部类列表\nLineNumberTable | Code 属性 | 源码中行号与字节码指令的映射关系\nLocalVariableTable | Code 属性 | 方法的局部变量描述\nLocalVariableTypeTable | 类 | 使用特征签名代替描述符，以支持在引入泛型语法后能够描述泛型参数化类型，JDK 5 新增\nStackMapTable | Code 属性 | 服务于类型检查验证器（Type Checker），用于检查和处理目标方法的局部变量和操作数栈所需要的的类型是否匹配，JDK 6 新增\nSignature | 类 / 方法表 / 字段表 | 由于 java 的泛型采用擦除法实现，为了避免擦除后导致签名混乱，需要使用此属性记录泛型信息，JDK 5 新增\nSourceFile | 类文件 | 记录源文件名称\nSourceDebugExtension | 类文件 | 用于存储额外的调试信息，JDK 5 新增\nSynthetic | 类 / 方法表 / 字段表 | 标识方法或字段为编译期自动生成的\nRuntimeVisibleAnnotations | 类 / 方法表 / 字段表 | 用于指明哪些注解是运行时可见的，JDK 5 新增\nRuntimeInvisibleAnnotations | 类 / 方法表 / 字段表 | 用于指明哪些注解是运行时不可见的，JDK 5 新增\nRuntimeVisibleParameterAnnotations | 方法表 | 用于指明哪些方法参数注解是运行时可见的，JDK 5 新增\nRuntimeInvisibleParameterAnnotations | 方法表 | 用于指明哪些方法参数注解是运行时不可见的，JDK 5 新增\nAnnotationDefault | 方法表 | 记录注解类元素的默认值，JDK 5 新增\nBootstrapMethods | 类文件 | 用于保存 invokedynamic 指令引用的引导方法限定符，JDK 7 新增\nRuntimeVisibleTypeAnnotations | 类 / 方法表 / 字段表 / Code 属性 | 为实现 JSR 308 中新增的类型注解提供支持，用于指明哪些类注解是运行时可见的，JDK 8 新增\nRuntimeInvisibleTypeAnnotations | 类 / 方法表 / 字段表 / Code 属性 | 为实现 JSR 308 中新增的类型注解提供支持，用于指明哪些类注解是运行时不可见的，JDK 8 新增\nMethodParameters | 方法表 | 用于支持将方法名称编译进 Class 文件（编译时添加 `-parameters` 参数），以在运行时获取，JDK 8 新增\nModule | 类 | 用于记录一个 Module 的名称和相关信息，JDK 9 新增\nModulePackages | 类 | 用于记录一个模块中所有被 exports 或 opens 的包，JDK 9 新增\nModuleMainClass | 类 | 用于指定一个模块的主类，JDK 9 新增\nNestHost | 类 | 用于支持嵌套类的反射和访问控制 API，一个内部类可以通过该属性获取自己的宿主类，JDK 11 新增\nNestMembers | 类 | 用于支持嵌套类的反射和访问控制 API，一个内部类可以通过该属性获取自己有哪些内部类，JDK 11 新增\n\n下面来重点来看一下 Code 属性。对于存在方法体的 java 方法，方法体部分经过 javac 编译之后变为字节码存储在方法表的 Code 属性中，该属性的结构如下：\n\n名称 | 类型 | 数量 | 说明\n--- | --- | --- | ---\nattribute_name_index | u2 | 1 | 固定为 Code，代表属性名\nattribute_length | u4 | 1 | 属性的长度\nmax_stack | u2 | 1 | 代表操作数栈的最大深度，JVM 依据该值分配栈帧\nmax_locals | u2 | 1 | 代表局部变量表所需的存储空间，单位是 Slot\ncode_length | u4 | 1 | 字节码指令长度，实际中最大只使用了 u2 的空间，也就是说 __JVM 限制一个方法最大不允许超过 65535 条字节码指令__ ，否则拒绝编译\ncode | u1 | code_length | 存储方法体对应的字节码指令\nexception_table_length | u2 | 1 | 异常表长度\nexception_table | exception_info | exception_table_length | 异常表\nattributes_count | u2 | 1 | 属性表长度\nattributes | attribute_info | attributes_count | 属性表\n\nCode 属性示例：\n\n```java\npublic int publicMethod(int a, int b) throws Exception {\n    return a + b;\n}\n```\n\n上述方法编译成字节码之后如下所示：\n\n```java\npublic int publicMethod(int, int) throws java.lang.Exception;\ndescriptor: (II)I\nflags: ACC_PUBLIC\nCode:\n  stack=2, locals=3, args_size=3\n     0: iload_1\n     1: iload_2\n     2: iadd\n     3: ireturn\n  LineNumberTable:\n    line 39: 0\n  LocalVariableTable:\n    Start  Length  Slot  Name   Signature  // start和length合起来显示了该变量的作用域\n        0       4     0  this   Lorg/zhenchao/jvm/chapter6/ClassStructTest;\n        0       4     1     a   I\n        0       4     2     b   I\nExceptions: // 与 Code 属性平级\n  throws java.lang.Exception\n```\n\n上述字节码的局部变量数 `locals` 和参数个数 `args_size` 值均为 3，然而实际上我们只定义了两个参数，多的那个是 this 引用，每个方法都隐式持有一个 this 引用，用于指向当前方法所属的类实例。\n\n__LineNumberTable__ 属性用于描述源码与字节码行号之间的映射关系，是生成字节码时的可选项（在执行 javac 时可以通过设置 `-g:none` 和 `-g:lines` 来关闭和打开）。如果指定不生成 LineNumberTable，当程序抛出异常时将不会显示发生异常的行号，并且在调试程序时也无法按照源码行来设置断点。\n\n__LocalVariableTable__ 用于描述栈帧局部变量表中的变量与源码中定义的变量之间的映射关系，也是生成字节码时的可选项（在执行 javac 时可以通过设置 `-g:none` 和 `-g:vars` 来关闭和打开）。如果指定不生成 LocalVariableTable，那么反编译或者引用这个方法时，所有的参数名称都会丢失，取而代之的是 arg0、arg1 之类的占位符。JDK 5 之后增加了姊妹属性 LocalVariableTypeTable，用于描述泛型类型。\n\n上述字节码中最后一行的 __Exceptions__ 属性与 Code 属性平级（不要与 `exception_table` 混淆啦），其作用是列举出方法中可能抛出的受检异常，也就是 throws 关键字后面列举的异常列表。\n\n### 字节码指令\n\nJava 字节码由一个操作码（Opcode）和零至多个紧随其后的操作数（Operand）构成，格式如下：\n\n```text\n操作码 [操作数1] [操作数2] ...\n```\n\n其中操作码占用 1 个字节，因此最多只能有 256 个，由于 JVM 采用面向操作数栈而不是寄存器的架构，所以 __大多数操作码不包含操作数__ 。\n\n大多数操作码都包含一个字母用于表明其操作的数据类型（大部分都是首字母）。例如，i 表示 int 类型的数据操作，l 表示 long 类型的数据操作，s 代表 short 类型的数据操作，b 代表 byte 类型的数据操作，c 代表 char 类型的数据操作，f 代表 float 类型的数据操作，d 代表 double 类型的数据操作，以及 a 代表 reference 类型的数据操作。不过，仍然包含一些指令没有明确指明对应的操作类型。\n\n由于 java 的操作码只占用 1 个字节，上限个数只有 256 个，秉承着节约主义，就不能为所有的数据类型和对应的操作设计独立的操作码，这样会导致 256 个操作码很快被用完。所以，大部分操作码都不支持直接操作 byte、char，以及 short 类型，甚至没有任何操作码支持操作 boolean 类型，但是编译器会在编译期或运行期将 byte 和 short 类型带符号扩展（Sign-Extend）为相应的 int 类型，将 boolean 和 char 类型零位扩展（Zero-Extend）为相应的 int 类型数据，所以大多数对于这些类型的操作，本质上是在操作 int 类型。\n\n#### 加载和存储指令\n\n加载和存储指令用于 __将数据在栈帧中的局部变量表和操作数栈之间来回进行传输__ ，包括：\n\n- 将一个局部变量加载到操作数栈\n\n`iload`、`iload_<n>`、`lload`、`lload_<n>`、`fload`、`fload_<n>`、`dload`、`dload_<n>`、`aload`、`aload_<n>`，其中 a 表示引用类型，n 表示操作数，比如 `iload_0` 等同于 `iload 0`。\n\n- 将一个数值从操作数栈存储到局部变量表\n\n`istore`、`istore_<n>`、`lstore`、`lstore_<n>`、`fstore`、`fstore_<n>`、`dstore`、`dstore_<n>`、`astore`、`astore_<n>`。\n\n- 将一个常量加载到操作数栈\n\n`bipush`、`sipush`、`ldc`、`ldc_w`、`ldc2_w`、`aconst_null`、`iconst_m1`、`iconst_<i>`、`lconst_<l>`、`fconst_<f>`、`dconst_<d>`。\n\n- 扩充局部变量表的访问索引\n\n`wide`。\n\n#### 运算指令\n\n运算指令用于对两个操作数栈上的数值进行某种特定的运算，并把结果重新存入到操作数栈顶。运算指令整体上可以分为两种：对整型数据进行运算的指令和对浮点型数据进行运算的指令。所有的运算指令包括：\n\n- 加法：`iadd`、`ladd`、`fadd`、`dadd`。\n- 减法：`isub`、`lsub`、`fsub`、`dsub`。\n- 乘法：`imul`、`lmul`、`fmul`、`dmul`。\n- 除法：`idiv`、`ldiv`、`fdiv`、`ddiv`。\n- 求余：`irem`、`lrem`、`frem`、`drem`。\n- 取反：`ineg`、`lneg`、`fneg`、`dneg`。\n- 位移：`ishl`、`lshl`、`fshl`、`dshl`。\n- 按位或：`ior`、`lor`。\n- 按位与：`iand`、`land`。\n- 按位异或：`ixor`、`lxor`。\n- 局部变量自增：`iinc`。\n- 比较：`dcmpg`、`dcmpl`、`fcmpg`、`fcmpl`、`lcmp`。\n\n整型和浮点型数的运算指令在溢出和被零除时有各自不同的行为表现。对于整型数据，JVM 规范并没有明确定义溢出的计算规则，仅规定只有除法指令（idiv 和 ldiv）和求余指令（irem 和 lrem）在遇到除数为零时会抛出 ArithmeticException 异常。对于浮点型数据，JVM 要求必须严格遵循 IEEE-754 规范。\n\nJVM 在处理浮点数据运算时不会抛出任何异常，当操作溢出时将使用有符号的无穷大进行表示；如果某个操作结果没有明确的数学定义的话，将使用 NaN（Not a Number）值进行表示；所有使用 NaN 值作为操作数的运算，结果都会返回 NaN。\n\n在对 long 类型数据进行比较时，JVM 采用带符号的比较方式，而对于浮点型数据则采用 IEEE-754 规范所定义的无信号比较（Nonsignaling Comparison）方式。\n\n#### 类型转换指令\n\n类型转换指令用于将两种不同的数值类型进行相互转换，一般用于实现代码中的显式类型转换，或者处理数据类型相关指令无法与数据类型一一对应的问题。数据类型转换分为 __宽化转换__ 和 __窄化转换__ ，其中宽化转换是虚拟机直接支持的，无需依赖对应的转换指令。宽化转换包括：\n\n1. int 类型到 long、float 或 double 类型的转换。\n2. long 类型到 float 和 double 类型的转换。\n3. float 类型到 double 类型的转换。\n\n窄化转换由于会导致结果正负变换或精度丢失等问题，所以需要使用转换指令来完成，包括：`i2b`、`i2c`、`i2s`、`l2i`、`f2i`、`f2l`、`d2i`、`d2l`、`d2f`。JVM 规范明确规定数值类型的窄化转换指令永远不会导致 JVM 抛出运行时异常。\n\nJVM 在将一个浮点数窄化转换成 int 或 long 类型时，必须遵循以下转换原则：\n\n1. 如果浮点数是 NaN，则转换结果是 0。\n2. 如果浮点数不是无穷大，则使用 IEEE-754 的向零舍入模式取整，得到的结果如果如果溢出，则依据正负号使用对应的最大最小正数值代替。\n\n对于从 double 类型到 float 类型的转换，则使用 IEEE-754 向最接近数舍入模式舍入得到一个可以使用 float 类型表示的数字。如果转换结果的绝对值太小，无法使用 float 类型进行表示的话，则返回 float 类型的正负零；如果转换结果的绝对值太大，无法使用 float 类型进行表示的话，则返回 float 类型的正负无穷大。\n\n#### 对象创建和访问指令\n\n虽然类实例和数据都是对象，但是 JVM 对于类实例和数据的创建与操作分别定义了不同的指令，如下所示：\n\n- 创建类实例：`new`。\n- 创建数组：`newarray`、`anewarray`、`multianewarray`。\n- 访问类字段和实例字段：`getfield`、`putfield`、`getstatic`、`putstatic`。\n- 加载一个数组元素到操作数栈：`baload`、`caload`、`saload`、`iaload`、`laload`、`faload`、`daload`、`aaload`。\n- 将一个操作数栈的值存储到数组元素：`bastore`、`castore`、`sastore`、`iastore`、`fastore`、`dastore`、`aastore`。\n- 取数组长度：`arraylength`。\n- 检查类实例类型：`instanceof`、`checkcast`。\n\n#### 操作数栈管理指令\n\n- 将栈顶一个或两个元素出栈：`pop`、`pop2`。\n- 复制栈顶一个或两个数值，并将复制值或双份复制值重新压入栈顶：`dup`、`dup2`、`dup_x1`、`dup2_x1`、`dup_x2`、`dup2_x2`。\n- 交换栈最顶端两个元素：`swap`。\n\n#### 控制转移指令\n\n控制转移指令可以让 JVM 有条件或无条件的从指定位置指令的下一条指令继续执行。控制转移指令包括：\n\n- 条件分支：`ifeq`、`iflt`、`ifle`、`ifne`、`ifgt`、`ifge`、`ifnull`、`ifnonnull`、`if_icmpeq`、`if_icmpne`、`if_icmplt`、`if_icmpgt`、`if_icmple`、`if_icmpge`、`if_acmpeq`、`if_acmpne`。\n- 复合条件分支：`tableswitch`、`lookupswitch`。\n- 无条件分支：`goto`、`goto_w`、`jsr`、`jsr_w`、`ret`。\n\nJVM 定义了专门的指令用于处理 int 和 reference 类型的条件分支比较操作，也有专门的指令用来检测 null。对于 long 、float 和 double 类型的条件分支比较，JVM 会先执行相应类型的比较运算指令，比较操作返回一个 int 型值到操作数栈，随后再执行 int 类型的条件分支比较操作。\n\n#### 方法调用和返回指令\n\n方法调用指令与数据类型无关，但是方法返回指令需要依据返回值区分数据类型。方法调用指令包括：\n\n- `invokevirtual`：用于调用对象的实例方法。\n- `invokeinterface`：用于调用接口方法。\n- `invokespecial`：用于调用一些需要特殊处理的实例方法，包括实例初始化方法、私有方法、父类方法。\n- `invokestatic`：用于调用类静态方法。\n- `invokedynamic`：用于在运行时动态解析出调用点限定符所引用的方法。\n\n返回指令与返回类型有关，包括 `ireturn`、`lreturn`、`freturn`、`dreturn`、`areturn`，以及供 void 方法、`<init>`、`<clinit>` 方法使用的 `return` 指令。\n\n#### 异常处理指令\n\n显式抛出异常的操作（throw 语句）都由 `athrow` 指令实现，而处理异常（catch 语句）却不是由字节码指令实现，而是采用异常表来完成。\n\n#### 同步指令\n\n同步（synchronized 关键字）分为方法级别的同步和代码块级别的同步，这两种同步在 JVM 中都是基于 __管程（Monitor）__ 实现。\n\n方法级别的同步是隐式的，通过方法表中的 `ACC_SYNCHRONIZED` 访问标志来标记一个方法是同步方法，当指令调用该方法时，会先检查 `ACC_SYNCHRONIZED` 标志位是否被设置，如果被设置了则无法获取管程（锁），必须等待其它指令释放。\n\n同步代码段则基于指令 monitorenter 和 monitorexit 两条指令实现同步，对于异常情况需要中断同步，所以字节码在实现时会主动添加一个异常处理器，并在异常产生时执行 monitorexit 指令，保证不因为异常而导致持有的锁无法正确释放。\n\n关于 synchronized 关键字推荐进一步阅读 [深入理解 JUC：synchronized 关键字](/2018/08/03/java/juc-synchronized/)。\n\n### 参考\n\n1. [Java 虚拟机规范（Java SE 8 版）](https://book.douban.com/subject/26418340/)\n2. [深入理解 java 虚拟机（第 2 版）](https://book.douban.com/subject/24722612/)\n3. [深入理解 java 虚拟机（第 3 版）](https://book.douban.com/subject/34907497/)\n","tags":["JVM"],"categories":["java"]},{"title":"探秘 JVM：垃圾收集机制","url":"/2016/10/23/jvm/garbage-collection/","content":"\nJVM 中的程序计数器、java 虚拟机栈、本地方法栈均属于线程私有，其生命周期控制在线程生命周期范围内，并且 java 虚拟机栈和本地方法栈中的的栈帧会随着对应方法的执行而出栈和入栈，由生到灭，所以这些区域的内存使用是确定性的（编译期已知）。然而，Java 堆和方法区是线程共享的，对象的创建也是动态的，所以垃圾收集的主战场集中在 java 堆和方法区。\n\n相对于 java 堆而言，方法区的垃圾收集性价比要低很多，JVM 规范甚至不强制要求 JVM 在方法区实现垃圾收集。不过对于复杂应用，尤其是大量使用反射、动态代理、CGLib 等字节码框架，动态生成 JSP，以及 OSGi 这类频繁自定义类加载器的场景中，对于方法区实现垃圾收集还是有必要的。方法区的垃圾收集主要回收两部分内容：废弃的常量和不再使用的类型。对于一个类型是否不再被使用，JVM 在判定时需要同时满足以下 3 个条件：\n\n1. 该类所有的实例都已经被回收了，也就是说堆中不存在该类及其派生子类的任何实例。\n2. 加载该类的类加载器已经被回收了。\n3. 该类对应的 Class 类对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n<!-- more -->\n\n### 引用类型与可达性分析\n\n#### Java 中的引用类型\n\n我们一般对于引用的定义是存放某个对象地址的对象，而 java 对于引用的定义则更加细化。自 JDK 1.2 起，Java 将引用细分为强引用（Strongly Reference）、软引用（Soft Reference）、弱引用（Weak Reference），以及虚引用（Phantom Reference） 4 种，强度逐级由强到弱。\n\n- __强引用__ ：通常在程序中存在的引用都是强引用，比如 `Object ref = new Object();`，这类引用的特点是只要存在，垃圾收集器就不会对被引用的对象执行回收操作。\n- __软引用__ ：通过继承 SoftReference 类实现，描述一些还有用但非必须的对象，JVM 会在发生 OOM 之前将这些对象纳入回收范围，如果这部分对象回收后仍然内存不足，才会抛出 OOM 异常。\n- __弱引用__ ：通过继承 WeakReference 类实现，描述一些非必须的对象，被弱引用的对象不管当前是否有足够的内存，都会被下一次 GC 操作所回收。典型的应用场景就是 ThreadLocal，ThreadLocal 维护了一个线程私有的内存数据库来记录线程私有的对象，而对象的 key 是一个弱引用的对象。\n- __虚引用__ ：通过继承 PhantomReference 类实现，虚引用并不能影响一个对象的生命周期，我们也无法通过虚引用来获取被引用对象的实例，其存在的唯一目的在于能在被引用的对象被回收时收到一个系统通知。\n\n所有的引用类型都继承自 `java.lang.ref.Reference` 抽象类，它定义了一个 `Reference#get` 方法用于获取当前引用指向的目标对象，但是虚引用除外，因为其 `PhantomReference#get` 方法始终返回 null。\n\n#### 对象可回收性判定策略\n\n一个对象只有在无效的情况下才可以被回收，如何判定一个对象是无效的，主要有两种思路：引用计数和可达性分析。\n\n##### 引用计数法\n\n引用计数法是比较简单的一种判定对象是否无效的策略。通过为每一个对象设置一个计数器，当一个对象被引用则计数加 1，反之则减 1，当一个对象的引用计数是 0 时，我们可以将其视为无效并回收。然而，该策略存在循环引用的问题，当两个对象互相引用时，即使没有被其它对象所引用，这两个对象的引用计数也至少是 1，无法被回收。\n\n##### 可达性分析\n\n可达性分析采用连通图的思想，我们可以把每个对象都看作是图上的一个结点，而引用则可以看作图上的边。在这个图中存在一些特殊的结点，被称为 GC Roots（可以简单将其理解为由堆外指向堆内的引用），如果某个对象不与任何一个 GC Roots 连通，则视为该对象无效，可以被回收。\n\n在 JVM 中，可以被视为 GC Roots 的结点包括下面几种：\n\n1. 虚拟机栈（栈帧中的本地变量表）中所引用的对象。\n2. 方法区中类静态（static）属性所引用的对象。\n3. 方法区中常量所引用的对象。\n4. 本地方法栈中 native 方法所引用的对象。\n5. 内部引用，例如类所属的 Class 对象、一些常驻内存的异常对象，以及系统类加载器所引用的对象。\n6. 锁对象，即被同步锁持有的对象。\n7. 反映 JVM 内部情况的 JMMXBean、JVMTI 中注册的回调，以及本地代码缓存等。\n\n除了上述这些固定的 GC Roots 之外，根据用户所选择的垃圾收集器和当前回收的内存区域不同，还可以将一些对象作为临时的 GC Roots。\n\n通过可达性分析判定的对象无效实际上是给对象判了一个死缓，并没有立即执行回收，一些对象还可以在后续通过良好的表现而无罪释放。真正需要对一个对象执行死刑需要经过 __两次标记__ 过程：\n\n- __第 1 次标记__ ：被判定为无效的对象将经过一次筛选，筛选出那些有必要执行 finalize 方法的对象（有必要是指该对象覆盖了 finalize 方法，且该方法还没有被 JVM 调用过，一个对象的 finalize 方法最多只能被 JVM 调用一次），这些对象被筛选出来之后就被放进 F-Queue 队列中；\n- __第 2 次标记__ ：由一个 JVM 自动创建的、低优先级的 Finalizer 线程去依次调用 F-Queue 队列中对象的 finalize 方法，我们可以认为 finalize 方法是对象最后一个改过自新的地方，如果对象在这里重新让自己被引用则复活，否则就几乎只有等死了。\n\n下面是一个验证上述过程的例子：\n\n```java\npublic class FinalizeDemo {\n\n    public static FinalizeDemo saveHook;\n\n    @Override\n    protected void finalize() throws Throwable {\n        System.out.println(\"do finalize method\");\n        super.finalize();\n        saveHook = this;\n    }\n\n    private static void isAlive() {\n        System.out.println(null == saveHook ? \"Sorry, I'm died!\" : \"yes, I'm still alive!\");\n    }\n\n    public static void main(String[] args) throws Exception {\n        saveHook = new FinalizeDemo();\n\n        /* 第一次改过自新 */\n        saveHook = null; // 去掉引用\n        System.gc();  // 触发finalize方法\n        TimeUnit.SECONDS.sleep(1);  // finalize方法优先级较低，暂停等待1秒钟\n        isAlive();\n\n        /* 第二次改过自新 */\n        saveHook = null; // 去掉引用\n        System.gc();  // 触发finalize方法，因为finalize只会被调用一次，所以本次不会调用finalize，自救失败\n        TimeUnit.SECONDS.sleep(1);  // finalize方法优先级较低，暂停等待1秒钟\n        isAlive();\n    }\n\n}\n```\n\n执行结果：\n\n```text\ndo finalize method\nyes, I'm still alive!\nSorry, I'm died!\n```\n\n上述示例在第一次 GC 时触发调用了对象的 finalize 方法，我们在该方法中为 saveHook 变量带来了第二春（即 `saveHook = this`），所以该对象从死缓中被保释了出来。然而，这货不老实，放出来之后又被抓进去了（即 `saveHook = null`），这一次就没有那么幸运了，因为一个对象的 finalize 方法最多只能被系统调用一次，所以这一次只能坐以待毙了。\n\n__注意__ ：一般不推荐在 finalize 方法中添加自定义逻辑，因为该方法的执行是不确定的，推荐将这些逻辑写到 finally 块中。\n\n虽然可达性分析能够解决引用计数存在的循环引用问题，但在具体实现时仍然存在一些其它需要解决的问题。例如，在多线程环境下线程可能会并发更新对象的引用，从而可能导致将对象设置为 null 造成误报，或者将引用设置为未被访问过的对象造成漏报。\n\n传统的 JVM 垃圾收集算法在解决这一问题方面采用的是一种简单粗暴的方式，即停止所有非垃圾收集线程的工作直到垃圾收集操作完成，这也就是臭名昭著的 Stop-The-World（简称 STW）。JVM 中的 STW 是通过安全点（safepoint）机制来实现的，当 JVM 收到 STW 请求，便会等待所有的线程都到达安全点，然后允许请求 STW 的线程进行独占的工作。\n\n### 垃圾收集算法\n\n垃圾收集的过程会中断正常业务逻辑的执行来查找和回收垃圾对象，因为回收时机的不确定性，如果收集的过程耗时较长会引起系统的卡顿，影响用户体验，所以一般收集过程不会一次性彻底执行，而是采用渐进式回收策略，将一次收集过程分摊到多次执行，控制每次执行的时间长度，以尽量避免用户感觉到这一过程。\n\n在 JVM 实现中并没有采取单一的 GC 算法，而是采用了分代回收的策略。JVM 将 java 堆分为新生代和老年代（以 HotSpot 为例，默认大小比例为 1:2，可以通过 `-XX:NewRatio` 参数进行设置），并针对不同的区域（代）采取不同的 GC 算法，比如新生代中对象生命周期较短，适合采用标记复制算法，而老年代中对象大部分时间都是处于存活状态，而且很多都是大对象，所以比较适合采用标记清除和标记整理算法。\n\n分代回收理论建立在以下假说之上：\n\n1. 弱分代假说：绝大多数对象都是朝生夕灭的。\n2. 强分代假说：熬过越多次垃圾收集过程的对象就越难消亡。\n3. 跨代引用假说：跨代引用相对于同代引用来说仅占极少数。\n\n其中第 3 点主要是说明待收集的对象并不是孤立的，对象之间存在跨代引用的可能性，例如新生代中的对象引用老年代中的对象，反之亦然。此种场景如果发生的较为频繁的话，那么仅对新生代，或仅对老年代进行回收是不合理的。\n\n在分代回收理论的前提下，针对不同内存区域的回收会划分出不同的回收类型，具体分类如下：\n\n- __Minor GC__ ：对新生代实施垃圾收集。\n- __Major GC__ ：对老年代实施垃圾收集，目前只有 CMS 收集器会单独收集老年代，也称为 CMS GC。\n- __Mixed GC__ ：对整个新生代和部分老年代实施垃圾收集，目前只有 G1 收集器采用这一策略。\n- __Full GC__ ：对整个 java 堆和方法区进行垃圾收集。\n\n其中 Minor GC、Major GC 和 Mixed GC 又可以统称为 __Partial GC__ ，即部分收集，对 java 堆的部分区域进行收集，与 Full GC 相对应。\n\n说明：虽然这里对 Major GC 和 Full GC 在概念上进行了区分，但是实际实现层面二者通常是等价的。\n\n下图描绘了新建一个对象在 JVM 层面的执行流程：\n\n![image](/images/2016/jvm-object-allocation.png)\n\n在为对象分配内存时，如果 Eden 区域内存不够则会触发 Minor GC，而 Full GC 的触发场景可以概括为以下几种：\n\n1. 调用 `System#gc` 方法：该方法会建议 JVM 执行 Full GC，但不一定会执行。\n2. 老年代空间不足：老年代在新生代对象晋升，或创建大对象、大数组时可能会出现内存不足的情况，为避免 OOM，JVM 一般会先执行一次 Full GC。\n3. 方法区空间不足：当系统要加载、反射调用大量类和方法时，可能会导致方法区出现内存不足的情况，为避免 OOM，JVM 一般会先执行一次 Full GC。\n4. 新生代晋升至老年代的对象平均大小大于老年代当前可用内存：当对新生代执行 Minor GC 时，部分存活很久的对象会晋升至老年代，如果在此之前历次晋升的对象平均大小不大于当前老年代可用内存，则依据空间分配担保策略，本次可以先尝试执行一次 Minor GC，否则需要执行一次 Full GC 以让老年代空出更多的可用空间。\n5. 在对新生代执行 Minor GC 时，剩余存活对象大于 Survivor 容量，所以需要将这些对象复制到老年代，但是老年代的可用内存不足，所以需要执行一次 Full GC。\n\nMinor GC 不用对整个堆进行垃圾收集，但是如果老年代的对象引用了新生代中的对象，则不能对这些（新生代）对象进行回收。此时，我们需要依赖某种机制进行发现，最简单的方法就是对整个老年代进行全表扫描，但是这样效率较低。HotSpot 引入了一种被称为卡表（Card Table）的技术，将整个堆划分为一个个大小为 512 字节的卡，并且维护一个卡表以记录每张卡的一个标识位（用于标识对应的卡是否存在指向新生代对象引用的可能）。这样在执行 Minor GC 时则无需扫描整个老年代，只需要扫描卡表即可。\n\n常见的垃圾收集算法总结：\n\n算法 | 优点 | 缺点 | 适用区域 | 垃圾收集器\n--- | --- | --- | --- | ---\n标记清除 | 简单，GC 停顿时间短 | 内存碎片化问题，影响后续内存分配，降低内存访问效率 | 老年代 | CMS\n标记复制 | 效率高 | 对象复制开销（新生代下此缺点不明显），内存利用率低（可以优化） | 新生代 | 大部分收集器对于新生代的垃圾收集均采用该算法\n标记整理 | 内存区域规整，利于内存分配，内存访问效率较高 | 整理过程开销较大，导致 GC 停顿时间较长 | 老年代 | Serial Old, Parallel Old, G1，Shenandoah, ZGC\n\n#### 标记清除算法\n\n标记清除算法是最基础的垃圾收集算法，其执行过程可以分为标记和清除 2 个阶段，算法在第 1 阶段先标记出所有可以回收的对象，然后在第 2 阶段对这些对象进行统一回收。\n\n标记清除算法的缺点主要分为 2 个方面：\n\n1. 标记和清除过程的效率都不高，尤其是当堆中包含大量对象，且其中的大部分都需要被清除的时候。\n2. 清除操作会产生大量不连续的内存碎片，影响后续内存分配的效率。\n\n#### 标记复制算法\n\n标记复制算法解决了标记清除算法在面对大量可回收对象时效率不高的问题。常规的标记复制算法（也叫半区复制）将内存区域分为大小 1:1 的两块，每次仅在其中一块上进行分配，当需要 GC 时就将当前存活的对象全部复制到另外一块上去，然后对之前的那一块内存实施一次性清理。\n\n常规的标记复制算法主要有以下两个缺点：\n\n1. 存在对象复制的开销。\n2. 内存利用率不高，只有 50%。\n\n针对缺点 1，考虑到新生代每次 GC 只有少部分对象存活，所以复制压力要小很多，因此被大多数 JVM 用于回收新生代。\n\n针对缺点 2，一种优化措施（即 Appel 式回收）是将新生代大小分为 3 块，一块大的 Eden 区域和两块小的 Survivor 区域（From Survivor 和 To Survivor），每次都使用 Eden 和其中一块 Survivor 进行内存分配。当发生 Minor GC 时，Eden 和 from 指针指向的 Survivor 区域的存活对象（即不应该被 GC 的对象）会被复制到 to 指针所指向的 Survivor 区域，然后交换 from 和 to 指针，所以任何时候总有一个 Survivor 区域是空闲的。\n\n以 HotSpot 虚拟机为例，Eden 和 Survivor 区域的大小比例为 8:1（通过 `java -XX:+PrintFlagsFinal -version` 命令可以查看 JVM 所有默认参数设置）。当然，JVM 也支持动态分配的策略，根据对象的生成速率和 Survivor 区域的使用情况动态调整 Eden 区和 Survivor 区域的比例。同时，JVM 也支持通过参数 `-XX:SurvivorRatio` 来固定这个比例。\n\n实际中可能会出现一块 Survivor 不够用的情况，即存活的对象大小大于 Survivor 区域的大小，这个时候就需要将多出来的对象直接送入老年代。然而老年代不一定有足够的容量能够容纳这些对象，如果容纳不了就需要执行一次 Full GC。然而，为了避免不必要的 Full GC，JVM 通过空间分配担保机制先尝试赌一把 Minor GC，如果赌失败了再走 Full GC 也不迟。\n\n所谓 __空间分配担保机制__ 是指 JVM 在执行 Minor GC 前会检查老年代最大连续空间是否大于新生代所有对象的总空间，如果大于则可以确保 Minor GC 能够安全执行。否则，就会继续检查 `-XX:HandlePromotionFailure` 参数是否允许开启担保机制，如果允许则继续检查老年代最大连续空间是否大于历次晋升至老年代对象的平均大小（相当于借鉴历史经验值），如果大于则尝试执行 Minor GC，如果小于或者 `-XX:HandlePromotionFailure` 参数设置为不允许担保，则执行一次 Full GC。\n\n然而，参数 `-XX:HandlePromotionFailure` 在 JDK 6 Update 24 之后已经被废弃，此后只要老年代的连续空间大于新生代对象的总大小，或者大于历次晋升的平均大小，就会执行 Minor GC，否则执行 Full GC。\n\n#### 标记整理算法\n\n上面介绍的标记复制算法适用于新生代的垃圾收集，但是对于老年代来说，每次 GC 都可能存在大量存活的对象，使用标记复制不仅复制开销大，而且内存利用效率不高。老年代一般采用标记整理算法，相对于标记清除算法而言，标记整理算法会将所有存活的对象移动到内存的一端，然后对剩余的内存进行清理。\n\n标记整理算法仍然避免不了对象的复制操作，尤其是对于老年代这种每次 GC 之后仍然有大量对象存活的场景，复制存活对象并更新所有引用这些对象的地方将会是一件极其复杂且高开销的操作，为了保证线程安全必须全程在暂停用户程序的情况下执行，期间会 STW。\n\n如果不执行整理操作，仅标记清除，则会极大降低 GC 的时间，但是这样会导致内存空间碎片化，让内存分配变得更加复杂，同时影响内存访问的效率（内存访问是一个高频的操作）。因此这是一个矛盾的问题，需要结合场景去抉择，例如关注吞吐量的 Parallel Scavenge 收集器基于标记整理算法实现，而注重延迟的 CMS 收集器则基于标记清除算法实现。另外一种思路是平时多数时间都采用标记清除策略，暂时容忍内存碎片的存在，直到碎片化程度严重到影响内存分配时再执行一次标记整理，这也是 CMS 收集器所采用的策略。\n\n### 垃圾收集器\n\n垃圾收集器 | 作用区域 | 收集算法 | 适用场景 | 优点 | 缺点\n--- | --- | --- | --- | --- | ---\nSerial | 新生代 | 标记复制 | 桌面应用，虚拟内存分配较小的微服务应用 | 简单、高效，内存开销小 | 单线程，GC 停顿时间长\nSerial Old | 老年代 | 标记整理 | 与 Serial 收集器搭配使用 | Serial 收集器面向老年代的版本 | 单线程，GC 停顿时间长\nParNew | 新生代 | 标记复制 | 服务端模式下 HotSpot 的首选新生代垃圾收集器，尤其是在 JDK 7 之前 | Serial 的多线程版本 | GC 停顿时间长\nParallel Scavenge | 新生代 | 标记复制 | 注重吞吐量，或处理器资源较为稀缺的场景 | 高吞吐，相对于 ParNew 收集器能够实现对吞吐量的精确控制，以及自适应的调整策略 | GC 停顿时间长\nParallel Old | 老年代 | 标记整理 | 与 Parallel Scavenge 收集器搭配使用 | Parallel Scavenge 收集器面向老年代的版本 | GC 停顿时间长\nCMS | 老年代 | 标记清除 | 互联网服务端应用 | 并发收集，GC 停顿时间短 | 并发策略占用 CPU 资源，导致用户程序变缓；并发失败会启用 Serial Old 作为备选方案，导致较长时间的 STW；标记清除算法导致的内存碎片化\nG1 | 新生代、老年代 | 整体采用标记整理算法，局部采用标记复制算法  | 服务端应用 | 新的设计思想，致力于做全功能的收集器 |\nShenandoah | 新生代、老年代 | 标记整理 | 服务端应用 | GC 停顿时间极短，致力于在尽可能对吞吐量影响不大的前提下，实现在任意堆对内大小下都可以将 GC 停顿时间控制在 10ms 以内  | 只有 OpenJDK 才会包含，受 Oracle 官方排斥\nZGC | 新生代、老年代 | 标记整理 | 服务端应用 | GC 停顿时间极短，致力于在尽可能对吞吐量影响不大的前提下，实现在任意堆对内大小下都可以将 GC 停顿时间控制在 10ms 以内 |\n\n在 CMS 和 G1 之前的垃圾收集器存在的通病就是 GC 停顿时间长。CMS 和 G1 分别使用了增量更新和原始快照技术实现了标记阶段的并发，不会因为管理的堆内存变大，要标记的对象增多而导致 GC 停顿时间随之变长。然而，对于标记之后的处理，这两款收集器各自仍然存在需要解决的难题。其中 CMS 虽然使用标记清除算法避免了整理操作所导致的长时间停顿，但是无法绕开与标记清除算法并存的内存碎片化问题，随着内存碎片化程度的逐渐严重，势必需要对内存进行整理，从而导致长时间 GC 停顿。G1 虽然通过缩小回收区域的粒度来降低 GC 停顿的时长，但是仍然避免不了停顿。后继者 Shenandoah 和 ZGC 都致力于在尽可能对吞吐量影响不大的前提下，实现在任意堆对内大小下都可以将 GC 停顿时间控制在 10ms 以内。\n\n考虑每种垃圾收集器有自己擅长的领域，所以实际中一般针对新生代和老年代分别选择对应的垃圾收集器组合使用。常用的垃圾收集器组合如下表所示：\n\n新生代 | 老年代 | 参数设置\n--- | --- | ---\nSerial | Serial Old | `-XX:+UseSerialGC`\nParallel Scavenge | Parallel Old | `-XX:+UseParallelGC`，`-XX:+UseParallelOldGC`\nParallel New | CMS | `-XX:+UseParNewGC`，`-XX:+UseConcMarkSweepGC`\nG1 | G1 | `-XX:+UseG1GC`\n\n#### Serial / Serial Old\n\nSerial 收集器是最基础，历史最悠久的垃圾收集器，也是 HotSpot 虚拟机迄今为止在客户端模式下的默认新生代垃圾收集器。Serial 收集器是一个以单线程工作的收集器，在执行垃圾收集时必须暂停其它所有的线程，直到垃圾收集过程结束。Serial 收集器的优点在于简单、高效，是所有收集器中额外内存消耗最小的垃圾收集器。对于单核处理器或处理器核心数较少的环境来说，Serial 收集器由于没有线程交互的开销，专心致力于垃圾收集，从而能够获得最高的单线程收集效率。\n\nSerial Old 收集器是 Serial 收集器针对老年代开发的版本，因此同样是单线程的工作模式，使用标记整理垃圾收集算法。Serial Old 收集器与 Serial 收集器一样适用于客户端模式，如果应用于服务端模式则主要用于：\n\n1. 在 JDK 5 以及之前与 Parallel Scavenge 收集器搭配使用。\n2. 作为 CMS 收集器在失败后的备选方案。\n\n#### ParNew\n\nParNew 收集器本质上是 Serial 收集器的多线程版本，除了同时使用多个线程执行垃圾收集之外，与 Serial 在设计和实现上完全一致，包括控制参数（eg. `-XX:SurvivorRatio`, `-XX:PretenureSizeThreshold`, `-XX:HandlePromotionFailure`）、收集算法、STW、对象分配规则，以及回收策略等。\n\nParNew 收集器在 JDK 7 之前，几乎是服务端模式下 HotSpot 虚拟机首选的新生代垃圾收集器，其中一个很重要的原因是除了 Serial 收集器之外，它是唯一能够与 CMS 收集器配合工作的。然而，随着 G1 收集器的出现，在 JDK 9 之后，“ParNew + CMS”组合不再是官方推荐的服务端模式下的解决方案了。\n\n#### Parallel Scavenge / Parallel Old\n\nParallel Scavenge 收集器同样致力于对新生代进行垃圾收集，其诸多特性从表面上看起来与 ParNew 收集器非常相似，但是 Parallel Scavenge 收集器的目标是达到一个可控的吞吐量。所谓吞吐量可以描述为：用户程序运行时间 / （用户程序运行时间 + GC 时间）。由此可以看出 GC 时间越短，则吞吐量越高，也就越适合需要与用户交互或需要保证服务质量的场景。\n\nParallel Scavenge 收集器提供了两个参数用于对吞吐量进行精确的控制：\n\n1. `-XX:MaxGCPauseMillis`：用于控制最大 GC 停顿时间，是一个大于 0 的毫秒值，收集器会尽力保证每次 GC 的时间不超过该值。需要注意的是，降低 GC 时间是以牺牲吞吐量和缩小新生代空间为代价的，导致的结果就是 GC 会更加频繁。\n2. `-XX:GCTimeRatio`：用于直接设置 GC 时间占总运行时间的比率，是一个大于 0 且小于 100 的整数。\n\n此外，Parallel Scavenge 收集器还提供了 `-XX:UseAdaptiveSizePolicy` 参数用于开启自适应策略，依据当前系统的运行状态对新生代大小、Eden 与 Survivor 区域的比例，以及晋升老年代对象的大小等参数进行自动调节。\n\nParallel Old 收集器是 Parallel Scavenge 收集器针对老年代开发的版本，基于标记整理算法，并于 JDK 6 开始提供，此前都是“Parallel Scavenge + Serial Old”的组合。\n\n#### CMS\n\nCMS 收集器致力于最短的 GC 停顿时间，以给用户带来良好的交互体验，基于标记清除算法实现， __首次实现了让 GC 线程与用户线程并发执行__ 。CMS 的标记清除过程分为 3 次标记和 1 次清除：\n\n1. __初始标记__ ：标记 GC Roots 能直接关联到的对象，速度很快；\n2. __并发标记__ ：从 GC Roots 直接关联的对象开始遍历整个对象关联图；\n3. __重新标记__ ：修正并发标记期间因为用户程序运行而导致的之前标记过期的部分对象的标记记录；\n4. __并发清除__ ：清除标记为已经死亡的对象。\n\n其中初始标记和重新标记都需要暂停用户程序，好在这两个过程耗时都比较短，所以给用户程序造成停顿的时间也比较短。并发标记过程虽然耗时较长，但是可以与用户程序并发执行，并发清除也是如此，所以这两个步骤都带有“并发”字样，可以理解为与用户程序并发执行，也就不会造成用户程序的停顿。\n\n然而不可否认的是，CMS 收集器同样存在以下缺点：\n\n1. __对处理器资源非常敏感__ ：CMS 收集器的并发过程默认会使用到 `(n + 3) / 4` 的 CPU 资源，其中 n 为 CPU 的核心数，当应用程序负载较高时，会因为 CMS 收集器的运行而导致用户程序运行变缓。\n2. __浮动垃圾可能导致 CMS 执行失败，进而导致 Full GC__ ：所谓浮动垃圾是指在并发标记期间，由于用户程序的并发执行导致期间产生的新的垃圾未被标记，这些垃圾将不会在本次并发清除阶段被清除，而需要留到下一次 GC。此外，由于 GC 与用户程序的并发执行，所以 CMS 收集器必须为当前用户程序的执行留出一定的老年代空间（可以通过 `-XX:CMSInitiatingOccupancyFraction` 参数设置），也就不能像其它老年代收集器一样等到老年代几乎快被用完了再执行 GC，如果预留的老年代空间无法容纳新对象，就会导致并发失败，此时 JVM 将启动备选方案，使用 Serial Old 收集器对老年代进行一次完整的收集，期间将 STW。\n3. __内存空间碎片化__ ：由于采用标记清除算法，如果不对内存空间进行整理，势必会因为碎片过多而触发 Full GC，从而导致停顿时间边长。\n\n#### G1\n\nGarbage First（简称 G1）收集器是一款主要面向于服务端应用的垃圾收集器，在 JDK 9 之后取代“Parallel Scavenge + Parallel Old”组合，成为服务端模式下默认的垃圾收集器，而 CMS 收集器自此开始沦落为不再推荐被使用的收集器。 __G1 开创了收集器面向局部收集的设计思路和基于 Region 的内存布局形式__ 。\n\n在 G1 之前，其它垃圾收集器均将 JVM 内存区域划分为新生代和老年代，对应的收集范围要么是整个新生代（Minor GC），要么是整个老年代（Major GC），甚至是是整个 java 堆（Full GC）。G1 收集器不再坚持按照固定大小和固定数量的分代区域划分策略，而是将连续的 java 堆划分成多个大小相等且独立的区域，称为 Region。每个 Region 都可以依据需要扮演不同的角色，例如新生代的 Eden 空间、Survivor 空间，亦或是老年代空间。G1 收集器能够依据具体 Region 所扮演的角色采用不同的策略对其执行垃圾收集。虽然，G1 仍然保留新生代和老年代的概念，但是其大小已经不再像之前的垃圾收集器一样是固定的，而是一系列（可以不连续的） Region 的动态集合。Region 中还有一类特殊的称为 Humongous 的区域，专门用于存储大对象。G1 收集器在执行垃圾收集时不再像之前的垃圾收集器一样按照新生代或老年代进行划分，而是计算哪块 Region 中存放的垃圾数量最多，回收收益最大，就对该 Region 或多个 Region 集合执行回收，这也是 Garbage First 命名的由来。\n\nG1 收集器的运行机制大致可以分为四个步骤：\n\n1. __初始标记__ ：标记 GC Roots 能直接关联到的对象，并修改 TAMS(Top at Mark Start) 指针，从而让下一阶段用户线程并发执行时能够正确的在可用的 Region 中分配新对象，此阶段会暂停用户程序，但是耗时很短；\n2. __并发标记__ ：从 GC Roots 直接关联的对象开始遍历整个堆中对象关联图，找出可以回收的对象，该过程虽然比较耗时，但是可以与用户程序并发执行。当对象图扫描完成之后，还需重新处理 SATB(Snapshot-At-The-Beginning) 记录下的在并发期间有引用变动的对象。\n3. __最终标记__ ：处理并发阶段结束后仍遗留下来的少量的 SATB 记录，此阶段会短暂暂停用户程序；\n4. __筛选回收__ ：更新 Region 的统计数据，并按照回收价值和成本对各个 Region 进行排序，并基于用户所期望的停顿时间来制定回收计划，此阶段必须暂停用户程序。\n\n从现阶段的表现来看，G1 相对于 CMS 而言并没有压倒性的优势，而是各自有属于自己的应用场景，但是从长期发展来说，G1 取代 CMS 是趋势。\n\n#### Shenandoah\n\nShenandoah 收集器是第一款由非 Oracle 官方虚拟机团队领导开发的 HotSpot 垃圾收集器，由于受 Oracle 官方排斥，所以只能包含在 OpenJDK 中。Shenandoah 收集器致力于在任何堆大小下都可以将 GC 停顿时间控制在 10ms 以内，在设计和实现层面更像是 G1 收集器的继承者，二者在堆内存布局、初始标记、并发标记等多方面都高度一致，甚至还共享了一部分代码。然后，在管理堆内存方面，Shenandoah 相对于 G1 存在以下 3 点不同：\n\n1. 支持并发整理。\n2. 默认不使用分代收集。\n3. 在跨 Region 的引用关系记录层面，使用连接矩阵全局数据结构，相对于 G1 更加高效和节省资源。\n\nShenandoah 收集器在工作流程上分为初始标记、并发标记、最终标记、并发清理、并发回收、初始引用更新、并发引用更新、最终引用更新，以及并发清理 9 个阶段。\n\n#### ZGC\n\nZGC 收集器与 Shenandoah 收集器一样致力于在尽可能对吞吐量影响不大的前提下，实现在任意堆对内大小下都可以将 GC 停顿时间控制在 10ms 以内，是一款基于 Region 内存布局的，（暂时）不设分代的，使用了读屏障、染色指针和内存多重映射等技术实现可并发的标记整理算法的，以低延迟为首要目标的垃圾收集器。\n\nZGC 收集器在工作流程上可以并发标记、并发预备重分配、并发重分配，以及并发重映射 4 个阶段。\n\n### 内存分配策略\n\n首先， __对象优先在 Eden 区域进行分配__ 。一般情况下对象会首先在新生代 Eden 区域进行分配，当 Eden 空间不足时，JVM 将发起一次 Minor GC。\n\n其次， __大对象直接进入老年代__ 。对于大对象（需要大量连续内存空间的对象），JVM 采取的策略是直接进入老年代（可以通过 `-XX:PretenureSizeThreshold` 参数设置，大于该阈值的对象直接进入老年代，但需要注意该参数只对 Serial 和 ParNew 两款收集器有效），因为新生代中的对象只有在一定的 GC 次数之后仍然存活才能进入老年代，而在此之前大对象会频繁在两个 Survivor 区域之间复制，这样会降低效率；然而，对于一个朝生夕灭的大对象，直接进入老年代也不是好事，实际上就算分配在新生代上也不是好事，所以编程中应该尽量避免这种朝生夕灭的大对象。\n\n最后， __长期存活的对象进入老年代__ 。因为采用分代存储，所以 JVM 需要知道哪些对象应该放在新生代，哪些对象应该放在老年代。JVM 一般会根据对象熬过的 GC 次数作为判定依据，并且会为该对象设置一个对象年龄计数器。如果某个对象在第 1 次 Minor GC 后仍然存活，并且能够被 Survivor 区域所容纳则进入 Survivor 区域，同时设置对象年龄计数器为 1。以后每熬过 1 次 Minor GC 则对象年龄计数器加 1，当年龄达到一定值（默认为 15，可以通过 `-XX:+MaxTenuringThreshold` 参数设置）则进入老年代。但这也不是绝对的，如果单个 Survivor 区域使用率超过 50%（对应 `-XX:TargetSurvivorRatio` 配置），则复制次数较多的对象也会被移入老年代。此外，如果 Survivor 空间中相同年龄的所有对象大小之和大于 Survivor 空间的一半，则年龄大于或等于这些对象的对象可以直接进入老年代。\n\n### 参考\n\n1. [Java 虚拟机规范（Java SE 8 版）](https://book.douban.com/subject/26418340/)\n2. [深入理解 java 虚拟机（第 2 版）](https://book.douban.com/subject/24722612/)\n3. [深入理解 java 虚拟机（第 3 版）](https://book.douban.com/subject/34907497/)\n4. [极客时间：深入拆解 java 虚拟机](https://time.geekbang.org/column/intro/108)\n","tags":["JVM"],"categories":["java"]},{"title":"探秘 JVM：运行时数据区","url":"/2016/10/16/jvm/runtime-data-areas/","content":"\nJVM 内存区域从概念模型上主要分为 __堆、元空间、java 虚拟机栈、本地方法栈、程序计数器__ 五大模块，其中前两者属于线程共享，而后三者属于线程私有，如下图（以 HotSpot 虚拟机为例）：\n\n![image](/images/2016/jvm-runtime-data-areas.png)\n\n说明：元空间在 java 8 中引入，替换之前的方法区。\n\n<!-- more -->\n\n各个区域的基本介绍如下：\n\n区域 | 线程共享 | 调整参数 | 异常类型 | 功能描述\n--- | --- | --- | --- | ---\n堆 | 是 | -Xms, -Xmx | OutOfMemoryError | 主要用于存放对象实例和数组\n方法区 | 是 | -XX:PermSize, -XX:MaxPermSize | OutOfMemoryError | 存储已被虚拟机加载的类型信息、常量、静态变量，以及 JIT 编译后的代码缓存，运行时常量池位于此区域\n虚拟机栈 | 否 | -Xss | StackOverflowError, OutOfMemoryError | 存储局部变量表、操作数栈、动态连接，以及方法出口信息\n本地方法栈 | 否 | -Xoss | StackOverflowError, OutOfMemoryError | 与虚拟机栈功能类似，但是服务于 native 方法\n程序计数器 | 否 | 无 | 无 | 用于指定下一条待执行的指令，控制代码的执行流程\n\n### 线程共享区域\n\n#### 堆\n\nJava 堆是线程共享的，在虚拟机启动时创建，是存放对象实例和数组的地方，垃圾收集器的主战场。虽然 JVM 规范要求所有的对象实例都要在堆上分配，但是随着 JIT 编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换等技术让对象实例必须在堆上分配逐渐变得不那么绝对。\n\n##### 堆内存分配策略\n\nJVM 规范只要求堆在逻辑上连续即可，但是具体是逻辑上连续还是物理上连续要看具体的内存分配算法。\n\n- __指针碰撞法__\n\n如果堆中内存是规整的，即使用中的内存放在一边，空闲的内存放在另外一边，中间维护一个指针作为分界指示器。这种情况下如果需要为一个对象分配内存，只要按需将指示器向空闲区域移动相应大小即可。\n\n- __空闲列表法__\n\n对于不规整的内存区域，只有在堆中维护一个空闲内存列表，用于标记哪些内存区域是空闲的，然后分配的时候从空闲列表中找到一块对应的足够大的内存区域予以分配。\n\n堆内存是否规整主要依据采用的垃圾收集器是否具备压缩整理功能。例如使用 Serial、ParNew 等带压缩整理的垃圾收集器时，系统采用的堆内存分配算法是指针碰撞算法；如果使用的是 CMS 这类清除算法垃圾收集器，一般就只能使用空闲列表算法执行堆内存分配。\n\n除了考虑具体的内存分配算法，我们还需要考虑内存分配的 __线程安全问题__ ，毕竟 new 操作是相当频繁的。解决线程安全主要有两种方法：\n\n1. 采用 CAS 配合失败重试的方式保证分配操作的原子性。\n2. 把堆内存分配成多块（TLAB: Thread Local Allocation Buffer），每块由一个线程维护分配，这样就能够避免线程之间的竞争，只有在分配 TLAB 时才需进行同步。\n\n##### 对象的内存布局\n\n在 HotSpot 中，对象的内存布局分为 3 块：对象头、实例数据，以及对齐填充。\n\n__对象头__ 包含两部分数据，第一部分用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID，偏向时间戳等）；另外一部分则是类型指针，用于定位当前对象是哪个类的实例，但是这部分不是必须的，视具体定位策略。此外，如果对象是一个数组，那么还需要在对象头中保存当前数组的长度。\n\n```text\n|----------------------------------------------------------------------------------------|--------------------|\n|                                    Object Header (64 bits)                             |        State       |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|                  Mark Word (32 bits)                  |      Klass Word (32 bits)      |                    |\n|-------------------------------------------------------|--------------------------------|--------------------|\n| identity_hashcode:25 | age:4 | biased_lock:1 | lock:2 |      OOP to metadata object    |       Normal       |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|  thread:23 | epoch:2 | age:4 | biased_lock:1 | lock:2 |      OOP to metadata object    |       Biased       |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|               ptr_to_lock_record:30          | lock:2 |      OOP to metadata object    | Lightweight Locked |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|               ptr_to_heavyweight_monitor:30  | lock:2 |      OOP to metadata object    | Heavyweight Locked |\n|-------------------------------------------------------|--------------------------------|--------------------|\n|                                              | lock:2 |      OOP to metadata object    |    Marked for GC   |\n|-------------------------------------------------------|--------------------------------|--------------------|\n```\n\n引用自 [https://gist.github.com/arturmkrtchyan/43d6135e8a15798cc46c](https://gist.github.com/arturmkrtchyan/43d6135e8a15798cc46c)\n\n__实例数据__ 部分记录了对象的有效信息，即各种类型的字段内容，包括继承的和自定义的。这部分的存储顺序由虚拟机分配策略参数与字段定义顺序决定。\n\n__对齐填充__ 不是必须的，仅仅起到占位符的作用，一般来说对象的大小必须是 8 字节的整数倍，所以在不满足时需要进行填充。\n\n##### 对象的访问定位\n\n引用（reference）类型是 JVM 所支持的类型之一，一般而言，虚拟机至少应该基于引用类型做到两件事情：\n\n1. 根据引用直接或间接的定位对象在 java 堆中数据存放的起始地址或索引。\n2. 根据引用直接或间接的定位对象所属类型在方法区中存储的类型信息。\n\n在 java 栈中通过引用记录着堆上具体对象的引用，如何基于引用来定位具体的对象是本小节需要讨论的问题，目前主流的定位策略主要分为 __句柄__ 和 __直接指针__ 两类。\n\n![image](/images/2016/jvm-object-location.png)\n\n如上图所示，左图描绘了基于句柄的定位策略，右图描绘了基于直接指针的定位策略。两种定位的区别在于基于句柄的策略需要在堆中专门分配一块句柄池，用于记录堆中对象实例和方法区中对象类型的真实地址信息，而栈中保存的则是对应堆中的对象句柄地址。基于直接指针的策略则是在栈中保存堆中对象的真实地址信息。\n\n两种策略各有优略，基于句柄策略的优势在于当对象的地址变更时只要修改句柄池中对应的地址即可，缺点就是每次定位一个对象需要访问两次堆内存；基于直接指针的优缺点则正好相反。HotSpot 虚拟机采用的是基于直接地址的访问策略。\n\n##### 控制参数\n\n参数 | 默认值 | 说明\n--- | --- | ---\n`-Xms` | | 设置堆内存初始大小，ms 是 memory start 的缩写\n`-Xmx` | | 设置堆内存大小上限，mx 是 memory max 的缩写\n`-XX:+HeapDumpOnOutOfMemoryError` | | 当出现 OOM 时 dump 出当前堆内存快照\n`-XX:HeapDumpPath` | | 用于指定堆内存快照文件的存储路径，文件名以 `.hprof` 后缀结尾\n\n说明：`-X` 前缀代表这是一个 JVM 运行时参数。\n\n生产环境通常建议将 `-Xms` 和 `-Xmx` 这两个参数值设为相同以避免堆内存的伸缩所带来的性能开销。\n\n如果内存不足该区域会抛出 OutOfMemoryError 异常，并且后面会跟“Java heap space”字样。下面的示例会导致堆内存 OOM：\n\n```java\nList<byte[]> bytes = new ArrayList<>();\nwhile (true) {\n    bytes.add(new byte[1024 * 1024]);\n}\n```\n\n当出现堆内存 OOM 时不应该马上调大堆内存，而是应该通过内存映像分析工具（比如 [MAT: Eclipse Memory Analyzer](https://www.eclipse.org/mat/)）对 dump 出来的堆内存转储快照进行分析，以确定是 __内存泄露__ ，还是 __内存溢出__ ，如果是前者则调再大也无济于事，此时需要进一步查看对象到 GC Roots 的引用链。\n\n#### 方法区\n\n方法区同样是线程共享的一块区域，用于存储已被虚拟机加载的 __类型信息、常量、静态变量，以及即时编译器编译后的代码缓存__ 等数据。既然是线程共享的，就需要一定的同步策略来保证线程安全，对于方法区来说一个类只能被一个线程加载，且只能被加载一次，从而保证方法区中存储的各个类的类信息只有一份。\n\n此区域垃圾收集效果不佳，所以 JVM 规范对此区域的垃圾收集不强制要求，一些虚拟机选择在这一区域设置永久代。需要注意的一点是永久代这一概念正在逐步被废弃，因为其设计容易导致内存溢出问题。以 HotSpot 虚拟机为例，在 java 8 中已经完全废弃了永久代的概念，取而代之的是在 __本地内存__ 中实现的元空间（Metaspace），这点上基本向 JRockit 和 J9 看齐。\n\n对于每个被装载的类，虚拟机都会在方法区内记录如下类信息：\n\n1. 类的全限定名称\n2. 类的直接父类的全限定名称\n3. 类或接口类型标识信息\n4. 类的访问修饰符\n5. 类实现接口的全限定名称有序列表\n6. 类的运行时常量池\n7. 字段信息\n8. 方法信息\n9. 静态（类）变量\n10. 类加载器引用\n11. 类 Class 引用\n\n下面针对上述列表中的一些名词作进一步解释：\n\n- __运行时常量池__\n\n运行时常量池用于存放类或接口中定义的常量，包括直接常量和对其它类型、字段和方法的符号引用，从编译期可知的数值字面量到需要在运行期解析后才能获得的方法或字段的引用。既然命名为运行时常量池，就说明这一块区域是动态的，允许运行时写入，一个典型的示例就是当我们调用 `String#intern` 方法将字符串写入运行时常量池。\n\n常量池中的数据项类似数组一样通过索引进行访问，因为存储了类所用到的所有类型、字段和方法的符号引用，所以在动态连接中起着核心作用。\n\n- __字段信息__\n\n字段信息包括：字段名称、字段类型，以及字段访问修饰符。比如：\n\n```java\nprivate String name;\n```\n\n需要注意的是，我们一般也称其为属性，但是实际上两者还是存在一些不同的。通常属性是通过 getter 和 setter 方法推断出来的，比如 `getAge()`，我们可以认为有一个名为 age 的属性，但是字段就是上面我们真实定义的。除了字段信息之外，字段声明的顺序也记录在方法区中。\n\n- __方法信息__\n\n方法信息包括：方法名称、参数列表、返回类型、访问修饰符。对于非 abstract 和非 native 方法，还必须包含：方法字节码、操作数栈和栈帧中局部变量表的大小、异常表。除了方法信息，方法声明的顺序也记录在方法区中。\n\n##### 控制参数\n\n参数 | 默认值 | 说明\n--- | --- | ---\n`-XX:PermSize` | | 设置方法区初始内存大小\n`-XX:MaxPermSize` | | 设置方法区内存大小上限\n\n当方法区内存不足时会抛出 OutOfMemoryError 异常，并且后面跟“PermGen space”字样。\n\n#### 直接内存\n\n首先需要声明 __直接内存并不是运行时数据区的一部分，也不是 JVM 规范中定义的内存区域__ 。Java 的 NIO 可以通过使用 native 函数库直接分配堆外内存，然后通过一个存储在 java 堆中的 DirectByteBuffer 对象作为这块内存对象的引用，这样可以避免在 java 堆和 native 堆间来回复制数据。\n\n##### 控制参数\n\n参数 | 默认值 | 说明\n--- | --- | ---\n`-XX:MaxDirectMemorySize` | 与 `-Xmx` 值相同 | 设置直接内存大小上限\n\n直接内存大小的分配往往受制于宿主机总内存，如果我们在设置 JVM 参数时忽略了直接内存大小的设置，导致总的内存大小上限超过了宿主机总内存，就会导致 OOM。直接内存溢出的一个明显特征就是堆内存转储文件中没有明显异常，而且一般都是 NIO 引发的。如果发现堆内存 dump 文件很小，且程序中直接或间接使用了 NIO，则可以考虑是不是直接内存溢出。\n\n### 线程私有区域\n\n#### 程序计数器（PC 寄存器）\n\n程序计数器是线程私有的一块内存区域，大小是一个字长（至少应该能够保存一个 returnAddress 类型的数据，或一个与平台相关的本地指针的值），用于控制线程执行代码的流程。我们可以直观上将其理解为线程所执行的字节码的行号指示器，用于指定下一条待执行的指令。\n\n> 说明：returnAddress 类型目前已经很少使用，该类型主要为字节码指令 jsr、jsr_w 和 ret 服务，指向一条字节码指令的地址，一些较老的 JVM 曾经使用这几条指令来实现异常处理时的跳转，但现在基本都采用变量表予以替换。\n\nJVM 中线程的运行需要依赖于 CPU 分配时间片，拿到时间片的线程切换到运行态。多线程程序在执行时会出现多个线程间切换上下文的情况，所以我们需要一个程序计数器以存储线程下一条需要执行的指令。当线程拿到 CPU 时间片的时候，可以知道该执行什么，从而最终实现 __分支、循环、跳转、异常处理，以及线程恢复等__ 基础逻辑。所以程序计数器只能是线程私有的，不然就乱套了，此外程序计数器也是 __唯一一个没有 OOM 的区域__ 。\n\n__注意__ ：对于 java 方法，计数器存储的是正在执行的虚拟机字节码指令的地址，如果是 native 方法则计数器为空（undefined）。\n\n#### Java 虚拟机栈\n\n个人觉得命名为 java 方法栈会更加已于理解，与本地方法栈相呼应。\n\n如果粗略的对虚拟机内存区域进行分类，可以分为 __堆__ 和 __栈__ 两大块，其中堆就是指前面所介绍的 java 堆，而栈就是指这里的 java 虚拟机栈。Java 虚拟机栈描述的是 java 方法执行的内存模型，它与线程同生命周期，当然也是线程私有的。Java 的每个方法在执行时都会创建一个 __栈帧（Stack Frame）__ ，用来存放局部变量表、操作数栈、动态连接，以及方法出口等信息。 __一个方法从调用到执行完成的过程，就对应着一个栈帧在虚拟机中从入栈到出栈的过程__ 。\n\n之所以存在栈帧的概念，是因为 java 编译器输出的指令流基本上是一种 __基于栈的指令集架构__ ，因为依赖于栈进行操作，所以这类指令流中的大部分指令都是 __零地址指令__ 。与基于栈的指令集架构相对应的是 __基于寄存器的指令集架构__ ，相对于该指令集架构而言，基于栈的指令集架构具备可移植性（因为不依赖于寄存器）、代码相对紧凑，以及编译器实现更加简单的优点，但因为执行过程中需要频繁出栈入栈，且执行相同逻辑需要的指令更多，所以在执行速度上要逊色于寄存器指令架构。\n\n##### 栈帧\n\n栈帧用于存储局部变量表、操作数栈、动态连接，以及方法出口信息。栈帧随着方法的被调用而创建，并随着方法的结束运行（不管是正常结束还是异常结束）而被销毁。栈帧是线程本地私有的数据，不可能在一个栈帧中引用另外一个线程的栈帧。\n\n- __局部变量表__\n\n局部变量表（Local Variables Table）用于存放方法参数和方法内部定义的局部变量，其容量在编译期确定（因为只存 8 种基本类型变量和对象的引用地址，所以容量可以事先计算），记录在 Code 属性的 `max_locals` 字段中。当一个方法被调用时，JVM 会使用局部变量表来完成实参到形参的传递。在变量类型层面，支持存放编译期可知的各种基本数据类型、引用类型，以及 returnAddress 类型数据，是一个以字长为单位，从 0 开始计数的数组。一个局部变量表可以保存一个类型为 boolean、byte、char、short、int、folat、reference，或 returnAddress 类型的数据，两个连续的局部变量表可以保存一个类型为 long 或 double 类型的数据，其中 byte、short、char，以及 boolean 都会被转成 int 类型进行存储（只有在堆和方法区中才会以原类型存储）。一个方法的局部变量表所占据的内存空间大小可以在编译期确定，当进入一个方法时会依据该大小值为局部变量表申请分配内存空间，且在方法运行期间不会发生改变。\n\n```java\n// 类方法\npublic static int classMethod(int i, long l, float f, double d, Object obj, byte b) {\n    return 0;\n}\n\n// 实例方法\npublic int instanceMethod(char c, double d, short s, boolean b, float f) {\n    return 0;\n}\n```\n\n假设某个类包含上面代码块中的两个方法，其中 classMethod 是类方法，而 instanceMethod 是实例方法，则这两个方法在局部变量表中的存储结构如下图所示：\n\n![image](/images/2016/jvm-local-variable-table.png)\n\n所有的参数都严格按照声明的顺序存储在局部变量表中，对于定义在方法内部的局部变量来说，其存储顺序则不一定按照声明的顺序，甚至在前面声明的局部变量生命周期已经结束的情况下，后面声明的局部变量可以覆盖掉该局部变量在变量表中对应的索引位置。其中需要注意的有 3 点：\n\n1. 所有的 byte、short、char、boolean 类型都转换成了 int 类型进行存储；\n2. 实例方法的 0 号索引位置是对 this 指针的引用，实例方法是属于具体类实例的，需要通过 this 指针来知晓当前隶属的对象；\n3. 参数 Object 类型在局部变量表中是以 reference 类型进行存储，该引用指向堆中的具体对象， __在局部变量表和操作数栈中永远都不会直接存储对象（包括堆中对象的拷贝）__ 。\n\n- __操作数栈__\n\n操作数的定义可以简单理解为当前执行计算所操作的对象，在 java 虚拟机栈中没有寄存器的概念，所以计算操作的存储位置基本上都是基于操作数栈来完成的。之所以取名为栈是因为对于操作数栈的操作是完全按照栈的操作出栈、入栈，而不是像局部变量表那样基于索引来定位。\n\n每一个操作数栈都会拥有一个明确的栈深度用于存储数值，一个 32bit 的数值可以用一个单位的栈深度来存储，而 2 个单位的栈深度则可以保存一个 64bit 的数值。操作数栈所需的容量大小同样可以在编译期被完全确定下来，并保存在方法的 Code 属性中（`max_stacks` 数据项）。\n\n虚拟机在操作数栈中存储数据的方式和在局部变量表中是一样的，对于 byte、short、boolean，以及 char 类型的值在压入到操作数栈之前，也会被转换为 int 类型。虚拟机把操作数栈作为它的工作区，大多数指令都要从这里弹出数据，执行运算，最后把结果压回操作数栈。\n\n假设我们现有下面这样一段简单的求和代码：\n\n```java\npublic void add(int a, int b) {\n    int c = a + b;\n}\n```\n\n对应的字节码如下：\n\n```java\npublic void add(int, int);\n    Code:\n       0: iload_1\n       1: iload_2\n       2: iadd\n       3: istore_3\n       4: return\n```\n\n整段字节码指令的执行过程如下图所示：\n\n![image](/images/2016/jvm-operand-stack.png)\n\n执行过程如图示的非常清楚，不再多做描述，可以看到操作数栈就相当于一个栈结构的数据缓存区域，栈顶永远存储着当前操作所需要的操作数。\n\n- __动态连接__\n\n每个栈帧都持有一个指向运行时常量池中该栈帧所属方法的引用，用于支持方法调用过程中的动态连接（Dynamic Linking）。字节码中的方法调用指令以常量池中指向方法的符号引用作为参数，这些符号引用一部分会在类加载阶段或首次使用时被解析成直接引用，这种转换被称为 __静态解析__ ；另外一部分将在每次运行期间被转换成直接引用，称为 __动态连接__ 。\n\n- __方法返回地址__\n\n方法的退出分为正常调用完成和异常调用完成两种：\n\n- __正常退出__ ：执行引擎遇到任意的方法返回指令，退出当前方法，并将返回值传递给上层方法调用者。\n- __异常退出__ ：方法执行期间遇到未被妥善处理的异常，此时不会给上层方法调用者传递返回值。\n\n不论何种形式的退出，当一个方法退出执行后必须回到最初方法被调用的位置。\n\n##### 控制参数\n\n参数 | 默认值 | 说明\n--- | --- | ---\n`-Xss` | | 设置每个线程的栈内存大小\n\n该区域包含两种异常类型：\n\n- StackOverflowError：线程请求的栈深度超过 java 虚拟机栈所允许的最大深度。\n- OutOfMemoryError：执行动态扩容时申请不到足够多的内存，或者在创建新的线程时没有足够多的内容予以分配。\n\n当我们在递归调用的时候，如果设计不当就很容易触发 StackOverflowError 异常。此外对于多线程应用来说，如果我们将每个线程的栈内存设置得越大，就越容易出现 OOM，因为每个线程都消耗一份内存。当出现这类情况的时候，如果不能减少线程数或者更换 64 位虚拟机（更换 64 位虚拟机可以增大单个进程使用的内存上限，一个 JVM 启动起来就是一个进程，所以 JVM 运行时数据区所使用的内存受制于该上限），则应该减少栈内存。\n\nJVM 规范既允许 java 虚拟机栈被实现成固定大小，也允许对其进行动态扩容和收缩，HotSpot 虚拟机的栈容量是不允许动态扩容的。\n\n#### 本地方法栈\n\n本地方法栈和 java 虚拟机栈的作用是相似的，区别在于前者服务于 native 方法，而后者服务于 java 方法（是不是叫 java 方法栈更加容易理解一些）。与 java 虚拟机栈一样，本地方法栈也存在 StackOverflowError 和 OutOfMemoryError 两类异常。\n\n##### 控制参数\n\n参数 | 默认值 | 说明\n--- | --- | ---\n`-Xoss` | | 设置每个线程的栈内存大小\n\n有些虚拟机并不区分虚拟机栈和本地方法栈，例如 HotSpot 就直接将二者合二为一，所以就算设置 `-Xoss` 参数也是无效的。\n\n### 参考\n\n1. [Java 虚拟机规范（Java SE 8 版）](https://book.douban.com/subject/26418340/)\n2. [深入理解 java 虚拟机（第 2 版）](https://book.douban.com/subject/24722612/)\n3. [深入理解 java 虚拟机（第 3 版）](https://book.douban.com/subject/34907497/)\n","tags":["JVM"],"categories":["java"]},{"title":"Java 语言实现单例模式的若干种方式","url":"/2016/10/15/design-pattern/singleton/","content":"\n在面向对象程序设计中，只要内存允许我们通常都可以为一个对象创建任意多个实例，但是一些场景下这不一定是一件好的事情。考虑一个文件类，在被使用之前需要从磁盘加载一定量的数据，我们肯定不希望每次调用该对象都去执行数据加载的操作，不仅费时，而且同样的数据因为一个对象的实例化操作就要在内存中重复存储一份，显然是对内存的一种浪费。这个时候我们就希望对数据的加载操作只执行一次，后面所有的调用都是对这份数据的复用，而这也正式单例模式的应用场景。\n\n如果可以任意的创建对象，那么当我们希望内存中仅保有一份实例，就必须让所有的程序开发人员维持一个约定，只实例化该对象一次，然而现实是对象是可以任意被实例化的，约定开发人员是不现实的。这个时候我们就需要从开发人员手中剥夺对目标对象实例化的权利，而由单例模式去控制对象的创建，并暴露给开发人员一个获取对象实例的入口。<!-- more -->\n\n单例模式广泛应用于我们的程序设计之中，比如缓存实例、窗口实例，以及计数器等等，是程序设计中最常用的设计模式之一。\n\n### 饿汉式\n\n```java\npublic class EagerSingleton {\n\n    private static final EagerSingleton INSTANCE = new EagerSingleton();\n\n    /**\n     * 私有构造函数\n     */\n    private EagerSingleton() { }\n\n    public static EagerSingleton getInstance() {\n        return INSTANCE;\n    }\n\n}\n```\n\n饿汉式的优点在于实现简单，无须考虑线程安全问题，但是因为在编译期就已经完成实例化对象，如果该对象一直不被使用则是对内存的浪费，此外此种方式会增加编译期时长。\n\n### 基于枚举的饿汉式\n\n```java\npublic enum EnumSingleton {\n\n    INSTANCE;\n\n    public void otherMethod() {\n\n    }\n\n}\n```\n\n相对于传统饿汉式，基于枚举的饿汉式具备饿汉式所有的优点，同时更加简单。此外，基于枚举的饿汉式还有一个非常重要的特性，就是 __防止反序列化创建新的对象__ ，测试如下：\n\n```java\npublic class EnumSingletonTest implements Serializable {\n\n    private static final long serialVersionUID = 991713955127096061L;\n\n    @Test\n    public void test() throws Exception {\n        // 枚举类型反序列化得到的还是原对象\n        EnumSingleton newInstance = this.deserialize(this.serialize(EnumSingleton.INSTANCE));\n        Assert.assertEquals(EnumSingleton.INSTANCE, newInstance);\n\n        // 普通类型反序列化会创建新的对象\n        EnumSingletonTest newInstance2 = this.deserialize(this.serialize(this));\n        Assert.assertNotEquals(this, newInstance2);\n\n    }\n\n    private byte[] serialize(Object obj) throws IOException {\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        ObjectOutputStream oos = new ObjectOutputStream(baos);\n        try {\n            oos.writeObject(obj);\n            oos.flush();\n            return baos.toByteArray();\n        } finally {\n            oos.close();\n        }\n    }\n\n    private <T> T deserialize(byte[] bytes) throws Exception {\n        ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(bytes));\n        try {\n            return (T) ois.readObject();\n        } finally {\n            ois.close();\n        }\n    }\n}\n```\n\n枚举类型之所以在反序列化时不会创建新的对象是因为 java 对于枚举类型的序列化操作进行了特殊处理。相对于普通对象，java 在序列化枚举对象时实际上只是调用 ``Enum#name`` 方法获取当前对象的 name 值，并将 name 值进行序列化存储，当执行反序列化时实际上是拿到 name 值，然后通过调用 `Enum#valueOf` 方法获取 name 值对应的枚举对象。此外，为了防止破坏该机制，所有自定义的 writeObject、readObject、readObjectNoData、writeReplace，以及 readResolve 方法在执行序列化操作时都会被忽略。官方文档如下：\n\n> __Serialization of Enum Constants__\n>\n> Enum constants are serialized differently than ordinary serializable or externalizable objects. The serialized form of an enum constant consists solely of its name; field values of the constant are not present in the form. To serialize an enum constant, ObjectOutputStream writes the value returned by the enum constant's name method. To deserialize an enum constant, ObjectInputStream reads the constant name from the stream; the deserialized constant is then obtained by calling the java.lang.Enum.valueOf method, passing the constant's enum type along with the received constant name as arguments. Like other serializable or externalizable objects, enum constants can function as the targets of back references appearing subsequently in the serialization stream.\n>\n> The process by which enum constants are serialized cannot be customized: any class-specific writeObject, readObject, readObjectNoData, writeReplace, and readResolve methods defined by enum types are ignored during serialization and deserialization. Similarly, any serialPersistentFields or serialVersionUID field declarations are also ignored--all enum types have a fixed serialVersionUID of 0L. Documenting serializable fields and data for enum types is unnecessary, since there is no variation in the type of data sent.\n\n不过 java 1.5 之后才有枚举类，所以之前的 JDK 没有这样的福利，不过现在的 JDK 版本基本上都是 1.6 之后，所以对于饿汉式而言 __大力推荐__ 这类方式。\n\n对于其它单例模式的实现方式，如果希望能够在反序列化时不创建新的对象，我们可以实现 readResolve 方法，并在该方法中返回单例对象，如下：\n\n```java\npublic class EnumSingletonTest implements Serializable {\n\n    private static final long serialVersionUID = 991713955127096061L;\n\n    private static final EnumSingletonTest INSTANCE = new EnumSingletonTest();\n\n    @Test\n    public void test() throws Exception {\n        // 反序列化操作没有创建新的对象\n        EnumSingletonTest newInstance2 = this.deserialize(this.serialize(INSTANCE));\n        Assert.assertEquals(INSTANCE, newInstance);\n\n    }\n\n    /**\n     * 防止反序列化创建新的对象\n     *\n     * @return\n     * @throws ObjectStreamException\n     */\n    private Object readResolve() throws ObjectStreamException {\n        return INSTANCE;\n    }\n\n    // ... 省略序列化和反序列化方法\n}\n```\n\n### 懒汉式\n\n```java\npublic class LazySingleton {\n\n    private static LazySingleton instance;\n\n    /**\n     * 私有的构造方法\n     */\n    private LazySingleton() { }\n\n    public synchronized static LazySingleton getInstance() {\n        if (null == instance) {\n            instance = new LazySingleton();\n        }\n        return instance;\n    }\n\n}\n```\n\n懒汉式相对于饿汉式的最大优点在于 __按需实例化对象__ ，懒汉式没有在编译期就触发对象实例化，而是推迟到 getInstance 方法第一次被调用的时候。也正因为如此，我们需要考虑线程安全问题，常规的懒汉式直接简单粗暴的在 getInstance 方法前面加了一个 `synchronized` 关键字修饰，这样虽然保证了线程安全但也严重降低了性能，不太推荐这种方式。\n\n### 基于双重检锁的懒汉式\n\n```java\npublic class DoubleCheckSingleton {\n\n    // 须使用 volatile 关键字修饰\n    private volatile static DoubleCheckSingleton instance;\n\n    private DoubleCheckSingleton() { }\n\n    public static DoubleCheckSingleton getInstance() {\n        if (null == instance) {\n            synchronized (DoubleCheckSingleton.class) {\n                if (null == instance) {\n                    instance = new DoubleCheckSingleton();\n                }\n            }\n        }\n        return instance;\n    }\n\n}\n```\n\n为了提高普通懒汉式的性能，出现了 __双重检查加锁机制（DCL: Double-Checked Locking）__ 。这样就可以保证在对象实例化之后，对于获取对象的操作只需要执行一次 if 判断即可，不需要阻塞，从而极大提升性能。为了保证对象实例的线程可见性，所以对象实例需要使用关键字 volatile 修饰，但是因为 1.4 以及更早版本的 JDK 中，许多 JVM 实现对于 volatile 关键字的检查会导致双重检查加锁失效，所以这种方式仅能够在 JDK 1.5 版本之后使用。\n\n__为什么需要两次判 null ?__\n\n在此说明一下为什么需要用两次判 null，考虑有线程 1 和线程 2 都经过第一个 if 来到 `synchronized` 前面，假设此时 1 拿到了锁进入了同步块，等 1 出了同步块之后释放了锁，此时 2 拿到了锁进入了同步块，如果此时不再次判 null，则会再次实例化对象从而达不到单例的目的。\n\n__为什么必须使用 volatile 关键字修饰？__\n\n在具体分析之前我们需要知道 volatile 关键字具备的两大特性：1.保证线程可见性；2.禁止指令重排。考虑上面的示例，如果不加 volatile 修饰会怎么样呢，这里先给出结论：__如果不加 volatile 修饰，那么某个线程读取到的不为 null 的对象实例可能还未被初始化__。\n\n一个对象的实例化过程可以简单的抽象为如下三个步骤：\n\n1. 为对象分配内存空间；\n2. 初始化对象；\n3. 将内存空间地址赋值给对应的变量。\n\nJIT 在编译上述过程指令时依据优化策略可能会对上述步骤进行重排序，比如将 3 排序到 2 的前面，这个时候在并发环境下就存在问题。假设线程 A 进入了临界区执行对象的实例化操作，由于 3 排在了 2 的前面，所以在线程 A 执行完 3 之后 instance 变量已不为 null，但是此时还没有执行 2，所以 instance 还没有被初始化，是一个不完整的对象。假设此时线程 B 到达第一个 if 语句，因为此时 instance 不为 null 所以继续往后走，但是线程 B 并不知道当前的 instance 还没有被初始化，一旦使用该对象就会出现问题，而 volatile 禁止指令重排的内存语义可以避免上述情况的发生。\n\n### 登记式\n\n```java\npublic class RegisterSingleton {\n\n    private static Map<String, Object> registry = new HashMap<>();\n\n    static {\n        RegisterSingleton instance = new RegisterSingleton();\n        registry.put(instance.getClass().getName(), instance);\n    }\n\n    protected RegisterSingleton() {\n    }\n\n    public static RegisterSingleton getInstance(String name) {\n        if (null == name) {\n            name = \"org.zhenchao.singleton.RegisterSingleton\";\n        }\n        if (null == registry.get(name)) {\n            try {\n                registry.put(name, Class.forName(name).newInstance());\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n        return (RegisterSingleton) registry.get(name);\n    }\n}\n\npublic class ChildRegisterSingleton extends RegisterSingleton {\n\n    public ChildRegisterSingleton() { }\n\n    public static ChildRegisterSingleton getInstance() {\n        return (ChildRegisterSingleton) RegisterSingleton.getInstance(\"org.zhenchao.singleton.ChildRegisterSingleton\");\n    }\n\n}\n```\n\n因为懒汉式和饿汉式的不可继承性，所以引出了登记式，常规的登记式通过在父类维持一个 map 以记录子类的实例，从而保证每次子类调用 getInstance 方法都能返回唯一的实例。然而，事情没有想象的那么美好，因为父类的构造函数是 `protected` 修饰的，所以子类的构造函数也必须由 `protected` 及以上宽泛权限的修饰符修饰，这样就会导致我们可以通过 `new` 关键字实例化子类，而无需将该实例注册到父类。除此之外，父类在创建实例的过程也存在线程安全问题，所以 __无视这一方法吧__ 。\n\n### 基于静态内部类的登记式\n\n```java\npublic class InnerClassSingleton {\n\n    private static class InnerClass {\n        private static InnerClassSingleton instance = new InnerClassSingleton();\n    }\n\n    /**\n     * 私有构造方法\n     */\n    private InnerClassSingleton() { }\n\n    public static InnerClassSingleton getInstance() {\n        return InnerClass.instance;\n    }\n}\n```\n\n基于静态内部类的登记式方式可以达到 __懒加载__ 的目的，同时实现简单，又无需考虑多线程问题，所以比较推荐。该方式依赖于 JVM 在初始化类时会进行加锁处理，java 语言规范规定对于每一个类或接口都有一个唯一的初始化锁与之对应，这一部分的具体执行逻辑由 JVM 实现，从而保证一个类在运行期间仅被初始化一次。\n\n最后还是需要提醒一下， __所有的单例都是针对同一个 ClassLoader 加载而言的__ ，如果是不同的 ClassLoader 则无单例可言。\n","tags":["设计模式"],"categories":["design-pattern"]},{"title":"Java 8th 函数式编程：默认接口方法","url":"/2016/10/07/java/java8-default-method/","content":"\nJava 8th 可以看做是 java 版本更新迭代过程中变化最大的几个版本之一（与时俱进，方能不灭），但是经过这么多年的发展和迭代，java 的源码俨然已是一个庞然大物，要在这样庞大的体积上大动干戈必定不易。所以当第一次看到默认接口方法的时候，我第一感觉就是这是设计人员在填自己之前挖的坑。\n\n从前几篇的讲解中我们知道 8th 在现有的接口上添加了许多方法，比如 List 的 `sort(Comparator<? super E> c)` 方法。如果按照 8th 之前接口的设计思路，当给一个接口添加方法声明的时候，实现该接口的类都必须为该新添加的方法添加相应的实现（或将自己设置为抽象类）。考虑兼容性这样是不可取的，所以说这是一个坑，而新的特性又要求不得不为接口添加一些新的方法，为了兼得鱼和熊掌，设计人员提出了默认接口方法的概念。<!-- more -->\n\n### 一. 默认接口方法的定义\n\n默认接口方法的定义很简单，只要在接口的方法定义前添加一个 `default` 关键字即可，如下：\n\n```java\npublic interface A {\n\n    /**\n     * 默认方法定义\n     */\n    default void method() {\n        System.out.println(\"This is a default method!\");\n    }\n\n}\n```\n\n当我们定义了一个默认接口方法之后，所有实现该接口的子类都间接持有了该方法。或许你会和我一样觉得接口和抽象类越来越像了，确实，不过它们之间还是有如下差别：\n\n> 1. 一个类只能继承一个类，但是可以实现多个接口\n> 2. 抽象类可以定义变量，而接口却不能\n\n除了上面提及到的区别，接口方法还具有如下优点：\n\n> 1. 对于一些不是每个子类都需要的方法，我们给它一个默认实现，从而避免子类中的无意义实现（一般我们都会直接 `throw new UnsupportedException()`）\n> 2. 默认方法为 java 的多重继承机制提供了新途径（虽然我们只能继承一个类，但是我们可以实现多个接口啊，现在接口也可以定义默认方法了）\n\n### 二. 冲突及其解决方法\n\n一个类可以实现多个接口，当一个类实现了多个接口，而这些接口中存在两个或两个以上方法签名相同的默认方法时就会产生冲突，8th 定义如下三条原则以解决冲突：\n\n> 1. 类或父类中显式声明的方法，其优先级高于所有的默认方法\n> 2. 如果 1 规则失效，则选择与当前类距离最近的具有具体实现的默认方法\n> 3. 如果 2 规则也失效，则需要显式指定接口\n\n下面通过几个例子加以说明：\n\n- 例1\n\n```java\npublic interface A {\n    /**\n     * 默认方法定义\n     */\n    default void method() {\n        System.out.println(\"A's default method!\");\n    }\n}\n\npublic interface B extends A {\n    /**\n     * 默认方法定义\n     */\n    default void method() {\n        System.out.println(\"B's default method!\");\n    }\n}\n\npublic class C implements A, B {\n\n    public static void main(String[] args) {\n        new C().method();\n    }\n}\n\n// 输出：B's default method!\n```\n\n此处因为接口 B 相对于 A 距离 C 更近，同时 B 的 method 是一个具体的默认实现，依据规则 2，所以此处实际上调用的是接口 B 的默认方法。\n\n- 例2\n\n```java\npublic class D implements A {\n}\n\npublic class C extends D implements A, B {\n\n    public static void main(String[] args) {\n        new C().method();\n    }\n\n}\n\n// 输出：B's default method!\n```\n\n例 2 在原有接口 A 和 B 的基础上添加了一个实现接口 A 的类 D，然后类 C 继承于 D，并实现 A 和 B 接口，此处虽然 C 离 D 更近，但因为 D 的具体实现在 A 中，所以 B 中的默认方法还是距离最近的默认实现，依据规则 2，此处实际上调用的是 B 的默认方法。\n\n- 例3\n\n```java\n// A接口不变\n\npublic interface B {\n\n    /**\n     * 默认方法定义\n     */\n    default void method() {\n        System.out.println(\"B's default method!\");\n    }\n\n}\n\npublic class C implements A, B {\n\n    @Override\n    public void method() {\n        // 必须显式指定\n        B.super.method();\n    }\n\n    public static void main(String[] args) {\n        new C().method();\n    }\n\n}\n```\n\n例 3 中接口 B 不再继承自接口 A，所以此时 C 中调用默认方法 `method()` 距离接口 A 和 B 的具体实现距离相同，编译器无法确定，所以报错，此时需要显式指定：`B.super.method()`。\n","tags":["Java"],"categories":["java"]},{"title":"Java 8th 函数式编程：流式数据处理","url":"/2016/10/06/java/java8-stream/","content":"\n第一次接触到流式数据处理的时候，第一感觉是流式数据处理让集合操作变得简洁了许多，通常我们需要多行代码才能完成的操作，借助于流式数据处理可以在一行中实现。比如我们希望对一个包含整数的集合筛选出所有的偶数，并将其封装成为一个新的集合返回，那么在 8th 之前，我们需要通过如下代码实现：\n\n```java\nList<Integer> evens = new ArrayList<>();\nfor (final Integer num : nums) {\n    if (num % 2 == 0) {\n        evens.add(num);\n    }\n}\n```\n\n<!-- more -->\n\n借助 java 8th 的流式数据处理，我们可以将代码简化为：\n\n```java\nList<Integer> evens = nums.stream().filter(num -> num % 2 == 0).collect(Collectors.toList());\n```\n\n先简单解释一下上面这行代码的语义，`stream()` 操作将集合转换成一个流，`filter()` 执行我们自定义的筛选处理，这里是通过 lambda 表达式筛选出所有偶数，最后通过 `collect()` 对结果进行封装处理，并通过 `Collectors.toList()` 指定将结果封装成为一个 List 集合返回。\n\n由上面的例子可以看到流式数据处理能够极大简化对于集合的操作，实际上不光是集合，包括数组、文件等，只要是可以转换成流，我们都可以借助流式数据处理简化代码实现。8th 通过内部迭代来实现对流的处理，一个流式数据处理可以分为三个部分：转换成流、中间操作、终端操作。如下图：\n\n![image](/images/2016/java8-stream.png)\n\n以集合为例，一个流式数据处理操作我们首先需要调用 `stream()` 函数将其转换成流，再调用相应的 “中间操作” 达到我们需要对集合进行的处理，比如筛选、转换等，最后通过 “终端操作” 对前面的结果进行封装，返回我们需要的结果。\n\n### 一. 中间操作\n\n这里先定义一个简单的学生实体类，用于后面的例子演示：\n\n```java\npublic class Student {\n    private long id;\n    private String name;\n    private int age;\n    private int grade;\n    private String major;\n    private String school;\n\n    // 省略getter和setter\n}\n```\n\n```java\n// 初始化\nList<Student> students = new ArrayList<Student>() {\n    {\n        add(new Student(20160001, \"孔明\", 20, 1, \"土木工程\", \"武汉大学\"));\n        add(new Student(20160002, \"伯约\", 21, 2, \"信息安全\", \"武汉大学\"));\n        add(new Student(20160003, \"玄德\", 22, 3, \"经济管理\", \"武汉大学\"));\n        add(new Student(20160004, \"云长\", 21, 2, \"信息安全\", \"武汉大学\"));\n        add(new Student(20161001, \"翼德\", 21, 2, \"机械与自动化\", \"华中科技大学\"));\n        add(new Student(20161002, \"元直\", 23, 4, \"土木工程\", \"华中科技大学\"));\n        add(new Student(20161003, \"奉孝\", 23, 4, \"计算机科学\", \"华中科技大学\"));\n        add(new Student(20162001, \"仲谋\", 22, 3, \"土木工程\", \"浙江大学\"));\n        add(new Student(20162002, \"鲁肃\", 23, 4, \"计算机科学\", \"浙江大学\"));\n        add(new Student(20163001, \"丁奉\", 24, 5, \"土木工程\", \"南京大学\"));\n    }\n};\n```\n\n#### 1.1 过滤\n\n过滤，顾名思义就是按照给定的要求从集合中筛选出满足条件的元素，8th 提供的筛选操作包括：filter、distinct、limit、skip。\n\n- __filter__\n\n在前面的例子中已经演示了如何使用 filter，其定义为： `Stream<T> filter(Predicate<? super T> predicate)`，filter 接受一个谓词 `Predicate`，我们可以通过这个谓词定义筛选条件，在介绍 lambda 表达式时我们介绍过 `Predicate` 是一个函数式接口，它包含一个 `test(T t)` 方法，用于测试条件是否满足。现在我们希望从集合 `students` 中筛选出所有武汉大学的学生，那么我们可以通过 filter 实现，并将筛选操作以参数形式传递给 filter：\n\n```java\nList<Student> whuStudents = students.stream()\n        .filter(student -> \"武汉大学\".equals(student.getSchool()))\n        .collect(Collectors.toList());\n```\n\n- __distinct__\n\ndistinct 操作类似于我们在写 SQL 语句时添加的 `DISTINCT` 关键字，用于去重处理，distinct 基于 `Object.equals(Object)` 实现，以最开始的例子为例，假设我们希望筛选出所有不重复的偶数，那么可以添加 distinct 操作对筛选结果进行去重：\n\n```java\nList<Integer> evens = nums.stream()\n        .filter(num -> num % 2 == 0).distinct()\n        .collect(Collectors.toList());\n```\n\n- __limit__\n\nlimit 操作也类似于 SQL 语句中的 `LIMIT` 关键字，不过相对功能较弱，limit 返回包含前 n 个元素的流，当集合大小小于n时则返回实际长度，比如下面的例子返回前两个专业为土木工程的学生：\n\n```java\nList<Student> civilStudents = students.stream()\n        .filter(student -> \"土木工程\".equals(student.getMajor())).limit(2)\n        .collect(Collectors.toList());\n```\n\n说到 limit，不得不提及一下另外一个流操作： `sorted`。该操作用于对流中元素进行排序，sorted 要求待比较的元素必须实现 `Comparable` 接口，如果没有实现也不要紧，我们可以将比较器作为参数传递给 `sorted(Comparator<? super T> comparator)`，比如我们希望筛选出专业为土木工程的学生，并按年龄从小到大排序，筛选出年龄最小的两个学生，那么可以实现为：\n\n```java\nList<Student> sortedCivilStudents = students.stream()\n        .filter(student -> \"土木工程\".equals(student.getMajor()))\n        .sorted(Comparator.comparingInt(Student::getAge))\n        .limit(2)\n        .collect(Collectors.toList());\n```\n\n- __skip__\n\nskip 操作与 limit 操作相反，如同其字面意思一样，skip 用于跳过前 n 个元素，比如我们希望找出排序在第二名之后的土木工程专业的学生，那么可以实现为：\n\n```java\nList<Student> civilStudents = students.stream()\n        .filter(student -> \"土木工程\".equals(student.getMajor()))\n        .skip(2)\n        .collect(Collectors.toList());\n```\n\n通过 skip 方法就会跳过前面两个元素，返回由后面所有元素构造的流，如果 n 大于满足条件的集合的长度，则会返回一个空的集合。\n\n#### 1.2 映射\n\n在 SQL 中，借助 `SELECT` 关键字后面添加需要的字段名称，可以仅输出我们需要的结果字段，而流式数据处理的映射操作也同样用于实现这一操作，在流式数据处理中主要包含两类映射操作：map 和 flatMap。\n\n- __map__\n\n举例说明，假设我们希望筛选出所有专业为计算机科学的学生姓名，那么我们可以在 filter 筛选的基础之上，通过 map 将学生实体映射成为学生姓名字符串，具体实现如下：\n\n```java\nList<String> names = students.stream()\n        .filter(student -> \"计算机科学\".equals(student.getMajor()))\n        .map(Student::getName).collect(Collectors.toList());\n```\n\n除了上面这类基础的 map，java 8th 还提供了 `mapToDouble(ToDoubleFunction<? super T> mapper)`，`mapToInt(ToIntFunction<? super T> mapper)`，`mapToLong(ToLongFunction<? super T> mapper)` 映射分别返回对应类型的流，8th 为这些流设定了一些特殊的操作，比如我们希望计算所有专业为计算机科学学生的年龄之和，那么可以实现如下：\n\n```java\nint totalAge = students.stream()\n        .filter(student -> \"计算机科学\".equals(student.getMajor()))\n        .mapToInt(Student::getAge).sum();\n```\n\n通过将 Student 按照年龄直接映射为 `IntStream`，我们可以直接调用类型提供的 `sum()` 方法进行求和，此外使用这些数值流的好处还在于可以避免 jvm 装箱操作所带来的性能消耗。\n\n- __flatMap__\n\nflatMap 与 map 的主要区别在于 __flatMap 是将一个流中的每个值都转成一个个流，然后再将这些流扁平化成为一个流__ 。举例说明，假设我们有一个字符串数组 `String[] strs = {\"java8\", \"is\", \"easy\", \"to\", \"use\"};`，我们希望输出构成这一数组的所有非重复字符，那么可能会首先想到如下实现：\n\n```java\nList<String[]> distinctStrs = Arrays.stream(strs)\n        .map(str -> str.split(\"\"))  // 映射成为Stream<String[]>\n        .distinct()\n        .collect(Collectors.toList());\n```\n\n在执行 map 操作以后，我们得到是一个包含多个字符串（构成一个字符串的字符数组）的流，此时执行 distinct 操作是基于在这些字符串数组之间的对比，所以达不到我们希望的目的，此时的输出为：\n\n```text\n[j, a, v, a, 8]\n[i, s]\n[e, a, s, y]\n[t, o]\n[u, s, e]\n```\n\ndistinct 只有对于一个包含多个字符的流进行操作才能达到我们的目的，即对 `Stream<String>` 进行操作。此时 flatMap 就可以派上用场：\n\n```java\nList<String> distinctStrs = Arrays.stream(strs)\n        .map(str -> str.split(\"\"))  // 映射成为Stream<String[]>\n        .flatMap(Arrays::stream)  // 扁平化为Stream<String>\n        .distinct()\n        .collect(Collectors.toList());\n```\n\nflatMap 将由 map 映射得到的 `Stream<String[]>` 转换成由各个字符串数组映射成的流 `Stream<String>`，再将这些小的流扁平化成为一个由所有字符串构成的大扁平流 `Steam<String>`，从而达到我们的目的。\n\n与 map 类似，flatMap 也提供了针对特定类型的映射操作：`flatMapToDouble(Function<? super T,? extends DoubleStream> mapper)`，`flatMapToInt(Function<? super T,? extends IntStream> mapper)`，`flatMapToLong(Function<? super T,? extends LongStream> mapper)`。\n\n### 二. 终端操作\n\n终端操作是流式数据处理的最后一步，我们可以在终端操作中实现对流查找、归约等操作。\n\n#### 2.1 查找\n\n- __allMatch__\n\nallMatch 用于检测元素是否全部都满足指定的参数行为，如果全部满足则返回 true，例如我们希望检测是否所有的学生都已满 18 周岁，那么可以实现为：\n\n```java\nboolean isAdult = students.stream().allMatch(student -> student.getAge() >= 18);\n```\n\n- __anyMatch__\n\nanyMatch 则是检测是否存在一个或多个元素满足指定的参数行为，如果满足则返回 true，例如我们希望检测是否有来自武汉大学的学生，那么可以实现为：\n\n```java\nboolean hasWhu = students.stream().anyMatch(student -> \"武汉大学\".equals(student.getSchool()));\n```\n\n- __noneMathch__\n\nnoneMatch 用于检测是否不存在满足指定行为的元素，如果不存在则返回 true，例如我们希望检测是否不存在专业为计算机科学的学生，可以实现如下：\n\n```java\nboolean noneCs = students.stream().noneMatch(student -> \"计算机科学\".equals(student.getMajor()));\n```\n\n- __findFirst__\n\nfindFirst 用于返回满足条件的第一个元素，比如我们希望选出专业为土木工程的排在第一位的学生，那么可以实现如下：\n\n```java\nOptional<Student> optStu = students.stream().filter(student -> \"土木工程\".equals(student.getMajor())).findFirst();\n```\n\nfindFirst 不携带参数，具体的查找条件可以通过 filter 设置，我们可以发现 findFirst 返回的是一个 Optional 类型，关于 Optional 的具体讲解可以参考本系列对应的文章。\n\n- __findAny__\n\nfindAny 相对于 findFirst 的区别在于 findAny 不一定返回第一个，而是返回任意一个，比如我们希望返回任意一个专业为土木工程的学生，可以实现如下：\n\n```java\nOptional<Student> optStu = students.stream().filter(student -> \"土木工程\".equals(student.getMajor())).findAny();\n```\n\n实际上对于顺序流式数据处理而言，findFirst 和 findAny 返回的结果是一样的，至于为什么这样设计是因为在下一篇我们介绍的 __并行流式数据处理__ ，当我们启用并行流式数据处理的时候，查找第一个元素往往会有很多限制，如果不是特别需求，在并行流式数据处理中使用 findAny 的性能要比 findFirst 要高。\n\n#### 2.2 归约\n\n前面的例子中我们大部分都是通过 `collect(Collectors.toList())` 对数据进行封装返回，如果我们的目标不是返回一个新的集合，而是希望对经过参数化操作后的集合进行进一步的运算，那么我们可用对集合实施归约操作。8th 的流式数据处理提供了 `reduce` 方法来达到这一目的。\n\n前面我们通过 mapToInt 将 `Stream<Student>` 映射成为 `IntStream`，并通过该类型的 sum 方法求得所有学生的年龄之和，实际上我们通过归约操作也可以达到这一目的，实现如下：\n\n```java\n// 前面例子中的方法\nint totalAge = students.stream()\n        .filter(student -> \"计算机科学\".equals(student.getMajor()))\n        .mapToInt(Student::getAge).sum();\n\n// 归约操作\nint totalAge = students.stream()\n        .filter(student -> \"计算机科学\".equals(student.getMajor()))\n        .map(Student::getAge)\n        .reduce(0, (a, b) -> a + b);\n\n// 进一步简化\nint totalAge2 = students.stream()\n        .filter(student -> \"计算机科学\".equals(student.getMajor()))\n        .map(Student::getAge)\n        .reduce(0, Integer::sum);\n\n// 采用无初始值的重载版本，需要注意返回Optional\nOptional<Integer> totalAge = students.stream()\n        .filter(student -> \"计算机科学\".equals(student.getMajor()))\n        .map(Student::getAge)\n        .reduce(Integer::sum);  // 去掉初始值\n```\n\n#### 2.3 收集\n\n前面采用的 `collect(Collectors.toList())` 是一个简单的收集操作，是对处理结果的封装，对应的还有 `toSet`、`toMap` 可以满足我们对于结果组织的需求。这些方法均来自于 `java.util.stream.Collectors`，我们可以称之为收集器。\n\n##### 2.3.1 归约\n\n收集器也提供了相应的归约操作，但是与 reduce 在内部实现上是有区别的，收集器更加适用于可变容器上的归约操作，这些收集器广义上均基于 `Collectors.reducing()` 实现。\n\n- 例1：求学生的总人数\n\n```java\nlong count = students.stream().collect(Collectors.counting());\n\n// 进一步简化\nlong count = students.stream().count();\n```\n\n- 例2：求年龄的最大值和最小值\n\n```java\n// 求最大年龄\nOptional<Student> olderStudent = students.stream().collect(Collectors.maxBy((s1, s2) -> s1.getAge() - s2.getAge()));\n\n// 进一步简化\nOptional<Student> olderStudent2 = students.stream().collect(Collectors.maxBy(Comparator.comparing(Student::getAge)));\n\n// 求最小年龄\nOptional<Student> olderStudent3 = students.stream().collect(Collectors.minBy(Comparator.comparing(Student::getAge)));\n```\n\n- 例3：求年龄总和\n\n```java\nint totalAge4 = students.stream().collect(Collectors.summingInt(Student::getAge));\n```\n\n对应的还有 `summingLong`、`summingDouble`。\n\n- 例4：求年龄的平均值\n\n```java\ndouble avgAge = students.stream().collect(Collectors.averagingInt(Student::getAge));\n```\n\n对应的还有 `averagingLong`、`averagingDouble`。\n\n- 例5：一次性得到元素个数、总和、均值、最大值、最小值\n\n```java\nIntSummaryStatistics statistics = students.stream().collect(Collectors.summarizingInt(Student::getAge));\n```\n\n输出：\n\n```java\nIntSummaryStatistics{count=10, sum=220, min=20, average=22.000000, max=24}\n```\n\n对应的还有 `summarizingLong`、`summarizingDouble`。\n\n- 例6：字符串拼接\n\n```java\nString names = students.stream().map(Student::getName).collect(Collectors.joining());\n// 输出：孔明伯约玄德云长翼德元直奉孝仲谋鲁肃丁奉\nString names = students.stream().map(Student::getName).collect(Collectors.joining(\", \"));\n// 输出：孔明, 伯约, 玄德, 云长, 翼德, 元直, 奉孝, 仲谋, 鲁肃, 丁奉\n```\n\n##### 2.3.2 分组\n\n在数据库操作中，我们可以通过 `GROUP BY` 关键字对查询到的数据进行分组，流式数据处理也为我们提供了这样的功能 `Collectors.groupingBy` 来操作集合。比如我们可以按学校对上面的学生进行分组：\n\n```java\nMap<String, List<Student>> groups = students.stream().collect(Collectors.groupingBy(Student::getSchool));\n```\n\n`groupingBy` 接收一个分类器 `Function<? super T, ? extends K> classifier`，我们可以自定义分类器来实现需要的分类效果。\n\n上面演示的是一级分组，我们还可以定义多个分类器实现 __多级分组__ ，比如我们希望在按学校分组的基础之上再按照专业进行分组，实现如下：\n\n```java\nMap<String, Map<String, List<Student>>> groups2 = students.stream().collect(\n        Collectors.groupingBy(Student::getSchool,  // 一级分组，按学校\n        Collectors.groupingBy(Student::getMajor)));  // 二级分组，按专业\n```\n\n实际上在 `groupingBy` 的第二个参数不是只能传递 groupingBy，还可以传递任意 Collector 类型，比如我们可以传递一个 `Collector.counting`，用以统计每个组的个数：\n\n```java\nMap<String, Long> groups = students.stream().collect(Collectors.groupingBy(Student::getSchool, Collectors.counting()));\n```\n\n如果我们不添加第二个参数，则编译器会默认帮我们添加一个 `Collectors.toList()`。\n\n##### 2.3.3 分区\n\n分区可以看做是分组的一种特殊情况，在分区中 key 只有两种情况：true 或 false，目的是将待分区集合按照条件一分为二，流式数据处理利用 `ollectors.partitioningBy()` 方法实现分区，该方法接收一个谓词，例如我们希望将学生分为武大学生和非武大学生，那么可以实现如下：\n\n```java\nMap<Boolean, List<Student>> partition = students.stream().collect(Collectors.partitioningBy(student -> \"武汉大学\".equals(student.getSchool())));\n```\n\n分区相对分组的优势在于我们可以同时得到两类结果，在一些应用场景下可以一步得到我们需要的所有结果，比如将数组分为奇数和偶数。\n\n以上介绍的所有收集器均实现自接口 `java.util.stream.Collector`，该接口的定义如下：\n\n```java\npublic interface Collector<T, A, R> {\n    /**\n     * A function that creates and returns a new mutable result container.\n     *\n     * @return a function which returns a new, mutable result container\n     */\n    Supplier<A> supplier();\n\n    /**\n     * A function that folds a value into a mutable result container.\n     *\n     * @return a function which folds a value into a mutable result container\n     */\n    BiConsumer<A, T> accumulator();\n\n    /**\n     * A function that accepts two partial results and merges them.  The\n     * combiner function may fold state from one argument into the other and\n     * return that, or may return a new result container.\n     *\n     * @return a function which combines two partial results into a combined\n     * result\n     */\n    BinaryOperator<A> combiner();\n\n    /**\n     * Perform the final transformation from the intermediate accumulation type\n     * {@code A} to the final result type {@code R}.\n     *\n     * <p>If the characteristic {@code IDENTITY_TRANSFORM} is\n     * set, this function may be presumed to be an identity transform with an\n     * unchecked cast from {@code A} to {@code R}.\n     *\n     * @return a function which transforms the intermediate result to the final\n     * result\n     */\n    Function<A, R> finisher();\n\n    /**\n     * Returns a {@code Set} of {@code Collector.Characteristics} indicating\n     * the characteristics of this Collector.  This set should be immutable.\n     *\n     * @return an immutable set of collector characteristics\n     */\n    Set<Characteristics> characteristics();\n\n}\n```\n\n我们也可以实现该接口来定义自己的收集器，此处不再展开。\n\n### 三. 并行流式数据处理\n\n流式数据处理中的很多都适合采用 __分而治之__ 的思想，从而在处理较大集合时极大的提升代码的性能，8th 的设计者也看到了这一点，所以提供了 __并行流式数据处理__ 。上面的例子中我们都是调用 `stream()` 方法启动流式数据处理，8th 还提供了 `parallelStream()` 方法以启动并行流式数据处理，`parallelStream()` 本质上基于 jdk 1.7 的 Fork-Join 框架实现，其默认的线程数为宿主机的内核数。\n\n启动并行流式数据处理虽然简单，只需要将 `stream()` 替换成 `parallelStream()` 即可，但既然是并行，就会涉及到多线程安全问题，所以在启用之前要先确认并行是否值得（并行的效率不一定高于顺序执行），另外就是要保证线程安全。此两项无法保证，那么并行毫无意义，毕竟结果的正确性要比速度更加重要，以后有时间再来详细分析一下并行流式数据处理的具体实现和最佳实践。\n","tags":["Java"],"categories":["java"]},{"title":"Java 8th 函数式编程：Optional 类型","url":"/2016/09/24/java/java8-optional/","content":"\nNullPointException 可以说是所有 java 程序员都遇到过的一个异常，虽然 java 从设计之初就力图让程序员脱离指针的苦海，但是指针确实是实际存在的，而 java 设计者也只能是让指针在 java 语言中变得更加简单、易用，而不能完全的将其剔除，所以才有了我们日常所见到的关键字 `null`。\n\n空指针异常是一个运行时异常，对于这一类异常，如果没有明确的处理策略，那么最佳实践在于让程序早点挂掉，但是很多场景下不是开发人员没有具体的处理策略，而是根本没有意识到空指针异常的存在。当异常真的发生的时候，处理策略也很简单，在存在异常的地方添加一个 if 语句判定即可，但是这样的应对策略会让我们的程序出现越来越多的 null 判定。<!-- more -->一个良好的程序设计应该让代码中尽量少出现 null 关键字，而 8th 所提供的 `Optional` 类则在减少 NullPointException 的同时，也提升了代码的美观度。但首先我们需要明确的是它并 __不是对 null 关键字的替代策略，而是对于 null 判定提供了一种更加优雅的实现，从而尽可能地避免 NullPointException__ 。\n\n下面通过一个小示例直观感受一下，假设我们需要返回一个字符串的长度，如果不借助第三方工具类，我们需要调用 `str.length()` 方法：\n\n```java\nif(null == str) { // 空指针判定\n    return 0;\n}\nreturn str.length();\n```\n\n如果采用 Optional 类，实现如下：\n\n```java\nreturn Optional.ofNullable(str).map(String::length).orElse(0);\n```\n\nOptional 的代码相对更加简洁，当代码量较大时，我们很容易忘记进行 null 判定，但是使用 Optional 类则会避免这类问题。\n\n### 一. 基本使用\n\n#### 1.1 Optional 对象的创建\n\n- __创建空对象__\n\n```java\nOptional<String> optStr = Optional.empty();\n```\n\n上面的示例代码调用 `empty()` 方法创建了一个空的 `Optional<String>` 对象型。\n\n- __创建对象：不允许我空__\n\nOptional 提供了方法 `of()` 用于创建非空对象，该方法要求传入的参数不能为空，否则抛 `NullPointException`，示例如下：\n\n```java\nOptional<String> optStr = Optional.of(str);  // 当str为null的时候，将抛出NullPointException\n```\n\n- __创建对象：允许为空__\n\n如果不能确定传入的参数是否存在 null 值的可能性，则可以用 Optional 的 `ofNullable()` 方法创建对象，如果入参为 null 则创建一个空对象。示例如下：\n\n```java\nOptional<String> optStr = Optional.ofNullable(str);  // 如果str是null，则创建一个空对象\n```\n\n#### 1.2 流式数据处理\n\n流式数据处理也是 8th 给我们带来的一个重量级新特性，让我们对集合的操作变得更加简洁和高效，本系列下一篇将对流式数据处理进行全面的讲解。Optional 类也提供了两个基本的流失处理：映射和过滤。\n\n为了演示，我们设计了一个 `User` 类，如下：\n\n```java\npublic class User {\n    private long id;\n    private String name;\n    private int age;\n    private Optional<Long> phone;\n    private Optional<String> email;\n\n    public User(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    // 省略setter和getter\n}\n```\n\n手机和邮箱不是一个人的必须有的，所以我们利用 Optional 类定义。\n\n- __映射：map 与 flatMap__\n\n映射是将输入转换成另外一种形式的输出的操作，比如前面例子中我们输入字符串，而输出的是字符串的长度，这就是一种映射，我们利用方法 `map()` 进行实现。假设我们希望获得一个人的姓名，我们可以如下实现：\n\n```java\nString name = Optional.ofNullable(user).map(User::getName).orElse(\"no name\");\n```\n\n这样当入参 user 不为空的时候则返回其 name，否则返回 `no name`。如我我们希望通过上面方式得到 phone 或 email，利用上面的方式则行不通了，因为 map 之后返回的是 Optional，我们把这种称为 Optional 嵌套，我们必须再 map 一次才能拿到我们想要的结果：\n\n```java\nlong phone = optUser.map(User::getPhone).map(Optional::get).orElse(-1L);\n```\n\n其实这个时候更好的方式是利用 flatMap，一步拿到我们想要的结果：\n\n```java\nlong phone = optUser.flatMap(User::getPhone).orElse(-1L);\n```\n\nflapMap 可以将方法返回的各个流扁平化成为一个流，具体在下一篇专门讲流式数据处理的文章中细说。\n\n- __过滤：fliter__\n\nfiliter，顾名思义是过滤的操作，我们可以将过滤操作做为参数传递给该方法以实现过滤目的，假如我们希望筛选 18 周岁以上的成年人，则可以实现如下：\n\n```java\noptUser.filter(u -> u.getAge() >= 18).ifPresent(u -> System.out.println(\"Adult:\" + u));\n```\n\n#### 1.3 默认行为\n\n默认行为是当 Optional 在不满足条件时所执行的操作，比如在上面的例子中我们使用的 `orElse()` 就是一个默认操作，用于在 Optional 对象为空时执行特定操作，当然也有一些默认操作是当满足条件的对象存在时执行的操作。\n\n- __get()__\n\nget 方法用于获取变量的值，但是当变量不存在时则会抛出 `NoSuchElementException`，所以如果不确定变量是否存在则不建议使用\n\n- __orElse(T other)__\n\n当 Optional 的变量不满足给定条件时，则执行 orElse，比如前面当 str 为 null 时返回 0。\n\n- __orElseGet(Supplier<? extends X> expectionSupplier)__\n\n如果条件不成立时需要执行相对复杂的逻辑而不是简单的返回操作，则可以使用 orElseGet 实现：\n\n```java\nlong phone = optUser.map(User::getPhone).map(Optional::get).orElseGet(() -> {\n    // do something here\n    return -1L;\n});\n```\n\n- __orElseThrow(Supplier<? extends X> expectionSupplier)__\n\n与 `get()` 方法类似，都是在不满足条件时返回异常，不过这里我们可以指定返回的异常类型。\n\n- __ifPresent(Consumer<? super T>)__\n\n当满足条件时执行传入的参数化操作。\n\n### 二. 注意事项\n\nOptional 是一个 final 类且未实现任何接口，所以当我们在利用该类包装定义类的属性的时候，如果我们定义的类有序列化的需求，那么因为 Optional 没有实现 Serializable 接口，这个时候执行序列化操作就会有问题：\n\n```java\npublic class User implements Serializable {\n    private long id;\n    private String name;\n    private int age;\n    private Optional<Long> phone;  // 不能序列化\n    private Optional<String> email;  // 不能序列化\n}\n```\n\n不过我们可以采用如下替换策略 Optinal：\n\n```java\nprivate long phone;\n\npublic Optional<Long> getPhone() {\n    return Optional.ofNullable(this.phone);\n}\n```\n\n看来 Optional 类在设计的时候就没有考虑将它作为类的字段使用。\n\n最后提醒一点，Optional 好用但不能滥用，在设计一个接口方法时是否采取 Optional 类型返回需要斟酌，一味的使用会让代码变得比较啰嗦，反而破坏了代码的简洁性。\n","tags":["Java"],"categories":["java"]},{"title":"Java 8th 函数式编程：lambda 表达式","url":"/2016/09/17/java/java8-lambda/","content":"\nLambda 表达式是 java 8th 给我们带来的几个重量级新特性之一，借用 lambda 表达式可以让我们的程序设计更加简洁。最近新的项目摒弃了 6th 版本，全面基于 8th 进行开发，本文将探讨 __行为参数化__ 、__lambda 表达式__ ，以及 __方法引用__ 等知识点。\n\n### 一. 行为参数化\n\n行为参数化简单的说就是将方法的逻辑以参数的形式传递到方法中，方法主体仅包含模板类通用代码，而一些会随着业务场景而变化的逻辑则以参数的形式传递到方法之中，采用行为参数化可以让程序更加的通用，以应对频繁变更的需求。<!-- more -->\n\n这里我们以 [java 8 in action](https://book.douban.com/subject/26772632/) 中的例子进行说明。考虑一个业务场景，假设我们需要通过程序对苹果按照一定的条件进行筛选，我们先定义一个苹果实体：\n\n```java\npublic class Apple {\n    /** 编号 */\n    private Long id;\n    /** 颜色 */\n    private Color color;\n    /** 重量 */\n    private Float weight;\n    /** 产地 */\n    private String origin;\n\n    public Apple() {\n    }\n\n    public Apple(Long id, Color color, Float weight, String origin) {\n        this.id = id;\n        this.color = color;\n        this.weight = weight;\n        this.origin = origin;\n    }\n\n    // 省略getter和setter\n}\n```\n\n用户最开始的需求可能只是简单的希望能够通过程序筛选出绿色的苹果，于是我们可以很快的通过程序实现：\n\n```java\npublic static List<Apple> filterGreenApples(List<Apple> apples) {\n    List<Apple> filterApples = new ArrayList<>();\n    for (final Apple apple : apples) {\n        // 筛选出绿色的苹果\n        if (Color.GREEN.equals(apple.getColor())) {\n            filterApples.add(apple);\n        }\n    }\n    return filterApples;\n}\n```\n\n如果过了一段时间用户提出了新的需求，希望能够通过程序筛选出红色的苹果，于是我们又需要针对性的添加了筛选红色苹果的功能：\n\n```java\npublic static List<Apple> filterRedApples(List<Apple> apples) {\n    List<Apple> filterApples = new ArrayList<>();\n    for (final Apple apple : apples) {\n        // 筛选出红色的苹果\n        if (Color.RED.equals(apple.getColor())) {\n            filterApples.add(apple);\n        }\n    }\n    return filterApples;\n}\n```\n\n更通用的实现是把颜色作为一个参数传递到方法中，这样就可以应对以后用户提出的各种颜色筛选需求：\n\n```java\npublic static List<Apple> filterApplesByColor(List<Apple> apples, Color color) {\n    List<Apple> filterApples = new ArrayList<>();\n    for (final Apple apple : apples) {\n        // 依据传入的颜色参数进行筛选\n        if (color.equals(apple.getColor())) {\n            filterApples.add(apple);\n        }\n    }\n    return filterApples;\n}\n```\n\n这样的设计再也不用担心用户的颜色筛选需求变化了，但是不幸的是某一天用户提了一个需求希望能够筛选重量达到某一标准的苹果，有了前面的教训我们也把重量的标准作为参数传递给筛选函数：\n\n```java\npublic static List<Apple> filterApplesByColorAndWeight(List<Apple> apples, Color color, float weight) {\n    List<Apple> filterApples = new ArrayList<>();\n    for (final Apple apple : apples) {\n        // 依据颜色和重量进行筛选\n        if (color.equals(apple.getColor()) && apple.getWeight() >= weight) {\n            filterApples.add(apple);\n        }\n    }\n    return filterApples;\n}\n```\n\n这样通过传递参数的方式真的好吗？如果筛选条件越来越多，组合模式越来越复杂，我们是不是需要考虑到所有的情况，并针对每一种情况都实现相应的策略呢？并且这些函数仅仅是筛选条件的部分不一样，其余部分都是相同的模板代码（遍历集合），这个时候我们就可以将行为进行 __参数化__ 处理，让函数仅保留模板代码，而把筛选条件抽离出来当做参数传递进来，在 java 8th 之前，我们通过定义一个过滤器接口来实现：\n\n```java\n// 过滤器\npublic interface AppleFilter {\n    boolean accept(Apple apple);\n}\n\n// 应用过滤器的筛选方法\npublic static List<Apple> filterApplesByAppleFilter(List<Apple> apples, AppleFilter filter) {\n    List<Apple> filterApples = new ArrayList<>();\n    for (final Apple apple : apples) {\n        if (filter.accept(apple)) {\n            filterApples.add(apple);\n        }\n    }\n    return filterApples;\n}\n```\n\n通过上面行为抽象化之后，我们可以在具体调用的地方设置筛选条件，并将条件作为参数传递到方法中：\n\n```java\npublic static void main(String[] args) {\n    List<Apple> apples = new ArrayList<>();\n\n    // 筛选苹果\n    List<Apple> filterApples = filterApplesByAppleFilter(apples, new AppleFilter() {\n        @Override\n        public boolean accept(Apple apple) {\n            // 筛选重量大于100g的红苹果\n            return Color.RED.equals(apple.getColor()) && apple.getWeight() > 100;\n        }\n    });\n}\n```\n\n上面的行为参数化方式采用匿名类实现，这样的设计在 jdk 内部也经常采用，比如 `java.util.Comparator`，`java.util.concurrent.Callable` 等，使用这类接口的时候，我们都可以在具体调用的地方用匿名类指定函数的具体执行逻辑，不过从上面的代码块来看，虽然很极客，但是不够简洁，在 java 8th 中我们可以通过 lambda 表达式进行简化：\n\n```java\n// 筛选苹果\nList<Apple> filterApples = filterApplesByAppleFilter(apples,\n        (Apple apple) -> Color.RED.equals(apple.getColor()) && apple.getWeight() >= 100);\n```\n\n如上述所示，通过 lambda 表达式极大精简了代码，同时行为参数让我们的程序极大的增强了可扩展性。\n\n### 二. Lambda 表达式\n\n#### 2.1 Lambda 表达式的定义与形式\n\n我们可以将 lambda 表达式定义为一种 __简洁、可传递的匿名函数__ ，首先我们需要明确 lambda 表达式本质上是一个函数，虽然它不属于某个特定的类，但具备参数列表、函数主体、返回类型，甚至能够抛出异常；其次它是匿名的，lambda 表达式没有具体的函数名称；lambda 表达式可以像参数一样进行传递，从而简化代码的编写，其格式定义如下：\n\n> 1. 参数列表 -> 表达式\n> 2. 参数列表 -> {表达式集合}\n\n需要注意 lambda 表达式隐含了 return 关键字，所以在单个的表达式中，我们无需显式的写 return 关键字，但是当表达式是一个语句集合的时候则需要显式添加 return 关键字，并用花括号 `{}` 将多个表达式包围起来，下面看几个例子：\n\n```java\n// 1. 返回给定字符串的长度（隐含return语句）\n(String s) -> s.length()\n\n// 2. 始终返回42的无参方法（隐含return语句）\n() -> 42\n\n// 3. 包含多行表达式，需用花括号括起来，并显示添加return\n(int x, int y) -> {\n    int z = x * y;\n    return x + z;\n}\n```\n\n#### 2.2 基于函数式接口使用 lambda 表达式\n\nlambda 表达式的使用需要借助于 __函数式接口__ ，也就是说只有函数式接口出现地方，我们才可以将其用 lambda 表达式进行简化。那么什么是函数接口？函数接口的定义如下：\n\n> 函数式接口定义为仅含有一个抽象方法的接口。\n\n按照这个定义，我们可以确定一个接口如果声明了两个或两个以上的方法就不叫函数式接口，需要注意一点的是 java 8th 为接口的定义引入了默认的方法，我们可以用 `default` 关键字在接口中定义具备方法体的方法，这个在后面的文章中专门讲解，如果一个接口存在多个默认方法，但是仍然仅含有一个抽象方法，那么这个接口也符合函数式接口的定义。\n\n##### 2.2.1 自定义函数式接口\n\n我们在前面例子中实现的苹果筛选接口就是一个函数式接口（定义如下），正因为如此我们可以将筛选逻辑参数化，并应用 lambda 表达式：\n\n```java\n@FunctionalInterface\npublic interface AppleFilter {\n    boolean accept(Apple apple);\n}\n```\n\nAppleFilter 仅包含一个抽象方法 `accept(Apple apple)`，依照定义可以将其视为一个函数式接口。在定义时我们为该接口添加了 `@FunctionalInterface` 注解，用于标记该接口是一个函数式接口，不过该注解是可选的，当添加了该注解之后，编译器会限制了该接口只允许有一个抽象方法，否则报错，所以推荐为函数式接口添加该注解。\n\n##### 2.2.2 jdk 自带的函数式接口\n\njdk 为 lambda 表达式已经内置了丰富的函数式接口，如下表所示(仅列出部分)：\n\n函数式接口 | 函数描述符 | 原始类型特化\n--- | --- | ---\nPredicate<T> | T -> boolean | IntPredicate, LongPredicate, DoublePredicate\nConsumer<T> | T -> void | IntConsumer, LongConsumer, DoubleConsumer\nFuncation<T, R> | T -> R | IntFuncation<R>, IntToDoubleFunction, IntToLongFunction<R>, LongFuncation...\nSupplier<T> | () -> T | BooleanSupplier, IntSupplier, LongSupplier, DoubleSupplier\nUnaryOperator<T> | T -> T | IntUnaryOperator, LongUnaryOperator, DoubleUnaryOperator\nBinaryOperator<T> | (T, T) -> T | IntBinaryOperator, LongBinaryOperator, DoubleBinaryOperator\nBiPredicate<L, R> | (L, R) -> boolean |\nBiConsumer<T, U> | (T, U) -> void |\nBiFunction<T, U, R> | (T, U) -> R |\n\n其中最典型的三个接口是 `Predicate<T>`、`Consumer<T>`，以及 `Function<T, R>`，其余接口几乎都是对这三个接口的定制化，下面就这三个接口举例说明其用处，针对接口中提供的逻辑操作默认方法，留到后面介绍接口的 default 方法时再进行说明。\n\n- __Predicate<T>__\n\n```java\n@FunctionalInterface\npublic interface Predicate<T> {\n\n    /**\n     * Evaluates this predicate on the given argument.\n     *\n     * @param t the input argument\n     * @return {@code true} if the input argument matches the predicate,\n     * otherwise {@code false}\n     */\n    boolean test(T t);\n}\n```\n\nPredicate 的功能类似于上面的 AppleFilter，利用我们在外部设定的条件对于传入的参数进行校验并返回验证通过与否，下面利用 Predicate 对 List 集合的元素进行过滤：\n\n```java\nprivate <T> List<T> filter(List<T> numbers, Predicate<T> predicate) {\n    Iterator<T> itr = numbers.iterator();\n    while (itr.hasNext()) {\n        if (!predicate.test(itr.next())) {\n            itr.remove();\n        }\n        itr.next();\n    }\n    return numbers;\n}\n```\n\n上述方法的逻辑是遍历集合中的元素，通过 Predicate 对集合元素进行验证，并将验证不过的元素从集合中移除。我们可以利用上面的函数式接口筛选整数集合中的偶数：\n\n```java\nPredicateDemo pd = new PredicateDemo();\nList<Integer> list = new ArrayList<>();\nlist.addAll(Arrays.asList(1, 2, 3, 4, 5, 6));\nlist = pd.filter(list, (value) -> value % 2 == 0);\nSystem.out.println(list);\n// 输出：[2, 4, 6]\n```\n\n- __Consumer<T>__\n\n```java\n@FunctionalInterface\npublic interface Consumer<T> {\n\n    /**\n     * Performs this operation on the given argument.\n     *\n     * @param t the input argument\n     */\n    void accept(T t);\n}\n```\n\nConsumer 提供了一个 accept 抽象函数，该函数接收参数并依据传递的行为应用传递的参数值，下面利用 Consumer 遍历字符串集合并转换成小写进行打印：\n\n```java\nprivate <T> void forEach(List<T> list, Consumer<T> consumer) {\n    for (final T value : list) {\n        // 应用行为\n        consumer.accept(value);\n    }\n}\n```\n\n利用上面的函数式接口，遍历字符串集合并以小写形式打印输出：\n\n```java\nConsumerDemo cd = new ConsumerDemo();\nList<String> list = new ArrayList<>();\nlist.addAll(Arrays.asList(\"I\", \" \", \"Love\", \" \", \"Java\", \" \", \"8th\"));\ncd.forEach(list, (value) -> System.out.print(value.toLowerCase()));\n// 输出：i love java 8th\n```\n\n- __Function<T, R>__\n\n```java\n@FunctionalInterface\npublic interface Function<T, R> {\n\n    /**\n     * Applies this function to the given argument.\n     *\n     * @param t the function argument\n     * @return the function result\n     */\n    R apply(T t);\n}\n```\n\nFuncation 执行转换操作，输入类型 T 的数据，返回 R 类型的结果，下面利用 Function 对字符串集合转换成整型集合，并忽略掉不是数值型的字符：\n\n```java\nprivate List<Integer> parse(List<String> list, Function<String, Integer> function) {\n    List<Integer> result = new ArrayList<>();\n    for (final String value : list) {\n        // 应用数据转换\n        if (NumberUtils.isDigits(value)) result.add(function.apply(value));\n    }\n    return result;\n}\n```\n\n下面利用上面的函数式接口，将一个封装字符串的集合转换成整型集合，忽略不是数值形式的字符串：\n\n```java\nFunctionDemo fd = new FunctionDemo();\nList<String> list = new ArrayList<>();\nlist.addAll(Arrays.asList(\"a\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"));\nList<Integer> result = fd.parse(list, (value) -> Integer.valueOf(value));\nSystem.out.println(result);\n// 输出：[1, 2, 3, 4, 5, 6]\n```\n\n##### 2.2.3 一些需要注意的事情\n\n- __类型推断__\n\n在编码过程中，有时候可能会疑惑我们的调用代码会具体匹配哪个函数式接口，实际上编译器会根据参数、返回类型、异常类型（如果存在）等因素做正确的判定。在具体调用时，一些时候可以省略参数的类型以进一步简化代码：\n\n```java\n// 筛选苹果\nList<Apple> filterApples = filterApplesByAppleFilter(apples,\n        (Apple apple) -> Color.RED.equals(apple.getColor()) && apple.getWeight() >= 100);\n\n// 某些情况下我们甚至可以省略参数类型，编译器会根据上下文正确判断\nList<Apple> filterApples = filterApplesByAppleFilter(apples,\n        apple -> Color.RED.equals(apple.getColor()) && apple.getWeight() >= 100);\n```\n\n- __局部变量__\n\n上面所有例子中使用的变量都是 lambda 表达式的主体参数，我们也可以在 lambda 中使用实例变量、静态变量，以及局部变量，如下代码为在 lambda 表达式中使用局部变量：\n\n```java\nint weight = 100;\nList<Apple> filterApples = filterApplesByAppleFilter(apples,\n        apple -> Color.RED.equals(apple.getColor()) && apple.getWeight() >= weight);\n```\n\n上述示例我们在 lambda 中使用了局部变量 weight，不过在 lambda 中使用局部变量还是有很多限制，学习初期 IDE 可能经常会提示我们 `Variable used in lambda expression should be final or effectively final` 的错误，即要求在 lambda 表达式中使用的变量必须 __显式声明为 final 或事实上的 final 类型__ 。\n\n为什么要限制我们直接使用外部的局部变量呢？主要原因在于内存模型，我们都知道实例变量在堆上分配的，而局部变量在栈上进行分配，lambda 表达式运行在一个独立的线程中，了解 JVM 的同学应该都知道栈内存是线程私有的，所以局部变量也属于线程私有，如果肆意的允许 lambda 表达式引用局部变量，可能会存在局部变量以及所属的线程被回收，而 lambda 表达式所在的线程却无从知晓，这个时候去访问就会出现错误，之所以允许引用事实上的 final（没有被声明为 final，但是实际中不存在更改变量值的逻辑），是因为对于该变量操作的是变量副本，因为变量值不会被更改，所以这份副本始终有效。这一限制可能会让刚刚开始接触函数式编程的同学不太适应，需要慢慢的转变思维方式。\n\n实际上在 java 8th 之前，我们在方法中使用内部类时就已经遇到了这样的限制，因为生命周期的限制 JVM 采用复制的策略将局部变量复制一份到内部类中，但是这样会带来多个线程中数据不一致的问题，于是衍生了禁止修改内部类引用的外部局部变量这一简单、粗暴的策略，只不过在 8th 之前必须要求这部分变量采用 final 修饰，但是 8th 开始放宽了这一限制，只要求所引用变量是 “事实上” 的 final 类型即可。\n\n### 三. 方法引用\n\n方法引用可以更近一步的简化代码，有时候这种简化让代码看上去更加直观，先看一个例子：\n\n```java\n/* ... 省略apples的初始化操作 */\n\n// 采用lambda表达式\napples.sort((Apple a, Apple b) -> Float.compare(a.getWeight(), b.getWeight()));\n\n// 采用方法引用\napples.sort(Comparator.comparing(Apple::getWeight));\n```\n\n方法引用通过 `::` 将方法隶属和方法自身连接起来，主要分为三类：\n\n- __静态方法__\n\n```java\n(args) -> ClassName.staticMethod(args)\n转换成：\nClassName::staticMethod\n```\n\n- __参数的实例方法__\n\n```java\n(args) -> args.instanceMethod()\n转换成：\nClassName::instanceMethod  // ClassName是args的类型\n```\n\n- __外部的实例方法__\n\n```java\n(args) -> ext.instanceMethod(args)\n转换成：\next::instanceMethod(args)\n```\n","tags":["Java"],"categories":["java"]},{"title":"转载：细聊分布式 ID 的生成方法","url":"/2016/08/24/solution/distributed-id/","content":"\n### 需求缘起\n\n几乎所有的业务系统，都有生成一个记录标识的需求，例如：\n\n> 1. 消息标识：message-id\n> 2. 订单标识：order-id\n> 3. 帖子标识：tiezi-id\n\n这个记录标识往往就是数据库中的唯一主键，数据库上会建立聚集索引（cluster index），即在物理存储上以这个字段排序。<!-- more -->这个记录标识上的查询，往往又有分页或者排序的业务需求，例如：\n\n```sql\n1. 拉取最新的一页消息： SELECT message-id ORDER BY time LIMIT 100\n2. 拉取最新的一页订单： SELECT order-id   ORDER BY time LIMIT 100\n3. 拉取最新的一页帖子： SELECT tiezi-id   ORDER BY time LIMIT 100\n```\n\n所以往往要有一个time字段，并且在time字段上建立普通索引（non-cluster index）.我们都知道普通索引存储的是实际记录的指针，其访问效率会比聚集索引慢，如果记录标识在生成时能够基本按照时间有序，则可以省去这个time字段的索引查询：\n\n```sql\nSELECT message-id ORDER BY message-id LIMIT 100\n```\n\n再次强调，能这么做的前提是message-id的生成基本是趋势时间递增的.这就引出了记录标识生成（也就是上文提到的三个XXX-id）的两大核心需求：\n\n- 全局唯一\n- 趋势有序\n\n这也是本文要讨论的核心问题：如何高效生成趋势有序的全局唯一ID。\n\n### 常见方法，不足与优化\n\n#### 常见方法一：使用数据库的 auto_increment 来生成全局唯一递增 ID\n\n优点：\n\n> 1. 简单，使用数据库已有的功能\n> 2. 能够保证唯一性\n> 3. 能够保证递增性\n> 4. 步长固定\n\n缺点：\n\n> 1. 可用性难以保证：数据库常见架构是一主多从+读写分离，生成自增ID是写请求，主库挂了就玩不转了\n> 2. 扩展性差，性能有上限：因为写入是单点，数据库主库的写性能决定ID的生成性能上限，并且难以扩展\n\n改进方法：\n\n> 1. 增加主库，避免写入单点\n> 2. 数据水平切分，保证各主库生成的ID不重复\n\n![image](/images/2016/d-id-1.webp)\n\n如上图所述，由1个写库变成3个写库，每个写库设置不同的auto_increment初始值，以及相同的增长步长，以保证每个数据库生成的ID是不同的（上图中库0生成0,3,6,9…，库1生成1,4,7,10，库2生成2,5,8,11…）\n改进后的架构保证了可用性，但缺点是：\n\n> 1. 丧失了ID生成的“绝对递增性”：先访问库0生成0,3，再访问库1生成1，可能导致在非常短的时间内，ID生成不是绝对递增的（这个问题不大，我们的目标是趋势递增，不是绝对递增）\n> 2. 数据库的写压力依然很大，每次生成ID都要访问数据库\n\n为了解决上述两个问题，引出了第二个常见的方案\n\n#### 常见方法二：单点批量ID生成服务\n\n分布式系统之所以难，很重要的原因之一是 __没有一个全局时钟，难以保证绝对的时序__ ，要想保证绝对的时序，还是只能使用单点服务，用本地时钟保证“绝对时序”。数据库写压力大，是因为每次生成ID都访问了数据库，可以使用批量的方式降低数据库写压力。\n\n![image](/images/2016/d-id-2.webp)\n\n如上图所述，数据库使用双master保证可用性，数据库中只存储当前ID的最大值，例如0。ID生成服务假设每次批量拉取6个ID，服务访问数据库，将当前ID的最大值修改为5，这样应用访问ID生成服务索要ID，ID生成服务不需要每次访问数据库，就能依次派发0,1,2,3,4,5这些ID了，当ID发完后，再将ID的最大值修改为11，就能再次派发6,7,8,9,10,11这些ID了，于是数据库的压力就降低到原来的1/6了。\n\n优点：\n\n> 1. 保证了ID生成的绝对递增有序\n> 2. 大大的降低了数据库的压力，ID生成可以做到每秒生成几万几十万个\n\n缺点：\n\n> 1. 服务仍然是单点\n> 2. 如果服务挂了，服务重启起来之后，继续生成ID可能会不连续，中间出现空洞（服务内存是保存着0,1,2,3,4,5，数据库中max-id是5，分配到3时，服务重启了，下次会从6开始分配，4和5就成了空洞，不过这个问题也不大）\n> 3. 虽然每秒可以生成几万几十万个ID，但毕竟还是有性能上限，无法进行水平扩展\n\n改进方法：\n\n单点服务的常用高可用优化方案是“备用服务”，也叫“影子服务”，所以我们能用以下方法优化上述缺点1，对外提供的服务是主服务，有一个影子服务时刻处于备用状态，当主服务挂了的时候影子服务顶上。这个切换的过程对调用方是透明的，可以自动完成，常用的技术是vip+keepalived，具体就不在这里展开。\n\n![image](/images/2016/d-id-3.png)\n\n#### 常见方法三：UUID\n\n上述方案来生成ID，虽然性能大增，但由于是单点系统，总还是存在性能上限的。同时，上述两种方案，不管是数据库还是服务来生成ID，业务方Application都需要进行一次远程调用，比较耗时。有没有一种本地生成ID的方法，即高性能，又时延低呢？\n\nuuid是一种常见的方案：`string ID = GenUUID();`\n\n优点：\n\n> 1. 本地生成ID，不需要进行远程调用，时延低\n> 2. 扩展性好，基本可以认为没有性能上限\n\n缺点：\n\n> 1. 无法保证趋势递增\n> 2. uuid过长，往往用字符串表示，作为主键建立索引查询效率低，常见优化方案为“转化为两个uint64整数存储”或者“折半存储”（折半后不能保证唯一性）\n\n#### 常见方法四：取当前毫秒数\n\nuuid是一个本地算法，生成性能高，但无法保证趋势递增，且作为字符串ID检索效率低，有没有一种能保证递增的本地算法呢？\n\n取当前毫秒数是一种常见方案：`uint64 ID = GenTimeMS();`\n\n优点：\n\n> 1. 本地生成ID，不需要进行远程调用，时延低\n> 2. 生成的ID趋势递增\n> 3. 生成的ID是整数，建立索引后查询效率高\n`\n缺点：\n\n> 1. 如果并发量超过1000，会生成重复的ID\n   我去，这个缺点要了命了，不能保证ID的唯一性。当然，使用微秒可以降低冲突概率，但每秒最多只能生成1000000个ID，再多的话就一定会冲突了，所以使用微秒并不从根本上解决问题。\n\n#### 常见方法五：类 snowflake 算法\n\n[snowflake](https://github.com/twitter/snowflake)是twitter开源的分布式ID生成算法，其核心思想是： __一个long型的ID，使用其中41bit作为毫秒数，10bit作为机器编号，12bit作为毫秒内序列号__ 。这个算法单机每秒内理论上最多可以生成1000*(2^12)，也就是400W的ID，完全能满足业务的需求。借鉴snowflake的思想，结合各公司的业务逻辑和并发量，可以实现自己的分布式ID生成算法。\n\n举例，假设某公司ID生成器服务的需求如下：\n\n> 1. 单机高峰并发量小于1W，预计未来5年单机高峰并发量小于10W\n> 2. 有2个机房，预计未来5年机房数量小于4个\n> 3. 每个机房机器数小于100台\n> 4. 目前有5个业务线有ID生成需求，预计未来业务线数量小于10个\n> 5. …\n\n分析过程如下：\n\n> 1. 高位取从2016年1月1日到现在的毫秒数（假设系统ID生成器服务在这个时间之后上线），假设系统至少运行10年，那至少需要10年*365天*24小时*3600秒*1000毫秒=320*10^9，差不多预留39bit给毫秒数\n> 2. 每秒的单机高峰并发量小于10W，即平均每毫秒的单机高峰并发量小于100，差不多预留7bit给每毫秒内序列号\n> 3. 5年内机房数小于4个，预留2bit给机房标识\n> 4. 每个机房小于100台机器，预留7bit给每个机房内的服务器标识\n> 5. 业务线小于10个，预留4bit给业务线标识\n\n这样设计的 64bit 标识，可以保证：\n\n> 1. 每个业务线、每个机房、每个机器生成的ID都是不同的\n> 2. 同一个机器，每个毫秒内生成的ID都是不同的\n> 3. 同一个机器，同一个毫秒内，以序列号区区分保证生成的ID是不同的\n> 4. 将毫秒数放在最高位，保证生成的ID是趋势递增的\n\n缺点：\n\n> 1. 由于“没有一个全局时钟”，每台服务器分配的ID是绝对递增的，但从全局看，生成的ID只是趋势递增的（有些服务器的时间早，有些服务器的时间晚）\n> 2. 一个容易忽略的问题：生成的ID，例如message-id，order-id，tiezi-id，在数据量大时往往需要分库分表，这些ID经常作为取模分库分表的依据，为了分库分表后数据均匀，ID生成往往有“取模随机性”的需求，所以我们通常把每秒内的序列号放在ID的最末位，保证生成的ID是随机的。又如果，我们在跨毫秒时，序列号总是归0，会使得序列号为0的ID比较多，导致生成的ID取模后不均匀。解决方法是，序列号不是每次都归0，而是归一个0到9的随机数，这个地方。\n\n转自：[细聊分布式ID生成方法](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=403837240&idx=1&sn=ae9f2bf0cc5b0f68f9a2213485313127&scene=21)\n","tags":["分布式"],"categories":["solution"]},{"title":"CAP 理论与分阶段提交协议","url":"/2016/08/23/protocol/x-phase-commit/","content":"\n在分布式系统中著有 CAP 理论，该理论由加州大学伯克利分校的 [Eric Brewer](https://en.wikipedia.org/wiki/Eric_Brewer_%28scientist%29) 教授提出，阐述了在一个分布式系统中不可能同时满足一致性（ __C__ onsistency）、可用性（ __A__ vailability），以及分区容错性（ __P__ artition Tolerance）。\n\n- __一致性__ ：在分布式系统中数据往往存在多个副本，一致性描述的是这些副本中的数据在内容和组织上的一致。\n- __可用性__ ：描述系统对用户的服务能力，所谓可用是指在用户能够容忍的时间范围内返回用户期望的结果。\n- __分区容错性__ ：分布式系统通常由多个节点构成，由于网络是不可靠的，所以存在分布式集群中的节点因为网络通信故障导致被孤立成一个个小集群的可能性，即网络分区，分区容错性要求在出现网络分区时系统仍然能够对外提供一致性的可用服务。\n\n<!-- more -->\n\n对于一个分布式系统而言，我们要始终假设网络是不可靠的，因此分区容错性是对一个分布式系统最基本的要求，我们的切入点更多的是尝试在可用性和一致性之间寻找一个平衡点，但这也并非要求我们在系统设计时一直建立在网络出现分区的前提之上，然后对一致性和可用性在选择时非此即彼。\n\nEric Brewer 教授在 2012 年就曾指出 __CAP 理论证明不能同时满足一致性、可用性，以及分区容错性的观点在实际系统设计指导上存在一定的误导性__ 。传统对于 CAP 理论的理解认为在设计分布式系统时必须满足 P，然后在 C 和 A 之间进行取舍，这是片面的。实际中网络出现分区的可能性还是比较小的，尤其是目前网络环境正在变得越来越好，甚至许多系统都拥有专线支撑，所以在网络未出现分区时，还是应该兼顾 A 和 C。所以，我们可以这样去理解 CAP，只有在网络出现分区的情况下才需要在一致性和可用性之间进行取舍。另外就是对于一致性、可用性，以及分区容错性三者在度量上也应该有一个评定范围，最简单的以可用性为例，当有多少占比请求出现响应超时才可以被认为是不满足可用性，而不是一出现超时就认为是不可用的。最后我们需要考虑的一点就是分布式系统一般都是一个比较大且复杂的系统，我们应该从更小的粒度上对各个子系统进行评估和设计，而不是简单的从整体上武断决策。\n\n让分布式集群始终对外提供可用的一致性服务一直是富有挑战和趣味的任务。暂且抛开可用性，拿一致性来说，对于关系型数据库我们通常利用事务来保证数据的强一致性，但是当我们的数据量越来越大，大到单库已经无法承担时，我们不得不采取分库分表的策略对数据库实现水平拆分，或者引入 NoSQL 技术，构建分布式数据库集群以分摊读写压力，从而提升数据库的存储和响应能力，但是多个数据库实例也为我们使用数据库带来了许多的限制，比如主键的全局唯一、联表查询、数据聚合等等，另外一个相当棘手的问题就是数据库的事务由原先的单库事务变成了现在的分布式事务。\n\n分布式事务的实现并不是无解的，比如下文要展开的两阶段提交（2PC：Two-Phase Commit）和三阶段提交（3PC：Three-Phase Commit）都给我们提供了思路，但是在分布式环境下如何保证数据的强一致性，并对外提供高可用的服务还是相当棘手的，因此很多分布式系统对于数据强一致性都敬而远之。\n\n### 两阶段提交协议（2PC：Two-Phase Commit）\n\n两阶段提交协议的目标在于为分布式系统保证数据的一致性，许多分布式系统采用该协议提供对分布式事务的支持。顾名思义，该协议将一个分布式的事务过程拆分成两个阶段： __投票__ 和 __事务提交__ 。为了让整个数据库集群能够正常的运行，该协议指定了一个 __协调者__ 单点，用于协调整个数据库集群各节点的运行。为了简化描述，我们将数据库集群中的各个节点称为 __参与者__ ，三阶段提交协议中同样包含协调者和参与者这两个角色定义。\n\n#### 第一阶段：投票\n\n该阶段的主要目的在于打探数据库集群中的各个参与者是否能够正常的执行事务，具体步骤如下：\n\n1. 协调者向所有的参与者发送事务执行请求，并等待参与者反馈事务执行结果；\n2. 事务参与者收到请求之后，执行事务但不提交，并记录事务日志；\n3. 参与者将自己事务执行情况反馈给协调者，同时阻塞等待协调者的后续指令。\n\n#### 第二阶段：事务提交\n\n在经过第一阶段协调者的询盘之后，各个参与者会回复自己事务的执行情况，这时候存在 3 种可能性：\n\n- 所有参与者都回复能够正常执行事务。\n- 一个或多个参与者回复事务执行失败。\n- 协调者等待超时。\n\n对于第 1 种情况，协调者将向所有的参与者发出提交事务的通知，具体步骤如下：\n\n1. 协调者向各个参与者发送 commit 通知，请求提交事务；\n2. 参与者收到事务提交通知之后执行 commit 操作，然后释放占有的资源；\n3. 参与者向协调者返回事务 commit 结果信息。\n\n![image](/images/2016/2pc-success.png)\n\n对于第 2 和第 3 种情况，协调者均认为参与者无法成功执行事务。为了保证数据一致性，协调者要向各个参与者发送事务回滚通知，具体步骤如下：\n\n1. 协调者向各个参与者发送事务 rollback 通知，请求回滚事务；\n2. 参与者收到事务回滚通知之后执行 rollback 操作，然后释放占有的资源；\n3. 参与者向协调者返回事务 rollback 结果信息。\n\n![image](/images/2016/2pc-failed.png)\n\n两阶段提交协议要解决的是分布式数据库数据强一致性问题，实际应用中更多的是用来保证跨系统事务操作的原子性，下图描绘了协调者与参与者的状态转换。\n\n![image](/images/2017/2pc-state.png)\n\n站在协调者的角度，在发起投票之后即进入了 WAIT 状态，等待所有参与者回复各自事务执行状态，并在收到所有参与者的回复后决策下一步是发送 commit 或 rollback 请求。\n\n站在参与者的角度，当回复完协调者的投票请求之后便进入 READY 状态（能够正常执行事务），接下去就是等待协调者最终的决策通知，一旦收到通知便可依据决策执行 commit 或 rollback 操作。\n\n两阶段提交协议原理简单、易于实现，但是缺点也是显而易见的，包括：\n\n- __单点问题__ ：协调者在整个两阶段提交过程中扮演着举足轻重的作用，一旦协调者所在服务器宕机，就会影响整个数据库集群的正常运行。比如在第二阶段中，如果协调者因为故障不能正常发送事务提交或回滚通知，那么参与者们将一直处于阻塞状态，整个数据库集群将无法提供服务。\n- __同步阻塞__ ：两阶段提交执行过程中，所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其它操作，这样效率极其低下。\n- __数据不一致__ ：两阶段提交协议虽然是为分布式数据强一致所设计，但仍然存在导致数据不一致的可能性。比如在第二阶段中，假设协调者发出了事务 commit 通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致问题。\n\n针对上述缺点可以引入 __超时机制__ 和 __互询机制__ 在一定程度上予以解决。\n\n对于协调者来说，如果在指定时间内没有收到所有参与者的应答，则可以自动退出 WAIT 状态，并向所有参与者发送 rollback 通知。对于参与者来说，如果位于 READY 状态，但是在指定时间内没有收到协调者的第二阶段通知，则不能武断地执行 rollback 操作，因为协调者可能发送的是 commit 通知，这个时候执行 rollback 就会导致数据不一致。\n\n此时，我们可以引入互询机制，让参与者（令为 A）去询问其它参与者（令为 B）的执行情况：\n\n- 如果 B 执行了 rollback 或 commit 操作，则 A 可以大胆的与 B 执行相同的操作。\n- 如果 B 此时还没有到达 READY 状态，则可以推断出协调者发出的肯定是 rollback 通知。\n- 如果 B 同样位于 READY 状态，则 A 可以继续询问另外的参与者，只有当所有的参与者都位于 READY 状态时，此时两阶段提交协议无法处理，将陷入长时间的阻塞状态。\n\n### 三阶段提交协议（3PC：Three-Phase Commit）\n\n针对两阶段提交存在的问题，三阶段提交协议通过引入一个 __预询盘__ 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。三阶段提交的三个阶段分别为：预询盘（can_commit）、预提交（pre_commit），以及事务提交（do_commit）。\n\n#### 第一阶段：预询盘\n\n该阶段协调者会去询问各个参与者是否能够正常执行事务，参与者根据自身情况回复一个预估值，相对于真正的执行事务，这个过程是轻量的，具体步骤如下：\n\n1. 协调者向各个参与者发送事务询问通知，询问是否可以执行事务操作，并等待回复；\n2. 各个参与者依据自身状况回复一个预估值，如果预估自己能够正常执行事务就返回确定信息，并进入预备状态，否则返回否定信息。\n\n#### 第二阶段：预提交\n\n本阶段协调者会根据第一阶段的询盘结果采取相应操作，询盘结果主要有 3 种：\n\n- 所有的参与者都返回确定信息。\n- 一个或多个参与者返回否定信息。\n- 协调者等待超时。\n\n针对第 1 种情况，协调者会向所有参与者发送事务执行请求，具体步骤如下：\n\n1. 协调者向所有的事务参与者发送事务执行通知；\n2. 参与者收到通知后执行事务但不提交；\n3. 参与者将事务执行情况返回给客户端。\n\n__在上述步骤中，如果参与者等待超时，则会中断事务。__ 针对第 2 和第 3 种情况，协调者认为事务无法正常执行，于是向各个参与者发出 abort 通知，请求退出预备状态，具体步骤如下：\n\n1. 协调者向所有事务参与者发送 abort 通知；\n2. 参与者收到通知后中断事务。\n\n![image](/images/2016/3pc-fail-1.png)\n\n#### 第三阶段：事务提交\n\n如果第二阶段事务未中断，那么本阶段协调者将会依据事务执行返回的结果来决定提交或回滚事务，分为 3 种情况：\n\n- 所有的参与者都能正常执行事务。\n- 一个或多个参与者执行事务失败。\n- 协调者等待超时。\n\n针对第 1 种情况，协调者向各个参与者发起事务提交请求，具体步骤如下：\n\n1. 协调者向所有参与者发送事务 commit 通知；\n2. 所有参与者在收到通知之后执行 commit 操作，并释放占有的资源；\n3. 参与者向协调者反馈事务提交结果。\n\n![image](/images/2016/3pc-success.png)\n\n针对第 2 和第 3 种情况，协调者认为事务无法成功执行，于是向各个参与者发送事务回滚请求，具体步骤如下：\n\n1. 协调者向所有参与者发送事务 rollback 通知；\n2. 所有参与者在收到通知之后执行 rollback 操作，并释放占有的资源；\n3. 参与者向协调者反馈事务回滚结果。\n\n![image](/images/2016/3pc-fail-2.png)\n\n在本阶段如果因为协调者或网络问题，导致参与者迟迟不能收到来自协调者的 commit 或 rollback 请求，那么参与者将不会如两阶段提交中那样陷入阻塞，而是等待超时后继续 commit，相对于两阶段提交虽然降低了同步阻塞，但仍然无法完全避免数据的不一致。\n\n![image](/images/2017/3pc-state.png)\n\n两阶段提交协议中所存在的长时间阻塞状态发生的几率还是非常低的，所以虽然三阶段提交协议相对于两阶段提交协议对于数据强一致性更有保障，但是因为效率问题，两阶段提交协议在实际系统中反而更加受宠。\n\n### 参考\n\n1. [CAP 理论十二年回顾：\"规则\"变了](https://www.infoq.cn/article/cap-twelve-years-later-how-the-rules-have-changed/?itm_source=infoq_en&itm_medium=link_on_en_item&itm_campaign=item_in_other_langs)\n","tags":["分布式","分布式事务"],"categories":["protocol"]},{"title":"基于锁分段机制的 ConcurrentHashMap 实现内幕","url":"/2016/08/16/java/segment-based-concurrent-hashmap/","content":"\nConcurrentHashMap 是线程安全的 HashMap。此前，HashTable 一直被认为是线程安全的 HashMap，ConcurrentHashMap 相对于 HashTable 采用了 __锁分段机制__ ，即将原本对整个对象加锁的实现进行粒度细化。这也是源于 HashMap 基本的存储特性，因为许多读写请求都是被哈希到了互相独立的区域，这种情况下即使并发读写也不会相互影响，更不会有线程安全问题，而对于操作加全局锁的实现方式显然是浪费了这一天然的并发优势，我们需要加锁的位置是真正存在竞争的地方，而分段锁很好的利用了这一特点。<!-- more -->\n\n### 一. 存储结构设计\n\n在实现上，ConcurrentHashMap 内置了两个静态内部类 HashEntry 和 Segment，前者用来封装 key/value，后者则用来充当锁的角色。一个 Segment（分段）上挂载着一张包含多行记录的表（table），负责范围内各个结点读写的线程安全，每行记录都是由一个以 HashEntry 为结点的链表构成。\n\n![image](/images/2016/concurrent_hashmap.png)\n\n上面这张图具体描绘了 ConcurrentHashMap 的存储结构设计，默认情况下一个 ConcurrentHashMap 包含 16 个分段（Segment），每个分段包含一张表（HashEntry 类型数组 table），而表中的每行记录都是一个包含了若干个 HashEntry 类型结点的链表，HashEntry 可以看作是整个存储结构中最小的存储单元。在这样的存储结构基础上，我们可以初步臆测 ConcurrentHashMap 存储、读取数据的实现过程，概括来说就是先基于 key 的哈希值定位到具体的分段，然后映射到对应的表，最后就是对表中链表的常规遍历操作。而在这个过程中，锁的粒度控制在一个分段范围内，也就是说只有哈希到同一个分段内的多个读写操作才会存在竞争，而分段与分段之间的读写操作则互不影响、并发执行。段内竞争的线程安全则以具体的分段对象作为锁来执行同步策略，所以在默认理想情况下，一个 ConcurrentHashMap 具备 16 个线程的并发读写能力，这相对于对整个存储对象加全局锁的 HashTable 来说，效率提升了许多。\n\n我们先来分别看一下 HashEntry 和 Segment 这两个基础组件的内部结构实现，首先来看一下 HashEntry:\n\n```java\nstatic final class HashEntry<K,V> {\n    final int hash; // 哈希值，key 的 hash 值，不允许修改，所以用 final 修饰，同时也保证了可见性\n    final K key;  // 键，final 修饰保证不允许修改与可见性\n    volatile V value; // 值，volatile 修饰保证值的可见性，value 的值允许被更新\n    volatile HashEntry<K,V> next; // 链表 next 指针\n\n    HashEntry(int hash, K key, V value, HashEntry<K,V> next) {\n        this.hash = hash;\n        this.key = key;\n        this.value = value;\n        this.next = next;\n    }\n\n    // 省略部分实现\n}\n```\n\nHashEntry 是对 key/value 的封装类，可以将一个 HashEntry 对象看做是整个存储结构中的最小单位，它是一个结点，包含了必要的 hash、key、value 元素，因为采用链地址法来解决冲突，所以还包含了链表的 next 指针。四个属性中 hash 和 key 是 final 修饰的，而 value 和 next 则是由 volatile 来修饰，这样的设计最根本的都是希望保证在并发访问过程中结点的线程可见性，又因为后两者是可变的对象，所以采用 volatile 进行修饰。\n\n再来看一下 Segment 的实现，Segment 实现了 ReentrantLock 类，所以可以将其视为一个针对 HashMap 作了适配的可重入锁，每个 Segment 对象的责任就是用来保证其守护的表内各个结点访问的线程安全：\n\n```java\nstatic final class Segment<K,V> extends ReentrantLock implements Serializable {\n\n    private static final long serialVersionUID = 2249069246763182397L;\n\n    static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() > 1 ? 64 : 1;\n\n    /** 分段内挂载的表，表中包含了若干条记录（对应数组大小），每条记录都是一个由一系列 HashEntry 结点构成的链表 */\n    transient volatile HashEntry<K,V>[] table;\n\n    /** 计数当前 Segment 范围内 HashEntry 结点的数目（各个槽位上链表长度之和） */\n    transient int count;\n\n    /** table 被修改的次数，可以用来表示一段时间内分段内是否有操作行为（不包含更新 key 对应的 value 行为） */\n    transient int modCount;\n\n    /**\n     * 再散列阈值，当 table 范围内包含的 HashEntry 结点的数量超过该阈值时，将触发再散列\n     * threshold = capacity * loadFactor\n     */\n    transient int threshold;\n\n    /** 装载因子 */\n    final float loadFactor;\n\n    Segment(float lf, int threshold, HashEntry<K,V>[] tab) {\n        this.loadFactor = lf;\n        this.threshold = threshold;\n        this.table = tab;\n    }\n\n    // 省略 put、rehash、scanAndLockForPut、scanAndLock、remove、replace 方法的实现\n}\n```\n\nSegment 可以理解为分段，默认 ConcurrentHashMap 包含 16 个分段，对应的属性已经在代码中注释，这里再进一步讲解一下 table 属性，因为它是存储结构的一份子。table 属性是一个 HashEntry 类型的数组，每个数组元素都是一个 HashEntry 链表。HashEntry 的名字取的个人觉得既好也不好，说其好是因为每个链表的起始节点也是 HashEntry 类型，可以形象的称其为“入口”，但是具体到链表中的每个结点应该用 Node 来表示更加形象，不过真正理解了也就不会因为名字而疑惑。\n\n接下来我们继续探究 ConcurrentHashMap 基于 HashEntry 和 Segment 的实现，实际上是对前面的存储结构图示的具体描述：\n\n```java\npublic class ConcurrentHashMap<K, V> extends AbstractMap<K, V> implements ConcurrentMap<K, V>, Serializable {\n    private static final long serialVersionUID = 7249069246763182397L;\n\n    /** 默认分段的数量 */\n    static final int DEFAULT_INITIAL_CAPACITY = 16;\n\n    /** 默认的装载因子 */\n    static final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n    /** 默认的并发度 */\n    static final int DEFAULT_CONCURRENCY_LEVEL = 16;\n\n    /** 分段 table 内最大的行记录数 */\n    static final int MAXIMUM_CAPACITY = 1 << 30;\n\n    /** 分段 table 内行记录数最小值，必须是二次幂 */\n    static final int MIN_SEGMENT_TABLE_CAPACITY = 2;\n\n    /** 分段的最大数目 */\n    static final int MAX_SEGMENTS = 1 << 16; // 保守值\n\n    /** 加锁之前的重试次数 */\n    static final int RETRIES_BEFORE_LOCK = 2;\n\n    /** 掩码值，用来计算分段数组的下标，以定位具体的分段 */\n    final int segmentMask;\n\n    /** 偏移量 */\n    final int segmentShift;\n\n    /** 分段数组 */\n    final Segment<K,V>[] segments;\n\n    transient Set<K> keySet;\n    transient Set<Map.Entry<K,V>> entrySet;\n    transient Collection<V> values;\n\n    // 构造函数\n    public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) {\n        if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)\n            throw new IllegalArgumentException();\n\n        if (concurrencyLevel > MAX_SEGMENTS)\n            concurrencyLevel = MAX_SEGMENTS;\n\n        // 寻找最佳匹配参数，大于给定参数 concurrencyLevel 的最小二次幂\n        // 必须是二次幂是用来保证能够通过按位与来定位具体的分段\n        int sshift = 0;\n        int ssize = 1;\n        while (ssize < concurrencyLevel) {\n            ++sshift;  // 默认为 4\n            ssize <<= 1; // 默认为 16\n        }\n        this.segmentShift = 32 - sshift;  // 偏移量，默认为 28\n        this.segmentMask = ssize - 1;  // 掩码值，默认为 15\n\n        if (initialCapacity > MAXIMUM_CAPACITY)\n            initialCapacity = MAXIMUM_CAPACITY;\n\n        int c = initialCapacity / ssize; // 16 / 16 = 1\n        if (c * ssize < initialCapacity) ++c;\n        int cap = MIN_SEGMENT_TABLE_CAPACITY; // cap 表示每个分段中 table 的最大长度\n        while (cap < c)\n            cap <<= 1;\n        // create segments and segments[0]\n        Segment<K,V> s0 = new Segment<K,V>(loadFactor, (int)(cap * loadFactor), (HashEntry<K,V>[])new HashEntry[cap]);\n        Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];\n        UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]\n        this.segments = ss;\n    }\n\n    public ConcurrentHashMap(int initialCapacity, float loadFactor) {\n        this(initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL);\n    }\n\n    public ConcurrentHashMap(int initialCapacity) {\n        this(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);\n    }\n\n    public ConcurrentHashMap() {\n        this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);\n    }\n\n    public ConcurrentHashMap(Map<? extends K, ? extends V> m) {\n        this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);\n        putAll(m);\n    }\n\n    // 省略剩余方法实现\n}\n```\n\n具体的属性含义参考代码注释，我们来看一下构造函数的内部逻辑。构造函数允许我们指定 initialCapacity、loadFactor，以及 concurrencyLevel 三个参数值，其中 loadFactor 译为装载因子，在数据结构课程中讲解哈希冲突时已经对相关概念解释的比较清楚，这里不再多做说明，默认为 0.75，一般不建议修改。\n\n我们来看一下 initialCapacity 和 concurrencyLevel 两个参数，这两个参数一起用来控制构造 map 的初始化大小，其中 concurrencyLevel 用来控制分段的数目，构造函数会计算得到大于该值的最小二次幂作为 map 的分段数目，因为分段数目的多少对应着并发度的多少，所以参数命名为 concurrencyLevel 也不难理解。之所以需要用大于该值的最小二次幂作为分段大小，主要是为了配合哈希函数的定义， __方便通过逻辑与运算来定位具体的分段__ ，相对于数值运算来说这样效率更高。再来看一下 initialCapacity，该参数用来控制整个 map 集合包含结点的的初始值，最终还是用来控制分段内表的记录行数。\n\n### 二. 基本方法实现\n\n探究了 ConcurrentHashMap 的存储结构设计，我们继续来看一下常用操作的实现细节。对于 Map 集合来说，常用的方法有添加（put）、获取（get）、删除（remove）键值，以及对这些基本方法的包装方法，此外还有获取集合大小（size）等操作，下面我们针对 ConcurrentHashMap 中典型方法逐个说明。\n\n#### 2.1 添加或更新键值对：put(K key, V value)\n\n首先来看一下 put 方法，我们都知道 put 操作会修改集合中的数据，也就是写操作，而写操作若希望保证线程安全和可见，则需要一定的同步策略。ConcurrentHashMap 的写操作相对于 HashTable 要高效很多，这主要归功于锁分段机制，具体的实现如下：\n\n```java\npublic V put(K key, V value) {\n    Segment<K,V> s;\n    if (value == null)\n        throw new NullPointerException();\n\n    // 计算键对应的哈希值\n    int hash = hash(key);\n\n    /*\n     * 基于键的哈希值找到对应的 Segment 对象\n     * 将 hash 向右移动 segmentShift 偏移位，并与 segmentMask 执行 与 操作\n     */\n    int j = (hash >>> segmentShift) & segmentMask;\n    if ((s = (Segment<K,V>)UNSAFE.getObject(segments, (j << SSHIFT) + SBASE)) == null)\n        s = ensureSegment(j);\n\n    // 调用 Segment 的 put 方法，执行 put 操作\n    return s.put(key, hash, value, false);\n}\n```\n\n上述过程的逻辑比较明确，可以概括成如下三步：\n\n> 1. 调用 hash 方法计算 key 的哈希值\n> 2. 基于 key 的哈希值定位具体的分段 Segment\n> 3. 调用 Segment 对象的 put 方法执行 put 逻辑\n\n从整个操作过程我们可以很直观的理解锁分段的实现细节，Segment 就是这里的锁对象，put 操作会首先定位当前需要操作的具体 Segment 对象，然后调用该对象的 put 方法执行写入或更新操作，而具体的锁策略就位于 Segment 的 put 方法内，这个我们后面再深入探究，先来看一下定位具体分段的过程，首先看一下 hash 算法的实现：\n\n```java\nprivate int hash(Object k) {\n    int h = hashSeed; // 调用 randomHashSeed(this) 方法计算得到\n\n    if ((0 != h) && (k instanceof String)) {\n        return sun.misc.Hashing.stringHash32((String) k);\n    }\n\n    h ^= k.hashCode();\n\n    // Spread bits to regularize both segment and index locations,\n    // using variant of single-word Wang/Jenkins hash.\n    h += (h <<  15) ^ 0xffffcd7d;\n    h ^= (h >>> 10);\n    h += (h <<   3);\n    h ^= (h >>>  6);\n    h += (h <<   2) + (h << 14);\n    return h ^ (h >>> 16);\n}\n```\n\n```java\n// 计算随机的 hash 种子，减少哈希碰撞\nprivate transient final int hashSeed = randomHashSeed(this);\n\nprivate static int randomHashSeed(ConcurrentHashMap instance) {\n    if (sun.misc.VM.isBooted() && Holder.ALTERNATIVE_HASHING) {\n        return sun.misc.Hashing.randomHashSeed(instance);\n    }\n    return 0;\n}\n```\n\n之所以不直接使用 jdk 提供的 hashCode() 方法，而是在此基础上进行改写（Wang/Jenkins Hash），主要是考虑到原生哈希算法冲突的可能性较大，而哈希均衡是 ConcurrentHashMap 良好性能的基础，下面的例子证明了改写之后的算法在哈希均衡性上优于原生算法：\n\n> 我做了一个测试，不通过再哈希而直接执行哈希计算。\n>\n> System.out.println(Integer.parseInt(\"0001111\", 2) & 15);\n> System.out.println(Integer.parseInt(\"0011111\", 2) & 15);\n> System.out.println(Integer.parseInt(\"0111111\", 2) & 15);\n> System.out.println(Integer.parseInt(\"1111111\", 2) & 15);\n>\n> 计算后输出的哈希值全是15，通过这个例子可以发现如果不进行再哈希，哈希冲突会非常严重，因为只要低位一样，无论高位是什么数，其哈希值总是一样。我们再把上面的二进制数据进行再哈希后结果如下，为了方便阅读，不足32位的高位补了0，每隔四位用竖线分割下。\n>\n> 0100｜0111｜0110｜0111｜1101｜1010｜0100｜1110\n> 1111｜0111｜0100｜0011｜0000｜0001｜1011｜1000\n> 0111｜0111｜0110｜1001｜0100｜0110｜0011｜1110\n> 1000｜0011｜0000｜0000｜1100｜1000｜0001｜1010\n>\n> 可以发现每一位的数据都散列开了，通过这种再哈希能让数字的每一位都能参加到哈希运算当中，从而减少哈希冲突。\n\n例子引用自 [聊聊并发 — 深入分析ConcurrentHashMap](http://www.infoq.com/cn/articles/ConcurrentHashMap/)。\n\n然后方法会基于计算得到的哈希值定位具体的分段：\n\n```java\nint j = (hash >>> segmentShift) & segmentMask;\nif ((s = (Segment<K,V>)UNSAFE.getObject(segments, (j << SSHIFT) + SBASE)) == null)\n    s = ensureSegment(j);\n```\n\n```java\n// 基于下标获取对应的分段对象，如果不存在则基于 CAS 策略创建\nprivate Segment<K,V> ensureSegment(int k) {\n    final Segment<K,V>[] ss = this.segments;\n    long u = (k << SSHIFT) + SBASE; // raw offset\n    Segment<K,V> seg;\n    if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {\n        Segment<K,V> proto = ss[0];\n        int cap = proto.table.length;  // 分段内 table 的长度\n        float lf = proto.loadFactor;\n        int threshold = (int)(cap * lf);\n        HashEntry<K,V>[] tab = (HashEntry<K,V>[])new HashEntry[cap];\n        if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) { // recheck\n            Segment<K,V> s = new Segment<K,V>(lf, threshold, tab);\n            while ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {\n                if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))\n                    break;\n            }\n        }\n    }\n    return seg;\n}\n```\n\n默认在构造 ConcurrentHashMap 对象时，segmentShift 值为 28，segmentMask 值为 15，而 hash 值为 32 为，所以这里的计算逻辑是对 hash 右移 28 位，再与 segmentMask 执行与操作，目的是让高 4 位也参与到哈希运算中，最终计算得到对应 segments 数组下标。然后基于下标获取对应的分段，如果分段不存在的话，则会基于 CAS 策略创建并记录相应的分段对象。\n\n接着会调用获取到的 Segment 对象的 put 方法执行 put 操作，记录 key/value 值，其中包含了分段锁机制的具体实现细节：\n\n```java\n// java.util.concurrent.ConcurrentHashMap.Segment#put\nfinal V put(K key, int hash, V value, boolean onlyIfAbsent) {\n    // 加锁，如果 tryLock 成功则继续，否则循环尝试加锁\n    HashEntry<K,V> node = tryLock() ? null : scanAndLockForPut(key, hash, value);\n    V oldValue;\n    try {\n        HashEntry<K,V>[] tab = table; // 当前 Segment 的 table\n        int index = (tab.length - 1) & hash;  // 计算对应的 table 下标\n        HashEntry<K,V> first = entryAt(tab, index); // 获取对应的 entry\n        for (HashEntry<K,V> e = first;;) {\n            if (e != null) { // 对应 entry 上存在链表，且当前还在链表结点上\n                K k;\n                if ((k = e.key) == key || (e.hash == hash && key.equals(k))) {\n                    // 找到相同的 key，则更新对应的 value\n                    oldValue = e.value;\n                    if (!onlyIfAbsent) {\n                        e.value = value;\n                        ++modCount;\n                    }\n                    break;\n                }\n                e = e.next; // 遍历链表上的下一个结点\n            } else { // 对应 entry 上没有链表，或已经达到链尾\n                if (node != null)\n                    node.setNext(first);  // 在链表上前置插入新的结点\n                else\n                    node = new HashEntry<K,V>(hash, key, value, first); // 创建新的结点\n                int c = count + 1;\n                if (c > threshold && tab.length < MAXIMUM_CAPACITY)\n                    rehash(node);  // 再散列，table 长度扩充一倍\n                else\n                    setEntryAt(tab, index, node); // 更新 entry\n                ++modCount; // 只有当前新插入结点时才计数，如果仅仅是更新已有 key 的 value 则不计数\n                count = c;\n                oldValue = null;  // 因为是新的结点，所以 oldValue = null\n                break;\n            }\n        }\n    } finally {\n        unlock();  // 释放锁\n    }\n    return oldValue;\n}\n```\n\n如代码注释所示，整个过程还是比较直观的，在代码一开始会尝试锁定当前分段对象，锁定之后就是常规的链表操作，因为整个操作位于临界区中，所以无需再考虑线程安全问题。而具体的实现正如我们一开始简单臆测的一样，首先通过与操作定位 key 在表中的记录行，然后对行上的链表执行遍历，如果对应的 key 已经存在则更新对应的 value，否则在链表最前端插入新的结点。因为 HashEntry 中 value 属性采用 volatile 修饰，所以能够保证更新操作能够立即对 get 线程可见，而之所以要采取前置插入是考虑到一个概率问题，HashMap 的开发者认为 __后面插入的 Entry 被检索的概率更大，从而提升整体 get 性能__ ，并且读操作是不需要加锁的，个人觉得前置插入还可以保证在插入的过程中如果存在读线程在遍历当前链表，则插入操作不会对整个遍历过程产生影响。\n\n#### 2.2 获取指定键值：get(Object key)\n\n再来看一下 get 操作，相对于 put 操作而言，get 要简单许多，这是因为读的过程是不需要加锁的，HashEntry 的设计能够保证节点变更的线程可见性。而结合对于存储结构设计的理解，即使不看源码，我们也能够大致知道整个过程的实现细节，这里不再展开说明。\n\n```java\npublic V get(Object key) {\n    Segment<K,V> s; // manually integrate access methods to reduce overhead\n    HashEntry<K,V>[] tab;\n    int h = hash(key);  // 计算 key 的哈希值\n    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;\n    if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null && (tab = s.table) != null) {\n        // 获取对应的 entry，并遍历链表上的结点\n        for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile(tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE); e != null; e = e.next) {\n            K k;\n            if ((k = e.key) == key || (e.hash == h && key.equals(k)))\n                // 找到对应的 key，返回对应的 value\n                return e.value;\n        }\n    }\n    // key 不存在，返回 null\n    return null;\n}\n```\n\n#### 2.3 删除指定键值：remove(Object key)\n\nremove 操作类似于 put 操作，都是需要对存储结构进行修改的操作，put 是插入或更新结点，而 remove 则是删除结点，所以都需要进行加锁操作。整个过程同样也分为三个步骤：\n\n> 1. 计算 key 对应的哈希值\n> 2. 基于 key 的哈希值定位具体的分段 Segment\n> 3. 调用 Segment 对象的 remove 方法执行删除逻辑\n\n```java\npublic V remove(Object key) {\n    // 1. 计算 key 对应的哈希值\n    int hash = hash(key);\n    // 2. 根据 key 的哈希值找到对应的 Segment 对象\n    Segment<K,V> s = segmentForHash(hash);\n    // 3. 调用 Segment 对象的 remove 方法执行删除\n    return s == null ? null : s.remove(key, hash, null);\n}\n```\n\nSegment 对象作为具体的锁对象，所以加锁的细节同样位于 Segment 的 remove 方法中（如下），而具体的实现细节比较直观，做代码注释所示，不再过多撰述。\n\n```java\nfinal V remove(Object key, int hash, Object value) {\n    // 尝试加锁\n    if (!tryLock()) scanAndLock(key, hash);\n    V oldValue = null;\n    try {\n        HashEntry<K,V>[] tab = table;\n        int index = (tab.length - 1) & hash;\n        HashEntry<K,V> e = entryAt(tab, index);  // 找到 key 对应的 entry\n        HashEntry<K,V> pred = null;\n        // 遍历 entry 上的链表寻找目标 key\n        while (e != null) {\n            K k;\n            HashEntry<K,V> next = e.next;\n            // 找到了目标 key\n            if ((k = e.key) == key || (e.hash == hash && key.equals(k))) {\n                V v = e.value;\n                // 如果没有制定期望值，或者当前结点的 value 等于期望值，则执行删除逻辑\n                if (value == null || value == v || value.equals(v)) {\n                    if (pred == null)\n                        // 没有前置结点，则直接将目标结点的 next 结点作为起始节点\n                        setEntryAt(tab, index, next);\n                    else\n                        // 存在前置结点，则修改前置结点的 next 指向目标结点的 next\n                        pred.setNext(next);\n                    ++modCount;\n                    --count;\n                    oldValue = v;\n                }\n                break;\n            }\n            pred = e;\n            e = next;\n        }\n    } finally {\n        unlock();  // 释放锁\n    }\n    return oldValue;\n}\n```\n\n#### 2.4 获取集合的大小：size()\n\n最后我们来一起看一下 size 方法，该方法用于返回当前 map 集合所包含的结点总数目。前面讲解 Segment 类设计的时候，介绍过该类包含一个 count 属性，用于记录分段内结点的总数，并且在具体插入或删除分段内结点时会更新该属性值，那么是不是说这里的 size 方法只需要对所有分段的 count 累加求和返回就行了呢？如果是这样的话那么这里势必要对所有分段加锁，以保证计算的过程中分段内的结构不被更改，否则获取到的 count 极有可能是过期的数据，但是这样的操作性能上将是不太乐观的。\n\n方法 size 的具体实现并没有一上来就加锁，而是先尝试两遍不加锁的累加求和方式，如果两次中所有结点的总数并没有发生变化，则认为计算得到的 size 是可信的，直接返回而不需要加锁，否则再加锁求和也不迟，基于概率统计，这样的设计能够在很大程序上提升整个 ConcurrentHashMap 的性能。具体实现见下面代码注释：\n\n```java\npublic int size() {\n    // Try a few times to get accurate count. On failure due to\n    // continuous async changes in table, resort to locking.\n    final Segment<K,V>[] segments = this.segments;\n    int size;\n    boolean overflow; // 标识当前元素总量是否超过 int 类型上限\n    long sum;         // 各个分段内修改数量的总数\n    long last = 0L;   // 记录上一次各个分段内修改数量的总数\n    int retries = -1; // 重试次数\n    try {\n        for (;;) {\n            if (retries++ == RETRIES_BEFORE_LOCK) {  // 达到重试最大次数，逐个锁定分段\n                for (int j = 0; j < segments.length; ++j)\n                    ensureSegment(j).lock(); // force creation\n            }\n            sum = 0L;  // 记录当前各个分段的修改总量\n            size = 0;  // 记录所有分段的元素总量\n            overflow = false;\n            for (int j = 0; j < segments.length; ++j) {\n                Segment<K,V> seg = segmentAt(segments, j);\n                if (seg != null) {\n                    sum += seg.modCount;  // 累加分段内修改的次数\n                    int c = seg.count;  // 累加分段内元素的总量\n                    if (c < 0 || (size += c) < 0)\n                        overflow = true;  // 标识溢出\n                }\n            }\n            if (sum == last)\n                break;  // 两次检查修改量都没有变化，说明计算的长度 size 可信\n            last = sum;\n        }\n    } finally {\n        if (retries > RETRIES_BEFORE_LOCK) {\n            for (int j = 0; j < segments.length; ++j)\n                segmentAt(segments, j).unlock();  // 释放锁\n        }\n    }\n    // 如果溢出则返回 int 最大值，否则返回真实 size\n    return overflow ? Integer.MAX_VALUE : size;\n}\n```\n\n以上主要列举了典型的几个操作的具体实现细节，实际上只要理解了整个 ConcurrentHashMap 的存储结构设计，具体方法的实现源码阅读起来将会简单许多，甚至有时候会觉得就是应该这样编码实现。不得不说锁分段技术是一种很巧妙的设计，简单的技术原理，简单的源码实现，却能够极大的提升并发的性能。\n\n但最后还是要泼一盆凉水，在写作本文时，jdk 1.8 已经发布，1.8 版本的 ConcurrentHashMap 彻底摒弃了锁分段技术，转而采用 CAS 机制，并引入了红黑树以解决链表过长而导致的性能低下问题，所有的改进都是为了性能的提升，不过这也增加了代码的实现复杂度，1.7 版本的 ConcurrentHashMap 源码仅 1600 多行，而 1.8 版本则增加到 6000 多行，如此复杂的实现不得不让人再次敬佩 [Doug Lea](https://en.wikipedia.org/wiki/Doug_Lea) 大师，以后抽时间笔者再来用一篇《[基于 CAS 机制的 ConcurrentHashMap 实现内幕](/2019/01/31/java/cas-based-concurrent-hashmap/)》的文章，从源码层面探究 1.8 版本 ConcurrentHashMap 的实现细节。\n\n### 参考\n\n1. jdk 1.7 源码\n2. [java 并发编程实战](https://book.douban.com/subject/10484692/)\n3. [探索 ConcurrentHashMap 高并发性的实现机制](https://www.ibm.com/developerworks/cn/java/java-lo-concurrenthashmap/index.html)\n4. [聊聊并发 — 深入分析 ConcurrentHashMap](http://www.infoq.com/cn/articles/ConcurrentHashMap/)\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"Java 异常处理机制与最佳实践","url":"/2016/08/13/java/java-exception/","content":"\n这周小组内的学习是探讨 java 异常处理的最佳实践，今天周末，外面太闷，宅在家里对 java 的异常处理的个人立即做一个总结，如有不对的地方欢迎指正~\n\n### 一. 谈谈个人对 java 异常处理的看法\n\n维基百科对于异常处理的定义是：\n\n> 异常处理，是编程语言或计算机硬件里的一种机制，用于处理软件或信息系统中出现的异常状况（即超出程序正常执行流程的某些特殊条件）。\n\n<!-- more -->\n\nJava 语言从设计之初就提供了对异常处理的支持，并且不同于其它语言，java 对于异常采取了强校验机制，即对于编译期异常需要 API 调用方显式地对异常进行处理，这种强校验机制被一部分人所钟爱，也有一部分人狂吐槽它。持支持观点的人认为这种机制可以极大的提升系统的稳定性，当存在潜在异常的时候强制开发人员去处理异常，而反对的人则认为强制异常处理降低了代码的可读性，一串串的 `try-catch` 让代码看起来不够简洁，并且不正确的使用不仅达不到提升系统稳定性的目的，反而成为了 bug 的良好栖息之地。\n\njava 的异常处理是一把双刃剑，这是我一向持有的观点。个人认为我们不能对 java 的异常处理片面的下一个好或者不好的定义，黑格尔说“存在即合理”，既然 java 的设计者强制要求我们去处理 java 的异常，那么与其在那里吐槽，还不如去学习如何用好 java 的异常处理，让其为提升程序的稳定性所服务。不过从笔者的亲身感受来看，用好 java 的异常处理门槛并不低！\n\n### 二. java 的异常继承体系\n\n![image](/images/2016/java-exception.png)\n\n上图展示了 java 的异常继承体系，Throwable 是整个 java 异常处理的最高抽象（但它不是抽象类哦），它实现了 `Serializable` 接口，然后 java 将异常分为了 Error 和 Exception 两大类。Error 定义了资源不足、约束失败、其它使程序无法继续执行的条件，一般我们在程序中不需要自己去定义额外的 Error，java 设计者提供的 Error 场景几乎覆盖了所有可预见的情况。当程序中存在 Error 时，我们也无须去处理它，因为这种错误一般都是致命的，让程序挂掉是最好的处理方法。\n\n我们一般经常接触到的是 Exception，Error 被翻译为错误，而 Exception 则被翻译成异常，异常可以理解为是轻微的错误，很多时候是不致命的，我们可以 catch 之后，经过处理让程序继续执行。但有时候一些错误虽然是轻微的，但依靠程序本身也无力挽救，即错误和异常之间没有明显的边界，为了解决这个问题，Exception 被设计成了 CheckedException 和 UnCheckedException 两大类，我们可以把 UnCheckedException 看做是介于 Exception 和 Error 的中间产物，有时候它可以被 catch，有时候我们也希望它可以让程序立即挂掉。\n\n- __CheckedException__ ：也称作编译期异常，这类异常强制软件研发人员进行 catch 处理，如果不处理则无法编译通过，这类异常很多时候都是可以恢复的。\n- __UnCheckedException__ ：也称作运行时异常，这类异常不强制要求软件研发人员进行 catch 处理，如果不处理则出现该异常的时候程序会挂掉，这个时候有点接近于 Error，虽然不强制，我们也可以主动去 catch 这些异常，处理之后让程序继续执行，这个时候有点接近于一般的 Exception。\n\n### 三. 最佳实践\n\n> __建议 1：异常应该使用在程序会发生异常的地方__\n\njava 异常处理体系的缺点不光在于降低了程序的可读性，JVM 在对待有 try-catch 代码块的时候的时候往往不能更好的优化，甚至不优化，并且对于一个异常的处理在时间开销上相对是比较昂贵的，所以对于正常的情况，我们不应该使用异常机制去达到自己所揣测的 JVM 对于代码的优化，因为 JVM 在不断的发展和进步中，任何一种优化的教条都不能保证在未来的某个时刻不会被 JVM 用更好的方式替换掉，所以我们在编码的时候更多的应该是去专注代码的逻辑正确和简洁，而不是去琢磨如何编码才能让 JVM 更好地优化，此外我们也不应该用异常去做流程控制，因为前面说过，异常的处理过程开销是昂贵的。总的说来就是我们应该针对潜在异常的程序才使用 java 的异常处理机制，而对于正常的程序流程则不应该试图利用异常去达到某种目的，这样往往会弄巧成拙。\n\n```java\n@Benchmark\n@BenchmarkMode(Mode.SampleTime)\npublic void badTry() {\n\n    int result = 0;\n    int i = 0;\n    try {\n        while (true) {\n            result += this.a[i++];\n        }\n    } catch (ArrayIndexOutOfBoundsException e) {\n        // do nothing\n    }\n\n}\n\n@Benchmark\n@BenchmarkMode(Mode.SampleTime)\npublic void goodTry() {\n\n    int result = 0;\n    for (int i = 0; i < ARRAY_SIZE; i++) {\n        result += this.a[i];\n    }\n\n}\n```\n\n上面两个函数都实现了对数组的遍历求和过程，但是两种方法使用不同的方式来结束这个过程，`badTry` 利用异常机制来终止遍历的过程，而 `goodTry` 则是我们常用的 `foreach` 迭代。咋看一眼，你可能会对 `badTry` 的用法感到不屑，谁特么会去这样写程序，但是如果对JVM的内部优化过程有一定了解的话，那么 `badTry` 的写法也似乎有那么点意思，首先我们来看一下利用 [JMH](http://openjdk.java.net/projects/code-tools/jmh/) 对这两个方法进行测试的时间开销：\n\n```text\n# Run complete. Total time: 00:07:41\n\nBenchmark                     Mode      Cnt    Score    Error  Units\nEffectiveException.badTry   sample     1819  117.413 ±  3.423  ms/op\nEffectiveException.goodTry  sample  5290340   ≈ 10⁻⁴           ms/op\n\n```\n\n_我一般推荐大家在统计程序运行时间的时候用 JMH 工具，而不是利用 `System.currentTimeMillis()` 这种方式去做时间打点。JMH 是 java 的微基准测试框架，相对于时间打点的方式来说，JMH 统计的是程序预热之后 CPU 真正的执行时间，剔除了解释、等待 CPU 分配时间片等时间，所以统计结果更加具备真实性_\n\n回到正题，从上面 JMH 经过 200 次迭代的统计结果来看，`goodTry` 执行的时间约为 10⁻⁴ms，而 `badTry` 则耗费了117.413ms（正负偏差3.423ms），所以可以看异常处理开销还是比较昂贵的，对于这种正常的流程，我们利用异常的机制去控制程序的执行往往会适得其反。\n\n对于数组的遍历，java 在每次访问元素的时候都会去检查一下数组下标是否越界，如果越界则会抛出 `IndexOutOfBoundsException` ，这样给 java 程序猿在编码上带来了便利，但是如果对于一个数组的频繁访问，那么这种边界检查将会是一笔不小的开销，但却是不能省去的步骤，为了提升执行效率，JVM 一般会采取如下优化措施：\n\n1. 如果下标是常量的情况，那么可以在编译器通过数据流分析就可以判定运行的时候是否需要检查\n2. 如果是在循环中利用变量去访问一个数组，那么JVM也可以在编译器分析循环的范围是否在数组边界之内，从而可以消除边界检查\n\n上面例子中的 `badTry` 写法，编码者应该是希望利用 java 的 __隐式异常处理机制__ 来提升程序的运行效率。\n\n```java\n/*\n * 用户调用\n */\nobj.toString();\n\n```\n\n上面的代码为用户的一次普通调用 `obj.toString()`，对于该调用，java 会去判断是否存在空指针异常，所以JVM会将这部分代码编译成下面这个样子：\n\n```java\n/*\n * JVM编译\n */\nif(null != obj) {\n    obj.toString();\n} else {\n    throw new NullPointerException();\n}\n```\n\n如果对于 `obj.toString()` 进行频繁的调用，那么这样的优化势必会造成每一次调用都要去判空，这可是一笔不小的开销，所以 JVM 会利用隐式异常处理机制对上面这部分代码进行再次优化：\n\n```java\n/*\n * JVM隐式异常优化\n */\ntry {\n    obj.toString();\n} catch (segment_fault) {  // Segment Fault信号异常处理器\n    /**\n     * 传入异常处理器中进行恢复并抛出NullPointerException\n     * 用户态->内核态->用户态\n     */\n    exception_handler();\n}\n```\n\n隐式异常处理通过异常机制来减免对于空指针的判定，也就是先执行代码主体，只要不抛异常就继续正常执行，一旦跑了异常说明 `obj` 为空指针，就转去处理异常，然后抛出 `NullPointerException` 来告知用户，这样就不用每次调用之前都去判空了。但是隐式异常也存在一个缺陷，如果上面的代码频繁的抛异常，那么每次 JVM 都要转去处理异常，然后再返回，这个过程是需要由用户态转到内核态处理，处理完成之后再返回用户态，最后向用户抛出 `NullPointerException` 的过程，这可比一次判空的代价要昂贵多了，所以对于频繁异常的情况，我们试图利用异常去控制流程是不合适的，就像我们在最开始的例子给出，当利用 `ArrayIndexOutOfBoundsException` 来结束数组遍历过程的开销是很大的，所以不要用异常去处理正常的执行流程，或者不要用异常去做流程控制。\n\n> __建议 2：如果 API 的调用方能够很好的处理异常，就抛 checked exception，否则 unchecked exception 更加合适__\n\n对于 java 的 `CheckedException`，`UnCheckedException`，以及 `Error`，我们在使用的时候可能经常会去疑惑到底使用哪一种，我始终觉得这没有具体的教条可寻，比如哪种情况一定用哪一种异常，但是我们还是可以总结出一些基本的使用原则。\n\n1. 什么时候使用 Error？\n\nError一般被用于定义资源不足、约束失败、其它使程序无法继续执行的条件的场景，我们经常会在JVM中看到Error的情况，比如OOM，所以对于Error而言，一般不推荐在程序中去主动使用，也不推荐去实现自己的Error，对于有这种需求的情况我们完全可以利用UncheckedException代替。\n\n2. 什么时候使用 CheckedException？\n\n对于 CheckedException 的使用，如果同时满足如下两条原则，则推荐使用，如果不能满足则使用 UnCheckedException 让程序早点挂掉应该是一种更好的选择：\n\n- API 的调用方正确的使用 API 不能阻止异常的发生\n- 一旦异常发生，调用方可以采取有效的应对措施\n\n在设计 API 的时候，抛出 CheckedException 能够暗示调用者对异常手动处理，提升系统稳定性，但是如果调用方也不知道如果更好的处理，那么把异常抛给调用方也没有任何意义，而且 API 每抛出一个 CheckedException，也就意味着 API 调用方需要多一个 catch，则将让程序变的不够简洁。\n\n有些情况下，我们在设计 API 时，可以通过一些技巧来避免抛出 CheckException。比如下面这段代码中，代码的意图在于设计了一个 `File` 类，而整个 `File` 类需要对外提供提供一个 `exec` 方法，但是在执行的时候需要验证该文件的 MD5 值是否正确。\n\n方法 `execShell` 里面给出了两种方案：\n\n1. 只对外提供一个方法，在该方法中先验证 MD5 值，然后执行文件。在验证 MD5 值的时候会抛出 CheckedException，于是 `exec` 方法向外抛出了一个 CodeException，调用该函数的程序不得不去处理该异常。\n2. 对外提供了两个函数：`isCheckSumRight` 和 `exec2`，前者执行 MD5 值验证逻辑，当验证通过则返回 true，否则返回 false，方法 `exec2` 则是执行主体。这样设计 API，调用时先调用 `isCheckSumRight` 方法，然后再调用 `exec2` 方法。\n\n方案二可以免去 CheckedException，让程序更加美观，同时 API 也可以更加灵活。但是这样去重构有两个不太适用的场景，一个是当并发调用时，如果没有做线程安全控制会存在线程安全问题，因为在方法 `isCheckSumRight` 和 `exec2` 之间的瞬间可能会发生状态的改变；另外一个就是如果拆分成两个函数之后，这两个函数之间有重复的逻辑，那么为了性能考虑，这样的拆分也不值得。\n\n比如状态检查函数里面是检查一个文件是否可以被打开，如果可以被打开就在主体函数里面去执行读取文件操作，但是在主体文件中读取文件时我们仍然需要将文件打开一次，于是这个时候就存在了重复，降低了性能，为了代码的美观，去做这样的设计不是好的设计。\n\n```java\npublic void execShell(File file) {\n\n    /*\n     * 方案一\n     */\n    try {\n        file.exec();\n    } catch (CodecException e) {\n        // TODO: handle this exception\n    }\n\n    /*\n     * 方案二\n     * 不适用的情景：\n     * 1.没有同步措施的并发访问\n     * 2.状态检查的执行逻辑与正文函数重复\n     */\n    if (file.isCheckSumRight()) {\n        file.exec2();\n    } else {\n        // TODO: do something\n    }\n\n}\n```\n\n```java\npublic class File<T> {\n\n    private T content;\n\n    private String md5Checksum;\n\n    public File(T content, String md5Checksum, boolean isCheckSum) {\n        this.content = content;\n        this.md5Checksum = md5Checksum;\n    }\n\n    /**\n     * 执行文件\n     * v1.0\n     *\n     * @throws CodecException\n     */\n    public void exec() throws CodecException {\n\n        String md5Value;\n        try {\n            md5Value = CodecUtil.MD5(String.valueOf(this.content));\n        } catch (NoSuchAlgorithmException e) {\n            throw new CodecException(\"no such no such algorithm\", e);\n        } catch (UnsupportedEncodingException e) {\n            throw new CodecException(\"unsupported encoding\", e);\n        }\n\n        if (StringUtils.isNotEmpty(md5Value) && StringUtils.equals(this.md5Checksum, md5Value)) {\n            // TODO: do something\n        } else {\n            // TODO: do something\n        }\n    }\n\n    /**\n     * 文件内容校验\n     *\n     * @return\n     */\n    public boolean isCheckSumRight() {\n\n        boolean checkResult = false;\n        String md5Value;\n        try {\n            md5Value = CodecUtil.MD5(String.valueOf(this.content));\n        } catch (NoSuchAlgorithmException e) {\n            return checkResult;\n        } catch (UnsupportedEncodingException e) {\n            return checkResult;\n        }\n\n        if (StringUtils.isNotEmpty(md5Value) && StringUtils.equals(this.md5Checksum, md5Value)) {\n            checkResult = true;\n        }\n\n        return checkResult;\n\n    }\n\n    /**\n     * 执行文件\n     * v2.0\n     *\n     */\n    public void exec2() {\n        // TODO: do something\n    }\n\n}\n```\n\n3. 什么时候使用 UnCheckedException？\n\nError 和 UnCheckedException 的共同点都是 UnChecked，但是之前有说过一般我们不应该主动使用 Error，所以当需要抛出 Unchecked 异常的时候，UnCheckedException 是我们最好的选择。我们也可以自己去继承 `RuntimeException` 类来定义自己的 UncheckedException。简单的说，当我们发现 CheckedException 不适用的时候，我们应该去使用 UncheckedException，而不是 Error。\n\n- __建议 3：尽量使用 JDK 提供的异常类型__\n\n“不要重复发明车轮”是软件开发中的一句至理名言，在异常的选择上也同样适用，JDK 内置了许多 Exception 类型，当我们需要使用的时候我们应该先去检查 JDK 是否有提供，而不是去实现一个自定义的异常。这样做主要有如下两点好处：\n\n1. 这样的API设计更加容易让调用方理解，减少了调用方的学习成本\n2. 减少了异常类的数目，可以降低程序编译、加载的时间\n\n在使用 JDK 提供的 Exception 类的时候，一定要去阅读一下 docs 对于该 Exception 类的说明，不能只是简单的依据类名去揣测类的用途，一旦揣测错误，将会给 API 的调用方造成困惑。\n\n- __建议 4：使用“异常转译”让语义更清晰__\n\n在软件设计的时候，我们通常会进行分层处理，典型的就是“三层软件设计架构”，即 web 层、业务逻辑层（service），以及持久化层（orm），三层之间相互隔离，不能跨层调用。虽然很多开发者在开发的时候会去注重分层，但是在异常处理方面还是会出现“跨层传播”的现象。比如我们在 orm 层抛出的 DAOException 异常，因为在 service 里面没有经过处理就直接抛给了 web 层，这样就出现了“跨层传播”。这样没有任何好处，web 开发人员在调用服务的时候，需要去捕获一个 DAOException，除了不知道如何去处理，也会让开发人员对于底层的设计疑惑。所以在这种时候我们可以通过“异常转译”，在 service 层对 orm 层抛出的异常进行处理之后，封装成 service 层的异常再抛给web层，如下面的代码：\n\n```java\npublic User getUserInfo(long userId) throws ServiceException {\n\n    User user = new User();\n\n    try {\n        user = userDao.findUserById(userId);\n    } catch (SQLException e) {\n        log.error(\"DB operate exception!\", e);\n        // 异常转译\n        throw new ServiceException(\"DB operate exception!\", e);\n    }\n\n    return user;\n\n}\n```\n\n异常转译值得提倡，但是不能滥用，我们还是要坚持对 CheckedException 处理的原则，不能仅仅捕获后就转译抛出，这样只是让异常在语义上更加易于理解，但是对API的调用并没有起到实质性的帮助。\n\n- __建议 5：推荐为方法的 checken exception 和 unchecken exception 编写文档__\n\n在方法的声明中，我们应该为每个方法编写可能会抛出的所有异常（CheckedException 和 UnCheckedException）利用 `@throws` 关键字编写文档，包括异常的名称，是 CheckedException 还是 UnCheckedException，异常发生的条件等，从而让 API 的调用方能够正确的使用.\n\n- __建议 6：留下罪症，不要偷吃__\n\n当异常发生的时候，我们通常会将其记录到日志文件，事后通过分析日志来查明造成错误的原因，异常在被抛出的时候，我们也可以在栈轨迹中添加一些描述信息，从而让异常更加易于理解，对于描述信息的设置，我们最主要的是要“保留作案现场”，即造成异常的实时条件，比如当造成 `ArrayIndexOutOfBoundsException` 的数组的上下界，以及当前访问的下标等数组，这样会为我们在后面排错起到极大的帮助作用，因为有些 bug 是很难被重现的。\n\n与“保留作案现场”这一良好习惯背道而驰的是“吃异常”，如果不是真的需要，千万不要把异常给吃了，哪怕你不去处理，用日志记录一下都比吃掉它要强很多。说一个故事背景，有一次在重构一个“订单审核服务”项目的时候，将服务部署启动之后，启动日志一切正常，一切都是那么的美好，但是订单审核的结果始终不正确，但是日志就是没有错误，无奈只能去看源码，然后在历史代码里面发现了下面这样一串：\n\n```java\ntry{\n\n    // 具体算法模型文件加载逻辑\n\n}catch (FileNotFoundException e) {\n\n    try{\n\n        throw new IOException(e);\n\n    } catch (IOException ee) {\n        // 他把异常给吃了！！！\n    }\n\n}\n```\n\n先不去讨论这段代码写的是有多奇葩，造成上面现象的主要原因是当算法模型文件找不到，发生异常的时候，这个异常吃掉了，catch 之后不做任何处理，连用日志记录一下都没有，它就这样无声无息地从这个宇宙中消失了，给我造成了 10000 点伤害。所以如果不是必须，我们在代码里面千万不要去把异常吃掉，这样会让原本提升系统稳定性的 java 异常处理机制成为 bug 的良好栖息之地！\n\n##### 参考\n\n1. [Effective Java 2nd Edition](http://www.ebooksbucket.com/uploads/itprogramming/java/Effective_Java_2nd_Edition.pdf)\n2. [透过 JVM 看 Exception 的本质](http://icyfenix.iteye.com/blog/857722)\n","tags":["Java"],"categories":["java"]},{"title":"转载：为什么要使用 slf4j 而不是 log4j","url":"/2016/08/07/java/slf4j-log4j/","content":"\n每一个 java 程序员都知道日志对于任何一个 java 应用程序，尤其是服务端程序是至关重要的，而很多程序员也已经熟悉各种不同的日志库，如 java.util.logging、Apache log4j，以及 logback 等。但如果你还不知道 slf4j（Simple logging facade for Java）的话，那么是时候去在你项目中学习使用 slf4j 了。\n\n在这篇文章中，我们将学习为什么使用 slf4j 比 log4j 或者 java.util.logging 要优秀。自从上次我写 java 程序员的 10 个日志技巧已经有一段时间了，我已经不记得我写的关于日志的一切了。<!-- more -->\n\n不管怎样，让我们回到这个话题，slf4j 不同于其他日志类库，与其它有很大的不同。 __slf4j(Simple logging Facade for Java)不是一个真正的日志实现，而是一个抽象层（abstraction layer），它允许你在后台使用任意一个日志类库__ 。如果是在编写供内外部都可以使用的 API 或者通用类库，那么你真不会希望使用你类库的客户端必须使用你选择的日志类库。\n\n如果一个项目已经使用了 log4j，而你加载了一个类库，比方说 Apache Active MQ，它依赖于于另外一个日志类库 logback，那么你就需要把它也加载进去。但如果 Apache Active MQ 使用了 slf4j，你可以继续使用你的日志类库而无语忍受加载和维护一个新的日志框架的痛苦。\n\n总的来说，slf4j 使你的代码独立于任意一个特定的日志 API，这是一个对于开发API的开发者很好的思想。虽然抽象日志类库的思想已经不是新鲜的事物而且 Apache commons logging 也已经在使用这种思想了，但现在 slf4j 正迅速成为 java 世界的日志标准。让我们再看看几个使用 slf4j 而不是 log4j、logback 或者 java.util.logging 的理由。\n\n### slf4j 对比 log4j，logback 和 java.util.Logging 的优势\n\n正如我之前说的，在你的代码中使用 slf4j 写日志语句的主要出发点是使得你的程序独立于任意特定的日志类库，依赖于特定类可能需要不同与你已有的配置，并且导致更多维护的麻烦。但除此之外，还要一个 slf4j API 的特性使得我坚持使用 slf4j 而抛弃我长期间钟爱的 log4j 的理由，是被称为占位符(place holder)，在代码中表示为 “{}” 的特性。占位符是一个非常类似于在 String 的 format() 方法中的 %s，因为它会在运行时被某个提供的实际字符串所替换。这不仅降低了你代码中字符串连接次数，而且还节省了新建的 String 对象。即使你可能没需要那些对象，但这个依旧成立，取决于你的生产环境的日志级别，例如在 DEBUG 或者 INFO 级别的字符串连接。因为 String 对象是不可修改的并且它们建立在一个 String 池中，它们消耗堆内存(heap memory)而且大多数时间他们是不被需要的，例如当你的应用程序在生产环境以 ERROR 级别运行时候，一个 String 使用在 DEBUG 语句就是不被需要的。\n\n通过使用 slf4j，你可以在运行时延迟字符串的建立，这意味着只有需要的 String 对象才被建立。而如果你已经使用 log4j，那么你已经对于在 if 条件中使用 debug 语句这种变通方案十分熟悉了，但 slf4j 的占位符就比这个好用得多。\n\n这是你在 log4j 中使用的方案，但肯定这一点都不有趣并且降低了代码可读性因为增加了不必要的繁琐重复代码(boiler-plate code)：\n\n```java\nif (logger.isDebugEnabled()) {\n    logger.debug(\"Processing trade with id: \" + id + \" symbol: \" + symbol);\n}\n```\n\n另一方面，如果你使用 slf4j 的话，你可以得到在极简洁的格式的结果，就像以下展示的一样：\n\n```java\nlogger.debug(\"Processing trade with id: {} and symbol : {} \", id, symbol);\n```\n\n在 slf4j，我们不需要字符串连接而且不会导致暂时不需要的字符串消耗。取而代之的，我们在一个以占位符和以参数传递实际值的模板格式下写日志信息。你可能会在想万一我有很个参数怎么办？嗯，那么你可以选择使用变量参数版本的日志方法或者用以 Object 数组传递。这是一个相当的方便和高效方法的打日志方法。记住，在生产最终日志信息的字符串之前，这个方法会检查一个特定的日志级别是不是打开了，这不仅降低了内存消耗而且预先降低了 CPU 去处理字符串连接命令的时间。这里是使用 slf4j 日志方法的代码，来自于 slf4j-log4j12-1.6.1.jar 中的 log4j 的适配器类 log4jLoggerAdapter。\n\n```java\npublic void debug(String format, Object arg1, Object arg2) {\n    if (logger.isDebugEnabled()) {\n        FormattingTuple ft = MessageFormatter.format(format, arg1, arg2);\n        logger.log(FQCN, Level.DEBUG, ft.getMessage(), ft.getThrowable());\n    }\n}\n```\n\n同时，我们也很值得知道打日志是对应用程序的性能有着很大影响的，在生产环节上只进行必要的日志记录是我们所建议的。\n\n### 怎么用 slf4j 做 log4j 的日志记录\n\n除了以上好处，我想还有一个告诫，就是为了使用 slf4j，你不仅需要包含 slf4j 的 API jar 包，例如  slf4j-api-1.6.1.jar，还需要相关 jar 包，这取决于你在后台使用的日志类库。如果你想要使用和 log4j  一起使用 slf4j ，Simple Logging Facade for Java,，你需要包含以下的 jar 包在你的 classpath 中，取决于哪个 slf4j 和你在使用的 log4j 的版本。例如：\n\n```text\nslf4j-api-1.6.1.jar – JAR for slf4j API\nlog4j-1.2.16.jar – JAR for log4j API\nslf4j-log4j12-1.6.1.jar – log4j Adapter for slf4j\n```\n\n如果你在使用 maven 去管理你的项目依赖，你只需要包含 slf4j jar 包，maven 会包含它的依赖的相关包。为了和 slf4j 一起中使用 log4j，你可以包含以下的依赖在你项目中的 pom.xml。\n\n```xml\n<dependency>\n    <groupId>org.slf4j</groupId>\n    <artifactId>slf4j-log4j12</artifactId>\n    <version>1.6.1</version>\n</dependency>\n<dependency>\n    <groupId>org.slf4j</groupId>\n    <artifactId>slf4j-log4j12</artifactId>\n    <version>1.6.1</version>\n</dependency>\n```\n\n还有，如果你对于使用变量参数版本（variable argument version ）的日志方法感兴趣的话，那么就导入 slf4j 1.7 的版本吧。\n\n### 总结\n\n总结这次说的，我建议使用 slf4j 的而不是直接使用 log4j, commons logging, logback 或者 java.util.logging 已经足够充分了。\n\n1. 在你的开源或内部类库中使用 slf4j 会使得它独立于任何一个特定的日志实现，这意味着不需要管理多个日志配置或者多个日志类库，你的客户端会很感激这点。\n2. slf4j 提供了基于占位符的日志方法，这通过去除检查 isDebugEnabled(), isInfoEnabled() 等等，提高了代码可读性。\n3. 通过使用 slf4j 的日志方法，你可以延迟构建日志信息（Srting）的开销，直到你真正需要，这对于内存和CPU都是高效的。\n4. 作为附注，更少的暂时的字符串意味着垃圾回收器（Garbage Collector）需要做更好的工作，这意味着你的应用程序有为更好的吞吐量和性能。\n5. 这些好处只是冰山一角，你将在开始使用 slf4j 和阅读其中代码的时候知道更多的好处。我强烈建议，任何一个新的 java 程序员，都应该使用 slf4j 做日志而不是使用包括 log4j 在内的其他日志 API。\n\n转自：[http://www.importnew.com/7450.html](http://www.importnew.com/7450.html)\n","tags":["Java"],"categories":["java"]},{"title":"理清 CountDownLatch 与 CyclicBarrier 的区别","url":"/2015/11/05/java/latch-and-barrier/","content":"\n对于刚接触同步器的同学来说，CountDownLatch 和 CyclicBarrier 应该是两个比较容易混淆的组件，它们都能表示让多个线程等待某个特定事件的语义，不过在功能上还是存在一些差别，实际上它们的 __主要区别在于参与的线程是否需要阻塞相互等待一起到达事件的位置，然后再继续向下执行__ 。官方对这两个组件的定义分别如下：\n\n> - __CountDownLatch__ : A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.\n> - __CyclicBarrier__ : A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.\n\n看了之后是不是更加迷惑？下面我们通过举例来理清这二者的区别。<!-- more -->\n\n### CountDownLatch\n\n首先来看一下 CountDownLatch，我们可以简单将其理解为一个计数器，当初始化一个 `count=n` 的 CountDownLatch 对象之后，需要调用该对象的 `CountDownLatch#countDown` 方法来对计数器进行减值，直到计数器为 0 的时候，等待该计数器的线程才能继续执行。但是需要注意的一点是，执行 `CountDownLatch#countDown` 方法的线程在执行完减值操作之后，并不会因此而阻塞。真正阻塞等待事件的是调用 CountDownLatch 对象 `CountDownLatch#await` 方法的线程，该线程一直会阻塞直到计数器计数变为 0 为止。\n\n先来举一个学生考试的例子，一般的考试都是一群学生坐在一个教室里面，等到规定的时间一起开始答题。因为每个学生资历的不同，所以学生在答题完成时间上有先有后，我们允许学生提前交卷。每个考场都有一个考官，负责收发试卷，以及维护考场秩序，考官必须等到收齐所有考生的试卷之后才能离开。这里我们可以利用两个 CountDownLatch 对象来模拟整个过程，假设有一名考官和三个考生参与整个过程，而每个个体都可以看做是一个独立的线程，示例实现如下：\n\n```java\nprivate static final CountDownLatch START = new CountDownLatch(1);\nprivate static final CountDownLatch END = new CountDownLatch(3);\n\nprivate static class Student implements Runnable {\n\n    @Override\n    public void run() {\n        try {\n            // 等待考试\n            System.out.println(Thread.currentThread().getName() + \" is waiting\");\n            START.await();\n            // 开始考试\n            TimeUnit.SECONDS.sleep(RandomUtils.nextInt(1, 5));\n            System.out.println(Thread.currentThread().getName() + \" finished\");\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            // 交卷\n            END.countDown();\n            System.out.println(Thread.currentThread().getName() + \" is over\");\n        }\n    }\n}\n\npublic static void main(String[] args) throws Exception {\n    new Thread(new Student(), \"A\").start();\n    new Thread(new Student(), \"B\").start();\n    new Thread(new Student(), \"C\").start();\n    TimeUnit.SECONDS.sleep(3);\n    System.out.println(\"Start\");\n    // 老师宣布开始考试\n    START.countDown();\n    // 等待学生交卷\n    END.await();\n    TimeUnit.SECONDS.sleep(1);\n    System.out.println(\"End\");\n}\n```\n\n运行结果：\n\n```text\nA is waiting\nB is waiting\nC is waiting\nStart\nB finished\nB is over\nC finished\nC is over\nA finished\nA is over\nEnd\n```\n\n由上面的例子可以看到 CountDownLatch 阻塞的是调用 `CountDownLatch#await` 方法的线程，而执行 `CountDownLatch#countDown` 方法的线程在执行完计数器计数之后并不会阻塞，而是继续往下执行。\n\n### CyclicBarrier\n\n下面继续来看一下 CyclicBarrier，在初始化构造 CyclicBarrier 时也需要指定计数器大小，同时我们还可以选择性的指定一个 Runnable 实现，当计数器计数完成时会回调执行该 Runnable 实现。相对于 CountDownLatch 来说，参与到 CyclicBarrier 中的线程执行计数器计数发生于 `CyclicBarrier#await` 方法中，不过这里的计数会阻塞当前线程直到计数变为 0，或阻塞被中断为止。\n\n最终的效果就是所有参与的线程都会在计数器变为 0 时一起被唤醒，然后继续向下执行。另外相对于 CountDownLatch 的一次性使用而言，CyclicBarrier 对象是可以被重用的，你可以理解为当前计数器变为 0，且所有的参与阻塞的线程都被唤醒之后，计数器立刻又恢复到最初设置的计数值，从而能够被再次使用。\n\n这里我们利用签到的过程来演示 CyclicBarrier 的使用。假设几个人需要一起跟团出去旅游，大家约定好时间、地点，集合一起出发，其中有一个导游负责整个旅行的签到和旅途安排。假定有一名导游和三个游客参与整个过程，而每个个体都可以看做是一个独立的线程，示例实现如下：\n\n```java\nprivate static class Tourist implements Runnable {\n\n    private CyclicBarrier cyclicBarrier;\n\n    public Tourist(CyclicBarrier cyclicBarrier) {\n        this.cyclicBarrier = cyclicBarrier;\n    }\n\n    @Override\n    public void run() {\n        try {\n            for (int i = 0; i < 2; i++) {\n                TimeUnit.SECONDS.sleep(RandomUtils.nextInt(1, 6));\n                System.out.println(\"[\" + i + \"] \" + Thread.currentThread().getName() + \" check in\");\n                cyclicBarrier.await();\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        System.out.println(Thread.currentThread().getName() + \" is over\");\n    }\n}\n\npublic static void main(String[] args) throws Exception {\n    CyclicBarrier barrier = new CyclicBarrier(3, () -> System.out.println(\"Let's go\"));\n    Tourist tourist = new Tourist(barrier);\n    new Thread(tourist, \"A\").start();\n    new Thread(tourist, \"B\").start();\n    new Thread(tourist, \"C\").start();\n}\n```\n\n运行结果：\n\n```text\n[0] C check in\n[0] A check in\n[0] B check in\nLet's go\n[1] C check in\n[1] B check in\n[1] A check in\nLet's go\nA is over\nC is over\nB is over\n```\n\n我们可以看到在所有人（线程）在都到达之前，其他人（线程）即使先到了也要阻塞等待，这里为了演示 CyclicBarrier 的可重用性，我们增加了一次循环。\n\n最后我们再来通过一个约饭的例子将 CountDownLatch 和 CyclicBarrier 结合起来设计一个程序。假设一个宿舍有三个人约好晚上一起吃饭，这三个同学一个在寝室，一个在实验室，另外一个在公司实习，大家都约好下午 5 点出发赶往目的地，先到的需要等待，直到三个人都到了才开吃，示例实现如下：\n\n```java\nprivate static CountDownLatch latch = new CountDownLatch(1);\n\nprivate static class Person implements Runnable {\n\n    private CyclicBarrier barrier;\n\n    public Person(CyclicBarrier barrier) {\n        this.barrier = barrier;\n    }\n\n    @Override\n    public void run() {\n        try {\n            String name = Thread.currentThread().getName();\n            System.out.println(name + \" is ready to go\");\n            latch.await();\n            System.out.println(name + \" is on the way\");\n            TimeUnit.SECONDS.sleep(RandomUtils.nextInt(1, 6));\n            System.out.println(name + \" arrived\");\n            barrier.await();\n            TimeUnit.SECONDS.sleep(RandomUtils.nextInt(1, 6));\n            System.out.println(name + \" ate up\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n\npublic static void main(String[] args) throws Exception {\n    CyclicBarrier barrier = new CyclicBarrier(3, () -> System.out.println(\"Let's eat~\"));\n    new Thread(new Person(barrier), \"A\").start();\n    new Thread(new Person(barrier), \"B\").start();\n    new Thread(new Person(barrier), \"C\").start();\n    TimeUnit.SECONDS.sleep(3);\n    latch.countDown();\n}\n```\n\n运行结果：\n\n```text\nA is ready to go\nB is ready to go\nC is ready to go\nA is on the way\nB is on the way\nC is on the way\nB arrived\nC arrived\nA arrived\nLet's eat~\nB ate up\nA ate up\nC ate up\n```\n\n上述例子中，我们利用 CountDownLatch 来约束大家（参与的线程）到点儿了一起出发，并用 CyclicBarrier 来约束大家需要等到所有人都到了再一起开吃。所以虽然这两个组件都表示等待的语义，但是各自拥有属于自己不同的特性，只有理解了它们的区别之后才能在特定场景下选择正确的组件来实现相应的逻辑。\n\n### 总结\n\n本文基于示例介绍了 CountDownLatch 和 CyclicBarrier 各自的用途，最后我们来总结一下 CountDownLatch 和 CyclicBarrier 的区别：\n\n1. CountDownLatch 用于阻塞当前 1 个或多个线程，其目的是让这些线程等待其它线程的执行完成。\n2. CyclicBarrier 用于阻塞当前多个线程，其目的是让这些线程彼此之间相互等待，当这些线程均到达屏障后再一起往下执行。\n3. CountDownLatch 是一次性的，而 CyclicBarrier 在使用完成之后允许被重置以复用。\n","tags":["并发编程","Java"],"categories":["java"]},{"title":"转载：Cookies 中的那些事儿","url":"/2015/10/04/protocol/http-cookies/","content":"\nHTTP cookies，通常称之为 “cookie”，已经存在很长时间了，但是仍然没有被充分理解。首要问题是存在许多误解，认为 cookie 是后门程序或病毒，却忽视了其工作原理。第二个问题是，对于 cookie 的操作缺少统一的接口。尽管存在这些问题，cookie 仍旧在 Web 开发中扮演者重要的角色，以至于如果没有出现相应的代替品就消失的话，我们许多喜欢的 Web 应用将变的不可用。<!-- more -->\n\n### 一. Cookie 的起源与定义\n\n早期的 Web 应用面临的最大问题之一就是如何维持状态。简言之，服务器无法知道两个请求是否来自于同一个浏览器。当时，最简单的办法就是在请求的页面中插入一个 token，然后在下次请求时将这个 token 返回至服务器。这需要在页面的 form 表单中插入一个包含 token 的隐藏域，或者将 token 放在 URL 的 query 字符串中来传递。这两种方法都需要手动操作，而且极易出错。\n\n当时网景通讯的一名员工 [Lou Montulli](https://en.wikipedia.org/wiki/Lou_Montulli)，在 1994 年将 “[magic cookies](https://en.wikipedia.org/wiki/Magic_cookie)” 的概念应用到 Web 通讯中。他试图解决 Web 的第一个购物车应用，现在购物车成了购物网站的支柱。他的 [原始说明文档](https://curl.haxx.se/rfc/cookie_spec.html) 提供了 cookie 工作原理的基本信息，该文档后来被作为规范纳入到 [RFC 2109](http://tools.ietf.org/html/rfc2109)（大多数浏览器的实现参考文档）中，最终被纳入到 [RFC 2965](http://tools.ietf.org/html/rfc2965) 中。Montulli 也被授予 cookie 的美国专利。网景浏览器在它的第一个版本中就开始支持 cookie，现在所有 Web 浏览器都支持 cookie。\n\n至于 cookie 是什么，简单地说，cookie 就是浏览器储存在用户电脑上的一小段文本文件。cookie 是纯文本格式，不包含任何可执行的代码。一个 Web 页面或服务器告知浏览器按照一定规范来储存这些信息，并在随后的请求中将这些信息发送至服务器，Web 服务器就可以使用这些信息来识别不同的用户。大多数需要登录的网站在用户验证成功之后都会设置一个 cookie，只要这个 cookie 存在并可以，用户就可以自由浏览这个网站的任意页面。再次说明，cookie 只包含数据，就其本身而言并不有害。\n\n### 二. Cookie 的创建与编码\n\nWeb 服务器通过发送一个称为 Set-Cookie 的 HTTP 消息头来创建一个 cookie，Set-Cookie 消息头是一个字符串，其格式如下（中括号的部分是可选的）：\n\n```http\nSet-Cookie: value[; expires=date][; domain=domain][; path=path][; secure]\n```\n\n消息头的第一部分，value 部分，通常是一个 `name=value` 格式的字符串。事实上这种格式是原始规范中指定的格式，但是浏览器并不会对 cookie 值按照此格式来验证。实际上，你可以指定一个不含等号的字符串，它同样会被存储。然而，最常用的使用方式是按照 `name=value` 格式来指定 cookie 的值（大多数接口只支持该格式）。\n\n当存在一个 cookie 并允许设置可选项，该 cookie 的值会在随后的每次请求中被发送至服务器，cookie 的值被存储在名为 Cookie 的 HTTP 消息头中，并且只包含了 cookie 的值，忽略全部设置选项。例如：\n\n```http\nCookie: value\n```\n\n通过 Set-Cookie 指定的可选项只会在浏览器端使用，而不会被发送至服务器端。发送至服务器的 cookie 的值与通过 Set-Cookie 指定的值完全一样，不会有进一步的解析或转码操作。如果请求中包含多个 cookie，它们将会被分号和空格分开，例如：\n\n```http\nCookie: value1; value2; name1=value1\n```\n\n服务器端框架通常包含解析 cookie 的方法，可以通过编程的方式获取 cookie 的值。\n\n在自动编码方面，一直都存在一些困惑。普遍认为 cookie 的值必须经过 URL 编码，但其实这是一个谬论，尽管通常都这么做。 __原始规范中明确指出只有三个字符必须进行编码：分号、逗号和空格，规范中还提到可以进行 URL 编码，但并不是必须，在 RFC 中没有提及任何编码__ 。然而，几乎所有的实现都对 cookie 的值进行了一系列的 URL 编码。对于 `name=value` 格式，通常会对 name 和 value 分别进行编码，而不对等号 = 进行编码操作。\n\n### 三. 过期时间选项\n\n紧跟 cookie 值后面的每个选项都以分号和空格分开，每个选择都指定了 cookie 在什么情况下应该被发送至服务器。第一个选项是过期时间（expires），指定了 cookie 何时不会再被发送至服务器，随后浏览器将删除该 cookie。该选项的值是一个 `Wdy, DD-Mon-YYYY HH:MM:SS GMT` 日期格式的值，例如：\n\n```http\nSet-Cookie: name=Nicholas; expires=Sat, 02 May 2009 23:38:25 GMT\n```\n\n没有设置 expires 选项时，cookie 的生命周期仅限于当前会话中，关闭浏览器意味着这次会话的结束，所以会话 cookie 仅存在于浏览器打开状态之下。这就是为什么当你登录一个 Web 应用时经常会看到一个复选框，询问你是否记住登录信息：如果你勾选了复选框，那么一个 expires 选项会被附加到登录 cookie 中。如果 expires 设置了一个过去的时间点，那么这个 cookie 会被立即删掉。\n\n### 四. 跨域控制\n\n#### 4.1 domain\n\ndomain 选项指定了 cookie 将要被发送至哪个或哪些域中。默认情况下，domain会被设置为创建该 cookie 的页面所在的域名，所以当给相同域名发送请求时该 cookie 会被发送至服务器。例如，本博客中 cookie 的默认值将是 `bubkoo.com`。domain 选项可用来扩充 cookie 可发送域的数量，例如：\n\n```http\nSet-Cookie: name=Nicholas; domain=nczonline.net\n```\n\n像 Yahoo! 这种大型网站，都会有许多 `name.yahoo.com` 形式的站点（例如：`my.yahoo.com`, `finance.yahoo.com` 等等）。将一个 cookie 的 domain 选项设置为 `yahoo.com`，就可以将该 cookie 的值发送至所有这些站点。浏览器会把 domain 的值与请求的域名做一个尾部比较（即从字符串的尾部开始比较），并将匹配的 cookie 发送至服务器。\n\ndomain 选项的值必须是发送 Set-Cookie 消息头的主机名的一部分，例如我不能在 google.com 上设置一个 cookie，因为这会产生安全问题，不合法的 domain 选择将直接被忽略。\n\n补充：\n\n> There is a distinction between the _Domain_ attribute value and the effective domain: the former is taken from the Set-Cookie header field and the latter is the interpretation of that attribute value. According to the RFC 2965, the following should apply:\n>\n> - If the Set-Cookie header field does not have a _Domain_ attribute, the effective domain is the domain of the request.\n> - If there is a _Domain_ attribute present, its value will be used as effective domain (if the value does not start with a `.` it will be added by the client).\n>\n> Having the effective domain it must also [domain-match](https://tools.ietf.org/html/rfc6265#section-5.1.3) the current requested domain for being set; otherwise the cookie will be revised. The same rule applies for choosing the cookies to be sent in a request.\n>\n> Mapping this knowledge onto your questions, the following should apply:\n>\n> - Cookie with `Domain=.example.com` will be available for `www.example.com`\n> - Cookie with `Domain=.example.com` will be available for `example.com`\n> - Cookie with `Domain=example.com` will be converted to `.example.com` and thus will also be available for `www.example.com`\n> - Cookie with `Domain=example.com` will not be available for `anotherexample.com`\n> - `www.example.com` will be able to set cookie for `example.com`\n> - `www.example.com` will not be able to set cookie for `www2.example.com`\n> - `www.example.com` will not be able to set cookie for `.com`\n>\n> And to set and read a cookie for/by `www.example.com` and `example.com`, set it for `.www.example.com` and `.example.com` respectively. But the first (`.www.example.com`) will only be accessible for other domains below that domain (e.g. `foo.www.example.com` or `bar.www.example.com`) where `.example.com` can also be accessed by any other domain below `example.com` (e.g. `foo.example.com` or `bar.example.com`).\n\n也就是说只有主域名，比如 `zhenchao.org` 与 `.zhenchao.org` 是等价的（因为前者会自动被转换成后者），对于其子域名来说是不等价的，比如 `.blog.zhenchao.org` 只能是 `a.blog.zhenchao.org` 或 `b.blog.zhenchao.org` 能够访问，而 `blog.zhenchao.org` 是访问不到的。\n\n#### 4.2. path\n\n另一个控制 Cookie 消息头发送时机的选项是 path 选项，和 domain 选项类似，path选项指定了请求的资源 URL 中必须存在指定的路径时，才会发送Cookie 消息头。这个比较通常是将 path 选项的值与请求的 URL 从头开始逐字符比较完成的。如果字符匹配，则发送 Cookie 消息头，例如：\n\n```http\nSet-Cookie:name=Nicholas;path=/blog\n```\n\n在这个例子中，path 选项值会与 `/blog`，`/blogrool` 等相匹配；任何以 `/blog` 开头的选项都是合法的。需要注意的是，只有在 domain 选项核实完毕之后才会对 path 属性进行比较。path 属性的默认值是发送 Set-Cookie 消息头所对应的 URL 中的 path 部分。\n\n#### 4.3 secure\n\n最后一个选项是 secure。不像其它选项，该选项只是一个标记而没有值。只有当一个请求通过 SSL 或 HTTPS 创建时，包含 secure 选项的 cookie 才能被发送至服务器。这种 cookie 的内容具有很高的价值，如果以纯文本形式传递很有可能被篡改，例如：\n\n```http\nSet-Cookie: name=Nicholas; secure\n```\n\n事实上，机密且敏感的信息绝不应该在 cookie 中存储或传输，因为 cookie 的整个机制原本都是不安全的。默认情况下，在 HTTPS 链接上传输的 cookie 都会被自动添加上 secure 选项。\n\n### 五. Cookie 的维护和生命周期\n\n在一个 cookie 中可以指定任意数量的选项，并且这些选项可以是任意顺序，例如：\n\n```http\nSet-Cookie:name=Nicholas; domain=nczonline.net; path=/blog\n```\n\n这个 cookie 有四个标识符：cookie 的 name，domain，path，secure 标记，其中 name， domain，path 三个维度用来标识一个 cookie。要想改变这个 cookie 的值，需要发送另一个具有相同 name，domain，path 的 Set-Cookie 消息头。例如：\n\n```http\nSet-Cookie: name=Greg; domain=nczonline.net; path=/blog\n```\n\n这将覆盖原来 cookie 的值。但是修改 cookie 选项的任意一个标识都将创建一个完全不同的新 cookie，例如：\n\n```http\nSet-Cookie: name=Nicholas; domain=nczonline.net; path=/\n```\n\n这个消息头返回之后，会同时存在两个名为 “name” 的不同的 cookie。如果你访问 `www.nczonline.net/blog` 下的一个页面，以下的消息头将被包含进来：\n\n```http\nCookie: name=Greg; name=Nicholas\n```\n\n在这个消息头中存在了两个名为 “name” 的 cookie， __path 值越详细则 cookie 越靠前__ 。 按照 domain-path-secure 的顺序，设置越详细的 cookie 在字符串中越靠前。假设我在 `ww.nczonline.net/blog` 下用默认选项创建了另一个 cookie：\n\n```http\nSet-Cookie: name=Mike\n```\n\n那么返回的消息头现在则变为：\n\n```http\nCookie: name=Mike; name=Greg; name=Nicholas\n```\n\n以 “Mike” 作为值的 cookie 使用了域名 `www.nczonline.net` 作为其 domain 值并且以全路径（/blog）作为其 path 值，则它较其它两个 cookie 更加详细。\n\n当 cookie 创建时指定了失效日期，这个失效日期则关联了以 name-domain-path-secure 为标识的 cookie。要改变一个 cookie 的失效日期，你必须指定同样的组合。当改变一个 cookie 的值时，你不必每次都设置失效日期，因为它不是 cookie 标识信息的组成部分。例如：\n\n```http\nSet-Cookie:name=Mike;expires=Sat,03 May 2025 17:44:22 GMT\n```\n\n现在已经设置了 cookie 的失效日期，所以下次我想要改变 cookie 的值时，我只需要使用它的名字：\n\n```http\nSet-Cookie:name=Matt\n```\n\ncookie 的失效日期并没有改变，因为 cookie 的标识符是相同的。实际上，只有你手工的改变 cookie 的失效日期，否则其失效日期不会改变。这意味着在同一个会话中，一个会话 cookie 可以变成一个持久化 cookie（一个可以在多个会话中存在的），反之则不可。为了要将一个持久化 cookie 变为一个会话 cookie，你必须删除这个持久化 cookie，这只要设置它的失效日期为过去某个时间之后再创建一个同名的会话 cookie 就可以实现。\n\n需要注意的是失效日期是以浏览器运行的电脑上的系统时间为基准进行核实的。没有任何办法来来验证这个系统时间是否和服务器的时间同步，所以当服务器时间和浏览器所处系统时间存在差异时这样的设置会出现错误。\n\n### 六. Cookie 自动删除\n\ncookie 会被浏览器自动删除，通常存在以下几种原因：\n\n- 会话 cooke (Session cookie) 在会话结束时（浏览器关闭）会被删除\n- 持久化 cookie（Persistent cookie）在到达失效日期时会被删除\n- 如果浏览器中的 cookie 数量达到限制，那么 cookie 会被删除以为新建的 cookie 创建空间\n\n对于自动删除来说，Cookie 管理显得十分重要，因为这些删除都是无意识的。\n\n### 七. Cookie 限制条件与 SubCookies\n\ncookie 存在许多限制条件以阻止 cookie 滥用并保护浏览器和服务器免受一些负面影响。有两种 cookie 限制条件：cookie 的属性和 cookie 的总大小。\n\n原始规范中限定每个域名下不超过 20 个 cookie，早期的浏览器都遵循该规范，并且在 IE7 中有更近一步的提升。在微软的一次更新中，他们在 IE7 中增加 cookie 的限制数量到 50 个，与此同时 Opera 限定 cookie 数量为 30 个，Safari 和 Chrome 对与每个域名下的 cookie 个数没有限制。\n\n发向服务器的所有 cookie 的最大数量（空间）仍旧维持原始规范中所指出的：4KB。所有超出该限制的 cookie 都会被截掉并且不会发送至服务器。\n\n鉴于 cookie 的数量存在限制，开发者提出 subcookies 的观点来增加 cookie 的存储量。Subcookies 是存储在一个 cookie 值中的一些 name-value 对，通常与以下格式类似：\n\n```http\nname=a=b&c=d&e=f&g=h\n```\n\n这种方式允许在单个 cookie 中保存多个 name-value 对，而不会超出浏览器 cookie 数量的限制。通过这种方式创建 cookie 的负面影响是，需要自定义解析方式来提取这些值，相比较而言 cookie 的格式会更为简单。服务器端框架已开始支持 subcookies 的存储。\n\n### 八. JavaScript 中的 Cookies 与 Http Only\n\n在 js 中通过 document.cookie 属性，你可以创建、维护和删除 cookie。创建 cookie 时该属性等同于 Set-Cookie 消息头，而在读取 cookie 时则等同于 Cookie 消息头。在创建一个 cookie 时，你需要使用和 Set-Cookie 期望格式相同的字符串：\n\n```javascript\ndocument.cookie=\"name=Nicholas;domain=nczonline.net;path=/\";\n```\n\n设置 document.cookie 属性的值并不会删除存储在页面中的所有 cookie。它只简单的创建或修改字符串中指定的 cookie。下次发送一个请求到服务器时，通过 document.cookie 设置的 cookie 会和其它通过 Set-Cookie 消息头设置的 cookie 一并发送至服务器。这些 cookie 并没有什么明确的不同之处。\n要使用 js 提取 cookie 的值，只需要从 document.cookie 中读取即可。返回的字符串与 Cookie 消息头中的字符串格式相同，所以多个 cookie 会被分号和字符串分割。例如：\n\n```http\nname1=Greg; name2=Nicholas\n```\n\n鉴于此，你需要手工解析这个 cookie 字符串来提取真实的 cookie 数据。当前已有许多描述如何利用 js 来解析 cookie 的资料。通常利用已存在的 js 库操作 cookie 会更简单，如使用 YUI Cookie utility 来处理 cookie，而不要手工重新创建这些算法。\n\n通过访问 document.cookie 返回的 cookie 遵循发向服务器的 cookie 一样的访问规则。要通过 js 访问 cookie，该页面和 cookie 必须在相同的域中，有相同的 path，有相同的安全级别。\n\n__注意__ ：一旦 cookie 通过 js 设置后便不能提取它的选项，所以你将不能知道 domain，path，expires 日期或 secure 标记。\n\n微软的 IE6 SP1 在 cookie 中引入了一个新的选项：HTTP-Only，HTTP-Only 背后的意思是告之浏览器该 cookie 绝不能通过 js 的 document.cookie 属性访问。设计该特征意在提供一个安全措施来帮助阻止通过 js 发起的跨站脚本攻击 (XSS) 窃取 cookie 的行为。今天 Firefox2.0.0.5+、Opera9.5+、Chrome 都支持 HTTP-Only cookie，但 3.2 版本的 Safari 仍不支持。\n\n要创建一个 HTTP-Only cookie，只要向你的 cookie 中添加一个 HTTP-Only 标记即可：\n\n```http\nSet-Cookie: name=Nicholas; HttpOnly\n```\n\n一旦设定这个标记，通过 documen.coookie 则不能再访问该 cookie。IE 同时更近一步并且不允许通过 XMLHttpRequest 的 getAllResponseHeaders() 或 getResponseHeader() 方法访问 cookie，然而其它浏览器则允许此行为。Firefox 在 3.0.6 中修复了该漏洞，然而仍旧有许多浏览器漏洞存在，complete browser support list 列出了这些。\n\n你不能通过 js 设置 HTTP-only，因为你不能再通过 js 读取这些 cookie，这是情理之中的事情。\n\n### 九. 总结\n\n为了高效的利用 cookie，仍旧有许多要了解和弄明白的东西。对于一项创建于十多年前但仍旧如最初实现的那样被使用至今的技术来说，这是件多不可思议的事。本篇只是提供了一些每个人都应该知道的关于浏览器 cookie 的基本指导，但无论如何，也不是一个完整的参考。对于今天的 Web 来说 cookie 仍旧起着非常重要的作用，并且不恰当的管理 cookie 会导致各种各样的问题，从最糟糕的用户体验到安全漏洞。我希望这篇手册能够激起一些关于 cookie 的不可思议的亮点。\n\n转自：[http://bubkoo.com/2014/04/21/http-cookies-explained/](http://bubkoo.com/2014/04/21/http-cookies-explained/)\n","tags":["HTTP"],"categories":["web"]},{"title":"二叉树遍历算法的非递归实现","url":"/2015/09/20/algorithm/binary-tree-traversal/","content":"\n二叉树遍历中的前、中、后，说的都是双亲结点，而左孩子结点和右孩子结点始终是先左再右。基于递归实现二叉树的遍历算法较为简单，如果放弃递归策略而以非递归的方式实现，则所有的遍历实现都需要借助于 __栈结构__ 。\n\n### 前序遍历\n\n前序遍历算法的遍历次序是 “中-左-右”。<!-- more -->\n\n#### 递归实现\n\n```java\npublic List<Integer> preorderTraversal(TreeNode root) {\n    List<Integer> res = new ArrayList<>();\n    this.doPreorderTraversal(root, res);\n    return res;\n}\n\nprivate void doPreorderTraversal(TreeNode node, List<Integer> res) {\n    if (null == node) {\n        return;\n    }\n    res.add(node.val);\n    this.doPreorderTraversal(node.left, res);\n    this.doPreorderTraversal(node.right, res);\n}\n```\n\n#### 非递归实现\n\n前序遍历的非递归实现属于三种遍历中最简单的一种，因为双亲结点需要第一个被访问，所以依赖于栈，基本的算法流程如下：\n\n1. 根结点入栈；\n2. 出栈，访问该结点 N；\n3. 如果 N 的右孩子结点不为空，则入栈；\n4. 如果 N 的左孩子结点不为空，则入栈；\n5. 如果栈不为空，则返回步骤 2。\n\n具体实现：\n\n```java\npublic List<Integer> preorderTraversal(TreeNode root) {\n    List<Integer> list = new ArrayList<>();\n    if (null == root) {\n        return list;\n    }\n    Stack<TreeNode> stack = new Stack<>();\n    stack.push(root);\n    while (!stack.isEmpty()) {\n        final TreeNode node = stack.pop();\n        list.add(node.val);\n        // 先加右孩子结点\n        if (null != node.right) {\n            stack.push(node.right);\n        }\n        // 再加左孩子结点\n        if (null != node.left) {\n            stack.push(node.left);\n        }\n    }\n    return list;\n}\n```\n\n由上述实现可以看出，整个算法流程需要注意的一点就是在将孩子结点入栈时需要先将右孩子结点入栈，再将左孩子结点入栈，从而保证左孩子结点先于右孩子结点被访问，以满足“中-左-右”的顺序约束。\n\n### 中序遍历\n\n中序遍历算法的遍历次序是 “左-中-右”。\n\n#### 递归实现\n\n```java\npublic List<Integer> inorderTraversal(TreeNode root) {\n    List<Integer> res = new ArrayList<>();\n    this.doInorderTraversal(root, res);\n    return res;\n}\n\npublic void doInorderTraversal(TreeNode node, List<Integer> res) {\n    if (null == node) {\n        return;\n    }\n    this.doInorderTraversal(node.left, res);\n    res.add(node.val);\n    this.doInorderTraversal(node.right, res);\n}\n```\n\n#### 非递归实现\n\n假设有输入结点 N （初始时 N = root），中序遍历的非递归算法流程如下：\n\n1. 如果 N 不为 null 则入栈，然后赋值 N = N.left，循环直到 N 为 null 为止；\n2. 出栈，访问该结点 M；\n3. 如果 M 的右孩子结点为空则继续出栈，否则令 N 为 M 的右孩子结点，回到步骤 1。\n\n具体实现：\n\n```java\npublic List<Integer> inorderTraversal(TreeNode root) {\n    List<Integer> result = new ArrayList<>();\n    Stack<TreeNode> stack = new Stack<>();\n    while (null != root || !stack.isEmpty()) {\n        // 循环将左孩子结点入栈\n        while (root != null) {\n            stack.add(root);\n            root = root.left;\n        }\n        if (!stack.isEmpty()) {\n            // 出栈访问该结点\n            TreeNode node = stack.pop();\n            result.add(node.val);\n            // 令 root = node.right\n            root = node.right;\n        }\n    }\n    return result;\n}\n```\n\n### 后序遍历\n\n后序遍历算法的遍历次序是 “左-右-中”。\n\n#### 递归实现\n\n```java\npublic List<Integer> postorderTraversal(TreeNode root) {\n    List<Integer> res = new ArrayList<>();\n    if (null == root) {\n        return res;\n    }\n    this.doPostorderTraversal(root, res);\n    return res;\n}\n\npublic void doPostorderTraversal(TreeNode node, List<Integer> res) {\n    if (null == node) {\n        return;\n    }\n    this.doPostorderTraversal(node.left, res);\n    this.doPostorderTraversal(node.right, res);\n    res.add(node.val);\n}\n```\n\n#### 非递归实现\n\n后序遍历的非递归实现属于三种遍历中最复杂的一种，某一个结点被访问的条件需要满足以下两个条件之一：\n\n1. 该结点没有孩子结点；\n2. 该结点的孩子结点已经被访问过。\n\n所以我们需要利用一个变量来记录上一次被访问的结点，令该变量为 pre，则算法思路如下：\n\n1. 根结点入栈；\n2. peek 栈顶元素，如果该结点满足上述两个条件之一，则 pop 栈顶元素并访问该结点，并记录到 pre 变量中；\n3. 如果不满足，则先判断如果右孩子不为空，则入栈，然后判断如果左孩子不为空，则入栈；\n4. 返回步骤 2，重复执行，直到栈为空为止。\n\n具体实现：\n\n```java\npublic List<Integer> postorderTraversal(TreeNode root) {\n    List<Integer> result = new ArrayList<Integer>();\n    Stack<TreeNode> stack = new Stack<TreeNode>();\n    if (null != root) stack.add(root); // 现将根结点入栈\n    TreeNode pre = null;\n    while (!stack.isEmpty()) {\n        TreeNode node = stack.peek();\n        /*\n         * 1. 当前结点没有孩子结点\n         * 2. 当前结点的孩子结点是上次访问的结点\n         */\n        if ((null == node.left && null == node.right)\n                || (null != pre && (pre == node.right || pre == node.left))) {\n            stack.pop();\n            result.add(node.val);\n            pre = node;\n        } else {\n            // 需要先右再左\n            if (null != node.right) stack.add(node.right);\n            if (null != node.left) stack.add(node.left);\n        }\n    }\n    return result;\n}\n```\n","tags":["数据结构","算法"],"categories":["algorithm"]},{"title":"模式匹配：KMP 算法","url":"/2015/09/18/algorithm/kmp/","content":"\nKMP 算法是在给定字符串中检索目标字符串的算法，该算法由 Knuth、Morris 和 Pratt 三人在 Brute-Force 算法的基础上提出的模式匹配改进算法。该算法消除了 Brute-Force 在进行匹配时，只要遇到不相等字符就需要回退到本次比较起始位置的后一个位置继续开始新一轮的比较的缺点，这样的回退就把过程中所有的比较操作的时间付出全部给否定了，KMP 算法则正是需要在匹配失败时，利用之前的匹配结果，再不回退的情况下开始新的一轮比较，KMP 总会将目标字符串向前移动到合适的位置，保证当前指针前的字符串都是匹配的。<!-- more -->\n\n### KMP 算法执行过程\n\nKMP 算法的核心在于一个 next 数组，这个数组在匹配失败时指明了字符串前移的位数，后面我们专门用一小节来讨论 next 数组的计算。现在我们以字符串 `BBC ABCDAB ABCDABCDABDE` 来演示用 KMP 的算法查找字符串 `ABCDABD` 的执行过程，并假设已经有了一个计算好了的 next 数组：\n\nA | B | C | D | A | B | D\n-- | -- | -- | -- | -- | -- | --\n-1 | 0 | 0| 0 | 0 | 1 | 2\n\n那么整一个匹配流程如下：\n\n![image](/images/2015/kmp.png)\n\n如上图所示，我们令原字符串为 txt，目标字符串为 pat，i 为 txt 的指针，j 为 pat 的指针，一开始 i = 0, j = 0，开始匹配过程：\n\n1. 图 1 所示，不匹配中则  `i++`；\n2. 图 2 所示，仍然不匹配，`i++`；\n3. 图 3 所示，继续比较直到第 1 个字符匹配，`i++`，`j++`；\n4. 图 4 所示，继续比较，匹配，`i++`,` j++`；\n5. 图 5 所示，遇到不匹配，此时需要根据 next 数组重新计算 j 的值，`j = next[j]`，即 `j = next[6] = 2`；\n6. 图 6 所示，此时 i=10，j=2，继续比较，不匹配，根据 next 数组重新计算 j 的值，`j = next[j] = next[2] = 0`；\n7. 图 7 所示，此时 i=10，j=0，继续比较，不匹配，j=0 时，如果不匹配，则直接 `i++` 即可；\n8. 图 8 所示，此时 i=11, j=0，匹配，`i++`，`j++`；\n9. 图 9 所示，匹配，`i++`，`j++`；\n10. 图 10 所示，遇到不匹配，此时 i=17，j=6，因为 j>0，所以需要依据 next 重新计算 j 值，`j=next[j] = next[6]=2`；\n11. 图 11 所示，比较 `text[i=17]` 和 `pat[j=2]`，匹配， `i++`，`j++`，如图 12；\n12. 图 13 所示，全部匹配，本次查找完成。\n\n由上面的过程，我们可以总结一下，KMP 算法的下标设置逻辑为：\n\n```text\nif(txt[i] == pat[j]) {\n    i++;\n    j++;\n} else if(j == 0) {\n    i++;\n} else{\n    j = next[j];\n}\n```\n\n算法的 java 实现如下：\n\n```java\n/**\n * KMP 检索\n * 如果未检索到则返回 -1\n *\n * @param haystack 原字符\n * @param needle 目标字符\n * @return\n */\npublic static int search(String haystack, String needle) {\n    int lenHay = haystack.length(), lenNeed = needle.length();\n    if (lenNeed > lenHay) {\n        // 肯定不存在，直接返回 -1\n        return -1;\n    }\n    if (lenNeed == 0) {\n        // 查找空白字符串始终返回 0\n        return 0;\n    }\n    int i = 0, j = 0;\n    int[] next = next(needle);  // 计算next数组\n    while (i < lenHay && j < lenNeed) {\n        if (haystack.charAt(i) == needle.charAt(j)) {\n            // 匹配\n            i++; j++;\n        } else if (j == 0) {\n            // 不匹配，但j=0，直接递增i\n            i++;\n        } else {\n            // 不匹配，但是已经匹配了一些字符，依据next数组重新计算j\n            j = next[j];\n        }\n    }\n    if (j == lenNeed) {\n        // 说明匹配到了，返回下标\n        return i - lenNeed;\n    }\n    return -1;\n}\n```\n\n### next 数组的计算方法\n\n#### next 数组计算的理论基础\n\nnext 数组是 KMP 算法的核心所在，next 数组的计算可以由如下公式表示：\n\n![image](/images/2015/kmp-next.png)\n\n上述公式所要表达的意思是，`next[j]` 的值等于在 `0<k<j` 的范围内存在一个 k 值将字符串截成两段，且前半段等于后半段，满足这样条件的最大 k 值就是 `next[j]` 的值。\n\n#### next 数组的算法设计\n\n```java\n/**\n * 计算 next 数组\n *\n * @param needle\n * @return\n */\nprivate static int[] next(String needle) {\n    int[] next = new int[needle.length()];\n    next[0] = -1; // 首字母的next值始终为-1\n    int k = -1;\n    for (int i = 1; i < needle.length(); ) {\n        if (k == -1 || needle.charAt(i - 1) == needle.charAt(k)) {\n            next[i] = ++k;\n            i++;\n        } else {\n            k = next[k];\n        }\n    }\n    return next;\n}\n```\n\n算法执行流程如下：\n\n![image](/images/2015/kmp-next-algorithm.png)\n\n如果是手动计算，且目标字符串不是很长的情况下，可以采用如下方式计算 next 数组，即 __前缀后缀法__ ，先来对前缀和后缀下一个定义，假设我们有一个单词 “bread”，那么该单词的前缀有 `b, br, bre, brea`，同理后缀有 `read, ead, ad, d`，那么对于之前的字符串 `ABCDABD` 则计算结果如下：\n\n字符串 | 前缀 | 后缀 | 最长公共字符串 | 最长公共字符串长度\n--- | --- | --- | --- | ---\nA | 空 | 空 | 空 | 0\nAB | A | B | 空 | 0\nABC | A, AB | BC, C | 空 | 0\nABCD | A, AB, ABC | BCD, CD, D | 空 | 0\nABCDA | A, AB, ABC, ABCD | BCDA, CDA, DA, A | A | 1\nABCDAB | A, AB, ABC, ABCD, ABCDA | BCDAB, CDAB, DAB, AB, B | AB | 2\nABCDABD | A, AB, ABC, ABCD, ABCDA, ABCDAB | BCDABD, CDABD, DABD, ABD, BD, D | 空 | 0\n\n我们只需要将最后一列的值平放（如下表格第二行），然后整体向右移动一格，首位置为 -1，就可以得到 next 数组（如下表格第三行）：\n\nA | B | C | D | A | B | D\n-- | -- | -- | -- | -- | -- | --\n0 | 0 | 0 | 0 | 1 | 2 | 0\n-1 | 0 | 0| 0 | 0 | 1 | 2\n","tags":["数据结构","算法"],"categories":["algorithm"]}]