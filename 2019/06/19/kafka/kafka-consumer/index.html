<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/favicon_16.png?v=2.6.1" type="image/png" sizes="16x16"><link rel="icon" href="/images/favicon_32.png?v=2.6.1" type="image/png" sizes="32x32"><meta name="google-site-verification" content="O5CNgi37yYXs3qQp7Xz61oL_AmGiwM28d7hRt5yh2to"><meta name="baidu-site-verification" content="pnKVynCWMP"><meta name="description" content="与上一篇介绍的 KafkaProducer 一样，Kafka 消费者 KafkaConsumer 同样是 Kafka 与开发者交互的媒介之一，负责从 Kafka 集群拉取消息给应用程序消费，并提交已经消费完成的 offset 值。此外，考虑到消费者上下线、topic 分区数目变更等情况，KafkaConsumer 还需要负责与服务端交互执行分区再分配操作，以保证消费者能够更加均衡的消费 topic">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka 源码解析：消费者运行机制">
<meta property="og:url" content="https://plotor.github.io/2019/06/19/kafka/kafka-consumer/index.html">
<meta property="og:site_name" content="指  间">
<meta property="og:description" content="与上一篇介绍的 KafkaProducer 一样，Kafka 消费者 KafkaConsumer 同样是 Kafka 与开发者交互的媒介之一，负责从 Kafka 集群拉取消息给应用程序消费，并提交已经消费完成的 offset 值。此外，考虑到消费者上下线、topic 分区数目变更等情况，KafkaConsumer 还需要负责与服务端交互执行分区再分配操作，以保证消费者能够更加均衡的消费 topic">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://plotor.github.io/images/2019/kafka-consumer.png">
<meta property="og:image" content="https://plotor.github.io/images/2019/kafka-group-rebalance.png">
<meta property="article:published_time" content="2019-06-19T05:45:56.000Z">
<meta property="article:modified_time" content="2025-03-12T02:34:37.275Z">
<meta property="article:author" content="zhenchao">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://plotor.github.io/images/2019/kafka-consumer.png"><title>Kafka 源码解析：消费者运行机制 | 指  间</title><link ref="canonical" href="https://plotor.github.io/2019/06/19/kafka/kafka-consumer/"><link rel="alternate" href="/atom.xml" type="application/atom+xml"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.1"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":false,"scrollDownIcon":true},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"carbon","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: true,
  pjax: {"avoidBanner":false},
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner header-inner--height header-inner--bgcolor"><nav class="header-nav header-nav--sticky"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/about/"><span class="header-nav-menu-item__icon"><i class="fas fa-user-circle"></i></span><span class="header-nav-menu-item__text">关于</span></a></div></div><div class="header-nav-search"><span class="header-nav-search__icon"><i class="fas fa-search"></i></span><span class="header-nav-search__text">搜索</span></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">Kafka 源码解析：消费者运行机制</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2019-06-19</span></span><span class="post-meta-item post-meta-item--wordcount"><span class="post-meta-item__icon"><i class="far fa-file-word"></i></span><span class="post-meta-item__info">字数统计</span><span class="post-meta-item__value">15.9k</span></span><span class="post-meta-item post-meta-item--readtime"><span class="post-meta-item__icon"><i class="far fa-clock"></i></span><span class="post-meta-item__info">阅读时长</span><span class="post-meta-item__value">71分</span></span></div></header><div class="post-body"><p>与上一篇介绍的 KafkaProducer 一样，Kafka 消费者 KafkaConsumer 同样是 Kafka 与开发者交互的媒介之一，负责从 Kafka 集群拉取消息给应用程序消费，并提交已经消费完成的 offset 值。此外，考虑到消费者上下线、topic 分区数目变更等情况，KafkaConsumer 还需要负责与服务端交互执行分区再分配操作，以保证消费者能够更加均衡的消费 topic 分区，从而提升消费的性能。</p>
<p>Kafka 定义了 group 的概念，将多个消费者实例组织成为一个 group，以丰富 Kafka 的应用场景。一个 group 名下可以包含任意数量的消费者实例，并从这些消费者中选择一个消费者担任 group 中的 Leader 消费者角色，负责管理 group 和其它 Follower 角色消费者的状态。当有消费者加入或离开当前 group 时，Group Leader 会依据集群确定的分区分配策略，为 group 名下所有消费者重新分配分区，以保证消息消费的均衡性。<a id="more"></a></p>
<p>本文我们同样先回忆一下 KafkaConsumer 的使用方式，然后重点分析消息的拉取过程、分区再分配机制，以及 offset 提交机制。</p>

        <h3 id="KafkaConsumer-使用示例">
          <a href="#KafkaConsumer-使用示例" class="heading-link"><i class="fas fa-link"></i></a>KafkaConsumer 使用示例</h3>
      <p>我们仍然以 Kafka 内置的 java 客户端为例，介绍如何消费 Kafka 中的消息。示例如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"localhost:9092"</span>);</span><br><span class="line">properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());</span><br><span class="line">properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.put(ConsumerConfig.GROUP_ID_CONFIG, DEFAULT_GROUP);</span><br><span class="line">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string">"false"</span>);</span><br><span class="line">KafkaConsumer&lt;Integer, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(properties);</span><br><span class="line"><span class="comment">// 订阅主题</span></span><br><span class="line">consumer.subscribe(Collections.singleton(DEFAULT_TOPIC));</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (!Thread.currentThread().isInterrupted()) {</span><br><span class="line">    ConsumerRecords&lt;Integer, String&gt; records = consumer.poll(TimeUnit.SECONDS.toMillis(<span class="number">1</span>));</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">final</span> ConsumerRecord&lt;Integer, String&gt; record : records) {</span><br><span class="line">            <span class="comment">// ... 这里是消费逻辑</span></span><br><span class="line">            <span class="keyword">this</span>.printResult(record);</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 异步提交</span></span><br><span class="line">        consumer.commitAsync();</span><br><span class="line">    } <span class="keyword">catch</span> (Throwable e) {</span><br><span class="line">        <span class="comment">// ... 异常</span></span><br><span class="line">    } <span class="keyword">finally</span> {</span><br><span class="line">        <span class="comment">// 同步提交</span></span><br><span class="line">        consumer.commitSync();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>示例中消费消息依赖于 KafkaConsumer 对象，KafkaConsumer 类也是我们分析消费者运行机制的入口。创建 KafkaConsumer 类对象时我们需要指定 Kafka 集群地址，以及消息 key 和 value 的反序列化器。接着我们可以循环调用 <code>KafkaConsumer#poll</code> 方法从 Kafka 集群拉取消息进行消费，该方法接收一个 timeout 参数，用于设置等待消息返回的超时时间，如果设置为 0 则 Kafka 会立即从本地缓存的消息集合中获取符合期望的结果进行返回。</p>
<p>读者可能对 <code>timeout=0</code> 的设置有些疑惑，认为这样的参数设置意义不大，因为一次网络请求多少都有时间上开销，这样的理解也是没有错的。但是后面在分析消息的消费过程时你将会看到，实际从集群拉取当前请求的消息的过程并不是在调用 poll 方法之后完成的。Kafka 为了性能考虑，在返回消息之前已经发送了下一次拉取消息的请求，这样处理消息的过程与请求下一轮消息的过程就是并行执行的。如果网络足够快，或者处理消息的逻辑足够耗时，则设置 <code>timeout=0</code> 是完全能够平滑工作的。</p>
<p>示例中我们关闭了 offset 的自动提交策略，并在正常运行过程中启用异步提交来提升性能，只有当出现异常的情况下才会使用同步提交，以防止 offset 丢失。</p>

        <h3 id="消息消费过程分析">
          <a href="#消息消费过程分析" class="heading-link"><i class="fas fa-link"></i></a>消息消费过程分析</h3>
      <p>我们以 KafkaConsumer 类为入口开始分析消费者的运行机制，首先来看一下 KafkaConsumer 类的字段定义：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumer</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Consumer</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>{</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** 客户端 ID 生成器 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> AtomicInteger CONSUMER_CLIENT_ID_SEQUENCE = <span class="keyword">new</span> AtomicInteger(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">/** 客户端 ID */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String clientId;</span><br><span class="line">    <span class="comment">/** 控制消费者与 GroupCoordinator 之间交互 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConsumerCoordinator coordinator;</span><br><span class="line">    <span class="comment">/** key 反序列化器 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Deserializer&lt;K&gt; keyDeserializer;</span><br><span class="line">    <span class="comment">/** value 反序列化器 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Deserializer&lt;V&gt; valueDeserializer;</span><br><span class="line">    <span class="comment">/** 负责从服务端拉取消息 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Fetcher&lt;K, V&gt; fetcher;</span><br><span class="line">    <span class="comment">/** 拦截器集合， 在方法返回给用户之前进行拦截修改 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConsumerInterceptors&lt;K, V&gt; interceptors;</span><br><span class="line">    <span class="comment">/** 时间戳工具 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Time time;</span><br><span class="line">    <span class="comment">/** 集群网络通信客户端，对 NetworkClient 的封装 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConsumerNetworkClient client;</span><br><span class="line">    <span class="comment">/** 维护消费者的消费状态 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SubscriptionState subscriptions;</span><br><span class="line">    <span class="comment">/** 集群元数据 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Metadata metadata;</span><br><span class="line">    <span class="comment">/** 重试间隔 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> retryBackoffMs;</span><br><span class="line">    <span class="comment">/** 请求超时时间 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> requestTimeoutMs;</span><br><span class="line">    <span class="comment">/** 标识当前消费者是否关闭 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> closed = <span class="keyword">false</span>;</span><br><span class="line">    <span class="comment">/** 记录当前正在使用 KafkaConsumer 的线程 ID，防止多个线程同时使用同一个 KafkaConsumer 对象 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicLong currentThread = <span class="keyword">new</span> AtomicLong(NO_CURRENT_THREAD);</span><br><span class="line">    <span class="comment">/** 记录线程重入次数 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger refcount = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ... 省略方法定义</span></span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>KafkaConsumer 对象的构造的过程比较简单，这里不再展开。</p>
<p>
        <img class="lazyload lazyload-gif" src="/images/loading.svg" data-src="/images/2019/kafka-consumer.png" alt="image">
      </p>
<p>与介绍 KafkaProducer 一样，在深入分析 KafkaConsumer 的运行机制之前，我们同样以一张图（如上图）从整体层面对消费消息的过程做一个整体的介绍。</p>
<p>当消费者请求拉取消息消费时，KafkaConsumer 会首先检查当前是否需要执行分区再平衡操作。Kafka 限定一个分区至多只能被一个消费者消费，因为消费者可能会发生上下线操作，并且分区的数量也可能会增加，所以 Kafka 内置了分区再平衡机制，尽量保证将分区均匀分配给各个消费者。</p>
<p>此外，为了提升消费的性能，Kafka 巧妙的将处理消息的过程与拉取消息的过程并行化。KafkaConsumer 在将消息返回给应用程序之前会发送拉取后续消息的请求，这样能够实现应用程序在处理消息的时候，KafkaConsumer 也在后台为应用程序准备下一轮需要消费的消息。所以，应用程序大多数时候都是直接从本地获取到缓存的消息数据，期间无需等待与 Kafka 集群的远程通信。</p>
<p>上述是整个消费者运行机制的两个关键点，下面的小节我们将展开对整个消费者运行机制进行深入分析。</p>

        <h4 id="订阅主题">
          <a href="#订阅主题" class="heading-link"><i class="fas fa-link"></i></a>订阅主题</h4>
      <p>在使用 KafkaConsumer 消费服务端消息之前，我们首先需要调用 <code>KafkaConsumer#subscribe</code> 方法订阅 topic 列表，该方法实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">subscribe</span><span class="params">(Collection&lt;String&gt; topics, ConsumerRebalanceListener listener)</span> </span>{</span><br><span class="line">    <span class="comment">// 防止一个 KafkaConsumer 对象被多个线程同时使用，以保证线程安全</span></span><br><span class="line">    <span class="keyword">this</span>.acquire();</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        <span class="keyword">if</span> (topics == <span class="keyword">null</span>) {</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Topic collection to subscribe to cannot be null"</span>);</span><br><span class="line">        } <span class="keyword">else</span> <span class="keyword">if</span> (topics.isEmpty()) {</span><br><span class="line">            <span class="comment">// 如果传递空的 topic 订阅列表，则视为解除订阅</span></span><br><span class="line">            <span class="keyword">this</span>.unsubscribe();</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="comment">// ... 校验输入的 topic 不为 null 或空，如果是则抛出 IllegalArgumentException 异常，省略</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 订阅当前 topic 列表</span></span><br><span class="line">            subscriptions.subscribe(<span class="keyword">new</span> HashSet&lt;&gt;(topics), listener);</span><br><span class="line">            metadata.setTopics(subscriptions.groupSubscription());</span><br><span class="line">        }</span><br><span class="line">    } <span class="keyword">finally</span> {</span><br><span class="line">        <span class="comment">// 线程重入计数 refcount 减 1，如果 refcount = 0，则标记当前 KafkaConsumer 对象没有线程占用</span></span><br><span class="line">        <span class="keyword">this</span>.release();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>在开始订阅 topic 之前会先校验 KafkaConsumer 对象是否被多个线程占用。我们知道 KafkaConsumer 不是线程安全的，KafkaConsumer 设置了两个字段 <code>KafkaConsumer#currentThread</code> 和 <code>KafkaConsumer#refcount</code> 用于控制访问当前 KafkaConsumer 对象的线程 ID 和线程重入次数。其中 currentThread 用于记录持有当前 KafkaConsumer 对象的线程 ID，refcount 则表示该线程的重入次数。对于这 2 个变量的控制，KafkaConsumer 一般会使用下面这样的模板代码：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.acquire();</span><br><span class="line"><span class="keyword">try</span> {</span><br><span class="line">    <span class="comment">// do somthing here</span></span><br><span class="line">} <span class="keyword">finally</span> {</span><br><span class="line">    <span class="keyword">this</span>.release();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>其中 <code>KafkaConsumer#acquire</code> 方法可以类比理解为加锁，而 <code>KafkaConsumer#release</code> 方法可以类比理解为释放锁。我们先来看一下 <code>KafkaConsumer#acquire</code> 方法，该方法首先会验证当前 KafkaConsumer 对象是否被关闭，如果没有被关闭则会继续验证当前操作线程是否是已经持有该 KafkaConsumer 对象的线程，如果不是且当前 KafkaConsumer 对象被其它线程持有，则会抛出异常，否则将重入计数 refcount 加 1。以此来保证一个 KafkaConsumer 对象在同一时段只能被同一个线程持有，但是允许同一个线程多次持有。方法 <code>KafkaConsumer#acquire</code> 实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">acquire</span><span class="params">()</span> </span>{</span><br><span class="line">    <span class="comment">// 检测当前 consumer 是否关闭，如果关闭则抛出异常</span></span><br><span class="line">    <span class="keyword">this</span>.ensureNotClosed();</span><br><span class="line">    <span class="keyword">long</span> threadId = Thread.currentThread().getId();</span><br><span class="line">    <span class="comment">// 如果存在多个线程使用同一个 consumer 对象，则抛出异常</span></span><br><span class="line">    <span class="keyword">if</span> (threadId != currentThread.get() &amp;&amp; !currentThread.compareAndSet(NO_CURRENT_THREAD, threadId)) {</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ConcurrentModificationException(<span class="string">"KafkaConsumer is not safe for multi-threaded access"</span>);</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 线程重入次数加 1</span></span><br><span class="line">    refcount.incrementAndGet();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>再来看一下 <code>KafkaConsumer#release</code> 方法的实现（如下），该方法逻辑比较简单，将重入计数 refcount 减 1，意味着本次线程退出当前临界区，如果重入计数为 0，则清空 currentThread，以允许其它线程获取锁。</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">()</span> </span>{</span><br><span class="line">    <span class="comment">// 线程重入次数减 1</span></span><br><span class="line">    <span class="keyword">if</span> (refcount.decrementAndGet() == <span class="number">0</span>) {</span><br><span class="line">        <span class="comment">// 如果当前线程重入次数为 0，则表示当前 KafkaConsumer 对象没有线程占用</span></span><br><span class="line">        currentThread.set(NO_CURRENT_THREAD);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>在保证线程安全的前提下，方法 <code>KafkaConsumer#subscribe</code> 会对传递的 topic 集合进行校验，如果当前传递的 topic 集合为空，则视为取消订阅。取消订阅主要做了 2 件事情：</p>
<ol>
<li>清空本地订阅的 topic 集合、清除本地记录的每个 topic 分区的消费状态，以及重置一些本地的变量。</li>
<li>构建并发送 LeaveGroupRequest 请求，告知服务端自己已经离开当前的 group。</li>
</ol>
<p>如果传递的 topic 集合不为空，则会调用 <code>SubscriptionState#subscribe</code> 方法订阅指定 topic 集合，实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">subscribe</span><span class="params">(Set&lt;String&gt; topics, ConsumerRebalanceListener listener)</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (listener == <span class="keyword">null</span>) {</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"RebalanceListener cannot be null"</span>);</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 设置 topic 订阅模式为 AUTO_TOPICS</span></span><br><span class="line">    <span class="keyword">this</span>.setSubscriptionType(SubscriptionType.AUTO_TOPICS);</span><br><span class="line">    <span class="keyword">this</span>.listener = listener;</span><br><span class="line">    <span class="comment">// 更新本地缓存的订阅的信息</span></span><br><span class="line">    <span class="keyword">this</span>.changeSubscription(topics);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>同一个 KafkaConsumer 对象订阅主题的模式有 3 种，定义在 SubscriptionType 枚举类中（其中 NONE 指代未订阅任何主题）：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">enum</span> <span class="title">SubscriptionType</span> </span>{</span><br><span class="line">    NONE,</span><br><span class="line">    <span class="comment">/** 按照指定的 topic 的名字进行订阅，自动分配分区 */</span></span><br><span class="line">    AUTO_TOPICS,</span><br><span class="line">    <span class="comment">/** 按照正则匹配 topic 名称进行订阅，自动分配分区 */</span></span><br><span class="line">    AUTO_PATTERN,</span><br><span class="line">    <span class="comment">/** 用户手动指定消费的 topic 以及分区 */</span></span><br><span class="line">    USER_ASSIGNED</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>并且这些订阅模式之间是互斥的，即一个 KafkaConsumer 对象不允许同时使用多种模式进行订阅，相关控制位于 <code>SubscriptionState#setSubscriptionType</code> 方法中：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setSubscriptionType</span><span class="params">(SubscriptionType type)</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.subscriptionType == SubscriptionType.NONE) {</span><br><span class="line">        <span class="comment">// NONE 表示没有设置过，设置为目标模式</span></span><br><span class="line">        <span class="keyword">this</span>.subscriptionType = type;</span><br><span class="line">    } <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">this</span>.subscriptionType != type) {</span><br><span class="line">        <span class="comment">// 如果之前设置过，且目标模式不是之前的模式，则抛出异常</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(SUBSCRIPTION_EXCEPTION_MESSAGE);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>如果当前的订阅模式合法，则会继续调用 <code>SubscriptionState#changeSubscription</code> 方法依据本次订阅的 topic 集合更新 <code>SubscriptionState#subscription</code> 和 <code>SubscriptionState#groupSubscription</code> 字段。其中 subscription 字段用于记录当前消费者订阅的 topic 集合，而 groupSubscription 字段则依据当前消费者是 Leader 还是 Follower 有所不同。如果是 Leader 则记录当前消费者所属 group 中所有消费者订阅的 topic 集合，如果是 Follower 则仅保存其自身订阅的 topic 集合。到这里，订阅 topic 的过程就算完成了，整个过程还未涉及到与集群的交互，这会在执行 <code>KafkaConsumer#poll</code> 时发生。</p>

        <h4 id="拉取消息">
          <a href="#拉取消息" class="heading-link"><i class="fas fa-link"></i></a>拉取消息</h4>
      <p>在完成了对目标 topic 的订阅之后，下面继续分析从集群拉取消息的过程，位于 <code>KafkaConsumer#poll</code> 方法中，实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout)</span> </span>{</span><br><span class="line">    <span class="keyword">this</span>.acquire();</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        <span class="comment">// 超时时间不允许设置为负数，但是允许设置为 0</span></span><br><span class="line">        <span class="keyword">if</span> (timeout &lt; <span class="number">0</span>) {</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Timeout must not be negative"</span>);</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 当前消费者未订阅任何 topic</span></span><br><span class="line">        <span class="keyword">if</span> (subscriptions.hasNoSubscriptionOrUserAssignment()) {</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Consumer is not subscribed to any topics or assigned any partitions"</span>);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> start = time.milliseconds();</span><br><span class="line">        <span class="keyword">long</span> remaining = timeout;</span><br><span class="line">        <span class="keyword">do</span> {</span><br><span class="line">            <span class="comment">// 拉取消息，优先从本地缓存中获取，如果没有则会请求服务端，期间会尝试执行分区再分配策略，以及异步提交 offset</span></span><br><span class="line">            Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = <span class="keyword">this</span>.pollOnce(remaining);</span><br><span class="line">            <span class="keyword">if</span> (!records.isEmpty()) {</span><br><span class="line">                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                 * 为了提升效率，在对响应的消息处理之前，先发送下一次 fetch 请求，</span></span><br><span class="line"><span class="comment">                 * 从而让处理消息的过程与拉取消息的过程并行，以减少等待网络 IO 的时间</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="keyword">if</span> (fetcher.sendFetches() &gt; <span class="number">0</span> || client.pendingRequestCount() &gt; <span class="number">0</span>) {</span><br><span class="line">                    <span class="comment">// 如果有待发送的请求，执行一次不可中断的 poll 请求</span></span><br><span class="line">                    client.pollNoWakeup();</span><br><span class="line">                }</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors == <span class="keyword">null</span>) {</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> ConsumerRecords&lt;&gt;(records);</span><br><span class="line">                } <span class="keyword">else</span> {</span><br><span class="line">                    <span class="comment">// 如果注册了拦截器，则在返回之前先应用拦截器</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">this</span>.interceptors.onConsume(<span class="keyword">new</span> ConsumerRecords&lt;&gt;(records));</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line"></span><br><span class="line">            <span class="keyword">long</span> elapsed = time.milliseconds() - start;</span><br><span class="line">            remaining = timeout - elapsed;</span><br><span class="line">        } <span class="keyword">while</span> (remaining &gt; <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> ConsumerRecords.empty();</span><br><span class="line">    } <span class="keyword">finally</span> {</span><br><span class="line">        <span class="keyword">this</span>.release();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>上述方法返回一个 ConsumerRecords 对象，用于对从每个 topic 分区拉取回来的 ConsumerRecord 对象集合进行封装。前面我们在分析 KafkaProducer 时介绍了 ProducerRecord 类，用于封装 Producer 发送的每条消息，而 ConsumerRecord 类则与之对应，用于封装 Consumer 消费的每条消息。</p>
<p>从集群拉取消息时需要指定响应超时时间 timeout 参数，该参数允许设置为非负数，前面我们已经介绍了 <code>timeout=0</code> 的意义，相应的逻辑位于这里实现。方法首先会调用 <code>KafkaConsumer#pollOnce</code> 从本地或服务端拉取一批消息，如果拉取成功（即返回结果不为空），方法并不会立即将结果返回，而是在返回之前尝试发送下一次拉取消息的请求。因为拉取消息涉及网络通信，需要与远端集群进行交互，比较耗时，而业务处理消息也是一个耗时的过程，Kafka 的设计者巧妙的将这两步并行执行，以提升效率。</p>
<p>如果设置了 Consumer 拦截器，那么在返回待消费消息数据之前会先对消息执行拦截修改。Kafka 定义了 ConsumerInterceptor 接口，该接口定义如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ConsumerInterceptor</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Configurable</span> </span>{</span><br><span class="line">    <span class="function">ConsumerRecords&lt;K, V&gt; <span class="title">onConsume</span><span class="params">(ConsumerRecords&lt;K, V&gt; records)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">onCommit</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>其中 <code>ConsumerInterceptor#onConsume</code> 方法会在消息数据被返回给应用程序之前执行，如 <code>KafkaConsumer#poll</code> 方法所示，而方法 <code>ConsumerInterceptor#onCommit</code> 会在 offset 成功提交后被调用。</p>
<p>下面先跳过 <code>KafkaConsumer#pollOnce</code> 方法来看一下 <code>Fetcher#sendFetches</code> 方法的实现，因为在 pollOnce 中同样调用了该方法，所以先了解其执行逻辑，以便于更好的理解 pollOnce 所做的工作。方法 <code>Fetcher#sendFetches</code> 的主要工作就是构建并向集群发送 FetchRequest 请求，以拉取指定 offset 的消息。Fetcher 类主要负责从服务端拉取消息，其字段定义如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Fetcher</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">SubscriptionState</span>.<span class="title">Listener</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** 网络客户端 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConsumerNetworkClient client;</span><br><span class="line">    <span class="comment">/** 时间戳工具 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Time time;</span><br><span class="line">    <span class="comment">/** 服务端返回的消息并不是立即响应，而是累积到 minBytes 再响应 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> minBytes;</span><br><span class="line">    <span class="comment">/** 请求时指定的服务端最大响应字节数 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> maxBytes;</span><br><span class="line">    <span class="comment">/** 累积等待的最大时长，达到该时间时，即使消息数据量不够，也会执行响应 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> maxWaitMs;</span><br><span class="line">    <span class="comment">/** 每次 fetch 操作的最大字节数 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> fetchSize;</span><br><span class="line">    <span class="comment">/** 重试间隔时间戳 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> retryBackoffMs;</span><br><span class="line">    <span class="comment">/** 每次获取 record 的最大数量 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> maxPollRecords;</span><br><span class="line">    <span class="comment">/** 是否对结果执行 CRC 校验 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> checkCrcs;</span><br><span class="line">    <span class="comment">/** 集群元数据 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Metadata metadata;</span><br><span class="line">    <span class="comment">/** 记录每个 topic 分区的消息消费情况 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SubscriptionState subscriptions;</span><br><span class="line">    <span class="comment">/** 每个响应在解析之前都会先转换成 CompletedFetch 对象记录到该队列中 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConcurrentLinkedQueue&lt;CompletedFetch&gt; completedFetches;</span><br><span class="line">    <span class="comment">/** key 反序列化器 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Deserializer&lt;K&gt; keyDeserializer;</span><br><span class="line">    <span class="comment">/** value 反序列化器 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Deserializer&lt;V&gt; valueDeserializer;</span><br><span class="line">    <span class="comment">/** 缓存，用于对响应结果进行解析 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BufferSupplier decompressionBufferSupplier = BufferSupplier.create();</span><br><span class="line">    <span class="comment">/** 保存响应的分区、消息 起始位移等 */</span></span><br><span class="line">    <span class="keyword">private</span> PartitionRecords&lt;K, V&gt; nextInLineRecords = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">/** 封装在解析指定 offset 时的异常信息 */</span></span><br><span class="line">    <span class="keyword">private</span> ExceptionMetadata nextInLineExceptionMetadata = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ... 省略方法定义</span></span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>下面来看一下 <code>Fetcher#sendFetches</code> 方法的实现：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sendFetches</span><span class="params">()</span> </span>{</span><br><span class="line">    <span class="comment">// 获取可以 fetch 的 topic 分区，并创建到分区 leader 副本所在节点的 FetchRequest 请求</span></span><br><span class="line">    Map&lt;Node, FetchRequest.Builder&gt; fetchRequestMap = <span class="keyword">this</span>.createFetchRequests();</span><br><span class="line">    <span class="comment">// 遍历并往各个目标节点发送 FetchRequest 请求</span></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Node, FetchRequest.Builder&gt; fetchEntry : fetchRequestMap.entrySet()) {</span><br><span class="line">        <span class="keyword">final</span> FetchRequest.Builder request = fetchEntry.getValue();</span><br><span class="line">        <span class="keyword">final</span> Node fetchTarget = fetchEntry.getKey();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 往目标节点发送 FetchRequest 请求</span></span><br><span class="line">        log.debug(<span class="string">"Sending fetch for partitions {} to broker {}"</span>, request.fetchData().keySet(), fetchTarget);</span><br><span class="line">        client.send(fetchTarget, request)</span><br><span class="line">                <span class="comment">// 添加监听器用于处理 FetchResponse 响应</span></span><br><span class="line">                .addListener(<span class="keyword">new</span> RequestFutureListener&lt;ClientResponse&gt;() {</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(ClientResponse resp)</span> </span>{</span><br><span class="line">                        FetchResponse response = (FetchResponse) resp.responseBody();</span><br><span class="line">                        <span class="comment">// 响应中的 topic 分区集合与请求的 topic 分区集合不匹配，忽略本次响应</span></span><br><span class="line">                        <span class="keyword">if</span> (!matchesRequestedPartitions(request, response)) {</span><br><span class="line">                            log.warn(<span class="string">"Ignoring fetch response containing partitions {} since it does not match the requested partitions {}"</span>, response.responseData().keySet(), request.fetchData().keySet());</span><br><span class="line">                            <span class="keyword">return</span>;</span><br><span class="line">                        }</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// 响应中的 topic 分区集合</span></span><br><span class="line">                        Set&lt;TopicPartition&gt; partitions = <span class="keyword">new</span> HashSet&lt;&gt;(response.responseData().keySet());</span><br><span class="line">                        FetchResponseMetricAggregator metricAggregator = <span class="keyword">new</span> FetchResponseMetricAggregator(sensors, partitions);</span><br><span class="line">                        <span class="comment">// 遍历处理响应中的数据</span></span><br><span class="line">                        <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, FetchResponse.PartitionData&gt; entry : response.responseData().entrySet()) {</span><br><span class="line">                            TopicPartition partition = entry.getKey();</span><br><span class="line">                            <span class="comment">// 当前 topic 分区对应请求的 offset</span></span><br><span class="line">                            <span class="keyword">long</span> fetchOffset = request.fetchData().get(partition).offset;</span><br><span class="line">                            FetchResponse.PartitionData fetchData = entry.getValue();</span><br><span class="line">                            <span class="comment">// 将结果包装成 CompletedFetch 缓存到 completedFetches 队列中</span></span><br><span class="line">                            completedFetches.add(<span class="keyword">new</span> CompletedFetch(partition, fetchOffset, fetchData, metricAggregator, request.version()));</span><br><span class="line">                        }</span><br><span class="line"></span><br><span class="line">                        sensors.fetchLatency.record(resp.requestLatencyMs());</span><br><span class="line">                        sensors.fetchThrottleTimeSensor.record(response.getThrottleTime());</span><br><span class="line">                    }</span><br><span class="line"></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(RuntimeException e)</span> </span>{</span><br><span class="line">                        log.debug(<span class="string">"Fetch request to {} for partitions {} failed"</span>, fetchTarget, request.fetchData().keySet(), e);</span><br><span class="line">                    }</span><br><span class="line">                });</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 返回本次发送的请求数目</span></span><br><span class="line">    <span class="keyword">return</span> fetchRequestMap.size();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>上述方法的主要执行逻辑就是获取需要拉取消息的 topic 分区集合，并为每个分区创建对应的 FetchRequest 请求对象，同时将这些请求按照分区对应的 Leader 副本所在 broker 节点组成 <code>Map&lt;Node, FetchRequest.Builder&gt;</code> 集合。接着，方法会遍历处理该集合向对应节点发送 FetchRequest 请求，并注册 RequestFutureListener 监听器对响应结果进行处理。如果响应中的分区集合与请求时的分区集合能够匹配，则方法会遍历响应结果，并将每个分区 offset 对应的响应结果对象封装成 CompletedFetch 对象，记录到 <code>Fetcher#completedFetches</code> 同步队列中。CompletedFetch 仅仅是对响应的一个简单的封装，后面会消费该队列，并将获取到的 CompletedFetch 对象解析成 ConsumerRecord 对象封装到 PartitionRecords 中，该类记录了消息对应的分区、offset、消息集合，以及客户端消费的位置等信息。</p>
<p>消费逻辑由 <code>Fetcher#fetchedRecords</code> 方法实现，如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取并移除队首元素</span></span><br><span class="line">CompletedFetch completedFetch = completedFetches.poll();</span><br><span class="line"><span class="keyword">if</span> (completedFetch == <span class="keyword">null</span>) <span class="keyword">break</span>; <span class="comment">// completedFetches 已空</span></span><br><span class="line"><span class="keyword">try</span> {</span><br><span class="line">    <span class="comment">// 解析 CompletedFetch 成 PartitionRecords 对象</span></span><br><span class="line">    nextInLineRecords = <span class="keyword">this</span>.parseCompletedFetch(completedFetch);</span><br><span class="line">} <span class="keyword">catch</span> (KafkaException e) {</span><br><span class="line">    <span class="keyword">if</span> (drained.isEmpty()) {</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 封装当前分区 offset 对应的异常信息，在下次获取该分区 offset 消息时抛出</span></span><br><span class="line">    nextInLineExceptionMetadata = <span class="keyword">new</span> ExceptionMetadata(completedFetch.partition, completedFetch.fetchedOffset, e);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> PartitionRecords&lt;K, V&gt; <span class="title">parseCompletedFetch</span><span class="params">(CompletedFetch completedFetch)</span> </span>{</span><br><span class="line">    TopicPartition tp = completedFetch.partition;</span><br><span class="line">    FetchResponse.PartitionData partition = completedFetch.partitionData;</span><br><span class="line">    <span class="keyword">long</span> fetchOffset = completedFetch.fetchedOffset;</span><br><span class="line">    <span class="keyword">int</span> bytes = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> recordsCount = <span class="number">0</span>;</span><br><span class="line">    PartitionRecords&lt;K, V&gt; parsedRecords = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 解析获取响应错误码</span></span><br><span class="line">    Errors error = Errors.forCode(partition.errorCode);</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        <span class="comment">// 当前 topic 分区不允许 fetch 消息，一般是因为当前正在执行分区再分配，或者消费者被暂停</span></span><br><span class="line">        <span class="keyword">if</span> (!subscriptions.isFetchable(tp)) {</span><br><span class="line">            log.debug(<span class="string">"Ignoring fetched records for partition {} since it is no longer fetchable"</span>, tp);</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 正常响应</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.NONE) {</span><br><span class="line">            <span class="comment">// 获取 topic 分区对应的下次获取消息的 offset</span></span><br><span class="line">            Long position = subscriptions.position(tp);</span><br><span class="line">            <span class="keyword">if</span> (position == <span class="keyword">null</span> || position != fetchOffset) {</span><br><span class="line">                <span class="comment">// 请求的 offset 与响应的不匹配</span></span><br><span class="line">                log.debug(<span class="string">"Discarding stale fetch response for partition {} since its offset {} does not match the expected offset {}"</span>, tp, fetchOffset, position);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">            }</span><br><span class="line"></span><br><span class="line">            List&lt;ConsumerRecord&lt;K, V&gt;&gt; parsed = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="keyword">boolean</span> skippedRecords = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">for</span> (LogEntry logEntry : partition.records.deepEntries(decompressionBufferSupplier)) {</span><br><span class="line">                <span class="comment">// 跳过请求 offset 位置之前的消息</span></span><br><span class="line">                <span class="keyword">if</span> (logEntry.offset() &gt;= position) {</span><br><span class="line">                    <span class="comment">// 封装成 ConsumerRecord 对象</span></span><br><span class="line">                    parsed.add(<span class="keyword">this</span>.parseRecord(tp, logEntry));</span><br><span class="line">                    bytes += logEntry.sizeInBytes();</span><br><span class="line">                } <span class="keyword">else</span> {</span><br><span class="line">                    skippedRecords = <span class="keyword">true</span>;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            recordsCount = parsed.size();</span><br><span class="line"></span><br><span class="line">            log.trace(<span class="string">"Adding fetched record for partition {} with offset {} to buffered record list"</span>, tp, position);</span><br><span class="line">            <span class="comment">// 封装结果为 PartitionRecords 对象</span></span><br><span class="line">            parsedRecords = <span class="keyword">new</span> PartitionRecords&lt;&gt;(fetchOffset, tp, parsed);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// ... 省略一些异常情况的处理</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 更新本地记录的对应 topic 分区最新的 HW 值</span></span><br><span class="line">            <span class="keyword">if</span> (partition.highWatermark &gt;= <span class="number">0</span>) {</span><br><span class="line">                log.trace(<span class="string">"Received {} records in fetch response for partition {} with offset {}"</span>, parsed.size(), tp, position);</span><br><span class="line">                subscriptions.updateHighWatermark(tp, partition.highWatermark);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// ... 省略对于错误响应的处理</span></span><br><span class="line">    } <span class="keyword">finally</span> {</span><br><span class="line">        completedFetch.metricAggregator.record(tp, bytes, recordsCount);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * we move the partition to the end if we received some bytes or if there was an error.</span></span><br><span class="line"><span class="comment">     * This way, it's more likely that partitions for the same topic can remain together (allowing for more efficient serialization).</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (bytes &gt; <span class="number">0</span> || error != Errors.NONE) {</span><br><span class="line">        subscriptions.movePartitionToEnd(tp);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parsedRecords;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>从队列中获取到的 CompletedFetch 对象会调用 <code>Fetcher#parseCompletedFetch</code> 方法将其解析封装成 PartitionRecords 对象，并记录到 <code>Fetcher#nextInLineRecords</code> 字段中，等待后续处理。下面来完整看一下 <code>Fetcher#fetchedRecords</code> 方法的实现：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; fetchedRecords() {</span><br><span class="line">    <span class="comment">// 如果之前解析当前分区 offset 存在异常，处理该异常</span></span><br><span class="line">    <span class="keyword">if</span> (nextInLineExceptionMetadata != <span class="keyword">null</span>) {</span><br><span class="line">        ExceptionMetadata exceptionMetadata = nextInLineExceptionMetadata;</span><br><span class="line">        nextInLineExceptionMetadata = <span class="keyword">null</span>;</span><br><span class="line">        TopicPartition tp = exceptionMetadata.partition;</span><br><span class="line">        <span class="comment">// 如果当前消费者处于运行状态，但是期望的 offset 在解析响应时存在异常，则直接抛出</span></span><br><span class="line">        <span class="keyword">if</span> (subscriptions.isFetchable(tp) &amp;&amp; subscriptions.position(tp) == exceptionMetadata.fetchedOffset) {</span><br><span class="line">            <span class="keyword">throw</span> exceptionMetadata.exception;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; drained = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">int</span> recordsRemaining = maxPollRecords; <span class="comment">// 剩余获取 record 的数量</span></span><br><span class="line">    <span class="keyword">while</span> (recordsRemaining &gt; <span class="number">0</span>) {</span><br><span class="line">        <span class="comment">// 如果当前 topic 分区没有可以处理的记录</span></span><br><span class="line">        <span class="keyword">if</span> (nextInLineRecords == <span class="keyword">null</span> || nextInLineRecords.isDrained()) {</span><br><span class="line">            <span class="comment">// ... 解析 CompletedFetch 成 PartitionRecords 对象，上面已经分析过</span></span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            TopicPartition partition = nextInLineRecords.partition;</span><br><span class="line">            <span class="comment">// 从之前解析得到的 PartitionRecords 对象中拉取指定数量的消息</span></span><br><span class="line">            List&lt;ConsumerRecord&lt;K, V&gt;&gt; records = <span class="keyword">this</span>.drainRecords(nextInLineRecords, recordsRemaining);</span><br><span class="line">            <span class="keyword">if</span> (!records.isEmpty()) {</span><br><span class="line">                List&lt;ConsumerRecord&lt;K, V&gt;&gt; currentRecords = drained.get(partition);</span><br><span class="line">                <span class="keyword">if</span> (currentRecords == <span class="keyword">null</span>) {</span><br><span class="line">                    drained.put(partition, records);</span><br><span class="line">                } <span class="keyword">else</span> {</span><br><span class="line">                    <span class="comment">/*</span></span><br><span class="line"><span class="comment">                     * 合并同一个分区的记录（发生的概率很小）</span></span><br><span class="line"><span class="comment">                     *</span></span><br><span class="line"><span class="comment">                     * this case shouldn't usually happen because we only send one fetch at a time per partition,</span></span><br><span class="line"><span class="comment">                     * but it might conceivably happen in some rare cases (such as partition leader changes).</span></span><br><span class="line"><span class="comment">                     * we have to copy to a new list because the old one may be immutable</span></span><br><span class="line"><span class="comment">                     */</span></span><br><span class="line">                    List&lt;ConsumerRecord&lt;K, V&gt;&gt; newRecords = <span class="keyword">new</span> ArrayList&lt;&gt;(records.size() + currentRecords.size());</span><br><span class="line">                    newRecords.addAll(currentRecords);</span><br><span class="line">                    newRecords.addAll(records);</span><br><span class="line">                    drained.put(partition, newRecords);</span><br><span class="line">                }</span><br><span class="line">                recordsRemaining -= records.size();</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回每个 topic 分区拉取到的消息</span></span><br><span class="line">    <span class="keyword">return</span> drained;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>前面我们在分析消费 <code>Fetcher#completedFetches</code> 同步队列时，对于解析过程中出现异常的 topic 分区对应的 offset，会将异常信息封装成 ExceptionMetadata 对象，记录到 <code>Fetcher#nextInLineExceptionMetadata</code> 字段中，方法 <code>Fetcher#fetchedRecords</code> 一开始会先处理该异常。如果之前解析过程能够正常拿到消息并封装成 PartitionRecords 对象，那么接下来将会从对象中拉取指定数量的消息返回给用户。该过程位于 <code>Fetcher#drainRecords</code> 方法中，该方法会校验目标分区是否被分配给当前消费者，因为在执行分区再分配时，一个消费者消费的分区是可能变化的，我们将在后面对分区再分配的逻辑进行针对性分析。如果目标 topic 分区仍然是分配给当前消费者的，那么方法会在对应分区允许拉取消息的情况下，从之前解析得到的 PartitionRecords 中获取指定数量的消息，并更新客户端记录的位置信息，包括对应分区的 offset，以及 PartitionRecords 中缓存的消息集合的消费位置。最后将每个分区对应的消息集合封装成 <code>Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt;</code> 集合返回。</p>
<p>下面我们回到 KafkaConsumer 类，看一下 <code>KafkaConsumer#pollOnce</code> 方法的执行逻辑，了解了 <code>Fetcher#sendFetches</code> 和 <code>Fetcher#fetchedRecords</code> 的实现，再来看 pollOnce 方法会简单很多。该方法实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollOnce(<span class="keyword">long</span> timeout) {</span><br><span class="line">    <span class="comment">// 执行分区再分配策略，以及异步提交 offset</span></span><br><span class="line">    coordinator.poll(time.milliseconds());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!subscriptions.hasAllFetchPositions()) {</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 如果存在没有分配 offset 的 topic 分区，则执行更新：</span></span><br><span class="line"><span class="comment">         * 1. 如果需要重置，则按照指定策略重置 offset</span></span><br><span class="line"><span class="comment">         * 2. 否则，尝试获取上次提交的 offset，如果结果为空则按照默认重置策略进行重置</span></span><br><span class="line"><span class="comment">         * 3. 否则，使用上次提交的 offset 更新本地记录的 offset 值</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">this</span>.updateFetchPositions(subscriptions.missingFetchPositions());</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 尝试从本地获取缓存的消息</span></span><br><span class="line">    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = fetcher.fetchedRecords();</span><br><span class="line">    <span class="keyword">if</span> (!records.isEmpty()) {</span><br><span class="line">        <span class="keyword">return</span> records;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果本地没有直接可用的消息，则创建 FetchRequest 请求，从集群拉取消息数据</span></span><br><span class="line">    fetcher.sendFetches();</span><br><span class="line">    <span class="keyword">long</span> now = time.milliseconds();</span><br><span class="line">    <span class="keyword">long</span> pollTimeout = Math.min(coordinator.timeToNextPoll(now), timeout);</span><br><span class="line">    <span class="comment">// 发送 FetchRequest 请求</span></span><br><span class="line">    client.poll(pollTimeout, now, <span class="keyword">new</span> PollCondition() {</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">shouldBlock</span><span class="params">()</span> </span>{</span><br><span class="line">            <span class="keyword">return</span> !fetcher.hasCompletedFetches();</span><br><span class="line">        }</span><br><span class="line">    });</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查是否需要执行分区再分配，如果是则返回空的结果，以保证尽快对分区执行再平衡操作</span></span><br><span class="line">    <span class="keyword">if</span> (coordinator.needRejoin()) {</span><br><span class="line">        <span class="keyword">return</span> Collections.emptyMap();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取 FetchRequest 请求返回的消息</span></span><br><span class="line">    <span class="keyword">return</span> fetcher.fetchedRecords();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>在拉取消息之前会先尝试执行分区再分配策略，以及异步提交 offset，这 2 步我们先不展开，留到后面的小节中针对性分析。</p>
<p>由于 Kafka 在设计上由消费者自己维护自身消费状态，所以在拉取消息之前需要确定是否需要更新消费者维护的分区 offset 信息，一方面是为了支持分区重置策略，另一方面也是配合分区再分配操作。KafkaConsumer 在拉取消息数据之前会调用 <code>SubscriptionState#hasAllFetchPositions</code> 方法检测分配给当前消费者的分区在本地是不是都记录着对应的 offset 值，如果存在没有记录 offset 值的分区，则需要调用 <code>KafkaConsumer#updateFetchPositions</code> 方法对这些分区进行更新：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updateFetchPositions</span><span class="params">(Set&lt;TopicPartition&gt; partitions)</span> </span>{</span><br><span class="line">    <span class="comment">// 对于需要重置 offset 的分区，请求分区 leader 副本所在节点获取对应的 offset 值</span></span><br><span class="line">    fetcher.resetOffsetsIfNeeded(partitions);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果仍然存在没有分配 offset 的分区</span></span><br><span class="line">    <span class="keyword">if</span> (!subscriptions.hasAllFetchPositions(partitions)) {</span><br><span class="line">        <span class="comment">// 如果需要从 GroupCoordinator 获取上次提交的 offset，则发送 OffsetFetchRequest 请求更新</span></span><br><span class="line">        coordinator.refreshCommittedOffsetsIfNeeded();</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 再次尝试对未分配 offset 的分区进行更新：</span></span><br><span class="line"><span class="comment">         * 1. 如果需要重置，则按照指定策略重置 offset</span></span><br><span class="line"><span class="comment">         * 2. 如果获取到的上次提交的 offset 为空，则按照默认重置策略进行重置</span></span><br><span class="line"><span class="comment">         * 3. 使用上次提交的 offset 更新本地记录的 offset 值</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        fetcher.updateFetchPositions(partitions);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>然后，KafkaConsumer 会调用 <code>Fetcher#fetchedRecords</code> 方法尝试从本地获取每个 topic 分区对应的缓存消息。如果本地缓存不命中，则会继续调用 <code>Fetcher#sendFetches</code> 方法构建并发送 FetchRequest 请求，尝试从集群拉取消息。</p>
<p>在调用 <code>Fetcher#fetchedRecords</code> 方法解析并返回服务端响应的消息之前，消费者会先检测当前是否需要执行分区再分配操作，如果需要则直接返回空的结果，这样在不超时的情况下，方法 <code>KafkaConsumer#pollOnce</code> 会立即被再次调用，从而开始对当前 topic 分区执行再分配，即调用 <code>ConsumerCoordinator#poll</code> 方法。我们会在后面的小节中对分区再分配和自动提交 offset 操作的逻辑展开分析，这里我们先来看一下 <code>ConsumerCoordinator#poll</code> 方法，了解这 2 个步骤的触发过程：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">poll</span><span class="params">(<span class="keyword">long</span> now)</span> </span>{</span><br><span class="line">    <span class="comment">// 触发执行注册的监听 offset 提交完成的方法</span></span><br><span class="line">    <span class="keyword">this</span>.invokeCompletedOffsetCommitCallbacks();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 确保当前是 AUTO_TOPICS 或 AUTO_PATTERN（USER_ASSIGNED 不需要再平衡）订阅模式，</span></span><br><span class="line">    <span class="comment">// 且目标 GroupCoordinator 节点可达，如果不可达，则会尝试寻找一个可用的节点</span></span><br><span class="line">    <span class="keyword">if</span> (subscriptions.partitionsAutoAssigned() &amp;&amp; <span class="keyword">this</span>.coordinatorUnknown()) {</span><br><span class="line">        <span class="keyword">this</span>.ensureCoordinatorReady();</span><br><span class="line">        now = time.milliseconds();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 需要执行再平衡</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.needRejoin()) {</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * due to a race condition between the initial metadata fetch and the initial rebalance,</span></span><br><span class="line"><span class="comment">         * we need to ensure that the metadata is fresh before joining initially.</span></span><br><span class="line"><span class="comment">         * This ensures that we have matched the pattern against the cluster's topics at least once before joining.</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 如果是 AUTO_PATTERN 订阅模式，则检查是否需要更新集群元数据</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (subscriptions.hasPatternSubscription()) {</span><br><span class="line">            client.ensureFreshMetadata();</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 1. 检查目标 GroupCoordinator 节点是否准备好接收请求</span></span><br><span class="line"><span class="comment">         * 2. 启动心跳线程</span></span><br><span class="line"><span class="comment">         * 3. 执行分区再分配操作</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">this</span>.ensureActiveGroup();</span><br><span class="line">        now = time.milliseconds();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 发送心跳</span></span><br><span class="line">    <span class="keyword">this</span>.pollHeartbeat(now);</span><br><span class="line">    <span class="comment">// 异步提交 offset</span></span><br><span class="line">    <span class="keyword">this</span>.maybeAutoCommitOffsetsAsync(now);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>我们前面介绍了 Kafka 有 3 种订阅模式：<code>AUTO_TOPICS</code>、<code>AUTO_PATTERN</code>，和 <code>USER_ASSIGNED</code>。其中 <code>USER_ASSIGNED</code> 订阅模式是由用户手动指定消费的分区，所以这种模式下不需要执行分区再分配操作对消费者消费的分区进行动态再分配。对于另外 2 种订阅模式来说，如果需要执行分区再分配，则方法首先需要确保与服务端交互的 GroupCoordinator 实例所在 broker 节点是可用的，然后调用 <code>AbstractCoordinator#ensureActiveGroup</code> 方法执行具体的分区再分配操作，我们将在 2.3 小节对这一过程进行深入分析。如果启用了自动 offset 提交策略，上述方法在最后还会调用 <code>ConsumerCoordinator#maybeAutoCommitOffsetsAsync</code> 方法尝试提交当前消费完成的 offset 值，我们将在 2.4 小节对自动提交 offset 的过程展开分析。</p>

        <h4 id="分区再分配机制">
          <a href="#分区再分配机制" class="heading-link"><i class="fas fa-link"></i></a>分区再分配机制</h4>
      <p>当我们使用 <code>AUTO_TOPICS</code> 或 <code>AUTO_PATTERN</code> 模式订阅 Kafka topic 时，我们并不需要考虑当前消费者具体消费哪个分区，Kafka 会依据分区分配策略为消费者分配一个或多个分区进行消费（一个分区至多被一个消费者消费，不允许多个消费者同时消费同一个分区）。但是消费者可能会中途加入，也可能会中途退出，topic 的分区数目也是允许改变的，此时就需要依赖分区再分配机制为注册的消费者重新分配分区。</p>
<p>当一个消费者发送心跳信息时，如果在集群的响应中侦测到 <code>REBALANCE_IN_PROGRESS</code> 错误码，则该消费者会意识到所属 group 正在执行分区再分配操作，于是会停下手头上的工作加入到这一进程中来。分区再分配操作分为 3 个阶段，并且是一个与集群交互联动的过程，这里我们以客户端视角，当消费者检测到需要重新分配分区时会触发执行：</p>
<ol>
<li>发送 GroupCoordinatorRequest 请求获取目标可用的 GroupCoordinator 实例所在的 broker 节点，如果没有则选择负载最小的节点并尝试建立连接；</li>
<li>向 GroupCoordinator 实例所在节点发送 JoinGroupRequest 请求申请加入目标 group。GroupCoordinator 实例会在既定时间范围内等待消费者的申请加入请求，如果提前检测到已经接收到 group 名下所有消费者的申请，或者等待时间超时，则会返回 JoinGroupResponse 响应，主要目的是告知谁是新的 Group Leader 消费者，以及最终确定的分区分配策略；</li>
<li>Group Leader 依据指定的分区分配策略为当前 group 名下的消费者分配分区，并向目标 GroupCoordinator 实例所在节点发送 SyncGroupRequest 请求以告知最终的分区分配结果。</li>
</ol>
<p>
        <img class="lazyload lazyload-gif" src="/images/loading.svg" data-src="/images/2019/kafka-group-rebalance.png" alt="image">
      </p>
<p>上述时序图描绘了分区再分配期间客户端与服务端的交互过程。</p>
<p>触发分区再分配操作的场景主要有以下 3 种：</p>
<ol>
<li>有消费者加入或离开 group，这里的离开可能是主动离开，也可能是宕机、GC 卡顿，或者是取消了对目标 topic 的订阅等。</li>
<li>消费者订阅的 topic 的分区数目发生变化。</li>
<li>消费者 group 对应的 GroupCoordinator 节点发生变更。</li>
</ol>
<p>在 2.2 小节我们最后简单分析了 <code>ConsumerCoordinator#poll</code> 方法，该方法会调用 <code>ConsumerCoordinator#needRejoin</code> 检测是否需要执行分区再分配，并在需要的情况下予以执行。ConsumerCoordinator 是消费者执行分区再分配操作和 offset 提交的核心类，该类继承自 AbstractCoordinator 抽象类，首先来看一下这两个类的字段定义：</p>
<ul>
<li><strong>AbstractCoordinator</strong></li>
</ul>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractCoordinator</span> <span class="keyword">implements</span> <span class="title">Closeable</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** 分区再分配操作超时时间 */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">int</span> rebalanceTimeoutMs;</span><br><span class="line">    <span class="comment">/** 消费者与服务端会话超时时间，超过该时间则认为与服务端断开连接 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> sessionTimeoutMs;</span><br><span class="line">    <span class="comment">/** 指定消费者被关闭时是否离开所属 group，如果为 true 的话会触发分区再分配操作 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> leaveGroupOnClose;</span><br><span class="line">    <span class="comment">/** 心跳机制 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Heartbeat heartbeat;</span><br><span class="line">    <span class="comment">/** 执行心跳机制的线程 */</span></span><br><span class="line">    <span class="keyword">private</span> HeartbeatThread heartbeatThread = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">/** 当前消费者所属的 group */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> String groupId;</span><br><span class="line">    <span class="comment">/** 网络通信客户端 */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> ConsumerNetworkClient client;</span><br><span class="line">    <span class="comment">/** 时间戳工具 */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> Time time;</span><br><span class="line">    <span class="comment">/** 重试时间间隔 */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">long</span> retryBackoffMs;</span><br><span class="line">    <span class="comment">/** 标记是否需要重新发送 {<span class="doctag">@link</span> JoinGroupRequest} 的请求条件之一 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> rejoinNeeded = <span class="keyword">true</span>;</span><br><span class="line">    <span class="comment">/** 标记是否需要执行发送 {<span class="doctag">@link</span> JoinGroupRequest} 请求前的准备工作 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needsJoinPrepare = <span class="keyword">true</span>;</span><br><span class="line">    <span class="comment">/** 记录当前消费者的运行状态 */</span></span><br><span class="line">    <span class="keyword">private</span> MemberState state = MemberState.UNJOINED;</span><br><span class="line">    <span class="comment">/** 分区再分配操作请求对应的 future 对象，避免多个请求同时执行 */</span></span><br><span class="line">    <span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; joinFuture = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">/** 服务端 GroupCoordinator 所在节点 */</span></span><br><span class="line">    <span class="keyword">private</span> Node coordinator = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">/** 服务端 GroupCoordinator 返回的年代信息，用于区分两次分区再分配操作 */</span></span><br><span class="line">    <span class="keyword">private</span> Generation generation = Generation.NO_GENERATION;</span><br><span class="line">    <span class="comment">/** 获取可用 GroupCoordinator 节点请求对应的 future，避免多个请求同时执行 */</span></span><br><span class="line">    <span class="keyword">private</span> RequestFuture&lt;Void&gt; findCoordinatorFuture = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ... 省略方法定义</span></span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<ul>
<li><strong>ConsumerCoordinator</strong></li>
</ul>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerCoordinator</span> <span class="keyword">extends</span> <span class="title">AbstractCoordinator</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 消费者在发送 JoinGroupRequest 请求时会传递自己支持的分区分配策略，服务端会从所有消费者都支持的策略中选择一种，</span></span><br><span class="line"><span class="comment">     * 并通知 group leader 使用此分配策略进行分配</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;PartitionAssignor&gt; assignors;</span><br><span class="line">    <span class="comment">/** 集群元数据信息 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Metadata metadata;</span><br><span class="line">    <span class="comment">/** 记录 topic 分区和 offset 的对应关系 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SubscriptionState subscriptions;</span><br><span class="line">    <span class="comment">/** 默认的 offset 提交完成时的 callback */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> OffsetCommitCallback defaultOffsetCommitCallback;</span><br><span class="line">    <span class="comment">/** 是否启用 offset 自动提交策略 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> autoCommitEnabled;</span><br><span class="line">    <span class="comment">/** offset 自动提交时间间隔 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> autoCommitIntervalMs;</span><br><span class="line">    <span class="comment">/** 注册的拦截器集合 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConsumerInterceptors&lt;?, ?&gt; interceptors;</span><br><span class="line">    <span class="comment">/** 是否排除内部 topic，即 offset topic */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> excludeInternalTopics;</span><br><span class="line">    <span class="comment">/** 记录正在等待异步提交 offset 的请求数目 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger pendingAsyncCommits;</span><br><span class="line">    <span class="comment">/** 记录每个 offset 提交对应的响应 callback */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ConcurrentLinkedQueue&lt;OffsetCommitCompletion&gt; completedOffsetCommits;</span><br><span class="line">    <span class="comment">/** 标记当前消费者是不是 group leader */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> isLeader = <span class="keyword">false</span>;</span><br><span class="line">    <span class="comment">/** 当前消费者成功订阅的 topic 集合 */</span></span><br><span class="line">    <span class="keyword">private</span> Set&lt;String&gt; joinedSubscription;</span><br><span class="line">    <span class="comment">/** 元数据快照，用于检测 topic 分区数量是否发生变化 */</span></span><br><span class="line">    <span class="keyword">private</span> MetadataSnapshot metadataSnapshot;</span><br><span class="line">    <span class="comment">/** 元数据快照，用于检测分区分配过程中分区数量是否发生变化 */</span></span><br><span class="line">    <span class="keyword">private</span> MetadataSnapshot assignmentSnapshot;</span><br><span class="line">    <span class="comment">/** 下一次自动提交 offset 的截止时间 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> nextAutoCommitDeadline;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ... 省略方法定义</span></span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>下面我们开始分析分区再分配机制，首先来看一下判定需要执行分区再分配操作的条件，位于 <code>ConsumerCoordinator#needRejoin</code> 中，实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">needRejoin</span><span class="params">()</span> </span>{</span><br><span class="line">    <span class="comment">// USER_ASSIGNED 订阅模式不需要执行分区再分配</span></span><br><span class="line">    <span class="keyword">if</span> (!subscriptions.partitionsAutoAssigned()) {</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 再平衡过程中分区数量发生变化</span></span><br><span class="line">    <span class="keyword">if</span> (assignmentSnapshot != <span class="keyword">null</span> &amp;&amp; !assignmentSnapshot.equals(metadataSnapshot)) {</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 消费者 topic 订阅信息发生变化</span></span><br><span class="line">    <span class="keyword">if</span> (joinedSubscription != <span class="keyword">null</span> &amp;&amp; !joinedSubscription.equals(subscriptions.subscription())) {</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 其它标识需要再平衡的操作，例如分区再分配执行失败、重置年代信息等</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">super</span>.needRejoin();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>如果判定需要执行分区再分配操作，消费者接下去会调用 <code>AbstractCoordinator#ensureActiveGroup</code> 方法确认所属 group 对应的目标 GroupCoordinator 实例所在节点是否准备好接收请求，如果对应节点不可用，则会发送 GroupCoordinatorRequest 请求查找负载较小且可用的节点，并与之建立连接。接着会调用 <code>AbstractCoordinator#joinGroupIfNeeded</code> 方法开始执行分区再分配策略，实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">joinGroupIfNeeded</span><span class="params">()</span> </span>{</span><br><span class="line">    <span class="comment">// 如果需要执行分区再分配，且目前正在进行中</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">this</span>.needRejoin() || <span class="keyword">this</span>.rejoinIncomplete()) {</span><br><span class="line">        <span class="comment">// 再次检查目标 GroupCoordinator 节点是否准备好接收请求</span></span><br><span class="line">        <span class="keyword">this</span>.ensureCoordinatorReady();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行前期准备工作</span></span><br><span class="line">        <span class="keyword">if</span> (needsJoinPrepare) {</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 1. 如果开启了 offset 自动提交，则同步提交 offset</span></span><br><span class="line"><span class="comment">             * 2. 调用注册的 ConsumerRebalanceListener 监听器的 onPartitionsRevoked 方法</span></span><br><span class="line"><span class="comment">             * 3. 取消当前消费者的 leader 身份（如果是的话），恢复成为一个普通的消费者</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">this</span>.onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">            needsJoinPrepare = <span class="keyword">false</span>;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建并发送 JoinGroupRequest 请求，申请加入目标 group</span></span><br><span class="line">        RequestFuture&lt;ByteBuffer&gt; future = <span class="keyword">this</span>.initiateJoinGroup();</span><br><span class="line">        client.poll(future);</span><br><span class="line">        <span class="comment">// 申请加入 group 完成，将 joinFuture 置为 null，表示允许发送下一次 JoinGroupRequest 请求</span></span><br><span class="line">        <span class="keyword">this</span>.resetJoinGroupFuture();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行分区分配成功</span></span><br><span class="line">        <span class="keyword">if</span> (future.succeeded()) {</span><br><span class="line">            needsJoinPrepare = <span class="keyword">true</span>;</span><br><span class="line">            <span class="keyword">this</span>.onJoinComplete(generation.generationId, generation.memberId, generation.protocol, future.value());</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 执行分区分配失败，依据失败类型考虑是否重试</span></span><br><span class="line">        <span class="keyword">else</span> {</span><br><span class="line">            RuntimeException exception = future.exception();</span><br><span class="line">            <span class="keyword">if</span> (exception <span class="keyword">instanceof</span> UnknownMemberIdException ||</span><br><span class="line">                    exception <span class="keyword">instanceof</span> RebalanceInProgressException ||</span><br><span class="line">                    exception <span class="keyword">instanceof</span> IllegalGenerationException) {</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            } <span class="keyword">else</span> <span class="keyword">if</span> (!future.isRetriable()) {</span><br><span class="line">                <span class="keyword">throw</span> exception;</span><br><span class="line">            }</span><br><span class="line">            time.sleep(retryBackoffMs);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>在开始执行分区再分配操作之前需要执行一些前期准备工作，这里使用了 needsJoinPrepare 字段进行控制，如果当前正在执行分区再分配，则 needsJoinPrepare 字段会被标记为 false，以防止重复执行。准备工作的逻辑实现位于 <code>ConsumerCoordinator#onJoinPrepare</code> 方法中，主要做了 3 件事情：</p>
<ol>
<li>如果开启了 offset 自动提交，则同步提交 offset 到集群。</li>
<li>激活注册的 ConsumerRebalanceListener 监听器的 onPartitionsRevoked 方法。</li>
<li>取消当前消费者的 Leader 身份（如果是的话），将其恢复成为一个普通的消费者。</li>
</ol>
<p>分区再分配操作之前需要提交当前消费者消费完成的 offset，因为当分区再分配完成之后，相应的分区可能会被分配给其它消费者，新的消费者需要依赖于前任消费者提交的 offset 来确定接下去消费的起始位置。所以，为了防止消息的遗漏或重复消费，在开始执行分区再分配之前，需要先提交当前消费者已经完成消费的 offset 值。</p>
<p>ConsumerRebalanceListener 监听器用于监听分区再分配操作，接口定义如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ConsumerRebalanceListener</span> </span>{</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>其中 onPartitionsRevoked 方法会在分区再分配操作之前被触发，也就是我们当前分析的位置，而 onPartitionsAssigned 方法则会在分区再分配操作完成之后被触发，调用的位置位于 <code>ConsumerCoordinator#onJoinComplete</code> 方法中，我们后面会对该方法进行分析。</p>
<p>因为接下去要执行分区再分配操作，当操作完成之后会有新的 Group Leader 消费者被选出，如果当前消费者是 Leader 角色，那么此时需要剥夺其 Leader 身份，同时将其 <code>SubscriptionState#groupSubscription</code> 字段中记录的所属 group 名下所有消费者订阅的 topic 集合重置为当前消费者自己订阅的 topic 集合。</p>
<p>完成了前期准备工作之后，消费者将正式开始执行分区再分配，这是一个客户端与服务端交互配合的过程，消费者需要构造并发送 JoinGroupResult 请求到对应的 GroupCoordinator 实例所在节点申请加入目标 group。这一过程位于 <code>AbstractCoordinator#initiateJoinGroup</code> 方法中，该方法的主要工作就是切换当前消费者的状态为 REBALANCING，创建并缓存 JoinGroupRequest 请求，并处理申请加入的结果。如果申请加入成功，则会切换当前消费者的状态为 STABLE，并重启心跳机制（为了避免心跳机制干扰分区再分配，在开始执行分区再分配之前会临时关闭心跳机制）；如果申请加入失败，则会切换当前消费者的状态为 UNJOINED。</p>
<p>JoinGroupRequest 请求中包含了当前消费者的 ID，消费者所属 group 的 ID、消费者支持的分区策略、协议类型、以及会话超时时间等信息。构造、发送，以及处理 JoinGroupRequest 请求及其响应的过程位于 <code>AbstractCoordinator#sendJoinGroupRequest</code> 方法中，实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">sendJoinGroupRequest</span><span class="params">()</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.coordinatorUnknown()) {</span><br><span class="line">        <span class="comment">// 如果目标 GroupCoordinator 节点不可达，则返回异常</span></span><br><span class="line">        <span class="keyword">return</span> RequestFuture.coordinatorNotAvailable();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    log.info(<span class="string">"(Re-)joining group {}"</span>, groupId);</span><br><span class="line">    <span class="comment">// 构建 JoinGroupRequest 请求</span></span><br><span class="line">    JoinGroupRequest.Builder requestBuilder = <span class="keyword">new</span> JoinGroupRequest.Builder(</span><br><span class="line">            groupId,</span><br><span class="line">            sessionTimeoutMs,</span><br><span class="line">            generation.memberId,</span><br><span class="line">            protocolType(),</span><br><span class="line">            metadata()).setRebalanceTimeout(rebalanceTimeoutMs);</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Sending JoinGroup ({}) to coordinator {}"</span>, requestBuilder, <span class="keyword">this</span>.coordinator);</span><br><span class="line">    <span class="comment">// 发送 JoinGroupRequest 请求，并注册结果处理器 JoinGroupResponseHandler</span></span><br><span class="line">    <span class="keyword">return</span> client.send(coordinator, requestBuilder).compose(<span class="keyword">new</span> JoinGroupResponseHandler());</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>消费者通过注册结果处理器 JoinGroupResponseHandler 对请求的响应结果进行处理，如果是正常响应则会执行分区分配操作，核心逻辑实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (AbstractCoordinator.<span class="keyword">this</span>) {</span><br><span class="line">    <span class="keyword">if</span> (state != MemberState.REBALANCING) {</span><br><span class="line">        <span class="comment">// 在接收到响应之前，消费者的状态发生变更（可能已经从所属 group 离开），抛出异常</span></span><br><span class="line">        future.raise(<span class="keyword">new</span> UnjoinedGroupException());</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">        <span class="comment">// 基于响应，更新 group 的年代信息</span></span><br><span class="line">        generation = <span class="keyword">new</span> Generation(</span><br><span class="line">                joinResponse.generationId(), joinResponse.memberId(), joinResponse.groupProtocol());</span><br><span class="line">        rejoinNeeded = <span class="keyword">false</span>;</span><br><span class="line">        <span class="comment">// 如果当前消费者是 group 中的 leader 角色</span></span><br><span class="line">        <span class="keyword">if</span> (joinResponse.isLeader()) {</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * 基于分区分配策略执行分区分配，leader 需要关注当前 group 中所有消费者订阅的 topic，</span></span><br><span class="line"><span class="comment">             * 并发送 SyncGroupRequest 请求反馈分区分配结果给 GroupCoordinator 节点</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            onJoinLeader(joinResponse)</span><br><span class="line">                    <span class="comment">// 这里调用 chain 方法，是希望当 SyncGroupResponse 处理完成之后，能够将结果传递给 future</span></span><br><span class="line">                    .chain(future);</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="comment">// 如果是 follower 消费者，则只关注自己订阅的 topic，这一步仅发送 SyncGroupRequest 请求</span></span><br><span class="line">            onJoinFollower().chain(future);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>在开始重新分配分区之前，消费者会确认当前状态是不是 REBALANCING，前面在发送 JoinGroupRequest 请求之前会将消费者状态变更为 REBALANCING，这里再次确认以防止在请求的过程中消费者的状态发生了变更，例如消费者因某种原理离开了所属的 group，这种情况下不应该再继续执行下去。如果状态未发生变更，那么会依据响应更新本地记录的状态信息（包括年代信息、标识不需要执行分区再分配等），然后依据当前消费者的角色（Leader/Follower）执行相应的逻辑。</p>
<p>对于 Follower 消费者而言，响应 JoinGroupRequest 请求的逻辑只是构造一个包含空的分区分配结果的 SyncGroupRequest 请求，并附带上所属的 group 和自身 ID，以及 group 年代信息，发送给对应的 GroupCoordinator 节点，如果此时所属的 group 已经处于正常运行的状态，则该消费者会拿到分配给自己的分区信息。</p>
<p>如果当前消费者是 Leader 角色，那么需要依据 GroupCoordinator 最终确定的分区分配策略为当前 group 名下所有的消费者分配分区，并发送 SyncGroupRequest 请求向对应的 GroupCoordinator 节点反馈最终的分区分配结果。方法 <code>AbstractCoordinator#onJoinLeader</code> 的实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">onJoinLeader</span><span class="params">(JoinGroupResponse joinResponse)</span> </span>{</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        <span class="comment">// 基于分区分配策略分配分区</span></span><br><span class="line">        Map&lt;String, ByteBuffer&gt; groupAssignment = <span class="keyword">this</span>.performAssignment(</span><br><span class="line">                joinResponse.leaderId(), joinResponse.groupProtocol(), joinResponse.members());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建 SyncGroupRequest 请求，反馈分区分配结果给 GroupCoordinator 节点</span></span><br><span class="line">        SyncGroupRequest.Builder requestBuilder =</span><br><span class="line">                <span class="keyword">new</span> SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId, groupAssignment);</span><br><span class="line">        log.debug(<span class="string">"Sending leader SyncGroup for group {} to coordinator {}: {}"</span>, groupId, <span class="keyword">this</span>.coordinator, requestBuilder);</span><br><span class="line">        <span class="comment">// 发送 SyncGroupRequest 请求</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sendSyncGroupRequest(requestBuilder);</span><br><span class="line">    } <span class="keyword">catch</span> (RuntimeException e) {</span><br><span class="line">        <span class="keyword">return</span> RequestFuture.failure(e);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>分配分区的具体过程位于 <code>ConsumerCoordinator#performAssignment</code> 方法中，这是一个长长的方法实现，但是逻辑并不复杂，实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Map&lt;String, ByteBuffer&gt; <span class="title">performAssignment</span><span class="params">(String leaderId, // leader 消费者 ID</span></span></span><br><span class="line"><span class="function"><span class="params">                                                    String assignmentStrategy, // 服务端最终确定的分区分配策略</span></span></span><br><span class="line"><span class="function"><span class="params">                                                    Map&lt;String, ByteBuffer&gt; allSubscriptions // group 名下所有消费者的 topic 订阅信息</span></span></span><br><span class="line"><span class="function"><span class="params">)</span> </span>{</span><br><span class="line">    <span class="comment">// 从消费者支持的分区分配策略集合中选择指定策略对应的分区分配器</span></span><br><span class="line">    PartitionAssignor assignor = <span class="keyword">this</span>.lookupAssignor(assignmentStrategy);</span><br><span class="line">    <span class="keyword">if</span> (assignor == <span class="keyword">null</span>) {</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Coordinator selected invalid assignment protocol: "</span> + assignmentStrategy);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 解析封装 topic 订阅信息</span></span><br><span class="line">    Set&lt;String&gt; allSubscribedTopics = <span class="keyword">new</span> HashSet&lt;&gt;(); <span class="comment">// 记录 group 名下所有消费者订阅的 topic 集合</span></span><br><span class="line">    Map&lt;String, Subscription&gt; subscriptions = <span class="keyword">new</span> HashMap&lt;&gt;(); <span class="comment">// Map&lt;String, ByteBuffer&gt; -&gt; Map&lt;String, Subscription&gt;</span></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, ByteBuffer&gt; subscriptionEntry : allSubscriptions.entrySet()) {</span><br><span class="line">        <span class="comment">// ByteBuffer -&gt; Subscription</span></span><br><span class="line">        Subscription subscription = ConsumerProtocol.deserializeSubscription(subscriptionEntry.getValue());</span><br><span class="line">        subscriptions.put(subscriptionEntry.getKey(), subscription);</span><br><span class="line">        allSubscribedTopics.addAll(subscription.topics());</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 对于 leader 消费者来说，需要关注 group 名下所有消费者订阅的 topic，</span></span><br><span class="line"><span class="comment">     * 以保证当相应 topic 对应的元数据发生变化，能够感知</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">this</span>.subscriptions.groupSubscribe(allSubscribedTopics);</span><br><span class="line">    metadata.setTopics(<span class="keyword">this</span>.subscriptions.groupSubscription());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分区再分配之后，检测是否需要更新集群元数据信息，如果需要则立即更新</span></span><br><span class="line">    client.ensureFreshMetadata();</span><br><span class="line">    <span class="comment">// 标记当前消费者为 leader 角色</span></span><br><span class="line">    isLeader = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Performing assignment for group {} using strategy {} with subscriptions {}"</span>, groupId, assignor.name(), subscriptions);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 基于分区分配器（range/round-robin）执行分区分配，</span></span><br><span class="line"><span class="comment">     * 返回结果：key 是消费者 ID，value 是对应的分区分配结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    Map&lt;String, Assignment&gt; assignment = assignor.assign(metadata.fetch(), subscriptions);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 记录所有完成分配的 topic 集合</span></span><br><span class="line">    Set&lt;String&gt; assignedTopics = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Assignment assigned : assignment.values()) {</span><br><span class="line">        <span class="keyword">for</span> (TopicPartition tp : assigned.partitions())</span><br><span class="line">            assignedTopics.add(tp.topic());</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 如果 group 中存在一些已经订阅的 topic 并未分配，则日志记录</span></span><br><span class="line">    <span class="keyword">if</span> (!assignedTopics.containsAll(allSubscribedTopics)) {</span><br><span class="line">        Set&lt;String&gt; notAssignedTopics = <span class="keyword">new</span> HashSet&lt;&gt;(allSubscribedTopics);</span><br><span class="line">        notAssignedTopics.removeAll(assignedTopics);</span><br><span class="line">        log.warn(<span class="string">"The following subscribed topics are not assigned to any members in the group {} : {} "</span>, groupId, notAssignedTopics);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果分配的 topic 集合包含一些未订阅的 topic 集合</span></span><br><span class="line">    <span class="keyword">if</span> (!allSubscribedTopics.containsAll(assignedTopics)) {</span><br><span class="line">        <span class="comment">// 日志记录这些未订阅的 topic</span></span><br><span class="line">        Set&lt;String&gt; newlyAddedTopics = <span class="keyword">new</span> HashSet&lt;&gt;(assignedTopics);</span><br><span class="line">        newlyAddedTopics.removeAll(allSubscribedTopics);</span><br><span class="line">        log.info(<span class="string">"The following not-subscribed topics are assigned to group {}, and their metadata will be fetched from the brokers : {}"</span>, groupId, newlyAddedTopics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将这些已分配但是未订阅的 topic 添加到 group 集合中</span></span><br><span class="line">        allSubscribedTopics.addAll(assignedTopics);</span><br><span class="line">        <span class="keyword">this</span>.subscriptions.groupSubscribe(allSubscribedTopics);</span><br><span class="line">        metadata.setTopics(<span class="keyword">this</span>.subscriptions.groupSubscription());</span><br><span class="line">        client.ensureFreshMetadata(); <span class="comment">// 更新元数据信息</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 更新本地缓存的元数据信息快照</span></span><br><span class="line">    assignmentSnapshot = metadataSnapshot;</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Finished assignment for group {}: {}"</span>, groupId, assignment);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 对分区分配结果进行序列化，后续需要反馈给集群</span></span><br><span class="line">    Map&lt;String, ByteBuffer&gt; groupAssignment = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, Assignment&gt; assignmentEntry : assignment.entrySet()) {</span><br><span class="line">        ByteBuffer buffer = ConsumerProtocol.serializeAssignment(assignmentEntry.getValue());</span><br><span class="line">        groupAssignment.put(assignmentEntry.getKey(), buffer);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> groupAssignment;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>整个分区分配的执行流程可以概括为：</p>
<ol>
<li>校验服务端确定的最终分区策略，获取对应的分区分配器 PartitionAssignor 对象；</li>
<li>反序列化解析并封装服务端返回的当前 group 名下所有消费者的 topic 订阅信息；</li>
<li>更新消费者本地缓存的状态信息，包括 group 名下所有消费者订阅的 topic 集合，Leader 角色自己订阅的 topic 集合等；</li>
<li>检查是否需要更新本地集群元数据信息，如果需要则立即执行更新；</li>
<li>依据具体的分区分配策略执行分区分配操作；</li>
<li>校验分区分配结果，如果 group 已经订阅的一些 topic 并未被分配，则记录到日志；</li>
<li>校验分配结果，如果分配了一些并未订阅的 topic，则将其加入到 group 集合中，并更新本地集群元数据信息；</li>
<li>序列化封装并返回分区分配结果，后续需要反馈给集群。</li>
</ol>
<p>Kafka 目前主流的分区分配策略分为 2 种（默认是 range，可以通过 <code>partition.assignment.strategy</code> 参数指定）：</p>
<ul>
<li><strong>range</strong> ：在保证均衡的前提下，将连续的分区分配给消费者，对应的实现是 RangeAssignor。</li>
<li><strong>round-robin</strong> ：在保证均衡的前提下，轮询分配，对应的实现是 RoundRobinAssignor。</li>
</ul>
<p>在 0.11.0.0 版本引入了一种新的分区分配策略 StickyAssignor，相对于上面两种分区分配策略的优势在于能够在保证分区均衡的前提下尽量保持原有的分区分配结果，从而避免许多冗余的分区分配操作，减少分区再分配的执行时间。不过据反映 StickyAssignor 目前还存在一些小 bug，所以在你的应用中具体是否采用还需要斟酌。</p>
<p>说到这里我们插点题外话，聊聊分区再分配机制的缺点。我们知道分区再分配机制设计的出发点是好的，也确实解决了实际面临的一些问题，但是缺点在于执行过程效率太低，究其根本可以概括为以下 2 方面的原因：</p>
<ol>
<li>在执行分区再分配过程中，对应 group 名下的所有消费者都需要暂停手头上的工作加入到分区再分配过程中来，外在的表现就是整个 group 在此期间不消费新的消息，会出现一段时间的消息堆积，有点 Stop The World 的意思。</li>
<li>基于 RangeAssignor 或 RoundRobinAssignor 分区分配策略会对 group 名下所有消费者的分区分配方案重新洗牌，实际上较好的策略是尽量复用原有的分区分配结果，并在此基础上进行微调，从而最大利用原有的状态信息，避免一些冗余的工作量。</li>
</ol>
<p>实际中因为订阅的 topic 数目发生变更，或者 topic 分区数目的变化导致触发的分区再分配操作我们无法避免，但是此类情况发生的概率较小，大部分的分区再分配都是由于消费者上下线导致的，而且是被 Kafka 误判为下线。Kafka 基于心跳机制来对具体的一个消费者进行判活，如果对应的参数设置不当会极大增加误判率，所以在这一块的参数配置上需要仔细斟酌。</p>
<p>继续接着分析分区再分配机制的实现，步骤 5 会依据具体的分区分配策略对分区执行分配操作，即执行 <code>PartitionAssignor#assign</code> 方法，我们已经知晓了每种分配算法的思想，具体分配细节这里不再深入。</p>
<p>完成了分配分区之后，消费者（不管是 Leader，还是 Follower）会构建 SyncGroupRequest 请求，将分区分配结果信息发送给对应的 GroupCoordinator 实例所在节点，并最终保存在服务端。如果请求异常，则会调用 <code>AbstractCoordinator#requestRejoin</code> 方法标记需要再次执行分区再分配操作。</p>
<p>下面继续回到 <code>AbstractCoordinator#joinGroupIfNeeded</code> 方法，如果分区分配操作失败，则消费者会依据异常类型决定是否继续重试。如果分区分配成功，则接下来需要对本地记录的相关信息重新初始化，因为分配给当前消费者的分区很可能已经变化，消费者需要知晓上一任消费者对当前分区的消费情况，从而找到合适的 offset 位置继续消费，相关实现位于 <code>ConsumerCoordinator#onJoinComplete</code> 方法中：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onJoinComplete</span><span class="params">(<span class="keyword">int</span> generation, String memberId, String assignmentStrategy, ByteBuffer assignmentBuffer)</span> </span>{</span><br><span class="line">    <span class="comment">// only the leader is responsible for monitoring for metadata changes (i.e. partition changes)</span></span><br><span class="line">    <span class="keyword">if</span> (!isLeader) {</span><br><span class="line">        assignmentSnapshot = <span class="keyword">null</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取最终确定的分区分配策略对应的分区分配器</span></span><br><span class="line">    PartitionAssignor assignor = <span class="keyword">this</span>.lookupAssignor(assignmentStrategy);</span><br><span class="line">    <span class="keyword">if</span> (assignor == <span class="keyword">null</span>) {</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Coordinator selected invalid assignment protocol: "</span> + assignmentStrategy);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 反序列化获取分区分配信息</span></span><br><span class="line">    Assignment assignment = ConsumerProtocol.deserializeAssignment(assignmentBuffer);</span><br><span class="line">    <span class="comment">// 标记需要从 GroupCoordinator 节点获取最近提交的 offset 值</span></span><br><span class="line">    subscriptions.needRefreshCommits();</span><br><span class="line">    <span class="comment">// 设置每个 topic 分区对应的消费状态</span></span><br><span class="line">    subscriptions.assignFromSubscribed(assignment.partitions());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历获取新分配的 topic，并更新本地记录的订阅信息</span></span><br><span class="line">    Set&lt;String&gt; addedTopics = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (TopicPartition tp : subscriptions.assignedPartitions()) {</span><br><span class="line">        <span class="keyword">if</span> (!joinedSubscription.contains(tp.topic())) {</span><br><span class="line">            addedTopics.add(tp.topic()); <span class="comment">// 新分配的分区</span></span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">if</span> (!addedTopics.isEmpty()) {</span><br><span class="line">        Set&lt;String&gt; newSubscription = <span class="keyword">new</span> HashSet&lt;&gt;(subscriptions.subscription());</span><br><span class="line">        Set&lt;String&gt; newJoinedSubscription = <span class="keyword">new</span> HashSet&lt;&gt;(joinedSubscription);</span><br><span class="line">        newSubscription.addAll(addedTopics);</span><br><span class="line">        newJoinedSubscription.addAll(addedTopics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用 AUTO_PATTERN 模式进行订阅</span></span><br><span class="line">        subscriptions.subscribeFromPattern(newSubscription);</span><br><span class="line">        joinedSubscription = newJoinedSubscription;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 更新本地缓存的集群元数据信息</span></span><br><span class="line">    metadata.setTopics(subscriptions.groupSubscription());</span><br><span class="line">    client.ensureFreshMetadata();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// give the assignor a chance to update internal state based on the received assignment</span></span><br><span class="line">    assignor.onAssignment(assignment);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重置下次自动提交 offset 的截止时间</span></span><br><span class="line">    nextAutoCommitDeadline = time.milliseconds() + autoCommitIntervalMs;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 应用监听分区再分配操作完成的监听器</span></span><br><span class="line">    ConsumerRebalanceListener listener = subscriptions.listener();</span><br><span class="line">    log.info(<span class="string">"Setting newly assigned partitions {} for group {}"</span>, subscriptions.assignedPartitions(), groupId);</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        Set&lt;TopicPartition&gt; assigned = <span class="keyword">new</span> HashSet&lt;&gt;(subscriptions.assignedPartitions());</span><br><span class="line">        listener.onPartitionsAssigned(assigned);</span><br><span class="line">    } <span class="keyword">catch</span> (WakeupException | InterruptException e) {</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">        log.error(<span class="string">"User provided listener {} for group {} failed on partition assignment"</span>, listener.getClass().getName(), groupId, e);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>上述方法主要做了以下 4 件事情：</p>
<ol>
<li>标记需要重新从集群获取最近一次提交的 offset 值。</li>
<li>重置本地记录的每个分区的消费状态，并更新本地记录的 topic 订阅信息。</li>
<li>条件性更新本地记录的集群元数据信息。</li>
<li>激活 ConsumerRebalanceListener 监听器的 onPartitionsAssigned 方法。</li>
</ol>
<p>前面我们介绍了 ConsumerRebalanceListener 接口的定义，在分区再分配操作执行之前会调用 <code>ConsumerRebalanceListener#onPartitionsRevoked</code> 方法，而另外一个方法 <code>ConsumerRebalanceListener#onPartitionsAssigned</code> 的调用时机则是位于这里。</p>

        <h4 id="分区消费-offset-提交策略">
          <a href="#分区消费-offset-提交策略" class="heading-link"><i class="fas fa-link"></i></a>分区消费 offset 提交策略</h4>
      <p>提交已经消费完成的消息对应的 offset 是保证消息不重复消费和遗漏消费的最重要的措施。这里提交的 offset 是下一条待消费消息的 offset，而非当前已经消费的最后一条消息的 offset。Kafka 默认会按照指定时间间隔自动提交消费者消费完成的 offset 值，同时也允许开发者手动控制 offset 的提交时机。提交操作分为同步（阻塞）和异步（非阻塞）两种，Kafka 为手动提交分别提供了对应 <code>KafkaConsumer#commitSync</code> 和 <code>KafkaConsumer#commitAsync</code> 方法实现，这些方法都存在多个重载版本，相应的实现均位于 ConsumerCoordinator 类中。</p>
<p>ConsumerCoordinator 类提供了多个提交 offset 的方法，区分同步和异步，这些方法之间的调用关系如下所示：</p>
<ul>
<li>同步 offset 提交</li>
</ul>
<figure class="highlight text"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">+ maybeAutoCommitOffsetsSync</span><br><span class="line">| ---- + commitOffsetsSync</span><br></pre></td></tr></tbody></table></div></figure>
<ul>
<li>异步 offset 提交</li>
</ul>
<figure class="highlight text"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">+ maybeAutoCommitOffsetsNow / maybeAutoCommitOffsetsAsync</span><br><span class="line">| ---- + doAutoCommitOffsetsAsync</span><br><span class="line">| ---- | ---- + commitOffsetsAsync</span><br><span class="line">| ---- | ---- | ---- + doCommitOffsetsAsync</span><br></pre></td></tr></tbody></table></div></figure>
<p>整个方法调用链路按照同步和异步提交方式分为两条独立的路线，自动提交和手动提交在底层实现上其实是复用的，下面的篇幅中我们分别分析同步提交和异步提交的具体实现细节。</p>

        <h5 id="同步-offset-提交策略">
          <a href="#同步-offset-提交策略" class="heading-link"><i class="fas fa-link"></i></a>同步 offset 提交策略</h5>
      <p>我们从 <code>ConsumerCoordinator#maybeAutoCommitOffsetsSync</code> 方法切入，该方法的调用时机有两个地方：</p>
<ol>
<li>执行分区再分配操作的准备阶段（<code>ConsumerCoordinator#onJoinPrepare</code> 方法）。</li>
<li>关闭消费者的时候（<code>ConsumerCoordinator#close</code> 方法，<code>KafkaConsumer#close</code> 方法在执行时会调用该方法）。</li>
</ol>
<p>前面曾提到过，当分区再分配操作完成之后，分区与消费者之间的订阅关系可能会发生变化，而 Kafka 又依赖于消费者自己去记录分区的消费状态，所以在执行分区再分配操作之前需要让每个消费者将自己维护的分区消费状态信息上报给集群，这样在完成分区重新分配之后，消费者可以通过请求就集群以知晓新分配的分区的消费 offset 位置，消费者关闭的过程本质上也是如此。这些场景下提交 offset 的过程必须是同步的，否则存在丢失消费状态的可能，最终将导致消息被重复消费。</p>
<p>方法 <code>ConsumerCoordinator#maybeAutoCommitOffsetsSync</code> 的实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">maybeAutoCommitOffsetsSync</span><span class="params">(<span class="keyword">long</span> timeoutMs)</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (autoCommitEnabled) {</span><br><span class="line">        <span class="comment">// 获取当前消费者订阅的所有 topic 分区，以及分区对应的消费状态信息</span></span><br><span class="line">        Map&lt;TopicPartition, OffsetAndMetadata&gt; allConsumedOffsets = subscriptions.allConsumed();</span><br><span class="line">        <span class="keyword">try</span> {</span><br><span class="line">            log.debug(<span class="string">"Sending synchronous auto-commit of offsets {} for group {}"</span>, allConsumedOffsets, groupId);</span><br><span class="line">            <span class="comment">// 执行同步 offset 提交</span></span><br><span class="line">            <span class="keyword">if</span> (!<span class="keyword">this</span>.commitOffsetsSync(allConsumedOffsets, timeoutMs)) {</span><br><span class="line">                log.debug(<span class="string">"Auto-commit of offsets {} for group {} timed out before completion"</span>, allConsumedOffsets, groupId);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// ... 省略异常处理</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>如果允许自动提交 offset，则上述方法首先会从本地获取当前消费者被分配的分区的消费状态，然后调用 <code>ConsumerCoordinator#commitOffsetsSync</code> 方法向集群提交 offset 值，方法 <code>KafkaConsumer#commitSync</code> 本质上也是调用了该方法实现对 offset 的提交操作。方法 <code>ConsumerCoordinator#commitOffsetsSync</code> 的实现如下：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">commitOffsetsSync</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, <span class="keyword">long</span> timeoutMs)</span> </span>{</span><br><span class="line">    <span class="comment">// 触发注册的监听 offset 提交完成的方法</span></span><br><span class="line">    <span class="keyword">this</span>.invokeCompletedOffsetCommitCallbacks();</span><br><span class="line">    <span class="comment">// 如果提交的 offset 数据为空，则直接返回</span></span><br><span class="line">    <span class="keyword">if</span> (offsets.isEmpty()) {</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> now = time.milliseconds();</span><br><span class="line">    <span class="keyword">long</span> startMs = now;</span><br><span class="line">    <span class="keyword">long</span> remainingMs = timeoutMs;</span><br><span class="line">    <span class="keyword">do</span> {</span><br><span class="line">        <span class="comment">// 如果目标 GroupCoordinator 节点不可用</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.coordinatorUnknown()) {</span><br><span class="line">            <span class="comment">// 尝试寻找负载最小且可用的 GroupCoordinator 节点</span></span><br><span class="line">            <span class="keyword">if</span> (!<span class="keyword">this</span>.ensureCoordinatorReady(now, remainingMs)) {</span><br><span class="line">                <span class="comment">// 如果目标 GroupCoordinator 节点未准备好接收请求</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            }</span><br><span class="line">            remainingMs = timeoutMs - (time.milliseconds() - startMs);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建并发送 OffsetCommitRequest 请求，提交 offset 值</span></span><br><span class="line">        RequestFuture&lt;Void&gt; future = <span class="keyword">this</span>.sendOffsetCommitRequest(offsets);</span><br><span class="line">        client.poll(future, remainingMs);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交成功</span></span><br><span class="line">        <span class="keyword">if</span> (future.succeeded()) {</span><br><span class="line">            <span class="keyword">if</span> (interceptors != <span class="keyword">null</span>) {</span><br><span class="line">                interceptors.onCommit(offsets);</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 提交失败，且不可重试，则抛出异常</span></span><br><span class="line">        <span class="keyword">if</span> (!future.isRetriable()) {</span><br><span class="line">            <span class="keyword">throw</span> future.exception();</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        time.sleep(retryBackoffMs);</span><br><span class="line"></span><br><span class="line">        now = time.milliseconds();</span><br><span class="line">        remainingMs = timeoutMs - (now - startMs);</span><br><span class="line">    } <span class="keyword">while</span> (remainingMs &gt; <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>同步 offset 提交的执行流程可以概括为：</p>
<ol>
<li>触发注册的监听 offset 提交完成的回调方法；</li>
<li>校验待提交的 offset 数据是否为空，如果为空则直接返回；</li>
<li>校验目标 GroupCoordinator 实例所在节点是否可用，如果不可用则尝试寻找负载最小且可用的节点；</li>
<li>创建并发送提交 offset 的 OffsetCommitRequest 请求；</li>
<li>处理请求的响应结果。</li>
</ol>
<p>所有的监听 offset 提交操作的 OffsetCommitCallback 都会被封装成 OffsetCommitCompletion 对象，记录到 <code>ConsumerCoordinator#completedOffsetCommits</code> 字段中，并在每次提交 offset 时触发调用。下面来看一下创建并发送 OffsetCommitRequest 请求的逻辑，实现位于 <code>ConsumerCoordinator#sendOffsetCommitRequest</code> 方法中：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;Void&gt; <span class="title">sendOffsetCommitRequest</span><span class="params">(<span class="keyword">final</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (offsets.isEmpty()) {</span><br><span class="line">        <span class="comment">// 如果没有请求的数据，则直接返回</span></span><br><span class="line">        <span class="keyword">return</span> RequestFuture.voidSuccess();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取 GroupCoordinator 节点，并检查其可达性</span></span><br><span class="line">    Node coordinator = <span class="keyword">this</span>.coordinator();</span><br><span class="line">    <span class="keyword">if</span> (coordinator == <span class="keyword">null</span>) {</span><br><span class="line">        <span class="keyword">return</span> RequestFuture.coordinatorNotAvailable();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 封装每个分区对应提交的 offset 数据</span></span><br><span class="line">    Map&lt;TopicPartition, OffsetCommitRequest.PartitionData&gt; offsetData = <span class="keyword">new</span> HashMap&lt;&gt;(offsets.size());</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, OffsetAndMetadata&gt; entry : offsets.entrySet()) {</span><br><span class="line">        OffsetAndMetadata offsetAndMetadata = entry.getValue();</span><br><span class="line">        <span class="keyword">if</span> (offsetAndMetadata.offset() &lt; <span class="number">0</span>) {</span><br><span class="line">            <span class="comment">// 非法的 offset 值</span></span><br><span class="line">            <span class="keyword">return</span> RequestFuture.failure(<span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid offset: "</span> + offsetAndMetadata.offset()));</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// key 是分区，value 是分区对应的请求数据</span></span><br><span class="line">        offsetData.put(entry.getKey(),</span><br><span class="line">                <span class="keyword">new</span> OffsetCommitRequest.PartitionData(offsetAndMetadata.offset(), offsetAndMetadata.metadata()));</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取当前消费者所属 group 的年代信息</span></span><br><span class="line">    <span class="keyword">final</span> Generation generation;</span><br><span class="line">    <span class="keyword">if</span> (subscriptions.partitionsAutoAssigned()) {</span><br><span class="line">        <span class="comment">// 如果是 AUTO_TOPICS 或 AUTO_PATTERN 订阅模式，则获取年代信息</span></span><br><span class="line">        generation = <span class="keyword">this</span>.generation();</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">        <span class="comment">// 对于 USER_ASSIGNED 模式，因为不涉及到分区再分配操作，所以没有年代信息</span></span><br><span class="line">        generation = Generation.NO_GENERATION;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">if</span> (generation == <span class="keyword">null</span>) {</span><br><span class="line">        <span class="comment">// 如果获取 group 年代信息失败，则说明当前消费者并不属于该 group，抛出异常，需要执行分区再分配</span></span><br><span class="line">        <span class="keyword">return</span> RequestFuture.failure(<span class="keyword">new</span> CommitFailedException());</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建 OffsetCommitRequest 请求</span></span><br><span class="line">    OffsetCommitRequest.Builder builder =</span><br><span class="line">            <span class="keyword">new</span> OffsetCommitRequest.Builder(groupId, offsetData)</span><br><span class="line">                    .setGenerationId(generation.generationId)</span><br><span class="line">                    .setMemberId(generation.memberId)</span><br><span class="line">                    .setRetentionTime(OffsetCommitRequest.DEFAULT_RETENTION_TIME);</span><br><span class="line"></span><br><span class="line">    log.trace(<span class="string">"Sending OffsetCommit request with {} to coordinator {} for group {}"</span>, offsets, coordinator, groupId);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 发送 OffsetCommitRequest 请求，并注册响应处理器</span></span><br><span class="line">    <span class="keyword">return</span> client.send(coordinator, builder).compose(<span class="keyword">new</span> OffsetCommitResponseHandler(offsets));</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>上述方法的执行流程如下：</p>
<ol>
<li>校验待发送的请求数据是否为空，如果为空则直接返回成功；</li>
<li>获取目标 GroupCoordinator 实例所在 broker 节点，并校验其可用性；</li>
<li>封装每个目标分区的待提交 offset 数据；</li>
<li>获取并校验当前 group 的年代信息，防止提交一些已经离开 group 的消费者的 offset 数据；</li>
<li>创建并缓存 OffsetCommitRequest 请求，同时注册响应结果处理器。</li>
</ol>
<p>整体流程都比较简单和直观，集群 GroupCoordinator 实例在收到 OffsetCommitRequest 请求之后，会依据请求指定的版本号决定将 offset 消费信息记录到 ZK 还是最新实现的 offset topic，我们将在后面分析 GroupCoordinator 组件的篇章中针对 OffsetCommitRequest 请求的处理过程进行深入分析。下面来看一下对于响应结果的处理过程，实现位于 <code>OffsetCommitResponseHandler#handle</code> 方法中：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(OffsetCommitResponse commitResponse, RequestFuture&lt;Void&gt; future)</span> </span>{</span><br><span class="line">    sensors.commitLatency.record(response.requestLatencyMs());</span><br><span class="line">    Set&lt;String&gt; unauthorizedTopics = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历对所有 topic 分区的响应</span></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, Short&gt; entry : commitResponse.responseData().entrySet()) {</span><br><span class="line">        TopicPartition tp = entry.getKey();</span><br><span class="line">        OffsetAndMetadata offsetAndMetadata = offsets.get(tp);</span><br><span class="line">        <span class="keyword">long</span> offset = offsetAndMetadata.offset();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取当前分区对应的响应错误码</span></span><br><span class="line">        Errors error = Errors.forCode(entry.getValue());</span><br><span class="line">        <span class="comment">// 正常响应</span></span><br><span class="line">        <span class="keyword">if</span> (error == Errors.NONE) {</span><br><span class="line">            log.debug(<span class="string">"Group {} committed offset {} for partition {}"</span>, groupId, offset, tp);</span><br><span class="line">            <span class="keyword">if</span> (subscriptions.isAssigned(tp)) {</span><br><span class="line">                <span class="comment">// 更新分区对应的消费状态</span></span><br><span class="line">                subscriptions.committed(tp, offsetAndMetadata);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">//  ... 省略异常响应处理的过程</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!unauthorizedTopics.isEmpty()) {</span><br><span class="line">        log.error(<span class="string">"Not authorized to commit to topics {} for group {}"</span>, unauthorizedTopics, groupId);</span><br><span class="line">        future.raise(<span class="keyword">new</span> TopicAuthorizationException(unauthorizedTopics));</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">        future.complete(<span class="keyword">null</span>);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>这里主要看一下对于正常响应的处理过程，一个消费者可能同时消费多个 topic 分区，前面我们已经说过对于每个 topic 分区的消费状态都是独立维护和提交的，所以对于响应的处理也需要针对每个 topic 分区进行单独处理。如果是正常响应，方法首先会确认对应 topic 分区是否分配给当前消费者，如果是的话则会更新对应的分区消费状态的 <code>TopicPartitionState#committed</code> 字段，本质上也就是将 <code>TopicPartitionState#position</code> 字段记录的消费 offset 值封装成 OffsetAndMetadata 对象进行赋值。</p>

        <h5 id="异步-offset-提交策略">
          <a href="#异步-offset-提交策略" class="heading-link"><i class="fas fa-link"></i></a>异步 offset 提交策略</h5>
      <p>下面继续看一下异步 offset 提交的过程，我们从 <code>ConsumerCoordinator#maybeAutoCommitOffsetsAsync</code> 方法切入。前面我们在分析 <code>ConsumerCoordinator#poll</code> 方法时曾提到了对于该方法的调用，方法的实现比较简单（如下），即判断是否启用了自动提交，如果启用了的话则首先判断对应的 GroupCoordinator 实例所在节点是否可用，如果不可用则修改下一次自动提交的时间戳，延迟到下一次执行，如果目标 GroupCoordinator 节点是可用的，同时自动提交的时间已到，则执行异步提交操作。</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">maybeAutoCommitOffsetsAsync</span><span class="params">(<span class="keyword">long</span> now)</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (autoCommitEnabled) {</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.coordinatorUnknown()) {</span><br><span class="line">            <span class="comment">// 目标 GroupCoordinator 节点不可达，稍后再试</span></span><br><span class="line">            <span class="keyword">this</span>.nextAutoCommitDeadline = now + retryBackoffMs;</span><br><span class="line">        } <span class="keyword">else</span> <span class="keyword">if</span> (now &gt;= nextAutoCommitDeadline) {</span><br><span class="line">            <span class="comment">// 时间已到，执行异步自动提交</span></span><br><span class="line">            <span class="keyword">this</span>.nextAutoCommitDeadline = now + autoCommitIntervalMs;</span><br><span class="line">            <span class="keyword">this</span>.doAutoCommitOffsetsAsync();</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>其中，方法 <code>ConsumerCoordinator#doAutoCommitOffsetsAsync</code> 除了在这里被调用之外，也会在 <code>ConsumerCoordinator#maybeAutoCommitOffsetsNow</code> 方法中被调用，用于立即发起一次异步提交 offset 请求，实现比较简单。方法 <code>ConsumerCoordinator#doAutoCommitOffsetsAsync</code> 的实现也比较简单，核心逻辑就是获取当前消费者消费的所有 topic 分区对应的消费状态信息，然后调用 <code>ConsumerCoordinator#commitOffsetsAsync</code> 方法执行异步提交操作。该方法首先会触发注册的监听 offset 提交完成的监听器，然后判断目标 GroupCoordinator 实例所在节点是否可用。如果可用则继续执行异步提交操作，如果不可用则会尝试寻找可用且负载最小的节点，并在找到的前提下继续执行异步提交，否则返回异常。</p>
<p>执行异步提交的核心实现位于 <code>ConsumerCoordinator#doCommitOffsetsAsync</code> 方法中：</p>
<figure class="highlight java"><div class="table-container"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doCommitOffsetsAsync</span><span class="params">(<span class="keyword">final</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, <span class="keyword">final</span> OffsetCommitCallback callback)</span> </span>{</span><br><span class="line">    <span class="comment">// 标记需要从 GroupCoordinator 节点获取最近提交的 offset 值</span></span><br><span class="line">    subscriptions.needRefreshCommits();</span><br><span class="line">    <span class="comment">// 创建并发送 OffsetCommitRequest 请求</span></span><br><span class="line">    RequestFuture&lt;Void&gt; future = <span class="keyword">this</span>.sendOffsetCommitRequest(offsets);</span><br><span class="line">    <span class="comment">// 封装 callback，用于监听 offset 提交结果</span></span><br><span class="line">    <span class="keyword">final</span> OffsetCommitCallback cb = callback == <span class="keyword">null</span> ? defaultOffsetCommitCallback : callback;</span><br><span class="line">    future.addListener(<span class="keyword">new</span> RequestFutureListener&lt;Void&gt;() {</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(Void value)</span> </span>{</span><br><span class="line">            <span class="keyword">if</span> (interceptors != <span class="keyword">null</span>) {</span><br><span class="line">                interceptors.onCommit(offsets);</span><br><span class="line">            }</span><br><span class="line">            completedOffsetCommits.add(<span class="keyword">new</span> OffsetCommitCompletion(cb, offsets, <span class="keyword">null</span>));</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(RuntimeException e)</span> </span>{</span><br><span class="line">            Exception commitException = e;</span><br><span class="line">            <span class="keyword">if</span> (e <span class="keyword">instanceof</span> RetriableException) {</span><br><span class="line">                commitException = <span class="keyword">new</span> RetriableCommitFailedException(e);</span><br><span class="line">            }</span><br><span class="line">            completedOffsetCommits.add(<span class="keyword">new</span> OffsetCommitCompletion(cb, offsets, commitException));</span><br><span class="line">        }</span><br><span class="line">    });</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></div></figure>
<p>执行提交 OffsetCommitRequest 请求之前，方法首先会标记需要从 GroupCoordinator 实例所在节点获取最近提交的 offset 值，这里的标记主要用于通知那些本地未有效记录分区消费状态的消费者。然后构造并缓存 OffsetCommitRequest 请求对象，等待下次 poll 操作时一并发送，方法 <code>ConsumerCoordinator#sendOffsetCommitRequest</code> 的执行逻辑在前面已经分析过。</p>
<p>异步发送和同步发送主要的区别在于是否立即调用 <code>ConsumerNetworkClient#poll</code> 方法阻塞发送请求，并处理响应结果。前面在介绍同步提交（<code>ConsumerCoordinator#commitOffsetsSync</code> 方法）时可以看到在构建完 OffsetCommitRequest 请求之后会立即执行 poll 方法，而在异步提交时，构建完 OffsetCommitRequest 请求之后并不会立即发送请求，而是会等到下一次执行 poll 方法时一并发送，并通过回调的方式处理响应结果。</p>

        <h3 id="总结">
          <a href="#总结" class="heading-link"><i class="fas fa-link"></i></a>总结</h3>
      <p>本文我们介绍了 java 版本的 KafkaConsumer 的使用，并深入分析了相关设计和实现，了解一个 group 名下的所有消费者区分 Leader 和 Follower 角色，其中 Leader 角色除了肩负普通消费者的职责外，还需要负责管理整个 group 的运行状态。此外，消费者在拉取消息时的预取策略虽然在设计上很简单，却很好的利用了消息拉取和消费这两者之间能够并行执行的特点，极大提升了消费者的运行性能。而分区再分配机制则为 Kafka 提供了良好的扩展性，保证在 topic 分区数据发生变化，以及消费者上下线时能够不停服，继续正常对外提供服务。</p>
<p>到此为止，关于 Kafka SDK 的相关实现已经基本介绍完了，从下一篇开始我们将转战服务端，分析 Kafka 集群各个组件的设计与实现。</p>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="https://plotor.github.io">zhenchao</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="https://plotor.github.io/2019/06/19/kafka/kafka-consumer/">https://plotor.github.io/2019/06/19/kafka/kafka-consumer/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://plotor.github.io/tags/Kafka/">Kafka</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2019/06/20/kafka/kafka-broker/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">Kafka 源码解析：Broker 节点的启动与关闭</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2019/06/18/kafka/kafka-producer/"><span class="paginator-prev__text">Kafka 源码解析：生产者运行机制</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div><div class="comments" id="comments"><div id="utterances-container"></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#KafkaConsumer-%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.</span> <span class="toc-text">
          KafkaConsumer 使用示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90"><span class="toc-number">2.</span> <span class="toc-text">
          消息消费过程分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A2%E9%98%85%E4%B8%BB%E9%A2%98"><span class="toc-number">2.1.</span> <span class="toc-text">
          订阅主题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%89%E5%8F%96%E6%B6%88%E6%81%AF"><span class="toc-number">2.2.</span> <span class="toc-text">
          拉取消息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E5%86%8D%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6"><span class="toc-number">2.3.</span> <span class="toc-text">
          分区再分配机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E6%B6%88%E8%B4%B9-offset-%E6%8F%90%E4%BA%A4%E7%AD%96%E7%95%A5"><span class="toc-number">2.4.</span> <span class="toc-text">
          分区消费 offset 提交策略</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5-offset-%E6%8F%90%E4%BA%A4%E7%AD%96%E7%95%A5"><span class="toc-number">2.4.1.</span> <span class="toc-text">
          同步 offset 提交策略</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5-offset-%E6%8F%90%E4%BA%A4%E7%AD%96%E7%95%A5"><span class="toc-number">2.4.2.</span> <span class="toc-text">
          异步 offset 提交策略</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">
          总结</span></a></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/author.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">追求技术深度，注重文章质量</p></div><div class="sidebar-ov-social"><a class="sidebar-ov-social-item" href="https://github.com/plotor" target="_blank" rel="noopener" data-popover="Github" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-github"></i></span></a><a class="sidebar-ov-social-item" href="https://weibo.com/" target="_blank" rel="noopener" data-popover="微博" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-weibo"></i></span></a><a class="sidebar-ov-social-item" href="null" target="_blank" rel="noopener" data-popover="微信" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-weixin"></i></span></a><a class="sidebar-ov-social-item" href="null" target="_blank" rel="noopener" data-popover="QQ" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-qq"></i></span></a><a class="sidebar-ov-social-item" href="https://twitter.com/" target="_blank" rel="noopener" data-popover="Twitter" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-twitter"></i></span></a></div><div class="sidebar-ov-feed"><span class="sidebar-ov-feed-rss"><a class="sidebar-ov-feed-rss__link" href="/atom.xml" target="_blank" rel="noopener"><span class="sidebar-ov-feed-rss__icon"><i class="fas fa-rss"></i></span><span>RSS 订阅</span></a></span></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">95</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">13</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">27</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2015~2025</span><span class="footer__devider"></span><span>Zhenchao All Rights Reserved</span><span class="footer__devider">|</span><span>浙ICP备 16010916 号</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v5.3.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.1</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><div class="search-mask"></div><div class="search-popup"><span class="search-close"></span><div class="search-input"><input placeholder="搜索文章（支持多关键词，请用空格分隔）"></div><div class="search-results"></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/ribbon.js@latest/dist/ribbon.min.js" size="120" alpha="0.6" zIndex="-1"></script><script src="https://cdn.jsdelivr.net/npm/lazyload@2.0.0-rc.2/lazyload.min.js"></script><script>function initSearch() {
  var isXML = true;
  var search_path = 'search.json';

  if (!search_path) {
    search_path = 'search.xml';
  } else if (/json$/i.test(search_path)) {
    isXML = false;
  }

  var path = '/' + search_path;
  $.ajax({
    url: path,
    dataType: isXML ? 'xml' : 'json',
    async: true,
    success: function (res) {
      var datas = isXML ? $('entry', res).map(function () {
        // 将 XML 转为 JSON
        return {
          title: $('title', this).text(),
          content: $('content', this).text(),
          url: $('url', this).text()
        };
      }).get() : res;
      var $input = $('.search-input input');
      var $result = $('.search-results');
      // 搜索对象（标题、内容）的权重，影响显示顺序
      var WEIGHT = { title: 100, content: 1 };
      var searchPost = function () {
        var searchText = $input.val().toLowerCase().trim();
        // 根据空白字符分隔关键字
        var keywords = searchText.split(/[\s]+/);
        // 搜索结果
        var matchPosts = [];

        // 有多个关键字时，将原文字整个保存下来
        if (keywords.length > 1) {
          keywords.push(searchText);
        }
        // 防止未输入字符时搜索
        if (searchText.length > 0) {
          datas.forEach(function (data) {
            var isMatch  = false;
            // 没有标题的文章使用预设的 i18n 变量代替
            var title = (data.title && data.title.trim()) || '[ 文章无标题 ]';
            var titleLower = title && title.toLowerCase();
            // 删除 HTML 标签 和 所有空白字符
            var content = data.content && data.content.replace(/<[^>]+>/g, '');
            var contentLower = content && content.toLowerCase();
            // 删除重复的 /
            var postURL = data.url && decodeURI(data.url).replace(/\/{2,}/g, '/');
            // 标题中匹配到的关键词
            var titleHitSlice = [];
            // 内容中匹配到的关键词
            var contentHitSlice = [];

            keywords.forEach(function (keyword) {
              /**
              * 获取匹配的关键词的索引
              * @param {String} keyword 要匹配的关键字
              * @param {String} text 原文字
              * @param {Boolean} caseSensitive 是否区分大小写
              * @param {Number} weight 匹配对象的权重。权重大的优先显示
              * @return {Array}
              */
              function getIndexByword (word, text, caseSensitive, weight) {
                if (!word || !text) {
                  return [];
                };

                var startIndex = 0; // 每次匹配的开始索引
                var index = -1;     // 匹配到的索引值
                var result = [];    // 匹配结果

                if (!caseSensitive) {
                  word = word.toLowerCase();
                  text = text.toLowerCase();
                }

                while((index = text.indexOf(word, startIndex)) !== -1) {
                  var hasMatch = false;
                  // 索引位置相同的关键词，保留长度较长的
                  titleHitSlice.forEach(function (hit) {
                    if (hit.index === index && hit.word.length < word.length) {
                      hit.word = word;
                      hasMatch = true;
                    }
                  });
                  startIndex = index + word.length;
                  !hasMatch && result.push({ index: index, word: word, weight: weight });
                }
                return result;
              }
              titleHitSlice = titleHitSlice.concat(getIndexByword(keyword, titleLower, false, WEIGHT.title));
              contentHitSlice = contentHitSlice.concat(getIndexByword(keyword, contentLower, false, WEIGHT.content));
            });

            var hitTitle = titleHitSlice.length;
            var hitContent = contentHitSlice.length;

            if (hitTitle > 0 || hitContent > 0) {
              isMatch = true;
            }
            if (isMatch) {
              ;[titleHitSlice, contentHitSlice].forEach(function (hit) {
                // 按照匹配文字的索引的递增顺序排序
                hit.sort(function (left, right) {
                  return left.index - right.index;
                });
              });
              /**
              * 给文本中匹配到的关键词添加标记，从而进行高亮显示
              * @param {String} text 原文本
              * @param {Array} hitSlice 匹配项的索引信息
              * @param {Number} start 开始索引
              * @param {Number} end 结束索引
              * @return {String}
              */
              function highlightKeyword (text, hitSlice, start, end) {
                if (!text || !hitSlice || !hitSlice.length) {
                  return;
                }

                var result = '';
                var startIndex = start;
                var endIndex = end;
                hitSlice.forEach(function (hit) {
                  if (hit.index < startIndex) {
                    return;
                  }

                  var hitWordEnd = hit.index + hit.word.length;
                  result += text.slice(startIndex, hit.index);
                  result += '<b>' + text.slice(hit.index, hitWordEnd) + '</b>';
                  startIndex = hitWordEnd;
                });
                result += text.slice(startIndex, endIndex);
                return result;
              }

              var postData = {};
              // 文章总的搜索权重
              var postWeight = titleHitSlice.length * WEIGHT.title + contentHitSlice.length * WEIGHT.content;
              // 标记匹配关键词后的标题
              var postTitle = highlightKeyword(title, titleHitSlice, 0, title.length) || title;
              // 标记匹配关键词后的内容
              var postContent;
              // 显示内容的长度
              var SHOW_WORD_LENGTH = 200;
              // 命中关键词前的字符显示长度
              var SHOW_WORD_FRONT_LENGTH = 20;
              var SHOW_WORD_END_LENGTH = SHOW_WORD_LENGTH - SHOW_WORD_FRONT_LENGTH;

              // 截取匹配的第一个字符，前后共 200 个字符来显示
              if (contentHitSlice.length > 0) {
                var firstIndex = contentHitSlice[0].index;
                var start = firstIndex > SHOW_WORD_FRONT_LENGTH ? firstIndex - SHOW_WORD_FRONT_LENGTH : 0;
                var end = firstIndex + SHOW_WORD_END_LENGTH;
                postContent = highlightKeyword(content, contentHitSlice, start, end);
              } else { // 未匹配到内容，直接截取前 200 个字符来显示
                postContent = content.slice(0, SHOW_WORD_LENGTH);
              }
              postData.title = postTitle;
              postData.content = postContent;
              postData.url = postURL;
              postData.weight = postWeight;
              matchPosts.push(postData);
            }
          });
        }

        var resultInnerHtml = '';
        if (matchPosts.length) {
          // 按权重递增的顺序排序，使权重大的优先显示
          matchPosts.sort(function (left, right) {
            return right.weight - left.weight;
          });
          resultInnerHtml += '<ul>';
          matchPosts.forEach(function (post) {
            resultInnerHtml += '<li><a class="search-results-title" href="' + post.url + '">';
            resultInnerHtml += post.title;
            resultInnerHtml += '</a><div class="search-results-content">';
            resultInnerHtml += post.content;
            resultInnerHtml += '</div></li>';
          });
          resultInnerHtml += '</ul>';
        } else {
          resultInnerHtml += '<div class="search-results-none"><i class="far fa-meh"></i></div>';
        }
        $result.html(resultInnerHtml);
      };
      $input.on('input', searchPost);
      $input.on('keyup', function (e) {
        if (e.keyCode === Stun.utils.codeToKeyCode('Enter')) {
          searchPost();
        }
      });
    }
  });
}

function closeSearch () {
  $('body').css({ overflow: 'auto' });
  $('.search-popup').css({ display: 'none' });
  $('.search-mask').css({ display: 'none' });
}

window.addEventListener('DOMContentLoaded', function () {
  Stun.utils.pjaxReloadLocalSearch = function () {
    $('.header-nav-search').on('click', function (e) {
      e.stopPropagation();
      $('body').css('overflow', 'hidden');
      $('.search-popup')
        .velocity('stop')
        .velocity('transition.expandIn', {
          duration: 300,
          complete: function () {
            $('.search-popup input').focus();
          }
        });
      $('.search-mask')
        .velocity('stop')
        .velocity('transition.fadeIn', {
          duration: 300
        });

      initSearch();
    });
    $('.search-mask, .search-close').on('click', function () {
      closeSearch();
    });
    $(document).on('keydown', function (e) {
      // Escape <=> 27
      if (e.keyCode === Stun.utils.codeToKeyCode('Escape')) {
        closeSearch();
      }
    });
  };

  Stun.utils.pjaxReloadLocalSearch();
}, false);

function safeOpenUrl(url) {
  var newTab = window.open();
  newTab.opener = null;
  newTab.location = url;
}

function extSearch(engine) {
  var engines = {
    google: 'https://www.google.com/search?q=',
    bing: 'https://cn.bing.com/search?q=',
    baidu: 'https://www.baidu.com/s?ie=UTF-8&wd=',
  };
  var host = window.location.host;
  var query = $('.search-input input').val().toLowerCase().trim();
  var uri = engines[engine] + query + ' site:' + host;

  if (query) {
    safeOpenUrl(uri);
  } else {
    Stun.utils.popAlert('warning', '请输入字符');
  }
}

var assistSearchList = window.CONFIG.assistSearch;

if (Array.isArray(assistSearchList)) {
  assistSearchList.forEach(function (name) {
    document.querySelector('.search-btns-item--' + name).addEventListener('click', function () {
      extSearch(name);
    }, false);
  });
}</script><script src="https://cdn.jsdelivr.net/npm/pjax@latest/pjax.min.js"></script><script>window.addEventListener('DOMContentLoaded', function () {
  var pjax = new Pjax({"selectors":["head title","#main",".pjax-reload",".header-inner"],"history":true,"scrollTo":false,"scrollRestoration":false,"cacheBust":false,"debug":false,"currentUrlFullReload":false,"timeout":0});
  // 加载进度条的计时器
  var loadingTimer = null;

  // 重置页面 Y 方向上的滚动偏移量
  document.addEventListener('pjax:send', function () {
    $('.header-nav-menu').removeClass('show');
    if (CONFIG.pjax && CONFIG.pjax.avoidBanner) {
      $('html').velocity('scroll', {
        duration: 500,
        offset: $('#header').height(),
        easing: 'easeInOutCubic'
      });
    }

    var loadingBarWidth = 20;
    var MAX_LOADING_WIDTH = 95;

    $('.loading-bar').addClass('loading');
    $('.loading-bar__progress').css('width', loadingBarWidth + '%');
    clearInterval(loadingTimer);
    loadingTimer = setInterval(function () {
      loadingBarWidth += 3;
      if (loadingBarWidth > MAX_LOADING_WIDTH) {
        loadingBarWidth = MAX_LOADING_WIDTH;
      }
      $('.loading-bar__progress').css('width', loadingBarWidth + '%');
    }, 500);
  }, false);

  window.addEventListener('pjax:complete', function () {
    clearInterval(loadingTimer);
    $('.loading-bar__progress').css('width', '100%');
    $('.loading-bar').removeClass('loading');
    setTimeout(function () {
      $('.loading-bar__progress').css('width', '0');
    }, 400);
    $('link[rel=prefetch], script[data-pjax-rm]').each(function () {
      $(this).remove();
    });
    $('script[data-pjax], #pjax-reload script').each(function () {
      $(this).parent().append($(this).remove());
    });

    if (Stun.utils.pjaxReloadBoot) {
      Stun.utils.pjaxReloadBoot();
    }
    if (Stun.utils.pjaxReloadScroll) {
      Stun.utils.pjaxReloadScroll();
    }
    if (Stun.utils.pjaxReloadSidebar) {
      Stun.utils.pjaxReloadSidebar();
    }
    if (true) {
      if (Stun.utils.pjaxReloadHeader) {
        Stun.utils.pjaxReloadHeader();
      }
      if (Stun.utils.pjaxReloadScrollIcon) {
        Stun.utils.pjaxReloadScrollIcon();
      }
      if (Stun.utils.pjaxReloadLocalSearch) {
        Stun.utils.pjaxReloadLocalSearch();
      }
    }
  }, false);
}, false);</script><div id="pjax-reload"></div><script data-pjax="">function loadUtterances() {
  var d = document, s = d.createElement('script');
  var container = d.getElementById('utterances-container');

  if (!container) {
    return;
  }
  s.src = 'https://utteranc.es/client.js';
  s.setAttribute('repo', 'plotor/hexo-comments');
  s.setAttribute('issue-term', 'title');
  s.setAttribute('label', 'utterances');
  s.setAttribute('theme', 'github-light');
  s.setAttribute('crossorigin', 'anonymous');
  s.setAttribute('async', '');
  if (true) {
    s.setAttribute('data-pjax-rm', '');
  }
  container.append(s);
}

if (true) {
  loadUtterances();
} else {
  window.addEventListener('DOMContentLoaded', loadUtterances, false);
}</script><script src="/js/utils.js?v=2.6.1"></script><script src="/js/stun-boot.js?v=2.6.1"></script><script src="/js/scroll.js?v=2.6.1"></script><script src="/js/header.js?v=2.6.1"></script><script src="/js/sidebar.js?v=2.6.1"></script><script type="application/json" src="/search.json"></script></body></html>